<!-- some code adapted from www.degeneratestate.org/static/metal_lyrics/metal_line.html -->
<!-- <!DOCTYPE html>
<meta content="utf-8"> -->
<style> /* set the CSS */

body {
  font: 12px Arial;
}

svg {
  font: 12px Helvetica;
}

path {
  stroke: steelblue;
  stroke-width: 2;
  fill: none;
}

.grid line {
  stroke: lightgrey;
  stroke-opacity: 0.4;
  shape-rendering: crispEdges;
}

.grid path {
  stroke-width: 0;
}

.axis path,
.axis lineper {
  fill: none;
  stroke: grey;
  stroke-width: 1;
  shape-rendering: crispEdges;
}

div.tooltip {
  position: absolute;
  text-align: center;
  width: 150px;
  height: 28px;
  padding: 2px;
  font: 12px sans-serif;
  background: lightsteelblue;
  border: 0px;
  border-radius: 8px;
  pointer-events: none;
}

div.tooltipscore {
  position: absolute;
  text-align: center;
  width: 150px;
  height: 50px;
  padding: 2px;
  font: 10px sans-serif;
  background: lightsteelblue;
  border: 0px;
  border-radius: 8px;
  pointer-events: none;
}

.category_header {
  font: 12px sans-serif;
  font-weight: bolder;
  text-decoration: underline;
}

div.label {
  color: rgb(252, 251, 253);
  color: rgb(63, 0, 125);
  color: rgb(158, 155, 201);

  position: absolute;
  text-align: left;
  padding: 1px;
  border-spacing: 1px;
  font: 10px sans-serif;
  font-family: Sans-Serif;
  border: 0;
  pointer-events: none;
}

input {
  border: 1px dotted #ccc;
  background: white;
  font-family: monospace;
  padding: 10px 20px;
  font-size: 14px;
  margin: 20px 10px 30px 0;
  color: darkred;
}

.alert {
  font-family: monospace;
  padding: 10px 20px;
  font-size: 14px;
  margin: 20px 10px 30px 0;
  color: darkred;
}

ul.top_terms li {
  padding-right: 20px;
  font-size: 30pt;
  color: red;
}

input:focus {
  background-color: lightyellow;
  outline: none;
}

.snippet {
  padding-bottom: 10px;
  padding-left: 5px;
  padding-right: 5px;
  white-space: pre-wrap;
}

.snippet_header {
  font-size: 20px;
  font-family: Helvetica, Arial, Sans-Serif;
  font-weight: bolder;
  #text-decoration: underline;
  text-align: center;
  border-bottom-width: 10px;
  border-bottom-color: #888888;
  padding-bottom: 10px;
}

.topic_preview {
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
  padding-bottom: 10px;
  font-weight: normal;
  text-decoration: none;
}


#d3-div-1-categoryinfo {
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
  padding-bottom: 10px;    

}


#d3-div-1-title-div {
  font-size: 20px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
}

.text_header {
  font: 18px sans-serif;
  font-size: 18px;
  font-family: Helvetica, Arial, Sans-Serif;

  font-weight: bolder;
  text-decoration: underline;
  text-align: center;
  color: darkblue;
  padding-bottom: 10px;
}

.text_subheader {
  font-size: 14px;
  font-family: Helvetica, Arial, Sans-Serif;

  text-align: center;
}

.snippet_meta {
  border-top: 3px solid #4588ba;
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
  color: darkblue;
}

.contexts {
  width: 45%;
  float: left;
}

.neut_display {
  display: none;
  float: left
}

.scattertext {
  font-size: 10px;
  font-family: Helvetica, Arial, Sans-Serif;
}

.label {
  font-size: 10px;
  font-family: Helvetica, Arial, Sans-Serif;
}

.obscured {
  /*font-size: 14px;
  font-weight: normal;
  color: dimgrey;
  font-family: Helvetica;*/
  text-align: center;
}

.small_label {
  font-size: 10px;
}

#d3-div-1-corpus-stats {
  text-align: center;
}

#d3-div-1-cat {
}

#d3-div-1-notcat {
}

#d3-div-1-neut {
}

#d3-div-1-neutcol {
  display: none;
}

</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/4.6.0/d3.min.js" charset="utf-8"></script>
<script src="https://d3js.org/d3-scale-chromatic.v1.min.js" charset="utf-8"></script>

<!-- INSERT SEMIOTIC SQUARE -->
<!--<a onclick="maxFreq = Math.log(data.map(d => d.cat + d.ncat).reduce((a,b) => Math.max(a,b))); plotInterface.redrawPoints(0.1, d => (Math.log(d.ncat + d.cat)/maxFreq), d => d.s, false); plotInterface.redrawPoints(0.1, d => (Math.log(d.ncat + d.cat)/maxFreq), d => d.s, true)">View Score Plot</a>-->
<span id="d3-div-1-title-div"></span>
<div class="scattertext" id="d3-div-1"></div>
<div id="d3-div-1-corpus-stats"></div>
<div id="d3-div-1-overlapped-terms"></div>
<form name="d3-div-1-termForm" onSubmit="plotInterface.handleSearch(); return false;">
  <input name="Submit" type="submit" value="Search for term">
  <input type="text" id="d3-div-1-searchTerm" placeholder="Type a word or two&hellip;">
  <span id="d3-div-1-alertMessage" class="alert"></span>
</form>
<a name="d3-div-1-snippets"></a>
<a name="d3-div-1-snippetsalt"></a>
<div id="d3-div-1-termstats"></div>
<div id="d3-div-1-overlapped-terms-clicked"></div>
<div id="d3-div-1-categoryinfo" style="display: hidden"></div>
<div id="d3-div-2">
  <div class="d3-div-1-contexts">
    <div class="snippet_header" id="d3-div-1-cathead"></div>
    <div class="snippet" id="d3-div-1-cat"></div>
  </div>
  <div id="d3-div-1-notcol" class="d3-div-1-contexts">
    <div class="snippet_header" id="d3-div-1-notcathead"></div>
    <div class="snippet" id="d3-div-1-notcat"></div>
  </div>
  <div id="d3-div-1-neutcol" class="d3-div-1-contexts">
    <div class="snippet_header" id="d3-div-1-neuthead"></div>
    <div class="snippet" id="d3-div-1-neut"></div>
  </div>
</div>
<script charset="utf-8">
    // Created using Cozy: github.com/uwplse/cozy
function Rectangle(ax1, ay1, ax2, ay2) {
    this.ax1 = ax1;
    this.ay1 = ay1;
    this.ax2 = ax2;
    this.ay2 = ay2;
    this._left7 = undefined;
    this._right8 = undefined;
    this._parent9 = undefined;
    this._min_ax12 = undefined;
    this._min_ay13 = undefined;
    this._max_ay24 = undefined;
    this._height10 = undefined;
}
function RectangleHolder() {
    this.my_size = 0;
    (this)._root1 = null;
}
RectangleHolder.prototype.size = function () {
    return this.my_size;
};
RectangleHolder.prototype.add = function (x) {
    ++this.my_size;
    var _idx69 = (x).ax2;
    (x)._left7 = null;
    (x)._right8 = null;
    (x)._min_ax12 = (x).ax1;
    (x)._min_ay13 = (x).ay1;
    (x)._max_ay24 = (x).ay2;
    (x)._height10 = 0;
    var _previous70 = null;
    var _current71 = (this)._root1;
    var _is_left72 = false;
    while (!((_current71) == null)) {
        _previous70 = _current71;
        if ((_idx69) < ((_current71).ax2)) {
            _current71 = (_current71)._left7;
            _is_left72 = true;
        } else {
            _current71 = (_current71)._right8;
            _is_left72 = false;
        }
    }
    if ((_previous70) == null) {
        (this)._root1 = x;
    } else {
        (x)._parent9 = _previous70;
        if (_is_left72) {
            (_previous70)._left7 = x;
        } else {
            (_previous70)._right8 = x;
        }
    }
    var _cursor73 = (x)._parent9;
    var _changed74 = true;
    while ((_changed74) && (!((_cursor73) == (null)))) {
        var _old__min_ax1275 = (_cursor73)._min_ax12;
        var _old__min_ay1376 = (_cursor73)._min_ay13;
        var _old__max_ay2477 = (_cursor73)._max_ay24;
        var _old_height78 = (_cursor73)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval79 = (_cursor73).ax1;
        var _child80 = (_cursor73)._left7;
        if (!((_child80) == null)) {
            var _val81 = (_child80)._min_ax12;
            _augval79 = ((_augval79) < (_val81)) ? (_augval79) : (_val81);
        }
        var _child82 = (_cursor73)._right8;
        if (!((_child82) == null)) {
            var _val83 = (_child82)._min_ax12;
            _augval79 = ((_augval79) < (_val83)) ? (_augval79) : (_val83);
        }
        (_cursor73)._min_ax12 = _augval79;
        /* _min_ay13 is min of ay1 */
        var _augval84 = (_cursor73).ay1;
        var _child85 = (_cursor73)._left7;
        if (!((_child85) == null)) {
            var _val86 = (_child85)._min_ay13;
            _augval84 = ((_augval84) < (_val86)) ? (_augval84) : (_val86);
        }
        var _child87 = (_cursor73)._right8;
        if (!((_child87) == null)) {
            var _val88 = (_child87)._min_ay13;
            _augval84 = ((_augval84) < (_val88)) ? (_augval84) : (_val88);
        }
        (_cursor73)._min_ay13 = _augval84;
        /* _max_ay24 is max of ay2 */
        var _augval89 = (_cursor73).ay2;
        var _child90 = (_cursor73)._left7;
        if (!((_child90) == null)) {
            var _val91 = (_child90)._max_ay24;
            _augval89 = ((_augval89) < (_val91)) ? (_val91) : (_augval89);
        }
        var _child92 = (_cursor73)._right8;
        if (!((_child92) == null)) {
            var _val93 = (_child92)._max_ay24;
            _augval89 = ((_augval89) < (_val93)) ? (_val93) : (_augval89);
        }
        (_cursor73)._max_ay24 = _augval89;
        (_cursor73)._height10 = 1 + ((((((_cursor73)._left7) == null) ? (-1) : (((_cursor73)._left7)._height10)) > ((((_cursor73)._right8) == null) ? (-1) : (((_cursor73)._right8)._height10))) ? ((((_cursor73)._left7) == null) ? (-1) : (((_cursor73)._left7)._height10)) : ((((_cursor73)._right8) == null) ? (-1) : (((_cursor73)._right8)._height10)));
        _changed74 = false;
        _changed74 = (_changed74) || (!((_old__min_ax1275) == ((_cursor73)._min_ax12)));
        _changed74 = (_changed74) || (!((_old__min_ay1376) == ((_cursor73)._min_ay13)));
        _changed74 = (_changed74) || (!((_old__max_ay2477) == ((_cursor73)._max_ay24)));
        _changed74 = (_changed74) || (!((_old_height78) == ((_cursor73)._height10)));
        _cursor73 = (_cursor73)._parent9;
    }
    /* rebalance AVL tree */
    var _cursor94 = x;
    var _imbalance95;
    while (!(((_cursor94)._parent9) == null)) {
        _cursor94 = (_cursor94)._parent9;
        (_cursor94)._height10 = 1 + ((((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) > ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10))) ? ((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) : ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10)));
        _imbalance95 = ((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) - ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10));
        if ((_imbalance95) > (1)) {
            if ((((((_cursor94)._left7)._left7) == null) ? (-1) : ((((_cursor94)._left7)._left7)._height10)) < (((((_cursor94)._left7)._right8) == null) ? (-1) : ((((_cursor94)._left7)._right8)._height10))) {
                /* rotate ((_cursor94)._left7)._right8 */
                var _a96 = (_cursor94)._left7;
                var _b97 = (_a96)._right8;
                var _c98 = (_b97)._left7;
                /* replace _a96 with _b97 in (_a96)._parent9 */
                if (!(((_a96)._parent9) == null)) {
                    if ((((_a96)._parent9)._left7) == (_a96)) {
                        ((_a96)._parent9)._left7 = _b97;
                    } else {
                        ((_a96)._parent9)._right8 = _b97;
                    }
                }
                if (!((_b97) == null)) {
                    (_b97)._parent9 = (_a96)._parent9;
                }
                /* replace _c98 with _a96 in _b97 */
                (_b97)._left7 = _a96;
                if (!((_a96) == null)) {
                    (_a96)._parent9 = _b97;
                }
                /* replace _b97 with _c98 in _a96 */
                (_a96)._right8 = _c98;
                if (!((_c98) == null)) {
                    (_c98)._parent9 = _a96;
                }
                /* _min_ax12 is min of ax1 */
                var _augval99 = (_a96).ax1;
                var _child100 = (_a96)._left7;
                if (!((_child100) == null)) {
                    var _val101 = (_child100)._min_ax12;
                    _augval99 = ((_augval99) < (_val101)) ? (_augval99) : (_val101);
                }
                var _child102 = (_a96)._right8;
                if (!((_child102) == null)) {
                    var _val103 = (_child102)._min_ax12;
                    _augval99 = ((_augval99) < (_val103)) ? (_augval99) : (_val103);
                }
                (_a96)._min_ax12 = _augval99;
                /* _min_ay13 is min of ay1 */
                var _augval104 = (_a96).ay1;
                var _child105 = (_a96)._left7;
                if (!((_child105) == null)) {
                    var _val106 = (_child105)._min_ay13;
                    _augval104 = ((_augval104) < (_val106)) ? (_augval104) : (_val106);
                }
                var _child107 = (_a96)._right8;
                if (!((_child107) == null)) {
                    var _val108 = (_child107)._min_ay13;
                    _augval104 = ((_augval104) < (_val108)) ? (_augval104) : (_val108);
                }
                (_a96)._min_ay13 = _augval104;
                /* _max_ay24 is max of ay2 */
                var _augval109 = (_a96).ay2;
                var _child110 = (_a96)._left7;
                if (!((_child110) == null)) {
                    var _val111 = (_child110)._max_ay24;
                    _augval109 = ((_augval109) < (_val111)) ? (_val111) : (_augval109);
                }
                var _child112 = (_a96)._right8;
                if (!((_child112) == null)) {
                    var _val113 = (_child112)._max_ay24;
                    _augval109 = ((_augval109) < (_val113)) ? (_val113) : (_augval109);
                }
                (_a96)._max_ay24 = _augval109;
                (_a96)._height10 = 1 + ((((((_a96)._left7) == null) ? (-1) : (((_a96)._left7)._height10)) > ((((_a96)._right8) == null) ? (-1) : (((_a96)._right8)._height10))) ? ((((_a96)._left7) == null) ? (-1) : (((_a96)._left7)._height10)) : ((((_a96)._right8) == null) ? (-1) : (((_a96)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval114 = (_b97).ax1;
                var _child115 = (_b97)._left7;
                if (!((_child115) == null)) {
                    var _val116 = (_child115)._min_ax12;
                    _augval114 = ((_augval114) < (_val116)) ? (_augval114) : (_val116);
                }
                var _child117 = (_b97)._right8;
                if (!((_child117) == null)) {
                    var _val118 = (_child117)._min_ax12;
                    _augval114 = ((_augval114) < (_val118)) ? (_augval114) : (_val118);
                }
                (_b97)._min_ax12 = _augval114;
                /* _min_ay13 is min of ay1 */
                var _augval119 = (_b97).ay1;
                var _child120 = (_b97)._left7;
                if (!((_child120) == null)) {
                    var _val121 = (_child120)._min_ay13;
                    _augval119 = ((_augval119) < (_val121)) ? (_augval119) : (_val121);
                }
                var _child122 = (_b97)._right8;
                if (!((_child122) == null)) {
                    var _val123 = (_child122)._min_ay13;
                    _augval119 = ((_augval119) < (_val123)) ? (_augval119) : (_val123);
                }
                (_b97)._min_ay13 = _augval119;
                /* _max_ay24 is max of ay2 */
                var _augval124 = (_b97).ay2;
                var _child125 = (_b97)._left7;
                if (!((_child125) == null)) {
                    var _val126 = (_child125)._max_ay24;
                    _augval124 = ((_augval124) < (_val126)) ? (_val126) : (_augval124);
                }
                var _child127 = (_b97)._right8;
                if (!((_child127) == null)) {
                    var _val128 = (_child127)._max_ay24;
                    _augval124 = ((_augval124) < (_val128)) ? (_val128) : (_augval124);
                }
                (_b97)._max_ay24 = _augval124;
                (_b97)._height10 = 1 + ((((((_b97)._left7) == null) ? (-1) : (((_b97)._left7)._height10)) > ((((_b97)._right8) == null) ? (-1) : (((_b97)._right8)._height10))) ? ((((_b97)._left7) == null) ? (-1) : (((_b97)._left7)._height10)) : ((((_b97)._right8) == null) ? (-1) : (((_b97)._right8)._height10)));
                if (!(((_b97)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval129 = ((_b97)._parent9).ax1;
                    var _child130 = ((_b97)._parent9)._left7;
                    if (!((_child130) == null)) {
                        var _val131 = (_child130)._min_ax12;
                        _augval129 = ((_augval129) < (_val131)) ? (_augval129) : (_val131);
                    }
                    var _child132 = ((_b97)._parent9)._right8;
                    if (!((_child132) == null)) {
                        var _val133 = (_child132)._min_ax12;
                        _augval129 = ((_augval129) < (_val133)) ? (_augval129) : (_val133);
                    }
                    ((_b97)._parent9)._min_ax12 = _augval129;
                    /* _min_ay13 is min of ay1 */
                    var _augval134 = ((_b97)._parent9).ay1;
                    var _child135 = ((_b97)._parent9)._left7;
                    if (!((_child135) == null)) {
                        var _val136 = (_child135)._min_ay13;
                        _augval134 = ((_augval134) < (_val136)) ? (_augval134) : (_val136);
                    }
                    var _child137 = ((_b97)._parent9)._right8;
                    if (!((_child137) == null)) {
                        var _val138 = (_child137)._min_ay13;
                        _augval134 = ((_augval134) < (_val138)) ? (_augval134) : (_val138);
                    }
                    ((_b97)._parent9)._min_ay13 = _augval134;
                    /* _max_ay24 is max of ay2 */
                    var _augval139 = ((_b97)._parent9).ay2;
                    var _child140 = ((_b97)._parent9)._left7;
                    if (!((_child140) == null)) {
                        var _val141 = (_child140)._max_ay24;
                        _augval139 = ((_augval139) < (_val141)) ? (_val141) : (_augval139);
                    }
                    var _child142 = ((_b97)._parent9)._right8;
                    if (!((_child142) == null)) {
                        var _val143 = (_child142)._max_ay24;
                        _augval139 = ((_augval139) < (_val143)) ? (_val143) : (_augval139);
                    }
                    ((_b97)._parent9)._max_ay24 = _augval139;
                    ((_b97)._parent9)._height10 = 1 + (((((((_b97)._parent9)._left7) == null) ? (-1) : ((((_b97)._parent9)._left7)._height10)) > (((((_b97)._parent9)._right8) == null) ? (-1) : ((((_b97)._parent9)._right8)._height10))) ? (((((_b97)._parent9)._left7) == null) ? (-1) : ((((_b97)._parent9)._left7)._height10)) : (((((_b97)._parent9)._right8) == null) ? (-1) : ((((_b97)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b97;
                }
            }
            /* rotate (_cursor94)._left7 */
            var _a144 = _cursor94;
            var _b145 = (_a144)._left7;
            var _c146 = (_b145)._right8;
            /* replace _a144 with _b145 in (_a144)._parent9 */
            if (!(((_a144)._parent9) == null)) {
                if ((((_a144)._parent9)._left7) == (_a144)) {
                    ((_a144)._parent9)._left7 = _b145;
                } else {
                    ((_a144)._parent9)._right8 = _b145;
                }
            }
            if (!((_b145) == null)) {
                (_b145)._parent9 = (_a144)._parent9;
            }
            /* replace _c146 with _a144 in _b145 */
            (_b145)._right8 = _a144;
            if (!((_a144) == null)) {
                (_a144)._parent9 = _b145;
            }
            /* replace _b145 with _c146 in _a144 */
            (_a144)._left7 = _c146;
            if (!((_c146) == null)) {
                (_c146)._parent9 = _a144;
            }
            /* _min_ax12 is min of ax1 */
            var _augval147 = (_a144).ax1;
            var _child148 = (_a144)._left7;
            if (!((_child148) == null)) {
                var _val149 = (_child148)._min_ax12;
                _augval147 = ((_augval147) < (_val149)) ? (_augval147) : (_val149);
            }
            var _child150 = (_a144)._right8;
            if (!((_child150) == null)) {
                var _val151 = (_child150)._min_ax12;
                _augval147 = ((_augval147) < (_val151)) ? (_augval147) : (_val151);
            }
            (_a144)._min_ax12 = _augval147;
            /* _min_ay13 is min of ay1 */
            var _augval152 = (_a144).ay1;
            var _child153 = (_a144)._left7;
            if (!((_child153) == null)) {
                var _val154 = (_child153)._min_ay13;
                _augval152 = ((_augval152) < (_val154)) ? (_augval152) : (_val154);
            }
            var _child155 = (_a144)._right8;
            if (!((_child155) == null)) {
                var _val156 = (_child155)._min_ay13;
                _augval152 = ((_augval152) < (_val156)) ? (_augval152) : (_val156);
            }
            (_a144)._min_ay13 = _augval152;
            /* _max_ay24 is max of ay2 */
            var _augval157 = (_a144).ay2;
            var _child158 = (_a144)._left7;
            if (!((_child158) == null)) {
                var _val159 = (_child158)._max_ay24;
                _augval157 = ((_augval157) < (_val159)) ? (_val159) : (_augval157);
            }
            var _child160 = (_a144)._right8;
            if (!((_child160) == null)) {
                var _val161 = (_child160)._max_ay24;
                _augval157 = ((_augval157) < (_val161)) ? (_val161) : (_augval157);
            }
            (_a144)._max_ay24 = _augval157;
            (_a144)._height10 = 1 + ((((((_a144)._left7) == null) ? (-1) : (((_a144)._left7)._height10)) > ((((_a144)._right8) == null) ? (-1) : (((_a144)._right8)._height10))) ? ((((_a144)._left7) == null) ? (-1) : (((_a144)._left7)._height10)) : ((((_a144)._right8) == null) ? (-1) : (((_a144)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval162 = (_b145).ax1;
            var _child163 = (_b145)._left7;
            if (!((_child163) == null)) {
                var _val164 = (_child163)._min_ax12;
                _augval162 = ((_augval162) < (_val164)) ? (_augval162) : (_val164);
            }
            var _child165 = (_b145)._right8;
            if (!((_child165) == null)) {
                var _val166 = (_child165)._min_ax12;
                _augval162 = ((_augval162) < (_val166)) ? (_augval162) : (_val166);
            }
            (_b145)._min_ax12 = _augval162;
            /* _min_ay13 is min of ay1 */
            var _augval167 = (_b145).ay1;
            var _child168 = (_b145)._left7;
            if (!((_child168) == null)) {
                var _val169 = (_child168)._min_ay13;
                _augval167 = ((_augval167) < (_val169)) ? (_augval167) : (_val169);
            }
            var _child170 = (_b145)._right8;
            if (!((_child170) == null)) {
                var _val171 = (_child170)._min_ay13;
                _augval167 = ((_augval167) < (_val171)) ? (_augval167) : (_val171);
            }
            (_b145)._min_ay13 = _augval167;
            /* _max_ay24 is max of ay2 */
            var _augval172 = (_b145).ay2;
            var _child173 = (_b145)._left7;
            if (!((_child173) == null)) {
                var _val174 = (_child173)._max_ay24;
                _augval172 = ((_augval172) < (_val174)) ? (_val174) : (_augval172);
            }
            var _child175 = (_b145)._right8;
            if (!((_child175) == null)) {
                var _val176 = (_child175)._max_ay24;
                _augval172 = ((_augval172) < (_val176)) ? (_val176) : (_augval172);
            }
            (_b145)._max_ay24 = _augval172;
            (_b145)._height10 = 1 + ((((((_b145)._left7) == null) ? (-1) : (((_b145)._left7)._height10)) > ((((_b145)._right8) == null) ? (-1) : (((_b145)._right8)._height10))) ? ((((_b145)._left7) == null) ? (-1) : (((_b145)._left7)._height10)) : ((((_b145)._right8) == null) ? (-1) : (((_b145)._right8)._height10)));
            if (!(((_b145)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval177 = ((_b145)._parent9).ax1;
                var _child178 = ((_b145)._parent9)._left7;
                if (!((_child178) == null)) {
                    var _val179 = (_child178)._min_ax12;
                    _augval177 = ((_augval177) < (_val179)) ? (_augval177) : (_val179);
                }
                var _child180 = ((_b145)._parent9)._right8;
                if (!((_child180) == null)) {
                    var _val181 = (_child180)._min_ax12;
                    _augval177 = ((_augval177) < (_val181)) ? (_augval177) : (_val181);
                }
                ((_b145)._parent9)._min_ax12 = _augval177;
                /* _min_ay13 is min of ay1 */
                var _augval182 = ((_b145)._parent9).ay1;
                var _child183 = ((_b145)._parent9)._left7;
                if (!((_child183) == null)) {
                    var _val184 = (_child183)._min_ay13;
                    _augval182 = ((_augval182) < (_val184)) ? (_augval182) : (_val184);
                }
                var _child185 = ((_b145)._parent9)._right8;
                if (!((_child185) == null)) {
                    var _val186 = (_child185)._min_ay13;
                    _augval182 = ((_augval182) < (_val186)) ? (_augval182) : (_val186);
                }
                ((_b145)._parent9)._min_ay13 = _augval182;
                /* _max_ay24 is max of ay2 */
                var _augval187 = ((_b145)._parent9).ay2;
                var _child188 = ((_b145)._parent9)._left7;
                if (!((_child188) == null)) {
                    var _val189 = (_child188)._max_ay24;
                    _augval187 = ((_augval187) < (_val189)) ? (_val189) : (_augval187);
                }
                var _child190 = ((_b145)._parent9)._right8;
                if (!((_child190) == null)) {
                    var _val191 = (_child190)._max_ay24;
                    _augval187 = ((_augval187) < (_val191)) ? (_val191) : (_augval187);
                }
                ((_b145)._parent9)._max_ay24 = _augval187;
                ((_b145)._parent9)._height10 = 1 + (((((((_b145)._parent9)._left7) == null) ? (-1) : ((((_b145)._parent9)._left7)._height10)) > (((((_b145)._parent9)._right8) == null) ? (-1) : ((((_b145)._parent9)._right8)._height10))) ? (((((_b145)._parent9)._left7) == null) ? (-1) : ((((_b145)._parent9)._left7)._height10)) : (((((_b145)._parent9)._right8) == null) ? (-1) : ((((_b145)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b145;
            }
            _cursor94 = (_cursor94)._parent9;
        } else if ((_imbalance95) < (-1)) {
            if ((((((_cursor94)._right8)._left7) == null) ? (-1) : ((((_cursor94)._right8)._left7)._height10)) > (((((_cursor94)._right8)._right8) == null) ? (-1) : ((((_cursor94)._right8)._right8)._height10))) {
                /* rotate ((_cursor94)._right8)._left7 */
                var _a192 = (_cursor94)._right8;
                var _b193 = (_a192)._left7;
                var _c194 = (_b193)._right8;
                /* replace _a192 with _b193 in (_a192)._parent9 */
                if (!(((_a192)._parent9) == null)) {
                    if ((((_a192)._parent9)._left7) == (_a192)) {
                        ((_a192)._parent9)._left7 = _b193;
                    } else {
                        ((_a192)._parent9)._right8 = _b193;
                    }
                }
                if (!((_b193) == null)) {
                    (_b193)._parent9 = (_a192)._parent9;
                }
                /* replace _c194 with _a192 in _b193 */
                (_b193)._right8 = _a192;
                if (!((_a192) == null)) {
                    (_a192)._parent9 = _b193;
                }
                /* replace _b193 with _c194 in _a192 */
                (_a192)._left7 = _c194;
                if (!((_c194) == null)) {
                    (_c194)._parent9 = _a192;
                }
                /* _min_ax12 is min of ax1 */
                var _augval195 = (_a192).ax1;
                var _child196 = (_a192)._left7;
                if (!((_child196) == null)) {
                    var _val197 = (_child196)._min_ax12;
                    _augval195 = ((_augval195) < (_val197)) ? (_augval195) : (_val197);
                }
                var _child198 = (_a192)._right8;
                if (!((_child198) == null)) {
                    var _val199 = (_child198)._min_ax12;
                    _augval195 = ((_augval195) < (_val199)) ? (_augval195) : (_val199);
                }
                (_a192)._min_ax12 = _augval195;
                /* _min_ay13 is min of ay1 */
                var _augval200 = (_a192).ay1;
                var _child201 = (_a192)._left7;
                if (!((_child201) == null)) {
                    var _val202 = (_child201)._min_ay13;
                    _augval200 = ((_augval200) < (_val202)) ? (_augval200) : (_val202);
                }
                var _child203 = (_a192)._right8;
                if (!((_child203) == null)) {
                    var _val204 = (_child203)._min_ay13;
                    _augval200 = ((_augval200) < (_val204)) ? (_augval200) : (_val204);
                }
                (_a192)._min_ay13 = _augval200;
                /* _max_ay24 is max of ay2 */
                var _augval205 = (_a192).ay2;
                var _child206 = (_a192)._left7;
                if (!((_child206) == null)) {
                    var _val207 = (_child206)._max_ay24;
                    _augval205 = ((_augval205) < (_val207)) ? (_val207) : (_augval205);
                }
                var _child208 = (_a192)._right8;
                if (!((_child208) == null)) {
                    var _val209 = (_child208)._max_ay24;
                    _augval205 = ((_augval205) < (_val209)) ? (_val209) : (_augval205);
                }
                (_a192)._max_ay24 = _augval205;
                (_a192)._height10 = 1 + ((((((_a192)._left7) == null) ? (-1) : (((_a192)._left7)._height10)) > ((((_a192)._right8) == null) ? (-1) : (((_a192)._right8)._height10))) ? ((((_a192)._left7) == null) ? (-1) : (((_a192)._left7)._height10)) : ((((_a192)._right8) == null) ? (-1) : (((_a192)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval210 = (_b193).ax1;
                var _child211 = (_b193)._left7;
                if (!((_child211) == null)) {
                    var _val212 = (_child211)._min_ax12;
                    _augval210 = ((_augval210) < (_val212)) ? (_augval210) : (_val212);
                }
                var _child213 = (_b193)._right8;
                if (!((_child213) == null)) {
                    var _val214 = (_child213)._min_ax12;
                    _augval210 = ((_augval210) < (_val214)) ? (_augval210) : (_val214);
                }
                (_b193)._min_ax12 = _augval210;
                /* _min_ay13 is min of ay1 */
                var _augval215 = (_b193).ay1;
                var _child216 = (_b193)._left7;
                if (!((_child216) == null)) {
                    var _val217 = (_child216)._min_ay13;
                    _augval215 = ((_augval215) < (_val217)) ? (_augval215) : (_val217);
                }
                var _child218 = (_b193)._right8;
                if (!((_child218) == null)) {
                    var _val219 = (_child218)._min_ay13;
                    _augval215 = ((_augval215) < (_val219)) ? (_augval215) : (_val219);
                }
                (_b193)._min_ay13 = _augval215;
                /* _max_ay24 is max of ay2 */
                var _augval220 = (_b193).ay2;
                var _child221 = (_b193)._left7;
                if (!((_child221) == null)) {
                    var _val222 = (_child221)._max_ay24;
                    _augval220 = ((_augval220) < (_val222)) ? (_val222) : (_augval220);
                }
                var _child223 = (_b193)._right8;
                if (!((_child223) == null)) {
                    var _val224 = (_child223)._max_ay24;
                    _augval220 = ((_augval220) < (_val224)) ? (_val224) : (_augval220);
                }
                (_b193)._max_ay24 = _augval220;
                (_b193)._height10 = 1 + ((((((_b193)._left7) == null) ? (-1) : (((_b193)._left7)._height10)) > ((((_b193)._right8) == null) ? (-1) : (((_b193)._right8)._height10))) ? ((((_b193)._left7) == null) ? (-1) : (((_b193)._left7)._height10)) : ((((_b193)._right8) == null) ? (-1) : (((_b193)._right8)._height10)));
                if (!(((_b193)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval225 = ((_b193)._parent9).ax1;
                    var _child226 = ((_b193)._parent9)._left7;
                    if (!((_child226) == null)) {
                        var _val227 = (_child226)._min_ax12;
                        _augval225 = ((_augval225) < (_val227)) ? (_augval225) : (_val227);
                    }
                    var _child228 = ((_b193)._parent9)._right8;
                    if (!((_child228) == null)) {
                        var _val229 = (_child228)._min_ax12;
                        _augval225 = ((_augval225) < (_val229)) ? (_augval225) : (_val229);
                    }
                    ((_b193)._parent9)._min_ax12 = _augval225;
                    /* _min_ay13 is min of ay1 */
                    var _augval230 = ((_b193)._parent9).ay1;
                    var _child231 = ((_b193)._parent9)._left7;
                    if (!((_child231) == null)) {
                        var _val232 = (_child231)._min_ay13;
                        _augval230 = ((_augval230) < (_val232)) ? (_augval230) : (_val232);
                    }
                    var _child233 = ((_b193)._parent9)._right8;
                    if (!((_child233) == null)) {
                        var _val234 = (_child233)._min_ay13;
                        _augval230 = ((_augval230) < (_val234)) ? (_augval230) : (_val234);
                    }
                    ((_b193)._parent9)._min_ay13 = _augval230;
                    /* _max_ay24 is max of ay2 */
                    var _augval235 = ((_b193)._parent9).ay2;
                    var _child236 = ((_b193)._parent9)._left7;
                    if (!((_child236) == null)) {
                        var _val237 = (_child236)._max_ay24;
                        _augval235 = ((_augval235) < (_val237)) ? (_val237) : (_augval235);
                    }
                    var _child238 = ((_b193)._parent9)._right8;
                    if (!((_child238) == null)) {
                        var _val239 = (_child238)._max_ay24;
                        _augval235 = ((_augval235) < (_val239)) ? (_val239) : (_augval235);
                    }
                    ((_b193)._parent9)._max_ay24 = _augval235;
                    ((_b193)._parent9)._height10 = 1 + (((((((_b193)._parent9)._left7) == null) ? (-1) : ((((_b193)._parent9)._left7)._height10)) > (((((_b193)._parent9)._right8) == null) ? (-1) : ((((_b193)._parent9)._right8)._height10))) ? (((((_b193)._parent9)._left7) == null) ? (-1) : ((((_b193)._parent9)._left7)._height10)) : (((((_b193)._parent9)._right8) == null) ? (-1) : ((((_b193)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b193;
                }
            }
            /* rotate (_cursor94)._right8 */
            var _a240 = _cursor94;
            var _b241 = (_a240)._right8;
            var _c242 = (_b241)._left7;
            /* replace _a240 with _b241 in (_a240)._parent9 */
            if (!(((_a240)._parent9) == null)) {
                if ((((_a240)._parent9)._left7) == (_a240)) {
                    ((_a240)._parent9)._left7 = _b241;
                } else {
                    ((_a240)._parent9)._right8 = _b241;
                }
            }
            if (!((_b241) == null)) {
                (_b241)._parent9 = (_a240)._parent9;
            }
            /* replace _c242 with _a240 in _b241 */
            (_b241)._left7 = _a240;
            if (!((_a240) == null)) {
                (_a240)._parent9 = _b241;
            }
            /* replace _b241 with _c242 in _a240 */
            (_a240)._right8 = _c242;
            if (!((_c242) == null)) {
                (_c242)._parent9 = _a240;
            }
            /* _min_ax12 is min of ax1 */
            var _augval243 = (_a240).ax1;
            var _child244 = (_a240)._left7;
            if (!((_child244) == null)) {
                var _val245 = (_child244)._min_ax12;
                _augval243 = ((_augval243) < (_val245)) ? (_augval243) : (_val245);
            }
            var _child246 = (_a240)._right8;
            if (!((_child246) == null)) {
                var _val247 = (_child246)._min_ax12;
                _augval243 = ((_augval243) < (_val247)) ? (_augval243) : (_val247);
            }
            (_a240)._min_ax12 = _augval243;
            /* _min_ay13 is min of ay1 */
            var _augval248 = (_a240).ay1;
            var _child249 = (_a240)._left7;
            if (!((_child249) == null)) {
                var _val250 = (_child249)._min_ay13;
                _augval248 = ((_augval248) < (_val250)) ? (_augval248) : (_val250);
            }
            var _child251 = (_a240)._right8;
            if (!((_child251) == null)) {
                var _val252 = (_child251)._min_ay13;
                _augval248 = ((_augval248) < (_val252)) ? (_augval248) : (_val252);
            }
            (_a240)._min_ay13 = _augval248;
            /* _max_ay24 is max of ay2 */
            var _augval253 = (_a240).ay2;
            var _child254 = (_a240)._left7;
            if (!((_child254) == null)) {
                var _val255 = (_child254)._max_ay24;
                _augval253 = ((_augval253) < (_val255)) ? (_val255) : (_augval253);
            }
            var _child256 = (_a240)._right8;
            if (!((_child256) == null)) {
                var _val257 = (_child256)._max_ay24;
                _augval253 = ((_augval253) < (_val257)) ? (_val257) : (_augval253);
            }
            (_a240)._max_ay24 = _augval253;
            (_a240)._height10 = 1 + ((((((_a240)._left7) == null) ? (-1) : (((_a240)._left7)._height10)) > ((((_a240)._right8) == null) ? (-1) : (((_a240)._right8)._height10))) ? ((((_a240)._left7) == null) ? (-1) : (((_a240)._left7)._height10)) : ((((_a240)._right8) == null) ? (-1) : (((_a240)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval258 = (_b241).ax1;
            var _child259 = (_b241)._left7;
            if (!((_child259) == null)) {
                var _val260 = (_child259)._min_ax12;
                _augval258 = ((_augval258) < (_val260)) ? (_augval258) : (_val260);
            }
            var _child261 = (_b241)._right8;
            if (!((_child261) == null)) {
                var _val262 = (_child261)._min_ax12;
                _augval258 = ((_augval258) < (_val262)) ? (_augval258) : (_val262);
            }
            (_b241)._min_ax12 = _augval258;
            /* _min_ay13 is min of ay1 */
            var _augval263 = (_b241).ay1;
            var _child264 = (_b241)._left7;
            if (!((_child264) == null)) {
                var _val265 = (_child264)._min_ay13;
                _augval263 = ((_augval263) < (_val265)) ? (_augval263) : (_val265);
            }
            var _child266 = (_b241)._right8;
            if (!((_child266) == null)) {
                var _val267 = (_child266)._min_ay13;
                _augval263 = ((_augval263) < (_val267)) ? (_augval263) : (_val267);
            }
            (_b241)._min_ay13 = _augval263;
            /* _max_ay24 is max of ay2 */
            var _augval268 = (_b241).ay2;
            var _child269 = (_b241)._left7;
            if (!((_child269) == null)) {
                var _val270 = (_child269)._max_ay24;
                _augval268 = ((_augval268) < (_val270)) ? (_val270) : (_augval268);
            }
            var _child271 = (_b241)._right8;
            if (!((_child271) == null)) {
                var _val272 = (_child271)._max_ay24;
                _augval268 = ((_augval268) < (_val272)) ? (_val272) : (_augval268);
            }
            (_b241)._max_ay24 = _augval268;
            (_b241)._height10 = 1 + ((((((_b241)._left7) == null) ? (-1) : (((_b241)._left7)._height10)) > ((((_b241)._right8) == null) ? (-1) : (((_b241)._right8)._height10))) ? ((((_b241)._left7) == null) ? (-1) : (((_b241)._left7)._height10)) : ((((_b241)._right8) == null) ? (-1) : (((_b241)._right8)._height10)));
            if (!(((_b241)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval273 = ((_b241)._parent9).ax1;
                var _child274 = ((_b241)._parent9)._left7;
                if (!((_child274) == null)) {
                    var _val275 = (_child274)._min_ax12;
                    _augval273 = ((_augval273) < (_val275)) ? (_augval273) : (_val275);
                }
                var _child276 = ((_b241)._parent9)._right8;
                if (!((_child276) == null)) {
                    var _val277 = (_child276)._min_ax12;
                    _augval273 = ((_augval273) < (_val277)) ? (_augval273) : (_val277);
                }
                ((_b241)._parent9)._min_ax12 = _augval273;
                /* _min_ay13 is min of ay1 */
                var _augval278 = ((_b241)._parent9).ay1;
                var _child279 = ((_b241)._parent9)._left7;
                if (!((_child279) == null)) {
                    var _val280 = (_child279)._min_ay13;
                    _augval278 = ((_augval278) < (_val280)) ? (_augval278) : (_val280);
                }
                var _child281 = ((_b241)._parent9)._right8;
                if (!((_child281) == null)) {
                    var _val282 = (_child281)._min_ay13;
                    _augval278 = ((_augval278) < (_val282)) ? (_augval278) : (_val282);
                }
                ((_b241)._parent9)._min_ay13 = _augval278;
                /* _max_ay24 is max of ay2 */
                var _augval283 = ((_b241)._parent9).ay2;
                var _child284 = ((_b241)._parent9)._left7;
                if (!((_child284) == null)) {
                    var _val285 = (_child284)._max_ay24;
                    _augval283 = ((_augval283) < (_val285)) ? (_val285) : (_augval283);
                }
                var _child286 = ((_b241)._parent9)._right8;
                if (!((_child286) == null)) {
                    var _val287 = (_child286)._max_ay24;
                    _augval283 = ((_augval283) < (_val287)) ? (_val287) : (_augval283);
                }
                ((_b241)._parent9)._max_ay24 = _augval283;
                ((_b241)._parent9)._height10 = 1 + (((((((_b241)._parent9)._left7) == null) ? (-1) : ((((_b241)._parent9)._left7)._height10)) > (((((_b241)._parent9)._right8) == null) ? (-1) : ((((_b241)._parent9)._right8)._height10))) ? (((((_b241)._parent9)._left7) == null) ? (-1) : ((((_b241)._parent9)._left7)._height10)) : (((((_b241)._parent9)._right8) == null) ? (-1) : ((((_b241)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b241;
            }
            _cursor94 = (_cursor94)._parent9;
        }
    }
};
RectangleHolder.prototype.remove = function (x) {
    --this.my_size;
    var _parent288 = (x)._parent9;
    var _left289 = (x)._left7;
    var _right290 = (x)._right8;
    var _new_x291;
    if (((_left289) == null) && ((_right290) == null)) {
        _new_x291 = null;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else if ((!((_left289) == null)) && ((_right290) == null)) {
        _new_x291 = _left289;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else if (((_left289) == null) && (!((_right290) == null))) {
        _new_x291 = _right290;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else {
        var _root292 = (x)._right8;
        var _x293 = _root292;
        var _descend294 = true;
        var _from_left295 = true;
        while (true) {
            if ((_x293) == null) {
                _x293 = null;
                break;
            }
            if (_descend294) {
                /* too small? */
                if (false) {
                    if ((!(((_x293)._right8) == null)) && (true)) {
                        if ((_x293) == (_root292)) {
                            _root292 = (_x293)._right8;
                        }
                        _x293 = (_x293)._right8;
                    } else if ((_x293) == (_root292)) {
                        _x293 = null;
                        break;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                } else if ((!(((_x293)._left7) == null)) && (true)) {
                    _x293 = (_x293)._left7;
                    /* too large? */
                } else if (false) {
                    if ((_x293) == (_root292)) {
                        _x293 = null;
                        break;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                    /* node ok? */
                } else if (true) {
                    break;
                } else if ((_x293) == (_root292)) {
                    _root292 = (_x293)._right8;
                    _x293 = (_x293)._right8;
                } else {
                    if ((!(((_x293)._right8) == null)) && (true)) {
                        if ((_x293) == (_root292)) {
                            _root292 = (_x293)._right8;
                        }
                        _x293 = (_x293)._right8;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                }
            } else if (_from_left295) {
                if (false) {
                    _x293 = null;
                    break;
                } else if (true) {
                    break;
                } else if ((!(((_x293)._right8) == null)) && (true)) {
                    _descend294 = true;
                    if ((_x293) == (_root292)) {
                        _root292 = (_x293)._right8;
                    }
                    _x293 = (_x293)._right8;
                } else if ((_x293) == (_root292)) {
                    _x293 = null;
                    break;
                } else {
                    _descend294 = false;
                    _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                    _x293 = (_x293)._parent9;
                }
            } else {
                if ((_x293) == (_root292)) {
                    _x293 = null;
                    break;
                } else {
                    _descend294 = false;
                    _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                    _x293 = (_x293)._parent9;
                }
            }
        }
        _new_x291 = _x293;
        var _mp296 = (_x293)._parent9;
        var _mr297 = (_x293)._right8;
        /* replace _x293 with _mr297 in _mp296 */
        if (!((_mp296) == null)) {
            if (((_mp296)._left7) == (_x293)) {
                (_mp296)._left7 = _mr297;
            } else {
                (_mp296)._right8 = _mr297;
            }
        }
        if (!((_mr297) == null)) {
            (_mr297)._parent9 = _mp296;
        }
        /* replace x with _x293 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _x293;
            } else {
                (_parent288)._right8 = _x293;
            }
        }
        if (!((_x293) == null)) {
            (_x293)._parent9 = _parent288;
        }
        /* replace null with _left289 in _x293 */
        (_x293)._left7 = _left289;
        if (!((_left289) == null)) {
            (_left289)._parent9 = _x293;
        }
        /* replace _mr297 with (x)._right8 in _x293 */
        (_x293)._right8 = (x)._right8;
        if (!(((x)._right8) == null)) {
            ((x)._right8)._parent9 = _x293;
        }
        /* _min_ax12 is min of ax1 */
        var _augval298 = (_x293).ax1;
        var _child299 = (_x293)._left7;
        if (!((_child299) == null)) {
            var _val300 = (_child299)._min_ax12;
            _augval298 = ((_augval298) < (_val300)) ? (_augval298) : (_val300);
        }
        var _child301 = (_x293)._right8;
        if (!((_child301) == null)) {
            var _val302 = (_child301)._min_ax12;
            _augval298 = ((_augval298) < (_val302)) ? (_augval298) : (_val302);
        }
        (_x293)._min_ax12 = _augval298;
        /* _min_ay13 is min of ay1 */
        var _augval303 = (_x293).ay1;
        var _child304 = (_x293)._left7;
        if (!((_child304) == null)) {
            var _val305 = (_child304)._min_ay13;
            _augval303 = ((_augval303) < (_val305)) ? (_augval303) : (_val305);
        }
        var _child306 = (_x293)._right8;
        if (!((_child306) == null)) {
            var _val307 = (_child306)._min_ay13;
            _augval303 = ((_augval303) < (_val307)) ? (_augval303) : (_val307);
        }
        (_x293)._min_ay13 = _augval303;
        /* _max_ay24 is max of ay2 */
        var _augval308 = (_x293).ay2;
        var _child309 = (_x293)._left7;
        if (!((_child309) == null)) {
            var _val310 = (_child309)._max_ay24;
            _augval308 = ((_augval308) < (_val310)) ? (_val310) : (_augval308);
        }
        var _child311 = (_x293)._right8;
        if (!((_child311) == null)) {
            var _val312 = (_child311)._max_ay24;
            _augval308 = ((_augval308) < (_val312)) ? (_val312) : (_augval308);
        }
        (_x293)._max_ay24 = _augval308;
        (_x293)._height10 = 1 + ((((((_x293)._left7) == null) ? (-1) : (((_x293)._left7)._height10)) > ((((_x293)._right8) == null) ? (-1) : (((_x293)._right8)._height10))) ? ((((_x293)._left7) == null) ? (-1) : (((_x293)._left7)._height10)) : ((((_x293)._right8) == null) ? (-1) : (((_x293)._right8)._height10)));
        var _cursor313 = _mp296;
        var _changed314 = true;
        while ((_changed314) && (!((_cursor313) == (_parent288)))) {
            var _old__min_ax12315 = (_cursor313)._min_ax12;
            var _old__min_ay13316 = (_cursor313)._min_ay13;
            var _old__max_ay24317 = (_cursor313)._max_ay24;
            var _old_height318 = (_cursor313)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval319 = (_cursor313).ax1;
            var _child320 = (_cursor313)._left7;
            if (!((_child320) == null)) {
                var _val321 = (_child320)._min_ax12;
                _augval319 = ((_augval319) < (_val321)) ? (_augval319) : (_val321);
            }
            var _child322 = (_cursor313)._right8;
            if (!((_child322) == null)) {
                var _val323 = (_child322)._min_ax12;
                _augval319 = ((_augval319) < (_val323)) ? (_augval319) : (_val323);
            }
            (_cursor313)._min_ax12 = _augval319;
            /* _min_ay13 is min of ay1 */
            var _augval324 = (_cursor313).ay1;
            var _child325 = (_cursor313)._left7;
            if (!((_child325) == null)) {
                var _val326 = (_child325)._min_ay13;
                _augval324 = ((_augval324) < (_val326)) ? (_augval324) : (_val326);
            }
            var _child327 = (_cursor313)._right8;
            if (!((_child327) == null)) {
                var _val328 = (_child327)._min_ay13;
                _augval324 = ((_augval324) < (_val328)) ? (_augval324) : (_val328);
            }
            (_cursor313)._min_ay13 = _augval324;
            /* _max_ay24 is max of ay2 */
            var _augval329 = (_cursor313).ay2;
            var _child330 = (_cursor313)._left7;
            if (!((_child330) == null)) {
                var _val331 = (_child330)._max_ay24;
                _augval329 = ((_augval329) < (_val331)) ? (_val331) : (_augval329);
            }
            var _child332 = (_cursor313)._right8;
            if (!((_child332) == null)) {
                var _val333 = (_child332)._max_ay24;
                _augval329 = ((_augval329) < (_val333)) ? (_val333) : (_augval329);
            }
            (_cursor313)._max_ay24 = _augval329;
            (_cursor313)._height10 = 1 + ((((((_cursor313)._left7) == null) ? (-1) : (((_cursor313)._left7)._height10)) > ((((_cursor313)._right8) == null) ? (-1) : (((_cursor313)._right8)._height10))) ? ((((_cursor313)._left7) == null) ? (-1) : (((_cursor313)._left7)._height10)) : ((((_cursor313)._right8) == null) ? (-1) : (((_cursor313)._right8)._height10)));
            _changed314 = false;
            _changed314 = (_changed314) || (!((_old__min_ax12315) == ((_cursor313)._min_ax12)));
            _changed314 = (_changed314) || (!((_old__min_ay13316) == ((_cursor313)._min_ay13)));
            _changed314 = (_changed314) || (!((_old__max_ay24317) == ((_cursor313)._max_ay24)));
            _changed314 = (_changed314) || (!((_old_height318) == ((_cursor313)._height10)));
            _cursor313 = (_cursor313)._parent9;
        }
    }
    var _cursor334 = _parent288;
    var _changed335 = true;
    while ((_changed335) && (!((_cursor334) == (null)))) {
        var _old__min_ax12336 = (_cursor334)._min_ax12;
        var _old__min_ay13337 = (_cursor334)._min_ay13;
        var _old__max_ay24338 = (_cursor334)._max_ay24;
        var _old_height339 = (_cursor334)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval340 = (_cursor334).ax1;
        var _child341 = (_cursor334)._left7;
        if (!((_child341) == null)) {
            var _val342 = (_child341)._min_ax12;
            _augval340 = ((_augval340) < (_val342)) ? (_augval340) : (_val342);
        }
        var _child343 = (_cursor334)._right8;
        if (!((_child343) == null)) {
            var _val344 = (_child343)._min_ax12;
            _augval340 = ((_augval340) < (_val344)) ? (_augval340) : (_val344);
        }
        (_cursor334)._min_ax12 = _augval340;
        /* _min_ay13 is min of ay1 */
        var _augval345 = (_cursor334).ay1;
        var _child346 = (_cursor334)._left7;
        if (!((_child346) == null)) {
            var _val347 = (_child346)._min_ay13;
            _augval345 = ((_augval345) < (_val347)) ? (_augval345) : (_val347);
        }
        var _child348 = (_cursor334)._right8;
        if (!((_child348) == null)) {
            var _val349 = (_child348)._min_ay13;
            _augval345 = ((_augval345) < (_val349)) ? (_augval345) : (_val349);
        }
        (_cursor334)._min_ay13 = _augval345;
        /* _max_ay24 is max of ay2 */
        var _augval350 = (_cursor334).ay2;
        var _child351 = (_cursor334)._left7;
        if (!((_child351) == null)) {
            var _val352 = (_child351)._max_ay24;
            _augval350 = ((_augval350) < (_val352)) ? (_val352) : (_augval350);
        }
        var _child353 = (_cursor334)._right8;
        if (!((_child353) == null)) {
            var _val354 = (_child353)._max_ay24;
            _augval350 = ((_augval350) < (_val354)) ? (_val354) : (_augval350);
        }
        (_cursor334)._max_ay24 = _augval350;
        (_cursor334)._height10 = 1 + ((((((_cursor334)._left7) == null) ? (-1) : (((_cursor334)._left7)._height10)) > ((((_cursor334)._right8) == null) ? (-1) : (((_cursor334)._right8)._height10))) ? ((((_cursor334)._left7) == null) ? (-1) : (((_cursor334)._left7)._height10)) : ((((_cursor334)._right8) == null) ? (-1) : (((_cursor334)._right8)._height10)));
        _changed335 = false;
        _changed335 = (_changed335) || (!((_old__min_ax12336) == ((_cursor334)._min_ax12)));
        _changed335 = (_changed335) || (!((_old__min_ay13337) == ((_cursor334)._min_ay13)));
        _changed335 = (_changed335) || (!((_old__max_ay24338) == ((_cursor334)._max_ay24)));
        _changed335 = (_changed335) || (!((_old_height339) == ((_cursor334)._height10)));
        _cursor334 = (_cursor334)._parent9;
    }
    if (((this)._root1) == (x)) {
        (this)._root1 = _new_x291;
    }
};
RectangleHolder.prototype.updateAx1 = function (__x, new_val) {
    if ((__x).ax1 != new_val) {
        /* _min_ax12 is min of ax1 */
        var _augval355 = new_val;
        var _child356 = (__x)._left7;
        if (!((_child356) == null)) {
            var _val357 = (_child356)._min_ax12;
            _augval355 = ((_augval355) < (_val357)) ? (_augval355) : (_val357);
        }
        var _child358 = (__x)._right8;
        if (!((_child358) == null)) {
            var _val359 = (_child358)._min_ax12;
            _augval355 = ((_augval355) < (_val359)) ? (_augval355) : (_val359);
        }
        (__x)._min_ax12 = _augval355;
        var _cursor360 = (__x)._parent9;
        var _changed361 = true;
        while ((_changed361) && (!((_cursor360) == (null)))) {
            var _old__min_ax12362 = (_cursor360)._min_ax12;
            var _old_height363 = (_cursor360)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval364 = (_cursor360).ax1;
            var _child365 = (_cursor360)._left7;
            if (!((_child365) == null)) {
                var _val366 = (_child365)._min_ax12;
                _augval364 = ((_augval364) < (_val366)) ? (_augval364) : (_val366);
            }
            var _child367 = (_cursor360)._right8;
            if (!((_child367) == null)) {
                var _val368 = (_child367)._min_ax12;
                _augval364 = ((_augval364) < (_val368)) ? (_augval364) : (_val368);
            }
            (_cursor360)._min_ax12 = _augval364;
            (_cursor360)._height10 = 1 + ((((((_cursor360)._left7) == null) ? (-1) : (((_cursor360)._left7)._height10)) > ((((_cursor360)._right8) == null) ? (-1) : (((_cursor360)._right8)._height10))) ? ((((_cursor360)._left7) == null) ? (-1) : (((_cursor360)._left7)._height10)) : ((((_cursor360)._right8) == null) ? (-1) : (((_cursor360)._right8)._height10)));
            _changed361 = false;
            _changed361 = (_changed361) || (!((_old__min_ax12362) == ((_cursor360)._min_ax12)));
            _changed361 = (_changed361) || (!((_old_height363) == ((_cursor360)._height10)));
            _cursor360 = (_cursor360)._parent9;
        }
        (__x).ax1 = new_val;
    }
}
RectangleHolder.prototype.updateAy1 = function (__x, new_val) {
    if ((__x).ay1 != new_val) {
        /* _min_ay13 is min of ay1 */
        var _augval369 = new_val;
        var _child370 = (__x)._left7;
        if (!((_child370) == null)) {
            var _val371 = (_child370)._min_ay13;
            _augval369 = ((_augval369) < (_val371)) ? (_augval369) : (_val371);
        }
        var _child372 = (__x)._right8;
        if (!((_child372) == null)) {
            var _val373 = (_child372)._min_ay13;
            _augval369 = ((_augval369) < (_val373)) ? (_augval369) : (_val373);
        }
        (__x)._min_ay13 = _augval369;
        var _cursor374 = (__x)._parent9;
        var _changed375 = true;
        while ((_changed375) && (!((_cursor374) == (null)))) {
            var _old__min_ay13376 = (_cursor374)._min_ay13;
            var _old_height377 = (_cursor374)._height10;
            /* _min_ay13 is min of ay1 */
            var _augval378 = (_cursor374).ay1;
            var _child379 = (_cursor374)._left7;
            if (!((_child379) == null)) {
                var _val380 = (_child379)._min_ay13;
                _augval378 = ((_augval378) < (_val380)) ? (_augval378) : (_val380);
            }
            var _child381 = (_cursor374)._right8;
            if (!((_child381) == null)) {
                var _val382 = (_child381)._min_ay13;
                _augval378 = ((_augval378) < (_val382)) ? (_augval378) : (_val382);
            }
            (_cursor374)._min_ay13 = _augval378;
            (_cursor374)._height10 = 1 + ((((((_cursor374)._left7) == null) ? (-1) : (((_cursor374)._left7)._height10)) > ((((_cursor374)._right8) == null) ? (-1) : (((_cursor374)._right8)._height10))) ? ((((_cursor374)._left7) == null) ? (-1) : (((_cursor374)._left7)._height10)) : ((((_cursor374)._right8) == null) ? (-1) : (((_cursor374)._right8)._height10)));
            _changed375 = false;
            _changed375 = (_changed375) || (!((_old__min_ay13376) == ((_cursor374)._min_ay13)));
            _changed375 = (_changed375) || (!((_old_height377) == ((_cursor374)._height10)));
            _cursor374 = (_cursor374)._parent9;
        }
        (__x).ay1 = new_val;
    }
}
RectangleHolder.prototype.updateAx2 = function (__x, new_val) {
    if ((__x).ax2 != new_val) {
        var _parent383 = (__x)._parent9;
        var _left384 = (__x)._left7;
        var _right385 = (__x)._right8;
        var _new_x386;
        if (((_left384) == null) && ((_right385) == null)) {
            _new_x386 = null;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else if ((!((_left384) == null)) && ((_right385) == null)) {
            _new_x386 = _left384;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else if (((_left384) == null) && (!((_right385) == null))) {
            _new_x386 = _right385;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else {
            var _root387 = (__x)._right8;
            var _x388 = _root387;
            var _descend389 = true;
            var _from_left390 = true;
            while (true) {
                if ((_x388) == null) {
                    _x388 = null;
                    break;
                }
                if (_descend389) {
                    /* too small? */
                    if (false) {
                        if ((!(((_x388)._right8) == null)) && (true)) {
                            if ((_x388) == (_root387)) {
                                _root387 = (_x388)._right8;
                            }
                            _x388 = (_x388)._right8;
                        } else if ((_x388) == (_root387)) {
                            _x388 = null;
                            break;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                    } else if ((!(((_x388)._left7) == null)) && (true)) {
                        _x388 = (_x388)._left7;
                        /* too large? */
                    } else if (false) {
                        if ((_x388) == (_root387)) {
                            _x388 = null;
                            break;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                        /* node ok? */
                    } else if (true) {
                        break;
                    } else if ((_x388) == (_root387)) {
                        _root387 = (_x388)._right8;
                        _x388 = (_x388)._right8;
                    } else {
                        if ((!(((_x388)._right8) == null)) && (true)) {
                            if ((_x388) == (_root387)) {
                                _root387 = (_x388)._right8;
                            }
                            _x388 = (_x388)._right8;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                    }
                } else if (_from_left390) {
                    if (false) {
                        _x388 = null;
                        break;
                    } else if (true) {
                        break;
                    } else if ((!(((_x388)._right8) == null)) && (true)) {
                        _descend389 = true;
                        if ((_x388) == (_root387)) {
                            _root387 = (_x388)._right8;
                        }
                        _x388 = (_x388)._right8;
                    } else if ((_x388) == (_root387)) {
                        _x388 = null;
                        break;
                    } else {
                        _descend389 = false;
                        _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                        _x388 = (_x388)._parent9;
                    }
                } else {
                    if ((_x388) == (_root387)) {
                        _x388 = null;
                        break;
                    } else {
                        _descend389 = false;
                        _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                        _x388 = (_x388)._parent9;
                    }
                }
            }
            _new_x386 = _x388;
            var _mp391 = (_x388)._parent9;
            var _mr392 = (_x388)._right8;
            /* replace _x388 with _mr392 in _mp391 */
            if (!((_mp391) == null)) {
                if (((_mp391)._left7) == (_x388)) {
                    (_mp391)._left7 = _mr392;
                } else {
                    (_mp391)._right8 = _mr392;
                }
            }
            if (!((_mr392) == null)) {
                (_mr392)._parent9 = _mp391;
            }
            /* replace __x with _x388 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _x388;
                } else {
                    (_parent383)._right8 = _x388;
                }
            }
            if (!((_x388) == null)) {
                (_x388)._parent9 = _parent383;
            }
            /* replace null with _left384 in _x388 */
            (_x388)._left7 = _left384;
            if (!((_left384) == null)) {
                (_left384)._parent9 = _x388;
            }
            /* replace _mr392 with (__x)._right8 in _x388 */
            (_x388)._right8 = (__x)._right8;
            if (!(((__x)._right8) == null)) {
                ((__x)._right8)._parent9 = _x388;
            }
            /* _min_ax12 is min of ax1 */
            var _augval393 = (_x388).ax1;
            var _child394 = (_x388)._left7;
            if (!((_child394) == null)) {
                var _val395 = (_child394)._min_ax12;
                _augval393 = ((_augval393) < (_val395)) ? (_augval393) : (_val395);
            }
            var _child396 = (_x388)._right8;
            if (!((_child396) == null)) {
                var _val397 = (_child396)._min_ax12;
                _augval393 = ((_augval393) < (_val397)) ? (_augval393) : (_val397);
            }
            (_x388)._min_ax12 = _augval393;
            /* _min_ay13 is min of ay1 */
            var _augval398 = (_x388).ay1;
            var _child399 = (_x388)._left7;
            if (!((_child399) == null)) {
                var _val400 = (_child399)._min_ay13;
                _augval398 = ((_augval398) < (_val400)) ? (_augval398) : (_val400);
            }
            var _child401 = (_x388)._right8;
            if (!((_child401) == null)) {
                var _val402 = (_child401)._min_ay13;
                _augval398 = ((_augval398) < (_val402)) ? (_augval398) : (_val402);
            }
            (_x388)._min_ay13 = _augval398;
            /* _max_ay24 is max of ay2 */
            var _augval403 = (_x388).ay2;
            var _child404 = (_x388)._left7;
            if (!((_child404) == null)) {
                var _val405 = (_child404)._max_ay24;
                _augval403 = ((_augval403) < (_val405)) ? (_val405) : (_augval403);
            }
            var _child406 = (_x388)._right8;
            if (!((_child406) == null)) {
                var _val407 = (_child406)._max_ay24;
                _augval403 = ((_augval403) < (_val407)) ? (_val407) : (_augval403);
            }
            (_x388)._max_ay24 = _augval403;
            (_x388)._height10 = 1 + ((((((_x388)._left7) == null) ? (-1) : (((_x388)._left7)._height10)) > ((((_x388)._right8) == null) ? (-1) : (((_x388)._right8)._height10))) ? ((((_x388)._left7) == null) ? (-1) : (((_x388)._left7)._height10)) : ((((_x388)._right8) == null) ? (-1) : (((_x388)._right8)._height10)));
            var _cursor408 = _mp391;
            var _changed409 = true;
            while ((_changed409) && (!((_cursor408) == (_parent383)))) {
                var _old__min_ax12410 = (_cursor408)._min_ax12;
                var _old__min_ay13411 = (_cursor408)._min_ay13;
                var _old__max_ay24412 = (_cursor408)._max_ay24;
                var _old_height413 = (_cursor408)._height10;
                /* _min_ax12 is min of ax1 */
                var _augval414 = (_cursor408).ax1;
                var _child415 = (_cursor408)._left7;
                if (!((_child415) == null)) {
                    var _val416 = (_child415)._min_ax12;
                    _augval414 = ((_augval414) < (_val416)) ? (_augval414) : (_val416);
                }
                var _child417 = (_cursor408)._right8;
                if (!((_child417) == null)) {
                    var _val418 = (_child417)._min_ax12;
                    _augval414 = ((_augval414) < (_val418)) ? (_augval414) : (_val418);
                }
                (_cursor408)._min_ax12 = _augval414;
                /* _min_ay13 is min of ay1 */
                var _augval419 = (_cursor408).ay1;
                var _child420 = (_cursor408)._left7;
                if (!((_child420) == null)) {
                    var _val421 = (_child420)._min_ay13;
                    _augval419 = ((_augval419) < (_val421)) ? (_augval419) : (_val421);
                }
                var _child422 = (_cursor408)._right8;
                if (!((_child422) == null)) {
                    var _val423 = (_child422)._min_ay13;
                    _augval419 = ((_augval419) < (_val423)) ? (_augval419) : (_val423);
                }
                (_cursor408)._min_ay13 = _augval419;
                /* _max_ay24 is max of ay2 */
                var _augval424 = (_cursor408).ay2;
                var _child425 = (_cursor408)._left7;
                if (!((_child425) == null)) {
                    var _val426 = (_child425)._max_ay24;
                    _augval424 = ((_augval424) < (_val426)) ? (_val426) : (_augval424);
                }
                var _child427 = (_cursor408)._right8;
                if (!((_child427) == null)) {
                    var _val428 = (_child427)._max_ay24;
                    _augval424 = ((_augval424) < (_val428)) ? (_val428) : (_augval424);
                }
                (_cursor408)._max_ay24 = _augval424;
                (_cursor408)._height10 = 1 + ((((((_cursor408)._left7) == null) ? (-1) : (((_cursor408)._left7)._height10)) > ((((_cursor408)._right8) == null) ? (-1) : (((_cursor408)._right8)._height10))) ? ((((_cursor408)._left7) == null) ? (-1) : (((_cursor408)._left7)._height10)) : ((((_cursor408)._right8) == null) ? (-1) : (((_cursor408)._right8)._height10)));
                _changed409 = false;
                _changed409 = (_changed409) || (!((_old__min_ax12410) == ((_cursor408)._min_ax12)));
                _changed409 = (_changed409) || (!((_old__min_ay13411) == ((_cursor408)._min_ay13)));
                _changed409 = (_changed409) || (!((_old__max_ay24412) == ((_cursor408)._max_ay24)));
                _changed409 = (_changed409) || (!((_old_height413) == ((_cursor408)._height10)));
                _cursor408 = (_cursor408)._parent9;
            }
        }
        var _cursor429 = _parent383;
        var _changed430 = true;
        while ((_changed430) && (!((_cursor429) == (null)))) {
            var _old__min_ax12431 = (_cursor429)._min_ax12;
            var _old__min_ay13432 = (_cursor429)._min_ay13;
            var _old__max_ay24433 = (_cursor429)._max_ay24;
            var _old_height434 = (_cursor429)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval435 = (_cursor429).ax1;
            var _child436 = (_cursor429)._left7;
            if (!((_child436) == null)) {
                var _val437 = (_child436)._min_ax12;
                _augval435 = ((_augval435) < (_val437)) ? (_augval435) : (_val437);
            }
            var _child438 = (_cursor429)._right8;
            if (!((_child438) == null)) {
                var _val439 = (_child438)._min_ax12;
                _augval435 = ((_augval435) < (_val439)) ? (_augval435) : (_val439);
            }
            (_cursor429)._min_ax12 = _augval435;
            /* _min_ay13 is min of ay1 */
            var _augval440 = (_cursor429).ay1;
            var _child441 = (_cursor429)._left7;
            if (!((_child441) == null)) {
                var _val442 = (_child441)._min_ay13;
                _augval440 = ((_augval440) < (_val442)) ? (_augval440) : (_val442);
            }
            var _child443 = (_cursor429)._right8;
            if (!((_child443) == null)) {
                var _val444 = (_child443)._min_ay13;
                _augval440 = ((_augval440) < (_val444)) ? (_augval440) : (_val444);
            }
            (_cursor429)._min_ay13 = _augval440;
            /* _max_ay24 is max of ay2 */
            var _augval445 = (_cursor429).ay2;
            var _child446 = (_cursor429)._left7;
            if (!((_child446) == null)) {
                var _val447 = (_child446)._max_ay24;
                _augval445 = ((_augval445) < (_val447)) ? (_val447) : (_augval445);
            }
            var _child448 = (_cursor429)._right8;
            if (!((_child448) == null)) {
                var _val449 = (_child448)._max_ay24;
                _augval445 = ((_augval445) < (_val449)) ? (_val449) : (_augval445);
            }
            (_cursor429)._max_ay24 = _augval445;
            (_cursor429)._height10 = 1 + ((((((_cursor429)._left7) == null) ? (-1) : (((_cursor429)._left7)._height10)) > ((((_cursor429)._right8) == null) ? (-1) : (((_cursor429)._right8)._height10))) ? ((((_cursor429)._left7) == null) ? (-1) : (((_cursor429)._left7)._height10)) : ((((_cursor429)._right8) == null) ? (-1) : (((_cursor429)._right8)._height10)));
            _changed430 = false;
            _changed430 = (_changed430) || (!((_old__min_ax12431) == ((_cursor429)._min_ax12)));
            _changed430 = (_changed430) || (!((_old__min_ay13432) == ((_cursor429)._min_ay13)));
            _changed430 = (_changed430) || (!((_old__max_ay24433) == ((_cursor429)._max_ay24)));
            _changed430 = (_changed430) || (!((_old_height434) == ((_cursor429)._height10)));
            _cursor429 = (_cursor429)._parent9;
        }
        if (((this)._root1) == (__x)) {
            (this)._root1 = _new_x386;
        }
        (__x)._left7 = null;
        (__x)._right8 = null;
        (__x)._min_ax12 = (__x).ax1;
        (__x)._min_ay13 = (__x).ay1;
        (__x)._max_ay24 = (__x).ay2;
        (__x)._height10 = 0;
        var _previous450 = null;
        var _current451 = (this)._root1;
        var _is_left452 = false;
        while (!((_current451) == null)) {
            _previous450 = _current451;
            if ((new_val) < ((_current451).ax2)) {
                _current451 = (_current451)._left7;
                _is_left452 = true;
            } else {
                _current451 = (_current451)._right8;
                _is_left452 = false;
            }
        }
        if ((_previous450) == null) {
            (this)._root1 = __x;
        } else {
            (__x)._parent9 = _previous450;
            if (_is_left452) {
                (_previous450)._left7 = __x;
            } else {
                (_previous450)._right8 = __x;
            }
        }
        var _cursor453 = (__x)._parent9;
        var _changed454 = true;
        while ((_changed454) && (!((_cursor453) == (null)))) {
            var _old__min_ax12455 = (_cursor453)._min_ax12;
            var _old__min_ay13456 = (_cursor453)._min_ay13;
            var _old__max_ay24457 = (_cursor453)._max_ay24;
            var _old_height458 = (_cursor453)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval459 = (_cursor453).ax1;
            var _child460 = (_cursor453)._left7;
            if (!((_child460) == null)) {
                var _val461 = (_child460)._min_ax12;
                _augval459 = ((_augval459) < (_val461)) ? (_augval459) : (_val461);
            }
            var _child462 = (_cursor453)._right8;
            if (!((_child462) == null)) {
                var _val463 = (_child462)._min_ax12;
                _augval459 = ((_augval459) < (_val463)) ? (_augval459) : (_val463);
            }
            (_cursor453)._min_ax12 = _augval459;
            /* _min_ay13 is min of ay1 */
            var _augval464 = (_cursor453).ay1;
            var _child465 = (_cursor453)._left7;
            if (!((_child465) == null)) {
                var _val466 = (_child465)._min_ay13;
                _augval464 = ((_augval464) < (_val466)) ? (_augval464) : (_val466);
            }
            var _child467 = (_cursor453)._right8;
            if (!((_child467) == null)) {
                var _val468 = (_child467)._min_ay13;
                _augval464 = ((_augval464) < (_val468)) ? (_augval464) : (_val468);
            }
            (_cursor453)._min_ay13 = _augval464;
            /* _max_ay24 is max of ay2 */
            var _augval469 = (_cursor453).ay2;
            var _child470 = (_cursor453)._left7;
            if (!((_child470) == null)) {
                var _val471 = (_child470)._max_ay24;
                _augval469 = ((_augval469) < (_val471)) ? (_val471) : (_augval469);
            }
            var _child472 = (_cursor453)._right8;
            if (!((_child472) == null)) {
                var _val473 = (_child472)._max_ay24;
                _augval469 = ((_augval469) < (_val473)) ? (_val473) : (_augval469);
            }
            (_cursor453)._max_ay24 = _augval469;
            (_cursor453)._height10 = 1 + ((((((_cursor453)._left7) == null) ? (-1) : (((_cursor453)._left7)._height10)) > ((((_cursor453)._right8) == null) ? (-1) : (((_cursor453)._right8)._height10))) ? ((((_cursor453)._left7) == null) ? (-1) : (((_cursor453)._left7)._height10)) : ((((_cursor453)._right8) == null) ? (-1) : (((_cursor453)._right8)._height10)));
            _changed454 = false;
            _changed454 = (_changed454) || (!((_old__min_ax12455) == ((_cursor453)._min_ax12)));
            _changed454 = (_changed454) || (!((_old__min_ay13456) == ((_cursor453)._min_ay13)));
            _changed454 = (_changed454) || (!((_old__max_ay24457) == ((_cursor453)._max_ay24)));
            _changed454 = (_changed454) || (!((_old_height458) == ((_cursor453)._height10)));
            _cursor453 = (_cursor453)._parent9;
        }
        /* rebalance AVL tree */
        var _cursor474 = __x;
        var _imbalance475;
        while (!(((_cursor474)._parent9) == null)) {
            _cursor474 = (_cursor474)._parent9;
            (_cursor474)._height10 = 1 + ((((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) > ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10))) ? ((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) : ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10)));
            _imbalance475 = ((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) - ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10));
            if ((_imbalance475) > (1)) {
                if ((((((_cursor474)._left7)._left7) == null) ? (-1) : ((((_cursor474)._left7)._left7)._height10)) < (((((_cursor474)._left7)._right8) == null) ? (-1) : ((((_cursor474)._left7)._right8)._height10))) {
                    /* rotate ((_cursor474)._left7)._right8 */
                    var _a476 = (_cursor474)._left7;
                    var _b477 = (_a476)._right8;
                    var _c478 = (_b477)._left7;
                    /* replace _a476 with _b477 in (_a476)._parent9 */
                    if (!(((_a476)._parent9) == null)) {
                        if ((((_a476)._parent9)._left7) == (_a476)) {
                            ((_a476)._parent9)._left7 = _b477;
                        } else {
                            ((_a476)._parent9)._right8 = _b477;
                        }
                    }
                    if (!((_b477) == null)) {
                        (_b477)._parent9 = (_a476)._parent9;
                    }
                    /* replace _c478 with _a476 in _b477 */
                    (_b477)._left7 = _a476;
                    if (!((_a476) == null)) {
                        (_a476)._parent9 = _b477;
                    }
                    /* replace _b477 with _c478 in _a476 */
                    (_a476)._right8 = _c478;
                    if (!((_c478) == null)) {
                        (_c478)._parent9 = _a476;
                    }
                    /* _min_ax12 is min of ax1 */
                    var _augval479 = (_a476).ax1;
                    var _child480 = (_a476)._left7;
                    if (!((_child480) == null)) {
                        var _val481 = (_child480)._min_ax12;
                        _augval479 = ((_augval479) < (_val481)) ? (_augval479) : (_val481);
                    }
                    var _child482 = (_a476)._right8;
                    if (!((_child482) == null)) {
                        var _val483 = (_child482)._min_ax12;
                        _augval479 = ((_augval479) < (_val483)) ? (_augval479) : (_val483);
                    }
                    (_a476)._min_ax12 = _augval479;
                    /* _min_ay13 is min of ay1 */
                    var _augval484 = (_a476).ay1;
                    var _child485 = (_a476)._left7;
                    if (!((_child485) == null)) {
                        var _val486 = (_child485)._min_ay13;
                        _augval484 = ((_augval484) < (_val486)) ? (_augval484) : (_val486);
                    }
                    var _child487 = (_a476)._right8;
                    if (!((_child487) == null)) {
                        var _val488 = (_child487)._min_ay13;
                        _augval484 = ((_augval484) < (_val488)) ? (_augval484) : (_val488);
                    }
                    (_a476)._min_ay13 = _augval484;
                    /* _max_ay24 is max of ay2 */
                    var _augval489 = (_a476).ay2;
                    var _child490 = (_a476)._left7;
                    if (!((_child490) == null)) {
                        var _val491 = (_child490)._max_ay24;
                        _augval489 = ((_augval489) < (_val491)) ? (_val491) : (_augval489);
                    }
                    var _child492 = (_a476)._right8;
                    if (!((_child492) == null)) {
                        var _val493 = (_child492)._max_ay24;
                        _augval489 = ((_augval489) < (_val493)) ? (_val493) : (_augval489);
                    }
                    (_a476)._max_ay24 = _augval489;
                    (_a476)._height10 = 1 + ((((((_a476)._left7) == null) ? (-1) : (((_a476)._left7)._height10)) > ((((_a476)._right8) == null) ? (-1) : (((_a476)._right8)._height10))) ? ((((_a476)._left7) == null) ? (-1) : (((_a476)._left7)._height10)) : ((((_a476)._right8) == null) ? (-1) : (((_a476)._right8)._height10)));
                    /* _min_ax12 is min of ax1 */
                    var _augval494 = (_b477).ax1;
                    var _child495 = (_b477)._left7;
                    if (!((_child495) == null)) {
                        var _val496 = (_child495)._min_ax12;
                        _augval494 = ((_augval494) < (_val496)) ? (_augval494) : (_val496);
                    }
                    var _child497 = (_b477)._right8;
                    if (!((_child497) == null)) {
                        var _val498 = (_child497)._min_ax12;
                        _augval494 = ((_augval494) < (_val498)) ? (_augval494) : (_val498);
                    }
                    (_b477)._min_ax12 = _augval494;
                    /* _min_ay13 is min of ay1 */
                    var _augval499 = (_b477).ay1;
                    var _child500 = (_b477)._left7;
                    if (!((_child500) == null)) {
                        var _val501 = (_child500)._min_ay13;
                        _augval499 = ((_augval499) < (_val501)) ? (_augval499) : (_val501);
                    }
                    var _child502 = (_b477)._right8;
                    if (!((_child502) == null)) {
                        var _val503 = (_child502)._min_ay13;
                        _augval499 = ((_augval499) < (_val503)) ? (_augval499) : (_val503);
                    }
                    (_b477)._min_ay13 = _augval499;
                    /* _max_ay24 is max of ay2 */
                    var _augval504 = (_b477).ay2;
                    var _child505 = (_b477)._left7;
                    if (!((_child505) == null)) {
                        var _val506 = (_child505)._max_ay24;
                        _augval504 = ((_augval504) < (_val506)) ? (_val506) : (_augval504);
                    }
                    var _child507 = (_b477)._right8;
                    if (!((_child507) == null)) {
                        var _val508 = (_child507)._max_ay24;
                        _augval504 = ((_augval504) < (_val508)) ? (_val508) : (_augval504);
                    }
                    (_b477)._max_ay24 = _augval504;
                    (_b477)._height10 = 1 + ((((((_b477)._left7) == null) ? (-1) : (((_b477)._left7)._height10)) > ((((_b477)._right8) == null) ? (-1) : (((_b477)._right8)._height10))) ? ((((_b477)._left7) == null) ? (-1) : (((_b477)._left7)._height10)) : ((((_b477)._right8) == null) ? (-1) : (((_b477)._right8)._height10)));
                    if (!(((_b477)._parent9) == null)) {
                        /* _min_ax12 is min of ax1 */
                        var _augval509 = ((_b477)._parent9).ax1;
                        var _child510 = ((_b477)._parent9)._left7;
                        if (!((_child510) == null)) {
                            var _val511 = (_child510)._min_ax12;
                            _augval509 = ((_augval509) < (_val511)) ? (_augval509) : (_val511);
                        }
                        var _child512 = ((_b477)._parent9)._right8;
                        if (!((_child512) == null)) {
                            var _val513 = (_child512)._min_ax12;
                            _augval509 = ((_augval509) < (_val513)) ? (_augval509) : (_val513);
                        }
                        ((_b477)._parent9)._min_ax12 = _augval509;
                        /* _min_ay13 is min of ay1 */
                        var _augval514 = ((_b477)._parent9).ay1;
                        var _child515 = ((_b477)._parent9)._left7;
                        if (!((_child515) == null)) {
                            var _val516 = (_child515)._min_ay13;
                            _augval514 = ((_augval514) < (_val516)) ? (_augval514) : (_val516);
                        }
                        var _child517 = ((_b477)._parent9)._right8;
                        if (!((_child517) == null)) {
                            var _val518 = (_child517)._min_ay13;
                            _augval514 = ((_augval514) < (_val518)) ? (_augval514) : (_val518);
                        }
                        ((_b477)._parent9)._min_ay13 = _augval514;
                        /* _max_ay24 is max of ay2 */
                        var _augval519 = ((_b477)._parent9).ay2;
                        var _child520 = ((_b477)._parent9)._left7;
                        if (!((_child520) == null)) {
                            var _val521 = (_child520)._max_ay24;
                            _augval519 = ((_augval519) < (_val521)) ? (_val521) : (_augval519);
                        }
                        var _child522 = ((_b477)._parent9)._right8;
                        if (!((_child522) == null)) {
                            var _val523 = (_child522)._max_ay24;
                            _augval519 = ((_augval519) < (_val523)) ? (_val523) : (_augval519);
                        }
                        ((_b477)._parent9)._max_ay24 = _augval519;
                        ((_b477)._parent9)._height10 = 1 + (((((((_b477)._parent9)._left7) == null) ? (-1) : ((((_b477)._parent9)._left7)._height10)) > (((((_b477)._parent9)._right8) == null) ? (-1) : ((((_b477)._parent9)._right8)._height10))) ? (((((_b477)._parent9)._left7) == null) ? (-1) : ((((_b477)._parent9)._left7)._height10)) : (((((_b477)._parent9)._right8) == null) ? (-1) : ((((_b477)._parent9)._right8)._height10)));
                    } else {
                        (this)._root1 = _b477;
                    }
                }
                /* rotate (_cursor474)._left7 */
                var _a524 = _cursor474;
                var _b525 = (_a524)._left7;
                var _c526 = (_b525)._right8;
                /* replace _a524 with _b525 in (_a524)._parent9 */
                if (!(((_a524)._parent9) == null)) {
                    if ((((_a524)._parent9)._left7) == (_a524)) {
                        ((_a524)._parent9)._left7 = _b525;
                    } else {
                        ((_a524)._parent9)._right8 = _b525;
                    }
                }
                if (!((_b525) == null)) {
                    (_b525)._parent9 = (_a524)._parent9;
                }
                /* replace _c526 with _a524 in _b525 */
                (_b525)._right8 = _a524;
                if (!((_a524) == null)) {
                    (_a524)._parent9 = _b525;
                }
                /* replace _b525 with _c526 in _a524 */
                (_a524)._left7 = _c526;
                if (!((_c526) == null)) {
                    (_c526)._parent9 = _a524;
                }
                /* _min_ax12 is min of ax1 */
                var _augval527 = (_a524).ax1;
                var _child528 = (_a524)._left7;
                if (!((_child528) == null)) {
                    var _val529 = (_child528)._min_ax12;
                    _augval527 = ((_augval527) < (_val529)) ? (_augval527) : (_val529);
                }
                var _child530 = (_a524)._right8;
                if (!((_child530) == null)) {
                    var _val531 = (_child530)._min_ax12;
                    _augval527 = ((_augval527) < (_val531)) ? (_augval527) : (_val531);
                }
                (_a524)._min_ax12 = _augval527;
                /* _min_ay13 is min of ay1 */
                var _augval532 = (_a524).ay1;
                var _child533 = (_a524)._left7;
                if (!((_child533) == null)) {
                    var _val534 = (_child533)._min_ay13;
                    _augval532 = ((_augval532) < (_val534)) ? (_augval532) : (_val534);
                }
                var _child535 = (_a524)._right8;
                if (!((_child535) == null)) {
                    var _val536 = (_child535)._min_ay13;
                    _augval532 = ((_augval532) < (_val536)) ? (_augval532) : (_val536);
                }
                (_a524)._min_ay13 = _augval532;
                /* _max_ay24 is max of ay2 */
                var _augval537 = (_a524).ay2;
                var _child538 = (_a524)._left7;
                if (!((_child538) == null)) {
                    var _val539 = (_child538)._max_ay24;
                    _augval537 = ((_augval537) < (_val539)) ? (_val539) : (_augval537);
                }
                var _child540 = (_a524)._right8;
                if (!((_child540) == null)) {
                    var _val541 = (_child540)._max_ay24;
                    _augval537 = ((_augval537) < (_val541)) ? (_val541) : (_augval537);
                }
                (_a524)._max_ay24 = _augval537;
                (_a524)._height10 = 1 + ((((((_a524)._left7) == null) ? (-1) : (((_a524)._left7)._height10)) > ((((_a524)._right8) == null) ? (-1) : (((_a524)._right8)._height10))) ? ((((_a524)._left7) == null) ? (-1) : (((_a524)._left7)._height10)) : ((((_a524)._right8) == null) ? (-1) : (((_a524)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval542 = (_b525).ax1;
                var _child543 = (_b525)._left7;
                if (!((_child543) == null)) {
                    var _val544 = (_child543)._min_ax12;
                    _augval542 = ((_augval542) < (_val544)) ? (_augval542) : (_val544);
                }
                var _child545 = (_b525)._right8;
                if (!((_child545) == null)) {
                    var _val546 = (_child545)._min_ax12;
                    _augval542 = ((_augval542) < (_val546)) ? (_augval542) : (_val546);
                }
                (_b525)._min_ax12 = _augval542;
                /* _min_ay13 is min of ay1 */
                var _augval547 = (_b525).ay1;
                var _child548 = (_b525)._left7;
                if (!((_child548) == null)) {
                    var _val549 = (_child548)._min_ay13;
                    _augval547 = ((_augval547) < (_val549)) ? (_augval547) : (_val549);
                }
                var _child550 = (_b525)._right8;
                if (!((_child550) == null)) {
                    var _val551 = (_child550)._min_ay13;
                    _augval547 = ((_augval547) < (_val551)) ? (_augval547) : (_val551);
                }
                (_b525)._min_ay13 = _augval547;
                /* _max_ay24 is max of ay2 */
                var _augval552 = (_b525).ay2;
                var _child553 = (_b525)._left7;
                if (!((_child553) == null)) {
                    var _val554 = (_child553)._max_ay24;
                    _augval552 = ((_augval552) < (_val554)) ? (_val554) : (_augval552);
                }
                var _child555 = (_b525)._right8;
                if (!((_child555) == null)) {
                    var _val556 = (_child555)._max_ay24;
                    _augval552 = ((_augval552) < (_val556)) ? (_val556) : (_augval552);
                }
                (_b525)._max_ay24 = _augval552;
                (_b525)._height10 = 1 + ((((((_b525)._left7) == null) ? (-1) : (((_b525)._left7)._height10)) > ((((_b525)._right8) == null) ? (-1) : (((_b525)._right8)._height10))) ? ((((_b525)._left7) == null) ? (-1) : (((_b525)._left7)._height10)) : ((((_b525)._right8) == null) ? (-1) : (((_b525)._right8)._height10)));
                if (!(((_b525)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval557 = ((_b525)._parent9).ax1;
                    var _child558 = ((_b525)._parent9)._left7;
                    if (!((_child558) == null)) {
                        var _val559 = (_child558)._min_ax12;
                        _augval557 = ((_augval557) < (_val559)) ? (_augval557) : (_val559);
                    }
                    var _child560 = ((_b525)._parent9)._right8;
                    if (!((_child560) == null)) {
                        var _val561 = (_child560)._min_ax12;
                        _augval557 = ((_augval557) < (_val561)) ? (_augval557) : (_val561);
                    }
                    ((_b525)._parent9)._min_ax12 = _augval557;
                    /* _min_ay13 is min of ay1 */
                    var _augval562 = ((_b525)._parent9).ay1;
                    var _child563 = ((_b525)._parent9)._left7;
                    if (!((_child563) == null)) {
                        var _val564 = (_child563)._min_ay13;
                        _augval562 = ((_augval562) < (_val564)) ? (_augval562) : (_val564);
                    }
                    var _child565 = ((_b525)._parent9)._right8;
                    if (!((_child565) == null)) {
                        var _val566 = (_child565)._min_ay13;
                        _augval562 = ((_augval562) < (_val566)) ? (_augval562) : (_val566);
                    }
                    ((_b525)._parent9)._min_ay13 = _augval562;
                    /* _max_ay24 is max of ay2 */
                    var _augval567 = ((_b525)._parent9).ay2;
                    var _child568 = ((_b525)._parent9)._left7;
                    if (!((_child568) == null)) {
                        var _val569 = (_child568)._max_ay24;
                        _augval567 = ((_augval567) < (_val569)) ? (_val569) : (_augval567);
                    }
                    var _child570 = ((_b525)._parent9)._right8;
                    if (!((_child570) == null)) {
                        var _val571 = (_child570)._max_ay24;
                        _augval567 = ((_augval567) < (_val571)) ? (_val571) : (_augval567);
                    }
                    ((_b525)._parent9)._max_ay24 = _augval567;
                    ((_b525)._parent9)._height10 = 1 + (((((((_b525)._parent9)._left7) == null) ? (-1) : ((((_b525)._parent9)._left7)._height10)) > (((((_b525)._parent9)._right8) == null) ? (-1) : ((((_b525)._parent9)._right8)._height10))) ? (((((_b525)._parent9)._left7) == null) ? (-1) : ((((_b525)._parent9)._left7)._height10)) : (((((_b525)._parent9)._right8) == null) ? (-1) : ((((_b525)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b525;
                }
                _cursor474 = (_cursor474)._parent9;
            } else if ((_imbalance475) < (-1)) {
                if ((((((_cursor474)._right8)._left7) == null) ? (-1) : ((((_cursor474)._right8)._left7)._height10)) > (((((_cursor474)._right8)._right8) == null) ? (-1) : ((((_cursor474)._right8)._right8)._height10))) {
                    /* rotate ((_cursor474)._right8)._left7 */
                    var _a572 = (_cursor474)._right8;
                    var _b573 = (_a572)._left7;
                    var _c574 = (_b573)._right8;
                    /* replace _a572 with _b573 in (_a572)._parent9 */
                    if (!(((_a572)._parent9) == null)) {
                        if ((((_a572)._parent9)._left7) == (_a572)) {
                            ((_a572)._parent9)._left7 = _b573;
                        } else {
                            ((_a572)._parent9)._right8 = _b573;
                        }
                    }
                    if (!((_b573) == null)) {
                        (_b573)._parent9 = (_a572)._parent9;
                    }
                    /* replace _c574 with _a572 in _b573 */
                    (_b573)._right8 = _a572;
                    if (!((_a572) == null)) {
                        (_a572)._parent9 = _b573;
                    }
                    /* replace _b573 with _c574 in _a572 */
                    (_a572)._left7 = _c574;
                    if (!((_c574) == null)) {
                        (_c574)._parent9 = _a572;
                    }
                    /* _min_ax12 is min of ax1 */
                    var _augval575 = (_a572).ax1;
                    var _child576 = (_a572)._left7;
                    if (!((_child576) == null)) {
                        var _val577 = (_child576)._min_ax12;
                        _augval575 = ((_augval575) < (_val577)) ? (_augval575) : (_val577);
                    }
                    var _child578 = (_a572)._right8;
                    if (!((_child578) == null)) {
                        var _val579 = (_child578)._min_ax12;
                        _augval575 = ((_augval575) < (_val579)) ? (_augval575) : (_val579);
                    }
                    (_a572)._min_ax12 = _augval575;
                    /* _min_ay13 is min of ay1 */
                    var _augval580 = (_a572).ay1;
                    var _child581 = (_a572)._left7;
                    if (!((_child581) == null)) {
                        var _val582 = (_child581)._min_ay13;
                        _augval580 = ((_augval580) < (_val582)) ? (_augval580) : (_val582);
                    }
                    var _child583 = (_a572)._right8;
                    if (!((_child583) == null)) {
                        var _val584 = (_child583)._min_ay13;
                        _augval580 = ((_augval580) < (_val584)) ? (_augval580) : (_val584);
                    }
                    (_a572)._min_ay13 = _augval580;
                    /* _max_ay24 is max of ay2 */
                    var _augval585 = (_a572).ay2;
                    var _child586 = (_a572)._left7;
                    if (!((_child586) == null)) {
                        var _val587 = (_child586)._max_ay24;
                        _augval585 = ((_augval585) < (_val587)) ? (_val587) : (_augval585);
                    }
                    var _child588 = (_a572)._right8;
                    if (!((_child588) == null)) {
                        var _val589 = (_child588)._max_ay24;
                        _augval585 = ((_augval585) < (_val589)) ? (_val589) : (_augval585);
                    }
                    (_a572)._max_ay24 = _augval585;
                    (_a572)._height10 = 1 + ((((((_a572)._left7) == null) ? (-1) : (((_a572)._left7)._height10)) > ((((_a572)._right8) == null) ? (-1) : (((_a572)._right8)._height10))) ? ((((_a572)._left7) == null) ? (-1) : (((_a572)._left7)._height10)) : ((((_a572)._right8) == null) ? (-1) : (((_a572)._right8)._height10)));
                    /* _min_ax12 is min of ax1 */
                    var _augval590 = (_b573).ax1;
                    var _child591 = (_b573)._left7;
                    if (!((_child591) == null)) {
                        var _val592 = (_child591)._min_ax12;
                        _augval590 = ((_augval590) < (_val592)) ? (_augval590) : (_val592);
                    }
                    var _child593 = (_b573)._right8;
                    if (!((_child593) == null)) {
                        var _val594 = (_child593)._min_ax12;
                        _augval590 = ((_augval590) < (_val594)) ? (_augval590) : (_val594);
                    }
                    (_b573)._min_ax12 = _augval590;
                    /* _min_ay13 is min of ay1 */
                    var _augval595 = (_b573).ay1;
                    var _child596 = (_b573)._left7;
                    if (!((_child596) == null)) {
                        var _val597 = (_child596)._min_ay13;
                        _augval595 = ((_augval595) < (_val597)) ? (_augval595) : (_val597);
                    }
                    var _child598 = (_b573)._right8;
                    if (!((_child598) == null)) {
                        var _val599 = (_child598)._min_ay13;
                        _augval595 = ((_augval595) < (_val599)) ? (_augval595) : (_val599);
                    }
                    (_b573)._min_ay13 = _augval595;
                    /* _max_ay24 is max of ay2 */
                    var _augval600 = (_b573).ay2;
                    var _child601 = (_b573)._left7;
                    if (!((_child601) == null)) {
                        var _val602 = (_child601)._max_ay24;
                        _augval600 = ((_augval600) < (_val602)) ? (_val602) : (_augval600);
                    }
                    var _child603 = (_b573)._right8;
                    if (!((_child603) == null)) {
                        var _val604 = (_child603)._max_ay24;
                        _augval600 = ((_augval600) < (_val604)) ? (_val604) : (_augval600);
                    }
                    (_b573)._max_ay24 = _augval600;
                    (_b573)._height10 = 1 + ((((((_b573)._left7) == null) ? (-1) : (((_b573)._left7)._height10)) > ((((_b573)._right8) == null) ? (-1) : (((_b573)._right8)._height10))) ? ((((_b573)._left7) == null) ? (-1) : (((_b573)._left7)._height10)) : ((((_b573)._right8) == null) ? (-1) : (((_b573)._right8)._height10)));
                    if (!(((_b573)._parent9) == null)) {
                        /* _min_ax12 is min of ax1 */
                        var _augval605 = ((_b573)._parent9).ax1;
                        var _child606 = ((_b573)._parent9)._left7;
                        if (!((_child606) == null)) {
                            var _val607 = (_child606)._min_ax12;
                            _augval605 = ((_augval605) < (_val607)) ? (_augval605) : (_val607);
                        }
                        var _child608 = ((_b573)._parent9)._right8;
                        if (!((_child608) == null)) {
                            var _val609 = (_child608)._min_ax12;
                            _augval605 = ((_augval605) < (_val609)) ? (_augval605) : (_val609);
                        }
                        ((_b573)._parent9)._min_ax12 = _augval605;
                        /* _min_ay13 is min of ay1 */
                        var _augval610 = ((_b573)._parent9).ay1;
                        var _child611 = ((_b573)._parent9)._left7;
                        if (!((_child611) == null)) {
                            var _val612 = (_child611)._min_ay13;
                            _augval610 = ((_augval610) < (_val612)) ? (_augval610) : (_val612);
                        }
                        var _child613 = ((_b573)._parent9)._right8;
                        if (!((_child613) == null)) {
                            var _val614 = (_child613)._min_ay13;
                            _augval610 = ((_augval610) < (_val614)) ? (_augval610) : (_val614);
                        }
                        ((_b573)._parent9)._min_ay13 = _augval610;
                        /* _max_ay24 is max of ay2 */
                        var _augval615 = ((_b573)._parent9).ay2;
                        var _child616 = ((_b573)._parent9)._left7;
                        if (!((_child616) == null)) {
                            var _val617 = (_child616)._max_ay24;
                            _augval615 = ((_augval615) < (_val617)) ? (_val617) : (_augval615);
                        }
                        var _child618 = ((_b573)._parent9)._right8;
                        if (!((_child618) == null)) {
                            var _val619 = (_child618)._max_ay24;
                            _augval615 = ((_augval615) < (_val619)) ? (_val619) : (_augval615);
                        }
                        ((_b573)._parent9)._max_ay24 = _augval615;
                        ((_b573)._parent9)._height10 = 1 + (((((((_b573)._parent9)._left7) == null) ? (-1) : ((((_b573)._parent9)._left7)._height10)) > (((((_b573)._parent9)._right8) == null) ? (-1) : ((((_b573)._parent9)._right8)._height10))) ? (((((_b573)._parent9)._left7) == null) ? (-1) : ((((_b573)._parent9)._left7)._height10)) : (((((_b573)._parent9)._right8) == null) ? (-1) : ((((_b573)._parent9)._right8)._height10)));
                    } else {
                        (this)._root1 = _b573;
                    }
                }
                /* rotate (_cursor474)._right8 */
                var _a620 = _cursor474;
                var _b621 = (_a620)._right8;
                var _c622 = (_b621)._left7;
                /* replace _a620 with _b621 in (_a620)._parent9 */
                if (!(((_a620)._parent9) == null)) {
                    if ((((_a620)._parent9)._left7) == (_a620)) {
                        ((_a620)._parent9)._left7 = _b621;
                    } else {
                        ((_a620)._parent9)._right8 = _b621;
                    }
                }
                if (!((_b621) == null)) {
                    (_b621)._parent9 = (_a620)._parent9;
                }
                /* replace _c622 with _a620 in _b621 */
                (_b621)._left7 = _a620;
                if (!((_a620) == null)) {
                    (_a620)._parent9 = _b621;
                }
                /* replace _b621 with _c622 in _a620 */
                (_a620)._right8 = _c622;
                if (!((_c622) == null)) {
                    (_c622)._parent9 = _a620;
                }
                /* _min_ax12 is min of ax1 */
                var _augval623 = (_a620).ax1;
                var _child624 = (_a620)._left7;
                if (!((_child624) == null)) {
                    var _val625 = (_child624)._min_ax12;
                    _augval623 = ((_augval623) < (_val625)) ? (_augval623) : (_val625);
                }
                var _child626 = (_a620)._right8;
                if (!((_child626) == null)) {
                    var _val627 = (_child626)._min_ax12;
                    _augval623 = ((_augval623) < (_val627)) ? (_augval623) : (_val627);
                }
                (_a620)._min_ax12 = _augval623;
                /* _min_ay13 is min of ay1 */
                var _augval628 = (_a620).ay1;
                var _child629 = (_a620)._left7;
                if (!((_child629) == null)) {
                    var _val630 = (_child629)._min_ay13;
                    _augval628 = ((_augval628) < (_val630)) ? (_augval628) : (_val630);
                }
                var _child631 = (_a620)._right8;
                if (!((_child631) == null)) {
                    var _val632 = (_child631)._min_ay13;
                    _augval628 = ((_augval628) < (_val632)) ? (_augval628) : (_val632);
                }
                (_a620)._min_ay13 = _augval628;
                /* _max_ay24 is max of ay2 */
                var _augval633 = (_a620).ay2;
                var _child634 = (_a620)._left7;
                if (!((_child634) == null)) {
                    var _val635 = (_child634)._max_ay24;
                    _augval633 = ((_augval633) < (_val635)) ? (_val635) : (_augval633);
                }
                var _child636 = (_a620)._right8;
                if (!((_child636) == null)) {
                    var _val637 = (_child636)._max_ay24;
                    _augval633 = ((_augval633) < (_val637)) ? (_val637) : (_augval633);
                }
                (_a620)._max_ay24 = _augval633;
                (_a620)._height10 = 1 + ((((((_a620)._left7) == null) ? (-1) : (((_a620)._left7)._height10)) > ((((_a620)._right8) == null) ? (-1) : (((_a620)._right8)._height10))) ? ((((_a620)._left7) == null) ? (-1) : (((_a620)._left7)._height10)) : ((((_a620)._right8) == null) ? (-1) : (((_a620)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval638 = (_b621).ax1;
                var _child639 = (_b621)._left7;
                if (!((_child639) == null)) {
                    var _val640 = (_child639)._min_ax12;
                    _augval638 = ((_augval638) < (_val640)) ? (_augval638) : (_val640);
                }
                var _child641 = (_b621)._right8;
                if (!((_child641) == null)) {
                    var _val642 = (_child641)._min_ax12;
                    _augval638 = ((_augval638) < (_val642)) ? (_augval638) : (_val642);
                }
                (_b621)._min_ax12 = _augval638;
                /* _min_ay13 is min of ay1 */
                var _augval643 = (_b621).ay1;
                var _child644 = (_b621)._left7;
                if (!((_child644) == null)) {
                    var _val645 = (_child644)._min_ay13;
                    _augval643 = ((_augval643) < (_val645)) ? (_augval643) : (_val645);
                }
                var _child646 = (_b621)._right8;
                if (!((_child646) == null)) {
                    var _val647 = (_child646)._min_ay13;
                    _augval643 = ((_augval643) < (_val647)) ? (_augval643) : (_val647);
                }
                (_b621)._min_ay13 = _augval643;
                /* _max_ay24 is max of ay2 */
                var _augval648 = (_b621).ay2;
                var _child649 = (_b621)._left7;
                if (!((_child649) == null)) {
                    var _val650 = (_child649)._max_ay24;
                    _augval648 = ((_augval648) < (_val650)) ? (_val650) : (_augval648);
                }
                var _child651 = (_b621)._right8;
                if (!((_child651) == null)) {
                    var _val652 = (_child651)._max_ay24;
                    _augval648 = ((_augval648) < (_val652)) ? (_val652) : (_augval648);
                }
                (_b621)._max_ay24 = _augval648;
                (_b621)._height10 = 1 + ((((((_b621)._left7) == null) ? (-1) : (((_b621)._left7)._height10)) > ((((_b621)._right8) == null) ? (-1) : (((_b621)._right8)._height10))) ? ((((_b621)._left7) == null) ? (-1) : (((_b621)._left7)._height10)) : ((((_b621)._right8) == null) ? (-1) : (((_b621)._right8)._height10)));
                if (!(((_b621)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval653 = ((_b621)._parent9).ax1;
                    var _child654 = ((_b621)._parent9)._left7;
                    if (!((_child654) == null)) {
                        var _val655 = (_child654)._min_ax12;
                        _augval653 = ((_augval653) < (_val655)) ? (_augval653) : (_val655);
                    }
                    var _child656 = ((_b621)._parent9)._right8;
                    if (!((_child656) == null)) {
                        var _val657 = (_child656)._min_ax12;
                        _augval653 = ((_augval653) < (_val657)) ? (_augval653) : (_val657);
                    }
                    ((_b621)._parent9)._min_ax12 = _augval653;
                    /* _min_ay13 is min of ay1 */
                    var _augval658 = ((_b621)._parent9).ay1;
                    var _child659 = ((_b621)._parent9)._left7;
                    if (!((_child659) == null)) {
                        var _val660 = (_child659)._min_ay13;
                        _augval658 = ((_augval658) < (_val660)) ? (_augval658) : (_val660);
                    }
                    var _child661 = ((_b621)._parent9)._right8;
                    if (!((_child661) == null)) {
                        var _val662 = (_child661)._min_ay13;
                        _augval658 = ((_augval658) < (_val662)) ? (_augval658) : (_val662);
                    }
                    ((_b621)._parent9)._min_ay13 = _augval658;
                    /* _max_ay24 is max of ay2 */
                    var _augval663 = ((_b621)._parent9).ay2;
                    var _child664 = ((_b621)._parent9)._left7;
                    if (!((_child664) == null)) {
                        var _val665 = (_child664)._max_ay24;
                        _augval663 = ((_augval663) < (_val665)) ? (_val665) : (_augval663);
                    }
                    var _child666 = ((_b621)._parent9)._right8;
                    if (!((_child666) == null)) {
                        var _val667 = (_child666)._max_ay24;
                        _augval663 = ((_augval663) < (_val667)) ? (_val667) : (_augval663);
                    }
                    ((_b621)._parent9)._max_ay24 = _augval663;
                    ((_b621)._parent9)._height10 = 1 + (((((((_b621)._parent9)._left7) == null) ? (-1) : ((((_b621)._parent9)._left7)._height10)) > (((((_b621)._parent9)._right8) == null) ? (-1) : ((((_b621)._parent9)._right8)._height10))) ? (((((_b621)._parent9)._left7) == null) ? (-1) : ((((_b621)._parent9)._left7)._height10)) : (((((_b621)._parent9)._right8) == null) ? (-1) : ((((_b621)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b621;
                }
                _cursor474 = (_cursor474)._parent9;
            }
        }
        (__x).ax2 = new_val;
    }
}
RectangleHolder.prototype.updateAy2 = function (__x, new_val) {
    if ((__x).ay2 != new_val) {
        /* _max_ay24 is max of ay2 */
        var _augval668 = new_val;
        var _child669 = (__x)._left7;
        if (!((_child669) == null)) {
            var _val670 = (_child669)._max_ay24;
            _augval668 = ((_augval668) < (_val670)) ? (_val670) : (_augval668);
        }
        var _child671 = (__x)._right8;
        if (!((_child671) == null)) {
            var _val672 = (_child671)._max_ay24;
            _augval668 = ((_augval668) < (_val672)) ? (_val672) : (_augval668);
        }
        (__x)._max_ay24 = _augval668;
        var _cursor673 = (__x)._parent9;
        var _changed674 = true;
        while ((_changed674) && (!((_cursor673) == (null)))) {
            var _old__max_ay24675 = (_cursor673)._max_ay24;
            var _old_height676 = (_cursor673)._height10;
            /* _max_ay24 is max of ay2 */
            var _augval677 = (_cursor673).ay2;
            var _child678 = (_cursor673)._left7;
            if (!((_child678) == null)) {
                var _val679 = (_child678)._max_ay24;
                _augval677 = ((_augval677) < (_val679)) ? (_val679) : (_augval677);
            }
            var _child680 = (_cursor673)._right8;
            if (!((_child680) == null)) {
                var _val681 = (_child680)._max_ay24;
                _augval677 = ((_augval677) < (_val681)) ? (_val681) : (_augval677);
            }
            (_cursor673)._max_ay24 = _augval677;
            (_cursor673)._height10 = 1 + ((((((_cursor673)._left7) == null) ? (-1) : (((_cursor673)._left7)._height10)) > ((((_cursor673)._right8) == null) ? (-1) : (((_cursor673)._right8)._height10))) ? ((((_cursor673)._left7) == null) ? (-1) : (((_cursor673)._left7)._height10)) : ((((_cursor673)._right8) == null) ? (-1) : (((_cursor673)._right8)._height10)));
            _changed674 = false;
            _changed674 = (_changed674) || (!((_old__max_ay24675) == ((_cursor673)._max_ay24)));
            _changed674 = (_changed674) || (!((_old_height676) == ((_cursor673)._height10)));
            _cursor673 = (_cursor673)._parent9;
        }
        (__x).ay2 = new_val;
    }
}
RectangleHolder.prototype.update = function (__x, ax1, ay1, ax2, ay2) {
    var _parent682 = (__x)._parent9;
    var _left683 = (__x)._left7;
    var _right684 = (__x)._right8;
    var _new_x685;
    if (((_left683) == null) && ((_right684) == null)) {
        _new_x685 = null;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else if ((!((_left683) == null)) && ((_right684) == null)) {
        _new_x685 = _left683;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else if (((_left683) == null) && (!((_right684) == null))) {
        _new_x685 = _right684;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else {
        var _root686 = (__x)._right8;
        var _x687 = _root686;
        var _descend688 = true;
        var _from_left689 = true;
        while (true) {
            if ((_x687) == null) {
                _x687 = null;
                break;
            }
            if (_descend688) {
                /* too small? */
                if (false) {
                    if ((!(((_x687)._right8) == null)) && (true)) {
                        if ((_x687) == (_root686)) {
                            _root686 = (_x687)._right8;
                        }
                        _x687 = (_x687)._right8;
                    } else if ((_x687) == (_root686)) {
                        _x687 = null;
                        break;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                } else if ((!(((_x687)._left7) == null)) && (true)) {
                    _x687 = (_x687)._left7;
                    /* too large? */
                } else if (false) {
                    if ((_x687) == (_root686)) {
                        _x687 = null;
                        break;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                    /* node ok? */
                } else if (true) {
                    break;
                } else if ((_x687) == (_root686)) {
                    _root686 = (_x687)._right8;
                    _x687 = (_x687)._right8;
                } else {
                    if ((!(((_x687)._right8) == null)) && (true)) {
                        if ((_x687) == (_root686)) {
                            _root686 = (_x687)._right8;
                        }
                        _x687 = (_x687)._right8;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                }
            } else if (_from_left689) {
                if (false) {
                    _x687 = null;
                    break;
                } else if (true) {
                    break;
                } else if ((!(((_x687)._right8) == null)) && (true)) {
                    _descend688 = true;
                    if ((_x687) == (_root686)) {
                        _root686 = (_x687)._right8;
                    }
                    _x687 = (_x687)._right8;
                } else if ((_x687) == (_root686)) {
                    _x687 = null;
                    break;
                } else {
                    _descend688 = false;
                    _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                    _x687 = (_x687)._parent9;
                }
            } else {
                if ((_x687) == (_root686)) {
                    _x687 = null;
                    break;
                } else {
                    _descend688 = false;
                    _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                    _x687 = (_x687)._parent9;
                }
            }
        }
        _new_x685 = _x687;
        var _mp690 = (_x687)._parent9;
        var _mr691 = (_x687)._right8;
        /* replace _x687 with _mr691 in _mp690 */
        if (!((_mp690) == null)) {
            if (((_mp690)._left7) == (_x687)) {
                (_mp690)._left7 = _mr691;
            } else {
                (_mp690)._right8 = _mr691;
            }
        }
        if (!((_mr691) == null)) {
            (_mr691)._parent9 = _mp690;
        }
        /* replace __x with _x687 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _x687;
            } else {
                (_parent682)._right8 = _x687;
            }
        }
        if (!((_x687) == null)) {
            (_x687)._parent9 = _parent682;
        }
        /* replace null with _left683 in _x687 */
        (_x687)._left7 = _left683;
        if (!((_left683) == null)) {
            (_left683)._parent9 = _x687;
        }
        /* replace _mr691 with (__x)._right8 in _x687 */
        (_x687)._right8 = (__x)._right8;
        if (!(((__x)._right8) == null)) {
            ((__x)._right8)._parent9 = _x687;
        }
        /* _min_ax12 is min of ax1 */
        var _augval692 = (_x687).ax1;
        var _child693 = (_x687)._left7;
        if (!((_child693) == null)) {
            var _val694 = (_child693)._min_ax12;
            _augval692 = ((_augval692) < (_val694)) ? (_augval692) : (_val694);
        }
        var _child695 = (_x687)._right8;
        if (!((_child695) == null)) {
            var _val696 = (_child695)._min_ax12;
            _augval692 = ((_augval692) < (_val696)) ? (_augval692) : (_val696);
        }
        (_x687)._min_ax12 = _augval692;
        /* _min_ay13 is min of ay1 */
        var _augval697 = (_x687).ay1;
        var _child698 = (_x687)._left7;
        if (!((_child698) == null)) {
            var _val699 = (_child698)._min_ay13;
            _augval697 = ((_augval697) < (_val699)) ? (_augval697) : (_val699);
        }
        var _child700 = (_x687)._right8;
        if (!((_child700) == null)) {
            var _val701 = (_child700)._min_ay13;
            _augval697 = ((_augval697) < (_val701)) ? (_augval697) : (_val701);
        }
        (_x687)._min_ay13 = _augval697;
        /* _max_ay24 is max of ay2 */
        var _augval702 = (_x687).ay2;
        var _child703 = (_x687)._left7;
        if (!((_child703) == null)) {
            var _val704 = (_child703)._max_ay24;
            _augval702 = ((_augval702) < (_val704)) ? (_val704) : (_augval702);
        }
        var _child705 = (_x687)._right8;
        if (!((_child705) == null)) {
            var _val706 = (_child705)._max_ay24;
            _augval702 = ((_augval702) < (_val706)) ? (_val706) : (_augval702);
        }
        (_x687)._max_ay24 = _augval702;
        (_x687)._height10 = 1 + ((((((_x687)._left7) == null) ? (-1) : (((_x687)._left7)._height10)) > ((((_x687)._right8) == null) ? (-1) : (((_x687)._right8)._height10))) ? ((((_x687)._left7) == null) ? (-1) : (((_x687)._left7)._height10)) : ((((_x687)._right8) == null) ? (-1) : (((_x687)._right8)._height10)));
        var _cursor707 = _mp690;
        var _changed708 = true;
        while ((_changed708) && (!((_cursor707) == (_parent682)))) {
            var _old__min_ax12709 = (_cursor707)._min_ax12;
            var _old__min_ay13710 = (_cursor707)._min_ay13;
            var _old__max_ay24711 = (_cursor707)._max_ay24;
            var _old_height712 = (_cursor707)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval713 = (_cursor707).ax1;
            var _child714 = (_cursor707)._left7;
            if (!((_child714) == null)) {
                var _val715 = (_child714)._min_ax12;
                _augval713 = ((_augval713) < (_val715)) ? (_augval713) : (_val715);
            }
            var _child716 = (_cursor707)._right8;
            if (!((_child716) == null)) {
                var _val717 = (_child716)._min_ax12;
                _augval713 = ((_augval713) < (_val717)) ? (_augval713) : (_val717);
            }
            (_cursor707)._min_ax12 = _augval713;
            /* _min_ay13 is min of ay1 */
            var _augval718 = (_cursor707).ay1;
            var _child719 = (_cursor707)._left7;
            if (!((_child719) == null)) {
                var _val720 = (_child719)._min_ay13;
                _augval718 = ((_augval718) < (_val720)) ? (_augval718) : (_val720);
            }
            var _child721 = (_cursor707)._right8;
            if (!((_child721) == null)) {
                var _val722 = (_child721)._min_ay13;
                _augval718 = ((_augval718) < (_val722)) ? (_augval718) : (_val722);
            }
            (_cursor707)._min_ay13 = _augval718;
            /* _max_ay24 is max of ay2 */
            var _augval723 = (_cursor707).ay2;
            var _child724 = (_cursor707)._left7;
            if (!((_child724) == null)) {
                var _val725 = (_child724)._max_ay24;
                _augval723 = ((_augval723) < (_val725)) ? (_val725) : (_augval723);
            }
            var _child726 = (_cursor707)._right8;
            if (!((_child726) == null)) {
                var _val727 = (_child726)._max_ay24;
                _augval723 = ((_augval723) < (_val727)) ? (_val727) : (_augval723);
            }
            (_cursor707)._max_ay24 = _augval723;
            (_cursor707)._height10 = 1 + ((((((_cursor707)._left7) == null) ? (-1) : (((_cursor707)._left7)._height10)) > ((((_cursor707)._right8) == null) ? (-1) : (((_cursor707)._right8)._height10))) ? ((((_cursor707)._left7) == null) ? (-1) : (((_cursor707)._left7)._height10)) : ((((_cursor707)._right8) == null) ? (-1) : (((_cursor707)._right8)._height10)));
            _changed708 = false;
            _changed708 = (_changed708) || (!((_old__min_ax12709) == ((_cursor707)._min_ax12)));
            _changed708 = (_changed708) || (!((_old__min_ay13710) == ((_cursor707)._min_ay13)));
            _changed708 = (_changed708) || (!((_old__max_ay24711) == ((_cursor707)._max_ay24)));
            _changed708 = (_changed708) || (!((_old_height712) == ((_cursor707)._height10)));
            _cursor707 = (_cursor707)._parent9;
        }
    }
    var _cursor728 = _parent682;
    var _changed729 = true;
    while ((_changed729) && (!((_cursor728) == (null)))) {
        var _old__min_ax12730 = (_cursor728)._min_ax12;
        var _old__min_ay13731 = (_cursor728)._min_ay13;
        var _old__max_ay24732 = (_cursor728)._max_ay24;
        var _old_height733 = (_cursor728)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval734 = (_cursor728).ax1;
        var _child735 = (_cursor728)._left7;
        if (!((_child735) == null)) {
            var _val736 = (_child735)._min_ax12;
            _augval734 = ((_augval734) < (_val736)) ? (_augval734) : (_val736);
        }
        var _child737 = (_cursor728)._right8;
        if (!((_child737) == null)) {
            var _val738 = (_child737)._min_ax12;
            _augval734 = ((_augval734) < (_val738)) ? (_augval734) : (_val738);
        }
        (_cursor728)._min_ax12 = _augval734;
        /* _min_ay13 is min of ay1 */
        var _augval739 = (_cursor728).ay1;
        var _child740 = (_cursor728)._left7;
        if (!((_child740) == null)) {
            var _val741 = (_child740)._min_ay13;
            _augval739 = ((_augval739) < (_val741)) ? (_augval739) : (_val741);
        }
        var _child742 = (_cursor728)._right8;
        if (!((_child742) == null)) {
            var _val743 = (_child742)._min_ay13;
            _augval739 = ((_augval739) < (_val743)) ? (_augval739) : (_val743);
        }
        (_cursor728)._min_ay13 = _augval739;
        /* _max_ay24 is max of ay2 */
        var _augval744 = (_cursor728).ay2;
        var _child745 = (_cursor728)._left7;
        if (!((_child745) == null)) {
            var _val746 = (_child745)._max_ay24;
            _augval744 = ((_augval744) < (_val746)) ? (_val746) : (_augval744);
        }
        var _child747 = (_cursor728)._right8;
        if (!((_child747) == null)) {
            var _val748 = (_child747)._max_ay24;
            _augval744 = ((_augval744) < (_val748)) ? (_val748) : (_augval744);
        }
        (_cursor728)._max_ay24 = _augval744;
        (_cursor728)._height10 = 1 + ((((((_cursor728)._left7) == null) ? (-1) : (((_cursor728)._left7)._height10)) > ((((_cursor728)._right8) == null) ? (-1) : (((_cursor728)._right8)._height10))) ? ((((_cursor728)._left7) == null) ? (-1) : (((_cursor728)._left7)._height10)) : ((((_cursor728)._right8) == null) ? (-1) : (((_cursor728)._right8)._height10)));
        _changed729 = false;
        _changed729 = (_changed729) || (!((_old__min_ax12730) == ((_cursor728)._min_ax12)));
        _changed729 = (_changed729) || (!((_old__min_ay13731) == ((_cursor728)._min_ay13)));
        _changed729 = (_changed729) || (!((_old__max_ay24732) == ((_cursor728)._max_ay24)));
        _changed729 = (_changed729) || (!((_old_height733) == ((_cursor728)._height10)));
        _cursor728 = (_cursor728)._parent9;
    }
    if (((this)._root1) == (__x)) {
        (this)._root1 = _new_x685;
    }
    (__x)._left7 = null;
    (__x)._right8 = null;
    (__x)._min_ax12 = (__x).ax1;
    (__x)._min_ay13 = (__x).ay1;
    (__x)._max_ay24 = (__x).ay2;
    (__x)._height10 = 0;
    var _previous749 = null;
    var _current750 = (this)._root1;
    var _is_left751 = false;
    while (!((_current750) == null)) {
        _previous749 = _current750;
        if ((ax2) < ((_current750).ax2)) {
            _current750 = (_current750)._left7;
            _is_left751 = true;
        } else {
            _current750 = (_current750)._right8;
            _is_left751 = false;
        }
    }
    if ((_previous749) == null) {
        (this)._root1 = __x;
    } else {
        (__x)._parent9 = _previous749;
        if (_is_left751) {
            (_previous749)._left7 = __x;
        } else {
            (_previous749)._right8 = __x;
        }
    }
    var _cursor752 = (__x)._parent9;
    var _changed753 = true;
    while ((_changed753) && (!((_cursor752) == (null)))) {
        var _old__min_ax12754 = (_cursor752)._min_ax12;
        var _old__min_ay13755 = (_cursor752)._min_ay13;
        var _old__max_ay24756 = (_cursor752)._max_ay24;
        var _old_height757 = (_cursor752)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval758 = (_cursor752).ax1;
        var _child759 = (_cursor752)._left7;
        if (!((_child759) == null)) {
            var _val760 = (_child759)._min_ax12;
            _augval758 = ((_augval758) < (_val760)) ? (_augval758) : (_val760);
        }
        var _child761 = (_cursor752)._right8;
        if (!((_child761) == null)) {
            var _val762 = (_child761)._min_ax12;
            _augval758 = ((_augval758) < (_val762)) ? (_augval758) : (_val762);
        }
        (_cursor752)._min_ax12 = _augval758;
        /* _min_ay13 is min of ay1 */
        var _augval763 = (_cursor752).ay1;
        var _child764 = (_cursor752)._left7;
        if (!((_child764) == null)) {
            var _val765 = (_child764)._min_ay13;
            _augval763 = ((_augval763) < (_val765)) ? (_augval763) : (_val765);
        }
        var _child766 = (_cursor752)._right8;
        if (!((_child766) == null)) {
            var _val767 = (_child766)._min_ay13;
            _augval763 = ((_augval763) < (_val767)) ? (_augval763) : (_val767);
        }
        (_cursor752)._min_ay13 = _augval763;
        /* _max_ay24 is max of ay2 */
        var _augval768 = (_cursor752).ay2;
        var _child769 = (_cursor752)._left7;
        if (!((_child769) == null)) {
            var _val770 = (_child769)._max_ay24;
            _augval768 = ((_augval768) < (_val770)) ? (_val770) : (_augval768);
        }
        var _child771 = (_cursor752)._right8;
        if (!((_child771) == null)) {
            var _val772 = (_child771)._max_ay24;
            _augval768 = ((_augval768) < (_val772)) ? (_val772) : (_augval768);
        }
        (_cursor752)._max_ay24 = _augval768;
        (_cursor752)._height10 = 1 + ((((((_cursor752)._left7) == null) ? (-1) : (((_cursor752)._left7)._height10)) > ((((_cursor752)._right8) == null) ? (-1) : (((_cursor752)._right8)._height10))) ? ((((_cursor752)._left7) == null) ? (-1) : (((_cursor752)._left7)._height10)) : ((((_cursor752)._right8) == null) ? (-1) : (((_cursor752)._right8)._height10)));
        _changed753 = false;
        _changed753 = (_changed753) || (!((_old__min_ax12754) == ((_cursor752)._min_ax12)));
        _changed753 = (_changed753) || (!((_old__min_ay13755) == ((_cursor752)._min_ay13)));
        _changed753 = (_changed753) || (!((_old__max_ay24756) == ((_cursor752)._max_ay24)));
        _changed753 = (_changed753) || (!((_old_height757) == ((_cursor752)._height10)));
        _cursor752 = (_cursor752)._parent9;
    }
    /* rebalance AVL tree */
    var _cursor773 = __x;
    var _imbalance774;
    while (!(((_cursor773)._parent9) == null)) {
        _cursor773 = (_cursor773)._parent9;
        (_cursor773)._height10 = 1 + ((((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) > ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10))) ? ((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) : ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10)));
        _imbalance774 = ((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) - ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10));
        if ((_imbalance774) > (1)) {
            if ((((((_cursor773)._left7)._left7) == null) ? (-1) : ((((_cursor773)._left7)._left7)._height10)) < (((((_cursor773)._left7)._right8) == null) ? (-1) : ((((_cursor773)._left7)._right8)._height10))) {
                /* rotate ((_cursor773)._left7)._right8 */
                var _a775 = (_cursor773)._left7;
                var _b776 = (_a775)._right8;
                var _c777 = (_b776)._left7;
                /* replace _a775 with _b776 in (_a775)._parent9 */
                if (!(((_a775)._parent9) == null)) {
                    if ((((_a775)._parent9)._left7) == (_a775)) {
                        ((_a775)._parent9)._left7 = _b776;
                    } else {
                        ((_a775)._parent9)._right8 = _b776;
                    }
                }
                if (!((_b776) == null)) {
                    (_b776)._parent9 = (_a775)._parent9;
                }
                /* replace _c777 with _a775 in _b776 */
                (_b776)._left7 = _a775;
                if (!((_a775) == null)) {
                    (_a775)._parent9 = _b776;
                }
                /* replace _b776 with _c777 in _a775 */
                (_a775)._right8 = _c777;
                if (!((_c777) == null)) {
                    (_c777)._parent9 = _a775;
                }
                /* _min_ax12 is min of ax1 */
                var _augval778 = (_a775).ax1;
                var _child779 = (_a775)._left7;
                if (!((_child779) == null)) {
                    var _val780 = (_child779)._min_ax12;
                    _augval778 = ((_augval778) < (_val780)) ? (_augval778) : (_val780);
                }
                var _child781 = (_a775)._right8;
                if (!((_child781) == null)) {
                    var _val782 = (_child781)._min_ax12;
                    _augval778 = ((_augval778) < (_val782)) ? (_augval778) : (_val782);
                }
                (_a775)._min_ax12 = _augval778;
                /* _min_ay13 is min of ay1 */
                var _augval783 = (_a775).ay1;
                var _child784 = (_a775)._left7;
                if (!((_child784) == null)) {
                    var _val785 = (_child784)._min_ay13;
                    _augval783 = ((_augval783) < (_val785)) ? (_augval783) : (_val785);
                }
                var _child786 = (_a775)._right8;
                if (!((_child786) == null)) {
                    var _val787 = (_child786)._min_ay13;
                    _augval783 = ((_augval783) < (_val787)) ? (_augval783) : (_val787);
                }
                (_a775)._min_ay13 = _augval783;
                /* _max_ay24 is max of ay2 */
                var _augval788 = (_a775).ay2;
                var _child789 = (_a775)._left7;
                if (!((_child789) == null)) {
                    var _val790 = (_child789)._max_ay24;
                    _augval788 = ((_augval788) < (_val790)) ? (_val790) : (_augval788);
                }
                var _child791 = (_a775)._right8;
                if (!((_child791) == null)) {
                    var _val792 = (_child791)._max_ay24;
                    _augval788 = ((_augval788) < (_val792)) ? (_val792) : (_augval788);
                }
                (_a775)._max_ay24 = _augval788;
                (_a775)._height10 = 1 + ((((((_a775)._left7) == null) ? (-1) : (((_a775)._left7)._height10)) > ((((_a775)._right8) == null) ? (-1) : (((_a775)._right8)._height10))) ? ((((_a775)._left7) == null) ? (-1) : (((_a775)._left7)._height10)) : ((((_a775)._right8) == null) ? (-1) : (((_a775)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval793 = (_b776).ax1;
                var _child794 = (_b776)._left7;
                if (!((_child794) == null)) {
                    var _val795 = (_child794)._min_ax12;
                    _augval793 = ((_augval793) < (_val795)) ? (_augval793) : (_val795);
                }
                var _child796 = (_b776)._right8;
                if (!((_child796) == null)) {
                    var _val797 = (_child796)._min_ax12;
                    _augval793 = ((_augval793) < (_val797)) ? (_augval793) : (_val797);
                }
                (_b776)._min_ax12 = _augval793;
                /* _min_ay13 is min of ay1 */
                var _augval798 = (_b776).ay1;
                var _child799 = (_b776)._left7;
                if (!((_child799) == null)) {
                    var _val800 = (_child799)._min_ay13;
                    _augval798 = ((_augval798) < (_val800)) ? (_augval798) : (_val800);
                }
                var _child801 = (_b776)._right8;
                if (!((_child801) == null)) {
                    var _val802 = (_child801)._min_ay13;
                    _augval798 = ((_augval798) < (_val802)) ? (_augval798) : (_val802);
                }
                (_b776)._min_ay13 = _augval798;
                /* _max_ay24 is max of ay2 */
                var _augval803 = (_b776).ay2;
                var _child804 = (_b776)._left7;
                if (!((_child804) == null)) {
                    var _val805 = (_child804)._max_ay24;
                    _augval803 = ((_augval803) < (_val805)) ? (_val805) : (_augval803);
                }
                var _child806 = (_b776)._right8;
                if (!((_child806) == null)) {
                    var _val807 = (_child806)._max_ay24;
                    _augval803 = ((_augval803) < (_val807)) ? (_val807) : (_augval803);
                }
                (_b776)._max_ay24 = _augval803;
                (_b776)._height10 = 1 + ((((((_b776)._left7) == null) ? (-1) : (((_b776)._left7)._height10)) > ((((_b776)._right8) == null) ? (-1) : (((_b776)._right8)._height10))) ? ((((_b776)._left7) == null) ? (-1) : (((_b776)._left7)._height10)) : ((((_b776)._right8) == null) ? (-1) : (((_b776)._right8)._height10)));
                if (!(((_b776)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval808 = ((_b776)._parent9).ax1;
                    var _child809 = ((_b776)._parent9)._left7;
                    if (!((_child809) == null)) {
                        var _val810 = (_child809)._min_ax12;
                        _augval808 = ((_augval808) < (_val810)) ? (_augval808) : (_val810);
                    }
                    var _child811 = ((_b776)._parent9)._right8;
                    if (!((_child811) == null)) {
                        var _val812 = (_child811)._min_ax12;
                        _augval808 = ((_augval808) < (_val812)) ? (_augval808) : (_val812);
                    }
                    ((_b776)._parent9)._min_ax12 = _augval808;
                    /* _min_ay13 is min of ay1 */
                    var _augval813 = ((_b776)._parent9).ay1;
                    var _child814 = ((_b776)._parent9)._left7;
                    if (!((_child814) == null)) {
                        var _val815 = (_child814)._min_ay13;
                        _augval813 = ((_augval813) < (_val815)) ? (_augval813) : (_val815);
                    }
                    var _child816 = ((_b776)._parent9)._right8;
                    if (!((_child816) == null)) {
                        var _val817 = (_child816)._min_ay13;
                        _augval813 = ((_augval813) < (_val817)) ? (_augval813) : (_val817);
                    }
                    ((_b776)._parent9)._min_ay13 = _augval813;
                    /* _max_ay24 is max of ay2 */
                    var _augval818 = ((_b776)._parent9).ay2;
                    var _child819 = ((_b776)._parent9)._left7;
                    if (!((_child819) == null)) {
                        var _val820 = (_child819)._max_ay24;
                        _augval818 = ((_augval818) < (_val820)) ? (_val820) : (_augval818);
                    }
                    var _child821 = ((_b776)._parent9)._right8;
                    if (!((_child821) == null)) {
                        var _val822 = (_child821)._max_ay24;
                        _augval818 = ((_augval818) < (_val822)) ? (_val822) : (_augval818);
                    }
                    ((_b776)._parent9)._max_ay24 = _augval818;
                    ((_b776)._parent9)._height10 = 1 + (((((((_b776)._parent9)._left7) == null) ? (-1) : ((((_b776)._parent9)._left7)._height10)) > (((((_b776)._parent9)._right8) == null) ? (-1) : ((((_b776)._parent9)._right8)._height10))) ? (((((_b776)._parent9)._left7) == null) ? (-1) : ((((_b776)._parent9)._left7)._height10)) : (((((_b776)._parent9)._right8) == null) ? (-1) : ((((_b776)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b776;
                }
            }
            /* rotate (_cursor773)._left7 */
            var _a823 = _cursor773;
            var _b824 = (_a823)._left7;
            var _c825 = (_b824)._right8;
            /* replace _a823 with _b824 in (_a823)._parent9 */
            if (!(((_a823)._parent9) == null)) {
                if ((((_a823)._parent9)._left7) == (_a823)) {
                    ((_a823)._parent9)._left7 = _b824;
                } else {
                    ((_a823)._parent9)._right8 = _b824;
                }
            }
            if (!((_b824) == null)) {
                (_b824)._parent9 = (_a823)._parent9;
            }
            /* replace _c825 with _a823 in _b824 */
            (_b824)._right8 = _a823;
            if (!((_a823) == null)) {
                (_a823)._parent9 = _b824;
            }
            /* replace _b824 with _c825 in _a823 */
            (_a823)._left7 = _c825;
            if (!((_c825) == null)) {
                (_c825)._parent9 = _a823;
            }
            /* _min_ax12 is min of ax1 */
            var _augval826 = (_a823).ax1;
            var _child827 = (_a823)._left7;
            if (!((_child827) == null)) {
                var _val828 = (_child827)._min_ax12;
                _augval826 = ((_augval826) < (_val828)) ? (_augval826) : (_val828);
            }
            var _child829 = (_a823)._right8;
            if (!((_child829) == null)) {
                var _val830 = (_child829)._min_ax12;
                _augval826 = ((_augval826) < (_val830)) ? (_augval826) : (_val830);
            }
            (_a823)._min_ax12 = _augval826;
            /* _min_ay13 is min of ay1 */
            var _augval831 = (_a823).ay1;
            var _child832 = (_a823)._left7;
            if (!((_child832) == null)) {
                var _val833 = (_child832)._min_ay13;
                _augval831 = ((_augval831) < (_val833)) ? (_augval831) : (_val833);
            }
            var _child834 = (_a823)._right8;
            if (!((_child834) == null)) {
                var _val835 = (_child834)._min_ay13;
                _augval831 = ((_augval831) < (_val835)) ? (_augval831) : (_val835);
            }
            (_a823)._min_ay13 = _augval831;
            /* _max_ay24 is max of ay2 */
            var _augval836 = (_a823).ay2;
            var _child837 = (_a823)._left7;
            if (!((_child837) == null)) {
                var _val838 = (_child837)._max_ay24;
                _augval836 = ((_augval836) < (_val838)) ? (_val838) : (_augval836);
            }
            var _child839 = (_a823)._right8;
            if (!((_child839) == null)) {
                var _val840 = (_child839)._max_ay24;
                _augval836 = ((_augval836) < (_val840)) ? (_val840) : (_augval836);
            }
            (_a823)._max_ay24 = _augval836;
            (_a823)._height10 = 1 + ((((((_a823)._left7) == null) ? (-1) : (((_a823)._left7)._height10)) > ((((_a823)._right8) == null) ? (-1) : (((_a823)._right8)._height10))) ? ((((_a823)._left7) == null) ? (-1) : (((_a823)._left7)._height10)) : ((((_a823)._right8) == null) ? (-1) : (((_a823)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval841 = (_b824).ax1;
            var _child842 = (_b824)._left7;
            if (!((_child842) == null)) {
                var _val843 = (_child842)._min_ax12;
                _augval841 = ((_augval841) < (_val843)) ? (_augval841) : (_val843);
            }
            var _child844 = (_b824)._right8;
            if (!((_child844) == null)) {
                var _val845 = (_child844)._min_ax12;
                _augval841 = ((_augval841) < (_val845)) ? (_augval841) : (_val845);
            }
            (_b824)._min_ax12 = _augval841;
            /* _min_ay13 is min of ay1 */
            var _augval846 = (_b824).ay1;
            var _child847 = (_b824)._left7;
            if (!((_child847) == null)) {
                var _val848 = (_child847)._min_ay13;
                _augval846 = ((_augval846) < (_val848)) ? (_augval846) : (_val848);
            }
            var _child849 = (_b824)._right8;
            if (!((_child849) == null)) {
                var _val850 = (_child849)._min_ay13;
                _augval846 = ((_augval846) < (_val850)) ? (_augval846) : (_val850);
            }
            (_b824)._min_ay13 = _augval846;
            /* _max_ay24 is max of ay2 */
            var _augval851 = (_b824).ay2;
            var _child852 = (_b824)._left7;
            if (!((_child852) == null)) {
                var _val853 = (_child852)._max_ay24;
                _augval851 = ((_augval851) < (_val853)) ? (_val853) : (_augval851);
            }
            var _child854 = (_b824)._right8;
            if (!((_child854) == null)) {
                var _val855 = (_child854)._max_ay24;
                _augval851 = ((_augval851) < (_val855)) ? (_val855) : (_augval851);
            }
            (_b824)._max_ay24 = _augval851;
            (_b824)._height10 = 1 + ((((((_b824)._left7) == null) ? (-1) : (((_b824)._left7)._height10)) > ((((_b824)._right8) == null) ? (-1) : (((_b824)._right8)._height10))) ? ((((_b824)._left7) == null) ? (-1) : (((_b824)._left7)._height10)) : ((((_b824)._right8) == null) ? (-1) : (((_b824)._right8)._height10)));
            if (!(((_b824)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval856 = ((_b824)._parent9).ax1;
                var _child857 = ((_b824)._parent9)._left7;
                if (!((_child857) == null)) {
                    var _val858 = (_child857)._min_ax12;
                    _augval856 = ((_augval856) < (_val858)) ? (_augval856) : (_val858);
                }
                var _child859 = ((_b824)._parent9)._right8;
                if (!((_child859) == null)) {
                    var _val860 = (_child859)._min_ax12;
                    _augval856 = ((_augval856) < (_val860)) ? (_augval856) : (_val860);
                }
                ((_b824)._parent9)._min_ax12 = _augval856;
                /* _min_ay13 is min of ay1 */
                var _augval861 = ((_b824)._parent9).ay1;
                var _child862 = ((_b824)._parent9)._left7;
                if (!((_child862) == null)) {
                    var _val863 = (_child862)._min_ay13;
                    _augval861 = ((_augval861) < (_val863)) ? (_augval861) : (_val863);
                }
                var _child864 = ((_b824)._parent9)._right8;
                if (!((_child864) == null)) {
                    var _val865 = (_child864)._min_ay13;
                    _augval861 = ((_augval861) < (_val865)) ? (_augval861) : (_val865);
                }
                ((_b824)._parent9)._min_ay13 = _augval861;
                /* _max_ay24 is max of ay2 */
                var _augval866 = ((_b824)._parent9).ay2;
                var _child867 = ((_b824)._parent9)._left7;
                if (!((_child867) == null)) {
                    var _val868 = (_child867)._max_ay24;
                    _augval866 = ((_augval866) < (_val868)) ? (_val868) : (_augval866);
                }
                var _child869 = ((_b824)._parent9)._right8;
                if (!((_child869) == null)) {
                    var _val870 = (_child869)._max_ay24;
                    _augval866 = ((_augval866) < (_val870)) ? (_val870) : (_augval866);
                }
                ((_b824)._parent9)._max_ay24 = _augval866;
                ((_b824)._parent9)._height10 = 1 + (((((((_b824)._parent9)._left7) == null) ? (-1) : ((((_b824)._parent9)._left7)._height10)) > (((((_b824)._parent9)._right8) == null) ? (-1) : ((((_b824)._parent9)._right8)._height10))) ? (((((_b824)._parent9)._left7) == null) ? (-1) : ((((_b824)._parent9)._left7)._height10)) : (((((_b824)._parent9)._right8) == null) ? (-1) : ((((_b824)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b824;
            }
            _cursor773 = (_cursor773)._parent9;
        } else if ((_imbalance774) < (-1)) {
            if ((((((_cursor773)._right8)._left7) == null) ? (-1) : ((((_cursor773)._right8)._left7)._height10)) > (((((_cursor773)._right8)._right8) == null) ? (-1) : ((((_cursor773)._right8)._right8)._height10))) {
                /* rotate ((_cursor773)._right8)._left7 */
                var _a871 = (_cursor773)._right8;
                var _b872 = (_a871)._left7;
                var _c873 = (_b872)._right8;
                /* replace _a871 with _b872 in (_a871)._parent9 */
                if (!(((_a871)._parent9) == null)) {
                    if ((((_a871)._parent9)._left7) == (_a871)) {
                        ((_a871)._parent9)._left7 = _b872;
                    } else {
                        ((_a871)._parent9)._right8 = _b872;
                    }
                }
                if (!((_b872) == null)) {
                    (_b872)._parent9 = (_a871)._parent9;
                }
                /* replace _c873 with _a871 in _b872 */
                (_b872)._right8 = _a871;
                if (!((_a871) == null)) {
                    (_a871)._parent9 = _b872;
                }
                /* replace _b872 with _c873 in _a871 */
                (_a871)._left7 = _c873;
                if (!((_c873) == null)) {
                    (_c873)._parent9 = _a871;
                }
                /* _min_ax12 is min of ax1 */
                var _augval874 = (_a871).ax1;
                var _child875 = (_a871)._left7;
                if (!((_child875) == null)) {
                    var _val876 = (_child875)._min_ax12;
                    _augval874 = ((_augval874) < (_val876)) ? (_augval874) : (_val876);
                }
                var _child877 = (_a871)._right8;
                if (!((_child877) == null)) {
                    var _val878 = (_child877)._min_ax12;
                    _augval874 = ((_augval874) < (_val878)) ? (_augval874) : (_val878);
                }
                (_a871)._min_ax12 = _augval874;
                /* _min_ay13 is min of ay1 */
                var _augval879 = (_a871).ay1;
                var _child880 = (_a871)._left7;
                if (!((_child880) == null)) {
                    var _val881 = (_child880)._min_ay13;
                    _augval879 = ((_augval879) < (_val881)) ? (_augval879) : (_val881);
                }
                var _child882 = (_a871)._right8;
                if (!((_child882) == null)) {
                    var _val883 = (_child882)._min_ay13;
                    _augval879 = ((_augval879) < (_val883)) ? (_augval879) : (_val883);
                }
                (_a871)._min_ay13 = _augval879;
                /* _max_ay24 is max of ay2 */
                var _augval884 = (_a871).ay2;
                var _child885 = (_a871)._left7;
                if (!((_child885) == null)) {
                    var _val886 = (_child885)._max_ay24;
                    _augval884 = ((_augval884) < (_val886)) ? (_val886) : (_augval884);
                }
                var _child887 = (_a871)._right8;
                if (!((_child887) == null)) {
                    var _val888 = (_child887)._max_ay24;
                    _augval884 = ((_augval884) < (_val888)) ? (_val888) : (_augval884);
                }
                (_a871)._max_ay24 = _augval884;
                (_a871)._height10 = 1 + ((((((_a871)._left7) == null) ? (-1) : (((_a871)._left7)._height10)) > ((((_a871)._right8) == null) ? (-1) : (((_a871)._right8)._height10))) ? ((((_a871)._left7) == null) ? (-1) : (((_a871)._left7)._height10)) : ((((_a871)._right8) == null) ? (-1) : (((_a871)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval889 = (_b872).ax1;
                var _child890 = (_b872)._left7;
                if (!((_child890) == null)) {
                    var _val891 = (_child890)._min_ax12;
                    _augval889 = ((_augval889) < (_val891)) ? (_augval889) : (_val891);
                }
                var _child892 = (_b872)._right8;
                if (!((_child892) == null)) {
                    var _val893 = (_child892)._min_ax12;
                    _augval889 = ((_augval889) < (_val893)) ? (_augval889) : (_val893);
                }
                (_b872)._min_ax12 = _augval889;
                /* _min_ay13 is min of ay1 */
                var _augval894 = (_b872).ay1;
                var _child895 = (_b872)._left7;
                if (!((_child895) == null)) {
                    var _val896 = (_child895)._min_ay13;
                    _augval894 = ((_augval894) < (_val896)) ? (_augval894) : (_val896);
                }
                var _child897 = (_b872)._right8;
                if (!((_child897) == null)) {
                    var _val898 = (_child897)._min_ay13;
                    _augval894 = ((_augval894) < (_val898)) ? (_augval894) : (_val898);
                }
                (_b872)._min_ay13 = _augval894;
                /* _max_ay24 is max of ay2 */
                var _augval899 = (_b872).ay2;
                var _child900 = (_b872)._left7;
                if (!((_child900) == null)) {
                    var _val901 = (_child900)._max_ay24;
                    _augval899 = ((_augval899) < (_val901)) ? (_val901) : (_augval899);
                }
                var _child902 = (_b872)._right8;
                if (!((_child902) == null)) {
                    var _val903 = (_child902)._max_ay24;
                    _augval899 = ((_augval899) < (_val903)) ? (_val903) : (_augval899);
                }
                (_b872)._max_ay24 = _augval899;
                (_b872)._height10 = 1 + ((((((_b872)._left7) == null) ? (-1) : (((_b872)._left7)._height10)) > ((((_b872)._right8) == null) ? (-1) : (((_b872)._right8)._height10))) ? ((((_b872)._left7) == null) ? (-1) : (((_b872)._left7)._height10)) : ((((_b872)._right8) == null) ? (-1) : (((_b872)._right8)._height10)));
                if (!(((_b872)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval904 = ((_b872)._parent9).ax1;
                    var _child905 = ((_b872)._parent9)._left7;
                    if (!((_child905) == null)) {
                        var _val906 = (_child905)._min_ax12;
                        _augval904 = ((_augval904) < (_val906)) ? (_augval904) : (_val906);
                    }
                    var _child907 = ((_b872)._parent9)._right8;
                    if (!((_child907) == null)) {
                        var _val908 = (_child907)._min_ax12;
                        _augval904 = ((_augval904) < (_val908)) ? (_augval904) : (_val908);
                    }
                    ((_b872)._parent9)._min_ax12 = _augval904;
                    /* _min_ay13 is min of ay1 */
                    var _augval909 = ((_b872)._parent9).ay1;
                    var _child910 = ((_b872)._parent9)._left7;
                    if (!((_child910) == null)) {
                        var _val911 = (_child910)._min_ay13;
                        _augval909 = ((_augval909) < (_val911)) ? (_augval909) : (_val911);
                    }
                    var _child912 = ((_b872)._parent9)._right8;
                    if (!((_child912) == null)) {
                        var _val913 = (_child912)._min_ay13;
                        _augval909 = ((_augval909) < (_val913)) ? (_augval909) : (_val913);
                    }
                    ((_b872)._parent9)._min_ay13 = _augval909;
                    /* _max_ay24 is max of ay2 */
                    var _augval914 = ((_b872)._parent9).ay2;
                    var _child915 = ((_b872)._parent9)._left7;
                    if (!((_child915) == null)) {
                        var _val916 = (_child915)._max_ay24;
                        _augval914 = ((_augval914) < (_val916)) ? (_val916) : (_augval914);
                    }
                    var _child917 = ((_b872)._parent9)._right8;
                    if (!((_child917) == null)) {
                        var _val918 = (_child917)._max_ay24;
                        _augval914 = ((_augval914) < (_val918)) ? (_val918) : (_augval914);
                    }
                    ((_b872)._parent9)._max_ay24 = _augval914;
                    ((_b872)._parent9)._height10 = 1 + (((((((_b872)._parent9)._left7) == null) ? (-1) : ((((_b872)._parent9)._left7)._height10)) > (((((_b872)._parent9)._right8) == null) ? (-1) : ((((_b872)._parent9)._right8)._height10))) ? (((((_b872)._parent9)._left7) == null) ? (-1) : ((((_b872)._parent9)._left7)._height10)) : (((((_b872)._parent9)._right8) == null) ? (-1) : ((((_b872)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b872;
                }
            }
            /* rotate (_cursor773)._right8 */
            var _a919 = _cursor773;
            var _b920 = (_a919)._right8;
            var _c921 = (_b920)._left7;
            /* replace _a919 with _b920 in (_a919)._parent9 */
            if (!(((_a919)._parent9) == null)) {
                if ((((_a919)._parent9)._left7) == (_a919)) {
                    ((_a919)._parent9)._left7 = _b920;
                } else {
                    ((_a919)._parent9)._right8 = _b920;
                }
            }
            if (!((_b920) == null)) {
                (_b920)._parent9 = (_a919)._parent9;
            }
            /* replace _c921 with _a919 in _b920 */
            (_b920)._left7 = _a919;
            if (!((_a919) == null)) {
                (_a919)._parent9 = _b920;
            }
            /* replace _b920 with _c921 in _a919 */
            (_a919)._right8 = _c921;
            if (!((_c921) == null)) {
                (_c921)._parent9 = _a919;
            }
            /* _min_ax12 is min of ax1 */
            var _augval922 = (_a919).ax1;
            var _child923 = (_a919)._left7;
            if (!((_child923) == null)) {
                var _val924 = (_child923)._min_ax12;
                _augval922 = ((_augval922) < (_val924)) ? (_augval922) : (_val924);
            }
            var _child925 = (_a919)._right8;
            if (!((_child925) == null)) {
                var _val926 = (_child925)._min_ax12;
                _augval922 = ((_augval922) < (_val926)) ? (_augval922) : (_val926);
            }
            (_a919)._min_ax12 = _augval922;
            /* _min_ay13 is min of ay1 */
            var _augval927 = (_a919).ay1;
            var _child928 = (_a919)._left7;
            if (!((_child928) == null)) {
                var _val929 = (_child928)._min_ay13;
                _augval927 = ((_augval927) < (_val929)) ? (_augval927) : (_val929);
            }
            var _child930 = (_a919)._right8;
            if (!((_child930) == null)) {
                var _val931 = (_child930)._min_ay13;
                _augval927 = ((_augval927) < (_val931)) ? (_augval927) : (_val931);
            }
            (_a919)._min_ay13 = _augval927;
            /* _max_ay24 is max of ay2 */
            var _augval932 = (_a919).ay2;
            var _child933 = (_a919)._left7;
            if (!((_child933) == null)) {
                var _val934 = (_child933)._max_ay24;
                _augval932 = ((_augval932) < (_val934)) ? (_val934) : (_augval932);
            }
            var _child935 = (_a919)._right8;
            if (!((_child935) == null)) {
                var _val936 = (_child935)._max_ay24;
                _augval932 = ((_augval932) < (_val936)) ? (_val936) : (_augval932);
            }
            (_a919)._max_ay24 = _augval932;
            (_a919)._height10 = 1 + ((((((_a919)._left7) == null) ? (-1) : (((_a919)._left7)._height10)) > ((((_a919)._right8) == null) ? (-1) : (((_a919)._right8)._height10))) ? ((((_a919)._left7) == null) ? (-1) : (((_a919)._left7)._height10)) : ((((_a919)._right8) == null) ? (-1) : (((_a919)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval937 = (_b920).ax1;
            var _child938 = (_b920)._left7;
            if (!((_child938) == null)) {
                var _val939 = (_child938)._min_ax12;
                _augval937 = ((_augval937) < (_val939)) ? (_augval937) : (_val939);
            }
            var _child940 = (_b920)._right8;
            if (!((_child940) == null)) {
                var _val941 = (_child940)._min_ax12;
                _augval937 = ((_augval937) < (_val941)) ? (_augval937) : (_val941);
            }
            (_b920)._min_ax12 = _augval937;
            /* _min_ay13 is min of ay1 */
            var _augval942 = (_b920).ay1;
            var _child943 = (_b920)._left7;
            if (!((_child943) == null)) {
                var _val944 = (_child943)._min_ay13;
                _augval942 = ((_augval942) < (_val944)) ? (_augval942) : (_val944);
            }
            var _child945 = (_b920)._right8;
            if (!((_child945) == null)) {
                var _val946 = (_child945)._min_ay13;
                _augval942 = ((_augval942) < (_val946)) ? (_augval942) : (_val946);
            }
            (_b920)._min_ay13 = _augval942;
            /* _max_ay24 is max of ay2 */
            var _augval947 = (_b920).ay2;
            var _child948 = (_b920)._left7;
            if (!((_child948) == null)) {
                var _val949 = (_child948)._max_ay24;
                _augval947 = ((_augval947) < (_val949)) ? (_val949) : (_augval947);
            }
            var _child950 = (_b920)._right8;
            if (!((_child950) == null)) {
                var _val951 = (_child950)._max_ay24;
                _augval947 = ((_augval947) < (_val951)) ? (_val951) : (_augval947);
            }
            (_b920)._max_ay24 = _augval947;
            (_b920)._height10 = 1 + ((((((_b920)._left7) == null) ? (-1) : (((_b920)._left7)._height10)) > ((((_b920)._right8) == null) ? (-1) : (((_b920)._right8)._height10))) ? ((((_b920)._left7) == null) ? (-1) : (((_b920)._left7)._height10)) : ((((_b920)._right8) == null) ? (-1) : (((_b920)._right8)._height10)));
            if (!(((_b920)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval952 = ((_b920)._parent9).ax1;
                var _child953 = ((_b920)._parent9)._left7;
                if (!((_child953) == null)) {
                    var _val954 = (_child953)._min_ax12;
                    _augval952 = ((_augval952) < (_val954)) ? (_augval952) : (_val954);
                }
                var _child955 = ((_b920)._parent9)._right8;
                if (!((_child955) == null)) {
                    var _val956 = (_child955)._min_ax12;
                    _augval952 = ((_augval952) < (_val956)) ? (_augval952) : (_val956);
                }
                ((_b920)._parent9)._min_ax12 = _augval952;
                /* _min_ay13 is min of ay1 */
                var _augval957 = ((_b920)._parent9).ay1;
                var _child958 = ((_b920)._parent9)._left7;
                if (!((_child958) == null)) {
                    var _val959 = (_child958)._min_ay13;
                    _augval957 = ((_augval957) < (_val959)) ? (_augval957) : (_val959);
                }
                var _child960 = ((_b920)._parent9)._right8;
                if (!((_child960) == null)) {
                    var _val961 = (_child960)._min_ay13;
                    _augval957 = ((_augval957) < (_val961)) ? (_augval957) : (_val961);
                }
                ((_b920)._parent9)._min_ay13 = _augval957;
                /* _max_ay24 is max of ay2 */
                var _augval962 = ((_b920)._parent9).ay2;
                var _child963 = ((_b920)._parent9)._left7;
                if (!((_child963) == null)) {
                    var _val964 = (_child963)._max_ay24;
                    _augval962 = ((_augval962) < (_val964)) ? (_val964) : (_augval962);
                }
                var _child965 = ((_b920)._parent9)._right8;
                if (!((_child965) == null)) {
                    var _val966 = (_child965)._max_ay24;
                    _augval962 = ((_augval962) < (_val966)) ? (_val966) : (_augval962);
                }
                ((_b920)._parent9)._max_ay24 = _augval962;
                ((_b920)._parent9)._height10 = 1 + (((((((_b920)._parent9)._left7) == null) ? (-1) : ((((_b920)._parent9)._left7)._height10)) > (((((_b920)._parent9)._right8) == null) ? (-1) : ((((_b920)._parent9)._right8)._height10))) ? (((((_b920)._parent9)._left7) == null) ? (-1) : ((((_b920)._parent9)._left7)._height10)) : (((((_b920)._parent9)._right8) == null) ? (-1) : ((((_b920)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b920;
            }
            _cursor773 = (_cursor773)._parent9;
        }
    }
    (__x).ax1 = ax1;
    (__x).ay1 = ay1;
    (__x).ax2 = ax2;
    (__x).ay2 = ay2;
}
RectangleHolder.prototype.findMatchingRectangles = function (bx1, by1, bx2, by2, __callback) {
    var _root967 = (this)._root1;
    var _x968 = _root967;
    var _descend969 = true;
    var _from_left970 = true;
    while (true) {
        if ((_x968) == null) {
            _x968 = null;
            break;
        }
        if (_descend969) {
            /* too small? */
            if ((false) || (((_x968).ax2) <= (bx1))) {
                if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                    if ((_x968) == (_root967)) {
                        _root967 = (_x968)._right8;
                    }
                    _x968 = (_x968)._right8;
                } else if ((_x968) == (_root967)) {
                    _x968 = null;
                    break;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
            } else if ((!(((_x968)._left7) == null)) && ((((true) && ((((_x968)._left7)._min_ax12) < (bx2))) && ((((_x968)._left7)._min_ay13) < (by2))) && ((((_x968)._left7)._max_ay24) > (by1)))) {
                _x968 = (_x968)._left7;
                /* too large? */
            } else if (false) {
                if ((_x968) == (_root967)) {
                    _x968 = null;
                    break;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
                /* node ok? */
            } else if ((((true) && (((_x968).ax1) < (bx2))) && (((_x968).ay1) < (by2))) && (((_x968).ay2) > (by1))) {
                break;
            } else if ((_x968) == (_root967)) {
                _root967 = (_x968)._right8;
                _x968 = (_x968)._right8;
            } else {
                if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                    if ((_x968) == (_root967)) {
                        _root967 = (_x968)._right8;
                    }
                    _x968 = (_x968)._right8;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
            }
        } else if (_from_left970) {
            if (false) {
                _x968 = null;
                break;
            } else if ((((true) && (((_x968).ax1) < (bx2))) && (((_x968).ay1) < (by2))) && (((_x968).ay2) > (by1))) {
                break;
            } else if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                _descend969 = true;
                if ((_x968) == (_root967)) {
                    _root967 = (_x968)._right8;
                }
                _x968 = (_x968)._right8;
            } else if ((_x968) == (_root967)) {
                _x968 = null;
                break;
            } else {
                _descend969 = false;
                _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                _x968 = (_x968)._parent9;
            }
        } else {
            if ((_x968) == (_root967)) {
                _x968 = null;
                break;
            } else {
                _descend969 = false;
                _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                _x968 = (_x968)._parent9;
            }
        }
    }
    var _prev_cursor5 = null;
    var _cursor6 = _x968;
    for (; ;) {
        if (!(!((_cursor6) == null))) break;
        var _name971 = _cursor6;
        /* ADVANCE */
        _prev_cursor5 = _cursor6;
        do {
            var _right_min972 = null;
            if ((!(((_cursor6)._right8) == null)) && ((((true) && ((((_cursor6)._right8)._min_ax12) < (bx2))) && ((((_cursor6)._right8)._min_ay13) < (by2))) && ((((_cursor6)._right8)._max_ay24) > (by1)))) {
                var _root973 = (_cursor6)._right8;
                var _x974 = _root973;
                var _descend975 = true;
                var _from_left976 = true;
                while (true) {
                    if ((_x974) == null) {
                        _x974 = null;
                        break;
                    }
                    if (_descend975) {
                        /* too small? */
                        if ((false) || (((_x974).ax2) <= (bx1))) {
                            if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                                if ((_x974) == (_root973)) {
                                    _root973 = (_x974)._right8;
                                }
                                _x974 = (_x974)._right8;
                            } else if ((_x974) == (_root973)) {
                                _x974 = null;
                                break;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                        } else if ((!(((_x974)._left7) == null)) && ((((true) && ((((_x974)._left7)._min_ax12) < (bx2))) && ((((_x974)._left7)._min_ay13) < (by2))) && ((((_x974)._left7)._max_ay24) > (by1)))) {
                            _x974 = (_x974)._left7;
                            /* too large? */
                        } else if (false) {
                            if ((_x974) == (_root973)) {
                                _x974 = null;
                                break;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                            /* node ok? */
                        } else if ((((true) && (((_x974).ax1) < (bx2))) && (((_x974).ay1) < (by2))) && (((_x974).ay2) > (by1))) {
                            break;
                        } else if ((_x974) == (_root973)) {
                            _root973 = (_x974)._right8;
                            _x974 = (_x974)._right8;
                        } else {
                            if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                                if ((_x974) == (_root973)) {
                                    _root973 = (_x974)._right8;
                                }
                                _x974 = (_x974)._right8;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                        }
                    } else if (_from_left976) {
                        if (false) {
                            _x974 = null;
                            break;
                        } else if ((((true) && (((_x974).ax1) < (bx2))) && (((_x974).ay1) < (by2))) && (((_x974).ay2) > (by1))) {
                            break;
                        } else if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                            _descend975 = true;
                            if ((_x974) == (_root973)) {
                                _root973 = (_x974)._right8;
                            }
                            _x974 = (_x974)._right8;
                        } else if ((_x974) == (_root973)) {
                            _x974 = null;
                            break;
                        } else {
                            _descend975 = false;
                            _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                            _x974 = (_x974)._parent9;
                        }
                    } else {
                        if ((_x974) == (_root973)) {
                            _x974 = null;
                            break;
                        } else {
                            _descend975 = false;
                            _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                            _x974 = (_x974)._parent9;
                        }
                    }
                }
                _right_min972 = _x974;
            }
            if (!((_right_min972) == null)) {
                _cursor6 = _right_min972;
                break;
            } else {
                while ((!(((_cursor6)._parent9) == null)) && ((_cursor6) == (((_cursor6)._parent9)._right8))) {
                    _cursor6 = (_cursor6)._parent9;
                }
                _cursor6 = (_cursor6)._parent9;
                if ((!((_cursor6) == null)) && (false)) {
                    _cursor6 = null;
                }
            }
        } while ((!((_cursor6) == null)) && (!((((true) && (((_cursor6).ax1) < (bx2))) && (((_cursor6).ay1) < (by2))) && (((_cursor6).ay2) > (by1)))));
        if (__callback(_name971)) {
            var _to_remove977 = _prev_cursor5;
            var _parent978 = (_to_remove977)._parent9;
            var _left979 = (_to_remove977)._left7;
            var _right980 = (_to_remove977)._right8;
            var _new_x981;
            if (((_left979) == null) && ((_right980) == null)) {
                _new_x981 = null;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else if ((!((_left979) == null)) && ((_right980) == null)) {
                _new_x981 = _left979;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else if (((_left979) == null) && (!((_right980) == null))) {
                _new_x981 = _right980;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else {
                var _root982 = (_to_remove977)._right8;
                var _x983 = _root982;
                var _descend984 = true;
                var _from_left985 = true;
                while (true) {
                    if ((_x983) == null) {
                        _x983 = null;
                        break;
                    }
                    if (_descend984) {
                        /* too small? */
                        if (false) {
                            if ((!(((_x983)._right8) == null)) && (true)) {
                                if ((_x983) == (_root982)) {
                                    _root982 = (_x983)._right8;
                                }
                                _x983 = (_x983)._right8;
                            } else if ((_x983) == (_root982)) {
                                _x983 = null;
                                break;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                        } else if ((!(((_x983)._left7) == null)) && (true)) {
                            _x983 = (_x983)._left7;
                            /* too large? */
                        } else if (false) {
                            if ((_x983) == (_root982)) {
                                _x983 = null;
                                break;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                            /* node ok? */
                        } else if (true) {
                            break;
                        } else if ((_x983) == (_root982)) {
                            _root982 = (_x983)._right8;
                            _x983 = (_x983)._right8;
                        } else {
                            if ((!(((_x983)._right8) == null)) && (true)) {
                                if ((_x983) == (_root982)) {
                                    _root982 = (_x983)._right8;
                                }
                                _x983 = (_x983)._right8;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                        }
                    } else if (_from_left985) {
                        if (false) {
                            _x983 = null;
                            break;
                        } else if (true) {
                            break;
                        } else if ((!(((_x983)._right8) == null)) && (true)) {
                            _descend984 = true;
                            if ((_x983) == (_root982)) {
                                _root982 = (_x983)._right8;
                            }
                            _x983 = (_x983)._right8;
                        } else if ((_x983) == (_root982)) {
                            _x983 = null;
                            break;
                        } else {
                            _descend984 = false;
                            _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                            _x983 = (_x983)._parent9;
                        }
                    } else {
                        if ((_x983) == (_root982)) {
                            _x983 = null;
                            break;
                        } else {
                            _descend984 = false;
                            _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                            _x983 = (_x983)._parent9;
                        }
                    }
                }
                _new_x981 = _x983;
                var _mp986 = (_x983)._parent9;
                var _mr987 = (_x983)._right8;
                /* replace _x983 with _mr987 in _mp986 */
                if (!((_mp986) == null)) {
                    if (((_mp986)._left7) == (_x983)) {
                        (_mp986)._left7 = _mr987;
                    } else {
                        (_mp986)._right8 = _mr987;
                    }
                }
                if (!((_mr987) == null)) {
                    (_mr987)._parent9 = _mp986;
                }
                /* replace _to_remove977 with _x983 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _x983;
                    } else {
                        (_parent978)._right8 = _x983;
                    }
                }
                if (!((_x983) == null)) {
                    (_x983)._parent9 = _parent978;
                }
                /* replace null with _left979 in _x983 */
                (_x983)._left7 = _left979;
                if (!((_left979) == null)) {
                    (_left979)._parent9 = _x983;
                }
                /* replace _mr987 with (_to_remove977)._right8 in _x983 */
                (_x983)._right8 = (_to_remove977)._right8;
                if (!(((_to_remove977)._right8) == null)) {
                    ((_to_remove977)._right8)._parent9 = _x983;
                }
                /* _min_ax12 is min of ax1 */
                var _augval988 = (_x983).ax1;
                var _child989 = (_x983)._left7;
                if (!((_child989) == null)) {
                    var _val990 = (_child989)._min_ax12;
                    _augval988 = ((_augval988) < (_val990)) ? (_augval988) : (_val990);
                }
                var _child991 = (_x983)._right8;
                if (!((_child991) == null)) {
                    var _val992 = (_child991)._min_ax12;
                    _augval988 = ((_augval988) < (_val992)) ? (_augval988) : (_val992);
                }
                (_x983)._min_ax12 = _augval988;
                /* _min_ay13 is min of ay1 */
                var _augval993 = (_x983).ay1;
                var _child994 = (_x983)._left7;
                if (!((_child994) == null)) {
                    var _val995 = (_child994)._min_ay13;
                    _augval993 = ((_augval993) < (_val995)) ? (_augval993) : (_val995);
                }
                var _child996 = (_x983)._right8;
                if (!((_child996) == null)) {
                    var _val997 = (_child996)._min_ay13;
                    _augval993 = ((_augval993) < (_val997)) ? (_augval993) : (_val997);
                }
                (_x983)._min_ay13 = _augval993;
                /* _max_ay24 is max of ay2 */
                var _augval998 = (_x983).ay2;
                var _child999 = (_x983)._left7;
                if (!((_child999) == null)) {
                    var _val1000 = (_child999)._max_ay24;
                    _augval998 = ((_augval998) < (_val1000)) ? (_val1000) : (_augval998);
                }
                var _child1001 = (_x983)._right8;
                if (!((_child1001) == null)) {
                    var _val1002 = (_child1001)._max_ay24;
                    _augval998 = ((_augval998) < (_val1002)) ? (_val1002) : (_augval998);
                }
                (_x983)._max_ay24 = _augval998;
                (_x983)._height10 = 1 + ((((((_x983)._left7) == null) ? (-1) : (((_x983)._left7)._height10)) > ((((_x983)._right8) == null) ? (-1) : (((_x983)._right8)._height10))) ? ((((_x983)._left7) == null) ? (-1) : (((_x983)._left7)._height10)) : ((((_x983)._right8) == null) ? (-1) : (((_x983)._right8)._height10)));
                var _cursor1003 = _mp986;
                var _changed1004 = true;
                while ((_changed1004) && (!((_cursor1003) == (_parent978)))) {
                    var _old__min_ax121005 = (_cursor1003)._min_ax12;
                    var _old__min_ay131006 = (_cursor1003)._min_ay13;
                    var _old__max_ay241007 = (_cursor1003)._max_ay24;
                    var _old_height1008 = (_cursor1003)._height10;
                    /* _min_ax12 is min of ax1 */
                    var _augval1009 = (_cursor1003).ax1;
                    var _child1010 = (_cursor1003)._left7;
                    if (!((_child1010) == null)) {
                        var _val1011 = (_child1010)._min_ax12;
                        _augval1009 = ((_augval1009) < (_val1011)) ? (_augval1009) : (_val1011);
                    }
                    var _child1012 = (_cursor1003)._right8;
                    if (!((_child1012) == null)) {
                        var _val1013 = (_child1012)._min_ax12;
                        _augval1009 = ((_augval1009) < (_val1013)) ? (_augval1009) : (_val1013);
                    }
                    (_cursor1003)._min_ax12 = _augval1009;
                    /* _min_ay13 is min of ay1 */
                    var _augval1014 = (_cursor1003).ay1;
                    var _child1015 = (_cursor1003)._left7;
                    if (!((_child1015) == null)) {
                        var _val1016 = (_child1015)._min_ay13;
                        _augval1014 = ((_augval1014) < (_val1016)) ? (_augval1014) : (_val1016);
                    }
                    var _child1017 = (_cursor1003)._right8;
                    if (!((_child1017) == null)) {
                        var _val1018 = (_child1017)._min_ay13;
                        _augval1014 = ((_augval1014) < (_val1018)) ? (_augval1014) : (_val1018);
                    }
                    (_cursor1003)._min_ay13 = _augval1014;
                    /* _max_ay24 is max of ay2 */
                    var _augval1019 = (_cursor1003).ay2;
                    var _child1020 = (_cursor1003)._left7;
                    if (!((_child1020) == null)) {
                        var _val1021 = (_child1020)._max_ay24;
                        _augval1019 = ((_augval1019) < (_val1021)) ? (_val1021) : (_augval1019);
                    }
                    var _child1022 = (_cursor1003)._right8;
                    if (!((_child1022) == null)) {
                        var _val1023 = (_child1022)._max_ay24;
                        _augval1019 = ((_augval1019) < (_val1023)) ? (_val1023) : (_augval1019);
                    }
                    (_cursor1003)._max_ay24 = _augval1019;
                    (_cursor1003)._height10 = 1 + ((((((_cursor1003)._left7) == null) ? (-1) : (((_cursor1003)._left7)._height10)) > ((((_cursor1003)._right8) == null) ? (-1) : (((_cursor1003)._right8)._height10))) ? ((((_cursor1003)._left7) == null) ? (-1) : (((_cursor1003)._left7)._height10)) : ((((_cursor1003)._right8) == null) ? (-1) : (((_cursor1003)._right8)._height10)));
                    _changed1004 = false;
                    _changed1004 = (_changed1004) || (!((_old__min_ax121005) == ((_cursor1003)._min_ax12)));
                    _changed1004 = (_changed1004) || (!((_old__min_ay131006) == ((_cursor1003)._min_ay13)));
                    _changed1004 = (_changed1004) || (!((_old__max_ay241007) == ((_cursor1003)._max_ay24)));
                    _changed1004 = (_changed1004) || (!((_old_height1008) == ((_cursor1003)._height10)));
                    _cursor1003 = (_cursor1003)._parent9;
                }
            }
            var _cursor1024 = _parent978;
            var _changed1025 = true;
            while ((_changed1025) && (!((_cursor1024) == (null)))) {
                var _old__min_ax121026 = (_cursor1024)._min_ax12;
                var _old__min_ay131027 = (_cursor1024)._min_ay13;
                var _old__max_ay241028 = (_cursor1024)._max_ay24;
                var _old_height1029 = (_cursor1024)._height10;
                /* _min_ax12 is min of ax1 */
                var _augval1030 = (_cursor1024).ax1;
                var _child1031 = (_cursor1024)._left7;
                if (!((_child1031) == null)) {
                    var _val1032 = (_child1031)._min_ax12;
                    _augval1030 = ((_augval1030) < (_val1032)) ? (_augval1030) : (_val1032);
                }
                var _child1033 = (_cursor1024)._right8;
                if (!((_child1033) == null)) {
                    var _val1034 = (_child1033)._min_ax12;
                    _augval1030 = ((_augval1030) < (_val1034)) ? (_augval1030) : (_val1034);
                }
                (_cursor1024)._min_ax12 = _augval1030;
                /* _min_ay13 is min of ay1 */
                var _augval1035 = (_cursor1024).ay1;
                var _child1036 = (_cursor1024)._left7;
                if (!((_child1036) == null)) {
                    var _val1037 = (_child1036)._min_ay13;
                    _augval1035 = ((_augval1035) < (_val1037)) ? (_augval1035) : (_val1037);
                }
                var _child1038 = (_cursor1024)._right8;
                if (!((_child1038) == null)) {
                    var _val1039 = (_child1038)._min_ay13;
                    _augval1035 = ((_augval1035) < (_val1039)) ? (_augval1035) : (_val1039);
                }
                (_cursor1024)._min_ay13 = _augval1035;
                /* _max_ay24 is max of ay2 */
                var _augval1040 = (_cursor1024).ay2;
                var _child1041 = (_cursor1024)._left7;
                if (!((_child1041) == null)) {
                    var _val1042 = (_child1041)._max_ay24;
                    _augval1040 = ((_augval1040) < (_val1042)) ? (_val1042) : (_augval1040);
                }
                var _child1043 = (_cursor1024)._right8;
                if (!((_child1043) == null)) {
                    var _val1044 = (_child1043)._max_ay24;
                    _augval1040 = ((_augval1040) < (_val1044)) ? (_val1044) : (_augval1040);
                }
                (_cursor1024)._max_ay24 = _augval1040;
                (_cursor1024)._height10 = 1 + ((((((_cursor1024)._left7) == null) ? (-1) : (((_cursor1024)._left7)._height10)) > ((((_cursor1024)._right8) == null) ? (-1) : (((_cursor1024)._right8)._height10))) ? ((((_cursor1024)._left7) == null) ? (-1) : (((_cursor1024)._left7)._height10)) : ((((_cursor1024)._right8) == null) ? (-1) : (((_cursor1024)._right8)._height10)));
                _changed1025 = false;
                _changed1025 = (_changed1025) || (!((_old__min_ax121026) == ((_cursor1024)._min_ax12)));
                _changed1025 = (_changed1025) || (!((_old__min_ay131027) == ((_cursor1024)._min_ay13)));
                _changed1025 = (_changed1025) || (!((_old__max_ay241028) == ((_cursor1024)._max_ay24)));
                _changed1025 = (_changed1025) || (!((_old_height1029) == ((_cursor1024)._height10)));
                _cursor1024 = (_cursor1024)._parent9;
            }
            if (((this)._root1) == (_to_remove977)) {
                (this)._root1 = _new_x981;
            }
            _prev_cursor5 = null;
        }
    };
}
; 
 
 buildViz = function (d3) {
    return function (widthInPixels = 1000,
                     heightInPixels = 600,
                     max_snippets = null,
                     color = null,
                     sortByDist = true,
                     useFullDoc = false,
                     greyZeroScores = false,
                     asianMode = false,
                     nonTextFeaturesMode = false,
                     showCharacteristic = true,
                     wordVecMaxPValue = false,
                     saveSvgButton = false,
                     reverseSortScoresForNotCategory = false,
                     minPVal = 0.1,
                     pValueColors = false,
                     xLabelText = null,
                     yLabelText = null,
                     fullData = null,
                     showTopTerms = true,
                     showNeutral = false,
                     getTooltipContent = null,
                     xAxisValues = null,
                     yAxisValues = null,
                     colorFunc = null,
                     showAxes = true,
                     showExtra = false,
                     doCensorPoints = true,
                     centerLabelsOverPoints = false,
                     xAxisLabels = null,
                     yAxisLabels = null,
                     topic_model_preview_size=10,
                     verticalLines = null,
                     horizontal_line_y_position = null,
                     vertical_line_x_position = null,
                     unifiedContexts = false,
                     showCategoryHeadings = true,
                     showCrossAxes = true,
                     divName = 'd3-div-1',
                     alternativeTermFunc = null) {
        //var divName = 'd3-div-1';
        // Set the dimensions of the canvas / graph
        var padding = {top: 30, right: 20, bottom: 30, left: 50};
        if (!showAxes) {
            padding = {top: 30, right: 20, bottom: 30, left: 50};
        }
        var margin = padding,
            width = widthInPixels - margin.left - margin.right,
            height = heightInPixels - margin.top - margin.bottom;
        fullData.data.forEach(function (x, i) {x.i = i});
        
        // Set the ranges
        var x = d3.scaleLinear().range([0, width]);
        var y = d3.scaleLinear().range([height, 0]);

        if (unifiedContexts) {
            document.querySelectorAll('#'+divName+'-'+'notcol')
                .forEach(function (x) {x.style.display = 'none'});
            document.querySelectorAll('.'+divName+'-'+'contexts')
                .forEach(function (x) {x.style.width = '90%'});
        } 
        else if (showNeutral) {
            if (showExtra) {
                document.querySelectorAll('.'+divName+'-'+'contexts')
                .forEach(function (x) {
                    x.style.width = '25%'
                    x.style.float = 'left'
                });

                ['notcol','neutcol','extracol'].forEach(function (columnName) { 
                    document.querySelectorAll('#'+divName+'-'+columnName)
                        .forEach(function (x) {
                            x.style.display = 'inline'
                            x.style.float = 'left'
                            x.style.width = '25%'
                        });
                })

            } else {
                document.querySelectorAll('.'+divName+'-'+'contexts')
                .forEach(function (x) {
                    x.style.width = '33%'
                    x.style.float = 'left'
                });

                ['notcol','neutcol'].forEach(function (columnName) { 
                    document.querySelectorAll('#'+divName+'-'+columnName)
                        .forEach(function (x) {
                            x.style.display = 'inline'
                            x.style.float = 'left'
                            x.style.width = '33%'
                        });
                })


            }
        } else {
            document.querySelectorAll('.'+divName+'-'+'contexts')
                .forEach(function (x) {
                    x.style.width = '45%'
                    //x.style.display = 'inline'
                    x.style.float = 'left'
                });

            ['notcol'].forEach(function (columnName) { 
                document.querySelectorAll('#'+divName+'-'+columnName)
                    .forEach(function (x) {
                        //x.style.display = 'inline'
                        x.style.float = 'left'
                        x.style.width = '45%'
                    });
            })
        }

        var yAxis = null;
        var xAxis = null;

        function axisLabelerFactory(axis) {
            if ((axis == "x" && xLabelText == null)
                || (axis == "y" && yLabelText == null))
                return function (d, i) {
                    return ["Infrequent", "Average", "Frequent"][i];
                };

            return function (d, i) {
                return ["Low", "Medium", "High"][i];
            }
        }


        function bs(ar, x) {
            function bsa(s, e) {
                var mid = Math.floor((s + e) / 2);
                var midval = ar[mid];
                if (s == e) {
                    return s;
                }
                if (midval == x) {
                    return mid;
                } else if (midval < x) {
                    return bsa(mid + 1, e);
                } else {
                    return bsa(s, mid);
                }
            }

            return bsa(0, ar.length);
        }
        

        console.log("fullData");
        console.log(fullData);

        
        var sortedX = fullData.data.map(x=>x).sort(function (a, b) {
            return a.x < b.x ? -1 : (a.x == b.x ? 0 : 1);
        }).map(function (x) {
            return x.x
        });

        var sortedOx = fullData.data.map(x=>x).sort(function (a, b) {
            return a.ox < b.ox ? -1 : (a.ox == b.ox ? 0 : 1);
        }).map(function (x) {
            return x.ox
        });

        var sortedY = fullData.data.map(x=>x).sort(function (a, b) {
            return a.y < b.y ? -1 : (a.y == b.y ? 0 : 1);
        }).map(function (x) {
            return x.y
        });

        var sortedOy = fullData.data.map(x=>x).sort(function (a, b) {
            return a.oy < b.oy ? -1 : (a.oy == b.oy ? 0 : 1);
        }).map(function (x) {
            return x.oy
        });
        console.log("444");
        console.log(fullData.data[0])


        function labelWithZScore(axis, axisName, tickPoints) {
            var myVals = axisName === 'x' ? sortedOx : sortedOy;
            var myPlotedVals = axisName === 'x' ? sortedX : sortedY;
            var ticks = tickPoints.map(function (x) {
                return myPlotedVals[bs(myVals, x)]
            });
            return axis.tickValues(ticks).tickFormat(
                function (d, i) {
                    return tickPoints[i];
                })
        }

        if (xAxisValues) {
            xAxis = labelWithZScore(d3.axisBottom(x), 'x', xAxisValues);
        } else if (xAxisLabels) {
            xAxis = d3.axisBottom(x)
                .ticks(xAxisLabels.length)
                .tickFormat(function (d, i) {
                    return xAxisLabels[i];
                });
        } else {
            xAxis = d3.axisBottom(x).ticks(3).tickFormat(axisLabelerFactory('x'));
        }
        if (yAxisValues) {
            yAxis = labelWithZScore(d3.axisLeft(y), 'y', yAxisValues);
        } else if (yAxisLabels) {
            yAxis = d3.axisLeft(y)
                .ticks(yAxisLabels.length)
                .tickFormat(function (d, i) {
                    return yAxisLabels[i];
                });
        } else {
            yAxis = d3.axisLeft(y).ticks(3).tickFormat(axisLabelerFactory('y'));
        }

        // var label = d3.select("body").append("div")
        var label = d3.select('#' + divName).append("div")
            .attr("class", "label");

        var interpolateLightGreys = d3.interpolate(d3.rgb(230, 230, 230),
            d3.rgb(130, 130, 130));
        // setup fill color
        if (color == null) {
            color = d3.interpolateRdYlBu;
            //color = d3.interpolateWarm;
        }

        var pixelsToAddToWidth = 200;
        if (!showTopTerms && !showCharacteristic) {
            pixelsToAddToWidth = 0;
        }

        // Adds the svg canvas
        // var svg = d3.select("body")
        svg = d3.select('#' + divName)
            .append("svg")
            .attr("width", width + margin.left + margin.right + pixelsToAddToWidth)
            .attr("height", height + margin.top + margin.bottom)
            .append("g")
            .attr("transform",
                "translate(" + margin.left + "," + margin.top + ")");


        origSVGLeft = svg.node().getBoundingClientRect().left;
        origSVGTop = svg.node().getBoundingClientRect().top;
        var lastCircleSelected = null;

        function getCorpusWordCounts() {
            var binaryLabels = fullData.docs.labels.map(function (label) {
                return 1 * (fullData.docs.categories[label] != fullData.info.category_internal_name);
            });
            var wordCounts = {}; // word -> [cat counts, not-cat-counts]
            var wordCountSums = [0, 0];
            fullData.docs.texts.forEach(function (text, i) {
                text.toLowerCase().trim().split(/\W+/).forEach(function (word) {
                    if (word.trim() !== '') {
                        if (!(word in wordCounts))
                            wordCounts[word] = [0, 0];
                        wordCounts[word][binaryLabels[i]]++;
                        wordCountSums[binaryLabels[i]]++;
                    }
                })
            });
            return {
                avgDocLen: (wordCountSums[0] + wordCountSums[1]) / fullData.docs.texts.length,
                counts: wordCounts,
                sums: wordCountSums,
                uniques: [[0, 0]].concat(Object.keys(wordCounts).map(function (key) {
                    return wordCounts[key];
                })).reduce(function (a, b) {
                    return [a[0] + (b[0] > 0), a[1] + (b[1] > 0)]
                })
            };
        }

        function getContextWordCounts(query) {
            var wordCounts = {};
            var wordCountSums = [0, 0];
            var priorCountSums = [0, 0];
            gatherTermContexts(termDict[query])
                .contexts
                .forEach(function (contextSet, categoryIdx) {
                    contextSet.forEach(function (context) {
                        context.snippets.forEach(function (snippet) {
                            var tokens = snippet.toLowerCase().trim().replace('<b>', '').replace('</b>', '').split(/\W+/);
                            var matchIndices = [];
                            tokens.forEach(function (word, i) {
                                if (word === query) matchIndices.push(i)
                            });
                            tokens.forEach(function (word, i) {
                                if (word.trim() !== '') {
                                    var isValid = false;
                                    for (var matchI in matchIndices) {
                                        if (Math.abs(i - matchI) < 3) {
                                            isValid = true;
                                            break
                                        }
                                    }
                                    if (isValid) {
                                        //console.log([word, i, matchI, isValid]);
                                        if (!(word in wordCounts)) {
                                            var priorCounts = corpusWordCounts.counts[word]
                                            wordCounts[word] = [0, 0].concat(priorCounts);
                                            priorCountSums[0] += priorCounts[0];
                                            priorCountSums[1] += priorCounts[1];
                                        }
                                        wordCounts[word][categoryIdx]++;
                                        wordCountSums[categoryIdx]++;
                                    }
                                }
                            })
                        })
                    })
                });
            return {
                counts: wordCounts,
                priorSums: priorCountSums,
                sums: wordCountSums,
                uniques: [[0, 0]].concat(Object.keys(wordCounts).map(function (key) {
                    return wordCounts[key];
                })).reduce(function (a, b) {
                    return [a[0] + (b[0] > 0), a[1] + (b[1] > 0)];
                })
            }

        }
        
        function denseRank(ar) {
            var markedAr = ar.map((x,i) => [x,i]).sort((a,b) => a[0] - b[0]);
            var curRank = 1
            var rankedAr = markedAr.map(
                function(x, i) {
                    if(i > 0 && x[0] != markedAr[i-1][0]) {
                        curRank++;
                    }
                    return [curRank, x[0], x[1]];
                }
            )
            return rankedAr.map(x=>x).sort((a,b) => (a[2] - b[2])).map(x => x[0]);    
        }
        
        
        function getDenseRanks(fullData, categoryNum) {
            var fgFreqs = Array(fullData.data.length).fill(0);
            var bgFreqs = Array(fullData.data.length).fill(0);
            var categoryTermCounts = fullData.termCounts[categoryNum];
            
            
            Object.keys(categoryTermCounts).forEach(
                key => fgFreqs[key] = categoryTermCounts[key][0]
            )
            fullData.termCounts.forEach( 
                function (categoryTermCounts, otherCategoryNum) {
                    if(otherCategoryNum != categoryNum) {
                        Object.keys(categoryTermCounts).forEach(
                           key => bgFreqs[key] += categoryTermCounts[key][0]
                        )                        
                    }
                }
            )
            var fgDenseRanks = denseRank(fgFreqs);
            var bgDenseRanks = denseRank(bgFreqs);
            
            var maxfgDenseRanks = Math.max(...fgDenseRanks);
            var minfgDenseRanks = Math.min(...fgDenseRanks);
            var scalefgDenseRanks = fgDenseRanks.map(
                x => (x - minfgDenseRanks)/(maxfgDenseRanks - minfgDenseRanks)
            )

            var maxbgDenseRanks = Math.max(...bgDenseRanks);
            var minbgDenseRanks = Math.min(...bgDenseRanks);
            var scalebgDenseRanks = bgDenseRanks.map(
                x => (x - minbgDenseRanks)/(maxbgDenseRanks - minbgDenseRanks)
            )

            return {'fg': scalefgDenseRanks, 'bg': scalebgDenseRanks, 'bgFreqs': bgFreqs, 'fgFreqs': fgFreqs}
        }

        function getCategoryDenseRankScores(fullData, categoryNum) {
            var denseRanks = getDenseRanks(fullData, categoryNum)
            return denseRanks.fg.map((x,i) => x - denseRanks.bg[i]);
        }
        
        function getTermCounts(fullData) {
            var counts = Array(fullData.data.length).fill(0);  
            fullData.termCounts.forEach( 
                function (categoryTermCounts) {
                    Object.keys(categoryTermCounts).forEach(
                       key => counts[key] = categoryTermCounts[key][0]
                    )                        
                }
            )
            return counts;
        }
        
        function getContextWordLORIPs(query) {
            var contextWordCounts = getContextWordCounts(query);
            var ni_k = contextWordCounts.sums[0];
            var nj_k = contextWordCounts.sums[1];
            var n = ni_k + nj_k;
            //var ai_k0 = contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1];
            //var aj_k0 = contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1];
            var a0 = 0.00001 //corpusWordCounts.avgDocLen;
            var a_k0 = Object.keys(contextWordCounts.counts)
                .map(function (x) {
                    var counts = contextWordCounts.counts[x];
                    return a0 * (counts[2] + counts[3]) /
                        (contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1]);
                })
                .reduce(function (a, b) {
                    return a + b
                });
            var ai_k0 = a_k0 / ni_k;
            var aj_k0 = a_k0 / nj_k;
            var scores = Object.keys(contextWordCounts.counts).map(
                function (word) {
                    var countData = contextWordCounts.counts[word];
                    var yi = countData[0];
                    var yj = countData[1];
                    //var ai = countData[2];
                    //var aj = countData[3];
                    //var ai = countData[2] + countData[3];
                    //var aj = ai;
                    //var ai = (countData[2] + countData[3]) * a0/ni_k;
                    //var aj = (countData[2] + countData[3]) * a0/nj_k;
                    var ai = a0 * (countData[2] + countData[3]) /
                        (contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1]);
                    var aj = ai;
                    var deltahat_i_j =
                        +Math.log((yi + ai) * 1. / (ni_k + ai_k0 - yi - ai))
                        - Math.log((yj + aj) * 1. / (nj_k + aj_k0 - yj - aj));
                    var var_deltahat_i_j = 1. / (yi + ai) + 1. / (ni_k + ai_k0 - yi - ai)
                        + 1. / (yj + aj) + 1. / (nj_k + aj_k0 - yj - aj);
                    var zeta_ij = deltahat_i_j / Math.sqrt(var_deltahat_i_j);
                    return [word, yi, yj, ai, aj, ai_k0, zeta_ij];
                }
            ).sort(function (a, b) {
                return b[5] - a[5];
            });
            return scores;
        }

        function getContextWordSFS(query) {
            // from https://stackoverflow.com/questions/14846767/std-normal-cdf-normal-cdf-or-error-function
            function cdf(x, mean, variance) {
                return 0.5 * (1 + erf((x - mean) / (Math.sqrt(2 * variance))));
            }

            function erf(x) {
                // save the sign of x
                var sign = (x >= 0) ? 1 : -1;
                x = Math.abs(x);

                // constants
                var a1 = 0.254829592;
                var a2 = -0.284496736;
                var a3 = 1.421413741;
                var a4 = -1.453152027;
                var a5 = 1.061405429;
                var p = 0.3275911;

                // A&S formula 7.1.26
                var t = 1.0 / (1.0 + p * x);
                var y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);
                return sign * y; // erf(-x) = -erf(x);
            }

            function scale(a) {
                return Math.log(a + 0.0000001);
            }

            var contextWordCounts = getContextWordCounts(query);
            var wordList = Object.keys(contextWordCounts.counts).map(function (word) {
                return contextWordCounts.counts[word].concat([word]);
            });
            var cat_freq_xbar = wordList.map(function (x) {
                return scale(x[0])
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var cat_freq_var = wordList.map(function (x) {
                return Math.pow((scale(x[0]) - cat_freq_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var cat_prec_xbar = wordList.map(function (x) {
                return scale(x[0] / (x[0] + x[1]));
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var cat_prec_var = wordList.map(function (x) {
                return Math.pow((scale(x[0] / (x[0] + x[1])) - cat_prec_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;

            var ncat_freq_xbar = wordList.map(function (x) {
                return scale(x[0])
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var ncat_freq_var = wordList.map(function (x) {
                return Math.pow((scale(x[0]) - ncat_freq_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var ncat_prec_xbar = wordList.map(function (x) {
                return scale(x[0] / (x[0] + x[1]));
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var ncat_prec_var = wordList.map(function (x) {
                return Math.pow((scale(x[0] / (x[0] + x[1])) - ncat_prec_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;

            function scaledFScore(cnt, other, freq_xbar, freq_var, prec_xbar, prec_var) {
                var beta = 1.5;
                var normFreq = cdf(scale(cnt), freq_xbar, freq_var);
                var normPrec = cdf(scale(cnt / (cnt + other)), prec_xbar, prec_var);
                return (1 + Math.pow(beta, 2)) * normFreq * normPrec / (Math.pow(beta, 2) * normFreq + normPrec);
            }

            var sfs = wordList.map(function (x) {
                cat_sfs = scaledFScore(x[0], x[1], cat_freq_xbar,
                    cat_freq_var, cat_prec_xbar, cat_prec_var);
                ncat_sfs = scaledFScore(x[1], x[0], ncat_freq_xbar,
                    ncat_freq_var, ncat_prec_xbar, ncat_prec_var);
                return [cat_sfs > ncat_sfs ? cat_sfs : -ncat_sfs].concat(x);

            }).sort(function (a, b) {
                return b[0] - a[0];
            });
            return sfs;
        }

        function deselectLastCircle() {
            if (lastCircleSelected) {
                lastCircleSelected.style["stroke"] = null;
                lastCircleSelected = null;
            }
        }

        function getSentenceBoundaries(text) {
            // !!! need to use spacy's sentence splitter
            if (asianMode) {
                var sentenceRe = /\n/gmi;
            } else {
                var sentenceRe = /\(?[^\.\?\!\n\b]+[\n\.!\?]\)?/g;
            }
            var offsets = [];
            var match;
            while ((match = sentenceRe.exec(text)) != null) {
                offsets.push(match.index);
            }
            offsets.push(text.length);
            return offsets;
        }

        function getMatchingSnippet(text, boundaries, start, end) {
            var sentenceStart = null;
            var sentenceEnd = null;
            for (var i in boundaries) {
                var position = boundaries[i];
                if (position <= start && (sentenceStart == null || position > sentenceStart)) {
                    sentenceStart = position;
                }
                if (position >= end) {
                    sentenceEnd = position;
                    break;
                }
            }
            var snippet = (text.slice(sentenceStart, start) + "<b>" + text.slice(start, end)
                + "</b>" + text.slice(end, sentenceEnd)).trim();
            if (sentenceStart == null) {
                sentenceStart = 0;
            }
            return {'snippet': snippet, 'sentenceStart': sentenceStart};
        }

        function gatherTermContexts(d) {
            var category_name = fullData['info']['category_name'];
            var not_category_name = fullData['info']['not_category_name'];
            var matches = [[], [], [], []];
            console.log("searching")

            if (fullData.docs === undefined) return matches;
            if (!nonTextFeaturesMode) {
                return searchInText(d);
            } else {
                return searchInExtraFeatures(d);
            }
        }

        function searchInExtraFeatures(d) {
            var matches = [[], [], [], []];
            var term = d.term;
            var categoryNum = fullData.docs.categories.indexOf(fullData.info.category_internal_name);
            var notCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.not_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var neutralCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.neutral_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var extraCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.extra_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });

            var pattern = null;
            if ('metalists' in fullData && term in fullData.metalists) {
                // from https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
                function escapeRegExp(str) {
                    return str.replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
                }

                console.log('term');
                console.log(term);
                pattern = new RegExp(
                    '\\b(' + fullData.metalists[term].map(escapeRegExp).join('|') + ')\\b',
                    'gim'
                );
            }

            for (var i in fullData.docs.extra) {
                if (term in fullData.docs.extra[i]) {
                    var strength = fullData.docs.extra[i][term] /
                        Object.values(fullData.docs.extra[i]).reduce(
                            function (a, b) {
                                return a + b
                            });

                    var docLabel = fullData.docs.labels[i];
                    var numericLabel = -1;
                    if (docLabel == categoryNum) {
                        numericLabel = 0;
                    } else if (notCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 1;
                    } else if (neutralCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 2;
                    } else if (extraCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 3;
                    }
                    if (numericLabel == -1) {
                        continue;
                    }
                    var text = fullData.docs.texts[i];
                    if (!useFullDoc)
                        text = text.slice(0, 300);
                    if (pattern !== null) {
                        text = text.replace(pattern, '<b>$&</b>');
                    }
                    var curMatch = {
                        'id': i,
                        'snippets': [text],
                        'strength': strength,
                        'docLabel': docLabel,
                        'meta': fullData.docs.meta ? fullData.docs.meta[i] : ""
                    }

                    matches[numericLabel].push(curMatch);
                }
            }
            for (var i in [0, 1]) {
                matches[i] = matches[i].sort(function (a, b) {
                    return a.strength < b.strength ? 1 : -1
                })
            }
            return {'contexts': matches, 'info': d};
        }

        // from https://mathiasbynens.be/notes/es-unicode-property-escapes#emoji
        var emojiRE = (/(?:[\u261D\u26F9\u270A-\u270D]|\uD83C[\uDF85\uDFC2-\uDFC4\uDFC7\uDFCA-\uDFCC]|\uD83D[\uDC42\uDC43\uDC46-\uDC50\uDC66-\uDC69\uDC6E\uDC70-\uDC78\uDC7C\uDC81-\uDC83\uDC85-\uDC87\uDCAA\uDD74\uDD75\uDD7A\uDD90\uDD95\uDD96\uDE45-\uDE47\uDE4B-\uDE4F\uDEA3\uDEB4-\uDEB6\uDEC0\uDECC]|\uD83E[\uDD18-\uDD1C\uDD1E\uDD1F\uDD26\uDD30-\uDD39\uDD3D\uDD3E\uDDD1-\uDDDD])(?:\uD83C[\uDFFB-\uDFFF])?|(?:[\u231A\u231B\u23E9-\u23EC\u23F0\u23F3\u25FD\u25FE\u2614\u2615\u2648-\u2653\u267F\u2693\u26A1\u26AA\u26AB\u26BD\u26BE\u26C4\u26C5\u26CE\u26D4\u26EA\u26F2\u26F3\u26F5\u26FA\u26FD\u2705\u270A\u270B\u2728\u274C\u274E\u2753-\u2755\u2757\u2795-\u2797\u27B0\u27BF\u2B1B\u2B1C\u2B50\u2B55]|\uD83C[\uDC04\uDCCF\uDD8E\uDD91-\uDD9A\uDDE6-\uDDFF\uDE01\uDE1A\uDE2F\uDE32-\uDE36\uDE38-\uDE3A\uDE50\uDE51\uDF00-\uDF20\uDF2D-\uDF35\uDF37-\uDF7C\uDF7E-\uDF93\uDFA0-\uDFCA\uDFCF-\uDFD3\uDFE0-\uDFF0\uDFF4\uDFF8-\uDFFF]|\uD83D[\uDC00-\uDC3E\uDC40\uDC42-\uDCFC\uDCFF-\uDD3D\uDD4B-\uDD4E\uDD50-\uDD67\uDD7A\uDD95\uDD96\uDDA4\uDDFB-\uDE4F\uDE80-\uDEC5\uDECC\uDED0-\uDED2\uDEEB\uDEEC\uDEF4-\uDEF8]|\uD83E[\uDD10-\uDD3A\uDD3C-\uDD3E\uDD40-\uDD45\uDD47-\uDD4C\uDD50-\uDD6B\uDD80-\uDD97\uDDC0\uDDD0-\uDDE6])|(?:[#\*0-9\xA9\xAE\u203C\u2049\u2122\u2139\u2194-\u2199\u21A9\u21AA\u231A\u231B\u2328\u23CF\u23E9-\u23F3\u23F8-\u23FA\u24C2\u25AA\u25AB\u25B6\u25C0\u25FB-\u25FE\u2600-\u2604\u260E\u2611\u2614\u2615\u2618\u261D\u2620\u2622\u2623\u2626\u262A\u262E\u262F\u2638-\u263A\u2640\u2642\u2648-\u2653\u2660\u2663\u2665\u2666\u2668\u267B\u267F\u2692-\u2697\u2699\u269B\u269C\u26A0\u26A1\u26AA\u26AB\u26B0\u26B1\u26BD\u26BE\u26C4\u26C5\u26C8\u26CE\u26CF\u26D1\u26D3\u26D4\u26E9\u26EA\u26F0-\u26F5\u26F7-\u26FA\u26FD\u2702\u2705\u2708-\u270D\u270F\u2712\u2714\u2716\u271D\u2721\u2728\u2733\u2734\u2744\u2747\u274C\u274E\u2753-\u2755\u2757\u2763\u2764\u2795-\u2797\u27A1\u27B0\u27BF\u2934\u2935\u2B05-\u2B07\u2B1B\u2B1C\u2B50\u2B55\u3030\u303D\u3297\u3299]|\uD83C[\uDC04\uDCCF\uDD70\uDD71\uDD7E\uDD7F\uDD8E\uDD91-\uDD9A\uDDE6-\uDDFF\uDE01\uDE02\uDE1A\uDE2F\uDE32-\uDE3A\uDE50\uDE51\uDF00-\uDF21\uDF24-\uDF93\uDF96\uDF97\uDF99-\uDF9B\uDF9E-\uDFF0\uDFF3-\uDFF5\uDFF7-\uDFFF]|\uD83D[\uDC00-\uDCFD\uDCFF-\uDD3D\uDD49-\uDD4E\uDD50-\uDD67\uDD6F\uDD70\uDD73-\uDD7A\uDD87\uDD8A-\uDD8D\uDD90\uDD95\uDD96\uDDA4\uDDA5\uDDA8\uDDB1\uDDB2\uDDBC\uDDC2-\uDDC4\uDDD1-\uDDD3\uDDDC-\uDDDE\uDDE1\uDDE3\uDDE8\uDDEF\uDDF3\uDDFA-\uDE4F\uDE80-\uDEC5\uDECB-\uDED2\uDEE0-\uDEE5\uDEE9\uDEEB\uDEEC\uDEF0\uDEF3-\uDEF8]|\uD83E[\uDD10-\uDD3A\uDD3C-\uDD3E\uDD40-\uDD45\uDD47-\uDD4C\uDD50-\uDD6B\uDD80-\uDD97\uDDC0\uDDD0-\uDDE6])\uFE0F/g);

        function isEmoji(str) {
            if (str.match(emojiRE)) return true;
            return false;
        }

        function displayObscuredTerms(obscuredTerms, data, term, termInfo, div='#'+divName+'-'+'overlapped-terms') {
            d3.select('#'+divName+'-'+'overlapped-terms')
                .selectAll('div')
                .remove();
            d3.select(div)
                .selectAll('div')
                .remove();
            if (obscuredTerms.length > 1) {
                var obscuredDiv = d3.select(div)
                    .append('div')
                    .attr("class", "obscured")
                    .style('align', 'center')
                    .style('text-align', 'center')
                    .html("<b>\"" + term + "\" obstructs</b>: ");
                obscuredTerms.map(
                    function (term, i) {
                        makeWordInteractive(
                            data,
                            svg,
                            obscuredDiv.append("text").text(term),
                            term,
                            data.filter(t=>t.term == term)[0],//termInfo
                            false
                        );
                        if (i < obscuredTerms.length - 1) {
                            obscuredDiv.append("text").text(", ");
                        }
                    }
                )
            }
        }

        function displayTermContexts(data, termInfo, jump=true) {
            var contexts = termInfo.contexts;
            var info = termInfo.info;
            if (contexts[0].length + contexts[1].length + contexts[2].length + contexts[3].length == 0) {
                return null;
            }
            //!!! Future feature: context words
            //var contextWords = getContextWordSFS(info.term);
            //var contextWords = getContextWordLORIPs(info.term);
            //var categoryNames = [fullData.info.category_name,
            //    fullData.info.not_category_name];
            var catInternalName = fullData.info.category_internal_name;


            function addSnippets(contexts, divId) {
                var meta = contexts.meta ? contexts.meta : '&nbsp;';
                d3.select(divId)
                    .append("div")
                    .attr('class', 'snippet_meta docLabel' + contexts.docLabel)
                    .html(meta);
                contexts.snippets.forEach(function (snippet) {
                    d3.select(divId)
                        .append("div")
                        .attr('class', 'snippet docLabel' + contexts.docLabel)
                        .html(snippet);
                })
            }
            if (unifiedContexts) {
               divId = '#'+divName+'-'+'cat';
                var docLabelCounts = fullData.docs.labels.reduce(
                    function(map, label) {map[label] = (map[label]||0)+1; return map;},
                    Object.create(null)
                );
               var numMatches = Object.create(null);
               var temp = d3.select(divId).selectAll("div").remove();
               var allContexts = contexts[0].concat(contexts[1]).concat(contexts[2]).concat(contexts[3]);
                allContexts.forEach(function (singleDoc) {
                    numMatches[singleDoc.docLabel] = (numMatches[singleDoc.docLabel]||0) + 1;
                });

               /*contexts.forEach(function(context) {
                    context.forEach(function (singleDoc) {
                        numMatches[singleDoc.docLabel] = (numMatches[singleDoc.docLabel]||0) + 1;
                        addSnippets(singleDoc, divId);
                    });
                });*/
                var docLabelCountsSorted = Object.keys(docLabelCounts).map(key => (
                    {"label": fullData.docs.categories[key],
                     "labelNum": key,
                     "matches": numMatches[key]||0,
                     "overall": docLabelCounts[key],
                     'percent': (numMatches[key]||0)*100./docLabelCounts[key]}))
                    .sort(function(a,b) {return b.percent-a.percent});
                console.log("docLabelCountsSorted")
                console.log(docLabelCountsSorted);
                console.log(numMatches)
                d3.select('#'+divName+'-'+'categoryinfo').selectAll("div").remove();
                if(showCategoryHeadings) {
                    d3.select('#'+divName+'-'+'categoryinfo').attr('display', 'inline')
                }
                function getCategoryStatsHTML(counts) {
                    return counts.matches + " document"
                        + (counts.matches == 1 ? "" : "s") + " out of " + counts.overall +': '
                        +counts['percent'].toFixed(2) + '%';
                }
                
                function getCategoryInlineHeadingHTML(counts) {
                    return '<a name="'+divName+'-category'
                        + counts.labelNum + '"></a>' 
                        + counts.label + ": <span class=topic_preview>"
                        + getCategoryStatsHTML(counts)
                        + "</span>";
                }

                docLabelCountsSorted.forEach(function(counts) {
                    var htmlToAdd = "<b>"+counts.label + "</b>: " +  getCategoryStatsHTML(counts);
                    console.log(htmlToAdd);
                    if(showCategoryHeadings) {
                        d3.select('#'+divName+'-'+'categoryinfo')
                            .attr('display', 'inline')
                            .append('div')
                            .html(htmlToAdd)
                            .on("click", function() {window.location.hash = '#'+divName+'-'+'category' + counts.labelNum});
                    }
                    if(counts.matches > 0) {
                        d3.select(divId)
                            .append("div")
                            .attr('class', 'text_header')
                            .html(getCategoryInlineHeadingHTML(counts));
                        allContexts
                            .filter(singleDoc => singleDoc.docLabel == counts.labelNum)
                            .forEach(function (singleDoc) {
                                addSnippets(singleDoc, divId);
                            });
                    }
                })

            
            } else {
                var contextColumns = [
                    fullData.info.category_internal_name,
                    fullData.info.not_category_name
                ];
                if (showNeutral) {
                    if ('neutral_category_name' in fullData.info) {
                        contextColumns.push(fullData.info.neutral_category_name)
                    } else {
                        contextColumns.push("Neutral")
                    }
                    if (showExtra) {
                        if ('extra_category_name' in fullData.info) {
                            contextColumns.push(fullData.info.extra_category_name)
                        } else {
                            contextColumns.push("Extra")
                        }
                    }

                }
                contextColumns.map(
                    function (catName, catIndex) {
                        if (max_snippets != null) {
                            var contextsToDisplay = contexts[catIndex].slice(0, max_snippets);
                        }
                        console.log("CATCAT")
                        console.log(catName, catIndex)
                        //var divId = catName == catInternalName ? '#cat' : '#notcat';
                        var divId = null
                        if (catName == fullData.info.category_internal_name) {
                            divId = '#'+divName+'-'+'cat'
                        } else if (fullData.info.not_category_name == catName) {
                            divId = '#'+divName+'-'+'notcat'
                        } else if (fullData.info.neutral_category_name == catName) {
                            divId = '#'+divName+'-'+'neut';
                        } else if (fullData.info.extra_category_name == catName) {
                            divId = '#'+divName+'-'+'extra'
                        } else {
                            return;
                        }
                        console.log('divid');
                        console.log(divId)

                        var temp = d3.select(divId).selectAll("div").remove();
                        contexts[catIndex].forEach(function (context) {
                            addSnippets(context, divId);
                        });
                    }
                );
            }

            var obscuredTerms = getObscuredTerms(data, termInfo.info);
            displayObscuredTerms(obscuredTerms, data, info.term, info, '#'+divName+'-'+'overlapped-terms-clicked');

            d3.select('#'+divName+'-'+'termstats')
                .selectAll("div")
                .remove();
            var termHtml = 'Term: <b>' + info.term + '</b>';
            if ('metalists' in fullData && info.term in fullData.metalists) {
                termHtml = 'Topic: <b>' + info.term + '</b>';
            }
            d3.select('#'+divName+'-'+'termstats')
                .append('div')
                .attr("class", "snippet_header")
                .html(termHtml);
            if ('metalists' in fullData && info.term in fullData.metalists) {
                d3.select('#'+divName+'-'+'termstats')
                    .attr("class", "topic_preview")
                    .append('div')
                    .html("<b>Topic preview</b>: "
                        + fullData.metalists[info.term]
                            .slice(0, topic_model_preview_size)
                            .reduce(function (x, y) {
                                return x + ', ' + y
                            }));
            }
            if ('metadescriptions' in fullData && info.term in fullData.metadescriptions) {
                d3.select('#'+divName+'-'+'termstats')
                    .attr("class", "topic_preview")
                    .append('div')
                    .html("<b>Description</b>: " + fullData.metadescriptions[info.term]);
            }
            var message = '';
            var cat_name = fullData.info.category_name;
            var ncat_name = fullData.info.not_category_name;


            var numCatDocs = fullData.docs.labels
                .map(function (x) {
                    return (x == fullData.docs.categories.indexOf(
                        fullData.info.category_internal_name)) + 0
                })
                .reduce(function (a, b) {
                    return a + b;
                })

            var notCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.not_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });


            var numNCatDocs = fullData.docs.labels
                .map(function (x) {
                    return notCategoryNumList.indexOf(x) > -1
                })
                .reduce(function (a, b) {
                    return a + b;
                });

            function getFrequencyDescription(name, count25k, count, ndocs) {
                var desc = name + ' frequency: <div class=text_subhead>' + count25k
                    + ' per 25,000 terms</div><div class=text_subhead>' + Math.round(ndocs)
                    + ' per 1,000 docs</div>';
                if (count == 0) {
                    desc += '<u>Not found in any ' + name + ' documents.</u>';
                } else {
                    desc += '<u>Some of the ' + count + ' mentions:</u>';
                }
                /*
                desc += '<br><b>Discriminative:</b> ';

                desc += contextWords
                    .slice(cat_name === name ? 0 : contextWords.length - 3,
                        cat_name === name ? 3 : contextWords.length)
                    .filter(function (x) {
                        //return Math.abs(x[5]) > 1.96;
                        return true;
                    })
                    .map(function (x) {return x.join(', ')}).join('<br>');
                */
                return desc;
            }

            if (!unifiedContexts) {
                console.log("NOT UNIFIED CONTEXTS")
                d3.select('#'+divName+'-'+'cathead')
                    .style('fill', color(1))
                    .html(
                        getFrequencyDescription(cat_name,
                            info.cat25k,
                            info.cat,
                            termInfo.contexts[0].length * 1000 / numCatDocs
                        )
                    );
                d3.select('#'+divName+'-'+'notcathead')
                    .style('fill', color(0))
                    .html(
                        getFrequencyDescription(ncat_name,
                            info.ncat25k,
                            info.ncat,
                            termInfo.contexts[1].length * 1000 / numNCatDocs)
                    );
                console.log("TermINfo")
                console.log(termInfo);
                console.log(info)
                if (showNeutral) {
                    console.log("NEUTRAL")

                    var numList = fullData.docs.categories.map(function (x, i) {
                        if (fullData.info.neutral_category_internal_names.indexOf(x) > -1) {
                            return i;
                        } else {
                            return -1;
                        }
                    }).filter(function (x) {
                        return x > -1
                    });

                    var numDocs = fullData.docs.labels
                        .map(function (x) {
                            return numList.indexOf(x) > -1
                        })
                        .reduce(function (a, b) {
                            return a + b;
                        });

                    d3.select("#" + divName + "-neuthead")
                        .style('fill', color(0))
                        .html(
                            getFrequencyDescription(fullData.info.neutral_category_name,
                                info.neut25k,
                                info.neut,
                                termInfo.contexts[2].length * 1000 / numDocs)
                        );

                    if (showExtra) {
                        console.log("EXTRA")
                        var numList = fullData.docs.categories.map(function (x, i) {
                            if (fullData.info.extra_category_internal_names.indexOf(x) > -1) {
                                return i;
                            } else {
                                return -1;
                            }
                        }).filter(function (x) {
                            return x > -1
                        });

                        var numDocs = fullData.docs.labels
                            .map(function (x) {
                                return numList.indexOf(x) > -1
                            })
                            .reduce(function (a, b) {
                                return a + b;
                            });

                        d3.select("#" + divName + "-extrahead")
                            .style('fill', color(0))
                            .html(
                                getFrequencyDescription(fullData.info.extra_category_name,
                                    info.extra25k,
                                    info.extra,
                                    termInfo.contexts[3].length * 1000 / numDocs)
                            );

                    }
                }
            } else {
                // extra unified context code goes here
            }
            if (jump) {
                if (window.location.hash == '#'+divName+'-'+'snippets') {
                    window.location.hash = '#'+divName+'-'+'snippetsalt';
                } else {
                    window.location.hash = '#'+divName+'-'+'snippets';
                }
            }
        }

        function searchInText(d) {
            function stripNonWordChars(term) {
                //d.term.replace(" ", "[^\\w]+")
            }

            function removeUnderScoreJoin(term) {
                /*
                '_ _asjdklf_jaksdlf_jaksdfl skld_Jjskld asdfjkl_sjkdlf'
                  ->
                "_ _asjdklf jaksdlf jaksdfl skld Jjskld asdfjkl_sjkdlf"
                 */
                return term.replace(/(\w+)(_)(\w+)/, "$1 $3")
                    .replace(/(\w+)(_)(\w+)/, "$1 $3")
                    .replace(/(\w+)(_)(\w+)/, "$1 $3");
            }

            function buildMatcher(term) {

                var boundary = '\\b';
                var wordSep = "[^\\w]+";
                if (asianMode) {
                    boundary = '( |$|^)';
                    wordSep = ' ';
                }
                if (isEmoji(term)) {
                    boundary = '';
                    wordSep = '';
                }
                var termToRegex = term;
                ['[', ']', '(', ')', '{', '}', '^', '$', '.', '|', '?', "'", '"',
                    '*', '+', '-', '=', '~', '`', '{', '#'].forEach(function (a) {
                    termToRegex = termToRegex.replace(a, '\\\\' + a)
                });
                var regexp = new RegExp(boundary + '('
                    + removeUnderScoreJoin(
                        termToRegex.replace(' ', wordSep, 'gim')
                    )
                    + ')' + boundary, 'gim');
                try {
                    regexp.exec('X');
                } catch (err) {
                    console.log("Can't search " + term);
                    console.log(err);
                    return null;
                }
                return regexp;
            }

            var matches = [[], [], [], []];
            var pattern = buildMatcher(d.term);
            var categoryNum = fullData.docs.categories.indexOf(fullData.info.category_internal_name);
            var notCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.not_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var neutralCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.neutral_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var extraCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.extra_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            console.log('extraCategoryNumList')
            console.log(extraCategoryNumList);
            console.log("categoryNum");
            console.log(categoryNum);
            console.log("categoryNum");
            if (pattern !== null) {
                for (var i in fullData.docs.texts) {
                    //var numericLabel = 1 * (fullData.docs.categories[fullData.docs.labels[i]] != fullData.info.category_internal_name);

                    var docLabel = fullData.docs.labels[i];
                    var numericLabel = -1;
                    if (docLabel == categoryNum) {
                        numericLabel = 0;
                    } else if (notCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 1;
                    } else if (neutralCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 2;
                    } else if (extraCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 3;
                    }
                    if (numericLabel == -1) {
                        continue;
                    }

                    var text = removeUnderScoreJoin(fullData.docs.texts[i]);
                    //var pattern = new RegExp("\\b(" + stripNonWordChars(d.term) + ")\\b", "gim");
                    var match;
                    var sentenceOffsets = null;
                    var lastSentenceStart = null;
                    var matchFound = false;
                    var curMatch = {'id': i, 'snippets': [], 'docLabel': docLabel};
                    if (fullData.docs.meta) {
                        curMatch['meta'] = fullData.docs.meta[i];
                    }
                    while ((match = pattern.exec(text)) != null) {
                        if (sentenceOffsets == null) {
                            sentenceOffsets = getSentenceBoundaries(text);
                        }
                        var foundSnippet = getMatchingSnippet(text, sentenceOffsets,
                            match.index, pattern.lastIndex);
                        if (foundSnippet.sentenceStart == lastSentenceStart) continue; // ensure we don't duplicate sentences
                        lastSentenceStart = foundSnippet.sentenceStart;
                        curMatch.snippets.push(foundSnippet.snippet);
                        matchFound = true;
                    }
                    if (matchFound) {
                        if (useFullDoc) {
                            curMatch.snippets = [
                                text
                                    .replace(/\n$/g, '\n\n')
                                    .replace(
                                        //new RegExp("\\b(" + d.term.replace(" ", "[^\\w]+") + ")\\b",
                                        //    'gim'),
                                        pattern,
                                        '<b>$&</b>')
                            ];
                        }
                        matches[numericLabel].push(curMatch);
                    }
                }
            }
            var toRet = {'contexts': matches, 'info': d, 'docLabel': docLabel};
            return toRet;
        }

        function getDefaultTooltipContent(d) {
            var message = d.term + "<br/>" + d.cat25k + ":" + d.ncat25k + " per 25k words";
            message += '<br/>score: ' + d.os.toFixed(5);
            return message;
        }

        function getDefaultTooltipContentWithoutScore(d) {
            var message = d.term + "<br/>" + d.cat25k + ":" + d.ncat25k + " per 25k words";
            return message;
        }

        function getObscuredTerms(data, d) {
            //data = fullData['data']
            var matches = (data.filter(function (term) {
                    return term.x === d.x && term.y === d.y && (term.display === undefined || term.display === true);
                }).map(function (term) {
                    return term.term
                }).sort()
            );
            return matches;
        }

        function showTooltip(data, d, pageX, pageY, showObscured=true) {
            deselectLastCircle();

            var obscuredTerms = getObscuredTerms(data, d);
            var message = '';
            console.log("!!!!! " + obscuredTerms.length)
            console.log(showObscured)
            if (obscuredTerms.length > 1 && showObscured)
                displayObscuredTerms(obscuredTerms, data, d.term, d);
            if (getTooltipContent !== null) {
                message += getTooltipContent(d);
            } else {
                if (sortByDist) {
                    message += getDefaultTooltipContentWithoutScore(d);
                } else {
                    message += getDefaultTooltipContent(d);
                }
            }
            pageX -= (svg.node().getBoundingClientRect().left) - origSVGLeft;
            pageY -= (svg.node().getBoundingClientRect().top) - origSVGTop;
            tooltip.transition()
                .duration(0)
                .style("opacity", 1)
                .style("z-index", 10000000);
            tooltip.html(message)
                .style("left", (pageX - 40) + "px")
                .style("top", (pageY - 85 > 0 ? pageY - 85 : 0) + "px");
            tooltip.on('click', function () {
                tooltip.transition()
                    .style('opacity', 0)
            }).on('mouseout', function () {
                tooltip.transition().style('opacity', 0)
            });
        }

        handleSearch = function (event) {
            deselectLastCircle();
            var searchTerm = document
                .getElementById(this.divName + "-searchTerm")
                .value
                .toLowerCase()
                .replace("'", " '")
                .trim();
            if(this.termDict[searchTerm] !== undefined) {
                showToolTipForTerm(this.data, this.svg, searchTerm, this.termDict[searchTerm], true);
            }
            if (this.termDict[searchTerm] != null) {
                var runDisplayTermContexts = true;
                if(alternativeTermFunc != null) {
                    runDisplayTermContexts = this.alternativeTermFunc(this.termDict[searchTerm]);
                }
                if(runDisplayTermContexts) {
                    displayTermContexts(this.data, this.gatherTermContexts(this.termDict[searchTerm]), false);
                }
            }
            return false;
        };

        function showToolTipForTerm(data, mysvg, searchTerm, searchTermInfo, showObscured=true) {
            //var searchTermInfo = termDict[searchTerm];
            console.log("showing tool tip")
            console.log(searchTerm)
            console.log(searchTermInfo)
            if (searchTermInfo === undefined) {
                console.log("can't show")
                d3.select("#" + divName + "-alertMessage")
                    .text(searchTerm + " didn't make it into the visualization.");
            } else {
                d3.select("#" + divName + "-alertMessage").text("");
                var circle = mysvg; 
                console.log("mysvg"); console.log(mysvg)
                if(circle.tagName !== "circle") { // need to clean this thing up
                    circle = mysvg._groups[0][searchTermInfo.ci];
                    if(circle === undefined || circle.tagName != 'circle') {
                        console.log("circle0")
                        if(mysvg._groups[0].children !== undefined) {
                            circle = mysvg._groups[0].children[searchTermInfo.ci];
                        }
                    }
                    if(circle === undefined || circle.tagName != 'circle') {
                        console.log("circle1"); 
                        if(mysvg._groups[0][0].children !== undefined) {
                            circle = Array.prototype.filter.call(
                                mysvg._groups[0][0].children, 
                                x=> (x.tagName == "circle" && x.__data__['term'] == searchTermInfo.term)
                            )[0];
                        }
                        console.log(circle)
                    }
                    if((circle === undefined || circle.tagName != 'circle') && mysvg._groups[0][0].children !== undefined) {
                        console.log("circle2"); 
                        console.log(mysvg._groups[0][0])
                        console.log(mysvg._groups[0][0].children)
                        console.log(searchTermInfo.ci);
                        circle = mysvg._groups[0][0].children[searchTermInfo.ci];
                        console.log(circle)
                    }
                }
                if(circle) {
                    var mySVGMatrix = circle.getScreenCTM().translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                    var pageX = mySVGMatrix.e;
                    var pageY = mySVGMatrix.f;
                    circle.style["stroke"] = "black";
                    //var circlePos = circle.position();
                    //var el = circle.node()
                    //showTooltip(searchTermInfo, pageX, pageY, circle.cx.baseVal.value, circle.cx.baseVal.value);
                    showTooltip(
                        data,
                        searchTermInfo,
                        pageX,
                        pageY,
                        showObscured
                    );

                    lastCircleSelected = circle;
                }

            }
        };


        function makeWordInteractive(data, svg, domObj, term, termInfo, showObscured=true) {
            return domObj
                .on("mouseover", function (d) {
                    console.log("mouseover" )
                    console.log(term)
                    console.log(termInfo)
                    showToolTipForTerm(data, svg, term, termInfo, showObscured);
                    d3.select(this).style("stroke", "black");
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                    if (showObscured) {
                        d3.select('#'+divName+'-'+'overlapped-terms')
                            .selectAll('div')
                            .remove();
                    }
                })
                .on("click", function (d) {
                    var runDisplayTermContexts = true;
                    if(alternativeTermFunc != null) {
                        runDisplayTermContexts = alternativeTermFunc(termInfo);
                    }
                    if(runDisplayTermContexts) {
                        displayTermContexts(data, gatherTermContexts(termInfo));
                    }
                });
        }

        function processData(fullData) {
            
            modelInfo = fullData['info'];
            /*
             categoryTermList.data(modelInfo['category_terms'])
             .enter()
             .append("li")
             .text(function(d) {return d;});
             */
            var data = fullData['data'];
            termDict = Object();
            data.forEach(function (x, i) {
                termDict[x.term] = x;
                //!!!
                //termDict[x.term].i = i;
            });

            var padding = 0;
            if (showAxes) {
                padding = 0.1;
            }

            // Scale the range of the data.  Add some space on either end.
            x.domain([-1 * padding, d3.max(data, function (d) {
                return d.x;
            }) + padding]);
            y.domain([-1 * padding, d3.max(data, function (d) {
                return d.y;
            }) + padding]);

            /*
             data.sort(function (a, b) {
             return Math.abs(b.os) - Math.abs(a.os)
             });
             */


            //var rangeTree = null; // keep boxes of all points and labels here
            var rectHolder = new RectangleHolder();
            // Add the scatterplot
            data.forEach(function(d,i) {d.ci = i});
            //console.log('XXXXX'); console.log(data)
            var mysvg = svg
                .selectAll("dot")
                .data(data.filter(d=>d.display === undefined || d.display === true))
                //.filter(function (d) {return d.display === undefined || d.display === true})
                .enter()
                .append("circle")
                .attr("r", function (d) {
                    if (pValueColors && d.p) {
                        return (d.p >= 1 - minPVal || d.p <= minPVal) ? 2 : 1.75;
                    }
                    return 2;
                })
                .attr("cx", function (d) {
                    return x(d.x);
                })
                .attr("cy", function (d) {
                    return y(d.y);
                })
                .style("fill", function (d) {
                    //.attr("fill", function (d) {
                    if (colorFunc) {
                        return colorFunc(d);
                    } else if (greyZeroScores && d.os == 0) {
                        return d3.rgb(230, 230, 230);
                    } else if (pValueColors && d.p) {
                        if (d.p >= 1 - minPVal) {
                            return wordVecMaxPValue ? d3.interpolateYlGnBu(d.s) : color(d.s);
                        } else if (d.p <= minPVal) {
                            return wordVecMaxPValue ? d3.interpolateYlGnBu(d.s) : color(d.s);
                        } else {
                            return interpolateLightGreys(d.s);
                        }
                    } else {
                        if(d.term == "psychological") {
                            console.log("COLS " + d.s + " " + color(d.s) + " " + d.term)
                            console.log(d)
                            console.log(color)
                        }
                        return color(d.s);
                    }
                })
                .on("mouseover", function (d) {
                    /*var mySVGMatrix = circle.getScreenCTM()n
                        .translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                    var pageX = mySVGMatrix.e;
                    var pageY = mySVGMatrix.f;*/

                    /*showTooltip(
                        d,
                        d3.event.pageX,
                        d3.event.pageY
                    );*/
                    console.log("point MOUSOEVER")
                    console.log(d)
                    showToolTipForTerm(data, this, d.term, d, true);
                    d3.select(this).style("stroke", "black");
                })
                .on("click", function (d) {
                    var runDisplayTermContexts = true;
                    if(alternativeTermFunc != null) {
                        runDisplayTermContexts = alternativeTermFunc(d);
                    }
                    if(runDisplayTermContexts) {
                        displayTermContexts(data, gatherTermContexts(d));
                    }
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                    d3.select('#'+divName+'-'+'overlapped-terms')
                        .selectAll('div')
                        .remove();
                })
            
            
            coords = Object();

            var pointStore = [];
            var pointRects = [];

            function censorPoints(datum, getX, getY) {
                var term = datum.term;
                var curLabel = svg.append("text")
                    .attr("x", x(getX(datum)))
                    .attr("y", y(getY(datum)) + 3)
                    .attr("text-anchor", "middle")
                    .text("x");
                var bbox = curLabel.node().getBBox();
                var borderToRemove = .5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                //rangeTree = insertRangeTree(rangeTree, x1, y1, x2, y2, '~~' + term);
                var pointRect = new Rectangle(x1, y1, x2, y2);
                pointRects.push(pointRect);
                rectHolder.add(pointRect);
                pointStore.push([x1, y1]);
                pointStore.push([x2, y1]);
                pointStore.push([x1, y2]);
                pointStore.push([x2, y2]);
                curLabel.remove();
            }
            
            function censorCircle(xCoord, yCoord) {
                var curLabel = svg.append("text")
                    .attr("x", x(xCoord))
                    .attr("y", y(yCoord) + 3)
                    .attr("text-anchor", "middle")
                    .text("x");
                var bbox = curLabel.node().getBBox();
                var borderToRemove = .5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                var pointRect = new Rectangle(x1, y1, x2, y2);
                pointRects.push(pointRect);
                rectHolder.add(pointRect);
                pointStore.push([x1, y1]);
                pointStore.push([x2, y1]);
                pointStore.push([x1, y2]);
                pointStore.push([x2, y2]);
                curLabel.remove();
            }

            function labelPointsIfPossible(datum, myX, myY) {
                var term = datum.term;
                if(term == "the") 
                    console.log("TERM " + term + " " + myX + " " + myY)
                //console.log('xxx'); console.log(term); console.log(term.display !== undefined && term.display === false)
                //if(term.display !== undefined && term.display === false) {
                //    return false;
                //}
                var configs = [
                    {'anchor': 'end', 'xoff': -5, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'end', 'xoff': -5, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                    
                    {'anchor': 'end', 'xoff': 10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'end', 'xoff': -10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'end', 'xoff': 10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'end', 'xoff': -10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                    
                    {'anchor': 'start', 'xoff': 3, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 3, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 5, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 5, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': -10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': 10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                    {'anchor': 'start', 'xoff': -10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                ];
                if (centerLabelsOverPoints) {
                    configs = [{'anchor': 'middle', 'xoff': 0, 'yoff': 0, 'alignment-baseline': 'middle'}];
                }
                var matchedElement = null;
                for (var configI in configs) {
                    var config = configs[configI];
                    var curLabel = svg.append("text")
                    //.attr("x", x(data[i].x) + config['xoff'])
                    //.attr("y", y(data[i].y) + config['yoff'])
                        .attr("x", x(myX) + config['xoff'])
                        .attr("y", y(myY) + config['yoff'])
                        .attr('class', 'label')
                        .attr('class', 'pointlabel')
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px')
                        .attr("text-anchor", config['anchor'])
                        .attr("alignment-baseline", config['alignment'])
                        .text(term);
                    var bbox = curLabel.node().getBBox();
                    var borderToRemove = .25;
                    if (doCensorPoints) {
                        var borderToRemove = .5;
                    }

                    var x1 = bbox.x + borderToRemove,
                        y1 = bbox.y + borderToRemove,
                        x2 = bbox.x + bbox.width - borderToRemove,
                        y2 = bbox.y + bbox.height - borderToRemove;
                    //matchedElement = searchRangeTree(rangeTree, x1, y1, x2, y2);
                    var matchedElement = false;
                    rectHolder.findMatchingRectangles(x1, y1, x2, y2, function (elem) {
                        matchedElement = true;
                        return false;
                    });
                    if (matchedElement) {
                        curLabel.remove();
                    } else {
                        curLabel = makeWordInteractive(data, svg, curLabel, term, datum);
                        break;
                    }
                }

                if (!matchedElement) {
                    coords[term] = [x1, y1, x2, y2];
                    //rangeTree = insertRangeTree(rangeTree, x1, y1, x2, y2, term);
                    var labelRect = new Rectangle(x1, y1, x2, y2)
                    rectHolder.add(labelRect);
                    pointStore.push([x1, y1]);
                    pointStore.push([x2, y1]);
                    pointStore.push([x1, y2]);
                    pointStore.push([x2, y2]);
                    return {label: curLabel, rect: labelRect};
                } else {
                    //curLabel.remove();
                    return false;
                }

            }

            var radius = 2;

            function euclideanDistanceSort(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                return (Math.min(aCatDist, aNotCatDist) > Math.min(bCatDist, bNotCatDist)) * 2 - 1;
            }

            function euclideanDistanceSortForCategory(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                return (aCatDist > bCatDist) * 2 - 1;
            }

            function euclideanDistanceSortForNotCategory(a, b) {
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                return (aNotCatDist > bNotCatDist) * 2 - 1;
            }

            function scoreSort(a, b) {
                return a.s - b.s;
            }

            function scoreSortReverse(a, b) {
                return b.s - a.s;
            }

            function backgroundScoreSort(a, b) {
                if (b.bg === a.bg)
                    return (b.cat + b.ncat) - (a.cat + a.ncat);
                return b.bg - a.bg;
            }

            function arePointsPredictiveOfDifferentCategories(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                var aGood = aCatDist < aNotCatDist;
                var bGood = bCatDist < bNotCatDist;
                return {aGood: aGood, bGood: bGood};
            }

            function scoreSortForCategory(a, b) {
                var __ret = arePointsPredictiveOfDifferentCategories(a, b);
                if (sortByDist) {
                    var aGood = __ret.aGood;
                    var bGood = __ret.bGood;
                    if (aGood && !bGood) return -1;
                    if (!aGood && bGood) return 1;
                }
                return b.s - a.s;
            }

            function scoreSortForNotCategory(a, b) {
                var __ret = arePointsPredictiveOfDifferentCategories(a, b);
                if (sortByDist) {
                    var aGood = __ret.aGood;
                    var bGood = __ret.bGood;
                    if (aGood && !bGood) return 1;
                    if (!aGood && bGood) return -1;
                }
                if (reverseSortScoresForNotCategory)
                    return a.s - b.s;
                else
                    return b.s - a.s;
            }

            var sortedData = data.map(x=>x).sort(sortByDist ? euclideanDistanceSort : scoreSort);
            if (doCensorPoints) {
                for (var i in data) {
                    var d = sortedData[i];
                    censorPoints(
                        d,
                        function (d) {
                            return d.x
                        },
                        function (d) {
                            return d.y
                        }
                    );
                }
            }


            function registerFigureBBox(curLabel) {
                var bbox = curLabel.node().getBBox();
                var borderToRemove = 1.5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                rectHolder.add(new Rectangle(x1, y1, x2, y2));
                //return insertRangeTree(rangeTree, x1, y1, x2, y2, '~~_other_');
            }
            function drawXLabel(svg, labelText) {
                    return svg.append("text")
                    .attr("class", "x label")
                    .attr("text-anchor", "end")
                    .attr("x", width)
                    .attr("y", height - 6)
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr('font-size', '10px')
                    .text(labelText);
            }
            function drawYLabel(svg, labelText) {
                    return svg.append("text")
                        .attr("class", "y label")
                        .attr("text-anchor", "end")
                        .attr("y", 6)
                        .attr("dy", ".75em")
                        .attr("transform", "rotate(-90)")
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px')
                        .text(labelText);
                        registerFigureBBox(yLabel);
                }

            d3.selection.prototype.moveToBack = function () {
                return this.each(function () {
                    var firstChild = this.parentNode.firstChild;
                    if (firstChild) {
                        this.parentNode.insertBefore(this, firstChild);
                    }
                });
            };

            if (verticalLines) {
                for (i in verticalLines) {
                    svg.append("g")
                        .attr("transform", "translate(" + x(verticalLines) + ", 1)")
                        .append("line")
                        .attr("y2", height)
                        .style("stroke", "#dddddd")
                        .style("stroke-width", "1px")
                        .moveToBack();
                }
            }

            if (showAxes) {

                var myXAxis = svg.append("g")
                    .attr("class", "x axis")
                    .attr("transform", "translate(0," + height + ")")
                    .call(xAxis);

                //rangeTree = registerFigureBBox(myXAxis);
                

                var xLabel = drawXLabel(svg, getLabelText('x'));

                //console.log('xLabel');
                //console.log(xLabel);

                //rangeTree = registerFigureBBox(xLabel);
                // Add the Y Axis

                if (!yAxisValues) {
                    var myYAxis = svg.append("g")
                        .attr("class", "y axis")
                        .call(yAxis)
                        .selectAll("text")
                        .style("text-anchor", "end")
                        .attr("dx", "30px")
                        .attr("dy", "-13px")
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px')
                        .attr("transform", "rotate(-90)");
                } else {
                    var myYAxis = svg.append("g")
                        .attr("class", "y axis")
                        .call(yAxis)
                        .selectAll("text")
                        .style("text-anchor", "end")
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px');
                }
                registerFigureBBox(myYAxis);

                function getLabelText(axis) {
                    if (axis == 'y') {
                        if (yLabelText == null)
                            return modelInfo['category_name'] + " Frequency";
                        else
                            return yLabelText;
                    } else {
                        if (xLabelText == null)
                            return modelInfo['not_category_name'] + " Frequency";
                        else
                            return xLabelText;
                    }
                }
                var yLabel = drawYLabel(svg, getLabelText('y'))
                
            
            } else {
                horizontal_line_y_position_translated = 0.5;
                if(horizontal_line_y_position !== null) {
                   var loOy = null, hiOy = null, loY = null, hiY = null;
                   for(i in fullData.data) {
                        var curOy = fullData.data[i].oy;
                        if(curOy < horizontal_line_y_position && (curOy > loOy || loOy === null)) {
                              loOy = curOy;
                              loY = fullData.data[i].y
                        }
                        if(curOy > horizontal_line_y_position && (curOy < hiOy || hiOy === null)) {
                              hiOy = curOy;
                              hiY = fullData.data[i].y
                        }
                   }
                   horizontal_line_y_position_translated = loY + (hiY - loY)/2.
                   if(loY === null) {
                        horizontal_line_y_position_translated = 0;
                   }
                }
                if(vertical_line_x_position === null) {
                    vertical_line_x_position_translated = 0.5;
                } else {
                    if(vertical_line_x_position !== null) {
                       var loOx = null, hiOx = null, loX = null, hiX = null;
                       for(i in fullData.data) {
                            var curOx = fullData.data[i].ox;
                            if(curOx < vertical_line_x_position && (curOx > loOx || loOx === null)) {
                                  loOx = curOx;
                                  loX = fullData.data[i].x;
                            }
                            if(curOx > vertical_line_x_position && (curOx < hiOx || hiOx === null)) {
                                  hiOx = curOx;
                                  hiX = fullData.data[i].x
                            }
                       }
                       vertical_line_x_position_translated = loX + (hiX - loX)/2.
                       if(loX === null) {
                            vertical_line_x_position_translated = 0;
                       }
                    }
                }
                if(showCrossAxes) {
                    var x_line = svg.append("g")
                        .attr("transform", "translate(0, " + y(horizontal_line_y_position_translated) + ")")
                        .append("line")
                        .attr("x2", width)
                        .style("stroke", "#cccccc")
                        .style("stroke-width", "1px")
                        .moveToBack();
                    var y_line = svg.append("g")
                        .attr("transform", "translate(" + x(vertical_line_x_position_translated) + ", 0)")
                        .append("line")
                        .attr("y2", height)
                        .style("stroke", "#cccccc")
                        .style("stroke-width", "1px")
                        .moveToBack();
                }
            }

            function showWordList(word, termDataList) {
                var maxWidth = word.node().getBBox().width;
                var wordObjList = [];
                for (var i in termDataList) {
                    var curTerm = termDataList[i].term;
                    word = (function (word, curTerm) {
                        var curWordPrinted = svg.append("text")
                                .attr("text-anchor", "start")
                                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                                .attr('font-size', '12px')
                                .attr("x", word.node().getBBox().x)
                                .attr("y", word.node().getBBox().y
                                    + 2 * word.node().getBBox().height)
                                .text(curTerm);
                        wordObjList.push(curWordPrinted)
                        return makeWordInteractive(
                            termDataList, //data,
                            svg, 
                            curWordPrinted,
                            curTerm,
                            termDataList[i]);
                    })(word, curTerm);
                    if (word.node().getBBox().width > maxWidth)
                        maxWidth = word.node().getBBox().width;
                    registerFigureBBox(word);
                }
                return {
                    'word': word,
                    'maxWidth': maxWidth,
                    'wordObjList':wordObjList
                };
            }

            function pickEuclideanDistanceSortAlgo(category) {
                if (category == true) return euclideanDistanceSortForCategory;
                return euclideanDistanceSortForNotCategory;
            }

            function pickScoreSortAlgo(category) {
                console.log("PICK SCORE ALGO")
                console.log(category)
                if (category == true) {
                    return scoreSortForCategory;
                } else {
                    return scoreSortForNotCategory;
                }
            }

            function pickTermSortingAlgorithm(category) {
                if (sortByDist) return pickEuclideanDistanceSortAlgo(category);
                return pickScoreSortAlgo(category);
            }

            function showAssociatedWordList(data, word, header, isAssociatedToCategory,  length=14) {
                var sortedData = null;
                var sortingAlgo = pickTermSortingAlgorithm(isAssociatedToCategory);
                sortedData = data.filter(term => (term.display === undefined || term.display === true)).sort(sortingAlgo);
                if (wordVecMaxPValue) {
                    function signifTest(x) {
                        if (isAssociatedToCategory)
                            return x.p >= 1 - minPVal;
                        return x.p <= minPVal;
                    }

                    sortedData = sortedData.filter(signifTest)
                }
                return showWordList(word, sortedData.slice(0, length));

            }
            var characteristicXOffset = width;
            function showCatHeader(startingOffset, catName, registerFigureBBox) {
                var catHeader =  svg.append("text")
                .attr("text-anchor", "start")
                .attr("x", startingOffset //width
                     )
                .attr("dy", "6px")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '12px')
                .attr('font-weight', 'bolder')
                .attr('font-decoration', 'underline')
                .text(catName
                      //"Top " + fullData['info']['category_name']
                     );
                registerFigureBBox(catHeader);
                return catHeader;
            }

            function showNotCatHeader(startingOffset, word, notCatName) {
                console.log("showNotCatHeader")
                console.log(word)
                console.log(word.node().getBBox().y - word.node().getBBox().height)
                console.log(word.node().getBBox().y + word.node().getBBox().height)
                return svg.append("text")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '12px')
                .attr('font-weight', 'bolder')
                .attr('font-decoration', 'underline')
                .attr("text-anchor", "start")
                .attr("x", startingOffset)
                .attr("y", word.node().getBBox().y + 3 * word.node().getBBox().height)
                .text(notCatName);
            }

            function showTopTermsPane(data,
                                       registerFigureBBox, 
                                       showAssociatedWordList,
                                       catName,
                                       notCatName,
                                       startingOffset) {
                data = data.filter(term => (term.display === undefined || term.display === true));
                //var catHeader = showCatHeader(startingOffset, catName, registerFigureBBox);
                var catHeader = svg.append("text")
                .attr("text-anchor", "start")
                .attr("x", startingOffset)
                .attr("dy", "6px")
                .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                .attr('font-size', '12px')
                .attr('font-weight', 'bolder')
                .attr('font-decoration', 'underline')
                .text(catName
                      //"Top " + fullData['info']['category_name']
                     );
                registerFigureBBox(catHeader);
                var word = catHeader;
                var wordListData = showAssociatedWordList(data, word, catHeader, true);
                word = wordListData.word;
                var maxWidth = wordListData.maxWidth;

                var notCatHeader = showNotCatHeader(startingOffset, word, notCatName);
                word = notCatHeader;
                characteristicXOffset = catHeader.node().getBBox().x + maxWidth + 10;

                var notWordListData = showAssociatedWordList(data, word, notCatHeader, false);
                word = wordListData.word;
                if (wordListData.maxWidth > maxWidth) {
                    maxWidth = wordListData.maxWidth;
                }
                return {wordListData, notWordListData,
                        word, maxWidth, characteristicXOffset, startingOffset,
                        catHeader, notCatHeader, registerFigureBBox};
            }

            var payload = Object();
            if (showTopTerms) {
                payload.topTermsPane = showTopTermsPane(
                    data,
                    registerFigureBBox, 
                    showAssociatedWordList,
                    "Top " + fullData['info']['category_name'],
                    "Top " + fullData['info']['not_category_name'],
                    width
                );
                payload.showTopTermsPane = showTopTermsPane;
                payload.showAssociatedWordList = showAssociatedWordList;
                payload.showWordList = showWordList;
                /*var wordListData = topTermsPane.wordListData;
                var word = topTermsPane.word;
                var maxWidth = topTermsPane.maxWidth;
                var catHeader = topTermsPane.catHeader;
                var notCatHeader = topTermsPane.notCatHeader;
                var startingOffset = topTermsPane.startingOffset;*/
                characteristicXOffset = payload.topTermsPane.characteristicXOffset;
            }


            if (!nonTextFeaturesMode && !asianMode && showCharacteristic) {
                var sortMethod = backgroundScoreSort;
                var title = 'Characteristic';
                if (wordVecMaxPValue) {
                    title = 'Most similar';
                    sortMethod = scoreSortReverse;
                } else if (data.reduce(function (a, b) {
                        return a + b.bg
                    }, 0) === 0) {
                    title = 'Most frequent';
                }
                word = svg.append("text")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr("text-anchor", "start")
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bolder')
                    .attr('font-decoration', 'underline')
                    .attr("x", characteristicXOffset)
                    .attr("dy", "6px")
                    .text(title);

                var wordListData = showWordList(word, data.filter(term => (term.display === undefined || term.display === true)).sort(sortMethod).slice(0, 30));

                word = wordListData.word;
                maxWidth = wordListData.maxWidth;
                console.log(maxWidth);
                console.log(word.node().getBBox().x + maxWidth);

                svg.attr('width', word.node().getBBox().x + 3 * maxWidth + 10);
            }

            function performPartialLabeling(data, existingLabels, getX, getY) {
                for (i in existingLabels) {
                    rectHolder.remove(existingLabels[i].rect);
                    existingLabels[i].label.remove();
                }
                console.log('labeling 1')
                

                var labeledPoints = [];
                //var filteredData = data.filter(d=>d.display === undefined || d.display === true);
                //for (var i = 0; i < filteredData.length; i++) {
                data.forEach(function(datum, i) {
                    //console.log(datum.i, datum.ci, i)
                    //var label = labelPointsIfPossible(i, getX(filteredData[i]), getY(filteredData[i]));
                    if(datum.display === undefined || datum.display === true) {
                        if(datum.term == "the" || i == 1) {
                            console.log("trying to label datum # " + i + ": " + datum.term)
                            console.log(datum)
                            console.log([getX(datum), getY(datum)])
                        }
                        var label = labelPointsIfPossible(datum, getX(datum), getY(datum));
                        if (label !== false) {
                            //console.log("labeled")
                            labeledPoints.push(label)
                        }
                    }
                    //if (labelPointsIfPossible(i), true) numPointsLabeled++;
                })
                return labeledPoints;
            }

            //var labeledPoints = performPartialLabeling();
            var labeledPoints = [];
            labeledPoints = performPartialLabeling(data,
                                                   labeledPoints,
                                                   function (d) {return d.x},
                                                   function (d) {return d.y});



            /*
            // pointset has to be sorted by X
            function convex(pointset) {
                function _cross(o, a, b) {
                    return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0]);
                }

                function _upperTangent(pointset) {
                    var lower = [];
                    for (var l = 0; l < pointset.length; l++) {
                        while (lower.length >= 2 && (_cross(lower[lower.length - 2], lower[lower.length - 1], pointset[l]) <= 0)) {
                            lower.pop();
                        }
                        lower.push(pointset[l]);
                    }
                    lower.pop();
                    return lower;
                }

                function _lowerTangent(pointset) {
                    var reversed = pointset.reverse(),
                        upper = [];
                    for (var u = 0; u < reversed.length; u++) {
                        while (upper.length >= 2 && (_cross(upper[upper.length - 2], upper[upper.length - 1], reversed[u]) <= 0)) {
                            upper.pop();
                        }
                        upper.push(reversed[u]);
                    }
                    upper.pop();
                    return upper;
                }

                var convex,
                    upper = _upperTangent(pointset),
                    lower = _lowerTangent(pointset);
                convex = lower.concat(upper);
                convex.push(pointset[0]);
                return convex;
            }

            console.log("POINTSTORE")
            console.log(pointStore);
            pointStore.sort();
            var convexHull = convex(pointStore);
            var minX = convexHull.sort(function (a,b) {
                return a[0] < b[0] ? -1 : 1;
            })[0][0];
            var minY = convexHull.sort(function (a,b) {
                return a[1] < b[1] ? -1 : 1;
            })[0][0];
            //svg.append("text").text("BLAH BLAH").attr("text-anchor", "middle").attr("cx", x(0)).attr("y", minY);
            console.log("POINTSTORE")
            console.log(pointStore);
            console.log(convexHull);
            for (i in convexHull) {
                var i = parseInt(i);
                if (i + 1 == convexHull.length) {
                    var nextI = 0;
                } else {
                    var nextI = i + 1;
                }
                console.log(i, ',', nextI);
                svg.append("line")
                    .attr("x2", width)
                    .style("stroke", "#cc0000")
                    .style("stroke-width", "1px")
                    .attr("x1", convexHull[i][0])     // x position of the first end of the line
                    .attr("y1", convexHull[i][1])      // y position of the first end of the line
                    .attr("x2", convexHull[nextI][0])     // x position of the second end of the line
                    .attr("y2", convexHull[nextI][1]);    // y position of the second end of the line
            }*/

            function populateCorpusStats() {
                var wordCounts = {};
                var docCounts = {}
                fullData.docs.labels.forEach(function (x, i) {
                    var cnt = (
                        fullData.docs.texts[i]
                            .trim()
                            .replace(/['";:,.?¿\-!¡]+/g, '')
                            .match(/\S+/g) || []
                    ).length;
                    var name = null;
                    if (fullData.docs.categories[x] == fullData.info.category_internal_name) {
                        name = fullData.info.category_name;
                    } else if (fullData.info.not_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                        name = fullData.info.not_category_name;
                    } else if (fullData.info.neutral_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                        name = fullData.info.neutral_category_name;
                    } else if (fullData.info.extra_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                        name = fullData.info.extra_category_name;
                    }
                    if (name) {
                        wordCounts[name] = wordCounts[name] ? wordCounts[name] + cnt : cnt
                    }
                    //!!!

                });
                fullData.docs.labels.forEach(function (x) {
                    var name = null;
                    if (fullData.docs.categories[x] == fullData.info.category_internal_name) {
                        name = fullData.info.category_name;
                    } else if (fullData.info.not_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                        name = fullData.info.not_category_name;
                    } else if (fullData.info.neutral_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                        name = fullData.info.neutral_category_name;
                    } else if (fullData.info.extra_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                        name = fullData.info.extra_category_name;
                    }
                    if (name) {
                        docCounts[name] = docCounts[name] ? docCounts[name] + 1 : 1
                    }
                });
                console.log("docCounts");
                console.log(docCounts)
                var messages = [];
                [fullData.info.category_name,
                 fullData.info.not_category_name,
                 fullData.info.neutral_category_name,
                 fullData.info.extra_category_name].forEach(function (x, i) {
                    if (docCounts[x] > 0) {
                        messages.push('<b>' + x + '</b> document count: '
                            + Number(docCounts[x]).toLocaleString('en')
                            + '; word count: '
                            + Number(wordCounts[x]).toLocaleString('en'));
                    }
                });

                d3.select('#'+divName+'-'+'corpus-stats')
                    .style('width', width + margin.left + margin.right + 200)
                    .append('div')
                    .html(messages.join('<br />'));
            }


            if (fullData.docs) {
                populateCorpusStats();
            }

            if (saveSvgButton) {
                // from https://stackoverflow.com/questions/23218174/how-do-i-save-export-an-svg-file-after-creating-an-svg-with-d3-js-ie-safari-an
                var svgElement = document.getElementById(divName);

                var serializer = new XMLSerializer();
                var source = serializer.serializeToString(svgElement);

                if (!source.match(/^<svg[^>]+xmlns="http\:\/\/www\.w3\.org\/2000\/svg"/)) {
                    source = source.replace(/^<svg/, '<svg xmlns="https://www.w3.org/2000/svg"');
                }
                if (!source.match(/^<svg[^>]+"http\:\/\/www\.w3\.org\/1999\/xlink"/)) {
                    source = source.replace(/^<svg/, '<svg xmlns:xlink="https://www.w3.org/1999/xlink"');
                }

                source = '<?xml version="1.0" standalone="no"?>\r\n' + source;

                var url = "data:image/svg+xml;charset=utf-8," + encodeURIComponent(source);

                var downloadLink = document.createElement("a");
                downloadLink.href = url;
                downloadLink.download = fullData['info']['category_name'] + ".svg";
                downloadLink.innerText = 'Download SVG';
                document.body.appendChild(downloadLink);

            }
            function rerender(xCoords, yCoords, color) {
                labeledPoints.forEach(function (p) {
                    p.label.remove();
                    rectHolder.remove(p.rect);
                });
                pointRects.forEach(function (rect) {
                    rectHolder.remove(rect);
                });
                pointRects = []
                /*
                var circles = d3.select('#' + divName).selectAll('circle')
                    .attr("cy", function (d) {return y(yCoords[d.i])})
                    .transition(0)
                    .attr("cx", function (d) {return x(xCoords[d.i])})
                    .transition(0);    
                */
                d3.select('#' + divName).selectAll("dot").remove();
                d3.select('#' + divName).selectAll("circle").remove();
                console.log(fullData)
                console.log(this)
                var circles = this.svg//.select('#' + divName)
                .selectAll("dot")
                .data(this.fullData.data.filter(d=>d.display === undefined || d.display === true))
                //.filter(function (d) {return d.display === undefined || d.display === true})
                .enter()
                .append("circle")
                .attr("cy", d=>d.y)
                .attr("cx", d=>d.x)
                .attr("r", d=>2)
                .on("mouseover", function (d) {
                    /*var mySVGMatrix = circle.getScreenCTM()n
                        .translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                    var pageX = mySVGMatrix.e;
                    var pageY = mySVGMatrix.f;*/

                    /*showTooltip(
                        d,
                        d3.event.pageX,
                        d3.event.pageY
                    );*/
                    console.log("point MOUSOEVER")
                    console.log(d)
                    showToolTipForTerm(data, this, d.term, d, true);
                    d3.select(this).style("stroke", "black");
                })
                .on("click", function (d) {
                    var runDisplayTermContexts = true;
                    if(alternativeTermFunc != null) {
                        runDisplayTermContexts = alternativeTermFunc(d);
                    }
                    if(runDisplayTermContexts) {
                        displayTermContexts(data, gatherTermContexts(d));
                    }
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                    d3.select('#'+divName+'-'+'overlapped-terms')
                        .selectAll('div')
                        .remove();
                })
                
                if(color !== null) {
                     circles.style("fill", d => color(d));
                }
                xCoords.forEach((xCoord,i) => censorCircle(xCoord, yCoords[i]))
                labeledPoints = [];
                labeledPoints = performPartialLabeling(
                    this.fullData.data,
                    labeledPoints, 
                    (d=>d.ox), //function (d) {return xCoords[d.ci]},
                    (d=>d.oy) //function (d) {return yCoords[d.ci]}
                );
            };
            //return [performPartialLabeling, labeledPoints];
            return {...payload, 
                    ...{'rerender': rerender, 
                        'performPartialLabeling': performPartialLabeling,
                        'showToolTipForTerm': showToolTipForTerm,
                        'svg': svg,
                        'data': data,
                        'xLabel': xLabel,
                        'yLabel': yLabel,
                        'drawXLabel': drawXLabel,
                        'drawYLabel': drawYLabel,
                        'populateCorpusStats': populateCorpusStats}};
        };

        
        
        //fullData = getDataAndInfo();
        if (fullData.docs) {
            var corpusWordCounts = getCorpusWordCounts();
        }
        var payload = processData(fullData);
        
        // The tool tip is down here in order to make sure it has the highest z-index
        var tooltip = d3.select('#' + divName)
            .append("div")
            //.attr("class", getTooltipContent == null && sortByDist ? "tooltip" : "tooltipscore")
            .attr("class", "tooltipscore")
            .style("opacity", 0);
        
        plotInterface = {}
        if(payload.topTermsPane) {
            plotInterface.topTermsPane = payload.topTermsPane;
            plotInterface.showTopTermsPane = payload.showTopTermsPane;
            plotInterface.showAssociatedWordList = payload.showAssociatedWordList;
        }
        plotInterface.divName = divName; 
        plotInterface.displayTermContexts = displayTermContexts;
        plotInterface.gatherTermContexts = gatherTermContexts;
        plotInterface.xLabel = payload.xLabel;
        plotInterface.yLabel = payload.yLabel;
        plotInterface.drawXLabel = payload.drawXLabel;
        plotInterface.drawYLabel = payload.drawYLabel;
        plotInterface.svg = payload.svg;
        plotInterface.termDict = termDict;
        plotInterface.showToolTipForTerm = payload.showToolTipForTerm;
        plotInterface.fullData = fullData;
        plotInterface.data = payload.data;
        plotInterface.rerender = payload.rerender;
        plotInterface.populateCorpusStats = payload.populateCorpusStats;
        plotInterface.handleSearch = handleSearch;
        plotInterface.y = y;
        plotInterface.x = x;
        plotInterface.tooltip = tooltip;
        plotInterface.alternativeTermFunc = alternativeTermFunc;
        plotInterface.drawCategoryAssociation = function (categoryNum) {
            var rawLogTermCounts = getTermCounts(this.fullData).map(Math.log);
            var maxRawLogTermCounts = Math.max(...rawLogTermCounts);
            var minRawLogTermCounts = Math.min(...rawLogTermCounts);
            var logTermCounts = rawLogTermCounts.map(
                x => (x - minRawLogTermCounts)/maxRawLogTermCounts
            )
            
            var rawScores = getCategoryDenseRankScores(this.fullData, categoryNum);
            var maxRawScores = Math.max(...rawScores);
            var minRawScores = Math.min(...rawScores);
            var scores = rawScores.map(
                function(rawScore) {
                    if(rawScore == 0) {
                        return 0.5;
                    } else if(rawScore > 0) {
                        return rawScore/(2.*maxRawScores) + 0.5;
                    } else if(rawScore < 0) {
                        return 0.5 - rawScore/(2.*minRawScores);
                    }
                }
            )
            
            var denseRanks = getDenseRanks(this.fullData, categoryNum)
            console.log("denseRanks")
            console.log(denseRanks);
            var fgFreqSum = denseRanks.fgFreqs.reduce((a,b) => a + b, 0)
            var bgFreqSum = denseRanks.bgFreqs.reduce((a,b) => a + b, 0)
            var ox = denseRanks.bg;
            var oy = denseRanks.fg; 
            //var ox = logTermCounts
            //var oy = scores;
            var xf = this.x;
            var yf = this.y;
            
            this.fullData.data = this.fullData.data.map(function(term, i) { 
                //term.ci = i;
                term.s = scores[i];
                term.os = rawScores[i];
                term.cat = denseRanks.fgFreqs[i];
                term.ncat = denseRanks.bgFreqs[i];
                term.cat25k = parseInt(denseRanks.fgFreqs[i] * 25000/fgFreqSum);
                term.ncat25k = parseInt(25000 *denseRanks.bgFreqs[i]/bgFreqSum);
                term.x = xf(ox[i]) // logTermCounts[term.i];
                term.y = yf(oy[i]) // scores[term.i];
                term.ox = ox[i];
                term.oy = oy[i];
                term.display = false;
                return term;
             })
            
            // Feature selection
            var targetTermsToShow = 1500;
            
            var sortedBg = denseRanks.bg.map((x,i)=>[x,i]).sort((a,b)=>b[0]-a[0]).map(x=>x[1]).slice(0,parseInt(targetTermsToShow/2));
            var sortedFg = denseRanks.fg.map((x,i)=>[x,i]).sort((a,b)=>b[0]-a[0]).map(x=>x[1]).slice(0,parseInt(targetTermsToShow/2));
            var sortedScores = denseRanks.fg.map((x,i)=>[x,i]).sort((a,b)=>b[0]-a[0]).map(x=>x[1]);
            var myFullData = this.fullData
            
            sortedBg.concat(sortedFg)//.concat(sortedScores.slice(0, parseInt(targetTermsToShow/2))).concat(sortedScores.slice(-parseInt(targetTermsToShow/4)))
                .forEach(function(i) {
                myFullData.data[i].display = true;
            })
            
            console.log('newly filtered')
            console.log(myFullData)
            
            // begin rescaling to ignore hidden terms
            /*
            function scaleDenseRanks(ranks) { 
                var max = Math.max(...ranks); 
                return ranks.map(x=>x/max) 
            }
            var filteredData = myFullData.data.filter(d=>d.display);
            var catRanks = scaleDenseRanks(denseRank(filteredData.map(d=>d.cat)))
            var ncatRanks = scaleDenseRanks(denseRank(filteredData.map(d=>d.ncat)))
            var rawScores = catRanks.map((x,i) => x - ncatRanks[i]);
            function stretch_0_1(scores) {
                var max = 1.*Math.max(...rawScores);
                var min = -1.*Math.min(...rawScores);
                return scores.map(function(x, i) {
                    if(x == 0) return 0.5;
                    if(x > 0) return (x/max + 1)/2;
                    return (x/min + 1)/2;
                })
            }
            var scores = stretch_0_1(rawScores);
            console.log(scores)
            filteredData.forEach(function(d, i) {
                d.x = xf(catRanks[i]);
                d.y = yf(ncatRanks[i]);
                d.ox = catRanks[i];
                d.oy = ncatRanks[i];
                d.s = scores[i];
                d.os = rawScores[i];
            });
            console.log("rescaled");
            */
            // end rescaling
            
            
            this.rerender(//denseRanks.bg, 
                          fullData.data.map(x=>x.ox), //ox 
                          //denseRanks.fg, 
                          fullData.data.map(x=>x.oy), //oy,          
                          d => d3.interpolateRdYlBu(d.s));
            this.yLabel.remove()
            this.xLabel.remove()
            this.yLabel = this.drawYLabel(this.svg, this.fullData.info.categories[categoryNum] + ' Frequncy Rank')
            this.xLabel = this.drawXLabel(this.svg,
                               "Not " + this.fullData.info.categories[categoryNum] + ' Frequency Rank')
            console.log(this.topTermsPane)
            this.topTermsPane.catHeader.remove()
            this.topTermsPane.notCatHeader.remove()
            this.topTermsPane.wordListData.wordObjList.map(x => x.remove())
            this.topTermsPane.notWordListData.wordObjList.map(x => x.remove())
            this.showWordList = payload.showWordList;
            this.showAssociatedWordList = function(data, word, header, isAssociatedToCategory, length=14) {
                var sortedData = null;
                if(!isAssociatedToCategory) {
                    sortedData = data.map(x=>x).sort((a, b) => scores[a.i] - scores[b.i])
                } else {
                    sortedData = data.map(x=>x).sort((a, b) => scores[b.i] - scores[a.i])
                }
                console.log('sortedData'); 
                console.log(isAssociatedToCategory); 
                console.log(sortedData.slice(0, length))
                console.log(payload)
                console.log(word)
                return payload.showWordList(word, sortedData.slice(0, length));
            }
            this.topTermsPane = payload.showTopTermsPane(
                this.data,
                this.topTermsPane.registerFigureBBox,
                this.showAssociatedWordList,
                "Top " + this.fullData.info.categories[categoryNum],
                "Top Not " + this.fullData.info.categories[categoryNum],
                this.topTermsPane.startingOffset
            )
            
            fullData.info.category_name = this.fullData.info.categories[categoryNum];
            fullData.info.not_category_name = "Not " + this.fullData.info.categories[categoryNum];
            fullData.info.category_internal_name = this.fullData.info.categories[categoryNum];
            fullData.info.not_category_internal_names = this.fullData.info.categories.filter(x => x!==this.fullData.info.categories[categoryNum]);
            ['snippets', 
             'snippetsalt', 'termstats', 
             'overlapped-terms-clicked', 'categoryinfo', 
             'cathead', 'cat', 'corpus-stats',
             'notcathead', 'notcat', 'neuthead', 'nuet'].forEach(function(divSubName) {
                var mydiv = '#'+divName+'-'+divSubName;
                d3.select(mydiv).selectAll("*").remove();
                d3.select(mydiv).html("");

            })
            this.populateCorpusStats();
            console.log(fullData)
        }
        
        return plotInterface
    };
}(d3);
 
function getDataAndInfo() { return{"info": {"category_name": "2009~2016", "not_category_name": "2017~2019", "category_terms": ["Shelhamer (2017)", "Donahue (2017)", "Zhang (2016)", "Long (2014)", "Dong (2015)", "Shao (2015)", "Ben-David (2010)", "Li (2014)", "Kendall (2015)", "Bruzzone (2010)"], "not_category_terms": ["Shelhamer (2017)", "Donahue (2017)", "Zhang (2016)", "Long (2014)", "Dong (2015)", "Shao (2015)", "Ben-David (2010)", "Li (2014)", "Kendall (2015)", "Bruzzone (2010)"], "category_internal_name": "NORMAL", "not_category_internal_names": ["FRONTIER"], "categories": ["NORMAL", "FRONTIER"], "neutral_category_internal_names": [], "extra_category_internal_names": [], "neutral_category_name": "Neutral", "extra_category_name": "Extra"}, "data": [{"x": 0.24776286785739926, "y": 0.14039285742157812, "ox": -0.2452037350876701, "oy": -0.35919710084309303, "term": "Shelhamer (2017)", "cat25k": 0, "ncat25k": 3571, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.0, "os": 0}, {"x": 0.5329449338986222, "y": 0.0, "ox": -0.01826965141582834, "oy": -0.4603833667754003, "term": "Girshick (2016)", "cat25k": 273, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.8168846342498276, "y": 0.7492094088783482, "ox": 0.2076758177776797, "oy": 0.07959924970562493, "term": "Pan (2011)", "cat25k": 410, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.5473396273290394, "y": 0.8955582358155874, "ox": -0.0068150511714475965, "oy": 0.1850782006531442, "term": "Duan (2012)", "cat25k": 546, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.8456429973395775, "y": 0.41864359811843316, "ox": 0.2305603310511446, "oy": -0.15865161753928178, "term": "Gao (2014)", "cat25k": 683, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 5, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.5371968182790737, "y": 0.08126769724571001, "ox": -0.01488620764199405, "oy": -0.4018107657454368, "term": "Donahue (2017)", "cat25k": 0, "ncat25k": 21429, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 6, "s": 0.0, "os": 0}, {"x": 0.06971751634425385, "y": 0.8221909745661711, "ox": -0.3868836073830975, "oy": 0.13219973273211533, "term": "Lu (2015)", "cat25k": 956, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 7, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.0, "y": 0.7931535520910478, "ox": -0.4423614321533723, "oy": 0.11127140057534717, "term": "Taylor (2009)", "cat25k": 1093, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 8, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.633222938610581, "y": 0.6624762579684085, "ox": 0.061526730690680306, "oy": 0.017087496370720615, "term": "Zhu (2014)", "cat25k": 1230, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 9, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.558481245775698, "y": 0.9212004351202157, "ox": 0.0020509094687572354, "oy": 0.20355947132160884, "term": "Bruzzone (2010)", "cat25k": 1366, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 10, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.4741341320809102, "y": 0.16971167310590168, "ox": -0.06506844071480052, "oy": -0.3380659583110635, "term": "Kendall (2015)", "cat25k": 1503, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 11, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.9583802353541916, "y": 0.7352325929579908, "ox": 0.3202711679199772, "oy": 0.06952564739722998, "term": "Li (2014)", "cat25k": 1639, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 12, "ncat": 0, "s": 1.0, "os": 1}, {"x": 1.0, "y": 0.7471892041523268, "ox": 0.3533901619845232, "oy": 0.07814321428901498, "term": "Ben-David (2010)", "cat25k": 1776, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 13, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.3167127771662725, "y": 0.8593928323005493, "ox": -0.19033673483947086, "oy": 0.15901247192000012, "term": "Shao (2015)", "cat25k": 1913, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 14, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.43271297601840997, "y": 0.16735328886215983, "ox": -0.09802939168256966, "oy": -0.33976573207192684, "term": "Dong (2015)", "cat25k": 2049, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 15, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.8107388423748891, "y": 0.7046837416019794, "ox": 0.20278529409595775, "oy": 0.04750797317927655, "term": "Long (2014)", "cat25k": 2186, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 16, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.724646114975961, "y": 0.722335838850385, "ox": 0.1342768690245814, "oy": 0.060230485130697176, "term": "Zhang (2016)", "cat25k": 2322, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 17, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.8397656377575611, "y": 0.700197245809344, "ox": 0.22588341279443347, "oy": 0.044274391608850994, "term": "Long (2013)", "cat25k": 2459, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 18, "ncat": 0, "s": 1.0, "os": 1}, {"x": 0.5567088007633753, "y": 0.449325504947991, "ox": 0.0006404835246796026, "oy": -0.1365380453762527, "term": "Fu (2015)", "cat25k": 2596, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 19, "ncat": 0, "s": 1.0, "os": 1}], "docs": {"categories": ["NORMAL", "FRONTIER"], "labels": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "texts": ["IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,VOL. 22,NO. 10,OCTOBER 20101345A Survey on Transfer LearningSinno Jialin Pan and Qiang Yang, Fellow, IEEEAbstract\u2014A major assumption in many machine learning and data mining algorithms is that the training and future data must be in thesame feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. Forexample, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domainof interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledgetransfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. Inrecent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizingand reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, wediscuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitasklearning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learningresearch.Index Terms\u2014Transfer learning, survey, machine learning, data mining.\u00c71INTRODUCTIONDATA mining and machine learning technologies havealready achieved significant success in many knowledge engineering areas including classification, regression,and clustering (e.g., [1], [2]). However, many machinelearning methods work well only under a common assumption: the training and test data are drawn from the samefeature space and the same distribution. When the distribution changes, most statistical models need to be rebuilt fromscratch using newly collected training data. In many realworld applications, it is expensive or impossible to recollectthe needed training data and rebuild the models. It would benice to reduce the need and effort to recollect the trainingdata. In such cases, knowledge transfer or transfer learningbetween task domains would be desirable.Many examples in knowledge engineering can be foundwhere transfer learning can truly be beneficial. Oneexample is Web-document classification [3], [4], [5], whereour goal is to classify a given Web document into severalpredefined categories. As an example, in the area of Webdocument classification (see, e.g., [6]), the labeled examplesmay be the university webpages that are associated withcategory information obtained through previous manuallabeling efforts. For a classification task on a newly createdwebsite where the data features or data distributions maybe different, there may be a lack of labeled training data. Asa result, we may not be able to directly apply the webpageclassifiers learned on the university website to the newwebsite. In such cases, it would be helpful if we couldtransfer the classification knowledge into the new domain.. The authors are with the Department of Computer Science andEngineering, Hong Kong University of Science and Technology,Clearwater Bay, Kowloon, Hong Kong.E-mail: {sinnopan, qyang}@cse.ust.hk.Manuscript received 13 Nov. 2008; revised 29 May 2009; accepted 13 July2009; published online 12 Oct. 2009.Recommended for acceptance by C. Clifton.For information on obtaining reprints of this article, please send e-mail to:tkde@computer.org, and reference IEEECS Log Number TKDE-2008-11-0600.Digital Object Identifier no. 10.1109/TKDE.2009.191.1041-4347/10/$26.00 \u00df 2010 IEEEThe need for transfer learning may arise when the datacan be easily outdated. In this case, the labeled dataobtained in one time period may not follow the samedistribution in a later time period. For example, in indoorWiFi localization problems, which aims to detect a user\u2019scurrent location based on previously collected WiFi data, itis very expensive to calibrate WiFi data for buildinglocalization models in a large-scale environment, becausea user needs to label a large collection of WiFi signal data ateach location. However, the WiFi signal-strength valuesmay be a function of time, device, or other dynamic factors.A model trained in one time period or on one device maycause the performance for location estimation in anothertime period or on another device to be reduced. To reducethe recalibration effort, we might wish to adapt thelocalization model trained in one time period (the sourcedomain) for a new time period (the target domain), or toadapt the localization model trained on a mobile device (thesource domain) for a new mobile device (the targetdomain), as done in [7].As a third example, consider the problem of sentimentclassification, where our task is to automatically classify thereviews on a product, such as a brand of camera, intopositive and negative views. For this classification task, weneed to first collect many reviews of the product andannotate them. We would then train a classifier on thereviews with their corresponding labels. Since the distribution of review data among different types of products can bevery different, to maintain good classification performance,we need to collect a large amount of labeled data in order totrain the review-classification models for each product.However, this data-labeling process can be very expensive todo. To reduce the effort for annotating reviews for variousproducts, we may want to adapt a classification model that istrained on some products to help learn classification modelsfor some other products. In such cases, transfer learning cansave a significant amount of labeling effort [8].In this survey paper, we give a comprehensive overviewof transfer learning for classification, regression, and clusterPublished by the IEEE Computer Society\f1346IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,ing developed in machine learning and data mining areas.There has been a large amount of work on transfer learningfor reinforcement learning in the machine learning literature(e.g., [9], [10]). However, in this paper, we only focus ontransfer learning for classification, regression, and clusteringproblems that are related more closely to data mining tasks.By doing the survey, we hope to provide a useful resource forthe data mining and machine learning community.The rest of the survey is organized as follows: In the nextfour sections, we first give a general overview and definesome notations we will use later. We, then, briefly survey thehistory of transfer learning, give a unified definition oftransfer learning and categorize transfer learning into threedifferent settings (given in Table 2 and Fig. 2). For eachsetting, we review different approaches, given in Table 3 indetail. After that, in Section 6, we review some currentresearch on the topic of \u201cnegative transfer,\u201d which happenswhen knowledge transfer has a negative impact on targetlearning. In Section 7, we introduce some successfulapplications of transfer learning and list some publisheddata sets and software toolkits for transfer learning research.Finally, we conclude the paper with a discussion of futureworks in Section 8.2OVERVIEW2.1 A Brief History of Transfer LearningTraditional data mining and machine learning algorithmsmake predictions on the future data using statistical modelsthat are trained on previously collected labeled or unlabeledtraining data [11], [12], [13]. Semisupervised classification[14], [15], [16], [17] addresses the problem that the labeleddata may be too few to build a good classifier, by making useof a large amount of unlabeled data and a small amount oflabeled data. Variations of supervised and semisupervisedlearning for imperfect data sets have been studied; forexample, Zhu and Wu [18] have studied how to deal with thenoisy class-label problems. Yang et al. considered costsensitive learning [19] when additional tests can be made tofuture samples. Nevertheless, most of them assume that thedistributions of the labeled and unlabeled data are the same.Transfer learning, in contrast, allows the domains, tasks, anddistributions used in training and testing to be different. Inthe real world, we observe many examples of transferlearning. For example, we may find that learning torecognize apples might help to recognize pears. Similarly,learning to play the electronic organ may help facilitatelearning the piano. The study of Transfer learning is motivatedby the fact that people can intelligently apply knowledgelearned previously to solve new problems faster or withbetter solutions. The fundamental motivation for Transferlearning in the field of machine learning was discussed in aNIPS-95 workshop on \u201cLearning to Learn,\u201d1 which focusedon the need for lifelong machine learning methods that retainand reuse previously learned knowledge.Research on transfer learning has attracted more andmore attention since 1995 in different names: learning tolearn, life-long learning, knowledge transfer, inductive1. https://socrates.acadiau.ca/courses/comp/dsilver/NIPS95_LTL/transfer.workshop.1995.html.VOL. 22,NO. 10,OCTOBER 2010Fig. 1. Different learning processes between (a) traditional machinelearning and (b) transfer learning.transfer, multitask learning, knowledge consolidation,context-sensitive learning, knowledge-based inductive bias,metalearning, and incremental/cumulative learning [20].Among these, a closely related learning technique totransfer learning is the multitask learning framework [21],which tries to learn multiple tasks simultaneously evenwhen they are different. A typical approach for multitasklearning is to uncover the common (latent) features that canbenefit each individual task.In 2005, the Broad Agency Announcement (BAA) 05-29of Defense Advanced Research Projects Agency (DARPA)\u2019sInformation Processing Technology Office (IPTO)2 gave anew mission of transfer learning: the ability of a system torecognize and apply knowledge and skills learned inprevious tasks to novel tasks. In this definition, transferlearning aims to extract the knowledge from one or moresource tasks and applies the knowledge to a target task. Incontrast to multitask learning, rather than learning all of thesource and target tasks simultaneously, transfer learningcares most about the target task. The roles of the source andtarget tasks are no longer symmetric in transfer learning.Fig. 1 shows the difference between the learning processesof traditional and transfer learning techniques. As we cansee, traditional machine learning techniques try to learn eachtask from scratch, while transfer learning techniques try totransfer the knowledge from some previous tasks to a targettask when the latter has fewer high-quality training data.Today, transfer learning methods appear in several topvenues, most notably in data mining (ACM KDD, IEEEICDM, and PKDD, for example), machine learning (ICML,NIPS, ECML, AAAI, and IJCAI, for example) and applications of machine learning and data mining (ACM SIGIR,WWW, and ACL, for example).3 Before we give differentcategorizations of transfer learning, we first describe thenotations used in this paper.2.2 Notations and DefinitionsIn this section, we introduce some notations and definitionsthat are used in this survey. First of all, we give thedefinitions of a \u201cdomain\u201d and a \u201ctask,\u201d respectively.In this survey, a domain D consists of two components: afeature space X and a marginal probability distribution P \u00f0X\u00de,where X \u00bc fx1 ; . . . ; xn g 2 X . For example, if our learning task2. https://www.darpa.mil/ipto/programs/tl/tl.asp.3. We summarize a list of conferences and workshops where transferlearning papers appear in these few years in the following webpage forreference, https://www.cse.ust.hk/~sinnopan/conferenceTL.htm.\fPAN AND YANG: A SURVEY ON TRANSFER LEARNING1347TABLE 1Relationship between Traditional Machine Learning and Various Transfer Learning Settingsis document classification, and each term is taken as a binaryfeature, then X is the space of all term vectors, xi is the ith termvector corresponding to some documents, and X is aparticular learning sample. In general, if two domains aredifferent, then they may have different feature spaces ordifferent marginal probability distributions.Given a specific domain, D \u00bc fX ; P \u00f0X\u00deg, a task consistsof two components: a label space Y and an objectivepredictive function f\u00f0\u0002\u00de (denoted by T \u00bc fY; f\u00f0\u0002\u00deg), which isnot observed but can be learned from the training data,which consist of pairs fxi ; yi g, where xi 2 X and yi 2 Y. Thefunction f\u00f0\u0002\u00de can be used to predict the corresponding label,f\u00f0x\u00de, of a new instance x. From a probabilistic viewpoint,f\u00f0x\u00de can be written as P \u00f0yjx\u00de. In our document classificationexample, Y is the set of all labels, which is True, False for abinary classification task, and yi is \u201cTrue\u201d or \u201cFalse.\u201dFor simplicity, in this survey, we only consider the casewhere there is one source domain DS , and one target domain,DT , as this is by far the most popular of the research works inthe literature. More specifically, we denote the source domaindata as DS \u00bc f\u00f0xS1 ; yS1 \u00de; . . . ; \u00f0xSnS ; ySnS \u00deg, where xSi 2 X S isthe data instance and ySi 2 Y S is the corresponding classlabel. In our document classification example, DS can be a setof term vectors together with their associated true or falseclass labels. Similarly, we denote the target-domain data asDT \u00bc f\u00f0xT1 ; yT1 \u00de; . . . ; \u00f0xTnT ; yTnT \u00deg, where the input xTi is inX T and yTi 2 Y T is the corresponding output. In most cases,0 \u0003 nT \u0004 nS .We now give a unified definition of transfer learning.Definition 1 (Transfer Learning). Given a source domain DSand learning task T S , a target domain DT and learning taskT T , transfer learning aims to help improve the learning of thetarget predictive function fT \u00f0\u0002\u00de in DT using the knowledge inDS and T S , where DS 6\u00bc DT , or T S 6\u00bc T T .In the above definition, a domain is a pair D \u00bc fX ; P \u00f0X\u00deg.Thus, the condition DS 6\u00bc DT implies that either X S 6\u00bc X T orPS \u00f0X\u00de 6\u00bc PT \u00f0X\u00de. For example, in our document classificationexample, this means that between a source document set anda target document set, either the term features are differentbetween the two sets (e.g., they use different languages), ortheir marginal distributions are different.Similarly, a task is defined as a pair T \u00bc fY; P \u00f0Y jX\u00deg.Thus, the condition T S 6\u00bc T T implies that either Y S 6\u00bc Y T orP \u00f0YS jXS \u00de 6\u00bc P \u00f0YT jXT \u00de. When the target and source domainsare the same, i.e., DS \u00bc DT , and their learning tasks are thesame, i.e., T S \u00bc T T , the learning problem becomes atraditional machine learning problem. When the domainsare different, then either 1) the feature spaces between thedomains are different, i.e., X S 6\u00bc X T , or 2) the feature spacesbetween the domains are the same but the marginalprobability distributions between domain data are different;i.e., P \u00f0XS \u00de 6\u00bc P \u00f0XT \u00de, where XSi 2 X S and XTi 2 X T . As anexample, in our document classification example, case 1corresponds to when the two sets of documents aredescribed in different languages, and case 2 may correspondto when the source domain documents and the targetdomain documents focus on different topics.Given specific domains DS and DT , when the learningtasks T S and T T are different, then either 1) the labelspaces between the domains are different, i.e., Y S 6\u00bc Y T , or2) the conditional probability distributions between thedomains are different; i.e., P \u00f0YS jXS \u00de 6\u00bc P \u00f0YT jXT \u00de, whereYSi 2 Y S and YTi 2 Y T . In our document classificationexample, case 1 corresponds to the situation where sourcedomain has binary document classes, whereas the targetdomain has 10 classes to classify the documents to. Case 2corresponds to the situation where the source and targetdocuments are very unbalanced in terms of the userdefined classes.In addition, when there exists some relationship, explicitor implicit, between the feature spaces of the two domains,we say that the source and target domains are related.2.3A Categorization ofTransfer Learning TechniquesIn transfer learning, we have the following three mainresearch issues: 1) what to transfer, 2) how to transfer, and3) when to transfer.\u201cWhat to transfer\u201d asks which part of knowledge can betransferred across domains or tasks. Some knowledge isspecific for individual domains or tasks, and some knowledge may be common between different domains such thatthey may help improve performance for the target domain ortask. After discovering which knowledge can be transferred,learning algorithms need to be developed to transfer theknowledge, which corresponds to the \u201chow to transfer\u201d issue.\u201cWhen to transfer\u201d asks in which situations, transferringskills should be done. Likewise, we are interested inknowing in which situations, knowledge should not betransferred. In some situations, when the source domainand target domain are not related to each other, brute-forcetransfer may be unsuccessful. In the worst case, it mayeven hurt the performance of learning in the targetdomain, a situation which is often referred to as negativetransfer. Most current work on transfer learning focuses on\u201cWhat to transfer\u201d and \u201cHow to transfer,\u201d by implicitlyassuming that the source and target domains be related toeach other. However, how to avoid negative transfer is animportant open issue that is attracting more and moreattention in the future.Based on the definition of transfer learning, we summarizethe relationship between traditional machine learning andvarious transfer learning settings in Table 1, where we\f1348IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,VOL. 22,NO. 10,OCTOBER 2010TABLE 2Different Settings of Transfer Learningcategorize transfer learning under three subsettings, inductivetransfer learning, transductive transfer learning, and unsupervised transfer learning, based on different situations betweenthe source and target domains and tasks.1.In the inductive transfer learning setting, the target taskis different from the source task, no matter when thesource and target domains are the same or not.In this case, some labeled data in the targetdomain are required to induce an objective predictivemodel fT \u00f0\u0002\u00de for use in the target domain. In addition,according to different situations of labeled andunlabeled data in the source domain, we can furthercategorize the inductive transfer learning setting intotwo cases:A lot of labeled data in the source domain areavailable. In this case, the inductive transferlearning setting is similar to the multitask learningsetting. However, the inductive transfer learningsetting only aims at achieving high performancein the target task by transferring knowledge fromthe source task while multitask learning tries tolearn the target and source task simultaneously.b. No labeled data in the source domain areavailable. In this case, the inductive transferlearning setting is similar to the self-taughtlearning setting, which is first proposed by Rainaet al. [22]. In the self-taught learning setting, thelabel spaces between the source and targetdomains may be different, which implies theside information of the source domain cannot beused directly. Thus, it\u2019s similar to the inductivetransfer learning setting where the labeled datain the source domain are unavailable.In the transductive transfer learning setting, the sourceand target tasks are the same, while the source andtarget domains are different.In this situation, no labeled data in the targetdomain are available while a lot of labeled data inthe source domain are available. In addition,according to different situations between the sourceand target domains, we can further categorize thetransductive transfer learning setting into two cases.a.2.a.b.The feature spaces between the source andtarget domains are different, X S 6\u00bc X T .The feature spaces between domains are thesame, X S \u00bc X T , but the marginal probabilitydistributions of the input data are different,P \u00f0XS \u00de 6\u00bc P \u00f0XT \u00de.The latter case of the transductive transferlearning setting is related to domain adaptationfor knowledge transfer in text classification [23]and sample selection bias [24] or covariate shift[25], whose assumptions are similar.3. Finally, in the unsupervised transfer learning setting,similar to inductive transfer learning setting, the targettask is different from but related to the source task.However, the unsupervised transfer learning focus onsolving unsupervised learning tasks in the targetdomain, such as clustering, dimensionality reduction,and density estimation [26], [27]. In this case, there areno labeled data available in both source and targetdomains in training.The relationship between the different settings oftransfer learning and the related areas are summarized inTable 2 and Fig. 2.Approaches to transfer learning in the above threedifferent settings can be summarized into four cases basedon \u201cWhat to transfer.\u201d Table 3 shows these four cases andbrief description. The first context can be referred to asinstance-based transfer learning (or instance transfer)approach [6], [28], [29], [30], [31], [24], [32], [33], [34], [35],which assumes that certain parts of the data in the sourcedomain can be reused for learning in the target domain byreweighting. Instance reweighting and importance samplingare two major techniques in this context.A second case can be referred to as feature-representation-transfer approach [22], [36], [37], [38], [39], [8], [40],[41], [42], [43], [44]. The intuitive idea behind this case is tolearn a \u201cgood\u201d feature representation for the target domain.In this case, the knowledge used to transfer across domainsis encoded into the learned feature representation. With thenew feature representation, the performance of the targettask is expected to improve significantly.A third case can be referred to as parameter-transferapproach [45], [46], [47], [48], [49], which assumes that thesource tasks and the target tasks share some parameters orprior distributions of the hyperparameters of the models. Thetransferred knowledge is encoded into the shared parameters or priors. Thus, by discovering the shared parametersor priors, knowledge can be transferred across tasks.Finally, the last case can be referred to as the relationalknowledge-transfer problem [50], which deals with transferlearning for relational domains. The basic assumption\fPAN AND YANG: A SURVEY ON TRANSFER LEARNING1349Fig. 2. An overview of different settings of transfer.behind this context is that some relationship among the datain the source and target domains is similar. Thus, theknowledge to be transferred is the relationship among thedata. Recently, statistical relational learning techniquesdominate this context [51], [52].Table 4 shows the cases where the different approachesare used for each transfer learning setting. We can see thatthe inductive transfer learning setting has been studied inmany research works, while the unsupervised transferlearning setting is a relatively new research topic and onlystudied in the context of the feature-representation-transfercase. In addition, the feature-representation-transfer problemhas been proposed to all three settings of transfer learning.However, the parameter-transfer and the relational-knowledgetransfer approach are only studied in the inductive transferlearning setting, which we discuss in detail below.3INDUCTIVE TRANSFER LEARNINGDefinition 2 (Inductive Transfer Learning). Given a sourcedomain DS and a learning task T S , a target domain DTand a learning task T T , inductive transfer learning aimsto help improve the learning of the target predictive functionfT \u00f0\u0002\u00de in DT using the knowledge in DS and T S , whereT S 6\u00bc T T .Based on the above definition of the inductive transferlearning setting, a few labeled data in the target domain arerequired as the training data to induce the target predictivefunction. As mentioned in Section 2.3, this setting has twocases: 1) labeled data in the source domain are available and2) labeled data in the source domain are unavailable whileunlabeled data in the source domain are available. Mosttransfer learning approaches in this setting focus on theformer case.3.1 Transferring Knowledge of InstancesThe instance-transfer approach to the inductive transferlearning setting is intuitively appealing: although the sourcedomain data cannot be reused directly, there are certainparts of the data that can still be reused together with a fewlabeled data in the target domain.Dai et al. [6] proposed a boosting algorithm, TrAdaBoost,which is an extension of the AdaBoost algorithm, to addressthe inductive transfer learning problems. TrAdaBoost assumesthat the source and target-domain data use exactly the sameTABLE 3Different Approaches to Transfer Learning\f1350IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,VOL. 22,NO. 10,OCTOBER 2010TABLE 4Different Approaches Used in Different Settingsset of features and labels, but the distributions of the data inthe two domains are different. In addition, TrAdaBoostassumes that, due to the difference in distributions betweenthe source and the target domains, some of the sourcedomain data may be useful in learning for the targetdomain but some of them may not and could even beharmful. It attempts to iteratively reweight the sourcedomain data to reduce the effect of the \u201cbad\u201d source datawhile encourage the \u201cgood\u201d source data to contribute morefor the target domain. For each round of iteration,TrAdaBoost trains the base classifier on the weighted sourceand target data. The error is only calculated on the targetdata. Furthermore, TrAdaBoost uses the same strategy asAdaBoost to update the incorrectly classified examples in thetarget domain while using a different strategy fromAdaBoost to update the incorrectly classified source examples in the source domain. Theoretical analysis of TrAdaBoost in also given in [6].Jiang and Zhai [30] proposed a heuristic method toremove \u201cmisleading\u201d training examples from the sourcedomain based on the difference between conditionalprobabilities P \u00f0yT jxT \u00de and P \u00f0yS jxS \u00de. Liao et al. [31]proposed a new active learning method to select theunlabeled data in a target domain to be labeled with thehelp of the source domain data. Wu and Dietterich [53]integrated the source domain (auxiliary) data an SupportVector Machine (SVM) framework for improving theclassification performance.Transferring Knowledge of FeatureRepresentationsThe feature-representation-transfer approach to the inductive transfer learning problem aims at finding \u201cgood\u201d featurerepresentations to minimize domain divergence and classification or regression model error. Strategies to find \u201cgood\u201dfeature representations are different for different types ofthe source domain data. If a lot of labeled data in the sourcedomain are available, supervised learning methods can beused to construct a feature representation. This is similar tocommon feature learning in the field of multitask learning[40]. If no labeled data in the source domain are available,unsupervised learning methods are proposed to constructthe feature representation.learning setting, the common features can be learned bysolving an optimization problem, given as follows:arg minA;UntX XL\u00f0yti ; hat ; U T xti i\u00de \u00fe \u0002kAk22;1t2fT ;Sg i\u00bc1\u00f01\u00deds:t: U 2 O :In this equation, S and T denote the tasks in the sourcedomain and target domain, respectively. A \u00bc \u00bdaS ; aT \u0005 2 Rd\u00062is a matrix of parameters. U is a d \u0006 d orthogonal matrix(mapping function) for mapping the original high-dimensional data to low-dimensional representations.The1 \u00f0r; p\u00dePnorm of A is defined as kAkr;p :\u00bc \u00f0 di\u00bc1 kai kpr \u00dep . Theoptimization problem (1) estimates the low-dimensionalrepresentations U T XT , U T XS and the parameters, A, of themodel at the same time. The optimization problem (1) canbe further transformed into an equivalent convex optimization formulation and be solved efficiently. In a follow-upwork, Argyriou et al. [41] proposed a spectral regularizationframework on matrices for multitask structure learning.Lee et al. [42] proposed a convex optimization algorithmfor simultaneously learning metapriors and feature weightsfrom an ensemble of related prediction tasks. The metapriors can be transferred among different tasks. Jebara [43]proposed to select features for multitask learning withSVMs. Ru\u0308ckert and Kramer [54] designed a kernel-basedapproach to inductive transfer, which aims at finding asuitable kernel for the target data.3.23.2.1 Supervised Feature ConstructionSupervised feature construction methods for the inductivetransfer learning setting are similar to those used in multitasklearning. The basic idea is to learn a low-dimensionalrepresentation that is shared across related tasks. Inaddition, the learned new representation can reduce theclassification or regression model error of each task as well.Argyriou et al. [40] proposed a sparse feature learningmethod for multitask learning. In the inductive transfer3.2.2 Unsupervised Feature ConstructionIn [22], Raina et al. proposed to apply sparse coding [55],which is an unsupervised feature construction method, forlearning higher level features for transfer learning. The basicidea of this approach consists of two steps. In the first step,higher level basis vectors b \u00bc fb1 ; b2 ; . . . ; bs g are learned onthe source domain data by solving the optimizationproblem (2) as shown as follows:\u0002\u00022X \u0002X j \u0002\u0002 \u0002\u0002\u0002aSi bj \u0002 \u00fe \u0003 \u0002aSi \u00021min\u0002xSi \u0007\u0002\u0002a;b\u00f02\u00deij2s:t:kbj k2 \u0003 1;8j 2 1; . . . ; s:In this equation, ajSi is a new representation of basis bj forinput xSi and \u0003 is a coefficient to balance the featureconstruction term and the regularization term. After learningthe basis vectors b, in the second step, an optimizationalgorithm (3) is applied on the target-domain data to learnhigher level features based on the basis vectors b.\u0002\u00022\u0002X j \u0002\u0002 \u0002\u0002\u0002\baTi bj \u0002 \u00fe \u0003 \u0002aTi \u00021 :\u00f03\u00deaTi \u00bc arg min\u0002xTi \u0007\u0002\u0002aT ij2\fPAN AND YANG: A SURVEY ON TRANSFER LEARNINGFinally, discriminative algorithms can be applied to fa\bTi g0 swith corresponding labels to train classification or regression models for use in the target domain. One drawback ofthis method is that the so-called higher level basis vectorslearned on the source domain in the optimization problem(2) may not be suitable for use in the target domain.Recently, manifold learning methods have beenadapted for transfer learning. In [44], Wang and Mahadevan proposed a Procrustes analysis-based approach tomanifold alignment without correspondences, which canbe used to transfer the knowledge across domains via thealigned manifolds.3.3 Transferring Knowledge of ParametersMost parameter-transfer approaches to the inductive transferlearning setting assume that individual models for relatedtasks should share some parameters or prior distributionsof hyperparameters. Most approaches described in thissection, including a regularization framework and ahierarchical Bayesian framework, are designed to workunder multitask learning. However, they can be easilymodified for transfer learning. As mentioned above, multitask learning tries to learn both the source and target taskssimultaneously and perfectly, while transfer learning onlyaims at boosting the performance of the target domain byutilizing the source domain data. Thus, in multitasklearning, weights of the loss functions for the source andtarget data are the same. In contrast, in transfer learning,weights in the loss functions for different domains can bedifferent. Intuitively, we may assign a larger weight to theloss function of the target domain to make sure that we canachieve better performance in the target domain.Lawrence and Platt [45] proposed an efficient algorithmknown as MT-IVM, which is based on Gaussian Processes(GP), to handle the multitask learning case. MT-IVM tries tolearn parameters of a Gaussian Process over multiple tasksby sharing the same GP prior. Bonilla et al. [46] alsoinvestigated multitask learning in the context of GP. Theauthors proposed to use a free-form covariance matrix overtasks to model intertask dependencies, where a GP prior isused to induce correlations between tasks. Schwaighoferet al. [47] proposed to use a hierarchical Bayesian framework (HB) together with GP for multitask learning.Besides transferring the priors of the GP models, someresearchers also proposed to transfer parameters of SVMsunder a regularization framework. Evgeniou and Pontil [48]borrowed the idea of HB to SVMs for multitask learning.The proposed method assumed that the parameter, w, inSVMs for each task can be separated into two terms. One isa common term over tasks and the other is a task-specificterm. In inductive transfer learning,wS \u00bc w0 \u00fe vS and wT \u00bc w0 \u00fe vT ;where wS and wT are parameters of the SVMs for the sourcetask and the target learning task, respectively. w0 is acommon parameter while vS and vT are specific parametersfor the source task and the target task, respectively. Byassuming ft \u00bc wt \u0002 x to be a hyperplane for task t, anextension of SVMs to multitask learning case can be writtenas the following:1351minw0 ;vt ;\u0004ti\u00bcJ\u00f0w0 ; vt ; \u0004ti \u00dentX Xt2fS;T g i\u00bc1s:t:\u0004ti \u00fe\u00051 Xkvt k2 \u00fe \u00052 kw0 k22 t2fS;T g\u00f04\u00deyti \u00f0w0 \u00fe vt \u00de \u0002 xti 1 \u0007 \u0004ti ;\u0004ti 0; i 2 f1; 2; . . . ; nt g and t 2 fS; T g:By solving the optimization problem above, we can learnthe parameters w0 , vS , and vT simultaneously.Several researchers have pursued the parameter-transferapproach further. Gao et al. [49] proposed a locallyweighted ensemble learning framework to combine multiple models for transfer learning, where the weights aredynamically assigned according to a model\u2019s predictivepower on each test example in the target domain.3.4 Transferring Relational KnowledgeDifferent from other three contexts, the relational-knowledge-transfer approach deals with transfer learning problems in relational domains, where the data are non-i.i.d. andcan be represented by multiple relations, such as networkeddata and social network data. This approach does not assumethat the data drawn from each domain be independent andidentically distributed (i.i.d.) as traditionally assumed. Ittries to transfer the relationship among data from a sourcedomain to a target domain. In this context, statistical relationallearning techniques are proposed to solve these problems.Mihalkova et al. [50] proposed an algorithm TAMAR thattransfers relational knowledge with Markov Logic Networks (MLNs) across relational domains. MLNs [56] is apowerful formalism, which combines the compact expressiveness of first-order logic with flexibility of probability,for statistical relational learning. In MLNs, entities in arelational domain are represented by predicates and theirrelationships are represented in first-order logic. TAMAR ismotivated by the fact that if two domains are related to eachother, there may exist mappings to connect entities andtheir relationships from a source domain to a target domain.For example, a professor can be considered as playing asimilar role in an academic domain as a manager in anindustrial management domain. In addition, the relationship between a professor and his or her students is similarto the relationship between a manager and his or herworkers. Thus, there may exist a mapping from professor tomanager and a mapping from the professor-studentrelationship to the manager-worker relationship. In thisvein, TAMAR tries to use an MLN learned for a sourcedomain to aid in the learning of an MLN for a targetdomain. Basically, TAMAR is a two-stage algorithm. In thefirst step, a mapping is constructed from a source MLN tothe target domain based on weighted pseudo log-likelihoodmeasure (WPLL). In the second step, a revision is done forthe mapped structure in the target domain through theFORTE algorithm [57], which is an inductive logicprogramming (ILP) algorithm for revising first-ordertheories. The revised MLN can be used as a relationalmodel for inference or reasoning in the target domain.In the AAAI-2008 workshop on transfer learning forcomplex tasks,4 Mihalkova and Mooney [51] extended4. https://www.cs.utexas.edu/~mtaylor/AAAI08TL/.\f1352IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,TAMAR to the single-entity-centered setting of transferlearning, where only one entity in a target domain isavailable. Davis and Domingos [52] proposed an approachto transferring relational knowledge based on a form ofsecond-order Markov logic. The basic idea of the algorithmis to discover structural regularities in the source domain inthe form of Markov logic formulas with predicate variables,by instantiating these formulas with predicates from thetarget domain.4TRANSDUCTIVE TRANSFER LEARNINGThe term transductive transfer learning was first proposed byArnold et al. [58], where they required that the source andtarget tasks be the same, although the domains may bedifferent. On top of these conditions, they further requiredthat all unlabeled data in the target domain are available attraining time, but we believe that this condition can berelaxed; instead, in our definition of the transductive transferlearning setting, we only require that part of the unlabeledtarget data be seen at training time in order to obtain themarginal probability for the target data.Note that the word \u201ctransductive\u201d is used with severalmeanings. In the traditional machine learning setting,transductive learning [59] refers to the situation where alltest data are required to be seen at training time, and thatthe learned model cannot be reused for future data. Thus,when some new test data arrive, they must be classifiedtogether with all existing data. In our categorization oftransfer learning, in contrast, we use the term transductive toemphasize the concept that in this type of transfer learning,the tasks must be the same and there must be someunlabeled data available in the target domain.Definition 3 (Transductive Transfer Learning). Given asource domain DS and a corresponding learning task T S , atarget domain DT and a corresponding learning task T T ,transductive transfer learning aims to improve the learning ofthe target predictive function fT \u00f0\u0002\u00de in DT using the knowledge inDS and T S , where DS 6\u00bc DT and T S \u00bc T T . In addition, someunlabeled target-domain data must be available at training time.This definition covers the work of Arnold et al. [58], sincethe latter considered domain adaptation, where the differencelies between the marginal probability distributions ofsource and target data; i.e., the tasks are the same but thedomains are different.Similar to the traditional transductive learning setting,which aims to make the best use of the unlabeled test datafor learning, in our classification scheme under transductivetransfer learning, we also assume that some target-domainunlabeled data be given. In the above definition oftransductive transfer learning, the source and target tasksare the same, which implies that one can adapt thepredictive function learned in the source domain for usein the target domain through some unlabeled target-domaindata. As mentioned in Section 2.3, this setting can be split totwo cases: 1) The feature spaces between the source andtarget domains are different, X S 6\u00bc X T , and 2) the featurespaces between domains are the same, X S \u00bc X T , but themarginal probability distributions of the input data aredifferent, P \u00f0XS \u00de 6\u00bc P \u00f0XT \u00de. This is similar to the requirements in domain adaptation and sample selection bias.VOL. 22,NO. 10,OCTOBER 2010Most approaches described in the following sections arerelated to case 2 above.4.1 Transferring the Knowledge of InstancesMost instance-transfer approaches to the transductivetransfer learning setting are motivated by importancesampling. To see how importance-sampling-based methodsmay help in this setting, we first review the problem ofempirical risk minimization (ERM) [60]. In general, wemight want to learn the optimal parameters \u0006\b of the modelby minimizing the expected risk,\u0006\b \u00bc arg min EE\u00f0x;y\u00de2P \u00bdl\u00f0x; y; \u0006\u00de\u0005;\u00062\u0002where l\u00f0x; y; \u0006\u00de is a loss function that depends on theparameter \u0006. However, since it is hard to estimate theprobability distribution P , we choose to minimize the ERMinstead,\u0006\b \u00bc arg min\u00062\u0002n1X\u00bdl\u00f0xi ; yi ; \u0006\u00de\u0005;n i\u00bc1where n is size of the training data.In the transductive transfer learning setting, we want tolearn an optimal model for the target domain by minimizing the expected risk,XP \u00f0DT \u00del\u00f0x; y; \u0006\u00de:\u0006\b \u00bc arg min\u00062\u0002\u00f0x;y\u00de2DTHowever, since no labeled data in the target domain areobserved in training data, we have to learn a model fromthe source domain data instead. If P \u00f0DS \u00de \u00bc P \u00f0DT \u00de, then wemay simply learn the model by solving the followingoptimization problem for use in the target domain,X\u0006\b \u00bc arg minP \u00f0DS \u00del\u00f0x; y; \u0006\u00de:\u00062\u0002\u00f0x;y\u00de2DSOtherwise, when P \u00f0DS \u00de 6\u00bc P \u00f0DT \u00de, we need to modify theabove optimization problem to learn a model with highgeneralization ability for the target domain, as follows:\u0006\b \u00bc arg min\u00062\u0002arg min\u00062\u0002X P \u00f0DT \u00deP \u00f0DS \u00del\u00f0x; y; \u0006\u00deP \u00f0DS \u00de\u00f0x;y\u00de2DSnSXPT \u00f0xT ; yT \u00deii\u00bc1iPS \u00f0xSi ; ySi \u00de\u00f05\u00del\u00f0xSi ; ySi ; \u0006\u00de:Therefore, by adding different penalty values to each instanceP \u00f0x ;y \u00de\u00f0xSi ; ySi \u00de with the corresponding weight PTS \u00f0xSTi ;ySTi \u00de , we caniilearn a precise model for the target domain. Furthermore,since P \u00f0YT jXT \u00de \u00bc P \u00f0YS jXS \u00de. Thus, the difference betweenP \u00f0DS \u00de and P \u00f0DT \u00de is caused by P \u00f0XS \u00de and P \u00f0XT \u00de andPT \u00f0xTi ; yTi \u00de P \u00f0xSi \u00de\u00bc:PS \u00f0xSi ; ySi \u00de P \u00f0xTi \u00deP \u00f0x \u00deIf we can estimate P \u00f0xSTi \u00de for each instance, we can solve theitransductive transfer learning problems.P \u00f0x \u00deThere exist various ways to estimate P \u00f0xSTi \u00de . Zadrozny [24]iproposed to estimate the terms P \u00f0xSi \u00de and P \u00f0xTi \u00de independently by constructing simple classification problems.\fPAN AND YANG: A SURVEY ON TRANSFER LEARNING1353Fan et al. [35] further analyzed the problems by usingvarious classifiers to estimate the probability ratio. Huanget al. [32] proposed a kernel-mean matching (KMM)P \u00f0x \u00dealgorithm to learn P \u00f0xSTi \u00de directly by matching the meansibetween the source domain data and the target domain datain a reproducing-kernel Hilbert space (RKHS). KMM can berewritten as the following quadratic programming (QP)optimization problem.min\u0003s:t:1 T\u0003 K\u0003 \u0007 \u0007T \u00032\u0003\u0003nS\u0003X\u0003\u0003\u0003\u0003i 2 \u00bd0; B\u0005 and \u0003\u0003i \u0007 nS \u0003 \u0003 nS \b;\u0003 i\u00bc1\u0003\u00f06\u00dewhere\u0004K\u00bcKS;SKT ;SKS;TKT ;T\u0005and Kij \u00bc k\u00f0xi ; xj \u00de. KS;S and KT ;T are kernel matrices forthe source domain Pdata and the target domain Sdata,Tk\u00f0xi ; xTj \u00de, where xi 2 XS XT ,respectively. \u0007i \u00bc nnTS nj\u00bc1while xTj 2 XT .P \u00f0x \u00deIt can be proved that \u0003i \u00bc P \u00f0xSTi \u00de [32]. An advantage of usingiKMM is that it can avoid performing density estimation ofeither P \u00f0xSi \u00de or P \u00f0xTi \u00de, which is difficult when the size of thedata set is small. Sugiyama et al. [34] proposed an algorithmknown as Kullback-Leibler Importance Estimation ProceP \u00f0x \u00dedure (KLIEP) to estimate P \u00f0xSTi \u00de directly, based on theiminimization of the Kullback-Leibler divergence. can beintegrated with cross-validation to perform model selectionautomatically in two steps: 1) estimating the weights of thesource domain data and 2) training models on the reweighteddata. Bickel et al. [33] combined the two steps in a unifiedframework by deriving a kernel-logistic regression classifier.Besides sample reweighting techniques, Dai et al. [28]extended a traditional Naive Bayesian classifier for thetransductive transfer learning problems. For more information on importance sampling and reweighting methods forcovariate shift or sample selection bias, readers can refer to arecently published book [29] by Quionero-Candela et al. Onecan also consult a tutorial on Sample Selection Bias by Fanand Sugiyama in ICDM-08.54.2Transferring Knowledge of FeatureRepresentationsMost feature-representation-transfer approaches to thetransductive transfer learning setting are under unsupervised learning frameworks. Blitzer et al. [38] proposed astructural correspondence learning (SCL) algorithm, whichextends [37], to make use of the unlabeled data from thetarget domain to extract some relevant features that mayreduce the difference between the domains. The first step ofSCL is to define a set of pivot features6 (the number of pivotfeature is denoted by m) on the unlabeled data from both5. Tutorial slides can be found at https://www.cs.columbia.edu/~fan/PPT/ICDM08SampleBias.ppt.6. The pivot features are domain specific and depend on priorknowledge.domains. Then, SCL removes these pivot features from thedata and treats each pivot feature as a new label vector. Them classification problems can be constructed. By assumingeach problem can be solved by linear classifier, which isshown as follows:\u0006\u0007fl \u00f0x\u00de \u00bc sgn wTl \u0002 x ; l \u00bc 1; . . . ; m:SCL can learn a matrix W \u00bc \u00bdw1 w2 . . . wm \u0005 of parameters. Inthe third step, singular value decomposition (SVD) is appliedTto matrix W \u00bc \u00bdw1 w2 . . . wm \u0005. Let W \u00bc UDV T , then \u0006 \u00bc U\u00bd1:h;:\u0005(h is the number of the shared features) is the matrix (linearmapping) whose rows are the top left singular vectors of W .Finally, standard discriminative algorithms can be applied tothe augmented feature vector to build models. The augmented feature vector contains all the original feature xiappended with the new shared features \u0006xi . As mentionedin [38], if the pivot features are well designed, then thelearned mapping \u0006 encodes the correspondence between thefeatures from the different domains. Although Ben-Davidet al. [61] showed experimentally that SCL can reduce thedifference between domains; how to select the pivot featuresis difficult and domain dependent. In [38], Blitzer et al. used aheuristic method to select pivot features for natural languageprocessing (NLP) problems, such as tagging of sentences. Intheir follow-up work, the researchers proposed to useMutual Information (MI) to choose the pivot features insteadof using more heuristic criteria [8]. MI-SCL tries to find somepivot features that have high dependence on the labels in thesource domain.Transfer learning in the NLP domain is sometimesreferred to as domain adaptation. In this area, Daume\u0301 [39]proposed a kernel-mapping function for NLP problems,which maps the data from both source and target domains toa high-dimensional feature space, where standard discriminative learning methods are used to train the classifiers.However, the constructed kernel-mapping function isdomain knowledge driven. It is not easy to generalize thekernel mapping to other areas or applications. Blitzer et al.[62] analyzed the uniform convergence bounds for algorithms that minimized a convex combination of source andtarget empirical risks.In [36], Dai et al. proposed a coclustering-based algorithmto propagate the label information across different domains.In [63], Xing et al. proposed a novel algorithm known asbridged refinement to correct the labels predicted by a shiftunaware classifier toward a target distribution and take themixture distribution of the training and test data as a bridgeto better transfer from the training data to the test data. In[64], Ling et al. proposed a spectral classification frameworkfor cross-domain transfer learning problem, where theobjective function is introduced to seek consistency betweenthe in-domain supervision and the out-of-domain intrinsicstructure. In [65], Xue et al. proposed a cross-domain textclassification algorithm that extended the traditional probabilistic latent semantic analysis (PLSA) algorithm tointegrate labeled and unlabeled data from different butrelated domains, into a unified probabilistic model. The newmodel is called Topic-bridged PLSA, or TPLSA.Transfer learning via dimensionality reduction wasrecently proposed by Pan et al. [66]. In this work, Pan et al.exploited the Maximum Mean Discrepancy Embedding\f1354IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,(MMDE) method, originally designed for dimensionalityreduction, to learn a low-dimensional space to reduce thedifference of distributions between different domains fortransductive transfer learning. However, MMDE may sufferfrom its computational burden. Thus, in [67], Pan et al.further proposed an efficient feature extraction algorithm,known as Transfer Component Analysis (TCA) to overcomethe drawback of MMDE.5UNSUPERVISED TRANSFER LEARNINGDefinition 4 (Unsupervised Transfer Learning). Given asource domain DS with a learning task T S , a target domain DTand a corresponding learning task T T , unsupervised transferlearning aims to help improve the learning of the targetpredictive function fT \u00f0\u0002\u00de7 in DT using the knowledge in DS andT S , where T S 6\u00bc T T and Y S and Y T are not observable.Based on the definition of the unsupervised transferlearning setting, no labeled data are observed in the sourceand target domains in training. So far, there is little researchwork on this setting. Recently, Self-taught clustering (STC)[26] and transferred discriminative analysis (TDA) [27]algorithms are proposed to transfer clustering and transferdimensionality reduction problems, respectively.5.1Transferring Knowledge of FeatureRepresentationsDai et al. [26] studied a new case of clustering problems,known as self-taught clustering. Self-taught clustering is aninstance of unsupervised transfer learning, which aims atclustering a small collection of unlabeled data in thetarget domain with the help of a large amount ofunlabeled data in the source domain. STC tries to learna common feature space across domains, which helps inclustering in the target domain. The objective function ofSTC is shown as follows:~J\u00f0X~T ; X~S ; Z\u00de\b~ \u00fe \u0005 I\u00f0XS ; Z\u00de \u0007 I\u00f0X~S ; Z\u00de~ ;\u00bc I\u00f0XT ; Z\u00de \u0007 I\u00f0X~T ; Z\u00de\u00f07\u00dewhere XS and XT are the source and target domain data,respectively. Z is a shared feature space by XS and XT , andI\u00f0\u0002; \u0002\u00de is the mutual information between two randomvariables. Suppose that there exist three clustering functions~ whereCXT : XT ! X~T , CXS : XS ! X~S , and CZ : Z ! Z,~~~XT , XS , and Z are corresponding clusters of XT , XS , and Z,respectively. The goal of STC is to learn X~T by solving theoptimization problem (7):~arg min J\u00f0X~T ; X~S ; Z\u00de:\u00f08\u00deX~T ;X~S ;Z~An iterative algorithm for solving the optimization function(8) was given in [26].Similarly, Wang et al. [27] proposed a TDA algorithm tosolve the transfer dimensionality reduction problem. TDA firstapplies clustering methods to generate pseudoclass labelsfor the target unlabeled data. It then applies dimensionalityreduction methods to the target data and labeled source7. In unsupervised transfer learning, the predicted labels are latentvariables, such as clusters or reduced dimensions.VOL. 22,NO. 10,OCTOBER 2010data to reduce the dimensions. These two steps runiteratively to find the best subspace for the target data.6TRANSFER BOUNDS AND NEGATIVE TRANSFERAn important issue is to recognize the limit of the power oftransfer learning. In [68], Mahmud and Ray analyzed thecase of transfer learning using Kolmogorov complexity,where some theoretical bounds are proved. In particular,the authors used conditional Kolmogorov complexity tomeasure relatedness between tasks and transfer the \u201cright\u201damount of information in a sequential transfer learning taskunder a Bayesian framework.Recently, Eaton et al. [69] proposed a novel graph-basedmethod for knowledge transfer, where the relationshipsbetween source tasks are modeled by embedding the set oflearned source models in a graph using transferability as themetric. Transferring to a new task proceeds by mapping theproblem into the graph and then learning a function on thisgraph that automatically determines the parameters totransfer to the new learning task.Negative transfer happens when the source domain dataand task contribute to the reduced performance of learningin the target domain. Despite the fact that how to avoidnegative transfer is a very important issue, little researchwork has been published on this topic. Rosenstein et al. [70]empirically showed that if two tasks are too dissimilar, thenbrute-force transfer may hurt the performance of the targettask. Some works have been exploited to analyze relatedness among tasks and task clustering techniques, such as[71], [72], which may help provide guidance on how toavoid negative transfer automatically. Bakker and Heskes[72] adopted a Bayesian approach in which some of themodel parameters are shared for all tasks and others moreloosely connected through a joint prior distribution that canbe learned from the data. Thus, the data are clustered basedon the task parameters, where tasks in the same cluster aresupposed to be related to each other. Argyriou et al. [73]considered situations in which the learning tasks can bedivided into groups. Tasks within each group are related bysharing a low-dimensional representation, which differsamong different groups. As a result, tasks within a groupcan find it easier to transfer useful knowledge.7APPLICATIONS OF TRANSFER LEARNINGRecently, transfer learning techniques have been appliedsuccessfully in many real-world applications. Raina et al.[74] and Dai et al. [36], [28] proposed to use transferlearning techniques to learn text data across domains,respectively. Blitzer et al. [38] proposed to use SCL forsolving NLP problems. An extension of SCL was proposedin [8] for solving sentiment classification problems. Wu andDietterich [53] proposed to use both inadequate targetdomain data and plenty of low quality source domain datafor image classification problems. Arnold et al. [58]proposed to use transductive transfer learning methods tosolve name-entity recognition problems. In [75], [76], [77],[78], [79], transfer learning techniques are proposed toextract knowledge from WiFi localization models acrosstime periods, space, and mobile devices, to benefit WiFi\fPAN AND YANG: A SURVEY ON TRANSFER LEARNINGlocalization tasks in other settings. Zhuo et al. [80] studiedhow to transfer domain knowledge to learn relational actionmodels across domains in automated planning.In [81], Raykar et al. proposed a novel Bayesian multipleinstance learning algorithm, which can automatically identify the relevant feature subset and use inductive transfer forlearning multiple, but conceptually related, classifiers, forcomputer aided design (CAD). In [82], Ling et al. proposedan information-theoretic approach for transfer learning toaddress the cross-language classification problem for translatingwebpages from English to Chinese. The approach addressedthe problem when there are plenty of labeled English textdata whereas there are only a small number of labeledChinese text documents. Transfer learning across the twofeature spaces are achieved by designing a suitable mappingfunction as a bridge.So far, there are at least two international competitionsbased on transfer learning, which made available some muchneeded public data. In the ECML/PKDD-2006 discoverychallenge,8 the task was to handle personalized spamfiltering and generalization across related learning tasks.For training a spam-filtering system, we need to collect a lotof e-mails from a group of users with corresponding labels:spam or not spam, and train a classifier based on these data.For a new e-mail user, we might want to adapt the learnedmodel for the user. The challenge is that the distributions ofemails for the first set of users and the new user are different.Thus, this problem can be modeled as an inductive transferlearning problem, which aims to adapt an old spam-filteringmodel to a new situation with fewer training data and lesstraining time.A second data set was made available through theICDM-2007 Contest, in which a task was to estimate a WiFiclient\u2019s indoor locations using the WiFi signal data obtainedover different periods of time [83]. Since the values of WiFisignal strength may be a function of time, space, anddevices, distributions of WiFi data over different timeperiods may be very different. Thus, transfer learning mustbe designed to reduce the data relabeling effort.Data sets for transfer learning. So far, several data setshave been published for transfer learning research. Wedenote the text mining data sets, Email spam-filtering dataset, the WiFi localization over time periods data set, and theSentiment classification data set by Text, E-mail, WiFi, andSen, respectively.1.2.3.Text. Three data sets, 20 Newsgroups, SRAA, andReuters-21578,9 have been preprocessed for a transfer learning setting by some researchers. The data inthese data sets are categorized to a hierarchicalstructure. Data from different subcategories underthe same parent category are considered to be fromdifferent but related domains. The task is to predictthe labels of the parent category.E-mail. This data set is provided by the 2006 ECML/PKDD discovery challenge.WiFi. This data set is provided by the ICDM-2007Contest.10 The data were collected inside a building8. https://www.ecmlpkdd2006.org/challenge.html.9. https://apex.sjtu.edu.cn/apex_wiki/dwyak.10. https://www.cse.ust.hk/~qyang/ICDMDMC2007.1355for localization around 145:5 \u0006 37:5 m2 in twodifferent time periods.4. Sen. This data set was first used in [8].11 This dataset contains product reviews downloaded fromAmazon.com from four product types (domains):Kitchen, Books, DVDs, and Electronics. Eachdomain has several thousand reviews, but theexact number varies by domain. Reviews containstar ratings (1-5 stars).Empirical evaluation. To show how much benefittransfer learning methods can bring as compared totraditional learning methods, researchers have used somepublic data sets. We show a list taken from some publishedtransfer learning papers in Table 5. In [6], [84], [49], theauthors used the 20 Newsgroups data12 as one of theevaluation data sets. Due to the differences in the preprocessing steps of the algorithms by different researchers,it is hard to compare the proposed methods directly. Thus,we denote them by 20-Newsgroups1 , 20-Newsgroups2 , and20-Newsgroups3 , respectively, and show the comparisonresults between the proposed transfer learning methodsand nontransfer learning methods in the table.On the 20 Newsgroups1 data, Dai et al. [6] showed thecomparison experiments between standard SVM and theproposed TrAdaBoost algorithm. On 20 Newsgroups2 , Shiet al. [84] applied an active learning algorithm to selectimportant instances for transfer learning (AcTraK) withTrAdaBoost and standard SVM. Gao et al. [49] evaluatedtheir proposed locally weighted ensemble learning algorithms, pLWE and LWE, on the 20 Newsgroups3 , comparedto SVM and Logistic Regression (LR).In addition, in the table, we also show the comparisonresults on the sentiment classification data set reported in[8]. On this data set, SGD denotes the stochastic gradientdescent algorithm with Huber loss, SCL represents a linearpredictor on the new representations learned by StructuralCorrespondence Learning algorithm, and SCL-MI is anextension of SCL by applying Mutual Information to selectthe pivot features for the SCL algorithm.Finally, on the WiFi localization data set, we show thecomparison results reported in [67], where the baseline is aregularized least square regression model (RLSR), which isa standard regression model, and KPCA, which representsto apply RLSR on the new representations of the datalearned by Kernel Principle Component Analysis. Thecompared transfer learning methods include KMM andthe proposed algorithm, TCA. For more detail about theexperimental results, the readers may refer to the referencepapers showed in the table. From these comparison results,we can find that the transfer learning methods designedappropriately for real-world applications can indeed improve the performance significantly compared to thenontransfer learning methods.Toolboxes for transfer learning. Researchers at UCBerkeley provided a MATLAB toolkit for transfer learning.13 The toolkit contains algorithms and benchmark datasets for transfer learning. In addition, it provides a standard11. https://www.cis.upenn.edu/~mdredze/datasets/sentiment/.12. https://people.csail.mit.edu/jrennie/20Newsgroups/.13. https://multitask.cs.berkeley.edu/.\f1356IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,VOL. 22,NO. 10,OCTOBER 2010TABLE 5Comparison between Transfer Learning and Nontransfer Learning Methodsplatform for developing and testing new algorithms fortransfer learning.7.1 Other Applications of Transfer LearningTransfer learning has found many applications in sequential machine learning as well. For example, Kuhlmann andStone [85] proposed a graph-based method for identifyingpreviously encountered games, and applied this techniqueto automate domain mapping for value function transferand speed up reinforcement learning on variants ofpreviously played games. A new approach to transferbetween entirely different feature spaces is proposed intranslated learning, which is made possible by learning amapping function for bridging features in two entirelydifferent domains (images and text) [86]. Finally, Li et al.[87], [88] have applied transfer learning to collaborativefiltering problems to solve the cold start and sparsityproblems. In [87], Li et al. learned a shared rating-patternmixture model, known as a Rating-Matrix GenerativeModel (RMGM), in terms of the latent user- and itemcluster variables. RMGM bridges multiple rating matricesfrom different domains by mapping the users and items ineach rating matrix onto the shared latent user and itemspaces in order to transfer useful knowledge. In [88], theyapplied coclustering algorithms on users and items in anauxiliary rating matrix. They then constructed a clusterlevel rating matrix known as a codebook. By assuming thetarget rating matrix (on movies) is related to the auxiliaryone (on books), the target domain can be reconstructed byexpanding the codebook, completing the knowledge transfer process.8CONCLUSIONSIn this survey paper, we have reviewed several currenttrends of transfer learning. Transfer learning is classified tothree different settings: inductive transfer learning, transductive transfer learning, and unsupervised transfer learning. Most previous works focused on the former twosettings. Unsupervised transfer learning may attract moreand more attention in the future.Furthermore, each of the approaches to transfer learningcan be classified into four contexts based on \u201cwhat totransfer\u201d in learning. They include the instance-transferapproach, the feature-representation-transfer approach, theparameter-transfer approach, and the relational-knowledgetransfer approach, respectively. The former three contextshave an i.i.d. assumption on the data while the last contextdeals with transfer learning on relational data. Most of theseapproaches assume that the selected source domain isrelated to the target domain.\fPAN AND YANG: A SURVEY ON TRANSFER LEARNINGIn the future, several important research issues need to beaddressed. First, how to avoid negative transfer is an openproblem. As mentioned in Section 6, many proposed transferlearning algorithms assume that the source and targetdomains are related to each other in some sense. However,if the assumption does not hold, negative transfer mayhappen, which may cause the learner to perform worse thanno transferring at all. Thus, how to make sure that nonegative transfer happens is a crucial issue in transferlearning. In order to avoid negative transfer learning, weneed to first study transferability between source domains ortasks and target domains or tasks. Based on suitabletransferability measures, we can then select relevant sourcedomains or tasks to extract knowledge from for learning thetarget tasks. To define the transferability between domainsand tasks, we also need to define the criteria to measure thesimilarity between domains or tasks. Based on the distancemeasures, we can then cluster domains or tasks, which mayhelp measure transferability. A related issue is when anentire domain cannot be used for transfer learning, whetherwe can still transfer part of the domain for useful learning inthe target domain.In addition, most existing transfer learning algorithmsso far focused on improving generalization across different distributions between source and target domains ortasks. In doing so, they assumed that the feature spacesbetween the source and target domains are the same.However, in many applications, we may wish to transferknowledge across domains or tasks that have differentfeature spaces, and transfer from multiple such sourcedomains. We refer to this type of transfer learning asheterogeneous transfer learning.Finally, so far, transfer learning techniques have beenmainly applied to small scale applications with a limitedvariety, such as sensor-network-based localization, textclassification, and image classification problems. In thefuture, transfer learning techniques will be widely used tosolve other challenging applications, such as video classification, social network analysis, and logical inference.1357[6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21]ACKNOWLEDGMENTS[22]The authors thank the support of Hong Kong CERG Project621307 and a grant from NEC China Lab.[23]REFERENCES[24][1][25][2][3][4][5]X. Wu, V. Kumar, J.R. Quinlan, J. Ghosh, Q. Yang, H. Motoda, G.J.McLachlan, A.F.M. Ng, B. Liu, P.S. Yu, Z.-H. Zhou, M. Steinbach,D.J. Hand, and D. Steinberg, \u201cTop 10 Algorithms in Data Mining,\u201dKnowledge and Information Systems, vol. 14, no. 1, pp. 1-37, 2008.Q. Yang and X. Wu, \u201c10 Challenging Problems in Data MiningResearch,\u201d Int\u2019l J. Information Technology and Decision Making,vol. 5, no. 4, pp. 597-604, 2006.G.P.C. Fung, J.X. Yu, H. Lu, and P.S. Yu, \u201cText Classificationwithout Negative Examples Revisit,\u201d IEEE Trans. Knowledge andData Eng., vol. 18, no. 1, pp. 6-20, Jan. 2006.H. Al Mubaid and S.A. Umair, \u201cA New Text CategorizationTechnique Using Distributional Clustering and Learning Logic,\u201dIEEE Trans. Knowledge and Data Eng., vol. 18, no. 9, pp. 1156-1165,Sept. 2006.K. Sarinnapakorn and M. Kubat, \u201cCombining Subclassifiers inText Categorization: A DST-Based Solution and a Case Study,\u201dIEEE Trans. Knowledge and Data Eng., vol. 19, no. 12, pp. 1638-1651,Dec. 2007.[26][27][28][29][30]W. Dai, Q. Yang, G. Xue, and Y. Yu, \u201cBoosting for TransferLearning,\u201d Proc. 24th Int\u2019l Conf. Machine Learning, pp. 193-200, June2007.S.J. Pan, V.W. Zheng, Q. Yang, and D.H. Hu, \u201cTransfer Learningfor WiFi-Based Indoor Localization,\u201d Proc. Workshop TransferLearning for Complex Task of the 23rd Assoc. for the Advancement ofArtificial Intelligence (AAAI) Conf. Artificial Intelligence, July 2008.J. Blitzer, M. Dredze, and F. Pereira, \u201cBiographies, Bollywood,Boom-Boxes and Blenders: Domain Adaptation for SentimentClassification,\u201d Proc. 45th Ann. Meeting of the Assoc. ComputationalLinguistics, pp. 432-439, 2007.J. Ramon, K. Driessens, and T. Croonenborghs, \u201cTransferLearning in Reinforcement Learning Problems through PartialPolicy Recycling,\u201d Proc. 18th European Conf. Machine Learning(ECML \u201907), pp. 699-707, 2007.M.E. Taylor and P. Stone, \u201cCross-Domain Transfer for Reinforcement Learning,\u201d Proc. 24th Int\u2019l Conf. Machine Learning (ICML \u201907),pp. 879-886, 2007.X. Yin, J. Han, J. Yang, and P.S. Yu, \u201cEfficient Classification acrossMultiple Database Relations: A Crossmine Approach,\u201d IEEETrans. Knowledge and Data Eng., vol. 18, no. 6, pp. 770-783, June2006.L.I. Kuncheva and J.J. Rodr\u0142guez, \u201cClassifier Ensembles with aRandom Linear Oracle,\u201d IEEE Trans. Knowledge and Data Eng.,vol. 19, no. 4, pp. 500-508, Apr. 2007.E. Baralis, S. Chiusano, and P. Garza, \u201cA Lazy Approach toAssociative Classification,\u201d IEEE Trans. Knowledge and Data Eng.,vol. 20, no. 2, pp. 156-171, Feb. 2008.X. Zhu, \u201cSemi-Supervised Learning Literature Survey,\u201d TechnicalReport 1530, Univ. of Wisconsin-Madison, 2006.K. Nigam, A.K. McCallum, S. Thrun, and T. Mitchell, \u201cTextClassification from Labeled and Unlabeled Documents UsingEM,\u201d Machine Learning, vol. 39, nos. 2/3, pp. 103-134, 2000.A. Blum and T. Mitchell, \u201cCombining Labeled and UnlabeledData with Co-Training,\u201d Proc. 11th Ann. Conf. ComputationalLearning Theory, pp. 92-100, 1998.T. Joachims, \u201cTransductive Inference for Text Classification UsingSupport Vector Machines,\u201d Proc. 16th Int\u2019l Conf. Machine Learning,pp. 825-830, 1999.X. Zhu and X. Wu, \u201cClass Noise Handling for Effective CostSensitive Learning by Cost-Guided Iterative Classification Filtering,\u201d IEEE Trans. Knowledge and Data Eng., vol. 18, no. 10, pp. 14351440, Oct. 2006.Q. Yang, C. Ling, X. Chai, and R. Pan, \u201cTest-Cost SensitiveClassification on Data with Missing Values,\u201d IEEE Trans. Knowledge and Data Eng., vol. 18, no. 5, pp. 626-638, May 2006.Learning to Learn. S. Thrun and L. Pratt, eds. Kluwer AcademicPublishers, 1998.R. Caruana, \u201cMultitask Learning,\u201d Machine Learning, vol. 28, no. 1,pp. 41-75, 1997.R. Raina, A. Battle, H. Lee, B. Packer, and A.Y. Ng, \u201cSelf-TaughtLearning: Transfer Learning from Unlabeled Data,\u201d Proc. 24th Int\u2019lConf. Machine Learning, pp. 759-766, June 2007.H. Daume\u0301 III and D. Marcu, \u201cDomain Adaptation for StatisticalClassifiers,\u201d J. Artificial Intelligence Research, vol. 26, pp. 101-126,2006.B. Zadrozny, \u201cLearning and Evaluating Classifiers under SampleSelection Bias,\u201d Proc. 21st Int\u2019l Conf. Machine Learning, July 2004.H. Shimodaira, \u201cImproving Predictive Inference under CovariateShift by Weighting the Log-Likelihood Function,\u201d J. StatisticalPlanning and Inference, vol. 90, pp. 227-244, 2000.W. Dai, Q. Yang, G. Xue, and Y. Yu, \u201cSelf-Taught Clustering,\u201dProc. 25th Int\u2019l Conf. Machine Learning, pp. 200-207, July 2008.Z. Wang, Y. Song, and C. Zhang, \u201cTransferred DimensionalityReduction,\u201d Proc. European Conf. Machine Learning and KnowledgeDiscovery in Databases (ECML/PKDD \u201908), pp. 550-565, Sept. 2008.W. Dai, G. Xue, Q. Yang, and Y. Yu, \u201cTransferring Naive BayesClassifiers for Text Classification,\u201d Proc. 22nd Assoc. for theAdvancement of Artificial Intelligence (AAAI) Conf. Artificial Intelligence, pp. 540-545, July 2007.J. Quionero-Candela, M. Sugiyama, A. Schwaighofer, and N.D.Lawrence, Dataset Shift in Machine Learning. MIT Press, 2009.J. Jiang and C. Zhai, \u201cInstance Weighting for Domain Adaptationin NLP,\u201d Proc. 45th Ann. Meeting of the Assoc. ComputationalLinguistics, pp. 264-271, June 2007.\f1358IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,[31] X. Liao, Y. Xue, and L. Carin, \u201cLogistic Regression with anAuxiliary Data Source,\u201d Proc. 21st Int\u2019l Conf. Machine Learning,pp. 505-512, Aug. 2005.[32] J. Huang, A. Smola, A. Gretton, K.M. Borgwardt, and B.Scho\u0308lkopf, \u201cCorrecting Sample Selection Bias by Unlabeled Data,\u201dProc. 19th Ann. Conf. Neural Information Processing Systems, 2007.[33] S. Bickel, M. Bru\u0308ckner, and T. Scheffer, \u201cDiscriminative Learningfor Differing Training and Test Distributions,\u201d Proc. 24th Int\u2019l Conf.Machine Learning, pp. 81-88, 2007.[34] M. Sugiyama, S. Nakajima, H. Kashima, P.V. Buenau, and M.Kawanabe, \u201cDirect Importance Estimation with Model Selectionand its Application to Covariate Shift Adaptation,\u201d Proc. 20th Ann.Conf. Neural Information Processing Systems, Dec. 2008.[35] W. Fan, I. Davidson, B. Zadrozny, and P.S. Yu, \u201cAn ImprovedCategorization of Classifier\u2019s Sensitivity on Sample SelectionBias,\u201d Proc. Fifth IEEE Int\u2019l Conf. Data Mining, 2005.[36] W. Dai, G. Xue, Q. Yang, and Y. Yu, \u201cCo-Clustering BasedClassification for Out-of-Domain Documents,\u201d Proc. 13th ACMSIGKDD Int\u2019l Conf. Knowledge Discovery and Data Mining, Aug.2007.[37] R.K. Ando and T. Zhang, \u201cA High-Performance Semi-SupervisedLearning Method for Text Chunking,\u201d Proc. 43rd Ann. Meeting onAssoc. for Computational Linguistics, pp. 1-9, 2005.[38] J. Blitzer, R. McDonald, and F. Pereira, \u201cDomain Adaptation withStructural Correspondence Learning,\u201d Proc. Conf. Empirical Methods in Natural Language, pp. 120-128, July 2006.[39] H. Daume\u0301 III, \u201cFrustratingly Easy Domain Adaptation,\u201d Proc. 45thAnn. Meeting of the Assoc. Computational Linguistics, pp. 256-263,June 2007.[40] A. Argyriou, T. Evgeniou, and M. Pontil, \u201cMulti-Task FeatureLearning,\u201d Proc. 19th Ann. Conf. Neural Information ProcessingSystems, pp. 41-48, Dec. 2007.[41] A. Argyriou, C.A. Micchelli, M. Pontil, and Y. Ying, \u201cA SpectralRegularization Framework for Multi-Task Structure Learning,\u201dProc. 20th Ann. Conf. Neural Information Processing Systems, pp. 2532, 2008.[42] S.I. Lee, V. Chatalbashev, D. Vickrey, and D. Koller, \u201cLearning aMeta-Level Prior for Feature Relevance from Multiple RelatedTasks,\u201d Proc. 24th Int\u2019l Conf. Machine Learning, pp. 489-496, July2007.[43] T. Jebara, \u201cMulti-Task Feature and Kernel Selection for SVMs,\u201dProc. 21st Int\u2019l Conf. Machine Learning, July 2004.[44] C. Wang and S. Mahadevan, \u201cManifold Alignment UsingProcrustes Analysis,\u201d Proc. 25th Int\u2019l Conf. Machine Learning,pp. 1120-1127, July 2008.[45] N.D. Lawrence and J.C. Platt, \u201cLearning to Learn with theInformative Vector Machine,\u201d Proc. 21st Int\u2019l Conf. MachineLearning, July 2004.[46] E. Bonilla, K.M. Chai, and C. Williams, \u201cMulti-Task GaussianProcess Prediction,\u201d Proc. 20th Ann. Conf. Neural InformationProcessing Systems, pp. 153-160, 2008.[47] A. Schwaighofer, V. Tresp, and K. Yu, \u201cLearning Gaussian ProcessKernels via Hierarchical Bayes,\u201d Proc. 17th Ann. Conf. NeuralInformation Processing Systems, pp. 1209-1216, 2005.[48] T. Evgeniou and M. Pontil, \u201cRegularized Multi-Task Learning,\u201dProc. 10th ACM SIGKDD Int\u2019l Conf. Knowledge Discovery and DataMining, pp. 109-117, Aug. 2004.[49] J. Gao, W. Fan, J. Jiang, and J. Han, \u201cKnowledge Transfer viaMultiple Model Local Structure Mapping,\u201d Proc. 14th ACMSIGKDD Int\u2019l Conf. Knowledge Discovery and Data Mining,pp. 283-291, Aug. 2008.[50] L. Mihalkova, T. Huynh, and R.J. Mooney, \u201cMapping andRevising Markov Logic Networks for Transfer Learning,\u201d Proc.22nd Assoc. for the Advancement of Artificial Intelligence (AAAI) Conf.Artificial Intelligence, pp. 608-614, July 2007.[51] L. Mihalkova and R.J. Mooney, \u201cTransfer Learning by Mappingwith Minimal Target Data,\u201d Proc. Assoc. for the Advancement ofArtificial Intelligence (AAAI \u201908) Workshop Transfer Learning forComplex Tasks, July 2008.[52] J. Davis and P. Domingos, \u201cDeep Transfer via Second-OrderMarkov Logic,\u201d Proc. Assoc. for the Advancement of ArtificialIntelligence (AAAI \u201908) Workshop Transfer Learning for ComplexTasks, July 2008.[53] P. Wu and T.G. Dietterich, \u201cImproving SVM Accuracy by Trainingon Auxiliary Data Sources,\u201d Proc. 21st Int\u2019l Conf. Machine Learning,July 2004.VOL. 22,NO. 10,OCTOBER 2010[54] U. Ru\u0308ckert and S. Kramer, \u201cKernel-Based Inductive Transfer,\u201dProc. European Conf. Machine Learning and Knowledge Discovery inDatabases (ECML/PKDD \u201908), pp. 220-233, Sept. 2008.[55] H. Lee, A. Battle, R. Raina, and A.Y. Ng, \u201cEfficient Sparse CodingAlgorithms,\u201d Proc. 19th Ann. Conf. Neural Information ProcessingSystems, pp. 801-808, 2007.[56] M. Richardson and P. Domingos, \u201cMarkov Logic Networks,\u201dMachine Learning J., vol. 62, nos. 1/2, pp. 107-136, 2006.[57] S. Ramachandran and R.J. Mooney, \u201cTheory Refinement ofBayesian Networks with Hidden Variables,\u201d Proc. 14th Int\u2019l Conf.Machine Learning, pp. 454-462, July 1998.[58] A. Arnold, R. Nallapati, and W.W. Cohen, \u201cA Comparative Studyof Methods for Transductive Transfer Learning,\u201d Proc. SeventhIEEE Int\u2019l Conf. Data Mining Workshops, pp. 77-82, 2007.[59] T. Joachims, \u201cTransductive Inference for Text Classification UsingSupport Vector Machines,\u201d Proc. 16th Int\u2019l Conf. Machine Learning,pp. 200-209, 1999.[60] V.N. Vapnik, Statistical Learning Theory. Wiley Interscience, Sept.1998.[61] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira, \u201cAnalysis ofRepresentations for Domain Adaptation,\u201d Proc. 20th Ann. Conf.Neural Information Processing Systems, pp. 137-144, 2007.[62] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. Wortman,\u201cLearning Bounds for Domain Adaptation,\u201d Proc. 21st Ann. Conf.Neural Information Processing Systems, pp. 129-136, 2008.[63] D. Xing, W. Dai, G.-R. Xue, and Y. Yu, \u201cBridged Refinement forTransfer Learning,\u201d Proc. 11th European Conf. Principles and Practiceof Knowledge Discovery in Databases, pp. 324-335, Sept. 2007.[64] X. Ling, W. Dai, G.-R. Xue, Q. Yang, and Y. Yu, \u201cSpectral DomainTransfer Learning,\u201d Proc. 14th ACM SIGKDD Int\u2019l Conf. KnowledgeDiscovery and Data Mining, pp. 488-496, Aug. 2008.[65] G.-R. Xue, W. Dai, Q. Yang, and Y. Yu, \u201cTopic-Bridged PLSA forCross-Domain Text Classification,\u201d Proc. 31st Ann. Int\u2019l ACMSIGIR Conf. Research and Development in Information Retrieval,pp. 627-634, July 2008.[66] S.J. Pan, J.T. Kwok, and Q. Yang, \u201cTransfer Learning viaDimensionality Reduction,\u201d Proc. 23rd Assoc. for the Advancementof Artificial Intelligence (AAAI) Conf. Artificial Intelligence, pp. 677682, July 2008.[67] S.J. Pan, I.W. Tsang, J.T. Kwok, and Q. Yang, \u201cDomain Adaptationvia Transfer Component Analysis,\u201d Proc. 21st Int\u2019l Joint Conf.Artificial Intelligence, 2009.[68] M.M.H. Mahmud and S.R. Ray, \u201cTransfer Learning UsingKolmogorov Complexity: Basic Theory and Empirical Evaluations,\u201d Proc. 20th Ann. Conf. Neural Information Processing Systems,pp. 985-992, 2008.[69] E. Eaton, M. desJardins, and T. Lane, \u201cModeling TransferRelationships between Learning Tasks for Improved InductiveTransfer,\u201d Proc. European Conf. Machine Learning and KnowledgeDiscovery in Databases (ECML/PKDD \u201908), pp. 317-332, Sept. 2008.[70] M.T. Rosenstein, Z. Marx, and L.P. Kaelbling, \u201cTo Transfer or Notto Transfer,\u201d Proc. Conf. Neural Information Processing Systems(NIPS \u201905) Workshop Inductive Transfer: 10 Years Later, Dec. 2005.[71] S. Ben-David and R. Schuller, \u201cExploiting Task Relatedness forMultiple Task Learning,\u201d Proc. 16th Ann. Conf. Learning Theory,pp. 825-830, 2003.[72] B. Bakker and T. Heskes, \u201cTask Clustering and Gating forBayesian Multitask Learning,\u201d J. Machine Learning Research,vol. 4, pp. 83-99, 2003.[73] A. Argyriou, A. Maurer, and M. Pontil, \u201cAn Algorithm forTransfer Learning in a Heterogeneous Environment,\u201d Proc.European Conf. Machine Learning and Knowledge Discovery inDatabases (ECML/PKDD \u201908), pp. 71-85, Sept. 2008.[74] R. Raina, A.Y. Ng, and D. Koller, \u201cConstructing Informative PriorsUsing Transfer Learning,\u201d Proc. 23rd Int\u2019l Conf. Machine Learning,pp. 713-720, June 2006.[75] J. Yin, Q. Yang, and L.M. Ni, \u201cAdaptive Temporal Radio Maps forIndoor Location Estimation,\u201d Proc. Third IEEE Int\u2019l Conf. PervasiveComputing and Comm., Mar. 2005.[76] S.J. Pan, J.T. Kwok, Q. Yang, and J.J. Pan, \u201cAdaptive Localizationin a Dynamic WiFi Environment through Multi-View Learning,\u201dProc. 22nd Assoc. for the Advancement of Artificial Intelligence (AAAI)Conf. Artificial Intelligence, pp. 1108-1113, July 2007.[77] V.W. Zheng, Q. Yang, W. Xiang, and D. Shen, \u201cTransferringLocalization Models over Time,\u201d Proc. 23rd Assoc. for theAdvancement of Artificial Intelligence (AAAI) Conf. Artificial Intelligence, pp. 1421-1426, July 2008.\fPAN AND YANG: A SURVEY ON TRANSFER LEARNING[78] S.J. Pan, D. Shen, Q. Yang, and J.T. Kwok, \u201cTransferringLocalization Models across Space,\u201d Proc. 23rd Assoc. for theAdvancement of Artificial Intelligence (AAAI) Conf. Artificial Intelligence, pp. 1383-1388, July 2008.[79] V.W. Zheng, S.J. Pan, Q. Yang, and J.J. Pan, \u201cTransferring MultiDevice Localization Models Using Latent Multi-Task Learning,\u201dProc. 23rd Assoc. for the Advancement of Artificial Intelligence (AAAI)Conf. Artificial Intelligence, pp. 1427-1432, July 2008.[80] H. Zhuo, Q. Yang, D.H. Hu, and L. Li, \u201cTransferring Knowledgefrom Another Domain for Learning Action Models,\u201d Proc. 10thPacific Rim Int\u2019l Conf. Artificial Intelligence, Dec. 2008.[81] V.C. Raykar, B. Krishnapuram, J. Bi, M. Dundar, and R.B. Rao,\u201cBayesian Multiple Instance Learning: Automatic Feature Selection and Inductive Transfer,\u201d Proc. 25th Int\u2019l Conf. MachineLearning, pp. 808-815, July 2008.[82] X. Ling, G.-R. Xue, W. Dai, Y. Jiang, Q. Yang, and Y. Yu, \u201cCanChinese Web Pages be Classified with English Data Source?\u201d Proc.17th Int\u2019l Conf. World Wide Web, pp. 969-978, Apr. 2008.[83] Q. Yang, S.J. Pan, and V.W. Zheng, \u201cEstimating Location UsingWi-Fi,\u201d IEEE Intelligent Systems, vol. 23, no. 1, pp. 8-13, Jan./Feb.2008.[84] X. Shi, W. Fan, and J. Ren, \u201cActively Transfer Domain Knowledge,\u201d Proc. European Conf. Machine Learning and KnowledgeDiscovery in Databases (ECML/PKDD \u201908), pp. 342-357, Sept. 2008.[85] G. Kuhlmann and P. Stone, \u201cGraph-Based Domain Mapping forTransfer Learning in General Games,\u201d Proc. 18th European Conf.Machine Learning, pp. 188-200, Sept. 2007.[86] W. Dai, Y. Chen, G.-R. Xue, Q. Yang, and Y. Yu, \u201cTranslatedLearning,\u201d Proc. 21st Ann. Conf. Neural Information ProcessingSystems, 2008.[87] B. Li, Q. Yang, and X. Xue, \u201cTransfer Learning for CollaborativeFiltering via a Rating-Matrix Generative Model,\u201d Proc. 26th Int\u2019lConf. Machine Learning, June 2009.[88] B. Li, Q. Yang, and X. Xue, \u201cCan Movies and Books Collaborate?Cross-Domain Collaborative Filtering for Sparsity Reduction,\u201dProc. 21st Int\u2019l Joint Conf. Artificial Intelligence, July 2009.1359Sinno Jialin Pan received the MS and BSdegrees from the Applied Mathematics Department, Sun Yat-sen University, China, in 2003and 2005, respectively. He is a PhD candidate inthe Department of Computer Science andEngineering, the Hong Kong University ofScience and Technology. His research interestsinclude transfer learning, semisupervised learning, and their applications in pervasive computing and Web mining. He is a member of theAAAI. More details about his research and background can be found athttps://www.cse.ust.hk/~sinnopan.Qiang Yang received the bachelor\u2019s degreefrom Peking University in astrophysics andthe PhD degree in computer science from theUniversity of Maryland, College Park. He is afaculty member in Hong Kong University ofScience and Technology\u2019s Department ofComputer Science and Engineering. His research interests are data mining and machinelearning, AI planning, and sensor-based activity recognition. He is a fellow of the IEEE, amember of the AAAI and the ACM, a former associate editor for theIEEE Transactions on Knowledge and Data Engineering, and acurrent associate editor for the IEEE Intelligent Systems. Moredetails about his research and background can be found at https://www.cse.ust.hk/~qyang.. For more information on this or any other computing topic,please visit our Digital Library at www.computer.org/publications/dlib.\f", "640IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 39,NO. 4,APRIL 2017Fully Convolutional Networksfor Semantic SegmentationEvan Shelhamer, Jonathan Long, and Trevor Darrell, Member, IEEEAbstract\u2014Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networksby themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is tobuild \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inferenceand learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks,and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) intofully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skiparchitecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer toproduce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC(30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth ofa second for a typical image.Index Terms\u2014Semantic Segmentation, Convolutional Networks, Deep Learning, Transfer Learning\u00c71INTRODUCTIONCnetworks are driving advances in recognition. Convnets are not only improving for wholeimage classification [1], [2], [3], but also making progress onlocal tasks with structured output. These include advancesin bounding box object detection [4], [5], [6], part and keypoint prediction [7], [8], and local correspondence [8], [9].The natural next step in the progression from coarse tofine inference is to make a prediction at every pixel. Priorapproaches have used convnets for semantic segmentation[10], [11], [12], [13], [14], [15], [16], in which each pixel islabeled with the class of its enclosing object or region, butwith shortcomings that this work addresses.We show that fully convolutional networks (FCNs) trainedend-to-end, pixels-to-pixels on semantic segmentation exceedthe previous best results without further machinery. To ourknowledge, this is the first work to train FCNs end-to-end (1)for pixelwise prediction and (2) from supervised pre-training.Fully convolutional versions of existing networks predictdense outputs from arbitrary-sized inputs. Both learning andinference are performed whole-image-at-a-time by densefeedforward computation and backpropagation, as shown inFig. 1. In-network upsampling layers enable pixelwise prediction and learning in nets with subsampling.This method is efficient, both asymptotically and absolutely, and precludes the need for the complications in other\u0001ONVOLUTIONALThe authors are with the Department of Electrical Engineering and ComputerScience (CS Division), University of California, Berkeley, CA 94704-7000,USA. E-mail: {shelhamer, jonlong, trevor}@cs.berkeley.edu.Manuscript received 6 Feb. 2016; revised 5 May 2016; accepted 9 May 2016.Date of publication 23 May 2016; date of current version 2 Mar. 2017.Recommended for acceptance by K. Grauman, A. Torralba, E. Learned-Miller,and A. Zisserman.For information on obtaining reprints of this article, please send e-mail to:reprints@ieee.org, and reference the Digital Object Identifier below.Digital Object Identifier no. 10.1109/TPAMI.2016.2572683works. Patchwise training is common [10], [11], [12], [13],[16], but lacks the efficiency of fully convolutional training.Our approach does not make use of pre- and post-processingcomplications, including superpixels [12], [14], proposals[14], [15], or post-hoc refinement by random fields or localclassifiers [12], [14]. Our model transfers recent success inclassification [1], [2], [3] to dense prediction by reinterpretingclassification nets as fully convolutional and fine-tuningfrom their learned representations. In contrast, previousworks have applied small convnets without supervised pretraining [10], [12], [13].Semantic segmentation faces an inherent tension betweensemantics and location: global information resolves whatwhile local information resolves where. What can be done tonavigate this spectrum from location to semantics? How canlocal decisions respect global structure? It is not immediatelyclear that deep networks for image classification yield representations sufficient for accurate, pixelwise recognition.In the conference version of this paper [17], we cast pretrained networks into fully convolutional form, and augmentthem with a skip architecture that takes advantage of the fullfeature spectrum. The skip architecture fuses the featurehierarchy to combine deep, coarse, semantic informationand shallow, fine, appearance information (see Section 4.3and Fig. 3). In this light, deep feature hierarchies encode location and semantics in a nonlinear local-to-global pyramid.This journal paper extends our earlier work [17] throughfurther tuning, analysis, and more results. Alternativechoices, ablations, and implementation details better coverthe space of FCNs. Tuning optimization leads to more accurate networks and a means to learn skip architectures all-atonce instead of in stages. Experiments that mask foregroundand background investigate the role of context and shape.Results on the object and scene labeling of PASCAL-Context0162-8828 \u00df 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fSHELHAMER ET AL.: FULLY CONVOLUTIONAL NETWORKS FOR SEMANTIC SEGMENTATION641et al. [12], and Pinheiro and Collobert [13]; boundary prediction for electron microscopy by Ciresan et al. [11] and fornatural images by a hybrid convnet/nearest neighbormodel by Ganin and Lempitsky [16]; and image restorationand depth estimation by Eigen et al. [23], [25]. Common elements of these approaches include\u0001\u0001\u0001Fig. 1. Fully convolutional networks can efficiently learn to make densepredictions for per-pixel tasks like semantic segmentation.reinforce merging object segmentation and scene parsing asunified pixelwise prediction.In the next section, we review related work on deepclassification nets, FCNs, recent approaches to semantic segmentation using convnets, and extensions to FCNs. The following sections explain FCN design, introduce ourarchitecture with in-network upsampling and skip layers,and describe our experimental framework. Next, we demonstrate improved accuracy on PASCAL VOC 2011-2, NYUDv2,SIFT Flow, and PASCAL-Context. Finally, we analyze designchoices, examine what cues can be learned by an FCN, andcalculate recognition bounds for semantic segmentation.2RELATED WORKOur approach draws on recent successes of deep nets forimage classification [1], [2], [3] and transfer learning [18],[19]. Transfer was first demonstrated on various visual recognition tasks [18], [19], then on detection, and on bothinstance and semantic segmentation in hybrid proposalclassifier models [5], [14], [15]. We now re-architect andfine-tune classification nets to direct, dense prediction ofsemantic segmentation. We chart the space of FCNs andrelate prior models both historical and recent.Fully convolutional networks. To our knowledge, theidea of extending a convnet to arbitrary-sized inputs firstappeared in Matan et al. [20], which extended the classicLeNet [21] to recognize strings of digits. Because their netwas limited to one-dimensional input strings, Matan et al.used Viterbi decoding to obtain their outputs. Wolf andPlatt [22] expand convnet outputs to two-dimensional mapsof detection scores for the four corners of postal addressblocks. Both of these historical works do inference andlearning fully convolutionally for detection. Ning et al. [10]define a convnet for coarse multiclass segmentation of C.elegans tissues with fully convolutional inference.Fully convolutional computation has also been exploited inthe present era of many-layered nets. Sliding window detection by Sermanet et al. [4], semantic segmentation by Pinheiroand Collobert [13], and image restoration by Eigen et al. [23]do fully convolutional inference. Fully convolutional trainingis rare, but used effectively by Tompson et al. [24] to learn anend-to-end part detector and spatial model for pose estimation, although they do not exposit on or analyze this method.Dense prediction with convnets. Several recent workshave applied convnets to dense prediction problems,including semantic segmentation by Ning et al. [10], Farabetsmall models restricting capacity and receptive fields;patchwise training [10], [11], [12], [13], [16];refinement by superpixel projection, random fieldregularization, filtering, or local classification [11],[12], [16];\u0001 \u201cinterlacing\u201d to obtain dense output [4], [13], [16];\u0001 multi-scale pyramid processing [12], [13], [16];\u0001 saturating tanh nonlinearities [12], [13], [23]; and\u0001 ensembles [11], [16],whereas our method does without this machinery. However, wedo study patchwise training (Section 3.4) and \u201cshift-and-stitch\u201ddense output (Section 3.2) from the perspective of FCNs. Wealso discuss in-network upsampling (Section 3.3), of which thefully connected prediction by Eigen et al. [25] is a special case.Unlike these existing methods, we adapt and extenddeep classification architectures, using image classificationas supervised pre-training, and fine-tune fully convolutionally to learn simply and efficiently from whole image inputsand whole image ground thruths.Hariharan et al. [14] and Gupta et al. [15] likewise adaptdeep classification nets to semantic segmentation, but do soin hybrid proposal-classifier models. These approachesfine-tune an R-CNN system [5] by sampling boundingboxes and/or region proposals for detection, semantic segmentation, and instance segmentation. Neither method islearned end-to-end. They achieve the previous best segmentation results on PASCAL VOC and NYUDv2 respectively,so we directly compare our standalone, end-to-end FCN totheir semantic segmentation results in Section 5.Combining feature hierarchies. We fuse features acrosslayers to define a nonlinear local-to-global representationthat we tune end-to-end. The Laplacian pyramid [26] is aclassic multi-scale representation made of fixed smoothingand differencing. The jet of Koenderink and van Doorn [27]is a rich, local feature defined by compositions of partialderivatives. In the context of deep networks, Sermanet et al.[28] fuse intermediate layers but discard resolution in doingso. In contemporary work Hariharan et al. [29] andMostajabi et al. [30] also fuse multiple layers but do notlearn end-to-end and rely on fixed bottom-up grouping.FCN extensions. Following the conference version of thispaper [17], FCNs have been extended to new tasks and data.Tasks include region proposals [31], contour detection [32],depth regression [33], optical flow [34], and weakly-supervised semantic segmentation [35], [36], [37], [38].In addition, new works have improved the FCNs presented here to further advance the state-of-the-art in semantic segmentation. The DeepLab models [39] raise outputresolution by dilated convolution and dense CRF inference.The joint CRFasRNN [40] model is an end-to-end integration of the CRF for further improvement. ParseNet [41]normalizes features for fusion and captures context withglobal pooling. The \u201cdeconvolutional network\u201d approach of[42] restores resolution by proposals, stacks of learned\f642IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 39,NO. 4,APRIL 2017deconvolution, and unpooling. U-Net [43] combines skiplayers and learned deconvolution for pixel labeling ofmicroscopy images. The dilation architecture of [44] makesthorough use of dilated convolution for pixel-precise outputwithout a random field or skip layers.3FULLY CONVOLUTIONAL NETWORKSEach layer output in a convnet is a three-dimensionalarray of size h \u0003 w \u0003 d, where h and w are spatial dimensions, and d is the feature or channel dimension. The firstlayer is the image, with pixel size h \u0003 w, and d channels.Locations in higher layers correspond to the locations inthe image they are path-connected to, which are calledtheir receptive fields.Convnets are inherently translation invariant. Their basiccomponents (convolution, pooling, and activation functions) operate on local input regions, and depend only onrelative spatial coordinates. Writing xij for the data vector atlocation \u00f0i; j\u00de in a particular layer, and yij for the followinglayer, these functions compute outputs yij byyij \u00bc fks\u0001\u0003fxsi\u00fedi;sj\u00fedj g0\u0004di;dj < k ;where k is called the kernel size, s is the stride or subsampling factor, and fks determines the layer type: a matrixmultiplication for convolution or average pooling, a spatialmax for max pooling, or an elementwise nonlinearity for anactivation function, and so on for other types of layers.This functional form is maintained under composition,with kernel size and stride obeying the transformation rulefks \u0005 gk0 s0 \u00bc \u00f0f \u0005 g\u00dek0 \u00fe\u00f0k\u00061\u00des0 ;ss0 :While a general net computes a general nonlinear function,a net with only layers of this form computes a nonlinear filter, which we call a deep filter or fully convolutional network.An FCN naturally operates on an input of any size, and produces an output of corresponding (possibly resampled) spatial dimensions.A real-valued loss function composed with an FCNdefines a task. If the loss function is a sum Pover the spatialdimensions of the final layer, \u2018\u00f0x; u\u00de \u00bc ij \u20180 \u00f0xij ; u\u00de, itsparameter gradient will be a sum over the parameter gradients of each of its spatial components. Thus stochastic gradient descent on \u2018 computed on whole images will be thesame as stochastic gradient descent on \u20180 , taking all of thefinal layer receptive fields as a minibatch.When these receptive fields overlap significantly, bothfeedforward computation and backpropagation are muchmore efficient when computed layer-by-layer over an entireimage instead of independently patch-by-patch.We next explain how to convert classification nets intofully convolutional nets that produce coarse output maps.For pixelwise prediction, we need to connect these coarseoutputs back to the pixels. Section 3.2 describes a trickused for this purpose (e.g., by \u201cfast scanning\u201d [45]). Weexplain this trick in terms of network modification. As anefficient, effective alternative, we upsample in Section 3.3,reusing our implementation of convolution. In Section 3.4we consider training by patchwise sampling, and giveFig. 2. Transforming fully connected layers into convolution layers enables a classification net to output a spatial map. Adding differentiableinterpolation layers and a spatial loss (as in Fig. 1) produces an efficientmachine for end-to-end pixelwise learning.evidence in Section 4.4 that our whole image training isfaster and equally effective.3.1 Adapting Classifiers for Dense PredictionTypical recognition nets, including LeNet [21], AlexNet [1],and its deeper successors [2], [3], ostensibly take fixed-sizedinputs and produce non-spatial outputs. The fully connectedlayers of these nets have fixed dimensions and throw awayspatial coordinates. However, fully connected layers can alsobe viewed as convolutions with kernels that cover their entireinput regions. Doing so casts these nets into fully convolutional networks that take input of any size and make spatialoutput maps. This transformation is illustrated in Fig. 2.Furthermore, while the resulting maps are equivalent tothe evaluation of the original net on particular inputpatches, the computation is highly amortized over theoverlapping regions of those patches. For example, whileAlexNet takes 1:2 ms (on a typical GPU) to infer the classification scores of a 227 \u0003 227 image, the fully convolutionalnet takes 22 ms to produce a 10 \u0003 10 grid of outputs from a500 \u0003 500 image, which is more than 5 times faster than thena\u20ac\u0131ve approach.1The spatial output maps of these convolutionalized models make them a natural choice for dense problems likesemantic segmentation. With ground truth available atevery output cell, both the forward and backward passesare straightforward, and both take advantage of the inherent computational efficiency (and aggressive optimization)of convolution. The corresponding backward times for theAlexNet example are 2:4 ms for a single image and 37 msfor a fully convolutional 10 \u0003 10 output map, resulting in aspeedup similar to that of the forward pass.While our reinterpretation of classification nets as fullyconvolutional yields output maps for inputs of any size, theoutput dimensions are typically reduced by subsampling.The classification nets subsample to keep filters small andcomputational requirements reasonable. This coarsens theoutput of a fully convolutional version of these nets, reducing it from the size of the input by a factor equal to the pixelstride of the receptive fields of the output units.1. Assuming efficient batching of single image inputs. The classification scores for a single image by itself take 5.4 ms to produce, which isnearly 25 times slower than the fully convolutional version.\fSHELHAMER ET AL.: FULLY CONVOLUTIONAL NETWORKS FOR SEMANTIC SEGMENTATION3.2 Shift-and-Stitch Is Filter DilationDense predictions can be obtained from coarse outputs bystitching together outputs from shifted versions of theinput. If the output is downsampled by a factor of f, shiftthe input x pixels to the right and y pixels down, once forevery \u00f0x; y\u00de such that 0 \u0004 x; y < f. Process each of these f 2inputs, and interlace the outputs so that the predictions correspond to the pixels at the centers of their receptive fields.Although this transformation na\u20ac\u0131vely increases the cost bya factor of f 2 , there is a well-known trick for efficiently producing identical results [4], [45]. (This trick is also used in thealgorithme \u0002a trous [46], [47] for wavelet transforms andrelated to the Noble identities [48] from signal processing.)Consider a layer (convolution or pooling) with inputstride s, and a subsequent convolution layer with filterweights fij (eliding the irrelevant feature dimensions). Setting the earlier layer\u2019s input stride to one upsamples its output by a factor of s. However, convolving the original filterwith the upsampled output does not produce the sameresult as shift-and-stitch, because the original filter only seesa reduced portion of its (now upsampled) input. To producethe same result, dilate (or \u201crarefy\u201d) the filter by formingfij0\u0004\u00bcfi=s;j=s0if s divides both i and j;otherwise(with i and j zero-based). Reproducing the full net output ofshift-and-stitch involves repeating this filter enlargementlayer-by-layer until all subsampling is removed. (In practice, this can be done efficiently by processing subsampledversions of the upsampled input.)Simply decreasing subsampling within a net is a tradeoff:the filters see finer information, but have smaller receptivefields and take longer to compute. This dilation trick isanother kind of tradeoff: the output is denser withoutdecreasing the receptive field sizes of the filters, but the filters are prohibited from accessing information at a finerscale than their original design.Although we have done preliminary experiments withdilation, we do not use it in our model. We find learningthrough upsampling, as described in the next section, to beeffective and efficient, especially when combined with theskip layer fusion described later on. For further detailregarding dilation, refer to the dilated FCN of [44].3.3Upsampling Is (Fractionally Strided)ConvolutionAnother way to connect coarse outputs to dense pixels isinterpolation. For instance, simple bilinear interpolationcomputes each output yij from the nearest four inputs by alinear map that depends only on the relative positions ofthe input and output cells:yij \u00bc1Xj1 \u0006 a \u0006 fi=fgj j1 \u0006 b \u0006 fj=fgj xbi=fc\u00fea;bj=fc\u00feb ;a;b\u00bc0where f is the upsampling factor, and f\u0007g denotes the fractional part.In a sense, upsampling with factor f is convolution witha fractional input stride of 1=f. So long as f is integral, it\u2019snatural to implement upsampling through \u201cbackward643convolution\u201d by reversing the forward and backwardpasses of more typical input-strided convolution. Thusupsampling is performed in-network for end-to-end learning by backpropagation from the pixelwise loss.Per their use in deconvolution networks (esp. [19]), these(convolution) layers are sometimes referred to as deconvolution layers. Note that the convolution filter in such a layerneed not be fixed (e.g., to bilinear upsampling), but can belearned. A stack of deconvolution layers and activationfunctions can even learn a nonlinear upsampling.In our experiments, we find that in-network upsamplingis fast and effective for learning dense prediction.3.4 Patchwise Training Is Loss SamplingIn stochastic optimization, gradient computation is drivenby the training distribution. Both patchwise training andfully convolutional training can be made to produce anydistribution of the inputs, although their relative computational efficiency depends on overlap and minibatch size.Whole image fully convolutional training is identical topatchwise training where each batch consists of all thereceptive fields of the output units for an image (or collection of images). While this is more efficient than uniformsampling of patches, it reduces the number of possiblebatches. However, random sampling of patches within animage may be easily recovered. Restricting the loss to a randomly sampled subset of its spatial terms (or, equivalentlyapplying a DropConnect mask [49] between the output andthe loss) excludes patches from the gradient.If the kept patches still have significant overlap, fullyconvolutional computation will still speed up training. Ifgradients are accumulated over multiple backward passes,batches can include patches from several images. If inputsare shifted by values up to the output stride, random selection of all possible patches is possible even though the output units lie on a fixed, strided grid.Sampling in patchwise training can correct class imbalance [10], [11], [12] and mitigate the spatial correlation ofdense patches [13], [14]. In fully convolutional training,class balance can also be achieved by weighting the loss,and loss sampling can be used to address spatial correlation.We explore training with sampling in Section 4.4, and donot find that it yields faster or better convergence for denseprediction. Whole image training is effective and efficient.4SEGMENTATION ARCHITECTUREWe cast ILSVRC classifiers into FCNs and augment them fordense prediction with in-network upsampling and a pixelwise loss. We train for segmentation by fine-tuning. Next,we add skips between layers to fuse coarse, semantic andlocal, appearance information. This skip architecture islearned end-to-end to refine the semantics and spatial precision of the output.For this investigation, we train and validate on the PASCAL VOC 2011 segmentation challenge [50]. We train witha per-pixel softmax loss and validate with the standard metric of mean pixel intersection over union, with the meantaken over all classes, including background. The trainingignores pixels that are masked out (as ambiguous or difficult) in the ground truth.\f644IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,TABLE 1Adapting ILSVRC Classifiers to FCNs39.816 ms857M3553256.0100 ms16134M40432NO. 4,APRIL 2017TABLE 2Comparison of Image-to-Image Optimization MethodsFCN-AlexNet FCN-VGG16 FCN-GoogLeNet3mean IUforward timeconv. layersparametersrf sizemax strideVOL. 39,42.520 ms226M90732We compare performance by mean intersection over union on the validation setof PASCAL VOC 2011 and by inference time (averaged over 20 trials for a500 \u0003 500 input on an NVIDIA Titan X). We detail the architecture of theadapted nets with regard to dense prediction: number of parameter layers,receptive field size of output units, and the coarsest stride within the net.(These numbers give the best performance obtained at a fixed learning rate, notbest performance possible.)4.1 From Classifier to Dense FCNWe begin by convolutionalizing proven classification architectures as in Section 3. We consider the AlexNet2 architecture [1] that won ILSVRC12, as well as the VGG nets [2] andthe GoogLeNet3 [3] which did exceptionally well inILSVRC14. We pick the VGG 16-layer net,4 which we foundto be equivalent to the 19-layer net on this task. For GoogLeNet, we use only the final loss layer, and improve performance by discarding the final average pooling layer. Wedecapitate each net by discarding the final classifier layer,and convert all fully connected layers to convolutions. Weappend a 1 \u0003 1 convolution with channel dimension 21 topredict scores for each of the PASCAL classes (includingbackground) at each of the coarse output locations, followedby a (backward) convolution layer to bilinearly upsamplethe coarse outputs to pixelwise outputs as described in Section 3.3. Table 1 compares the preliminary validation resultsalong with the basic characteristics of each net. We reportthe best results achieved after convergence at a fixed learning rate (at least 175 epochs).Our training for this comparison follows the practices forclassification networks. We train by SGD with momentum.Gradients are accumulated over 20 images. We set fixedlearning rates of 10\u00063 , 10\u00064 , and 5\u00065 for FCN-AlexNet, FCNVGG16, and FCN-GoogLeNet, respectively, chosen by linesearch. We use momentum 0:9, weight decay of 5\u00064 or 2\u00064 ,and doubled learning rate for biases. We zero-initialize theclass scoring layer, as random initialization yielded neitherbetter performance nor faster convergence. Dropout isincluded where used in the original classifier nets (however,training without it made little to no difference).Fine-tuning from classification to segmentation gives reasonable predictions from each net. Even the worst modelachieved \b 75 percent of the previous best performance.FCN-VGG16 already appears to be better than previousmethods at 56.0 mean IU on val, compared to 52.6 on test[14]. Although VGG and GoogLeNet are similarly accurateas classifiers, our FCN-GoogLeNet did not match FCNVGG16. We select FCN-VGG16 as our base network.2. Using the publicly available CaffeNet reference model.3. We use our own reimplementation of GoogLeNet. Ours is trainedwith less extensive data augmentation, and gets 68.5 percent top-1 and88.4 percent top-5 ILSVRC accuracy.4. Using the publicly available version from the Caffe model zoo.FCN-accumFCN-onlineFCN-heavybatchsize2011mom.0.90.90.99pixelacc.86.089.390.5meanacc.66.576.276.5meanIU51.960.763.6f.w.IU76.581.883.5All methods are trained on a fixed sequence of 100,000 images (sampled from adataset of 8,498) to control for stochasticity and equalize the number of gradient computations. The loss is not normalized so that every pixel has the sameweight no matter the batch and image dimensions. Scores are the best achievedduring training on a subset5 of PASCAL VOC 2011 segval. Learning is endto-end with FCN-VGG16.4.2 Image-to-Image LearningThe image-to-image learning setting includes high effectivebatch size and correlated inputs. This optimization requiressome attention to properly tune FCNs.We begin with the loss. We do not normalize the loss, sothat every pixel has the same weight regardless of the batchand image dimensions. Thus we use a small learning ratesince the loss is summed spatially over all pixels.We consider two regimes for batch size. In the first, gradients are accumulated over 20 images. Accumulationreduces the memory required and respects the differentdimensions of each input by reshaping the network. Wepicked this batch size empirically to result in reasonableconvergence. Learning in this way is similar to standardclassification training: each minibatch contains severalimages and has a varied distribution of class labels. Thenets compared in Table 1 are optimized in this fashion.However, batching is not the only way to do imagewise learning. In the second regime, batch size one isused for online learning. Properly tuned, online learningachieves higher accuracy and faster convergence in bothnumber of iterations and wall clock time. Additionally,we try a higher momentum of 0:99, which increases theweight on recent gradients in a similar way to batching.See Table 2 for the comparison of accumulation, online,and high momentum or \u201cheavy\u201d learning (discussedfurther in Section 6.2).4.3 Combining What and WhereWe define a new fully convolutional net for segmentationthat combines layers of the feature hierarchy and refines thespatial precision of the output. See Fig. 3.While fully convolutionalized classifiers fine-tuned tosemantic segmentation both recognize and localize, asshown in Section 4.1, these networks can be improved tomake direct use of shallower, more local features. Eventhough these base networks score highly on the standardmetrics, their output is dissatisfyingly coarse (see Fig. 4).The stride of the network prediction limits the scale of detailin the upsampled output.We address this by adding skips [51] that fuse layer outputs, in particular to include shallower layers with finerstrides in prediction. This turns a line topology into a DAG:edges skip ahead from shallower to deeper layers. It is natural to make more local predictions from shallower layerssince their receptive fields are smaller and see fewer pixels.\fSHELHAMER ET AL.: FULLY CONVOLUTIONAL NETWORKS FOR SEMANTIC SEGMENTATION645Fig. 3. Our DAG nets learn to combine coarse, high layer information with fine, low layer information. Pooling and prediction layers are shown asgrids that reveal relative spatial coarseness, while intermediate layers are shown as vertical lines. First row (FCN-32s): Our single-stream net,described in Section 4.1, upsamples stride 32 predictions back to pixels in a single step. Second row (FCN-16s): Combining predictions from boththe final layer and the pool4 layer, at stride 16, lets our net predict finer details, while retaining high-level semantic information. Third row (FCN8s): Additional predictions from pool3, at stride 8, provide further precision.Once augmented with skips, the network makes and fusespredictions from several streams that are learned jointlyand end-to-end.Combining fine layers and coarse layers lets the modelmake local predictions that respect global structure. Thiscrossing of layers and resolutions is a learned, nonlinearcounterpart to the multi-scale representation of the Laplacian pyramid [26]. By analogy to the jet of Koenderick andvan Doorn [27], we call our feature hierarchy the deep jet.Layer fusion is essentially an elementwise operation.However, the correspondence of elements across layers iscomplicated by resampling and padding. Thus, in general,layers to be fused must be aligned by scaling and cropping.We bring two layers into scale agreement by upsamplingthe lower-resolution layer, doing so in-network asexplained in Section 3.3. Cropping removes any portion ofthe upsampled layer which extends beyond the other layerdue to padding. This results in layers of equal dimensionsin exact alignment. The offset of the cropped regiondepends on the resampling and padding parameters of allintermediate layers. Determining the crop that results inexact correspondence can be intricate, but it follows automatically from the network definition (and we include codefor it in Caffe).Having spatially aligned the layers, we next pick a fusionoperation. We fuse features by concatenation, and immediately follow with classification by a \u201cscore layer\u201d consistingof a 1 \u0003 1 convolution. Rather than storing concatenated features in memory, we commute the concatenation and subsequent classification (as both are linear). Thus, our skips areimplemented by first scoring each layer to be fused by 1 \u0003 1convolution, carrying out any necessary interpolation andalignment, and then summing the scores. We also consideredmax fusion, but found learning to be difficult due to gradient switching. The score layer parameters are zero-initialized when a skip is added, so that they do not interfere withexisting predictions of other streams. Once all layers havebeen fused, the final prediction is then upsampled back toimage resolution.Skip architectures for segmentation. We define a skiparchitecture to extend FCN-VGG16 to a three-stream netwith eight pixel stride shown in Fig. 3. Adding a skip frompool4 halves the stride by scoring from this stride sixteenlayer. The 2\u0003 interpolation layer of the skip is initialized tobilinear interpolation, but is not fixed so that it can belearned as described in Section 3.3. We call this two-streamnet FCN-16s, and likewise define FCN-8s by adding a further skip from pool3 to make stride eight predictions.(Note that predicting at stride eight does not significantlylimit the maximum achievable mean IU; see Section 6.3.)We experiment with both staged training and all-at-oncetraining. In the staged version, we learn the single-streamFCN-32s, then upgrade to the two-stream FCN-16s and continue learning, and finally upgrade to the three-streamFCN-8s and finish learning. At each stage the net is learnedend-to-end, initialized with the parameters of the earliernet. The learning rate is dropped 100\u0003 from FCN-32s toFCN-16s and 100\u0003 more from FCN-16s to FCN-8s, whichwe found to be necessary for continued improvements.Fig. 4. Refining fully convolutional networks by fusing information fromlayers with different strides improves spatial detail. The first three imagesshow the output from our 32, 16, and 8 pixel stride nets (see Fig. 3).\f646IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 39,NO. 4,APRIL 2017TABLE 3Comparison of FCN Variationspixel acc.mean acc.mean IUf.w. IUFCN-32sFCN-16sFCN-8s at-onceFCN-8s staged90.591.091.191.276.578.178.577.663.665.065.465.583.584.384.484.5FCN-32s fixed82.964.646.672.3FCN-pool5FCN-pool4FCN-pool387.478.770.960.531.713.750.022.49.278.567.057.6Learning is end-to-end with batch size one and high momentum, with theexception of the fixed variant that fixes all features. Note that FCN-32s isFCN-VGG16, renamed to highlight stride, and the FCN-poolX are truncatednets with the same strides as FCN-32/16/8s. Scores are evaluated on a subsetof PASCAL VOC 2011 segval.5Learning all-at-once rather than in stages gives nearlyequivalent results, while training is faster and less tedious.However, disparate feature scales make na\u20ac\u0131ve training proneto divergence. To remedy this we scale each stream by a fixedconstant, for a similar in-network effect to the staged learning rate adjustments. These constants are picked to approximately equalize average feature norms across streams.(Other normalization schemes should have similar effect.)With FCN-16s validation score improves to 65.0 mean IU,and FCN-8s brings a minor improvement to 65.5. At thispoint our fusion improvements have met diminishingreturns, so we do not continue fusing even shallower layers.To identify the contribution of the skips we comparescoring from the intermediate layers in isolation, whichresults in poor performance, or dropping the learning ratewithout adding skips, which gives negligible improvementin score without refining the visual quality of output. Allskip comparisons are reported in Table 3. Fig. 4 shows theprogressively finer structure of the output.4.4 Experimental FrameworkFine-tuning. We fine-tune all layers by backpropagationthrough the whole net. Fine-tuning the output classifieralone yields only 73 percent of the full fine-tuning performance as compared in Table 3. Fine-tuning in stages takes36 hours on a single GPU. Learning FCN-8s all-at-once takeshalf the time to reach comparable accuracy. Training fromscratch gives substantially lower accuracy.More training data. The PASCAL VOC 2011 segmentation training set labels 1,112 images. Hariharan et al. [52]collected labels for a larger set of 8,498 PASCAL trainingimages, which was used to train the previous best system,SDS [14]. This training data improves the FCN-32s validation score5 from 57.7 to 63.6 mean IU and improves theFCN-AlexNet score from 39.8 to 48.0 mean IU.Loss. The per-pixel, unnormalized softmax loss is a natural choice for segmenting images of any size into disjointclasses, so we train our nets with it. The softmax operationinduces competition between classes and promotes the mostconfident prediction, but it is not clear that this is necessary5. There are training images from [52] included in the PASCAL VOC2011 val set, so we validate on the non-intersecting set of 736 images.Fig. 5. Training on whole images is just as effective as sampling patches,but results in faster (wall clock time) convergence by making more efficient use of data. Left shows the effect of sampling on convergence ratefor a fixed expected batch size, while right plots the same by relative wallclock time.or helpful. For comparison, we train with the sigmoid crossentropy loss and find that it gives similar results, eventhough it normalizes each class prediction independently.Patch sampling. As explained in Section 3.4, our wholeimage training effectively batches each image into a regulargrid of large, overlapping patches. By contrast, prior workrandomly samples patches over a full dataset [10], [11], [12],[13], [16], potentially resulting in higher variance batchesthat may accelerate convergence [53]. We study this tradeoffby spatially sampling the loss in the manner described earlier, making an independent choice to ignore each final layercell with some probability 1 \u0006 p. To avoid changing theeffective batch size, we simultaneously increase the numberof images per batch by a factor 1=p. Note that due to the efficiency of convolution, this form of rejection sampling is stillfaster than patchwise training for large enough values of p(e.g., at least for p > 0:2 according to the numbers in Section3.1). Fig. 5 shows the effect of this form of sampling on convergence. We find that sampling does not have a significanteffect on convergence rate compared to whole image training, but takes significantly more time due to the larger number of images that need to be considered per batch. Wetherefore choose unsampled, whole image training in ourother experiments.Class balancing. Fully convolutional training can balance classes by weighting or sampling the loss. Althoughour labels are mildly unbalanced (about 3=4 are background), we find class balancing unnecessary.Dense prediction. The scores are upsampled to the inputdimensions by backward convolution layers within the net.Final layer backward convolution weights are fixed to bilinear interpolation, while intermediate upsampling layers areinitialized to bilinear interpolation, and then learned. Thissimple, end-to-end method is accurate and fast.Augmentation. We tried augmenting the training databy randomly mirroring and \u201cjittering\u201d the images by translating them up to 32 pixels (the coarsest scale of prediction)in each direction. This yielded no noticeable improvement.Implementation. All models are trained and tested withCaffe [54] on a single NVIDIA Titan X. Our models andcode are publicly available at https://fcn.berkeleyvision.org.5RESULTSWe test our FCN on semantic segmentation and scene parsing, exploring PASCAL VOC, NYUDv2, SIFT Flow, and\fSHELHAMER ET AL.: FULLY CONVOLUTIONAL NETWORKS FOR SEMANTIC SEGMENTATION647TABLE 4Results on PASCAL VOCR-CNN [5]SDS [14]FCN-8smean IUVOC2011 test47.952.667.5mean IUVOC2012 test51.667.2inferencetime\b 50 s\b 100 msOur FCN gives a 30% relative improvement on the previous best PASCALVOC test results with faster inference and learning.TABLE 5Results on NYUDv2pixel acc. mean acc. mean IU f.w. IUGupta et al. [15]FCN-32s RGBFCN-32s RGB-DFCN-32s HHAFCN-32s RGB-HHA60.361.862.158.365.344.744.835.744.028.631.631.725.233.347.046.046.341.748.6RGB-D is early-fusion of the RGB and depth channels at the input. HHAis the depth embedding of [15] as horizontal disparity, height above ground,and the angle of the local surface normal with the inferred gravity direction. RGB-HHA is the jointly trained late fusion model that sums RGBand HHA predictions.TABLE 6Results on SIFT FlowFig. 6. Fully convolutional networks improve performance on PASCAL. The left column shows the output of our most accurate net,FCN-8s. The second shows the output of the previous best methodby Hariharan et al. [14]. Notice the fine structures recovered (firstrow), ability to separate closely interacting objects (second row),and robustness to occluders (third row). The fifth and sixth rowsshow failure cases: the net sees lifejackets in a boat as people andconfuses human hair with a dog.PASCAL-Context. Although these tasks have historicallydistinguished between objects and regions, we treat bothuniformly as pixel prediction. We evaluate our FCN skiparchitecture on each of these datasets, and then extend it tomulti-modal input for NYUDv2 and multi-task predictionfor the semantic and geometric labels of SIFT Flow. Allexperiments follow the same network architecture and optimization settings decided on in Section 4.Metrics. We report metrics from common semantic segmentation and scene parsing evaluations that are variationson pixel accuracy and region intersection over union (IU):PP\u0001 pixel accuracy: i nii = Pi ti\u0001 mean accuraccy: \u00f01=n\u00de=tii niiP clP\u0001 mean IU: \u00f01=ncl \u00de i nii =\u00f0ti \u00fe j nji \u0006 nii \u00de\u0001 frequency weighted IU:\u0001P \u0003\u00061 PPk tki ti nii =\u00f0ti \u00fej nji \u0006 nii \u00dewhere nij is the number of pixels of class i predicted tobelong to class j, there are ncl different classes, andPti \u00bc j nij is the total number of pixels of class i.PASCAL VOC. Table 4 gives the performance of ourFCN-8s on the test sets of PASCAL VOC 2011 and 2012, andcompares it to the previous best, SDS [14], and the wellknown R-CNN [5]. We achieve the best results on mean IUby 30 percent relative. Inference time is reduced 114\u0003Liu et al. [57]Tighe et al. [58] transferTighe et al. [59] SVMTighe et al. [59] SVM+MRFFarabet et al. [12] naturalFarabet et al. [12] balancedPinheiro et al. [13]FCN-8spixelacc.76.775.678.672.378.577.785.9meanacc.41.139.250.829.629.853.9meanIU41.2f.w.IU77.2geom.acc.90.894.6Evaluation of semantics (center) and geometry (right). Farabet is a multi-scaleconvnet trained on class-balanced or natural frequency samples. Pinheiro isthe multi-scale, recurrent convnet RCNN3 \u00f0\u00053 \u00de. The metric for geometry ispixel accuracy.TABLE 7Results on PASCAL-Context for the 59 Class TaskO2 PCFMFCN-32sFCN-16sFCN-8spixel acc.mean acc.mean IUf.w. IU65.566.967.549.151.352.318.134.436.738.439.150.952.353.0CFM is convolutional feature masking [60] and segment pursuit with theVGG net. O2 P is the second order pooling method [61] as reported in theerrata of [62].(convnet only, ignoring proposals and refinement) or 286\u0003(overall). Fig. 6 compares the outputs of FCN-8s and SDS.NYUDv2. [55] is an RGB-D dataset collected using theMicrosoft Kinect. It has 1,449 RGB-D images, with pixelwiselabels that have been coalesced into a 40 class semantic segmentation task by Gupta et al. [56]. We report results on thestandard split of 795 training images and 654 testing images.\f648IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 39,NO. 4,APRIL 2017TABLE 8The Role of Foreground, Background, and Shape CuestrainReferenceReference-FGReference-BGFG-onlyBG-onlyShapetestFGBGFGBGkeepkeepkeepkeepmaskmaskkeepkeepkeepmaskkeepmaskkeepkeepmaskkeepmaskmaskkeepmaskkeepmaskkeepmaskmean IU84.881.019.876.137.829.1All scores are the mean intersection over union metric excluding background. The architecture and optimization are fixed to those of FCN-32s (Reference) and only input masking differs.Table 5 gives the performance of several net variations. Firstwe train our unmodified coarse model (FCN-32s) on RGBimages. To add depth information, we train on a modelupgraded to take four-channel RGB-D input (early fusion).This provides little benefit, perhaps due to similar numberof parameters or the difficulty of propagating meaningfulgradients all the way through the net. Following the successof Gupta et al. [15], we try the three-dimensional HHAencoding of depth and train a net on just this information.To effectively combine color and depth, we define a \u201clatefusion\u201d of RGB and HHA that averages the final layer scoresfrom both nets and learn the resulting two-stream net endto-end. This late fusion RGB-HHA net is the most accurate.SIFT Flow. is a dataset of 2,688 images with pixel labelsfor 33 semantic classes (\u201cbridge\u201d, \u201cmountain\u201d, \u201csun\u201d), aswell as three geometric classes (\u201chorizontal\u201d, \u201cvertical\u201d, and\u201csky\u201d). An FCN can naturally learn a joint representationthat simultaneously predicts both types of labels. We learna two-headed version of FCN-32/16/8s with semantic andgeometric prediction layers and losses. This net performs aswell on both tasks as two independently trained nets, whilelearning and inference are essentially as fast as each independent net by itself. The results in Table 6, computed onthe standard split into 2,488 training and 200 test images,6show better performance on both tasks.PASCAL-Context. [62] provides whole scene annotations of PASCAL VOC 2010. While there are 400+ classes,we follow the 59 class task defined by [62] that picks themost frequent classes. We train and evaluate on the trainingand val sets respectively. In Table 7 we compare to the previous best result on this task. FCN-8s scores 39.1 mean IUfor a relative improvement of more than 10 percent.6ANALYSISWe examine the learning and inference of fully convolutional networks. Masking experiments investigate the roleof context and shape by reducing the input to only foreground, only background, or shape alone. Defining a \u201cnull\u201dbackground model checks the necessity of learning a background classifier for semantic segmentation. We detailan approximation between momentum and batch size tofurther tune whole image learning. Finally, we measure6. Three of the SIFT Flow classes are not present in the test set. Wemade predictions across all 33 classes, but only included classes actually present in the test set in our evaluation.Fig. 7. FCNs learn to recognize by shape when deprived of other inputdetail. From left to right: regular image (not seen by network), groundtruth, output, mask input.bounds on task accuracy for given output resolutions toshow there is still much to improve.6.1 CuesGiven the large receptive field size of an FCN, it is natural towonder about the relative importance of foreground andbackground pixels in the prediction. Is foreground appearance sufficient for inference, or does the context influencethe output? Conversely, can a network learn to recognize aclass by its shape and context alone?Masking. To explore these issues we experiment withmasked versions of the standard PASCAL VOC segmentation challenge. We both mask input to networks trained onnormal PASCAL, and learn new networks on the maskedPASCAL. See Table 8 for masked results.Masking the foreground at inference time is catastrophic.However, masking the foreground during learning yields anetwork capable of recognizing object segments withoutobserving a single pixel of the labeled class. Masking thebackground has little effect overall but does lead to classconfusion in certain cases. When the background is maskedduring both learning and inference, the network unsurprisingly achieves nearly perfect background accuracy; however certain classes are more confused. All-in-all thissuggests that FCNs do incorporate context even thoughdecisions are driven by foreground pixels.To separate the contribution of shape, we learn a netrestricted to the simple input of foreground/backgroundmasks. The accuracy in this shape-only condition is lowerthan when only the foreground is masked, suggesting thatthe net is capable of learning context to boost recognition.Nonetheless, it is surprisingly accurate. See Fig. 7.\fSHELHAMER ET AL.: FULLY CONVOLUTIONAL NETWORKS FOR SEMANTIC SEGMENTATIONBackground modeling. It is standard in detection andsemantic segmentation to have a background model. Thismodel usually takes the same form as the models for theclasses of interest, but is supervised by negative instances. In our experiments we have followed the sameapproach, learning parameters to score all classes including background. Is this actually necessary, or do classmodels suffice?To investigate, we define a net with a \u201cnull\u201d background model that gives a constant score of zero. Insteadof training with the softmax loss, which induces competition by normalizing across classes, we train with the sigmoid cross-entropy loss, which independently normalizeseach score. For inference each pixel is assigned the highestscoring class. In all other respects the experiment is identical to our FCN-32s on PASCAL VOC. The null backgroundnet scores 1 point lower than the reference FCN-32s and acontrol FCN-32s trained on all classes including background with the sigmoid cross-entropy loss. To put thisdrop in perspective, note that discarding the backgroundmodel in this way reduces the total number of parametersby less than 0.1 percent. Nonetheless, this result suggeststhat learning a dedicated background model for semanticsegmentation is not vital.6.2 Momentum and Batch SizeIn comparing optimization schemes for FCNs, we find that\u201cheavy\u201d online learning with high momentum trains moreaccurate models in less wall clock time (see Section 4.2).Here we detail a relationship between momentum andbatch size that motivates heavy learning.By writing the updates computed by gradient accumulation as a non-recursive sum, we will see thatmomentum and batch size can be approximately tradedoff, which suggests alternative training parameters. Letgt be the step taken by minibatch SGD with momentumat time t,gt \u00bc \u0006hk\u00061Xru \u2018\u00f0xkt\u00fei ; ut\u00061 \u00de \u00fe pgt\u00061 ;i\u00bc0where \u2018\u00f0x; u\u00de is the loss for example x and parameters u,p < 1 is the momentum, k is the batch size, and h is thelearning rate. Expanding this recurrence as an infinite sumwith geometric coefficients, we havegt \u00bc \u0006h1 Xk\u00061Xps ru \u2018\u00f0xk\u00f0t\u0006s\u00de\u00fei ; ut\u0006s \u00de:s\u00bc0 i\u00bc0In other words, each example is included in the sum withcoefficient pbj=kc , where the index j orders the examples frommost recently considered to least recently considered.Approximating this expression by dropping the floor, we seethat learning with momentum p and batch size k appears tobe similar to learning with momentum p0 and batch size k0 if0p\u00f01=k\u00de \u00bc p0\u00f01=k \u00de . Note that this is not an exact equivalence: asmaller batch size results in more frequent weight updates,and may make more learning progress for the same numberof gradient computations. For typical FCN values of momentum 0:9 and a batch size of 20 images, an approximately649equivalent training regime uses momentum 0:9\u00f01=20\u00de 0:99and a batch size of one, resulting in online learning. In practice, we find that online learning works well and yields betterFCN models in less wall clock time.6.3 Upper Bounds on IUFCNs achieve good performance on the mean IU segmentation metric even with spatially coarse semanticprediction. To better understand this metric and thelimits of this approach with respect to it, we computeapproximate upper bounds on performance with prediction at various resolutions. We do this by downsamplingground truth images and then upsampling back to simulate the best results obtainable with a particular downsampling factor. The following table gives the meanIU on a subset5 of PASCAL 2011 val for various downsampling factors.factor12864321684mean IU50.973.386.192.896.498.5Pixel-perfect prediction is clearly not necessary toachieve mean IU well above state-of-the-art, and, conversely, mean IU is a not a good measure of fine-scale accuracy. The gaps between oracle and state-of-the-art accuracyat every stride suggest that recognition and not resolution isthe bottleneck for this metric.7CONCLUSIONFully convolutional networks are a rich class of models thataddress many pixelwise tasks. FCNs for semantic segmentation dramatically improve accuracy by transferring pretrained classifier weights, fusing different layer representations, and learning end-to-end on whole images. End-toend, pixel-to-pixel operation simultaneously simplifies andspeeds up learning and inference. All code for this paper isopen source in Caffe, and all models are freely available inthe Caffe Model Zoo. Further works have demonstrated thegenerality of fully convolutional networks for a variety ofimage-to-image tasks.ACKNOWLEDGMENTSThis work was supported in part by DARPA\u2019s MSEE andSMISC programs, US National Science Foundation awardsIIS-1427425, IIS-1212798, IIS-1116411, and the NSF GRFP,Toyota, and the Berkeley Vision and Learning Center. Wegratefully acknowledge NVIDIA for GPU donation. Wethank Bharath Hariharan and Saurabh Gupta for theiradvice and dataset tools. We thank Sergio Guadarrama forreproducing GoogLeNet in Caffe. We thank Jitendra Malikfor his helpful comments. Thanks to Wei Liu for pointingout an issue wth our SIFT Flow mean IU computation andan error in our frequency weighted mean IU formula. EvanShelhamer and Jonathan Long contributed equally tothis article.\f650IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,REFERENCES[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22][23][24][25]A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u201cImagenet classification with deep convolutional neural networks,\u201d in Proc. NeuralInf. Process. Syst., 2012, pp. 1106\u20131114.K. Simonyan and A. Zisserman, \u201cVery deep convolutional networks for large-scale image recognition,\u201d in Proc. Int. Conf. Learn.Represent., 2015.C. Szegedy, et al., \u201cGoing deeper with convolutions,\u201d in Proc.Comput. Vis. Pattern Recognit., 2015, pp. 1\u20139.P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, andY. LeCun, \u201cOverFeat: Integrated recognition, localization anddetection using convolutional networks,\u201d in Proc. Int. Conf. Learn.Represent., 2014.R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRegion-basedconvolutional networks for accurate object detection andsegmentation,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 38,no. 1, pp. 142\u2013158, Jan. 2015.K. He, X. Zhang, S. Ren, and J. Sun, \u201cSpatial pyramid pooling indeep convolutional networks for visual recognition,\u201d in Proc. Eur.Conf. Comput. Vis., 2014, pp. 346\u2013361.N. Zhang, J. Donahue, R. Girshick, and T. Darrell, \u201cPart-basedR-CNNs for fine-grained category detection,\u201d in Proc. Eur. Conf.Comput. Vis., 2014, pp. 834\u2013849.J. Long, N. Zhang, and T. Darrell, \u201cDo convnets learn correspondence?\u201d in Proc. Neural Inf. Process. Syst, 2014, pp. 1601\u20131609.P. Fischer, A. Dosovitskiy, and T. Brox, \u201cDescriptor matching withconvolutional neural networks: A comparison to SIFT,\u201d arXivpreprint arXiv:1405.5769, 2014.F. Ning, D. Delhomme, Y. LeCun, F. Piano, L. Bottou, andP. E. Barbano, \u201cToward automatic phenotyping of developingembryos from videos,\u201d IEEE Trans. Image Process., vol. 14, no. 9,pp. 1360\u20131371, Sep. 2005.D. C. Ciresan, A. Giusti, L. M. Gambardella, and J. Schmidhuber,\u201cDeep neural networks segment neuronal membranes in electronmicroscopy images,\u201d in Proc. Neural Inf. Process. Syst., 2012,pp. 2852\u20132860.C. Farabet, C. Couprie, L. Najman, and Y. LeCun, \u201cLearning hierarchical features for scene labeling,\u201d Proc. IEEE Trans. PatternAnal. Mach. Intel., vol. 35, no. 8, pp. 1915\u20131929, Aug. 2013.P. H. Pinheiro and R. Collobert, \u201cRecurrent convolutional neuralnetworks for scene labeling,\u201d in Proc. 31st Int. Conf. Mach. Learn.,2014, pp. 82\u201390.B. Hariharan, P. Arbel\u0003aez, R. Girshick, and J. Malik,\u201cSimultaneous detection and segmentation,\u201d in Proc. Eur. Conf.Comput. Vis., 2014, pp. 297\u2013312.S. Gupta, R. Girshick, P. Arbelaez, and J. Malik, \u201cLearning richfeatures from RGB-D images for object detection andsegmentation,\u201d in Proc. Eur. Conf. Comput. Vis., 2014, pp. 345\u2013360.Y. Ganin and V. Lempitsky, \u201cN4 -fields: Neural network nearestneighbor fields for image transforms,\u201d in Proc. Asian Conf. Comput.Vis., 2014, pp. 536\u2013551.J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in Proc. Comput. Vis. PatternRecognit., 2015.J. Donahue, et al., \u201cDeCAF: A deep convolutional activation feature for generic visual recognition,\u201d in Proc. Int. Conf. Mach. Learn.,2014, pp. 647\u2013655.M. D. Zeiler and R. Fergus, \u201cVisualizing and understanding convolutionalnetworks,\u201dinProc.Eur.Conf.Comput.Vis.,2014,pp.818\u2013833.O. Matan, C. J. Burges, Y. LeCun, and J. S. Denker, \u201cMulti-digitrecognition using a space displacement neural network,\u201d in Proc.Neural Inf. Process. Syst., 1991, pp. 488\u2013495.Y. LeCun, et al., \u201cBackpropagation applied to hand-written zipcode recognition,\u201d in Proc. Neural Comput., 1989, pp. 541\u2013551.R. Wolf and J. C. Platt, \u201cPostal address block location using a convolutional locator network,\u201d in Proc. Neural Inf. Process. Syst.,1994, pp. 745\u2013745.D. Eigen, D. Krishnan, and R. Fergus, \u201cRestoring an image takenthrough a window covered with dirt or rain,\u201d in Proc. Int. Conf.Comput. Vis., 2013, pp. 633\u2013640.J. Tompson, A. Jain, Y. LeCun, and C. Bregler, \u201cJoint training of aconvolutional network and a graphical model for human poseestimation,\u201d in Proc. Neural Inf. Process. Syst., 2014, pp. 1799\u20131807.D. Eigen, C. Puhrsch, and R. Fergus, \u201cDepth map prediction froma single image using a multi-scale deep network,\u201d in Proc. NeuralInf. Process. Syst., 2014, pp. 2366\u20132374.VOL. 39,NO. 4,APRIL 2017[26] P. Burt and E. Adelson, \u201cThe Laplacian pyramid as a compactimage code,\u201d IEEE Trans. Commun., vol. 31, no. 4, pp. 532\u2013540,Apr. 1983.[27] J. J. Koenderink and A. J. van Doorn, \u201cRepresentation of localgeometry in the visual system,\u201d Biol. Cybern., vol. 55, no. 6,pp. 367\u2013375, Mar. 1987.[28] P. Sermanet, K. Kavukcuoglu, S. Chintala, and Y. LeCun,\u201cPedestrian detection with unsupervised multi-stage featurelearning,\u201d in Proc. Comput. Vis. Pattern Recognit., 2013, pp. 3626\u20133633.[29] B. Hariharan, P. Arbel\u0003aez, R. Girshick, and J. Malik,\u201cHypercolumns for object segmentation and fine-grained localization,\u201d in Proc. Comput. Vis. Pattern Recognit., 2015, pp. 447\u2013456.[30] M. Mostajabi, P. Yadollahpour, and G. Shakhnarovich,\u201cFeedforward semantic segmentation with zoom-out features,\u201d inProc. Comput. Vis. Pattern Recognit., 2015, pp. 3376\u20133385.[31] S. Ren, K. He, R. Girshick, and J. Sun, \u201cFaster R-CNN: Towardsreal-time object detection with region proposal networks,\u201d inProc. Neural Inf. Process. Syst., 2015, pp. 91\u201399.[32] S. Xie and Z. Tu, \u201cHolistically-nested edge detection,\u201d in Proc. Int.Conf. Comput. Vis., 2015, pp. 1395\u20131403.[33] F. Liu, C. Shen, G. Lin, and I. Reid, \u201cLearning depth from singlemonocular images using deep convolutional neural fields,\u201d IEEETrans. Pattern Anal. Mach. Intell., 2015, Doi: 10.1109/TPAMI.2015.2505283.[34] P. Fischer, et al., \u201cLearning optical flow with convolutionalnetworks,\u201d in Proc. Int. Conf. Comput. Vis., 2015.[35] D. Pathak, P. Kr\u20acahenb\u20acuhl, and T. Darrell, \u201cConstrained convolutional neural networks for weakly supervised segmentation,\u201d inProc. Int. Conf. Comput. Vis., 2015, pp. 1796\u20131804.[36] G. Papandreou, L.-C. Chen, K. Murphy, and A. L. Yuille,\u201cWeakly-and semi-supervised learning of a DCNN for semanticimage segmentation,\u201d in Proc. Int. Conf. Comput. Vis., 2015,pp. 1742\u20131750.[37] J. Dai, K. He, and J. Sun, \u201cBoxsup: Exploiting bounding boxes tosupervise convolutional networks for semantic segmentation,\u201d inProc. Int. Conf. Comput. Vis., 2015, pp. 1635\u20131643.[38] S. Hong, H. Noh, and B. Han, \u201cDecoupled deep neural networkfor semi-supervised semantic segmentation,\u201d in Proc. Neural Inf.Process. Syst., 2015, pp. 1495\u20131503.[39] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, andA. L. Yuille, \u201cSemantic image segmentation with deep convolutional nets and fully connected CRFs,\u201d in Proc. Int. Conf. Learn.Represent., 2015.[40] S. Zheng, et al., \u201cConditional random fields as recurrentneural networks,\u201d in Proc. Int. Conf. Comput. Vis., 2015,pp. 1529\u20131537.[41] W. Liu, A. Rabinovich, and A. C. Berg, \u201cParseNet: Looking widerto see better,\u201d arXiv preprint arXiv:1506.04579, 2015.[42] H. Noh, S. Hong, and B. Han, \u201cLearning deconvolution networkfor semantic segmentation,\u201d in Proc. Int. Conf. Comput. Vis., 2015,pp. 1520\u20131528.[43] O. Ronneberger, P. Fischer, and T. Brox, \u201cU-Net: Convolutionalnetworks for biomedical image segmentation,\u201d in Proc. Med. ImageComput. Comput.-Assist. Intervention, 2015, pp. 234\u2013241.[44] F. Yu and V. Koltun, \u201cMulti-scale context aggregation by dilatedconvolutions,\u201d in Proc. Int. Conf. Learn. Represent., 2016.[45] A. Giusti, D. C. Cires\u0327an, J. Masci, L. M. Gambardella, andJ. Schmidhuber, \u201cFast image scanning with deep max-poolingconvolutional neural networks,\u201d in Proc. Int. Conf. Image Process.,2013, pp. 4034\u20134038.[46] M. Holschneider, R. Kronland-Martinet, J. Morlet, andP. Tchamitchian, \u201cA real-time algorithm for signal analysis withthe help of the wavelet transform,\u201d in Proc. Int. Conf. Time-Freq.Methods Phase Space, 1989, pp. 286\u2013297.[47] S. Mallat, A Wavelet Tour of Signal Processing, 2nd ed. New York,NY, USA: Academic, 1999.[48] P. P. Vaidyanathan, \u201cMultirate digital filters, filter banks, polyphase networks, and applications: A tutorial,\u201d Proc. IEEE, vol. 78,no. 1, pp. 56\u201393, Jan. 1990.[49] L. Wan, M. Zeiler, S. Zhang, Y. L. Cun, and R. Fergus,\u201cRegularization of neural networks using DropConnect,\u201d in Proc.Int. Conf. Mach. Learn., 2013, pp. 1058\u20131066.[50] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, andA. Zisserman, The PASCAL Visual Object Classes Challenge 2011Results. [Online]. Available: https://www.pascal-network.org/challenges/VOC/voc2011/workshop/index.html\fSHELHAMER ET AL.: FULLY CONVOLUTIONAL NETWORKS FOR SEMANTIC SEGMENTATION[51] C. M. Bishop, Pattern Recognition and Machine Learning. New York,NY, USA: Springer-Verlag, 2006, p. 229.[52] B. Hariharan, P. Arbelaez, L. Bourdev, S. Maji, and J. Malik,\u201cSemantic contours from inverse detectors,\u201d in Proc. Int. Conf.Comput. Vis., 2011, pp. 991\u2013998.[53] Y. A. LeCun, L. Bottou, G. B. Orr, and K.-R. M\u20aculler, \u201cEfficientbackprop,\u201d in Neural Networks: Tricks of the Trade. Berlin, Germany:Springer, 1998, pp. 9\u201348.[54] Y. Jia, et al., \u201cCaffe: Convolutional architecture for fast featureembedding,\u201d arXiv preprint arXiv:1408.5093, 2014.[55] N. Silberman, D. Hoiem, P. Kohli, and R. Fergus, \u201cIndoor segmentation and support inference from RGBD images,\u201d in Proc. Eur.Conf. Comput. Vis., 2012, pp. 746\u2013760.[56] S. Gupta, P. Arbelaez, and J. Malik, \u201cPerceptual organization andrecognition of indoor scenes from RGB-D images,\u201d in Proc. Comput. Vis. Pattern Recognit., 2013, pp. 564\u2013571.[57] C. Liu, J. Yuen, and A. Torralba, \u201cSift flow: Dense correspondenceacross scenes and its applications,\u201d IEEE Trans. Pattern Anal.Mach. Intell., vol. 33, no. 5, pp. 978\u2013994, May 2011.[58] J. Tighe and S. Lazebnik, \u201cSuperparsing: scalable nonparametricimage parsing with superpixels,\u201d in Proc. Eur. Conf. Comput. Vis.,2010, pp. 352\u2013365.[59] J. Tighe and S. Lazebnik, \u201cFinding things: Image parsing withregions and per-exemplar detectors,\u201d in Proc. Comput. Vis. PatternRecognit., 2013, pp. 3001\u20133008.[60] J. Dai, K. He, and J. Sun, \u201cConvolutional feature masking for jointobject and stuff segmentation,\u201d in Proc. Comput. Vis. Pattern Recognit., 2015, pp. 3992\u20134000.[61] J. Carreira, R. Caseiro, J. Batista, and C. Sminchisescu, \u201cSemanticsegmentation with second-order pooling,\u201d in Proc. Eur. Conf. Comput. Vis., 2012 pp. 430\u2013443.[62] R. Mottaghi, X. Chen, X. Liu, N.-G. Cho, S.-W. Lee, S. Fidler,R. Urtasun, and A. Yuille, \u201cThe role of context for object detectionand semantic segmentation in the wild,\u201d in IEEE Conf. Comput.Vis. Pattern Recognit., 2014, pp. 891\u2013898.Evan Shelhamer is a PhD student at UC Berkeleyadvised by Trevor Darrell as a member of theBerkeley Vision and Learning Center. He graduated from UMass Amherst in 2012 with dualdegrees in computer science and psychology andcompleted an honors thesis with Erik LearnedMiller. Evan\u2019s research interests are in visual recognition and machine learning with a focus ondeep learning and end-to-end optimization. He isthe lead developer of the Caffe framework.651Jonathan Long is a PhD candidate at UCBerkeley advised by Trevor Darrell as a memberof the Berkeley Vision and Learning Center. Hegraduated from Carnegie Mellon University in2010 with degrees in computer science, physics,and mathematics. Jon likes finding robust andrich solutions to recognition problems. His recentprojects focus on segmentation and detectionwith deep learning. He is a core developer of theCaffe framework.Trevor Darrell received the BSE degree fromthe University of Pennsylvania in 1988, havingstarted his career in computer vision as anundergraduate researcher in Ruzena Bajcsy\u2019sGRASP lab. He received the SM and PhDdegrees from MIT in 1992 and 1996, respectively. He is with the faculty of the CS Division ofthe EECS Department, UC Berkeley, and is alsoappointed at the UCB-affiliated InternationalComputer Science Institute (ICSI). He is thedirector of the Berkeley Vision and LearningCenter (BVLC) and is the faculty director of the PATH center in theUCB Institute of Transportation Studies. He was previously on the faculty of the MIT EECS department from 1999 to 2008, where he directedthe Vision Interface Group. His interests include computer vision,machine learning, computer graphics, and perception-based humancomputer interfaces. He was a member of the research staff at IntervalResearch Corporation from 1996 to 1999. He is a member of the IEEE.\" For more information on this or any other computing topic,please visit our Digital Library at www.computer.org/publications/dlib.\f", "This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence1Region-based Convolutional Networks forAccurate Object Detection and SegmentationRoss Girshick, Jeff Donahue, Student Member, IEEE, Trevor Darrell, Member, IEEE, andJitendra Malik, Fellow, IEEEAbstract\u2014Object detection performance, as measured on the canonical PASCAL VOC Challenge datasets, plateaued in the finalyears of the competition. The best-performing methods were complex ensemble systems that typically combined multiple low-levelimage features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves meanaverage precision (mAP) by more than 50% relative to the previous best result on VOC 2012\u2014achieving a mAP of 62.4%. Ourapproach combines two ideas: (1) one can apply high-capacity convolutional networks (CNNs) to bottom-up region proposals in orderto localize and segment objects and (2) when labeled training data are scarce, supervised pre-training for an auxiliary task, followed bydomain-specific fine-tuning, boosts performance significantly. Since we combine region proposals with CNNs, we call the resultingmodel an R-CNN or Region-based Convolutional Network. Source code for the complete system is available athttps://www.cs.berkeley.edu/\u223crbg/rcnn.Index Terms\u2014Object Recognition, Detection, Semantic Segmentation, Convolutional Networks, Deep Learning, Transfer LearningF1I NTRODUCTIONRECOGNIZING objects and localizing them in images isone of the most fundamental and challenging problemsin computer vision. There has been significant progress onthis problem over the last decade due largely to the useof low-level image features, such as SIFT [1] and HOG[2], in sophisticated machine learning frameworks. But ifwe look at performance on the canonical visual recognitiontask, PASCAL VOC object detection [3], it is generally acknowledged that progress slowed from 2010 onward, withsmall gains obtained by building ensemble systems andemploying minor variants of successful methods.SIFT and HOG are semi-local orientation histograms, arepresentation we could associate roughly with complexcells in V1, the first cortical area in the primate visualpathway. But we also know that recognition occurs severalstages downstream, which suggests that there might behierarchical, multi-stage processes for computing featuresthat are even more informative for visual recognition.In this paper, we describe an object detection and segmentation system that uses multi-layer convolutional networks to compute highly discriminative, yet invariant, features. We use these features to classify image regions, whichcan then be output as detected bounding boxes or pixel-levelsegmentation masks. On the PASCAL detection benchmark,our system achieves a relative improvement of more than50% mean average precision compared to the best methodsbased on low-level image features. Our approach also scaleswell with the number of object categories, which is a longstanding challenge for existing methods.\u2022\u2022R. Girshick is with Microsoft Research and was with the Department ofElectrical Engineering and Computer Science, UC Berkeley during themajority of this work. E-mail: rbg@eecs.berkeley.edu.J. Donahue, T. Darrell, and J. Malik are with the Department ofElectrical Engineering and Computer Science, UC Berkeley. E-mail:{jdonahue,trevor,malik}@eecs.berkeley.edu.We trace the roots of our approach to Fukushima\u2019s\u201cneocognitron\u201d [4], a hierarchical and shift-invariant modelfor pattern recognition. While the basic architecture of theneocognitron is used widely today, Fukushima\u2019s methodhad limited empirical success in part because it lacked asupervised training algorithm. Rumelhart et al. [5] showedthat a similar architecture could be trained with supervisederror backpropagation to classify synthetic renderings of thecharacters \u2018T\u2018 and \u2018C\u2018. Building on this work, LeCun and colleagues demonstrated in an influential sequence of papers(from [6] to [7]) that stochastic gradient descent via backpropagation was effective for training deeper networks forchallenging real-world handwritten character recognitionproblems. These models are now known as convolutional(neural) networks, CNNs, or ConvNets.CNNs saw heavy use in the 1990s, but then fell out offashion with the rise of support vector machines. In 2012,Krizhevsky et al. [8] rekindled interest in CNNs by showinga substantial improvement in image classification accuracyon the ImageNet Large Scale Visual Recognition Challenge(ILSVRC) [9], [10]. Their success resulted from training alarge CNN on 1.2 million labeled images, together with afew twists on CNNs from the 1990s (e.g., max(x, 0) \u201cReLU\u201dnon-linearities, \u201cdropout\u201d regularization, and a fast GPUimplementation).The significance of the ImageNet result was vigorouslydebated during the ILSVRC 2012 workshop. The centralissue can be distilled to the following: To what extent do theCNN classification results on ImageNet generalize to objectdetection results on the PASCAL VOC Challenge?We answered this question in a conference version of thispaper [11] by showing that a CNN can lead to dramaticallyhigher object detection performance on PASCAL VOC ascompared to systems based on simpler HOG-like features.To achieve this result, we bridged the gap between imageclassification and object detection by developing solutions0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence2to two problems: (1) How can we localize objects with adeep network? and (2) How can we train a high-capacitymodel with only a small quantity of annotated detectiondata?Unlike image classification, detection requires localizing(likely many) objects within an image. One approach is toframe detection as a regression problem. This formulationcan work well for localizing a single object, but detectingmultiple objects requires complex workarounds [12] or anad hoc assumption about the number of objects per image[13]. An alternative is to build a sliding-window detector.CNNs have been used in this way for at least two decades,typically on constrained object categories, such as faces[14], [15], hands [16], and pedestrians [17]. This approachis attractive in terms of computational efficiency, howeverits straightforward application requires all objects to sharea common aspect ratio. The aspect ratio problem can beaddressed with mixture models (e.g., [18]), where eachcomponent specializes in a narrow band of aspect ratios,or with bounding-box regression (e.g., [18], [19]).Instead, we solve the localization problem by operatingwithin the \u201crecognition using regions\u201d paradigm [20], whichhas been successful for both object detection [21] and semantic segmentation [22]. At test time, our method generatesaround 2000 category-independent region proposals for theinput image, extracts a fixed-length feature vector from eachproposal using a CNN, and then classifies each region withcategory-specific linear SVMs. We use a simple warpingtechnique (anisotropic image scaling) to compute a fixedsize CNN input from each region proposal, regardless of theregion\u2019s shape. Fig. 1 shows an overview of a Region-basedConvolutional Network (R-CNN) and highlights some ofour results.A second challenge faced in detection is that labeled dataare scarce and the amount currently available is insufficientfor training large CNNs from random initializations. Theconventional solution to this problem is to use unsupervised pre-training, followed by supervised fine-tuning (e.g.,[17]). The second principle contribution of this paper isto show that supervised pre-training on a large auxiliarydataset (ILSVRC), followed by domain-specific fine-tuningon a small dataset (PASCAL), is an effective paradigm forlearning high-capacity CNNs when data are scarce. In ourexperiments, fine-tuning for detection can improve mAPby as much as 8 percentage points. After fine-tuning, oursystem achieves a mAP of 63% on VOC 2010 comparedto 33% for the highly-tuned, HOG-based deformable partmodel (DPM) [18], [23].Our original motivation for using regions was born outof a pragmatic research methodology: move from imageclassification to object detection as simply as possible. Sincethen, this design choice has proved valuable because RCNNs are straightforward to implement and train (compared to sliding-window CNNs) and it provides a unifiedsolution to object detection and segmentation.This journal paper extends our earlier work [11] in anumber of ways. First, we provide more implementationdetails, rationales for design decisions, and ablation studies.Second, we present new results on PASCAL detection usingdeeper networks. Our approach is agnostic to the particularchoice of network architecture used and we show that recentR-CNN:Region-basedNetworkR-CNN:RegionsConvolutionalwith CNN featureswarped regionaeroplane? no....person? yes.CNN...tvmonitor? no.1. Inputimage2. Extract regionproposals (~2k)3. ComputeCNN features4. ClassifyregionsFig. 1. Object detection system overview. Our system (1) takes aninput image, (2) extracts around 2000 bottom-up region proposals, (3)computes features for each proposal using a large convolutional network(CNN), and then (4) classifies each region using class-specific linearSVMs. We trained an R-CNN that achieves a mean average precision(mAP) of 62.9% on PASCAL VOC 2010. For comparison, [21] reports35.1% mAP using the same region proposals, but with a spatial pyramidand bag-of-visual-words approach. The popular deformable part modelsperform at 33.4%. On the 200-class ILSVRC2013 detection dataset,we trained an R-CNN with a mAP of 31.4%, a large improvement overOverFeat [19], which had the previous best result at 24.3% mAP.work on deeper networks (e.g., [24]) translates into largeimprovements in object detection. Finally, we give a headto-head comparison of R-CNNs with the recently proposedOverFeat [19] detection system. OverFeat uses a slidingwindow CNN for detection and was a top-performingmethod on ILSVRC2013 detection. We train an R-CNN thatsignificantly outperforms OverFeat, with a mAP of 31.4%versus 24.3% on the 200-class ILSVRC2013 detection dataset.2R ELATED WORKDeep CNNs for object detection. There were several efforts[12], [13], [19] to use convolutional networks for PASCALstyle object detection concurrent with the development ofR-CNNs. Szegedy et al. [12] model object detection as aregression problem. Given an image window, they use aCNN to predict foreground pixels over a coarse grid forthe whole object as well as the object\u2019s top, bottom, leftand right halves. A grouping process then converts thepredicted masks into detected bounding boxes. Szegedy etal. train their model from a random initialization on VOC2012 trainval and get a mAP of 30.5% on VOC 2007 test. Incomparison, an R-CNN using the same network architecturegets a mAP of 58.5%, but uses supervised ImageNet pretraining. One hypothesis is that [12] performs worse becauseit does not use ImageNet pre-training. Recent work fromAgrawal et al. [25] shows that this is not the case; they findthat an R-CNN trained from a random initialization on VOC2007 trainval (using the same network architecture as [12])achieves a mAP of 40.7% on VOC 2007 test despite usinghalf the amount of training data as [12].Scalability and speed. In addition to being accurate, it\u2019simportant for object detection systems to scale well as thenumber of object categories increases. Significant effort hasgone into making methods like DPM [18] scale to thousands of object categories. For example, Dean et al. [26]replace exact filter convolutions in DPM with hashtablelookups. They show that with this technique it\u2019s possibleto run 10k DPM detectors in about 5 minutes per imageon a desktop workstation. However, there is an unfortunatetradeoff. When a large number of DPM detectors compete,the approximate hashing approach causes a substantial loss0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence3in detection accuracy. R-CNNs, in contrast, scale very wellwith the number of object classes to detect because nearlyall computation is shared between all object categories.The only class-specific computations are a reasonably smallmatrix-vector product and greedy non-maximum suppression. Although these computations scale linearly with thenumber of categories, the scale factor is small. Measuredempirically, it takes only 30ms longer to detect 200 classesthan 20 classes on a CPU, without any approximations. Thismakes it feasible to rapidly detect tens of thousands of objectcategories without any modifications to the core algorithm.Despite this graceful scaling behavior, an R-CNN cantake 10 to 45 seconds per image on a GPU, depending onthe network used, since each region is passed through thenetwork independently. Recent work from He et al. [27](\u201cSPPnet\u201d) improves R-CNN efficiency by sharing computation through a feature pyramid, allowing for detectionat a few frames per second. Building on SPPnet, Girshick[28] shows that it\u2019s possible to further reduce training andtesting times, while improving detection accuracy and simplifying the training process, using an approach called \u201cFastR-CNN.\u201d Fast R-CNN reduces testing times to 50 to 300msper image, depending on network architecture.This strategy is different from the dominant paradigmin recent neural network literature of unsupervised tranferlearning (see [40] for a survey covering unsupervised pretraining and represetation learning more generally). Supervised transfer learning using CNNs, but without finefuning, was also investigated in concurrent work by Donahue et al. [41]. They show that Krizhevsky et al.\u2019s CNN,once trained on ImageNet, can be used as a blackbox featureextractor, yielding excellent performing on several recognition tasks including scene classification, fine-grained subcategorization, and domain adaptation. Hoffman et al. [42]show how transfer learning can be used to train R-CNNs forclasses that have image-level labels, but no bounding-boxtraining data. Their approach is based on modeling the taskshift from image classification to object detection and thentransfering that knowledge to classes that have no detectiontraining data.Localization methods. The dominant approach to objectdetection has been based on sliding-window detectors. Thisapproach goes back (at least) to early face detectors [15],and continued with HOG-based pedestrian detection [2],and part-based generic object detection [18]. An alternativeis to first compute a pool of (likely overlapping) imageregions, each one serving as a candidate object, and thento filter these candidates in a way that aims to retain onlythe true objects. Multiple segmentation hypotheses wereused by Hoiem et al. [29] to estimate the rough geometricscene structure and by Russell et al. [30] to automaticallydiscover object classes in a set of images. The \u201cselectivesearch\u201d algorithm of van de Sande et al. [21] popularizedthe multiple segmentation approach for object detection byshowing strong results on PASCAL object detection. Ourapproach was inspired by the success of selective search.Object proposal generation is now an active researcharea. EdgeBoxes [31] outputs high-quality rectangular (box)proposals quickly (\u223c0.3s per image). BING [32] generatesbox proposals at \u223c3ms per image, however it has subsequently been shown that the proposal quality is too poor tobe useful in R-CNN [33]. Other methods focus on pixel-wisesegmentation, producing regions instead of boxes. Theseapproaches include RIGOR [34] and MCG [35], which take10 to 30s per image and GOP [36], a faster methods thattakes \u223c1s per image. For a more in-depth survey of proposalalgorithms, Hosang et al. [33] provide an insightful metaevaluation of recent methods.R-CNN extensions. Since their introduction, R-CNNs havebeen extended to a variety of new tasks and datasets. Karpathy et al. [43] learn a model for bi-directional image and sentence retrieval. Their image representation is derived froman R-CNN trained to detect 200 classes on the ILSVRC2013detection dataset. Gkioxari et al. [44] use multi-task learningto train R-CNNs for person detection, 2D pose estimation,and action recognition. Hariharan et al. [45] propose a unification of the object detection and semantic segmentationtasks, termed \u201csimultaneous detection and segmentation\u201d(SDS), and train a two-column R-CNN for this task. Theyshow that a single region proposal algorithm (MCG [35]) canbe used effectively for traditional bounding-box detection aswell as semantic segmentation. Their PASCAL segmentationresults improve significantly on the ones reported in thispaper. Gupta et al. [46] extend R-CNNs to object detection indepth images. They show that a well-designed input signal,where the depth map is augmented with height aboveground and local surface orientation with respect to gravity,allows training an R-CNN that outperforms existing RGB-Dobject detection baselines. Song et al. [47] train an R-CNNusing weak, image-level supervision by mining for positivetraining examples using a submodular cover algorithm andthen training a latent SVM.Many systems based on, or implementing, R-CNNs wereused in the recent ILSVRC2014 object detection challenge[48], resulting in substantial improvements in detectionaccuracy. In particular, the winning method, GoogLeNet[49], [50], uses an innovative network design in an R-CNN.With a single network (and a slightly simpler pipeline thatexcludes SVM training and bounding-box regression), theyimprove R-CNN performance to 38.0% mAP from a baslineof 34.5%. They also show that an ensemble of six networksimproves their result to 43.9% mAP.Transfer learning. R-CNN training is based on inductivetransfer learning, using the taxonomy of Pan and Yang [37].To train an R-CNN, we typically start with ImageNet classification as a source task and dataset, train a network usingsupervision, and then transfer that network to the targettask and dataset using supervised fine-tuning. This methodis related to traditional multi-task learning [38], [39], exceptthat we train for the tasks sequentially and are ultimatelyonly interested in performing well on the target task.Our object detection system consists of three modules.The first generates category-independent region proposals.These proposals define the set of candidate detections available to our detector. The second module is a convolutionalnetwork that extracts a fixed-length feature vector from eachregion. The third module is a set of class-specific linearSVMs. In this section, we present our design decisions for3O BJECT DETECTION WITH AN R-CNN0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence43.2aeroplanebicyclebirdcarFig. 2. Warped training samples from VOC 2007 train.each module, describe their test-time usage, detail howtheir parameters are learned, and show detection results onPASCAL VOC 2010-12 and ILSVRC2013.3.13.1.1Module designRegion proposalsA variety of recent papers offer methods for generatingcategory-independent region proposals. Examples include:objectness [51], selective search [21], category-independentobject proposals [52], constrained parametric min-cuts(CPMC) [22], multi-scale combinatorial grouping [35], andCires\u0327an et al. [53], who detect mitotic cells by applying aCNN to regularly-spaced square crops, which are a specialcase of region proposals. While R-CNN is agnostic to theparticular region proposal method, we use selective searchto enable a controlled comparison with prior detection work(e.g., [21], [54]).3.1.2Feature extractionWe extract a fixed-length feature vector from each regionproposal using a CNN. The particular CNN architectureused is a system hyperparameter. Most of our experimentsuse the Caffe [55] implementation of the CNN described byKrizhevsky et al. [8] (TorontoNet), however we have also experimented with the 16-layer deep network from Simonyanand Zisserman [24] (OxfordNet). In both cases, the featurevectors are 4096-dimensional. Features are computed byforward propagating a mean-subtracted S \u00d7 S RGB imagethrough the network and reading off the values output bythe penultimate layer (the layer just before the softmaxclassifier). For TorontoNet, S = 227 and for OxfordNetS = 224. We refer readers to [8], [24], [55] for more networkarchitecture details.In order to compute features for a region proposal, wemust first convert the image data in that region into a formthat is compatible with the CNN (its architecture requiresinputs of a fixed S \u00d7 S pixel size).1 Of the many possibletransformations of our arbitrary-shaped regions, we opt forthe simplest. Regardless of the size or aspect ratio of thecandidate region, we warp all pixels in a tight bounding boxaround it to the required size. Prior to warping, we dilatethe tight bounding box so that at the warped size there areexactly p pixels of warped image context around the originalbox (we use p = 16). Fig. 2 shows a random samplingof warped training regions. Alternatives to warping arediscussed in Section 7.1.1. Of course the entire network can be run convolutionally, whichenables handling arbitrary input sizes, however then the output sizeis no longer a fixed-length vector. The output can be converted to afixed-length through another transformation, such as in [27].Test-time detectionAt test time, we run selective search on the test imageto extract around 2000 region proposals (we use selectivesearch\u2019s \u201cfast mode\u201d in all experiments). We warp each proposal and forward propagate it through the CNN in orderto compute features. Then, for each class, we score eachextracted feature vector using the SVM trained for that class.Given all scored regions in an image, we apply a greedynon-maximum suppression (for each class independently)that rejects a region if it has an intersection-over-union (IoU)overlap with a higher scoring selected region larger than alearned threshold.3.2.1Run-time analysisTwo properties make detection efficient. First, all CNN parameters are shared across all categories. Second, the featurevectors computed by the CNN are low-dimensional whencompared to other common approaches, such as spatialpyramids with bag-of-visual-word encodings. The featuresused in the UVA detection system [21], for example, aretwo orders of magnitude larger than ours (360k vs. 4kdimensional).The result of such sharing is that the time spent computing region proposals and features (10s/image on an NVIDIATitan Black GPU or 53s/image on a CPU, using TorontoNet) is amortized over all classes. The only class-specificcomputations are dot products between features and SVMweights and non-maximum suppression. In practice, all dotproducts for an image are batched into a single matrixmatrix product. The feature matrix is typically 2000 \u00d7 4096and the SVM weight matrix is 4096 \u00d7 N , where N is thenumber of classes.This analysis shows that R-CNNs can scale to thousands of object classes without resorting to approximatetechniques, such as hashing. Even if there were 100k classes,the resulting matrix multiplication takes only 10 seconds ona modern multi-core CPU. This efficiency is not merely theresult of using region proposals and shared features. TheUVA system, due to its high-dimensional features, wouldbe two orders of magnitude slower while requiring 134GBof memory just to store 100k linear predictors, compared tojust 1.5GB for our lower-dimensional features.It is also interesting to contrast R-CNNs with the recentwork from Dean et al. on scalable detection using DPMsand hashing [56]. They report a mAP of around 16% onVOC 2007 at a run-time of 5 minutes per image whenintroducing 10k distractor classes. With our approach, 10kdetectors can run in about a minute on a CPU, and becauseno approximations are made mAP would remain at 59%with TorontoNet and 66% with OxfordNet (Section 4.2).3.33.3.1TrainingSupervised pre-trainingWe discriminatively pre-trained the CNN on a large auxiliary dataset (ILSVRC2012 classification) using image-level annotations only (bounding-box labels are not available for thisdata). Pre-training was performed using the open sourceCaffe CNN library [55].0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence53.3.2 Domain-specific fine-tuningTo adapt the CNN to the new task (detection) and the newdomain (warped proposal windows), we continue stochasticgradient descent (SGD) training of the CNN parametersusing only warped region proposals. Aside from replacingthe CNN\u2019s ImageNet-specific 1000-way classification layerwith a randomly initialized (N + 1)-way classification layer(where N is the number of object classes, plus 1 for background), the CNN architecture is unchanged. For VOC,N = 20 and for ILSVRC2013, N = 200. We treat all regionproposals with \u2265 0.5 IoU overlap with a ground-truth boxas positives for that box\u2019s class and the rest as negatives. Westart SGD at a learning rate of 0.001 (1/10th of the initial pretraining rate), which allows fine-tuning to make progresswhile not clobbering the initialization. In each SGD iteration,we uniformly sample 32 positive windows (over all classes)and 96 background windows to construct a mini-batch ofsize 128. We bias the sampling towards positive windowsbecause they are extremely rare compared to background.OxfordNet requires more memory than TorontoNet makingit necessary to decrease the minibatch size in order to fit ona single GPU. We decreased the batch size from 128 to just24 while maintaining the same biased sampling scheme.3.3.3 Object category classifiersConsider training a binary classifier to detect cars. It\u2019s clearthat an image region tightly enclosing a car should be a positive example. Similarly, it\u2019s clear that a background region,which has nothing to do with cars, should be a negativeexample. Less clear is how to label a region that partiallyoverlaps a car. We resolve this issue with an IoU overlapthreshold, below which regions are defined as negatives.The overlap threshold, 0.3, was selected by a grid searchover {0, 0.1, . . . , 0.5} on a validation set. We found thatselecting this threshold carefully is important. Setting it to0.5, as in [21], decreased mAP by 5 points. Similarly, settingit to 0 decreased mAP by 4 points. Positive examples aredefined simply to be the ground-truth bounding boxes foreach class.Once features are extracted and training labels are applied, we optimize one linear SVM per class. Since thetraining data are too large to fit in memory, we adopt thestandard hard negative mining method [18], [58]. Hardnegative mining converges quickly and in practice mAPstops increasing after only a single pass over all images.In Section 7.2 we discuss why the positive and negativeexamples are defined differently in fine-tuning versus SVMtraining. We also discuss the trade-offs involved in trainingdetection SVMs rather than simply using the outputs fromthe final softmax layer of the fine-tuned CNN.3.4Results on PASCAL VOC 2010-12Following the PASCAL VOC best practices [3], we validatedall design decisions and hyperparameters on the VOC 2007dataset (Section 4.2). For final results on the VOC 2010-12datasets, we fine-tuned the CNN on VOC 2012 train andoptimized our detection SVMs on VOC 2012 trainval. Wesubmitted test results to the evaluation server only once foreach of the two major algorithm variants (with and withoutbounding-box regression).Table 1 shows complete results on VOC 2010.2 We compare our method against four strong baselines, includingSegDPM [57], which combines DPM detectors with the output of a semantic segmentation system [59] and uses additional inter-detector context and image-classifier rescoring.The most germane comparison is to the UVA system fromUijlings et al. [21], since our systems use the same regionproposal algorithm. To classify regions, their method buildsa four-level spatial pyramid and populates it with denselysampled SIFT, Extended OpponentSIFT, and RGB-SIFT descriptors, each vector quantized with 4000-word codebooks.Classification is performed with a histogram intersectionkernel SVM. Compared to their multi-feature, non-linearkernel SVM approach, we achieve a large improvement inmAP, from 35.1% to 53.7% mAP with TorontoNet and 62.9%with OxfordNet, while also being much faster. R-CNNsachieve similar performance (53.3% / 62.4% mAP) on VOC2012 test.3.5Results on ILSVRC2013 detectionWe ran an R-CNN on the 200-class ILSVRC2013 detectiondataset using the same system hyperparameters that weused for PASCAL VOC. We followed the same protocolof submitting test results to the ILSVRC2013 evaluationserver only twice, once with and once without boundingbox regression.Fig. 3 compares our R-CNN to the entries in the ILSVRC2013 competition and to the post-competition OverFeat result [19]. Using TorontoNet, our R-CNN achieves a mAPof 31.4%, which is significantly ahead of the second-bestresult of 24.3% from OverFeat. To give a sense of the APdistribution over classes, box plots are also presented. Mostof the competing submissions (OverFeat, NEC-MU, TorontoA, and UIUC-IFP) used convolutional networks, indicatingthat there is significant nuance in how CNNs can be appliedto object detection, leading to greatly varying outcomes. Notably, UvA-Euvision\u2019s entry did not CNNs and was basedon a fast VLAD encoding [60].In Section 5, we give an overview of the ILSVRC2013detection dataset and provide details about choices that wemade when training R-CNNs on it.44.1A NALYSISVisualizing learned featuresFirst-layer filters can be visualized directly and are easyto understand [8]. They capture oriented edges and opponent colors. Understanding the subsequent layers is morechallenging. Zeiler and Fergus present a visually attractivedeconvolutional approach in [63]. We propose a simple(and complementary) non-parametric method that directlyshows what the network learned.The idea is to single out a particular unit (feature) in thenetwork and use it as if it were an object detector in its ownright. That is, we compute the unit\u2019s activations on a largeset of held-out region proposals (about 10 million), sort the2. We use VOC 2010 because there are more published results compared to 2012. Additionally, VOC 2010, 2011, 2012 are very similardatasets, with 2011 and 2012 being identical (for the detection task).0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence6TABLE 1Detection average precision (%) on VOC 2010 test. T-Net stands for TorontoNet and O-Net for OxfordNet (Section 3.1.2). R-CNNs are mostdirectly comparable to UVA and Regionlets since all methods use selective search region proposals. Bounding-box regression (BB) is described inSection 7.3. At publication time, SegDPM was the top-performer on the PASCAL VOC leaderboard. DPM and SegDPM use context rescoring notused by the other methods. SegDPM and all R-CNNs use additional training data.VOC 2010 testaero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv mAPDPM v5 [23]49.2 53.8 13.1 15.3 35.5 53.4 49.7 27.0 17.2 28.8 14.7 17.8 46.451.247.710.834.2 20.7 43.8 38.3 33.4UVA [21]56.2 42.4 15.3 12.6 21.8 49.3 36.8 46.1 12.9 32.1 30.0 36.5 43.552.932.915.341.1 31.8 47.0 44.8 35.1Regionlets [54]65.0 48.9 25.9 24.6 24.5 56.1 54.5 51.2 17.0 28.9 30.2 35.8 40.255.743.514.343.9 32.6 54.0 45.9 39.7SegDPM [57]61.4 53.4 25.6 25.2 35.5 51.7 50.6 50.8 19.3 33.8 26.8 40.4 48.354.447.114.838.7 35.0 52.8 43.1 40.4R-CNN T-Net67.1 64.1 46.7 32.0 30.5 56.4 57.2 65.9 27.0 47.3 40.9 66.6 57.865.953.626.756.5 38.1 52.8 50.2 50.2R-CNN T-Net BB 71.8 65.8 53.0 36.8 35.9 59.7 60.0 69.9 27.9 50.6 41.4 70.0 62.069.058.129.559.4 39.3 61.2 52.4 53.7R-CNN O-Net76.5 70.4 58.0 40.2 39.6 61.8 63.7 81.0 36.2 64.5 45.7 80.5 71.974.360.631.564.7 52.5 64.6 57.2 59.8R-CNN O-Net BB 79.3 72.4 63.1 44.0 44.4 64.6 66.3 84.9 38.8 67.3 48.4 82.3 75.076.765.735.866.2 54.8 69.1 58.8 62.9ILSVRC2013 detection test set mAPSYSU_Vision10.5%*R\u2212CNN BB9.8%GPU_UCLA6.1%Deltacompetition resultpost competition resultUIUC\u2212IFP 1.0%020406080100mean average precision (mAP) in %UIUC\u2212IFP11.5%DeltaToronto AGPU_UCLA19.4%*OverFeat (1)SYSU_Vision20.9%*NEC\u2212MUToronto A22.6%*OverFeat (1)24.3%*OverFeat (2)UvA\u2212Euvision*NEC\u2212MUaverage precision (AP) in %31.4%*R\u2212CNN BBUvA\u2212EuvisionILSVRC2013 detection test set class AP box plots1009080706050403020100Fig. 3. (Left) Mean average precision on the ILSVRC2013 detection test set. Methods preceeded by * use outside training data (images and labelsfrom the ILSVRC classification dataset in all cases). (Right) Box plots for the 200 average precision values per method. A box plot for the postcompetition OverFeat result is not shown because per-class APs are not yet available. The red line marks the median AP, the box bottom and topare the 25th and 75th percentiles. The whiskers extend to the min and max AP of each method. Each AP is plotted as a green dot over the whiskers(best viewed digitally with zoom).1.01.00.90.90.90.90.90.90.90.90.90.90.90.90.90.91.00.90.90.80.80.80.70.70.70.70.70.70.70.70.60.61.00.80.70.70.70.70.70.70.70.70.70.70.70.70.60.61.00.90.80.80.80.70.70.70.70.70.70.70.70.70.70.71.01.00.90.90.90.80.80.80.80.80.80.80.80.80.80.81.00.90.80.80.80.70.70.70.70.70.70.70.70.70.70.7Fig. 4. Top regions for six pool5 units. Receptive fields and activation values are drawn in white. Some units are aligned to concepts, such as people(row 1) or text (4). Other units capture texture and material properties, such as dot arrays (2) and specular reflections (6).proposals from highest to lowest activation, perform nonmaximum suppression, and then display the top-scoringregions. Our method lets the selected unit \u201cspeak for itself\u201dby showing exactly which inputs it fires on. We avoidaveraging in order to see different visual modes and gaininsight into the invariances computed by the unit.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence7TABLE 2Detection average precision (%) on VOC 2007 test. Rows 1-3 show R-CNN performance without fine-tuning. Rows 4-6 show results for the CNNpre-trained on ILSVRC 2012 and then fine-tuned (FT) on VOC 2007 trainval. Row 7 includes a simple bounding-box regression (BB) stage thatreduces localization errors (Section 7.3). Rows 8-10 present DPM methods as a strong baseline. The first uses only HOG, while the next two usedifferent feature learning approaches to augment or replace HOG. All R-CNN results use TorontoNet.VOC 2007 testaero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv mAPR-CNN pool551.8 60.2 36.4 27.8 23.2 52.8 60.6 49.2 18.3 47.8 44.3 40.8 56.658.742.423.446.1 36.7 51.3 55.7 44.2R-CNN fc659.3 61.8 43.1 34.0 25.1 53.1 60.6 52.8 21.7 47.8 42.7 47.8 52.558.544.625.648.3 34.0 53.1 58.0 46.2R-CNN fc757.6 57.9 38.5 31.8 23.7 51.2 58.9 51.4 20.0 50.5 40.9 46.0 51.655.943.323.348.1 35.3 51.0 57.4 44.7R-CNN FT pool5 58.2 63.3 37.9 27.6 26.1 54.1 66.9 51.4 26.7 55.5 43.4 43.1 57.759.045.828.150.8 40.6 53.1 56.4 47.3R-CNN FT fc663.5 66.0 47.9 37.7 29.9 62.5 70.2 60.2 32.0 57.9 47.0 53.5 60.164.252.231.355.0 50.0 57.7 63.0 53.1R-CNN FT fc764.2 69.7 50.0 41.9 32.0 62.6 71.0 60.7 32.7 58.5 46.5 56.1 60.666.854.231.552.8 48.9 57.9 64.7 54.2R-CNN FT fc7 BB 68.1 72.8 56.8 43.0 36.8 66.3 74.2 67.6 34.4 63.5 54.5 61.2 69.168.658.733.462.9 51.1 62.5 64.8 58.5DPM v5 [23]DPM ST [61]DPM HSC [62]33.2 60.3 10.2 16.123.8 58.2 10.5 8.532.2 58.3 11.5 16.327.327.130.654.3 58.2 23.050.4 52.0 7.349.9 54.8 23.520.019.221.524.122.827.726.718.134.012.78.013.758.155.958.148.244.851.643.232.439.912.013.312.421.115.923.536.122.834.446.046.247.443.544.945.233.729.134.3TABLE 3Detection average precision (%) on VOC 2007 test for two different CNN architectures. The first two rows are results from Table 2 using Krizhevskyet al.\u2019s TorontoNet architecture (T-Net). Rows three and four use the recently proposed 16-layer OxfordNet architecture (O-Net) from Simonyanand Zisserman [24].VOC 2007 testaero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv mAPR-CNN T-Net64.2 69.7 50.0 41.9 32.0 62.6 71.0 60.7 32.7 58.5 46.5 56.1 60.666.854.231.552.8 48.9 57.9 64.7 54.268.658.733.462.9 51.1 62.5 64.8 58.5R-CNN T-Net BB 68.1 72.8 56.8 43.0 36.8 66.3 74.2 67.6 34.4 63.5 54.5 61.2 69.1R-CNN O-Net71.6 73.5 58.1 42.2 39.4 70.7 76.0 74.5 38.7 71.0 56.9 74.5 67.969.659.335.762.1 64.0 66.5 71.2 62.273.164.235.666.8 67.2 70.4 71.1 66.0R-CNN O-Net BB 73.4 77.0 63.4 45.4 44.6 75.1 78.1 79.8 40.5 73.7 62.2 79.4 78.1We visualize units from layer pool5 of a TorontoNet,which is the max-pooled output of the network\u2019s fifthand final convolutional layer. The pool5 feature map is6 \u00d7 6 \u00d7 256 = 9216-dimensional. Ignoring boundary effects,each pool5 unit has a receptive field of 195 \u00d7 195 pixels inthe original 227 \u00d7 227 pixel input. A central pool5 unit hasa nearly global view, while one near the edge has a smaller,clipped support.Each row in Fig. 4 displays the top 16 activations for apool5 unit from a CNN that we fine-tuned on VOC 2007trainval. Six of the 256 functionally unique units are visualized. These units were selected to show a representativesample of what the network learns. In the second row,we see a unit that fires on dog faces and dot arrays. Theunit corresponding to the third row is a red blob detector.There are also detectors for human faces and more abstractpatterns such as text and triangular structures with windows. The network appears to learn a representation thatcombines a small number of class-tuned features togetherwith a distributed representation of shape, texture, color,and material properties. The subsequent fully connectedlayer fc6 has the ability to model a large set of compositionsof these rich features. Agrawal et al. [25] provide a morein-depth analysis of the learned features.4.2feature map (reshaped as a 9216-dimensional vector) andthen adds a vector of biases. This intermediate vector iscomponent-wise half-wave rectified (x \u2190 max(0, x)).Layer fc7 is the final layer of the network. It is implemented by multiplying the features computed by fc6 by a4096 \u00d7 4096 weight matrix, and similarly adding a vector ofbiases and applying half-wave rectification.We start by looking at results from the CNN withoutfine-tuning on PASCAL, i.e. all CNN parameters were pretrained on ILSVRC 2012 only. Analyzing performance layerby-layer (Table 2 rows 1-3) reveals that features from fc7generalize worse than features from fc6 . This means that29%, or about 16.8 million, of the CNN\u2019s parameters canbe removed without degrading mAP. More surprising isthat removing both fc7 and fc6 produces quite good resultseven though pool5 features are computed using only 6% ofthe CNN\u2019s parameters. Much of the CNN\u2019s representationalpower comes from its convolutional layers, rather thanfrom the much larger densely connected layers. This findingsuggests potential utility in computing a dense feature map,in the sense of HOG, of an arbitrary-sized image by usingonly the convolutional layers of the CNN. This representation would enable experimentation with sliding-windowdetectors, including DPM, on top of pool5 features.Ablation studies4.2.1 Performance layer-by-layer, without fine-tuningTo understand which layers are critical for detection performance, we analyzed results on the VOC 2007 datasetfor each of the TorontoNet\u2019s last three layers. Layer pool5was briefly described in Section 4.1. The final two layers aresummarized below.Layer fc6 is fully connected to pool5 . To compute features, it multiplies a 4096 \u00d7 9216 weight matrix by the pool54.2.2Performance layer-by-layer, with fine-tuningWe now look at results from our CNN after having finetuned its parameters on VOC 2007 trainval. The improvement is striking (Table 2 rows 4-6): fine-tuning increasesmAP by 8.0 percentage points to 54.2%. The boost from finetuning is much larger for fc6 and fc7 than for pool5 , whichsuggests that the pool5 features learned from ImageNetare general and that most of the improvement is gained0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence84.3Network architecturesMost results in this paper use the TorontoNet networkarchitecture from Krizhevsky et al. [8]. However, we havefound that the choice of architecture has a large effect on RCNN detection performance. In Table 3, we show results onVOC 2007 test using the 16-layer deep OxfordNet recentlyproposed by Simonyan and Zisserman [24]. This networkwas one of the top performers in the recent ILSVRC 2014classification challenge. The network has a homogeneousstructure consisting of 13 layers of 3\u00d73 convolution kernels,with five max pooling layers interspersed, and topped withthree fully-connected layers.To use OxfordNet in an R-CNN, we downloaded thepublicly available pre-trained network weights for theVGG_ILSVRC_16_layers model from the Caffe ModelZoo.3 We then fine-tuned the network using the same protocol as we used for TorontoNet. The only difference was touse smaller minibatches (24 examples) as required in orderto fit within GPU memory. The results in Table 3 showthat an R-CNN with OxfordNet substantially outperformsan R-CNN with TorontoNet, increasing mAP from 58.5% to66.0%. However there is a considerable drawback in termsof compute time, with the forward pass of OxfordNet taking3. https://github.com/BVLC/caffe/wiki/Model-Zoo4.4Detection error analysisWe applied the excellent detection analysis tool from Hoiemet al. [64] in order to reveal our method\u2019s error modes,understand how fine-tuning changes them, and to see howour error types compare with DPM. A full summary ofthe analysis tool is beyond the scope of this paper and weencourage readers to consult [64] to understand some finerdetails (such as \u201cnormalized AP\u201d). Since the analysis is bestabsorbed in the context of the associated plots, we presentthe discussion within the captions of Fig. 5 and Fig. 6.R\u2212CNN fc6: animalsR\u2212CNN FT fc7: animals806020025100LocSimOthBG6020025604020LocSimOthBG80604020LocSimOthBG00100 400 1600 6400 25100 400 1600 6400 25100 400 1600 6400total false positivestotal false positivestotal false positivesR\u2212CNN fc6: furnitureR\u2212CNN FT fc7: furnitureR\u2212CNN FT fc7 BB: furniture100100804080LocSimOthBG806040200100 400 1600 6400 25total false positivesLocSimOthBGpercentage of each type40R\u2212CNN FT fc7 BB: animals100100percentage of each type100percentage of each typeRelatively few feature learning methods have been tried onPASCAL VOC detection. We look at two recent approachesthat build on deformable part models. For reference, we alsoinclude results for the standard HOG-based DPM [23].The first DPM feature learning method, DPM ST [61],augments HOG features with histograms of \u201csketch token\u201dprobabilities. Intuitively, a sketch token is a tight distribution of contours passing through the center of an imagepatch. Sketch token probabilities are computed at each pixelby a random forest that was trained to classify 35 \u00d7 35 pixelpatches into one of 150 sketch tokens or background.The second method, DPM HSC [62], replaces HOG withhistograms of sparse codes (HSC). To compute an HSC,sparse code activations are solved for at each pixel usinga learned dictionary of 100 7 \u00d7 7 pixel (grayscale) atoms.The resulting activations are rectified in three ways (full andboth half-waves), spatially pooled, unit `2 normalized, andthen power transformed (x \u2190 sign(x)|x|\u03b1 ).All R-CNN variants strongly outperform the three DPMbaselines (Table 2 rows 8-10), including the two that usefeature learning. Compared to the latest version of DPM,which uses only HOG features, our mAP is more than20 percentage points higher: 54.2% vs. 33.7%\u2014a 61% relative improvement. The combination of HOG and sketchtokens yields 2.5 mAP points over HOG alone, while HSCimproves over HOG by 4 mAP points (when comparedinternally to their private DPM baselines\u2014both use nonpublic implementations of DPM that underperform theopen source version [23]). These methods achieve mAPs of29.1% and 34.3%, respectively.percentage of each typeComparison to recent feature learning methodspercentage of each type4.2.3roughly 7 times longer than TorontoNet. From a transferlearning point of view, it is very encouraging that largeimprovements in image classification translate directly intolarge improvements in object detection.percentage of each typefrom learning domain-specific non-linear classifiers on topof them.806040200100 400 1600 6400 25total false positivesLocSimOthBG100 400 1600 6400total false positivesFig. 5. Distribution of top-ranked false positive (FP) types for R-CNNswith TorontoNet. Each plot shows the evolving distribution of FP typesas more FPs are considered in order of decreasing score. Each FPis categorized into 1 of 4 types: Loc\u2014poor localization (a detectionwith an IoU overlap with the correct class between 0.1 and 0.5, or aduplicate); Sim\u2014confusion with a similar category; Oth\u2014confusion witha dissimilar object category; BG\u2014a FP that fired on background. Compared with DPM (see [64]), significantly more of our errors result frompoor localization, rather than confusion with background or other objectclasses, indicating that the CNN features are much more discriminativethan HOG. Loose localization likely results from our use of bottom-upregion proposals and the positional invariance learned from pre-trainingthe CNN for whole-image classification. Column three shows how oursimple bounding-box regression method fixes many localization errors.4.5Bounding-box regressionBased on the error analysis, we implemented a simple method to reduce localization errors. Inspired by thebounding-box regression employed in DPM [18], we train alinear regression model to predict a new detection windowgiven the pool5 features for a selective search region proposal. Full details are given in Section 7.3. Results in Table 1,Table 2, and Fig. 5 show that this simple approach fixes alarge number of mislocalized detections, boosting mAP by3 to 4 points.4.6Qualitative resultsQualitative detection results on ILSVRC2013 are presentedin Fig. 8. Each image was sampled randomly from the val20162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence90.5570.5160.6090.4200.40.20.6770.6060.344 0.3510.2120.2010.244normalized APnormalized AP0.7200.6120.60.7660.7010.6720.6340.6 0.5930.7230.6850.4980.442 0.4290.40.3350.2R\u2212CNN FT fc7 BB: sensitivity and impact0.80.3250.1790.7860.7310.60.7790.5420.4840.40.20.7200.7090.6760.633DPM voc\u2212release5: sensitivity and impact0.80.4530.3850.3680.211normalized APR\u2212CNN FT fc7: sensitivity and impact0.8normalized APR\u2212CNN fc6: sensitivity and impact0.80.60.4870.40.2970.2160.20.126 0.1370.1320.0560occtrnsize asp view part0occtrnsize asp view part0occtrnsize asp view part00.4530.391 0.3880.339 0.347occtrn0.094size asp view partFig. 6. Sensitivity to object characteristics. Each plot shows the mean (over classes) normalized AP (see [64]) for the highest and lowest performingsubsets within six different object characteristics (occlusion, truncation, bounding-box area, aspect ratio, viewpoint, part visibility). For example,bounding-box area comprises the subsets extra-small, small, ..., extra-large. We show plots for our method (R-CNN) with and without fine-tuning(FT) and bounding-box regression (BB) as well as for DPM voc-release5. Overall, fine-tuning does not reduce sensitivity (the difference betweenmax and min), but does substantially improve both the highest and lowest performing subsets for nearly all characteristics. This indicates thatfine-tuning does more than simply improve the lowest performing subsets for aspect ratio and bounding-box area, as one might conjecture basedon how we warp network inputs. Instead, fine-tuning improves robustness for all characteristics including occlusion, truncation, viewpoint, and partvisibility.set and all detections from all detectors with a precisiongreater than 0.5 are shown. Note that these are not curatedand give a realistic impression of the detectors in action.5T HE ILSVRC2013 DETECTION DATASETIn Section 3 we presented results on the ILSVRC2013 detection dataset. This dataset is less homogeneous than PASCALVOC, requiring choices about how to use it. Since thesedecisions are non-trivial, we cover them in this section. Themethodology and \u201cval1 \u201d and \u201cval2 \u201d data splits introducedin this section were used widely by participants in theILSVRC2014 detection challenge.5.1Dataset overviewThe ILSVRC2013 detection dataset is split into three sets:train (395,918), val (20,121), and test (40,152), where thenumber of images in each set is in parentheses. The valand test splits are drawn from the same image distribution. These images are scene-like and similar in complexity(number of objects, amount of clutter, pose variability, etc.)to PASCAL VOC images. The val and test splits are exhaustively annotated, meaning that in each image all instancesfrom all 200 classes are labeled with bounding boxes. Thetrain set, in contrast, is drawn from the ILSVRC2013 classification image distribution. These images have more variablecomplexity with a skew towards images of a single centeredobject. Unlike val and test, the train images (due to theirlarge number) are not exhaustively annotated. In any giventrain image, instances from the 200 classes may or may notbe labeled. In addition to these image sets, each class has anextra set of negative images. Negative images are manuallychecked to validate that they do not contain any instancesof their associated class. The negative image sets were notused in this work. More information on how ILSVRC wascollected and annotated can be found in [65], [66].The nature of these splits presents a number of choicesfor training an R-CNN. The train images cannot be used forhard negative mining, because annotations are not exhaustive. Where should negative examples come from? Also,the train images have different statistics than val and test.Should the train images be used at all, and if so, to whatextent? While we have not thoroughly evaluated a largenumber of choices, we present what seemed like the mostobvious path based on previous experience.Our general strategy is to rely heavily on the val setand use some of the train images as an auxiliary sourceof positive examples. To use val for both training andvalidation, we split it into roughly equally sized \u201cval1 \u201d and\u201cval2 \u201d sets. Since some classes have very few examples inval (the smallest has only 31 and half have fewer than 110),it is important to produce an approximately class-balancedpartition. To do this, a large number of candidate splitswere generated and the one with the smallest maximumrelative class imbalance was selected.4 Each candidate splitwas generated by clustering val images using their classcounts as features, followed by a randomized local searchthat may improve the split balance. The particular split usedhere has a maximum relative imbalance of about 11% anda median relative imbalance of 4%. The val1 /val2 split andcode used to produce them are publicly available in the RCNN code repository, allowing other researchers to comparetheir methods on the val splits used in this report.5.2Region proposalsWe followed the same region proposal approach that wasused for detection on PASCAL. Selective search [21] wasrun in \u201cfast mode\u201d on each image in val1 , val2 , and test(but not on images in train). One minor modification wasrequired to deal with the fact that selective search is not scaleinvariant and so the number of regions produced dependson the image resolution. ILSVRC image sizes range fromvery small to a few that are several mega-pixels, and sowe resized each image to a fixed width (500 pixels) beforerunning selective search. On val, selective search resultedin an average of 2403 region proposals per image with a91.6% recall of all ground-truth bounding boxes (at 0.5 IoUthreshold). This recall is notably lower than in PASCAL,where it is approximately 98%, indicating significant roomfor improvement in the region proposal stage.5.3Training dataFor training data, we formed a set of images and boxes thatincludes all selective search and ground-truth boxes from4. Relative imbalance is measured as |a \u2212 b|/(a + b) where a and bare class counts in each half of the split.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence10val1 together with up to N ground-truth boxes per classfrom train (if a class has fewer than N ground-truth boxesin train, then we take all of them). We\u2019ll call this datasetof images and boxes val1 +trainN . In an ablation study, weshow mAP on val2 for N \u2208 {0, 500, 1000} (Section 5.5).Training data are required for three procedures in RCNN: (1) CNN fine-tuning, (2) detector SVM training, and(3) bounding-box regressor training. CNN fine-tuning wasrun for 50k SGD iteration on val1 +trainN using the exactsame settings as were used for PASCAL. Fine-tuning ona single NVIDIA Tesla K20 took 13 hours using Caffe.For SVM training, all ground-truth boxes from val1 +trainNwere used as positive examples for their respective classes.Hard negative mining was performed on a randomly selected subset of 5000 images from val1 . An initial experimentindicated that mining negatives from all of val1 , versus a5000 image subset (roughly half of it), resulted in only a 0.5percentage point drop in mAP, while cutting SVM trainingtime in half. No negative examples were taken from trainbecause the annotations are not exhaustive. The extra sets ofverified negative images were not used. The bounding-boxregressors were trained on val1 .5.4Validation and evaluationBefore submitting results to the evaluation server, we validated data usage choices and the effect of fine-tuningand bounding-box regression on the val2 set using thetraining data described above. All system hyperparameters(e.g., SVM C hyperparameters, padding used in regionwarping, NMS thresholds, bounding-box regression hyperparameters) were fixed at the same values used for PASCAL. Undoubtedly some of these hyperparameter choicesare slightly suboptimal for ILSVRC, however the goal ofthis work was to produce a preliminary R-CNN result onILSVRC without extensive dataset tuning. After selectingthe best choices on val2 , we submitted exactly two resultfiles to the ILSVRC2013 evaluation server. The first submission was without bounding-box regression and the secondsubmission was with bounding-box regression. For thesesubmissions, we expanded the SVM and bounding-box regressor training sets to use val+train1k and val, respectively.We used the CNN that was fine-tuned on val1 +train1k toavoid re-running fine-tuning and feature computation.5.5Ablation studyTable 4 shows an ablation study of the effects of differentamounts of training data, fine-tuning, and bounding-boxregression. A first observation is that mAP on val2 matchesmAP on test very closely. This gives us confidence thatmAP on val2 is a good indicator of test set performance.The first result, 20.9%, is what R-CNN achieves using aCNN pre-trained on the ILSVRC2012 classification dataset(no fine-tuning) and given access to the small amount oftraining data in val1 (recall that half of the classes in val1have between 15 and 55 examples). Expanding the trainingset to val1 +trainN improves performance to 24.1%, withessentially no difference between N = 500 and N = 1000.Fine-tuning the CNN using examples from just val1 givesa modest improvement to 26.5%, however there is likelysignificant overfitting due to the small number of positive training examples. Expanding the fine-tuning set toval1 +train1k , which adds up to 1000 positive examples perclass from the train set, helps significantly, boosting mAP to29.7%. Bounding-box regression improves results to 31.0%,which is a smaller relative gain that what was observed inPASCAL.5.6Relationship to OverFeatThere is an interesting relationship between R-CNN andOverFeat: OverFeat can be seen (roughly) as a special caseof an R-CNN. If one were to replace selective search regionproposals with a multi-scale pyramid of regular squareregions and change the per-class bounding-box regressorsto a single bounding-box regressor, then the systems wouldbe very similar (modulo some potentially significant differences in how they are trained: CNN detection fine-tuning,using SVMs, etc.). It is worth noting that OverFeat has asignificant speed advantage over R-CNN: it is about 9xfaster, based on a figure of 2 seconds per image quoted from[19]. This speed comes from the fact that OverFeat\u2019s slidingwindows (i.e., region proposals) are not warped at theimage level and therefore computation can be easily sharedbetween overlapping windows. Sharing is implemented byrunning the entire network in a convolutional fashion overarbitrary-sized inputs. OverFeat is slower than the pyramidbased version of R-CNN from He et al. [27].6S EMANTIC SEGMENTATIONRegion classification is a standard technique for semanticsegmentation, allowing us to easily apply R-CNNs to thePASCAL VOC segmentation challenge. To facilitate a directcomparison with the current leading semantic segmentation system (called O2 P for \u201csecond-order pooling\u201d) [59],we work within their open source framework. O2 P usesCPMC to generate 150 region proposals per image and thenpredicts the quality of each region, for each class, usingsupport vector regression (SVR). The high performance oftheir approach is due to the quality of the CPMC regionsand the powerful second-order pooling of multiple featuretypes (enriched variants of SIFT and LBP). We also notethat Farabet et al. [67] recently demonstrated good resultson several dense scene labeling datasets (not includingPASCAL) using a CNN as a multi-scale per-pixel classifier.We follow [59], [68] and extend the PASCAL segmentation training set to include the extra annotations madeavailable by Hariharan et al. [69]. Design decisions andhyperparameters were cross-validated on the VOC 2011validation set. Final test results were evaluated only once.6.1CNN features for segmentationWe evaluate three strategies for computing features onCPMC regions, all of which begin by warping the rectangular window around the region to 227 \u00d7 227 (we useTorontoNet for these experiments). The first strategy (full)ignores the region\u2019s shape and computes CNN featuresdirectly on the warped window, exactly as we did for detection. However, these features ignore the non-rectangularshape of the region. Two regions might have very similar0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence11TABLE 4ILSVRC2013 ablation study of data usage choices, fine-tuning, and bounding-box regression. All experiments use TorontoNet.test setSVM training setCNN fine-tuning setbbox reg setCNN feature layermAPmedian APval2val2val2val2val2val2testtestval1 val1 +train.5k val1 +train1k val1 +train1k val1 +train1k val1 +train1k val+train1k val+train1kn/an/an/aval1val1 +train1k val1 +train1k val1 +train1k val1 +train1kn/an/an/an/an/aval1n/avalfc6fc6fc6fc7fc7fc7fc7fc720.924.124.126.529.731.030.231.417.721.021.424.829.229.629.030.3bounding boxes while having very little overlap. Therefore,the second strategy (fg) computes CNN features only on aregion\u2019s foreground mask. We replace the background withthe mean input so that background regions are zero aftermean subtraction. The third strategy (full+fg) simply concatenates the full and fg features; our experiments validatetheir complementarity.TABLE 5Segmentation mean accuracy (%) on VOC 2011 validation. Column 1presents O2 P; 2-7 use our CNN pre-trained on ILSVRC 2012.O2 P [59]46.46.2full R-CNNfc6fc743.0 42.5fg R-CNNfc6fc743.7 42.1full+fg R-CNNfc6fc747.945.8Results on VOC 2011Table 5 shows a summary of our results on the VOC2011 validation set compared with O2 P. Within each feature computation strategy, layer fc6 always outperformsfc7 and the following discussion refers to the fc6 features.The fg strategy slightly outperforms full, indicating that themasked region shape provides a stronger signal, matchingour intuition. However, full+fg achieves an average accuracyof 47.9%, our best result by a margin of 4.2% (also modestlyoutperforming O2 P), indicating that the context providedby the full features is highly informative even given thefg features. Notably, training the 20 SVRs on our full+fgfeatures takes an hour on a single core, compared to 10+hours for training on O2 P features.Table 6 shows the per-category segmentation accuracyon VOC 2011 val for each of our six segmentation methodsin addition to the O2 P method [59]. These results showwhich methods are strongest across each of the 20 PASCALclasses, plus the background class.In Table 7 we present results on the VOC 2011 testset, comparing our best-performing method, fc6 (full+fg),against two strong baselines. Our method achieves thehighest segmentation accuracy for 11 out of 21 categories,and the highest overall segmentation accuracy of 47.9%,averaged across categories (but likely ties with the O2 Presult under any reasonable margin of error). Still betterperformance could likely be achieved by fine-tuning.More recently, a number of semantic segmentation approaches based on deep CNNs have lead to dramaticimprovements, pushing segmentation mean accuracy over70% [70], [71], [72], [73]. The highest performing of thesemethods combine fully-convolution networks (fine-tunedfor segmentation) with efficient fully-connected GaussianCRFs [74].77.1I MPLEMENTATION AND DESIGN DETAILSObject proposal transformationsThe convolutional networks used in this work require afixed-size input (e.g., 227 \u00d7 227 pixels) in order to produce a fixed-size output. For detection, we consider objectproposals that are arbitrary image rectangles. We evaluatedtwo approaches for transforming object proposals into validCNN inputs.The first method (\u201ctightest square with context\u201d) encloses each object proposal inside the tightest square andthen scales (isotropically) the image contained in that squareto the CNN input size. Fig. 7 column (B) shows this transformation. A variant on this method (\u201ctightest square without context\u201d) excludes the image content that surroundsthe original object proposal. Fig. 7 column (C) shows thistransformation. The second method (\u201cwarp\u201d) anisotropically scales each object proposal to the CNN input size.Fig. 7 column (D) shows the warp transformation.For each of these transformations, we also consider including additional image context around the original objectproposal. The amount of context padding (p) is defined as aborder size around the original object proposal in the transformed input coordinate frame. Fig. 7 shows p = 0 pixelsin the top row of each example and p = 16 pixels in thebottom row. In all methods, if the source rectangle extendsbeyond the image, the missing data are replaced with theimage mean (which is then subtracted before inputing theimage into the CNN). A pilot set of experiments showedthat warping with context padding (p = 16 pixels) outperformed the alternatives by a large margin (3-5 mAP points).Obviously more alternatives are possible, including usingreplication instead of mean padding. Exhaustive evaluationof these alternatives is left as future work.7.2Positive vs. negative examples and softmaxTwo design choices warrant further discussion. The first is:Why are positive and negative examples defined differentlyfor fine-tuning the CNN versus training the object detectionSVMs? To review the definitions briefly, for fine-tuning wemap each object proposal to the ground-truth instance withwhich it has maximum IoU overlap (if any) and label it asa positive for the matched ground-truth class if the IoU isat least 0.5. All other proposals are labeled \u201cbackground\u201d(i.e., negative examples for all classes). For training SVMs,in contrast, we take only the ground-truth boxes as positive0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence12TABLE 6Per-category segmentation accuracy (%) on the VOC 2011 validation set. These experiments use TorontoNet without fine-tuning.VOC 2011 valO2 P [59]full R-CNN fc6full R-CNN fc7fg R-CNN fc6fg R-CNN fc7full+fg R-CNN fc6full+fg R-CNN fc7bg aero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv mean84.0 69.0 21.7 47.7 42.2 42.4 64.7 65.8 57.4 12.9 37.4 20.5 43.7 35.752.751.035.851.0 28.4 59.8 49.7 46.481.3 56.2 23.9 42.9 40.7 38.8 59.2 56.5 53.2 11.4 34.6 16.7 48.1 37.051.446.031.544.0 24.3 53.7 51.1 43.081.0 52.8 25.1 43.8 40.5 42.7 55.4 57.7 51.38.7 32.5 11.5 48.1 37.050.546.430.242.1 21.2 57.7 56.0 42.581.4 54.1 21.1 40.6 38.7 53.6 59.9 57.2 52.59.1 36.5 23.6 46.4 38.153.251.332.238.7 29.0 53.0 47.5 43.780.9 50.1 20.0 40.2 34.1 40.9 59.7 59.8 52.77.3 32.1 14.3 48.8 42.954.048.628.942.6 24.9 52.2 48.8 42.183.1 60.4 23.2 48.4 47.3 52.6 61.6 60.6 59.1 10.8 45.8 20.9 57.7 43.357.452.934.748.7 28.1 60.0 48.6 47.982.3 56.7 20.6 49.9 44.2 43.6 59.3 61.3 57.87.7 38.4 15.1 53.4 43.750.852.034.147.8 24.7 60.1 55.2 45.7TABLE 7Segmentation accuracy (%) on VOC 2011 test. We compare against two strong baselines: the \u201cRegions and Parts\u201d (R&P) method of [68] and thesecond-order pooling (O2 P) method of [59]. Without any fine-tuning, our CNN achieves top segmentation performance, outperforming R&P androughly matching O2 P. These experiments use TorontoNet without fine-tuning.VOC 2011 testbg aero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv meanR&P [68]83.4 46.8 18.9 36.6 31.2 42.7 57.3 47.4 44.18.1 39.4 36.1 36.3 49.548.350.726.347.2 22.1 42.0 43.2 40.8O2 P [59]85.4 69.7 22.3 45.2 44.4 46.9 66.7 57.8 56.2 13.5 46.1 32.3 41.2 59.155.351.036.250.4 27.8 46.9 44.6 47.6ours (full+fg R-CNN fc6 ) 84.2 66.9 23.7 58.3 37.4 55.4 73.3 58.7 56.59.7 45.5 29.5 49.3 40.157.853.933.860.7 22.7 47.1 41.3 47.9(A)(B)(C)(D)(A)(B)(C)(D)Fig. 7. Different object proposal transformations. (A) the original objectproposal at its actual scale relative to the transformed CNN inputs; (B)tightest square with context; (C) tightest square without context; (D)warp. Within each column and example proposal, the top row corresponds to p = 0 pixels of context padding while the bottom row hasp = 16 pixels of context padding.examples for their respective classes and label proposalswith less than 0.3 IoU overlap with all instances of a classas a negative for that class. Proposals that fall into the greyzone (more than 0.3 IoU overlap, but are not ground truth)are ignored.Historically speaking, we arrived at these definitionsbecause we started by training SVMs on features computedby the ImageNet pre-trained CNN, and so fine-tuning wasnot a consideration at that point in time. In that setup, wefound that our particular label definition for training SVMswas optimal within the set of options we evaluated (whichincluded the setting we now use for fine-tuning). When westarted using fine-tuning, we initially used the same positiveand negative example definition as we were using for SVMtraining. However, we found that results were much worsethan those obtained using our current definition of positivesand negatives.Our hypothesis is that this difference in how positivesand negatives are defined is not fundamentally importantand arises from the fact that fine-tuning data are limited.Our current scheme introduces many \u201cjittered\u201d examples(those proposals with overlap between 0.5 and 1, but notground truth), which expands the number of positive examples by approximately 30x. We conjecture that this largeset is needed when fine-tuning the entire network to avoidoverfitting. However, we also note that using these jitteredexamples is likely suboptimal because the network is notbeing fine-tuned for precise localization.This leads to the second issue: Why, after fine-tuning,train SVMs at all? It would be cleaner to simply applythe last layer of the fine-tuned network, which is a 21-waysoftmax regression classifier, as the object detector. We triedthis and found that performance on VOC 2007 droppedfrom 54.2% to 50.9% mAP. This performance drop likelyarises from a combination of several factors including thatthe definition of positive examples used in fine-tuning doesnot emphasize precise localization and the softmax classifier was trained on randomly sampled negative examplesrather than on the subset of \u201chard negatives\u201d used for SVMtraining.This result shows that it\u2019s possible to obtain close to thesame level of performance without training SVMs after finetuning. We conjecture that with some additional tweaks tofine-tuning the remaining performance gap may be closed.If true, this would simplify and speed up R-CNN trainingwith no loss in detection performance.7.3Bounding-box regressionWe use a simple bounding-box regression stage to improvelocalization performance. After scoring each selective searchproposal with a class-specific detection SVM, we predict anew bounding box for the detection using a class-specificbounding-box regressor. This is similar in spirit to thebounding-box regression used in deformable part models[18]. The primary difference between the two approachesis that here we regress from features computed by theCNN, rather than from geometric features computed on theinferred DPM part locations.The input to our training algorithm is a set of N training pairs {(P i , Gi )}i=1,...,N , where P i = (Pxi , Pyi , Pwi , Phi )0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence13specifies the pixel coordinates of the center of proposalP i \u2019s bounding box together with P i \u2019s width and height inpixels. Hence forth, we drop the superscript i unless it isneeded. Each ground-truth bounding box G is specified inthe same way: G = (Gx , Gy , Gw , Gh ). Our goal is to learna transformation that maps a proposed box P to a groundtruth box G.We parameterize the transformation in terms of fourfunctions dx (P ), dy (P ), dw (P ), and dh (P ). The first twospecify a scale-invariant translation of the center of P \u2019sbounding box, while the second two specify log-spacetranslations of the width and height of P \u2019s bounding box.After learning these functions, we can transform an inputproposal P into a predicted ground-truth box G\u0302 by applyingthe transformationG\u0302x = Pw dx (P ) + Px(1)G\u0302y = Ph dy (P ) + Py(2)G\u0302w = Pw exp(dw (P ))(3)G\u0302h = Ph exp(dh (P )).(4)Each function d? (P ) (where ? is one of x, y, h, w) ismodeled as a linear function of the pool5 features of proposal P , denoted by \u03c65 (P ). (The dependence of \u03c65 (P )on the image data is implicitly assumed.) Thus we haved? (P ) = wT? \u03c65 (P ), where w? is a vector of learnable modelparameters. We learn w? by optimizing the regularized leastsquares objective (ridge regression):w? = argminw\u0302?NX2(ti? \u2212 w\u0302?T \u03c65 (P i ))2 + \u03bb kw\u0302? k .(5)iThe regression targets t? for the training pair (P, G) aredefined astxtytwth= (Gx \u2212 Px )/Pw= (Gy \u2212 Py )/Ph= log(Gw /Pw )= log(Gh /Ph ).(6)(7)(8)(9)As a standard regularized least squares problem, this can besolved efficiently in closed form.We found two subtle issues while implementingbounding-box regression. The first is that regularization isimportant: we set \u03bb = 1000 based on a validation set. Thesecond issue is that care must be taken when selecting whichtraining pairs (P, G) to use. Intuitively, if P is far from allground-truth boxes, then the task of transforming P to aground-truth box G does not make sense. Using exampleslike P would lead to a hopeless learning problem. Therefore,we only learn from a proposal P if it is nearby at least oneground-truth box. We implement \u201cnearness\u201d by assigning Pto the ground-truth box G with which it has maximum IoUoverlap (in case it overlaps more than one) if and only if theoverlap is greater than a threshold (which we set to 0.6 usinga validation set). All unassigned proposals are discarded.We do this once for each object class in order to learn a setof class-specific bounding-box regressors.At test time, we score each proposal and predict its newdetection window only once. In principle, we could iteratethis procedure (i.e., re-score the newly predicted boundingbox, and then predict a new bounding box from it, and soon). However, we found that iterating does not improveresults.7.4Analysis of cross-dataset redundancyOne concern when training on an auxiliary dataset is thatthere might be redundancy between it and the test set.Even though the tasks of object detection and whole-imageclassification are substantially different, making such crossset redundancy much less worrisome, we still conducted athorough investigation that quantifies the extent to whichPASCAL test images are contained within the ILSVRC 2012training and validation sets. Our findings may be usefulto researchers who are interested in using ILSVRC 2012 astraining data for the PASCAL image classification task.We performed two checks for duplicate (and nearduplicate) images. The first test is based on exact matchesof flickr image IDs, which are included in the VOC 2007test annotations (these IDs are intentionally kept secret forsubsequent PASCAL test sets). All PASCAL images, andabout half of ILSVRC, were collected from flickr.com. Thischeck turned up 31 matches out of 4952 (0.63%).The second check uses GIST [75] descriptor matching,which was shown in [76] to have excellent performance atnear-duplicate image detection in large (> 1 million) imagecollections. Following [76], we computed GIST descriptorson warped 32\u00d732 pixel versions of all ILSVRC 2012 trainvaland PASCAL 2007 test images.Euclidean distance nearest-neighbor matching of GISTdescriptors revealed 38 near-duplicate images (including all31 found by flickr ID matching). The matches tend to varyslightly in JPEG compression level and resolution, and to alesser extent cropping. These findings show that the overlapis small, less than 1%. For VOC 2012, because flickr IDsare not available, we used the GIST matching method only.Based on GIST matches, 1.5% of VOC 2012 test images are inILSVRC 2012 trainval. The slightly higher rate for VOC 2012is likely due to the fact that the two datasets were collectedcloser together in time than VOC 2007 and ILSVRC 2012were.8C ONCLUSIONIn recent years, object detection performance had stagnated.The best performing systems were complex ensembles combining multiple low-level image features with high-levelcontext from object detectors and scene classifiers. Thispaper presents a simple and scalable object detection algorithm that gives more than a 50% relative improvement overthe best previous results on PASCAL VOC 2012.We achieved this performance through two insights. Thefirst is to apply high-capacity convolutional networks tobottom-up region proposals in order to localize and segmentobjects. The second is a paradigm for training large CNNswhen labeled training data are scarce. We show that it ishighly effective to pre-train the network\u2014with supervision\u2014for a auxiliary task with abundant data (image classification)and then to fine-tune the network for the target task wheredata is scarce (detection). We conjecture that the \u201csupervisedpre-training/domain-specific fine-tuning\u201d paradigm will behighly effective for a variety of data-scarce vision problems.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence14We conclude by noting that it is significant that weachieved these results by using a combination of classicaltools from computer vision and deep learning (bottom-upregion proposals and convolutional networks). Rather thanopposing lines of scientific inquiry, the two are natural andinevitable partners.ACKNOWLEDGMENTSThis research was supported in part by DARPA Mind\u2019sEye and MSEE programs, by NSF awards IIS-0905647, IIS1134072, and IIS-1212798, MURI N000014-10-1-0933, and bysupport from Toyota. The GPUs used in this research weregenerously donated by the NVIDIA Corporation.R EFERENCES[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22]D. Lowe, \u201cDistinctive image features from scale-invariant keypoints,\u201d IJCV, 2004.N. Dalal and B. Triggs, \u201cHistograms of oriented gradients forhuman detection,\u201d in CVPR, 2005.M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman, \u201cThe PASCAL Visual Object Classes (VOC) Challenge,\u201dIJCV, 2010.K. Fukushima, \u201cNeocognitron: A self-organizing neural networkmodel for a mechanism of pattern recognition unaffected by shiftin position,\u201d Biological cybernetics, vol. 36, no. 4, pp. 193\u2013202, 1980.D. E. Rumelhart, G. E. Hinton, and R. J. Williams, \u201cLearninginternal representations by error propagation,\u201d Parallel DistributedProcessing, vol. 1, pp. 318\u2013362, 1986.Y. LeCun, B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, and L. Jackel, \u201cBackpropagation applied to handwritten zipcode recognition,\u201d Neural Comp., 1989.Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \u201cGradient-basedlearning applied to document recognition,\u201d Proc. of the IEEE, 1998.A. Krizhevsky, I. Sutskever, and G. Hinton, \u201cImageNet classification with deep convolutional neural networks,\u201d in NIPS, 2012.J. Deng, A. Berg, S. Satheesh, H. Su, A. Khosla, and L. FeiFei, \u201cImageNet Large Scale Visual Recognition Competition 2012(ILSVRC2012),\u201d https://www.image-net.org/challenges/LSVRC/2012/.J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, \u201cImageNet: A large-scale hierarchical image database,\u201d in CVPR, 2009.R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRich feature hierarchies for accurate object detection and semantic segmentation,\u201din CVPR, 2014.C. Szegedy, A. Toshev, and D. Erhan, \u201cDeep neural networks forobject detection,\u201d in NIPS, 2013.D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov, \u201cScalable objectdetection using deep neural networks,\u201d in CVPR, 2014.H. A. Rowley, S. Baluja, and T. Kanade, \u201cNeural network-basedface detection,\u201d TPAMI, 1998.R. Vaillant, C. Monrocq, and Y. LeCun, \u201cOriginal approach for thelocalisation of objects in images,\u201d IEE Proc on Vision, Image, andSignal Processing, 1994.J. Platt and S. Nowlan, \u201cA convolutional neural network handtracker,\u201d in NIPS, 1995.P. Sermanet, K. Kavukcuoglu, S. Chintala, and Y. LeCun, \u201cPedestrian detection with unsupervised multi-stage feature learning,\u201din CVPR, 2013.P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan, \u201cObject detection with discriminatively trained part based models,\u201dTPAMI, 2010.P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, andY. LeCun, \u201cOverFeat: Integrated Recognition, Localization andDetection using Convolutional Networks,\u201d in ICLR, 2014.C. Gu, J. J. Lim, P. Arbela\u0301ez, and J. Malik, \u201cRecognition usingregions,\u201d in CVPR, 2009.J. Uijlings, K. van de Sande, T. Gevers, and A. Smeulders, \u201cSelective search for object recognition,\u201d IJCV, 2013.J. Carreira and C. Sminchisescu, \u201cCPMC: Automatic object segmentation using constrained parametric min-cuts,\u201d TPAMI, 2012.[23] R. Girshick, P. Felzenszwalb, and D. McAllester, \u201cDiscriminatively trained deformable part models, release 5,\u201d https://www.cs.berkeley.edu/\u223crbg/latent-v5/.[24] K. Simonyan and A. Zisserman, \u201cVery deep convolutional networks for large-scale image recognition,\u201d in ICLR, 2015.[25] P. Agrawal, R. Girshick, and J. Malik, \u201cAnalyzing the performanceof multilayer neural networks for object recognition,\u201d in ECCV,2014.[26] T. Dean, J. Yagnik, M. Ruzon, M. Segal, J. Shlens, and S. Vijayanarasimhan, \u201cFast, accurate detection of 100,000 object classes ona single machine,\u201d in CVPR, 2013.[27] K. He, X. Zhang, S. Ren, and J. Sun, \u201cSpatial pyramid poolingin deep convolutional networks for visual recognition,\u201d in ECCV,2014.[28] R. Girshick, \u201cFast R-CNN,\u201d arXiv e-prints, vol. arXiv:1504.08083v1[cs.CV], 2015.[29] D. Hoiem, A. Efros, and M. Hebert, \u201cGeometric context from asingle image,\u201d in CVPR, 2005.[30] B. C. Russell, W. T. Freeman, A. A. Efros, J. Sivic, and A. Zisserman,\u201cUsing multiple segmentations to discover objects and their extentin image collections,\u201d in CVPR, 2006.[31] C. L. Zitnick and P. Dolla\u0301r, \u201cEdge boxes: Locating object proposalsfrom edges,\u201d in ECCV, 2014.[32] M.-M. Cheng, Z. Zhang, W.-Y. Lin, and P. H. S. Torr, \u201cBING:Binarized normed gradients for objectness estimation at 300fps,\u201din CVPR, 2014.[33] J. Hosang, R. Benenson, P. Dolla\u0301r, and B. Schiele, \u201cWhatmakes for effective detection proposals?\u201d arXiv e-prints, vol.arXiv:1502.05082v1 [cs.CV], 2015.[34] A. Humayun, F. Li, and J. M. Rehg, \u201cRIGOR: Reusing Inference inGraph Cuts for generating Object Regions,\u201d in CVPR, 2014.[35] P. Arbela\u0301ez, J. Pont-Tuset, J. Barron, F. Marques, and J. Malik,\u201cMultiscale combinatorial grouping,\u201d in CVPR, 2014.[36] P. Kra\u0308henbu\u0308hl and V. Koltun, \u201cGeodesic object proposals,\u201d inECCV, 2014.[37] S. J. Pan and Q. Yang, \u201cA survey on transfer learning,\u201d TPAMI,2010.[38] R. Caruana, \u201cMultitask learning: A knowledge-based source ofinductive bias,\u201d in ICML, 1993.[39] S. Thrun, \u201cIs learning the n-th thing any easier than learning thefirst?\u201d NIPS, 1996.[40] Y. Bengio, A. Courville, and P. Vincent, \u201cRepresentation learning:A review and new perspectives,\u201d TPAMI, 2013.[41] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, andT. Darrell, \u201cDeCAF: A Deep Convolutional Activation Feature forGeneric Visual Recognition,\u201d in ICML, 2014.[42] J. Hoffman, S. Guadarrama, E. Tzeng, J. Donahue, R. Girshick,T. Darrell, and K. Saenko, \u201cFrom large-scale object classifiers tolarge-scale object detectors: An adaptation approach,\u201d in NIPS,2014.[43] A. Karpathy, A. Joulin, and L. Fei-Fei, \u201cDeep fragment embeddings for bidirectional image sentence mapping,\u201d in NIPS, 2014.[44] G. Gkioxari, B. Hariharan, R. Girshick, and J. Malik, \u201cR-CNNsfor pose estimation and action detection,\u201d arXiv e-prints, vol.arXiv:1406.5212v1 [cs.CV], 2014.[45] B. Hariharan, P. Arbela\u0301ez, R. Girshick, and J. Malik, \u201cSimultaneousdetection and segmentation,\u201d in ECCV, 2014.[46] S. Gupta, R. Girshick, P. Arbelaez, and J. Malik, \u201cLearning rich features from RGB-D images for object detection and segmentation,\u201din ECCV, 2014.[47] H. O. Song, R. Girshick, S. Jegelka, J. Mairal, Z. Harchaoui, andT. Darrell, \u201cOn learning to localize objects with minimal supervision,\u201d in ICML, 2014.[48] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, andL. Fei-Fei, \u201cImageNet large scale visual recognition challenge,\u201darXiv e-prints, vol. arXiv:1409.0575v1 [cs.CV], 2014.[49] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,D. Erhan, V. Vanhoucke, and A. Rabinovich, \u201cGoing deeper withconvolutions,\u201d arXiv e-prints, vol. arXiv:1409.4842v1 [cs.CV], 2014.[50] C. Szegedy, S. Reed, D. Erhan, and D. Anguelov, \u201cScalable, highquality object detection,\u201d arXiv e-prints, vol. arXiv:1412.1441v2[cs.CV], 2015.[51] B. Alexe, T. Deselaers, and V. Ferrari, \u201cMeasuring the objectness ofimage windows,\u201d TPAMI, 2012.[52] I. Endres and D. Hoiem, \u201cCategory independent object proposals,\u201din ECCV, 2010.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence15cocktail shaker 0.56person 0.88helmet 0.65dog 0.97dog 0.95person 0.72dog 0.85dog 0.57dog 0.97bird 0.63dog 0.64lemon 0.79lemon 0.70lemon 0.56lemon 0.50person 0.82bird 0.96dog 0.66domestic cat 0.57dog 0.61helmet0.52person0.75motorcycle 0.65person 0.58snowmobile 0.83snowmobile 0.83sofa 0.71bow tie 0.86bird 0.61ladybug 1.00dog 0.91person 0.87dog 0.77car 0.63car 0.96dog 0.95car 0.66dog 0.55pretzel 0.78bird 0.98person 0.52watercraft 1.00bird 0.91flower pot 0.62bird 0.99person 0.65dog 0.98car 0.96watercraft 0.69person 0.52bird 0.75person 0.58person 0.65armadillo 0.56bird 0.93train 1.00dog0.97dog0.56train 0.53armadillo 1.00person 0.90dog 0.92swine 0.88bird 1.00butterfly 0.96antelope 0.53tv or monitor 0.82tv or monitor 0.76tv or monitor 0.54mushroom 0.93snake 0.70bell pepper 0.54flower pot 0.62turtle 0.54bell pepper 0.62bell pepper 0.81ruler 1.00dog 0.97person 0.58lipstick 0.61lipstick 0.80bird 0.83bird 0.89soccer ball 0.90person 0.91person 0.75person 0.73bird 1.00butterfly 0.98stethoscope 0.83person 0.61bird 0.78Fig. 8. Example detections on the val2 set from the configuration that achieved 31.0% mAP on val2 . Each image was sampled randomly (these arenot curated). All detections at precision greater than 0.5 are shown. Each detection is labeled with the predicted class and the precision value ofthat detection from the detector\u2019s precision-recall curve. Viewing digitally with zoom is recommended.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2437384, IEEE Transactions on Pattern Analysis and Machine Intelligence16[53] D. Cires\u0327an, A. Giusti, L. Gambardella, and J. Schmidhuber, \u201cMitosis detection in breast cancer histology images with deep neuralnetworks,\u201d in MICCAI, 2013.[54] X. Wang, M. Yang, S. Zhu, and Y. Lin, \u201cRegionlets for genericobject detection,\u201d in ICCV, 2013.[55] Y. Jia, \u201cCaffe: An open source convolutional architecture for fastfeature embedding,\u201d https://caffe.berkeleyvision.org/, 2013.[56] T. Dean, M. A. Ruzon, M. Segal, J. Shlens, S. Vijayanarasimhan,and J. Yagnik, \u201cFast, accurate detection of 100,000 object classes ona single machine,\u201d in CVPR, 2013.[57] S. Fidler, R. Mottaghi, A. Yuille, and R. Urtasun, \u201cBottom-upsegmentation for top-down detection,\u201d in CVPR, 2013.[58] K. Sung and T. Poggio, \u201cExample-based learning for view-basedhuman face detection,\u201d Massachussets Institute of Technology,Tech. Rep. A.I. Memo No. 1521, 1994.[59] J. Carreira, R. Caseiro, J. Batista, and C. Sminchisescu, \u201cSemanticsegmentation with second-order pooling,\u201d in ECCV, 2012.[60] K. E. van de Sande, C. G. Snoek, and A. W. Smeulders, \u201cFisherand vlad with flair,\u201d in CVPR, 2014.[61] J. J. Lim, C. L. Zitnick, and P. Dolla\u0301r, \u201cSketch tokens: A learnedmid-level representation for contour and object detection,\u201d inCVPR, 2013.[62] X. Ren and D. Ramanan, \u201cHistograms of sparse codes for objectdetection,\u201d in CVPR, 2013.[63] M. Zeiler, G. Taylor, and R. Fergus, \u201cAdaptive deconvolutionalnetworks for mid and high level feature learning,\u201d in CVPR, 2011.[64] D. Hoiem, Y. Chodpathumwan, and Q. Dai, \u201cDiagnosing error inobject detectors,\u201d in ECCV, 2012.[65] J. Deng, O. Russakovsky, J. Krause, M. Bernstein, A. C. Berg, andL. Fei-Fei, \u201cScalable multi-label annotation,\u201d in CHI, 2014.[66] H. Su, J. Deng, and L. Fei-Fei, \u201cCrowdsourcing annotations forvisual object detection,\u201d in AAAI Technical Report, 4th HumanComputation Workshop, 2012.[67] C. Farabet, C. Couprie, L. Najman, and Y. LeCun, \u201cLearninghierarchical features for scene labeling,\u201d TPAMI, 2013.[68] P. Arbela\u0301ez, B. Hariharan, C. Gu, S. Gupta, L. Bourdev, andJ. Malik, \u201cSemantic segmentation using regions and parts,\u201d inCVPR, 2012.[69] B. Hariharan, P. Arbela\u0301ez, L. Bourdev, S. Maji, and J. Malik,\u201cSemantic contours from inverse detectors,\u201d in ICCV, 2011.[70] B. Hariharan, P. Arbela\u0301ez, R. Girshick, and J. Malik, \u201cHypercolumns for object segmentation and fine-grained localization,\u201din CVPR, 2015.[71] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L.Yuille, \u201cSemantic image segmentation with deep convolutionalnets and fully connected CRFs,\u201d in ICLR, 2015.[72] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su,D. Du, C. Huang, and P. Torr, \u201cConditional random fields asrecurrent neural networks,\u201d arXiv e-print, vol. arXiv:1502.03240v2[cs.CV], 2015.[73] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in CVPR, 2015.[74] P. Kra\u0308henbu\u0308hl and V. Koltun, \u201cEfficient inference in fully connected CRFs with gaussian edge potentials,\u201d in NIPS, 2011.[75] A. Oliva and A. Torralba, \u201cModeling the shape of the scene: Aholistic representation of the spatial envelope,\u201d IJCV, 2001.[76] M. Douze, H. Je\u0301gou, H. Sandhawalia, L. Amsaleg, and C. Schmid,\u201cEvaluation of gist descriptors for web-scale image search,\u201d inProc. of the ACM International Conference on Image and Video Retrieval, 2009.Ross Girshick is a Researcher at Microsoft Research, Redmond. He holds a PhD and MS incomputer science, both from the University ofChicago where he studied under the supervisionof Pedro Felzenszwalb. Prior to joining MicrosoftResearch, Ross was a Postdoctorial Fellow atthe University of California, Berkeley where hecollaborated with Jitendra Malik and Trevor Darrell. During the course of PASCAL VOC objectdetection challenge, Ross participated in multiple winning object detection entries and wasawarded a \u201clifetime achievement\u201d prize for his work on the widely usedDeformable Part Models.Jeff Donahue is a fourth year PhD student atUC Berkeley, supervised by Trevor Darrell. Hegraduated from UT Austin in 2011 with a BS incomputer science, completing an honors thesiswith Kristen Grauman. Jeff\u2019s research interestsare in visual recognition and machine learning,most recently focusing on the application of deeplearning to visual localization and sequencingproblems.Trevor Darrell\u2019s group is co-located at the University of California, Berkeley, and the UCBaffiliated International Computer Science Institute (ICSI), also located in Berkeley, CA. Prof.Darrell is on the faculty of the CS Division ofthe EECS Department at UCB and is the vision group lead at ICSI. Darrell\u2019s group develops algorithms for large-scale perceptual learning, including object and activity recognition anddetection, for a variety of applications includingmultimodal interaction with robots and mobiledevices. His interests include computer vision, machine learning, computer graphics, and perception-based human computer interfaces. Prof.Darrell was previously on the faculty of the MIT EECS department from1999-2008, where he directed the Vision Interface Group. He was amember of the research staff at Interval Research Corporation from1996-1999, and received the SM, and PhD degrees from MIT in 1992and 1996, respectively. He obtained the BSE degree from the Universityof Pennsylvania in 1988, having started his career in computer vision asan undergraduate researcher in Ruzena Bajcsy\u2019s GRASP lab.Jitendra Malik was born in 1960, received theB.Tech degree in EE from Indian Institute ofTechnology, Kanpur in 1980 and the PhD degree in CS from Stanford University in 1985. InJanuary 1986, he joined UC Berkeley, where heis currently the Arthur J. Chick Professor in theDepartment of EECS. He is also on the facultyof the department of Bioengineering, and theCognitive Science and Vision Science groups.During 2002-2004 he served as the Chair ofthe Computer Science Division and during 20042006 as the Department Chair of EECS. Jitendra Malik\u2019s research grouphas worked on computer vision, computational modeling of humanvision, computer graphics and the analysis of biological images. Severalwell-known concepts and algorithms arose in this research, such asanisotropic diffusion, normalized cuts, high dynamic range imaging,and shape contexts. He is one of the most highly cited researchersin computer vision, with ten of his papers having received more thana thousand citations each. Jitendra has graduated 33 PhD students,many of whom are now prominent researchers in academia and industry. He received the gold medal for the best graduating student inElectrical Engineering from IIT Kanpur in 1980 and a Presidential YoungInvestigator Award in 1989. He was awarded the Longuet-Higgins Prizefor a contribution that has stood the test of time twice, in 2007 and in2008. Jitendra Malik is a Fellow of both ACM and IEEE, a member ofthe National Academy of Engineering and a Fellow of the AmericanAcademy of Arts and Sciences. In 2013 he received the IEEE PAMI-TCDistinguished Researcher in Computer Vision Award, and in 2014 theK.S.Fu Prize from the International Association of Pattern Recognition.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\f", "IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 2011199Domain Adaptation via TransferComponent AnalysisSinno Jialin Pan, Ivor W. Tsang, James T. Kwok, and Qiang Yang, Fellow, IEEEAbstract\u2014 Domain adaptation allows knowledge from a sourcedomain to be transferred to a different but related targetdomain. Intuitively, discovering a good feature representationacross domains is crucial. In this paper, we first propose to findsuch a representation through a new learning method, transfercomponent analysis (TCA), for domain adaptation. TCA tries tolearn some transfer components across domains in a reproducingkernel Hilbert space using maximum mean miscrepancy. In thesubspace spanned by these transfer components, data propertiesare preserved and data distributions in different domains areclose to each other. As a result, with the new representations inthis subspace, we can apply standard machine learning methodsto train classifiers or regression models in the source domainfor use in the target domain. Furthermore, in order to uncoverthe knowledge hidden in the relations between the data labelsfrom the source and target domains, we extend TCA in asemisupervised learning setting, which encodes label informationinto transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that wepropose a novel dimensionality reduction framework for reducingthe distance between domains in a latent space for domainadaptation. We propose both unsupervised and semisupervisedfeature extraction approaches, which can dramatically reduce thedistance between domain distributions by projecting data onto thelearned transfer components. Finally, our approach can handlelarge datasets and naturally lead to out-of-sample generalization.The effectiveness and efficiency of our approach are verified byexperiments on five toy datasets and two real-world applications:cross-domain indoor WiFi localization and cross-domain textclassification.Index Terms\u2014 Dimensionality reduction, domain adaptation,Hilbert space embedding of distributions, transfer learning.I. I NTRODUCTIONDOMAIN adaptation aims at solving a learning problemin the target domain by utilizing training data in theManuscript received January 15, 2010; revised October 14, 2010; acceptedOctober 31, 2010. Date of publication November 18, 2010; date of currentversion February 9, 2011. The work of S. J. Pan and Q. Yang was supportedin part by Hong Kong Research Grants Council/National Natural Sciencefund under Grant NHKUST 624/09. The work of I. W. Tsang was supportedin part by Singapore Nanyang Technological University Academic ResearchFund Tier-1 Research under Grant RG15/08 and State Emergency ResponseCommission under Grant 102 1580034. The work of J. T. Kwok was supported in part by Hong Kong Competitive Earmarked Research Grants underProject 615209.S. J. Pan is with the Institute of Infocomm Research, 138632, Singapore(e-mail: sinnocat@gmail.com).I. W. Tsang is with the School of Computer Engineering, NanyangTechnological University, 639798, Singapore (e-mail: ivortsang@ntu.edu.sg).J. T. Kwok and Q. Yang are with the Department of Computer Science andEngineering, Hong Kong University of Science and Technology, Hong Kong(e-mail: jamesk@cse.ust.hk; qyang@cse.ust.hk).Color versions of one or more of the figures in this paper are availableonline at https://ieeexplore.ieee.org.Digital Object Identifier 10.1109/TNN.2010.2091281source domain, even when these domains may have differentdistributions. This is an important learning problem becauselabeled data are often difficult to come by, making it desirableto make the best use of any related data available. Forexample, in indoor WiFi localization which requires regressionlearning, the labeled training data are difficult and expensiveto obtain [1]. Moreover, once calibrated, these data can beeasily outdated because the WiFi signal strength may be afunction of many dynamic factors including time, device, andspace [2]. To reduce the recalibration effort, we might wantto adapt a localization model trained in one time period (thesource domain) for a new time period (the target domain), or toadapt the localization model trained on one mobile device (thesource domain) for a new mobile device (the target domain).Domain adaptation can be considered as a special setting oftransfer learning which aims at transferring shared knowledgeacross different but related tasks or domains [3]\u2013[5]. A majorcomputational problem in domain adaptation is how to reducethe difference between the distributions of the source andtarget domain data. Intuitively, discovering a good featurerepresentation across domains is crucial [3], [6]. A goodfeature representation should be able to reduce the differencein distributions between domains as much as possible, whileat the same time preserving important properties (such asgeometric properties, statistical properties, or side information[7]) of the original data, especially for the target domaindata. Recently, several approaches have been proposed tolearn a common feature representation for domain adaptation[8]\u2013[10]. Daum\u00e9 III [8] designed a heuristic kernel to augmentfeatures for solving some specific domain adaptation problemsin natural language processing. Blitzer et al. [9] proposed thestructural correspondence learning (SCL) algorithm, motivatedfrom [11], to induce correspondences among features from thedifferent domains. This method depends on the heuristic selections of pivot features appearing frequently in both domains.Although it is experimentally shown that SCL can reduce thedifference between domains based on the A-distance measure[6], the heuristic criterion of pivot feature selection may besensitive to different applications.Most previous feature-based domain adaptation methods donot minimize the distance in distributions between domainsexplicitly. Recently, von B\u00fcnau et al. [12] proposed stationarysubspace analysis (SSA) to match distributions in a latentspace. However, SSA is focused on the identification of astationary subspace, without considering the preservation ofproperties such as data variance in the subspace. Pan et al.[10] proposed a new dimensionality reduction method calledmaximum mean discrepancy embedding (MMDE) for domain1045\u20139227/$26.00 \u00a9 2010 IEEE\f200IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 2011adaptation. MMDE aims at learning a shared latent spaceunderlying the domains where distance between distributionscan be reduced while the data variance can be preserved. However, MMDE suffers from two major limitations: 1) MMDE istransductive, and does not generalize to out-of-sample patterns[13], and 2) MMDE learns the latent space by solving a semidefinite program (SDP), which is computationally expensive.In this paper, we propose a new feature extraction approach,called transfer component analysis (TCA), for domain adaptation. It tries to learn a set of common transfer componentsunderlying both domains such that the difference in datadistributions of the different domains, when projected onto thissubspace, can be dramatically reduced and data properties canbe preserved. Standard machine learning methods can thenbe used in this subspace to train classification or regressionmodels across domains. More specifically, if two domainsare related to each other, there may exist several commoncomponents (or latent variables) underlying them. Some ofthese may cause the data distributions between domains tobe different, while others may not. Meanwhile, some of thesecomponents may capture the intrinsic structure or discriminative information underlying the original data, while othersmay not. Hence, our goal is to discover those componentsthat do not cause distribution change very much across thedomains and can well preserve the structure or task-relevantinformation of the original data.Our main contribution is on proposing a novel dimensionality reduction method to reduce the distance betweendomains via projecting data onto a learned transfer subspace.Once the subspace is found, one can use any method forsubsequent classification, regression, and clustering. Furthermore, TCA and its semisupervised extension SSTCA aremuch more efficient than MMDE and can handle the outof-sample extension problem [13]. The rest of this paper isorganized as follows. In Section II, we first introduce thedomain adaptation problem and traditional dimensionality reduction methods and describe the Hilbert space embedding fordistances and dependence measure between distributions. Ourproposed feature extraction methods for domain adaptation arepresented in Sections III and IV. In Section V, we conduct aseries of experiments on some toy datasets and two real-worldapplication problems to verify the effectiveness and efficiencyof the proposed methods. Finally, we conclude our work inSection VI.II. P REVIOUS W ORKS AND P RELIMINARIESA. Domain AdaptationWe consider a domain as consisting of two main components: a feature space of inputs X and a marginal probabilitydistribution of inputs P(X), where X = {x 1 , . . . , x n } \u2208 X isa set of learning samples. For example, if our learning taskis document classification, and each term is taken as a binaryfeature, then X is the space of all document vectors. In general,if two domains are different, they may have different featurespaces or different marginal probability distributions. In thispaper, we focus on the setting where there are only one sourceand one target domain sharing the same feature space. We alsoassume that some labeled data D S are available in the sourcedomain, while only unlabeled data DT are available in thetarget domain. More specifically, let the source domain databe D S = {(x S1 , y S1 ), . . . , (x Sn1 , y Sn1 )}, where x Si \u2208 X is theinput and y Si \u2208 Y is the corresponding output. Similarly, letthe target domain data be DT = {x T1 , . . . , x Tn2 }, where theinput x Ti is also in X .Let P(X S ) and Q(X T ) (or P and Q in short) be themarginal distributions of X S = {x Si } and X T = {x Ti } fromthe source and target domains, respectively. In general, P andQ can be different. Our task is to predict the labels yTi scorresponding to inputs x Ti s in the target domain. The keyassumption in most domain adaptation methods is that P \u0003= Q,but P(Y S |X S ) = P(YT |X T ).The problem of covariate shift adaptation is also relatedto domain adaption. To address this problem, importancereweighting is a major technique [14]\u2013[18]. Huang et al. [14]proposed a kernel-based method, known as kernel meanmatching (KMM) to reweight instances in a reproducing kernelHilbert space (RKHS). Sugiyama et al. [15] proposed another importance reweighting algorithm, known as Kullback\u2013Leibler importance estimation procedure (KLIEP), which isintegrated with cross validation to perform model selectionautomatically. Bickel et al. [16] proposed to integrate thedistribution correcting process into a kernelized logistic regression. Kanamori et al. [17] proposed a method called unconstrained least-squares importance fitting (uLSIF) to estimatethe importance efficiently by formulating the direct importanceestimation problem as a least-squares function fitting problem.The main difference between these methods and our proposedmethod is that we aim to match data distributions betweendomains in a latent space, where data properties can bepreserved, instead of matching them in the original featurespace. Recently, Sugiyama et al. [18] further extended theuLSIF algorithm by estimating importance in a nonstationarysubspace, which performs well even when the dimensionalityof the data domains is high. However, this method is focusedon estimating the importance in a latent space instead of learning a latent space for adaptation. Note that, besides covariateshift adaptation, importance estimation techniques have alsobeen applied to various applications, such as independent component analysis [19], outlier detection [20], and change-pointdetection [21].Besides reweighting methods, von B\u00fcnau et al. [12]proposed to match distributions in a latent space. Morespecifically, they theoretically studied the conditions underwhich a stationary space can be identified from a multivariatetime series. They also proposed the SSA procedure to findstationary components by matching the first two momentsof the data distributions in different epochs. However, SSAis focused on how to identify a stationary subspace withoutconsidering how to preserve data properties in the latent space.As a result, SSA may map the data to some noisy factors whichare stationary across domains but completely irrelevant to thetarget supervised task. Then classifiers trained on the newrepresentations learned by SSA may not get good performancefor domain adaptation. We will show a motivating example inSection III.\fPAN et al.: DOMAIN ADAPTATION VIA TRANSFER COMPONENT ANALYSISB. Hilbert Space Embedding of Distributions1) Maximum Mean Discrepancy (MMD): Given samplesX = {x i } and Y = {yi } drawn from two distributions, thereexist many criteria [such as the Kullback\u2013Leibler (KL) divergence] that can be used to estimate their distance. However,many of these estimators are parametric or require an intermediate density estimate. Recently, a nonparametric distanceestimate was designed by embedding distributions in an RKHS[22]. Gretton et al. [23] introduced the MMD for comparingdistributions based on the corresponding RKHS distance. Letthe kernel-induced feature map be \u03c6. The empirical estiand {y1 , . . . , yn2 } ismate of MMD between\u0002 1 {x 1 , . . . , x n1 } \u00022MMD(X, Y ) = \u00041/n 1 ni=1\u03c6(x i )\u22121/n 2 ni=1\u03c6(yi )\u00042H where\u0004 \u00b7 \u0004H is the RKHS norm. Therefore, the distance betweentwo distributions is simply the distance between the two meanelements in a RKHS. It can be shown [22] that, when theRKHS is universal, MMD will asymptotically approach zeroif and only if the two distributions are the same.2) Hilbert\u2013Schmidt Independence Criterion (HSIC): Related to the MMD, the HSIC [24] is a simple yet powerfulnonparametric criterion for measuring the dependence betweenthe sets X and Y . As its name implies, it computes theHilbert\u2013Schmidt norm of a cross-covariance operator in theRKHS. An (biased) empirical estimate can be easily obtainedfrom the corresponding kernel matrices, as HSIC(X, Y ) =(1/(n \u2212 1)2 )tr(H K H K yy ) where K , K yy are kernel matricesdefined on X and Y , respectively, H = I \u2212 (1/n)11\u0005 is thecentering matrix, and n is the number of samples in X andY . Similar to MMD, it can also be shown that if the RKHSis universal, HSIC asymptotically approaches zero if and onlyif X and Y are independent [25]. Conversely, a large HSICvalue suggests strong dependence.C. Embedding Using HSICIn embedding or dimensionality reduction, it is often desirable to preserve the local data geometry while at thesame time maximally align the embedding with availableside information (such as labels). For example, in coloredmaximum variance unfolding (colored MVU) [7], the localgeometry is captured in the form of local distance constraintson the target embedding K , while the alignment with the sideinformation (represented as kernel matrix K yy ) is measured bythe HSIC criterion. Mathematically, this leads to the followingSDP:max tr(H K H K yy ) subject to constraints on K .K \u00060(1)In particular, (1) reduces to MVU [26] when no sideinformation is given (i.e., K yy = I ).III. TCAAs mentioned in Section II-A, most domain adaptationmethods assume that P \u0003= Q, but P(Y S |X S ) = P(YT |X T ).However, in many real-world applications, the conditionalprobability P(Y |X) may also change across domains due tonoisy or dynamic factors underlying the observed data. In thispaper, we use the weaker assumption that P \u0003= Q, but there201exists a transformation \u03c6 such that P(\u03c6(X S )) \u2248 P(\u03c6(X T ))and P(Y S |\u03c6(X S )) \u2248 P(YT |\u03c6(X T )). Standard supervisedlearning methods can then be applied on the mapped sourcedomain data \u03c6(X S ), together with the corresponding labelsY S , to train models for use on the mapped target domain data\u03c6(X T ).A key issue is how to find this transformation \u03c6. Since wehave no labeled data in the target domain, \u03c6 cannot be learnedby directly minimizing the distance between P(Y S |\u03c6(X S ))and P(YT |\u03c6(X T )). Here, we propose to learn \u03c6 such that:1) the distance between the marginal distributions P(\u03c6(X S ))and P(\u03c6(X T )) is small, and 2) \u03c6(X S ) and \u03c6(X T ) preserveimportant properties of X S and X T . We then assume that sucha \u03c6 satisfies P(Y S |\u03c6(X S )) \u2248 P(YT |\u03c6(X T )). We believe thatdomain adaptation under this assumption is more realistic,though also more challenging. Finally, a classifier f trainedon \u03c6(X S ) and Y S is used to make predictions on \u03c6(X T ).A. Minimizing Distance Between P(\u03c6(X S )) and P(\u03c6(X T ))Assume that \u03c6 is the feature map induced by a universalkernel. As shown in Section II-B.1, the distance between twodistributions P and Q can be empirically measured by thedistance between \u0003the empirical means of the two domains\u00032\u0002 1\u0002 2\u03c6(x Si ) \u2212 1/n 2 ni=1\u03c6(x Ti )\u0003H .Dist(X \bS , X T\b ) = \u00031/n 1 ni=1Therefore, a desired nonlinear mapping \u03c6 can be foundby minimizing this quantity. However, \u03c6 is usually highlynonlinear and a direct optimization of minimizing the quantitywith respect to \u03c6 can get stuck in poor local minima.1) MMDE: Instead of finding the nonlinear transformation\u03c6 explicitly, we first revisit a dimensionality reduction-baseddomain adaptation method called MMDE [10]. It embedsboth the source and target domain data into a shared lowdimensional latent space using a nonlinear mapping \u03c6, andthen learns the corresponding kernel matrix K by solvingan SDP. Specifically, let the Gram matrices defined on thesource domain, target domain, and cross-domain data in theembedded space be K S,S , K T ,T , and K S,T , respectively. Thekey idea is to learn\u0004\u0005KK(2)K = K S,S K S,T \u2208 R(n1 +n2 )\u00d7(n1 +n2 )T ,ST ,Ti.e., the kernel matrix defined on all the data, by minimizingthe distance (measured w.r.t. the MMD) between the projectedsource and target domain data while maximizing the embeddeddata variance. By virtue of the kernel trick, it can be shown thatthe MMD distance in Section III-A can be written as tr(K L),where K = [\u03c6(x i )\u0005 \u03c6(x j )], and L i j = 1/n 21 if x i , x j \u2208 X S ,else L i j = 1/n 22 if x i , x j \u2208 X T , otherwise, L i j = \u2212(1/n 1 n 2 ).The objective function of MMDE can then be written asmax tr(K L) \u2212 \u03bbtr(K ) subject to constraints on KK \u00060(3)where the first term in the objective minimizes the distancebetween distributions, while the second term maximizes thevariance in the feature space, and \u03bb \u2265 0 is a tradeoff parameter.However, there are several limitations of MMDE. First,it is transductive and cannot generalize to unseen patterns.Second, the resultant kernel learning problem has to be solved\fIEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 2011\u0006 = (K K \u22121/2 W\u0006 )(W\u0006 \u0005 K \u22121/2 K ) = K W W \u0005 KK(4)\u0006 . In particular, the corresponding kernelwhere W = K \u22121/2 Wk(x i , x j ) =evaluation between any two patterns x i and x j is \u0006k x\u0005i W W \u0005 k x j where k x = [k(x 1 , x), . . . , k(x n1 +n2 , x)]\u0005 \u2208k facilitates a readily parametricRn1 +n2 . Hence, this kernel \u0006form for out-of-sample kernel evaluations.\u0006 in (4), the MMD distanceOn using the definition of Kbetween the empirical means of the two domains X \bS and X T\bcan be rewritten asDist(X \bS , X T\b ) = tr((K W W \u0005 K )L) = tr(W \u0005 K L K W ).(5)In minimizing (5), a regularization term tr(W \u0005 W ) is usuallyneeded to control the complexity of W . As will be shown later,this regularization term can also avoid the rank deficiency ofthe denominator in the generalized eigenvalue decomposition.B. Preserving Properties of X S and X TIn domain adaptation, learning the transformation \u03c6 by onlyminimizing the distance between P(\u03c6(X S )) and P(\u03c6(X T ))may not be enough. Fig. 1(a) shows a simple 2-D example,where the source domain data is in red and the target domaindata is in blue. For both domains, x 1 is the discriminativedirection that separates the positive and negative samples,while x 2 is a noisy dimension with small variance. By focusingonly on minimizing the distance between P(\u03c6(X S )) andP(\u03c6(X T )), one would select the noisy component x 2 , whichhowever is completely irrelevant to the target supervised task.Hence, besides reducing the distance between the twomarginal distributions, \u03c6 should also preserve data propertiesthat are useful for the target supervised learning task. Anobvious choice is to maximally preserve the data variance,as performed by PCA and KPCA. Note from (4) that theembedding of the data in the latent space is W \u0005 K , where thei th column [W \u0005 K ]i provides the embedding coordinates of x i .Hence, the variance of the projected samples is W \u0005 K H K W ,where H = In1 +n2 \u2212 (1/n 1 + n 2 )11\u0005 is the centering matrix,1 \u2208 Rn1 +n2 is the column vector with all 1\u2019s, and In1 +n2 \u2208R(n1 +n2 )\u00d7(n1 +n2 ) is the identity matrix.32.521.510.50\u22120.5\u22121Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data\u2212+\u2212+Target domain dataSource domain datax2by expensive SDP solvers. Finally, in order to construct lowdimensional representations of X \bS and X T\b , the obtained K hasto be further post-processed by PCA [10]. This may discardpotentially useful information in K .2) Parametric Kernel Map for Unseen Patterns: In this section, we propose an efficient framework to find the nonlinearmapping \u03c6 based on kernel feature extraction. It avoids the useof SDP and thus its high computational burden. Moreover, thelearned kernel can be generalized to out-of-sample patterns.Besides, instead of using a two-step approach as in MMDE,we propose a unified kernel learning method which utilizes anexplicit low-rank representation.First, note that the kernel matrix K in (2) can be decomposed as K = (K K \u22121/2 )(K \u22121/2 K ), which is often known asthe empirical kernel map [27]. Consider the use of a matrix\u0006 \u2208 R(n1 +n2 )\u00d7m that transforms the empirical kernel mapWfeatures to an m-dimensional space (where mn 1 + n 2 ).The resultant kernel matrix is thenx2202543210\u22121\u22123 \u22122 \u22121 0 1 2 3 4 5 6x1\u22122Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data++\u2212\u2212Source domain dataSource domain data\u22122 \u22121 0 1 2 3 4 5 6 7 8 9x1Fig. 1. Motivating examples for the TCA formulation. (a) Only minimizingthe distance between P(\u03c6(X S )) and P(\u03c6(X T )). (b) Only maximizing thedata variance.However, focusing only on the data variance is again notdesirable in domain adaptation. An example is shown inFig. 1(b), where the direction with the largest variance (x 1 )cannot be used to reduce the distance of distributions acrossdomains and is not useful in boosting the performance fordomain adaptation.C. Unsupervised TCACombining the observations in Sections III-A and III-B, wedevelop a new dimensionality reduction method for domainadaptation such that in the latent space spanned by the learnedcomponents, the variance of the data can be preserved as muchas possible and the distance between different distributionsacross domains can be reduced. The kernel learning problemthen becomesmin Ws.t.tr(W \u0005 K L K W ) + \u03bc tr(W \u0005 W )W \u0005 K H K W = Im(6)where \u03bc > 0 is a tradeoff parameter, and Im \u2208 Rm\u00d7m isthe identity matrix. For notational simplicity, we will drop thesubscript m from Im in the sequel.Though this optimization problem involves a nonconvexnorm constraint W \u0005 K H K W = I , it can still be solved efficiently by the following trace optimization problem:Proposition 1: Problem (6) can be reformulated asmax tr((W \u0005 (K L K + \u03bcI )W )\u22121 W \u0005 K H K W ).W(7)Proof: The Lagrangian of (6) istr(W \u0005 (K L K + \u03bcI )W ) \u2212 tr((W \u0005 K H K W \u2212 I )Z )(8)where Z is a diagonal matrix containing Lagrange multipliers. Setting the derivative of (8) w.r.t. W to zero, we have(K L K + \u03bcI )W = K H K W Z . Multiplying both sides onthe left by W T , and then on substituting it into (8), weobtain min W tr((W \u0005 K H K W )\u2020 W \u0005 (K L K + \u03bcI )W ). Sincethe matrix K L K + \u03bcI is nonsingular, we obtain an equivalenttrace maximization problem (7).Similar to kernel Fisher discriminant analysis [28], the Wsolutions in (7) are the m leading eigenvectors of (K L K +\u03bcI )\u22121 K H K , where m \u2264 n 1 + n 2 \u2212 1. In the sequel, this willbe referred to as TCA.\fPAN et al.: DOMAIN ADAPTATION VIA TRANSFER COMPONENT ANALYSISIV. SSTCAAs discussed in [6], a good representation should: 1) reducethe distance between the distributions of the source and targetdomain data, and 2) minimize the empirical error on thelabeled data in the source domain. However, the unsupervisedTCA proposed in Section III-C does not consider the labelinformation in learning the components. Moreover, in manyreal-world applications (such as WiFi localization), there existsan intrinsic low-dimensional manifold underlying the highdimensional observations. The effective use of manifold information is an important component in many semisupervisedlearning algorithms [29].In this section, we extend the unsupervised TCA in Section III-C to the semisupervised learning setting. Motivatedby the kernel target alignment [30], [31], a representation thatmaximizes its dependence with the data labels may lead tobetter generalization performance. Hence, we can maximizethe label dependence instead of minimizing the empiricalerror (Section IV-A.2). Moreover, we encode the manifoldstructure into the embedding learning so as to propagate labelinformation from the labeled (source domain) data to theunlabeled (target domain) data (Section IV-A.3). Note that intraditional semisupervised learning settings, the labeled andunlabeled data are from the same domain. However, in thecontext of domain adaptation here, the labeled and unlabeleddata are from different domains.A. Optimization ObjectivesIn this section, we delineate three desirable properties forthis semisupervised embedding, namely: 1) maximal alignment of distributions between the source and target domaindata in the embedded space; 2) high dependence on the labelinformation; and 3) preservation of the local geometry.1) Objective 1: Distribution Matching: As in the unsupervised TCA, our first objective is to minimize the MMD (5)between the source and target domain data in the embeddedspace.2) Objective 2: Label Dependence: Our second objective isto maximize the dependence (measured w.r.t. HSIC) betweenthe embedding and labels. Recall that, while the source domaindata are fully labeled, the target domain data are unlabeled.We propose to maximally align the embedding [which is\u0006 in (4)] withrepresented by KK\u0303 yy = \u03b3 K l + (1 \u2212 \u03b3 )K v(9)where \u03b3 \u2265 0. Here, [K l ]i j = k yy (yi , y j ) if i, j \u2264 n 1 ,otherwise [K l ]i j = 0, serves to maximize label dependenceon the labeled data, while K v = I , serves to maximize thevariance on both the source and target domain data, which is\u0006 (4) and K\u0303 yy (9)in line with MVU [26]. By substituting Kinto HSIC (Section II-B.2), our objective is thus to maximizetr(H (K W W \u0005K )H K\u0303 yy ) = tr(W \u0005K H K\u0303 yy H K W ).203via HSIC, and a large \u03b3 may be used. Otherwise, when thereare only a few labeled data in the source domain and a largenumber of unlabeled data in the target domain, we may use asmall \u03b3 . Empirically, simply setting \u03b3 = 0.5 works well onall the datasets. The sensitivity of the performance to \u03b3 willbe studied in more detail in Sections V-B and V-C.3) Objective 3: Locality Preserving: As reviewed in Sections II-C and III-A.1, colored MVU and MMDE preservethe local geometry of the manifold by enforcing distanceconstraints on the desired kernel matrix K . More specifically,let N = {(x i , x j )} be the set of sample pairs that are k-nearestneighbors of each other, and di j = \u0004x i \u2212 x j \u0004 be the distancebetween x i , x j in the original input space. For each (x i , x j ) inN , a constraint K ii + K j j \u2212 2K i j = di2j will be added to theoptimization problem. Hence, the resultant SDP will typicallyhave a very large number of constraints.To avoid this problem, we make use of the locality preserving property of the manifold regularizer [32]. First, weconstruct a graph with the affinity m i j = exp(\u2212di2j /2\u03c3 2 ) ifx i is one of the k nearest neighbors of x j , or vice versa. LetM = [m i j ]. The graph Laplacian matrix is L =\u0002D \u2212 M,where D is the diagonal matrix with entries dii = nj =1 m i j .Intuitively, if x i , x j are neighbors in the input space, thedistance between the embedding coordinates of x i and x jshould be small. Note that the data\u2019s embedding in Rm isW \u0005 K , where the i th column [W \u0005 K ]i provides the embeddingcoordinates of x i . Hence, our third objective is to minimize\u0003\u00032\u0007\u0003\u0003m i j \u0003[W \u0005 K ]i \u2212 [W \u0005 K ] j \u0003 = tr(W \u0005 K LK W ). (11)(i, j )\u2208NB. Formulation and Optimization ProcedureCombining all three objectives, we thus want to find a Wthat maximizes (10) while simultaneously minimizing (5) and(11). The final optimization problem can be written asminW tr(W \u0005 K L K W )+\u03bc tr(W \u0005 W )+\u0006yy H K W = Is.t. W \u0005 K H K\u03bbtr(W \u0005 K LK W )n2(12)where \u03bb \u2265 0 is another tradeoff parameter, and n 2 =(n 1 + n 2 )2 is a normalization term. For simplicity, we use\u03bb to denote \u03bb/n 2 in the rest of this paper. Similar to theunsupervised TCA, (12) can be formulated as the followingtrace problem:\b\u22121\u0006yy H K W .W\u0005K H Kmax tr W \u0005 K (L + \u03bbL)K W + \u03bcIWWe call this semisupervised transfer component analysis(SSTCA). It is Well known that it can be solved by eigen\u0006yy H K .decomposing (K (L + \u03bbL)K + \u03bcI )\u22121 K H KThe procedure for both the unsupervised and semisupervised TCA is summarized in Algorithm 1.(10)Note that \u03b3 is a tradeoff parameter that balances the labeldependence and data variance terms. Intuitively, if there aresufficient labeled data in the source domain, the dependencebetween features and labels can be estimated more preciselyC. Computational IssuesThe kernel learning algorithm for domain adaptation in [10]\u0006, therelies on SDPs. As there are O((n 1 +n 2 )2 ) variables in Koverall time complexity is O((n 1 + n 2 )6.5 ) [33]. This becomes\f204IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 2011Algorithm 1: TCA1Input: Source domain data set D S = {(x Si , ysrci )}ni=1,n2target domain data set DT = {x T j } j =1.andOutput: Transformation matrix W .n11: Construct kernel matrix K from {x Si }i=1and {x T j }nj 2=1based on (2), matrix L from (3), and centering matrix H .2: (Unsupervised TCA) Eigendecompose the matrix(K L K + \u03bcI )\u22121 K H K and select the m leadingeigenvectors to construct the transformation matrix W .3: (Semisupervised TCA) Eigendecompose matrix\u0006yy H K and select the m(K (L + \u03bb)LK + \u03bcI )\u22121 K H Kleading eigenvectors to construct the transformationmatrix W .4: return transformation matrix W .computationally prohibitive even for small-sized problems. Incontrast, our proposed kernel learning method requires onlya simple and efficient eigenvalue decomposition. This takesonly O(m(n 1 + n 2 )2 ) time when m nonzero eigenvectors areto be extracted [34].V. E XPERIMENTSIn this section, we first verify the motivations of ourproposed methods for domain adaptation on some toydatasets.A. Synthetic DataAs discussed in Section II-A, the optimization objective needs to include a number of criteria. In this section,we perform experiments to demonstrate the effectiveness ofTCA/SSTCA in learning a 1-D latent space from the 2-Ddata. For TCA, we use the linear kernel on inputs, and fix\u03bc = 1. For SSTCA, we use the linear kernel on both inputsand outputs, and fix \u03bc = 1, \u03b3 = 0.5.1) Only Minimizing Distance between Distributions: Asdiscussed in Section III-B, it is not desirable to learn thetransformation \u03c6 by only minimizing the distance betweenthe marginal distributions P(\u03c6(X S )) and P(\u03c6(X T )). Here, weillustrate this by using the synthetic data from the example inFig. 1(a) [which is also reproduced in Fig. 2(a)]. We compareTCA with the method of SSA [12], which is an empiricalmethod to find an identical stationary latent space of the sourceand target domain data.As can be seen from Fig. 2(b), the distance between distributions of different domain data in the 1-D space learned bySSA is small. However, the positive and negative samples areoverlapped together in this latent space, which is not useful formaking predictions on the mapped target domain data. On theother hand, as can be seen from Fig. 2(c), though the distancebetween distributions of different domain data in the latentspace learned by TCA is larger than that learned by SSA, thetwo classes are now more separated. We further apply the onenearest-neighbor (1-NN) classifier to make predictions on thetarget domain data in the original 2-D space, and latent spaceslearned by SSA and TCA. As can be seen from Fig. 2(a)\u2013(c),TCA leads to significantly better accuracy than SSA.2) Only Maximizing the Data Variance: As discussed inSection III-B, learning the transformation \u03c6 by only maximizing the data variance may not be useful in domain adaptation.Here, we reproduce Fig. 1(b) in Fig. 2(d). As can be seenfrom Fig. 2(e) and (f), the variance of the mapped data in the1-D space learned by PCA is very large. However, the distancebetween the mapped data across different domains is still largeand the positive and negative samples are overlapped togetherin the latent space, which is not useful for domain adaptation.On the other hand, though the variance of the mapped datain the 1-D space learned by TCA is smaller than that learnedby PCA, the distance between different domain data in thelatent space is reduced and the positive and negative samplesare more separated in the latent space.3) Label Information: In this experiment, we demonstratethe advantage of using label information in the source domaindata to improve classification performance [Fig. 2(g)]. Sincethe focus is not on locality preserving, we set the \u03bb inSSTCA to zero. Consequently, the difference between SSAand SSTCA is in the use of label information. As can beseen from Fig. 2(h), the positive and negative samples overlapsignificantly in the latent space learned by TCA. On the otherhand, with the use of label information, the positive andnegative samples are more separated in the latent space learnedby SSTCA [Fig. 2(i)], and thus classification also becomeseasier.However, in some applications, it may be possible that thediscriminative direction of the source domain data is quitedifferent from that of the target domain data. An example isshown in Fig. 2(j). In this case, encoding label informationfrom the source domain (as SSTCA does) may not help oreven hurt the classification performance as compared to theunsupervised TCA. As can be seen from Fig. 2(k) and (l),positive and negative samples in the target domain are moreseparated in the latent space learned by TCA than in thatlearned by SSTCA.In summary, when the discriminative directions acrossdifferent domains are similar, SSTCA can outperform TCAby encoding label information into the embedding learning.However, when the discriminative directions across differentdomains are different, SSTCA may not improve the performance or even performs worse than TCA. Nevertheless,compared to nonadaptive methods, both SSTCA and TCA canobtain better performance.4) Manifold Information: In this experiment, we demonstrate the advantage of using manifold information to improve classification performance. Both the source and domaindata have the well-known two-moon manifold structure [29][Fig. 2(m)]. SSTCA is used with and without Laplaciansmoothing [by setting \u03bb in (12) to 1000 and 0, respectively].As can be seen from Fig. 2(n) and (o), Laplacian smoothingcan indeed help improve classification performance whenthe manifold structure is available underlying the observeddata.B. Cross-Domain Indoor WiFi LocalizationWith the increasing availability of 802.11 WiFi networksin cities and buildings, locating and tracking a user or cargo\fPAN et al.: DOMAIN ADAPTATION VIA TRANSFER COMPONENT ANALYSIS2052Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data1.81.61.41PDFPDFx21.20.80.60.40.20\u221221-D latent space1-D latent space\u22121012x134\u2212135\u221212\u221211(a)\u221210x\u22129\u22128\u22127\u221225\u221220\u221215(b)\u221210x\u221250(c)5Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data43PDFx2PDF210\u22121\u22122\u221221-D latent space1-D latent space\u221210123456789\u2212150\u2212100\u221250x10x50(d)(e)100150\u221210\u2212505x101520(f)9Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data73PDFPDFx251\u22121\u22123\u221215\u221210\u221250x151015\u22123001-D latent space0\u2212100x1-D latent space\u2212200(g)100200300\u2212175\u2212125\u221275\u221225x(h)2575125(i)5Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data431PDFx2PDF20\u22121\u22122\u22122 \u221210123x145678\u221251-D latent space\u22122.5 0 2.5 57.5x10 12.5 15 17.5 201-D latent space\u221220\u221217.5\u221215\u221212.5\u221210 \u22127.5 \u22125 \u22122.5 0 2.5 5 7.5 10x(k)(j)(l)4Pos. source domain dataNeg. source domain dataPos. target domain dataNeg. target domain data3.532.5PDFPDFx221.510.50\u22120.5\u22121\u22122 \u221211-D latent space0123x1(m)45678\u221210 \u22127.5 \u22125 \u22122.51-D latent space02.5x(n)57.51012\u221212 \u221210 \u22128 \u22126 \u22124 \u221220246810x(o)Fig. 2. Illustrations of the proposed TCA and SSTCA on five synthetic datasets. The leftmost column shows data in the original 2-D input space, while theother columns show the projected data in the 1-D latent spaces learned by different methods. Accuracy of the 1-NN classifier in the original input/latent spaceis shown inside brackets. (a) Dataset 1 (acc: 82%). (b) 1-D projection by SSA (acc: 60%). (c) 1-D projection by TCA (acc: 86%). (d) Dataset 2 (accuracy:50%). (e) 1-D projection by PCA (acc: 48%). (f) 1-D projection by TCA (acc: 82%). (g) Data set 3 (acc: 69%). (h) 1-D projection by TCA (acc: 56%). (i)1-D projection by SSTCA (acc: 79%). (j) Dataset 4 (accuracy: 60%). (k) 1-D projection by TCA (acc: 90%). (l) 1-D projection by SSTCA (acc: 68%). (m)Dataset 5 (acc: 70%). (n) 1-D projection by SSTCA without Laplacian smoothing (acc: 83%). (o) 1-D projection by SSTCA with Laplacian smoothing (acc:91%).\f206IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 2011with wireless signal strength or received signal strength (RSS)is becoming a reality [1], [2]. The objective of indoor WiFilocalization is to estimate the location yi of a mobile devicebased on the RSS values x i = (x i1 , x i2 , . . . , x ik ) received fromk access points, which periodically send out wireless signalsto others. In the following, we consider the 2-D coordinatesof a location, and indoor WiFi localization is intrinsically aregression problem. However, it is expensive to calibrate alocalization model in a large environment. Moreover, the RSSvalues are noisy and can vary with time [2]. As a result,even in the same environment, the RSS data collected inone time period may differ from those collected in another.Hence, domain adaptation is necessary for indoor WiFi localization.1) Experimental Setup: We use a public dataset from the2007 IEEE ICDM Contest (the second task). This containsa few labeled WiFi data collected in time period T1 (thesource domain) and a large amount of unlabeled WiFi datacollected in time period T2 (the target domain). Here, \u201clabel\u201drefers to the location information for which the WiFi data arereceived. WiFi data collected from different time periods areconsidered as different domains. The task is to predict thelabels of the WiFi data collected in time period T2 . For moredetails on the dataset, readers may refer to the contest reportarticle [2].Denote the data collected in time period T1 and time periodT2 by D S and DT , respectively. In the experiments, we have|D S | = 621 and |DT | = 3, 128. Furthermore, we randomlysplit DT into DTu (the label information is removed in training)and DTo . All the source domain data (621 instances in total) areused for training. As for the target domain data, 2328 patternsare sampled to form DTo , and a variable number of patternsare sampled from the rest 800 patterns to form DTu .In the transductive evaluation setting, our goal is to learna model from D S and DTu , and then evaluate the modelon DTu . In the out-of-sample evaluation setting, our goalis to learn a model from D S and DTu , and then evaluatethe model on DTo (out-of-sample patterns). For each experiment, we repeat 10 times and then report the averageperformance using the average error distance (AED): AED =\u0002(x i ,yi )\u2208D | f (x i ) \u2212 yi | /N. Here, x i is a vector of RSSvalues, f (x i ) is the predicted location, yi is the correspondingground truth location, while D = DTu in the transductivesetting, and D = DTo in the out-of-sample evaluation setting.The following methods will be compared. For parametertuning of all methods, 50 labeled data are sampled from thesource domain as a validation set. 1) Traditional regressionmodels that do not perform domain adaptation. These includethe (supervised) regularized least square regression (RLSR),which is trained on D S only, and the (semisupervised) Laplacian RLSR (LapRLSR) [32], which is trained on both D Sand DTu but without considering the difference in distributions.2) A traditional dimensionality reduction method: Kernel PCA(KPCA) [27]. It first learns a projection from both D S and DTuvia KPCA. RLSR is then applied on the projected D S to learn alocalization model. 3) Importance reweighting methods: KMMand KLIEP. They use both D S and DTu to learn weights ofthe patterns in D S , and then train an RLSR model on theweighted data. Following [14], we set the \u0006 parameter in\u221aKMM as B/ n 1 , where n 1 is the number of training data inthe source domain. For KLIEP, we use the likelihood crossvalidation method in [15] to automatically select the kernelwidth. Preliminary results suggest that the final performanceof KLIEP can be sensitive to the initialization of the kernelwidth. Thus, its initial value is also tuned on the validationset. 4) A state-of-the-art domain adaptation method. SCL [9]1It learns a set of new cross-domain features from both D S andDTu , and then augments features on the source domain data inD S with the new features. A RLSR model is then trained.5) The proposed TCA and SSTCA. First, we applyTCA/SSTCA on both D S and DTu to learn transfer components, and map data in D S to the latent space. Finally, a RLSRmodel is trained on the projected source domain data. Thereare two parameters in TCA, kernel width2 \u03c3 and parameter \u03bc.We first set \u03bc = 1 and search for the best \u03c3 value (based onthe validation set) in the range [10\u22125 , 105 ]. Afterwards, we fix\u03c3 and search for the best \u03bc value in [10\u22123 , 103 ]. For SSTCA,we use linear kernel for k yy in (9) on the labels, and there arefour tunable parameters (\u03c3 , \u03bc, \u03bb, and \u03b3 ). We set \u03c3 and \u03bc in thesame manner as TCA. Then, we set \u03b3 = 0.5 and search for thebest \u03bb value in [10\u22126 , 106 ]. Afterwards, we fix \u03bb and searchfor \u03b3 in [0, 1]. 6) Methods that only perform distributionmatching in a latent space: SSA [12] and TCAReduced,which replaces the constraint W \u0005 K H K W = I in TCA byW \u0005 W = I . Hence, TCAReduced aims to find a transformation W that minimizes the distance between different distributions without maximizing the variance in the latent space.7) A closely related dimensionality reduction method, MMDE.This is a state-of-the-art method on the ICDM-09 contestdataset [35].2) Comparison to Dimensionality Reduction Methods: Wefirst compare TCA and SSTCA with some dimensionalityreduction methods, including KPCA, SSA and TCAReducedin the out-of-sample setting. The number of unlabeled patternsin DTu is fixed at 400, while the dimensionality of the latentspace varies from 5 to 50.Fig. 3(a) shows the results. As can be seen, TCA andSSTCA outperform all the other methods. Moreover, notethat KPCA, though simple, can lead to significantly improvedperformance. This is because the WiFi data are highly noisy,and thus localization models learned in the denoised latentspace can be more accurate than those learned in the originalinput space. However, as mentioned in Section V-A, KPCAcan only denoise but cannot ensure that the distance betweendata distributions in the two domains is reduced. Thus, TCAperforms better than KPCA. In addition, though TCAReducedand SSA aim to reduce distance between domains, they maylose important information of the original data in the latentspace, which in turn may hurt performance of the target learning tasks. Thus, they do not obtain good performance. Finally,we observe that SSTCA obtains better performance than1 The pivot features are selected by mutual information while the numberof pivots and other SCL parameters are determined by the validation data.2 Here, we use the Laplacian kernel k(x , x ) = exp \u2212\u0004x \u2212 x \u0004/\u03c3 .i jij\fPAN et al.: DOMAIN ADAPTATION VIA TRANSFER COMPONENT ANALYSIS207TABLE ID ATA D ESCRIPTION : THE 20-N EWSGROUPS D ATASETSSource Domain Target DomainTask# Fea. # Doc.# Pos. # Neg. # Pos. # Neg.Comp versus Sci (C versus S) 38 065 6000 1500150015001500Rec versus Talk (R versus T)30 165 6000 1500150015001500Rec versus Sci (R versus S)29 644 6000 1500150015001500Sci versus Talk (S versus T)33 151 6000 1500150015001500Comp versus Rec (C versus R) 40 827 6000 1500150015001500Comp versus Talk (C versus T) 45 514 6000 1500150015001500TCA. As demonstrated in previous research [35], the manifoldassumption holds on the WiFi data. Thus, the graph Laplacianterm in SSTCA can effectively exploit label information fromthe labeled data to the unlabeled data across domains.3) Comparison with Nonadaptive Methods: In this experiment, we compare TCA and SSTCA with learning-basedlocalization models that do not perform domain adaptation,including RLSR, LapRLSR, and KPCA. The dimensionalitiesof the latent spaces for KPCA, TCA and SSTCA are fixed at15. These values are determined based on the first experimentin Section V-B.2.Fig. 3(b) shows the performance when the number ofunlabeled patterns in DTu varies. As can be seen, even withonly a few unlabeled data in the target domain, TCA andSSTCA can perform well for domain adaptation.4) Comparison with Domain Adaptation Methods: In thissection, we compare TCA and SSTCA with some state-ofthe-art domain adaptation methods, including KMM, KLIEP,SCL, and SSA. We fix the dimensionalities of the latent spacein TCA and SSTCA at 15, while we fix the dimensionalities ofthe latent space in SSA and TCAReduced at 50. For training,all the source domain data are used and varying amounts ofthe target domain data are sampled as |DTu |.Results are shown in Fig. 3(c). As can be seen, domain adaptation methods that are based on feature extraction (includingSCL, TCA, and SSTCA) perform much better than instancereweighting methods (including KMM and KLIEP). This isagain because the WiFi data are highly noisy, and so matchingdistributions directly based on the noisy observations may notbe useful. Indeed, SCL may suffer from the bad choice of pivotfeatures due to the noisy observations. On the other hand, TCAand SSTCA match distributions in the latent space, where theWiFi data have been implicitly denoised.5) Comparison with MMDE: In this section, we compareTCA and SSTCA with MMDE in the transductive setting. Thelatent space is learned from D S and a subset of the unlabeledtarget domain data sampled from DTu . The performance is thenmeasured on DTu .Fig. 4(a) shows the results for different dimensionalities ofthe latent space with |DTu | = 400, while Fig. 4(b) shows theresults for different amounts of unlabeled target domain data,with the dimensionalities of MMDE, TCA, and SSTCA fixedat 15. As can be seen, MMDE outperforms TCA and SSTCA.This may be due to the limitation that the kernel matrix used inTCA/SSTCA is parametric. However, as mentioned in SectionIV-C, MMDE is computationally expensive because it involvesan SDP. This is confirmed in the training time comparison inFig. 4(c). In practice, TCA or SSTCA may be a better choicethan MMDE.6) Sensitivity to Parameters: In this section, we investigatethe effects of the parameters on the regression performance.These include the kernel width \u03c3 in the Laplacian kernel,tradeoff parameter \u03bc, and for SSTCA, the two additionalparameters \u03b3 and \u03bb. The out-of-sample evaluation setting isused. All the source domain data are used, and we sample2328 samples from the target domain data to form DTo , andanother 400 samples to form DTu . The dimensionalities of thelatent spaces in TCA and SSTCA are fixed at 15. As can beseen from Fig. 5, both TCA and SSTCA are insensitive tovarious settings of the parameters.C. Cross-Domain Text Classification1) Experimental Setup: In this section, we perform crossdomain text classification experiments on a preprocesseddataset of the 20-Newsgroups [36]. In this experiment, wefollow the preprocessing strategy in [37] to create six datasetsfrom this collection. For each dataset, two top categories arechosen, one as positive and the other as negative. We then splitthe data based on subcategories. Different subcategories areconsidered as different domains, and the binary classificationtask is defined as top category classification. This splittingstrategy ensures that the domains of labeled and unlabeleddata are related, since they are under the same top categories.Besides, the domains are also ensured to be different, sincethey are drawn from different subcategories. The six data setscreated are \u201ccomp versus sci,\u201d \u201crec versus talk,\u201d \u201crec versussci,\u201d \u201csci versus talk,\u201d \u201ccomp versus rec,\u201d and \u201ccomp versustalk\u201d (Table I).From each of these six datasets, we randomly sample 40%of the documents from the source domain as D S , and sample40% from the target domain to form the unlabeled subset DTu ,and the remaining 60% in the target domain to form the out-ofsample subset DTo . Hence, in each cross-domain classificationtask, |D S | = 1200, |DTu | = 1200, and |DTo | = 1800. We run10 repetitions and report the average results. All experimentsare performed in the out-of-sample setting. The evaluationcriterion is the classification accuracy.Similar to Section V-B, we perform a series of experimentsto compare TCA and SSTCA with the following methods.1) Linear support vector machine (SVM) in the original inputspace. 2) KPCA. A linear SVM is then trained in the latentspace. 3) Three domain adaptation methods: KMM, KLIEP,and SCL. Again, a linear SVM is used as the classifierin the latent space. We experiment with the radial basis\f208IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 20113015890RLSRLapRLSRKPCASSTCATCA7AED (unit: m)AED (unit: m)8KPCASSTCATCATCAReducedSSA556544.522138532.51.50KLIEPSCLKMMSSTCATCATCAReducedSSA40AED (unit: m)1005101520 25 30 35# Dimensions404550255(a)3200100 200 300 400 500 600 700 800 900# Unlabeled Data in the Target Domain for Training100 200 300 400 500 600 700 800 900# Unlabeled Data in the Target Domain for Training(b)(c)64.543.532.52.62.42.221.821.50MMDESSTCATCA2.8AED (unit: m)5AED (unti: m)3MMDESSTCATCA5.55101520 25 30 35# Dimensions40455055(a)1.60100 200 300 400 500 600 700 800 900# Unlabeled Data in the Target Domain for TrainingRunning Time (unit: sec)Fig. 3. Comparison of TCA, SSTCA and the various baseline methods in the inductive setting on the WiFi data. (a) Results on dimensionality reductionmethods. (b) Comparison with nonadaptive methods. (c) Comparison with domain adaptation methods.MMDESSTCATCA1051041031021011000100 200 300 400 500 600 700 800 900# Unlabeled Data in the Target Domain for Training(b)(c)TCASSTCA2.82.72.62.52.42.3\u22125 \u22124 \u22123 \u22122 \u22121 0 1 2 3 4 5log10\u03c3(a)2.2\u22124 \u22123 \u22122 \u2212101log10\u03bc234(b)2.7SSTCA2.652.62.552.52.452.42.352.32.252.2\u22120.1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1Values of \u03b31 (\u03b32 = 1 \u2212 \u03b31)(c)AED (unit: m)2.9TCASSTCAAED (unit: m)5550454035302520151050AED (unit: m)AED (unit: m)Fig. 4. Comparison with MMDE in the transductive setting on the WiFi data. (a) Varying the dimensionality of the latent space. (b) Varying the number ofunlabeled data. (c) Comparison on training time.454035302520151050SSTCA\u22127\u22126\u22125\u22124\u22123\u22122\u22121 0 1 2 3 4 5 6 7log10\u03bb(d)Fig. 5. Sensitivity analysis of the TCA/SSTCA parameters on the WiFi data. (a) Varying \u03c3 of the Laplacian kernel. (b) Varying \u03bc. (c) Varying \u03b3 in SSTCA.(d) varying \u03bb in SSTCA.function (RBF), Laplacian, and linear kernels for featureextraction or reweighting in KPCA, KMM, TCA and SSTCA.Note that we do not compare with SSA because it results in\u201cout of memory\u201d on computing the covariance matrices. ForSSTCA, kernel k yy in (9) is the linear kernel. The \u03bc parametersin TCA and SSTCA are set to 1, and the \u03bb parameter inSSTCA is set to 0.0001.2) Results: Results are shown in Table II. As can be seen,we can obtain a similar conclusion as in Section V-B. Overall,feature extraction methods outperform instance-reweightingmethods. In addition, on tasks such as \u201cR versus T,\u201d \u201cCversus T,\u201d \u201cC versus S,\u201d and \u201cC versus R,\u201d the performance ofPCA is comparable to that of linear TCA. However, on taskssuch as \u201cR versus S\u201d and \u201cS versus T,\u201d linear TCA performsmuch better than PCA. This agrees with our motivation andthe previous conclusion on the WiFi experiments, namely thatmapping data from different domains to a latent space spannedby the principal components may not work well, as PCAcannot guarantee a reduction in distance of the two domaindistributions. In general, one may notice two main differencesbetween the results on the WiFi data and those on the textdata. First, the linear kernel performs better than the RBFand Laplacian kernels here. This agrees with the well-knownobservation that the linear kernel is often adequate for highdimensional text data. Moreover, TCA performs better thanSSTCA on the text data. This may be because the manifoldassumption is weaker in the text domain than in the WiFidomain.We also test how the various parameters in TCA andSSTCA affect the classification performance. For this test, weuse linear kernels for both the inputs and outputs, and thedimensionalities of the latent spaces are fixed at 10. Thus, theremaining free parameters are \u03bc for TCA, and \u03bc, \u03b3 and \u03bb forSSTCA. Due to the limitation of space, we do not show thedetailed results of these experiments. Similar to the results onthe WiFi data, both TCA and SSTCA are insensitive to thesetting of \u03bc. In addition, there is a wide range of \u03bb for whichthe performance of SSTCA is quite stable. However, differentfrom the WiFi results in Fig. 5(d) where SSTCA performswell when \u03bb \u2264 102 , on the text datasets SSTCA performswell only when \u03bb is very small (\u03bb \u2264 10\u22124 ). This indicates thatmanifold regularization may not be useful on this text data.\fPAN et al.: DOMAIN ADAPTATION VIA TRANSFER COMPONENT ANALYSIS209TABLE IIC LASSIFICATION A CCURACIES (%) OF THE VARIOUS M ETHODS ( THE N UMBER I NSIDE PARENTHESES I S THE S TANDARD D EVIATION )taskmethod#dimC versus SR versus TR versus SS versus TC versus RC versus TSVMall68.26 (1.23)72.33 (2.32)75.86 (1.55)76.70 (1.05)81.59 (1.36)90.51 (0.70)linear1070.41 (6.84)87.67 (2.12)82.83 (3.07)84.51 (5.04)89.79 (2.54)88.67 (3.01)kernel2069.04 (5.07)81.52 (8.86)83.86 (3.24)82.23 (2.64)89.73 (4.04)92.03 (2.05)3069.01 (2.39)77.26 (15.81)84.44 (2.29)79.81 (4.20)91.81 (2.38)92.23 (2.41)Laplacian1069.12 (13.27)78.68 (8.23)79.58 (8.12)69.02 (5.31)82.29 (2.57)90.01 (1.02)TCAkernel2069.37 (11.22)79.57 (4.31)78.71 (9.22)74.71 (3.01)85.59 (1.59)92.68 (1.12)3068.58 (11.21)80.43 (4.64)76.69 (9.52)74.40 (2.49)87.89 (2.22)92.63 (0.84)RBF1074.88 (3.51)82.51 (7.65)78.34 (6.58)81.65 (4.08)82.69 (2.24)89.15 (0.69)kernel2072.60 (5.60)77.47 (2.62)78.09 (6.88)79.54 (1.89)83.51 (3.32)90.77 (0.83)3071.64 (5.49)77.62 (3.75)80.11 (7.73)79.50 (1.91)83.71 (2.27)91.58 (0.64)68.64 (3.00)75.11 (11.93)81.46 (3.59)73.75 (7.55)85.99 (3.22)91.38 (2.22)linear10kernel2064.28 (3.48)60.69 (14.87)77.45 (5.30)78.19 (4.17)86.71 (3.36)91.81 (2.13)3065.08 (3.12)66.30 (16.74)77.98 (4.19)72.79 (5.75)85.81 (3.23)93.38 (2.02)Laplacian1075.29 (3.92)79.84 (5.03)72.70 (10.69)73.10 (2.10)85.26 (2.25)91.72 (0.64)SSTCAkernel2071.99 (4.73)81.77 (3.44)72.99 (9.99)74.94 (2.28)84.28 (1.27)92.47 (0.74)3069.71 (4.99)82.09 (4.42)72.34 (10.82)74.67 (1.79)85.30 (1.80)92.73 (0.76)RBF1073.76 (3.25)74.50 (7.85)78.51 (7.50)77.61 (1.49)83.09 (.0287)90.35 (1.18)kernel2070.87 (7.51)75.49 (6.67)79.28 (7.20)79.46 (1.27)80.02 (.0287)90.62 (0.83)3070.16 (5.98)77.03 (5.56)79.06 (7.60)79.88 (1.52)81.30 (.0287)90.21 (0.96)68.66 (6.59)88.26 (5.85)68.59 (10.00)81.42 (6.67)87.33 (3.56)91.24 (1.84)linear10kernel2069.18 (6.27)82.59 (7.07)71.46 (7.41)80.22 (3.81)89.49 (3.34)93.44 (1.92)3070.55 (2.81)80.94 (11.63)78.90 (8.33)77.92 (4.32)91.36 (1.51)93.66 (1.81)Laplacian1044.43 (8.01)81.52 (9.00)54.42 (7.33)80.37 (.0252)58.87 (4.97)58.47 (2.35)KPCAkernel2049.08 (10.46)55.67 (6.35)50.42 (1.01)72.67 (.0252)75.71 (6.83)73.94 (3.75)3045.24 (8.17)63.13 (7.76)50.43 (1.03)69.36 (.0252)75.07 (10.64)74.18 (4.24)RBF1053.82 (6.23)78.50 (4.23)51.64 (2.11)79.92 (.0252)57.84 (3.74)56.82 (2.03)kernel2047.66 (8.19)60.94 (10.97)50.49 (1.00)79.37 (.0252)67.73 (5.53)62.36 (3.84)3047.82 (8.37)69.13 (9.66)51.86 (3.82)72.31 (.0252)67.66 (4.48)64.76 (5.14)SCLall+5068.29 (1.22)72.38 (2.36)75.87 (1.48)76.73 (1.00)81.60 (1.35)90.61 (0.64)69.81 (1.27)72.86 (1.53)75.29 (1.85)76.38 (1.32)78.17 (1.29)88.06 (1.33)linear kernelallKMMLaplacian kernelall69.64 (1.27)73.10 (1.67)76.62 (1.23)75.83 (1.27)77.81 (1.21)85.92 (0.70)RBF kernelall69.65 (1.24)73.07 (1.48)76.63 (1.14)76.43 (1.17)77.28 (1.18)84.30 (1.00)KLIEPall68.55 (1.36)72.23 (1.20)75.53 (1.17)75.11 (0.81)77.94 (1.09)85.12 (0.99)In this case, using unsupervised TCA for domain adaptationmay be a better choice than using SSTCA.VI. C ONCLUSION AND F UTURE W ORKIn this paper, we proposed a novel feature extractionmethod, TCA, for domain adaptation. It learns a set of transfercomponents in a RKHS such that when projecting domain dataonto the latent space spanned by the transfer components, thedistance between domains can be reduced. In order to capturethe label dependence in transfer components learning, wefurther proposed a semisupervised feature extraction method,i.e., SSTCA, which can reduce the distance in data distributions between domains and maximize label dependence in alatent space simultaneously. Compared to the previous domainadaptation methods, TCA and SSTCA match distributions ina denoised latent space instead of the original feature space.Experiments on toy datasets and two real-world applicationsverify the efficiency and effectiveness of the proposed TCAand SSTCA.In the future, we plan to continue our work by pursuingseveral avenues. First, we plan to adaptively estimate thenumber of transfer components in TCA and SSTCA. Second,in order to speed up kernel learning for domain adaptation,TCA and SSTCA propose to use parametric kernels for theMMD measure, we plan to develop an efficient algorithm forkernel choice in TCA and SSTCA. Moreover, we also plan toextend TCA and SSTCA to a multidomain setting.ACKNOWLEDGMENTThe authors would like to thank P. von B\u00fcnau for providingthe code of stationary subspace analysis.R EFERENCES[1] S.-H. Fang and T.-N. Lin, \u201cIndoor location system based ondiscriminant-adaptive neural network in IEEE 802.11 environments,\u201dIEEE Trans. Neural Netw., vol. 19, no. 11, pp. 1973\u20131978, Nov. 2008.[2] Q. Yang, S. J. Pan, and V. W. Zheng, \u201cEstimating location using Wi-Fi,\u201dIEEE Intell. Syst., vol. 23, no. 1, pp. 8\u201313, Jan.\u2013Feb. 2008.[3] J. Ghosn and Y. Bengio, \u201cBias learning, knowledge sharing,\u201d IEEETrans. Neural Netw., vol. 14, no. 4, pp. 748\u2013765, Jul. 2003.[4] S. Ozawa, A. Roy, and D. Roussinov, \u201cA multitask learning model foronline pattern recognition,\u201d IEEE Trans. Neural Netw., vol. 20, no. 3,pp. 430\u2013445, Mar. 2009.[5] S. J. Pan and Q. Yang, \u201cA survey on transfer learning,\u201d IEEE Trans.Knowl. Data Eng., vol. 22, no. 10, pp. 1345\u20131359, Oct. 2010.[6] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira, \u201cAnalysis of representations for domain adaptation,\u201d in Advances in Neural InformationProcessing Systems 19. Cambridge, MA: MIT Press, 2007, pp. 137\u2013144.[7] L. Song, A. Smola, K. Borgwardt, and A. Gretton, \u201cColored maximumvariance unfolding,\u201d in Advances in Neural Information ProcessingSystems 20. Cambridge, MA: MIT Press, 2008, pp. 1385\u20131392.[8] H. Daum\u00e9, III, \u201cFrustratingly easy domain adaptation,\u201d in Proc. 45thAnn. Meeting Assoc. Comput. Linguistics, Prague, Czech Republic, Jun.2007, pp. 256\u2013263.[9] J. Blitzer, R. McDonald, and F. Pereira, \u201cDomain adaptation withstructural correspondence learning,\u201d in Proc. Conf. Empirical MethodsNatural Lang., Sydney, Australia, Jul. 2006, pp. 120\u2013128.[10] S. J. Pan, J. T. Kwok, and Q. Yang, \u201cTransfer learning via dimensionalityreduction,\u201d in Proc. 23rd AAAI Conf. Artif. Intell., Chicago, IL, Jul. 2008,pp. 677\u2013682.[11] R. K. Ando and T. Zhang, \u201cA framework for learning predictivestructures from multiple tasks and unlabeled data,\u201d J. Mach. Learn. Res.,vol. 6, pp. 1817\u20131853, Nov. 2005.\f210[12] P. von B\u00fcnau, F. C. Meinecke, F. C. Kir\u00faly, and K. R. M\u00fcller, \u201cFindingstationary subspaces in multivariate time series,\u201d Phys. Rev. Lett., vol.103, no. 21, pp. 214101-1\u2013214101-4, Sep. 2009.[13] J. Suykens, \u201cData visualization and dimensionality reduction usingkernel maps with a reference point,\u201d IEEE Trans. Neural Netw., vol.19, no. 9, pp. 1501\u20131517, Sep. 2008.[14] J. Huang, A. Smola, A. Gretton, K. M. Borgwardt, and B. Sch\u00f6lkopf,\u201cCorrecting sample selection bias by unlabeled data,\u201d in Advances inNeural Information Processing Systems 19. Cambridge, MA: MIT Press,2007, pp. 601\u2013608.[15] M. Sugiyama, S. Nakajima, H. Kashima, P. V. Buenau, andM. Kawanabe, \u201cDirect importance estimation with model selection andits application to covariate shift adaptation,\u201d in Advances in NeuralInformation Processing Systems 20. Cambridge, MA: MIT Press, 2008,pp. 1433\u20131440.[16] S. Bickel, M. Br\u00fcckner, and T. Scheffer, \u201cDiscriminative learning undercovariate shift,\u201d J. Mach. Learn. Res., vol. 10, pp. 2137\u20132155, Sep. 2009.[17] T. Kanamori, S. Hido, and M. Sugiyama, \u201cA least-squares approach todirect importance estimation,\u201d J. Mach. Learn. Res., vol. 10, pp. 1391\u20131445, Jul. 2009.[18] M. Sugiyama, M. Kawanabe, and P. L. Chui, \u201cDimensionality reductionfor density ratio estimation in high-dimensional spaces,\u201d Neural Netw.,vol. 23, no. 1, pp. 44\u201359, Jan. 2010.[19] T. Suzuki and M. Sugiyama, \u201cEstimating squared-loss mutual information for independent component analysis,\u201d in Proc. 8th Int. Conf.Independent Compon. Anal. Signal Separation, Paraty, Brazil, Mar.2009, pp. 130\u2013137.[20] S. Hido, Y. Tsuboi, H. Kashima, M. Sugiyama, and T. Kanamori, \u201cInlierbased outlier detection via direct density ratio estimation,\u201d in Proc. 8thIEEE Int. Conf. Data Mining, Pisa, Italy, Dec. 2008, pp. 223\u2013232.[21] Y. Kawahara and M. Sugiyama, \u201cChange-point detection in time-seriesdata by direct density-ratio estimation,\u201d in Proc. SIAM Int. Conf. DataMining, Sparks, NV, Apr. 2009, pp. 389\u2013400.[22] A. J. Smola, A. Gretton, L. Song, and B. Sch\u00f6lkopf, \u201cA Hilbert spaceembedding for distributions,\u201d in Proc. 18th Int. Conf. Algorithmic Learn.Theory, Sendai, Japan, Oct. 2007, pp. 13\u201331.[23] A. Gretton, K. Borgwardt, M. Rasch, B. Sch\u00f6lkopf, and A. Smola, \u201cAkernel method for the two-sample problem,\u201d in Proc. Conf. Neural Inf.Process. Syst. 19. Cambridge, MA, 2007, pp. 513\u2013520.[24] A. Gretton, O. Bousquet, A. J. Smola, and B. Sch\u00f6lkopf, \u201cMeasuringstatistical dependence with Hilbert-Schmidt norms,\u201d in Proc. 18th Int.Conf. Algorithmic Learn. Theory, Singapore, Oct. 2005, pp. 63\u201377.[25] I. Steinwart, \u201cOn the influence of the kernel on the consistency ofsupport vector machines,\u201d J. Mach. Learn. Res., vol. 2, pp. 67\u201393, Nov.2001.[26] K. Q. Weinberger, F. Sha, and L. K. Saul, \u201cLearning a kernel matrixfor nonlinear dimensionality reduction,\u201d in Proc. 21st Int. Conf. Mach.Learn., Banff, AB, Canada, Jul. 2004, pp. 839\u2013846.[27] B. Sch\u00f6lkopf, A. Smola, and K.-R. M\u00fcller, \u201cNonlinear componentanalysis as a kernel eigenvalue problem,\u201d Neural Comput., vol. 10, no.5, pp. 1299\u20131319, Jul. 1998.[28] K.-R. M\u00fcller, S. Mika, G. R\u00e4tsch, K. Tsuda, and B. Sch\u00f6lkopf, \u201cAnintroduction to kernel-based learning algorithms,\u201d IEEE Trans. NeuralNetw., vol. 12, no. 2, pp. 181\u2013201, Mar. 2001.[29] O. Chapelle, B. Sch\u00f6lkopf, and A. Zien, Semi-Supervised Learning.Cambridge, MA: MIT Press, 2006.[30] N. Cristianini, J. Kandola, A. Elisseeff, and J. Shawe-Taylor, \u201cOnkernel-target alignment,\u201d in Advances in Neural Information ProcessingSystems 14. Cambridge, MA: MIT Press, 2002, pp. 367\u2013373.[31] H. Xiong, M. Swamy, and M. Ahmad, \u201cOptimizing the kernel in theempirical feature space,\u201d IEEE Trans. Neural Netw., vol. 16, no. 2, pp.460\u2013474, Mar. 2005.[32] M. Belkin, P. Niyogi, and V. Sindhwani, \u201cManifold regularization:A geometric framework for learning from labeled and unlabeledexamples,\u201d J. Mach. Learn. Res., vol. 7, pp. 2399\u20132434, Nov. 2006.[33] Y. Nesterov and A. Nemirovskii, Interior-Point Polynomial Algorithmsin Convex Programming. Philadelphia, PA: SIAM, 1994.[34] D. C. Sorensen, \u201cImplicitly restarted Arnoldi/Lanczos methods for largescale eigenvalue calculations,\u201d Dept. Comput. Appl. Math., Rice Univ.,Houston, TX, Tech. Rep. TR-96-40, 1996.[35] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, \u201cDomain adaptationvia transfer component analysis,\u201d in Proc. 21st Int. Joint Conf. Artif.Intell., Pasadena, CA, Jul. 2009, pp. 1187\u20131192.[36] K. Lang, \u201cNewsweeder: Learning to filter netnews,\u201d in Proc. 12th Int.Conf. Mach. Learn., San Mateo, CA, 1995, pp. 331\u2013339.IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 22, NO. 2, FEBRUARY 2011[37] W. Dai, G. Xue, Q. Yang, and Y. Yu, \u201cCo-clustering based classificationfor out-of-domain documents,\u201d in Proc. 13th ACM SIGKDD Int. Conf.Knowl. Discovery Data Mining, San Jose, CA, Aug. 2007, pp. 210\u2013219.Sinno Jialin Pan received the B.S. and M.S. degreesin applied mathematics from Sun Yat-sen University,Guangzhou, China, in 2003 and 2005, respectively,and the Ph.D. degree in computer science and engineering from the Hong Kong University of Scienceand Technology, Hong Kong, in 2010.He is currently a Research Fellow at the Institute for Infocomm Research, Singapore. His currentresearch interests include transfer learning and itsapplications in pervasive computing, bioinformatics,and web mining such as opinion mining, text mining,and information extraction.Ivor W. Tsang received the Ph.D. degree in computer science from the Hong Kong University ofScience and Technology, Hong Kong, in 2007.He is currently an Assistant Professor with theSchool of Computer Engineering, Nanyang Technological University (NTU), Singapore. He is alsothe Deputy Director of the Center for ComputationalIntelligence, NTU.Dr. Tsang received the IEEE T RANSACTIONS ONN EURAL N ETWORKS Outstanding Paper Award for2004 in 2006, and the second-class Prize of theNational Natural Science Award 2008, China, in 2009. He was awarded theMicrosoft Fellowship in 2005 and the Best Paper Award from the IEEE HongKong Chapter of the Signal Processing Postgraduate Forum in 2006. His workwas also awarded the Best Student Paper Prize at CVPR\u201910.James T. Kwok received the Ph.D. degree in computer science from the Hong Kong University ofScience and Technology, Hong Kong, in 1996.He was with the Department of Computer Science,Hong Kong Baptist University, Hong Kong, as anAssistant Professor. Since 2000, he has been anAssociate Professor in the Department of ComputerScience and Engineering, Hong Kong Universityof Science and Technology. His current researchinterests include kernel methods, machine learning,pattern recognition, and artificial neural networks.Dr. Kwok received the IEEE Outstanding Paper Award in 2006, and thesecond-class Prize of the National Natural Science Award 2008, China, in2009. He is currently an Associate Editor for the IEEE T RANSACTIONS ONN EURAL N ETWORKS and the Neurocomputing Journal.Qiang Yang (F\u201902) received the B.S. degree inastrophysics from Peking University, Beijing, China,and the Ph.D. degree in computer science from theUniversity of Maryland, College Park.He is now a Professor in the Department ofComputer Science and Engineering, Hong KongUniversity of Science and Technology, Hong Kong.His current research interests include data miningand artificial intelligence.Prof. Yang was elected a Vice-Chair of the Association for Computing Machinery (ACM) specialinterest group on artificial intelligence in July 2010. He is the founding Editorin-Chief of the ACM Transactions on Intelligent Systems and Technology. Hehas been a PC Co-Chair or General Co-Chair for a number of internationalconferences. He was an invited speaker at the International Joint Conferenceon Artificial Intelligence\u201909, ACL\u201909, ACML\u201909, and ADMA\u201908.\f", "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 34, NO. 3,MARCH 2012465Domain Transfer Multiple Kernel LearningLixin Duan, Ivor W. Tsang, and Dong Xu, Member, IEEEAbstract\u2014Cross-domain learning methods have shown promising results by leveraging labeled patterns from the auxiliary domain tolearn a robust classifier for the target domain which has only a limited number of labeled samples. To cope with the considerablechange between feature distributions of different domains, we propose a new cross-domain kernel learning framework into which manyexisting kernel methods can be readily incorporated. Our framework, referred to as Domain Transfer Multiple Kernel Learning(DTMKL), simultaneously learns a kernel function and a robust classifier by minimizing both the structural risk functional and thedistribution mismatch between the labeled and unlabeled samples from the auxiliary and target domains. Under the DTMKLframework, we also propose two novel methods by using SVM and prelearned classifiers, respectively. Comprehensive experimentson three domain adaptation data sets (i.e., TRECVID, 20 Newsgroups, and email spam data sets) demonstrate that DTMKL-basedmethods outperform existing cross-domain learning and multiple kernel learning methods.Index Terms\u2014Cross-domain learning, domain adaptation, transfer learning, support vector machine, multiple kernel learning.\u00c71INTRODUCTIONTHEconventional machine learning methods usuallyassume that the training and test data are drawn fromthe same data distribution. In many applications, it isexpensive and time consuming to collect labeled trainingsamples. Meanwhile, classifiers trained with only a limitednumber of labeled patterns are usually not robust for patternrecognition tasks. Recently, there has been increasingresearch interest in developing new transfer learning (orcross-domain learning/domain adaptation) methods whichcan learn robust classifiers with only a limited number oflabeled patterns from the target domain by leveraging a largeamount of labeled training data from other domains(referred to as auxiliary/source domains). In practice,cross-domain learning methods have been successfully usedin many real-world applications, such as sentiment classification [2], natural language processing [11], text categorization [9], [21], information extraction [9], WiFi localization[21], and visual concept classification [16], [17], [36].Recall that the feature distributions of training samplesfrom different domains change tremendously, and thetraining samples from multiple sources also have verydifferent statistical properties (such as mean, intraclass, andinterclass variance). Though a large number of training dataare available in the auxiliary domain, the classifiers trainedfrom those data or the combined data from both theauxiliary and target domains may perform poorly on thetest data from the target domain [16], [36].To take advantage of all labeled patterns from bothauxiliary and target domains, Daume\u0301 III [11] proposed a socalled Feature Replication (FR) method to augment features. The authors are with the School of Computer Engineering, NanyangTechnological University, Nanyang Avenue, Singapore 639798.E-mail: {S080003, IvorTsang, DongXu}@ntu.edu.sg.Manuscript received 26 Oct. 2009; revised 22 Oct. 2010; accepted 2 May2011; published online 26 May 2011.Recommended for acceptance by M. Meila.For information on obtaining reprints of this article, please send e-mail to:tpami@computer.org, and reference IEEECS Log NumberTPAMI-2009-10-0720.Digital Object Identifier no. 10.1109/TPAMI.2011.114.0162-8828/12/$31.00 \u00df 2012 IEEEfor cross-domain learning. The augmented features are thenused to construct a kernel function for Support VectorMachine (SVM) training. Yang et al. [36] proposed AdaptiveSVM (A-SVM) for visual concept classification, in which thenew SVM classifier f T \u00f0x\u00de is adapted from an existingclassifier f A \u00f0x\u00de (referred to as auxiliary classifier) trainedfrom the auxiliary domain. Cross-domain SVM (CD-SVM)proposed by Jiang et al. [16] used k-nearest neighbors fromthe target domain to define a weight for each auxiliarypattern, and then the SVM classifier was trained with thereweighted auxiliary patterns. More recently, Jiang et al.[17] proposed mining the relationship among differentvisual concepts for video concept detection. They first builta semantic graph and the graph can then be adapted in anonline fashion to fit the new knowledge mined from the testdata. However, all these methods [11], [16], [17], [31], [36]did not utilize unlabeled patterns from the target domain.Such unlabeled patterns can also be used to improve theclassification performance [3], [37].When there are only a few or even no labeled patternsavailable in the target domain, the auxiliary patterns or theunlabeled target patterns can be used to train the targetclassifier. Several cross-domain learning methods [15], [29]were proposed to cope with the inconsistency of datadistributions (such as covariate shift [29] or samplingselection bias [15]). These methods reweighted the trainingsamples from the auxiliary domain by using unlabeled datafrom the target domain such that the statistics of samplesfrom both domains are matched. Very recently, Bruzzoneand Marconcini [6] proposed Domain Adaptation SupportVector Machine (DASVM), which extended TransductiveSVM (T-SVM) to label unlabeled target patterns progressively and simultaneously remove some auxiliary labeledpatterns. Interested readers may refer to [22] for the morecomplete survey of cross-domain learning methods.The common observation is that most of these crossdomain learning methods are either variants of SVM or intandem with SVM or other kernel methods. The predictionperformances of these kernel methods heavily depend onthe choice of the kernel. To obtain the optimal kernel,Published by the IEEE Computer Society\f466IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,Lanckriet et al. [18] proposed to learn a nonparametrickernel matrix by solving an expensive semidefinite programming (SDP) problem. However, the time complexity isO\u00f0n6:5 \u00de, which is computationally prohibitive for many realworld applications. Instead of directly learning the kernelmatrix, many efficient Multiple Kernel Learning (MKL)methods [1], [18], [28], [24] have been proposed to learn thekernel function in which the kernel function is assumed tobe a linear combination of multiple predefined kernelfunctions (referred to as base kernel functions). And thesemethods simultaneously learn the decision function as wellas the kernel. In practice, MKL has been successfullyemployed in many computer vision applications, such asaction recognition [30], [32], object detection [33], and so on.However, these methods commonly assume that bothtraining data and test data are drawn from the samedomain. As a result, MKL methods cannot learn the optimalkernel with the combined data from the auxiliary and targetdomains for the cross-domain problem. Therefore, thetraining data from the auxiliary domain may degrade theperformance of MKL algorithms in the target domain.In this paper, we propose a unified cross-domain kernellearning framework, referred to as Domain Transfer Multiple Kernel Learning (DTMKL), for several challengingdomain adaptation tasks. The main contributions of thispaper include:....To deal with the considerable change between featuredistributions of different domains, DTMKL minimizes the structural risk functional and MaximumMean Discrepancy (MMD) [4], a criterion to evaluatethe distribution mismatch between the auxiliary andtarget domains. In practice, DTMKL provides aunified framework to simultaneously learn an optimal kernel function as well as a robust classifier.Many existing kernel methods, including SVM,Support Vector Regression (SVR), Kernel Regularized Least Squares (KRLS), and so on, can beincorporated into the framework of DTMKL totackle cross-domain learning problems. Moreover,we propose a reduced gradient descent procedure toefficiently and effectively learn the linear combination coefficients of multiple base kernels as well asthe target classifier.Under the DTMKL framework, we propose twomethods on the basis of SVM and prelearnedclassifiers, respectively. The first method,DTMKL_AT, directly utilizes the training data fromthe auxiliary and target domain. The second method,DTMKL_f, makes use of the labeled target trainingdata as well as the decision values from the existingbase classifiers on the unlabeled data from the targetdomain. And, these base classifiers can be prelearnedby using any method (e.g., SVM and SVR).To the best of our knowledge, DTMKL is the first semisupervised cross-domain kernel learning frameworkfor the single auxiliary domain problem which canincorporate many existing kernel methods. Incontrast to the traditional kernel learning methods,DTMKL does not assume that the training and testdata are drawn from the same domain.VOL. 34,NO. 3,MARCH 2012Comprehensive experiments on TRECVID, 20 Newsgroups, and email spam data sets demonstrate theeffectiveness of the DTMKL framework in realworld applications.The rest of the paper is organized as follows: We brieflyreview the related work in Section 2. We then introduce ourframework Domain Transfer Multiple Kernel Learning inSection 3. In particular, we present two methods DTMKL_ATand DTMKL_f to tackle the single auxiliary domain problemby using SVM and prelearned classifiers, respectively. Weexperimentally compare the two proposed methods withother SVM-based cross-domain learning methods on theTRECVID data set for video concept detection, as well as onthe 20 Newsgroups and email spam data sets for textclassification in Section 4. Finally, conclusive remarks arepresented in Section 5..2BRIEF REVIEW OF RELATED WORKLet us denote the data set of labeled and unlabeled patternslfrom the target domain as DTl \u00bc \u00f0xTi ; yTi \u00dejni\u00bc1and DTu \u00bcT nl \u00fenuTxi ji\u00bcnl \u00fe1 , respectively, where yi is the label of xTi . We alsodefine DT \u00bc DTl [ DTu as the data set from the target domainwith the size nT \u00bc nl \u00fe nu under the marginal data distribuA nAtion P, and DA \u00bc \u00f0xAi ; yi \u00deji\u00bc1 as the data set from the auxiliarydomain under the marginal data distribution Q. Let us alsorepresent the labeled training data set as D \u00bc \u00f0xi ; yi \u00dejni\u00bc1 ,where n is the total number of labeled patterns. The labeledtraining data can be from the target domain (i.e., D \u00bc DTl ) orfrom both domains (i.e., D \u00bc DTl [ DA ).In this work, the transpose of vector/matrix is denotedby the superscript 0 and the trace of a matrix A isrepresented as tr\u00f0A\u00de. Let us also define In as the n-by-nidentity matrix. 0n and 1n are n-by-1 vectors of all zeros andones, respectively. The inequality u \u00bc \u00bdu1 ; . . . ; un \u00020 \u0003 0nmeans that ui \u0003 0 for i \u00bc 1; . . . ; n. And the element-wiseproduct between vectors u and v is represented asu \u0004 v \u00bc \u00bdu1 v1 ; . . . ; un vn \u00020 . A\u0005 0 means that the matrix A issymmetric and positive definite (pd).In the following sections, we will briefly review twomajor paradigms of cross-domain learning. The first is todirectly learn the decision function for the target domain(also known as target classifier) based on the labeled datafrom the target domain or two domains by minimizing themismatch of data distribution between two domains. Thesecond is to make use of the existing auxiliary classifierstrained based on the auxiliary domain patterns for crossdomain learning.2.1 Reducing Mismatch of Data DistributionIn cross-domain learning, it is crucial to reduce the differencebetween the data distributions of the auxiliary and targetdomains. Many parametric criteria (e.g., Kullback-Leibler(KL) divergence) have been used to measure the distancebetween data distributions. However, an intermediatedensity estimate process is usually required. To avoid sucha nontrivial task, Borgwardt et al. [4] proposed an effectivenonparametric criterion, referred to as Maximum MeanDiscrepancy, to compare data distributions based on thedistance between the means of samples from two domains ina kernel k induced Reproducing Kernel Hilbert Space(RKHS) H, namely,\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNING\u0002DISTk \u00f0DA ; DT \u00de \u00bc sup ExA \u0007Q \u00bdf\u00f0xA \u00de\u0002 \b ExT \u0007P \u00bdf\u00f0xT \u00de\u0002467\u0003kfkH \u00061\u0004 \u0002\u0003\u0005\u00bc sup f; ExA \u0007Q \u00bd\u0002\u00f0xA \u00de\u0002 \b ExT \u0007P \u00bd\u0002\u00f0xT \u00de\u0002 HkfkH \u00061\u0006\u0006\u00bc \u0006ExA \u0007Q \u00bd\u0002\u00f0xA \u00de\u0002 \b ExT \u0007P \u00bd\u0002\u00f0xT \u00de\u0002\u0006H ;\u00f01\u00dewhere Ex\u0007U \u00bd \u0002 denotes the expectation operator under thedata distribution U and f\u00f0x\u00de is any function in H. Thesecond equality holds as f\u00f0x\u00de \u00bc hf; \u0002\u00f0x\u00deiH by the propertyof RKHS [25], where \u0002\u00f0 \u00de is the nonlinear feature mappingof the kernel k. Note that the inner product of \u0002\u00f0xi \u00de and\u0002\u00f0xj \u00de equals to the kernel function k (or k\u00f0 ; \u00de) on xi and xj ,namely, k\u00f0xi ; xj \u00de \u00bc \u0002\u00f0xi \u00de0 \u0002\u00f0xj \u00de. Asymptotically, the empirical measure of MMD in (1) can be well estimated by\u0006\u0006nAnT\u00061 X\u0006X\u0002\u0002\u0003\u00031\u0006\u0006DISTk \u00f0DA ; DT \u00de \u00bc \u0006\u0002 xA\u0002 xTi \u0006 : \u00f02\u00de\bi\u0006nA i\u00bc1\u0006nT i\u00bc1HTo capture higher order statistics of the data (e.g., higherorder moments of probability distribution), the samples in(2) are transformed into a higher dimensional or eveninfinite dimensional space through the nonlinear featuremapping \u0002\u00f0 \u00de. When DISTk \u00f0DA ; DT \u00de is close to zero, thehigher order moments of the data from the two domainsbecome matched, and so their data distributions are alsoclose to each other [4]. The MMD criterion was successfullyused to integrate biological data from multiple sources in [4].Due to the change of data distributions from differentdomains, training with samples only from the auxiliarydomain may degrade the classification performance in thetarget domain. To reduce the mismatch between twodifferent domains, Huang et al. [15] proposed a two-stepapproach called Kernel Mean Matching (KMM). The firststep is to diminish the mismatch between means of samplesin RKHS from the two domains by reweighting the samples\u0002\u00f0xi \u00de in the auxiliary domain as \u0003i \u0002\u00f0xi \u00de, where \u0003i is learnedby using the square of the MMD criterion in (2). Then, thesecond step is to learn a decision function f\u00f0x\u00de \u00bc w0 \u0002\u00f0x\u00de \u00fe bthat separates patterns from two opposite classes in D usingthe loss function reweighted by \u0003i .Recently, Pan et al. [21] proposed an unsupervisedkernel learning method, referred to as Maximum MeanDiscrepancy Embedding (MMDE), by minimizing thesquare of the MMD criterion in (2) as well, and thenapplied the learned kernel matrix to train an SVM classifierfor WiFi localization and text categorization.2.2 Learning from Existing Auxiliary ClassifiersInstead of learning the target classifier directly from thelabeled data in both auxiliary and target domains, someresearchers make use of the prelearned classifiers trainedfrom the auxiliary domain to learn the target classifier. Yanget al. [36] proposed Adaptive SVM, in which a new SVMclassifier f T \u00f0x\u00de is adapted from an existing auxiliary classifierf A \u00f0x\u00de trained with the patterns from the auxiliary domain.1Specifically, the new decision function is formulated as1. Yang et al. [36] also proposed a formulation to solve the multipleauxiliary domain problem. This paper mainly focuses on single auxiliarydomain setting. We therefore briefly introduce their work under thissetting.f T \u00f0x\u00de \u00bc f A \u00f0x\u00de \u00fe \u0002f\u00f0x\u00de, where the perturbation function\u0002f\u00f0x\u00de is learned by using the labeled data DTl from thetarget domain. As shown in [36], f A \u00f0x\u00de can be deemed as apattern-dependent bias, and then the perturbation function\u0002f\u00f0x\u00de can be easily learned.Besides A-SVM, Schweikert et al. [26] proposed to usethe linear combination of the decision values from theauxiliary SVM classifier and the target SVM classifier for theprediction in the target domain. It is noteworthy that boththis method and A-SVM do not utilize the abundant anduseful unlabeled data DTu in the target domain for crossdomain learning.3DOMAIN TRANSFER MULTIPLE KERNEL LEARNINGFRAMEWORKIn this section, we introduce our proposed unified crossdomain learning framework, referred to as Domain Transfer Multiple Kernel Learning. And we also present a unifiedlearning algorithm for DTMKL. Based on the proposedframework, we further propose two methods using SVMand the existing classifiers, respectively.3.1 Proposed FrameworkIn previous cross-domain learning methods [15], [21], theweights or the kernel matrix of samples are learnedseparately using the MMD criterion in (2) withoutconsidering any label information. However, it is usuallybeneficial to utilize label information during kernellearning. Instead of using the two-step approaches as in[15], [21], we propose a unified cross-domain learningframework, DTMKL, to learn the decision function for thetarget domain:f\u00f0x\u00de \u00bc w0 \u0002\u00f0x\u00de \u00fe b \u00bcnX\u0004i k\u00f0xi ; x\u00de \u00fe b;\u00f03\u00dei\u00bc1as well as the kernel function k simultaneously, where w isthe weight vector in the feature space and b is the bias term.Notice that \u0004i s are the coefficients of the kernel expansionfor the decision function f\u00f0x\u00de using Representer Theorem[25]. In practice, DTMKL minimizes the distance betweenthe data distributions of the auxiliary and target domains,as well as the structural risk functional of any kernelmethod. The learning framework of DTMKL is thenformulated as\u0002\u0003\u00bdk; f\u0002 \u00bc arg min \u0003 DIST2k \u00f0DA ; DT \u00de \u00fe \u0005R\u00f0k; f; D\u00de;\u00f04\u00dek;fwhere \u0003\u00f0 \u00de is any monotonic increasing function and \u0005 > 0is a tradeoff parameter to balance the mismatch betweendata distributions of two domains and the structural riskfunctional R\u00f0k; f; D\u00de defined on the labeled patterns.3.1.1 Minimizing Data Distribution MismatchThe first objective in DTMKL is to minimize the mismatchbetween data distributions of two domains using the MMDcriterion defined in (2). We define a column vector s withnA \u00fe nT entries, in which the first nA entries are set as 1=nAand the remaining entries are set as \b1=nT , respectively.ATTLet \u0004 \u00bc \u00bd\u0002\u00f0xA1 \u00de; . . . ; \u0002\u00f0xnA \u00de; \u0002\u00f0x1 \u00de; . . . ; \u0002\u00f0xnT \u00de\u0002 be the kernel\f468IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,P Amatrix after feature mapping, and then n1A ni\u00bc1\u0002\u00f0xAi \u00de\bPnT1T\u0002\u00f0x\u00dein(2)issimplifiedas\u0004s.Thus,thecriterioninii\u00bc1nT(2) can be rewritten asVOL. 34,NO. 3,MARCH 20123.1.4 Learning AlgorithmLet us defineJ\u00f0d\u00de \u00bc min R\u00f0d; f; D\u00de:DIST2k \u00f0DA ; DT \u00de \u00bc k\u0004sk2 \u00bc tr\u00f0\u00040 \u0004S\u00de \u00bc tr\u00f0KS\u00de;f\u00f06\u00deThen, the optimization problem (5) can be rewritten aswhere\"0S \u00bc ss 2 <\u00f0nA \u00fenT \u00de \u00f0nA \u00fenT \u00de2 <\u00f0nA \u00fenT \u00de\u00f0nA \u00fenT \u00de;0K\u00bc\u0004\u0004\u00bc;KA;A 2 <nAnA;KA;AKT ;AKA;TKT ;TKT ;T 2 <nT#min h\u00f0d\u00de \u00bc mind2DnT;and KA;T 2 <nA nT are the kernel matrices defined for theauxiliary domain, the target domain, and the cross domainfrom the auxiliary domain to the target domain, respectively.3.1.2 Minimizing Structural Risk FunctionalThe second objective in DTMKL is to minimize thestructural risk functional R\u00f0k; f; D\u00de defined on the labeledpatterns in D. Note that the structural risk functional ofmany existing kernel methods, including SVM, SVR,KRLS, and so on, can be used here. Without using thefirst term in (4), the resultant optimization problembecomes a standard kernel learning problem [18] to learnthe kernel k and the decision function f for thecorresponding kernel method.3.1.3 Multiple Base KernelsInstead of learning a nonparametric kernel matrix K in (4)for cross-domain learning as in [21], following [18], [24], [28]we assume the kernel k is a linear combination of a set ofbase kernels km s, namely,k\u00bcMXd2D1 0 0d pp d \u00fe \u0005 J\u00f0d\u00de:2\u00f07\u00deIt is worth mentioning that the traditional MKLmethods suffer from the nonsmooth problem on the linearkernel combination coefficient d, and thus the simplecoordinate descent algorithms such as SMO may not leadto the global solution [1]. As shown in the literature, theglobal optimum of MKL can be achieved by usingthe reduced gradient descent method [24] or semi-infinitelinear programming [28], [38]. Following [24], we developan efficient and effective reduced gradient descent procedure to iteratively update different variables (e.g., d and f)in (5) to obtain the optimal solution. The algorithm isdetailed as follows:Updating the decision function f. With the fixed d, onlythe structural risk functional R\u00f0d; f; D\u00de in (5) depends on f.We can solve the decision function f by minimizingR\u00f0d; f; D\u00de.Updating kernel coefficients d. When the decisionfunction f is fixed, (7) can be updated using the reducedgradient descent method as suggested in [24]. Specifically,the gradient of h in (7) isrh \u00bc pp0 d \u00fe \u0005rJ;where rJ is the gradient of J in (6). Furthermore, theHessian matrix can be derived asdm km ;m\u00bc1PMwhere dm \u0003 0,m\u00bc1 dm \u00bc 1. We further assume the firstobjective \u0003\u00f0tr\u00f0KS\u00de\u00de in (4) is1\u0003\u00f0tr\u00f0KS\u00de\u00de \u00bc \u00f0tr\u00f0KS\u00de\u00de22!!2MX11tr\u00bcdm Km S\u00bc d0 pp0 d;22m\u00bc1wherep \u00bc \u00bdp1 ; . . . ; pM \u00020 ; pm \u00bc tr\u00f0Km S\u00de; Km \u00bc \u00bdkm \u00f0xi ; xj \u00de\u00022 <\u00f0nA \u00fenT \u00de\u00f0nA \u00fenT \u00de;and d \u00bc \u00bdd1 ; . . . ; dM \u00020 . Moreover, from (3), we have f\u00f0x\u00de \u00bcPMPn0m\u00bc1 dm wm \u0002m \u00f0x\u00de \u00fe b, where wm \u00bci\u00bc1 \u0004i \u0002m \u00f0xi \u00de.Thus, the optimization problem in (4) can be rewritten asmin mind2Df1 0 0d pp d \u00fe \u0005 R\u00f0d; f; D\u00de;2\u00f05\u00dewhere D \u00bc fdjd \u0003 0; d0 1M \u00bc 1g is the feasible set of d and fis the target decision function. Note that we have onlyM variables in d, which is much smaller than the totalnumber of variables \u00f0nA \u00fe nT \u00de2 in K. Thus, the resultantoptimization problem is much simpler than that of thenonparametric kernel matrix learning in MMDE [21].r2 h \u00bc pp0 \u00fe \u0005r2 J:Note that pp0 \u00fe \u0005r2 J may not be full rank. Thus, to avoidnumerical instability, we replace pp0 by pp0 \u00fe \"I to makesure r2 h \u00bc pp0 \u00fe \"I \u00fe \u0005r2 J \u0005 0, where \" is set to 10\b2 inthe experiments. Compared with first-order gradient-basedmethods, second-order derivative-based methods usuallyconverge faster. So, we use g \u00bc \u00f0r2 h\u00de\b1 rh as the updatingdirection. To maintain d 2 D, the updating direction g isreduced as in [24], so the updated weight of multiple basekernels isdt\u00fe1 \u00bc dt \b \u0006t gt 2 D;\u00f08\u00dewhere dt and gt are the linear combination coefficient vector dand the reduced updating direction g at the tth iteration,respectively, and \u0006t is the learning rate. The overallprocedure of the proposed DTMKL is summarized inAlgorithm 1.Algorithm 1. DTMKL Algorithm.1: Initialize d \u00bc M1 1M .2: For t \u00bc 1; . . . ; Tmax3:Solve the target classifer f in the objective functionin (6).\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNING4694:Update the linear combination coefficient vector dof multiple base kernels using (8).5: End.As mentioned before, one can employ any structural riskfunctional of kernel methods in the learning framework ofDTMKL. In the preliminary conference version of this paper2[13], we proposed to use the hinge loss in SVM. Then, thestructural risk functional becomes SVM, which is the firstformulation in this paper. Moreover, inspired by theutilization of auxiliary classifiers for cross-domain learning,we also propose another formulation which considers thedecision values from the base classifiers on the unlabeledpatterns in the target domain.3.2 DTMKL Using Hinge LossSVM is used to model the second objective R\u00f0d; f; D\u00de in (5),that is,min mind2Df1 0 0d pp d \u00fe \u0005 SVMprimal \u00f0d; f; D\u00de;2\u00f09\u00dewhich employs the hinge loss,P i.e., \u2018\u0005h \u00f0t\u00de \u00bc2max\u00f00; 1 \b t\u00de.Here, we use the regularizer 12 Mm\u00bc1 dm kwm k for multiplekernel learning introduced in [38]. Then, the corresponding constrained optimization problem in (9) can berewritten as!MnX1 0 01X2min min d pp d \u00fe \u0005dm kwm k \u00fe C\u0007i ; \u00f010\u00ded2D wm ;b;\u0007i 22 m\u00bc1i\u00bc1s:t: yiMX!dm w0m \u0002m \u00f0xi \u00de\u00feb\u0003 1 \b \u0007i ; \u0007i \u0003 0;\u00f011\u00dem\u00bc1where C > 0 is the regularization parameter and \u0007i s are theslack variables for the corresponding constraints. However,(10) in general is nonconvex due to the product of dm andwm in the inequality constraints of (10). Following [38], weintroduce a transformation vm \u00bc dm wm , and (10) can bethen rewritten as!MnX1 0 01Xkvm k2min min d pp d \u00fe \u0005\u00feC\u0007i ;\u00f012\u00ded2D vm ;b;\u0007i 22 m\u00bc1 dmi\u00bc1|\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04{z\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04\ufb04}J\u00f0d\u00des:t: yiMX!v0m \u0002m \u00f0xi \u00de\u00feb\u0003 1 \b \u0007i ; \u0007i \u0003 0:\u00f013\u00dem\u00bc1In the following theorem, we prove that the optimizationproblem (12) is convex.Theorem 1. The optimization problem (12) is jointly convex withrespect to d, vm , b, and \u0007i .Proof. The first term 12 d0 pp0 d in the objective function (12) isa convex quadratic term. Other terms in the objectivefunctionconstraints are linear except the termPM kvmandk21in(12). As shown in [24], this term is alsom\u00bc1 dm2jointly convex with respect to d and vm . Therefore, the2. The corresponding cross-domain learning method is referred to asDomain Transfer SVM (DTSVM) in [13].optimization problem in (12) is jointly convex withutrespect to d, vm , b, and \u0007i .Therefore, (12) can converge to the global minimumusing the reduced gradient descent procedure described inAlgorithm 1. Note that when one of the linear combinationcoefficients (say, dm ) is zero, the corresponding vm at theoptimality must be zero as well [24]. In other cases (i.e.,the corresponding vm is nonzero), the correspondingdescent direction is nonzero, and so dm will be updatedagain by using the reduced descent direction in thesubsequent iteration until the objective function in (12)cannot be decreased.Recall that the constrained optimization problem of SVMis usually solved by its dual problem, which is in the formof a quadratic programming (QP) problem:1\u0004 \u0004 y\u00de0 K\u00f0\u0004max 10n \u0004 \b \u00f0\u0004\u0004 \u0004 y\u00de:\u0004 2A2Similarly, one can show that J\u00f0d\u00de in (12) can be writtenas follows [38]:!MX100\u0004 \u0004 y\u00de\u0004 \u0004 y\u00de;\u00f014\u00dedm Km \u00f0\u0004J\u00f0d\u00de \u00bc max 1n \u0004 \b \u00f0\u0004\u0004 2A2m\u00bc1where J\u00f0d\u00de is linear in d 2 D, A \u00bc f\u0004\u0004j\u0004\u00040 y \u00bc 0; 0n \u0006 \u0004 \u0006C1n g is the feasible set of the dual variables \u0004, y \u00bc\u00bdy1 ; . . . ; yn \u00020 is the label vector, and Km \u00bc \u00bdkm \u00f0xi ; xj \u00de\u0002 \u00bc\u00bd\u0002m \u00f0xi \u00de0 \u0002m \u00f0xj \u00de\u0002 2 <n n is the mth base kernel matrix of thelabeled patterns.With the optimal d and the dual variables \u0004, the predictionof any test data x using the target decision function can beobtained:f T \u00f0x\u00de \u00bcMXdm w0m \u0002m \u00f0x\u00de \u00fe bm\u00bc1\u00bcXi: \u0004i 6\u00bc0\u0004i yiMXdm km \u00f0xi ; x\u00de \u00fe b:m\u00bc1In this method, the labeled samples from the Auxiliarydomain and the Target domain can be directly used toimprove the classification performance of the classifier inthe target domain. In this case, we term this method asDTMKL_AT. It is worth mentioning that the unlabeledtarget data DTu can be used for the calculation of the MMDvalues in (2), which does not require label information.3.3 DTMKL Using Existing Base ClassifiersIn this section, we extend our proposed DTMKL bydefining the structural risk functional of SVR on bothlabeled and unlabeled data in the target domain. There areno input labels for the unlabeled target patterns. Inspired bythe use of base classifiers, we introduce a regularizationterm (i.e., the last term in (15)) to enforce that the decisionvalues from the target classifier and the existing baseclassifiers are similar on the unlabeled target patterns.Moreover, we further introduce another penalty term (i.e.,the fourth term in (15)) for the labeled target patterns toensure that the decision values from the target classifier areclose to the true labels. Note that the labeled training datacan be from the target domain (i.e., D \u00bc DTl ) or from both\f470IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 34,NO. 3,MARCH 2012domains (i.e., D \u00bc DTl [ DA ). Let us denote f T ;m and f B;m asthe target classifier and the base classifier with the mth basekernel, respectively. For simplicity, we define fiT ;m andfiB;m as the decision values on any data xi , respectively.Similarlyto (10), we also assume that the regularizer isPM21dkwmm k . Then, we present another formulation ofm\u00bc12DTMKL as follows:(n\u00fenMXu1 0 01Xd pp d \u00fe \u0005dm kwm k2 \u00fe C\u00f0\u0007i \u00fe \u0007i \u00demind2D;wm ;b;\u0007i ; 22 m\u00bc1i\u00bc1T ;m T ;m\u0007 ;ffi l;ff u\u00fes:t:MX\b2M \u0006M \u0006XX\u0006\u0006\u0006f T ;m \b y\u00062 \u00fe\u0006f T ;m \b f B;m \u00062uulm\u00bc1;m\u00bc1dm w0m \u0002m \u00f0xi \u00de \u00fe b \bm\u00bc1MX!)MXdm fiT ;m \u0006 \u00fe \u0007i ; \u0007i \u0003 0;m\u00bc1dm fiT ;m \bm\u00bc1MXdm w0m \u0002m \u00f0xi \u00de \b b \u0006 \u00fe \u0007i ; \u0007i \u0003 0;m\u00bc1Fig. 1. Illustration of virtual labels. The base classifier f B;m is learnedwith the base kernel function km and the labeled training data from D,where m \u00bc 1; . . . ; M. For each of the unlabeled target pattern x fromDTu , we can obtain its decision value f B;m \u00f0x\u00de from each base classifier.Then, the virtual label y~ of x is defined as the linear combination of itsdecisionvalues f B;m \u00f0x\u00des weighted by the coefficients dm s, i.e.,PB;m\u00f0x\u00de.y~ \u00bc Mm\u00bc1 dm f1^ \u0004\b\u0004 \u00de\u0004 \b \u0004 \u00de0 K\u00f0\u0004max \b \u00f0\u00042\u00f0\u0004\u0004;\u0004\u0004 \u00de2A\u00f015\u00dewhere > 0 is the balance parameter, C; \b > 0 are theregularization parameters, y \u00bc \u00bdy1 ; . . . ; yn \u00020 is the labelvector of the labeled training data from D, \u0007i s and \u0007i s areslack variables for -insensitive loss, f Tl ;m \u00bc \u00bdf1T ;m ; . . . ; fnT ;m \u00020is the decision value vector of the labeled training data DT ;mT ;m 0from the target classifier, and f Tu ;m \u00bc \u00bdfn\u00fe1; . . . ; fn\u00fen\u0002 anduB;mB;m 0B;mf u \u00bc \u00bdfn\u00fe1 ; . . . ; fn\u00fenu \u0002 are the decision value vectors of theunlabeled target data DTu from the target classifier f T ;m andthe base classifier f B;m , respectively. While the objectivefunction in (15) is not jointly convex with respect to thevariables dm and wm , our iterative approach listed inAlgorithm 1 can still reach the local minimum.We denote the objective inside fg of (15) as J\u00f0d\u00de. Thedual of J\u00f0d\u00de (see the supplemental material for the detailedderivation, which can be found in the Computer SocietyDigital Library at https://doi.ieeecomputersociety.org/10.1109/TPAMI.2011.114) can be derived by introducingthe Lagrangian multipliers \u0004 and \u0004 :J\u00f0d\u00de \u00bc max\u00f0\u0004\u0004;\u0004\u0004 \u00de2A1~ \u0004\b\u0004 \u00de\b \u00f0\u0004\u0004 \b \u0004 \u00de0 K\u00f0\u00042\u00f016\u00dewhere~ \u00bcKMX~m \u00bcdm Km\u00bc1MXdm Km \u00fem\u00bc1~\u00bcyMXm\u00bc1M1X\b m\u00bc12M6X~m \u00bc 4dm yd2my\bIn1Inu;\u00f017\u00de375;dm f B;muSurprisingly, (16) is very similar to (19) except for some^ and yminor changes, that is, the kernel matrices K^ are~ and y~ , respectively. Therefore, (16) canreplaced by Kbe efficiently solved by using the state-of-the-art SVM~ is similar tosolver (e.g., LIBSVM [7]). The kernel matrix KAutomatic Relevance Determination (ARD) kernel used inGaussian Process, and the second term in (17) is to controlthe noise of output. Interestingly, each of the last nu entriesof y~Pin (18) can be considered as a so-called virtual labelB;my~ \u00bc M\u00f0x\u00de composed by the linear combination ofm\u00bc1 dm fthe decision values from the base classifiers f B;m s on theunlabeled target pattern x (see Fig. 1 for illustration).With the optimal d and the dual variables \u0004 and \u0004 , thetarget decision function can be found asf\u00f0x\u00de \u00bcMXdm w0m \u0002m \u00f0x\u00de \u00fe bm\u00bc1\u00bcXi: \u0004i \b\u0004i 6\u00bc0~ 0 \u00f0\u0004\u0004 \b \u0004 \u00de \b 10n\u00fenu \u00f0\u0004\u0004 \u00fe \u0004 \u00de;\by\u00f018\u00dem\u00bc1\u00040 1n\u00fenu \u00bc \u0004 0 1n\u00fenu ; 0n\u00fenu \u0006 \u0004; \u0004 \u0006 C1n\u00fenu g isA \u00bc f\u00f0\u0004\u0004; \u0004 \u00dej\u0004the feasible set of the dual variables \u0004 and \u0004 , and Km \u00bc\u00bdkm \u00f0xi ; xj \u00de\u0002 2 <\u00f0n\u00fenu \u00de \u00f0n\u00fenu \u00de is the kernel matrix of both thelabeled patterns from D and unlabeled patterns from DTu .Recall that the dual form of the standard -SVR is asfollows:\u00f019\u00de^ 0 \u00f0\u0004\u0004 \b \u0004 \u00de \b 10n\u00fenu \u00f0\u0004\u0004 \u00fe \u0004 \u00de:\by\u00f0\u0004i \b \u0004i \u00deMXdm km \u00f0xi ; x\u00de \u00fe b:m\u00bc1Because of the use of the existing base classificationfunctions, we then refer to this method as DTMKL_f.3.4 Computational Complexity of DTMKLRecall that DTMKL adopts the reduced gradient descentscheme as in [24] to iteratively update the coefficients ofbase kernels and learn the target classifier. For DTMKL_AT,the overall optimization procedure is dominated by a seriesof the kernel classifier training.3 For example, at eachiteration of DTMKL_AT, the cost is essentially the same asthe SVM training. Empirically, the SVM training complexityis O\u00f0n2:3 \u00de [23]. And so the training cost for our proposedDTMKL_AT is O\u00f0Tmax n2:3 \u00de, where Tmax is the number ofiterations in DTMKL. As shown in Section 4.5, ourDTMKL_AT generally converges after less than five3. Here, we suppose multiple base kernels can be precomputed andloaded into memory before the DTMKL training.PThen, the computationalcost for the calculation of the learned kernel K \u00bc Mm\u00bc1 dm Km , which takesO\u00f0Mn2 \u00de time can be ignored.\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNINGiterations. For DTMKL_f, we use multiple base classifiers.For example, the base classifiers SVM_AT can be prelearnedand adapted from the existing classifier SVM_A at verylittle computational cost by using warm start strategy orusing A-SVM. Thus, the cost of the calculation of the virtuallabels for DTMKL_f is not significant. Recall that DTMKL_fincorporates both labeled and unlabeled patterns in thetraining stage. Therefore, the training complexity ofDTMKL_f is O\u00f0Tmax \u00f0n \u00fe nu \u00de2:3 \u00de.The testing complexity of DTMKL_AT and DTMKL_fdepends on the number of support vectors learned from thetraining stage. And we show in Table 3 that our methodsDTMKL_AT and DTMKL_f take less than 1 minute to finishthe whole prediction process for about 21,213 test samplesfrom each of 36 concepts on the TRECVID data set, whichare as fast as the MKL algorithm.3.5 Discussions with Related WorkOur work is different from prior cross-domain learningmethods such as [6], [11], [15], [16], [31], [36]. Thesemethods use standard kernel functions for SVM training,in which the kernel parameters are usually determinedthrough cross validation. Recall that the kernel functionplays a crucial role in SVM. When the labeled data from thetarget domain are limited, the cross-validation approachmay not choose the optimal kernel, which significantlydegrades the generalization performance of SVM. Moreover, most existing cross-domain learning algorithms [11],[16], [31], [36] do not explicitly consider any specificcriterion to measure the distribution mismatch of samplesbetween different domains. As demonstrated in theprevious work [12], [19], [26], [36], the auxiliary classifiers(i.e., the base classifiers trained with the data from one ormultiple auxiliary domains) can be used to learn a robusttarget classifier. Again, there is no specific criterion used tominimize the distribution mismatch between the auxiliaryand target domains in these methods. In addition, the workin [12] focuses on the setting with multiple auxiliary domainsand the Domain Adaptation Machine (DAM) algorithm wasspecifically proposed for multiple auxiliary domain adaptation problem. The algorithm Cross-Domain RegularizedRegression (CDRR) and its incremental version IncrementalCDRR (ICDRR) in [19] were specifically designed for largescale image retrieval applications. In order to achieve realtime retrieval performance on the large image data set withabout 270,000 images, a linear regression function is used asthe target function in [19]. Also, in the previous work [12],[19], [26], [36], only one kernel is used in the target decisionfunction. In contrast to these methods [11], [12], [16], [19],[26], [31], [36], DTMKL is a unified cross-domain kernellearning framework in which the optimal kernel is learnedby explicitly minimizing the distribution mismatch betweenthe auxiliary and target domains by using both labeled andunlabeled patterns. Most importantly, many kernel learningmethods (e.g., SVM, SVR, KRLS, etc.) can be readilyembedded into our DTMKL framework to solve crossdomain learning problems.The work most closely related to DTMKL was proposed byPan et al. [21] in which a two-step approach is used for crossdomain learning. The first step is to learn a kernel matrix ofsamples using the MMD criterion, and the second step is toapply the learned kernel matrix to train an SVM classifier.DTMKL is different from [21] in the following aspects:471A kernel matrix is learned in an unsupervisedsetting in [21] without using any label information,which is not as effective as our semi-supervisedlearning method DTMKL.2. In contrast to the two-step approach in [21], DTMKLsimultaneously learns a kernel function and SVMclassifier.3. The learned kernel matrix in [21] is nonparametric;thus, it cannot be applied to unseen data. Instead,DTMKL can handle any new test data.4. The optimization problem in [21] is in the form ofexpensive semidefinite programming [5], the timecomplexity of which is O\u00f0n6:5 \u00de.As a result, it can only handle several hundred patterns.Therefore, it cannot be applied to medium or large-scaleapplications such as video concept detection. Anotherrelated work is Adaptive Multiple Kernel Learning(A-MKL) [14] in which the target classifier is constrainedas the linear combination of a set of prelearned classifiersand the perturbation function learned by multiple kernellearning. A-MKL can be considered as an extension ofDTMKL_AT. In A-MKL, the unlabeled target patterns areonly used to measure the distribution mismatch between thetwo domains in the Maximum Mean Discrepancy criterion,which is similar as in DTMKL_AT and DTMKL_f. Incontrast, in DTMKL_f, the decision values from theprelearned base classifiers on the unlabeled target patternsare used as virtual labels in a new regularizer (i.e., the lastterm in (15)) in order to enforce that the decision values fromthe target classifier and the existing base classifiers aresimilar on the unlabeled target patterns. Moreover, A-MKLclassifier can also be used as one base classifier in DTMKL_f.Multiple Kernel Learning methods [18], [24], [28] alsosimultaneously learn the decision function and the kernel inan inductive setting. However, the default assumption ofMKL is that the training data and the test data are drawnfrom the same domain. When the training data and the testdata come from different distributions, MKL methodscannot learn the optimal kernel with the combined trainingdata from the auxiliary and target domains. Therefore, thetraining data from the auxiliary domain may degrade theclassification performances of MKL algorithms in the targetdomain. In contrast, DTMKL can utilize the patterns fromboth domains for better classification performances.1.4EXPERIMENTSIn this section, we evaluate our methods DTMKL_AT andDTMKL_f for two cross-domain learning related applications: 1) video concept detection on the challengingTRECVID video corpus and 2) text classification on the20 Newsgroups data set and the email spam data set.4.1Descriptions of Data Sets and Features4.1.1 TRECVID Data SetThe TRECVID video corpus4 is one of the largest annotatedvideo benchmark data sets for research purposes. TheTRECVID 2005 data set contains 61,901 keyframes extractedfrom 108 hours of video programs from six broadcastchannels (in English, Arabic, and Chinese), and theTRECVID 2007 data set contains 21,532 keyframes extracted4. https://www-nlpir.nist.gov/projects/trecvid.\f472IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 34,NO. 3,MARCH 2012TABLE 1Description of the 20 Newsgroups Data Setfrom 60 hours of news magazine, science news, documentaries, and educational programming videos. As shown in[16], TRECVID data sets are challenging for cross-domainlearning methods due to the large difference betweenTRECVID 2007 data set and TRECVID 2005 data set in termsof program structure and production values. Thirty-sixsemantic concepts are chosen from the LSCOM-lite lexicon[20], a preliminary version of LSCOM, which covers36 dominant visual concepts present in broadcast newsvideos, including objects, scenes, locations, people, events,and programs. The 36 concepts have been manuallyannotated to describe the visual content of the keyframes inboth TRECVID 2005 and 2007 data sets.In this work, we focus on the single auxiliary domainand single target domain setting. To evaluate the performances of all the methods, we choose one Chinese channel,CCTV4, from TRECVID 2005 data set as the auxiliarydomain, and use the TRECVID 2007 data set as the targetdomain. The auxiliary data set DA consists of all the labeledsamples from the auxiliary domain (i.e., 10,896 keyframes inCCTV4 channel). We randomly select 10 positive samplesper concept from the TRECVID 2007 data set as the labeledtarget training data set DTl . Considering that it is computationally prohibitive to compare all the methods overmultiple random training and testing splits, we reportresults from one split. In order to facilitate other researchersto repeat the results, we have made the selected 355 positivesamples5 publicly available at https://www.ntu.edu.sg/home/dongxu/sampled_keyframes.txt. And, for each ofthe 36 concepts, we have 21,213 test samples on average.Three low-level global features Grid Color Moment(225 dim.), Gabor Texture (48 dim.), and Edge DirectionHistogram (73 dim.) are extracted to represent the diversecontent of keyframes because of their consistent goodperformances reported in TRECVID [16], [36]. Moreover,the three types of global features can be efficiently extractedand the previous work [16], [36] also shows that the crossdomain issue exists when using these global features.Yanagawa et al. have made the three types of featuresextracted from the keyframes of TRECVID data setspublicly available (see [35] for more details). We furtherconcatenate the three types of features to form a346-dimensional feature vector for each keyframe.4.1.2 20 Newsgroups Data SetThe 20 Newsgroups data set6 is a collection of 18,774 newsdocuments. This data set is organized in a hierarchical5. A large portion of keyframes in TRECVID 2007 data set have multiplelabels. We therefore only have 355 unique labeled target training samples.For each concept, we make sure that there are only 10 positive samples fromthe target domain when training one-versus-all classifiers. It is worth notingthat for some concepts (e.g., \u201cPerson\u201d), we have fewer than 345 negativesamples for model learning after excluding some training samples that areselected from other non-\u201cPerson\u201d concepts but also positively labeled as\u201cPerson.\u201d6. https://people.csail.mit.edu/jrennie/20Newsgroups.structure which consists of six main categories and20 subcategories. Some of the subcategories (from the samecategory) are related to each other while others (fromdifferent categories) are not related, making this data setsuitable to evaluate cross-domain learning algorithms.In the experiments, the four largest main categories (i.e.,\u201ccomp,\u201d \u201crec,\u201d \u201csci,\u201d and \u201ctalk\u201d) are chosen for evaluation.Specifically, for each main category, the largest subcategoryis selected as the target domain, while the second largestsubcategory is chosen as the auxiliary domain. Moreover,we consider the largest category \u201ccomp\u201d as the positiveclass and one of the three other categories as the negativeclass for each setting. Table 1 provides the detailedinformation of all three settings. To construct the trainingdata set, we use all labeled samples from the auxiliarydomain, as well as randomly choose m positive andm negative samples from the target domain. And theremaining samples in the target domain are considered asthe test data which are also used as the unlabeled data fortraining. In the experiments, m is set as 0, 1, 3, 5, 7, and 10.For any given m, we randomly sample the training datafrom the target domain five times and report the means andthe standard deviations of all methods. Moreover, theword-frequency feature is used to represent each document.4.1.3 Email Spam Data SetThere are three email subsets (denoted by User1, User2, andUser3, respectively) annotated by three different users inthe email spam data set.7 The task is to classify spam andnonspam emails. Since the spam and nonspam emails in thesubsets have been differentiated by different users, the datadistributions of the three subsets are related but different.Each subset has 2,500 emails, in which one half of the emailsare nonspam (labeled as 1) and the other half of them arespam (labeled as -1).On this data set, we consider three settings: 1) User1(auxiliary domain) and User2 (target domain); 2) User2(auxiliary domain) and User3 (target domain); and 3) User3(auxiliary domain) and User1 (target domain). For eachsetting, the training data set contains all labeled samplesfrom the auxiliary domain as well as the labeled samplesfrom the target domain in which five positive and fivenegative samples are randomly chosen. And the remainingsamples in the target domain are used as the unlabeledtraining data and the test data as well. We randomly samplethe training data from the target domain for five times andreport the means and the standard deviations of allmethods. Again, the word-frequency feature is used torepresent each document.7. https://www.ecmlpkdd2006.org/challenge.html.\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNING4.2 Experimental SetupWe systematically compare our proposed methodsDTMKL_AT and DTMKL_f with the baseline SVM andother cross-domain learning algorithms including FeatureReplication [11], Adaptive SVM [36], Cross-Domain SVM[16], and Kernel Mean Matching [15]. We also report theresults of the Multiple Kernel Learning algorithm in whichthe optimal kernel combination coefficients are learned byonly minimizing the second part of DTMKL_AT in (10)corresponding to the structural risk functional of SVM.Note that we do not compare with [21] because their workcannot cope with thousands of training and test samples.For all methods, we train one-versus-all classifiers. Notethat the standard SVM can use the labeled training data set DTlfrom the target domain, the labeled training data set DA fromthe auxiliary domain, or the combined training data set DA [DTl from both auxiliary and target domains. We then refer toSVM in the above three cases as SVM_T, SVM_A, andSVM_AT, respectively. We also report the results of MKL_ATby employing the combined training data from two domains.The cross-domain learning methods FR, A-SVM, CD-SVM,and KMM also make use of the combined training data setDA [ DTl for model learning.MKL_AT and our DTMKL-based methods can make useof multiple base kernels. For fair comparison, we use thesame kernels for other methods, including SVM_T, SVM_A,SVM_AT, FR, A-SVM, CD-SVM, and KMM. Specifically, foreach method we train multiple classifiers using the samekernels and then equally fuse the decision values to obtainthe final prediction results.Note that we make use of the unlabeled target trainingdata from DTu in KMM and our DTMKL-based methods. ForKMM and DTMKL_AT, the labeled and unlabeled trainingdata are employed to measure the data distributionmismatch between two domains using the MMD criterionin (2). We additionally make use of the virtual labels forDTMKL_f, which are the linear combination of the decisionvalues from multiple base classifiers on the unlabeledtraining data from DTu . In this work, we employ SVM_ATfrom multiple base kernels as the base classifiers inDTMKL_f.With our experimental setting, cross validation is notsuitable to automatically tune the optimal parameters forthe target classifier because we only have a limited numberof labeled samples or even no labeled samples from thetarget domain. For the two text data sets, we varythe regularization parameter C for all methods and reportthe best result of each method with the optimal C, whereC 2 f0:1; 0:2; 0:5; 1; 2; 5; 10; 20; 50g. We fix the regularizationparameter C as the default value 1 in LIBSVM for the largeTRECVID data set, because it is time consuming to run theexperiments multiple times using different C.4.2.1 Details on the TRECVID Data SetFour thousand unlabeled samples from the target domainare randomly selected as the unlabeled training data setDTu for model learning in KMM and our DTMKL methods.Moreover, for DTMKL_f, only the labeled and unlabeledsamples DTl [ DTu from the target domain are used as thetraining data. For KMM, the parameter B is empirically473set as 0.99. And for our methods, the parameter \u0005 inDTMKL_AT and DTMKL_f and the parameters ; \b inDTMKL_f need to be determined beforehand. We empirically set \b \u00bc 0:1 and \u0005 \u00bc 10\b5 . Recall that the parameterin DTMKL_f is used to balance the costs from labeled dataand unlabeled data. Considering that the total number ofunlabeled target samples is roughly 10 times more thanthat of the labeled target samples, we fix \u00bc 0:1 in ourexperiments.Base kernels are predetermined for all methods. Specifically, we use four types of kernels: Gaussian kernel(i.e., k\u00f0xi ; xj \u00de \u00bc exp\u00f0\b kxi \b xj k2 \u00de), Laplacian kernel (i.e.,p\ufb03\ufb03\ufb03k\u00f0xi ; xj \u00de \u00bc exp\u00f0\b kxi \b xj k\u00de), inverse square distancekernel (i.e., k\u00f0xi ; xj \u00de \u00bc kx \bx1 k2 \u00fe1 ), and inverse distanceij1), where the kernel parakernel (i.e., k\u00f0xi ; xj \u00de \u00bc p\ufb03\ufb03kxi \bxj k\u00fe1meter is set as the default value 1d \u00bc 0:0029 (d \u00bc 346 is thefeature dimension) in LIBSVM. And for each type of kernels,we use 13 kernel parameters 1:2 \u00fe3 , 2 f\b3; \b2:5; . . . ;2:5; 3g. In total, we have 52 base kernels for all methods.Note that our framework can readily incorporate othermethods such as FR. Therefore, we introduce anotherapproach (referred to as DTMKL ATFR ) by replacingSVM with FR in DTMKL_AT, in which we employ thekernel proposed in the FR method [11] to form the basekernels for DTMKL ATFR .For performance evaluation, we use noninterpolatedAverage Precision (AP) [8], [27], [34], which has been usedas the official performance metric in TRECVID since 2001.AP is related to the multipoint average precision value of aprecision-recall curve and incorporates the effect of recallwhen AP is computed over the entire classification results.4.2.2 Details on the 20 Newsgroups and Email SpamData SetsOn two text data sets, all the test data in the target domain arealso considered as the unlabeled data in the training stage.And for our proposed method DTMKL_f, the unlabeled datafrom the target domain as well as the labeled data from boththe auxiliary and target domains are used to construct thetraining data set, i.e., DA [ DTl [ DTu . For DTMKL_f, we set\u00bc 1 in the experiments because the total number ofunlabeled target samples is roughly the same with that ofthe labeled training samples from both domains.We consider two types of base kernels: linear kernel (i.e.,k\u00f0xi ; xj \u00de \u00bc x0i xj ) and polynomial kernel (i.e., k\u00f0xi ; xj \u00de \u00bc\u00f0x0i xj \u00fe 1\u00dea ), where a \u00bc 1:5; 1:6; . . . ; 2:0. Then, we have, intotal, seven base kernels for all methods. Classificationaccuracy is adopted as the performance evaluation metricfor text classification.4.3 Results of Video Concept DetectionWe compare our DTMKL methods with other algorithmson the challenging TRECVID data set for the video conceptdetection task. For each concept, we count the frequency(referred to as positive frequency) of positive samples in theauxiliary domain. According to the positive frequency, wepartition all 36 concepts into three groups (i.e., Group_High, Group_Med, and Group_Low), with 12 concepts foreach group. The concepts in Group_High, Group_Med, andGroup_Low are with high, moderate, and low positive\f474IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 34,NO. 3,MARCH 2012TABLE 2Mean Average Precisions (Percent) of All Methods on the TRECVID Data SetMAPs are from concepts of three individual groups and all 36 concepts.frequencies, respectively. And the average results of allmethods are presented in Table 2, where Mean AveragePrecisions (MAPs) of the concepts in three groups and all36 concepts are referred to as MAP_High, MAP_Med,MAP_Low, and MAP_ALL, respectively. Fig. 2 plots theper-concept APs of all 36 concepts using different methods.From Table 2 and Fig 2, we have the following observations:1.SVM_A is much worse than SVM_T according to theMAPs over all 36 concepts, which demonstrates thatthe SVM classifier learned with the training datafrom the auxiliary domain performs poorly on thetarget domain. The explanation is that the datadistributions of TRECVID data sets collected indifferent years are quite different. It is interestingto observe that SVM_AT outperforms SVM_T andSVM_A in terms of MAP_High, but SVM_T is betterthan SVM_AT and SVM_A in terms of MAP_Low.The explanation is that the concepts in Group_Highgenerally have a large number of positive patterns inboth auxiliary and target domains. Intuitively, whensufficient positive samples exist in both domains, thesamples distribute densely in the feature space. Inthis case, the distributions of samples from twodomains may overlap between each other [16], andthus, the data from the auxiliary domain may behelpful for video concept detection in the targetdomain. On the other hand, for the concepts inGroup_Low, the positive samples from both domains distribute sparsely in the feature space. It ismore likely that there is less overlap between thedata distributions of two domains. Therefore, for theconcepts in Group_Low, the data from the auxiliaryFig. 2. Per-concept APs of all 36 concepts using different methods. The concepts are divided into three groups according to the positive frequency.Our methods achieve the best performances for the circled concepts.\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNING475TABLE 3Average Training and Testing Time (in Seconds) Comparisons of All Methods on the TRECVID Data SetFor A-SVM and DTMKL_f, the two numbers represent the average training time for the learning of the prelearned classifiers and the learning of thetarget classifier.2.3.4.domain may degrade the performance for videoconcept detection in the target domain.MKL_AT is worse than SVM_AT. The assumptionin MKL is the training data and the test data comefrom the same domain. When the data distributionsof different domains change considerably in crossdomain learning, the optimal kernel combinationcoefficients may not be effectively learned by usingMKL methods based on the combined data setfrom two domains.FR and A-SVM outperform SVM_AT in terms ofMAPs from all the three groups, which demonstrates that the information from the auxiliarydomain can be effectively used in FR and A-SVMto improve the classification performance in thetarget domain. We also observe that KMM and CDSVM are slightly worse than SVM_AT in terms ofMAP_ALL. A possible explanation is that in CDSVM, k-nearest neighbors from the target domainare used to define the weights for the auxiliarypatterns. When the total number of positive trainingsamples in the target domain is very limited (e.g., 10positive samples per concept in this work), thelearned weights for the auxiliary patterns are notreliable, which may degrade the performance of CDSVM. Similarly, KMM learns the weights for theauxiliary samples in an unsupervised setting without using any label information, which may not beas effective as other cross-domain learning methods(e.g., FR and A-SVM).DTMKL_AT is better than SVM_AT and MKL_AT interms of MAPs over all 36 concepts. Moreover,DTMKL ATFR and DTMKL_f outperform all othermethods in terms of MAPs from all three groups.These results clearly demonstrate that the DTMKLmethods can successfully minimize the data distribution mismatch between two domains and the structural risk functional through effective combination ofmultiple base kernels. DTMKL_f is better thanDTMKL ATFR in terms of MAP_ALL because ofthe additional utilization of the base classifiers.DTMKL ATFR or DTMKL_f achieves the best resultsin 21 out of 36 concepts. In addition, some conceptsenjoy large performance gains. For instance, the APfor the concept \u201cWaterscape_Waterfront\u201d significantly increases from 20.0 (A-SVM) to 24.5 percent(DTMKL_f), equivalent to a 22.5 percent relativeimprovement; and the AP for the concept \u201cCar\u201d isimproved from 11.9 (CD-SVM) to 14.3 percent(DTMKL_f), equivalent to a 20.2 percent relativeimprovement. Compared with the best results fromthe existing methods, DTMKL_f (15.1 percent) enjoysa relative improvement 15.3 percent over FR andA-SVM (13.1 percent) in terms of MAP_Med,DTMKL_f (16.4 percent) enjoys a relative improvement 6.5 percent over FR (15.4 percent) in terms ofMAP_Low. Moreover, compared with FR (24.7 percent), A-SVM (24.6 percent), KMM (23.7 percent), CDSVM (23.6 percent), MKL_AT (22.7 percent),SVM_AT (23.8 percent), and SVM_T (22.3 percent),the relative MAP improvements of DTMKL_f(26.0 percent) over all 36 concepts are 5.3, 5.7, 9.7,10.2, 14.5, 9.2, and 16.6 percent, respectively.5. We also observe that DTMKL ATFR is slightly betterthan DTMKL_f in terms of MAP_High, possiblybecause the distributions of samples from twodomains overlap between each other in this case. Wetherefore propose a simple predicting method byusing DTMKL ATFR for the concepts in Group_Highand DTMKL_f for the rest concepts in Group_Medand Group_Low. The MAP of the predicting methodover all 36 concepts is 26.1 percent, with the relativeimprovements over FR, A-SVM, KMM, CD-SVM,MKL_AT, SVM_AT, and SVM_T as 5.7, 6.1, 10.1, 10.6,15.0, 9.7, and 17.0 percent, respectively.We additionally report the average training (TR) andtesting (TE) time of all the methods for each concept inTable 3. All the experiments are performed on an IBMworkstation (2.66 GHz CPU with 32 Gbyte RAM) withLIBSVM [7]. From Table 3, we observe that SVM_T is quitefast because it only utilizes the labeled training data fromthe target domain. We also observe that some MKL-basedmethods (i.e., MKL_AT, DTMKL_AT, and DTMKL ATFR )are much faster than the late-fusion-based methods exceptSVM_T in the training phase. For A-SVM and DTMKL_f, themost time-consuming part in the training phase is from thelearning of the prelearned classifiers, while it is very fast tolearn the target classifier. Moreover, all the MKL-basedmethods are also much faster than the late-fusion-basedmethods except SVM_T in the testing phase. On average,our DTMKL methods take less than 1 minute to finish thewhole prediction phase for about 21,213 test samples fromeach concept, which is still acceptable in the real-worldapplications.4.4 Results of Text ClassificationFor the text classification task, we focus the comparisonsbetween DTMKL_f and other related methods using twotext data sets. For each setting, we report the results of allmethods obtained by using the training data from theauxiliary domain as well as m positive and m negativetraining samples randomly selected from the target domain,where we set m \u00bc 0; 1; 3; 5; 7, and 10 for the 20 Newsgroupsdata set and m \u00bc 5 for the email spam data set. Werandomly sample the training data from the target domain\f476IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 34,NO. 3,MARCH 2012TABLE 4Means and Standard Deviations (Percent) of Classification Accuraciesof All Methods with Different Number of Positive and Negative Training Samples (i.e., m)from the Target Domain on the 20 Newsgroups Data SetEach result in the table is the best among all the results obtained by using different regularization parameters C 2 f0:1; 0:2; 0:5; 1; 2; 5; 10; 20; 50g. Theresults shown in boldface are significantly better than the others, judged by the t-test with a significance level of 0.1.for five times. In Tables 4 and 5, we report the means andstandard deviations of classification accuracies (ACC) for allmethods on the 20 Newsgroups and email spam data sets,respectively. It is worth noting that when there are notraining samples from the target domain, DTMKL_f canemploy the base SVM classifiers learned from the auxiliarydata only. But other methods, like SVM_T, SVM_AT,MKL_AT, FR, A-SVM, CD-SVM, and A-MKL [14], cannotwork in this case. Also note that for all methods, each resultin Tables 4 and 5 is the best among all the results obtainedby using different regularization parameters C 2 f0:1;0:2; 0:5; 1; 2; 5; 10; 20; 50g. From Tables 4 and 5, we have thefollowing observations:1.2.On both data sets, MKL_AT is comparable withSVM_AT, which shows that the auxiliary domain isrelevant to the target domain. The performances ofSVM_T and SVM_AT become better on the 20 Newsgroups data set, when the number of labeled positiveand negative training samples (i.e., m) increases. AndSVM_AT outperforms SVM_T and SVM_A on bothdata sets, which demonstrates that it is beneficial toutilize the data from the auxiliary domain to improvethe performance in the target domain.Some cross-domain learning methods (i.e., CD-SVMand KMM) generally achieve similar performanceswhen compared with SVM_AT. The explanation isthat the data distributions of two domains are quiteTABLE 5Means and Standard Deviations (Percent) of Classification Accuracies of All Methodswith Five Positive and Five Negative Training Samples from the Target Domain on the EMail Spam Data SetEach result in the table is the best among all the results obtained by using different regularization parameters C 2 f0:1; 0:2; 0:5; 1; 2; 5; 10; 20; 50g. Theresults shown in boldface are significantly better than the others, judged by the t-test with a significance level of 0.1.\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNING477Fig. 3. Performance comparisons of DTMKL_f with other methods in terms of the means and standard deviations of classification accuracies on the20 Newsgroups data set by using different regularization parameters C 2 f0:1; 0:2; 0:5; 1; 2; 5; 10; 20; 50g. We set m \u00bc 5 (top) and m \u00bc 10 (bottom).Fig. 4. Performance (i.e., the means of classification accuracies) variation of DTMKL_f with respect to the balance parameter20 Newsgroups data set. We set the regularization parameter C \u00bc 2 and C \u00bc 5.2 \u00bd0:1; 10\u0002 on theFig. 5. Illustration of the convergence of DTMKL_AT.related, making it difficult for the existing crossdomain learning methods to further improve theperformances in the target domain. We also observethat A-SVM is worse than SVM_AT in most settingson the two text data sets. It seems that the limitednumber of labeled training samples from the targetdomain are not sufficient to facilitate robust adaptation for A-SVM. And it is interesting to observe thatFR is generally worse than SVM_AT on the emailspam data set in terms of the means of classificationaccuracies. A possible explanation is that the kernelof FR, which is constructed based on the augmented3.features, is less effective on this data set. Moreover,in most cases, A-MKL [14] outperforms othermethods except DTMKL_f in terms of the means ofclassification accuracies.Our proposed method DTMKL_f is consistentlybetter than all other methods in terms of the meansof classification accuracies on both data sets, thanks tothe explicit modeling of the data distribution mismatch as well as the successful utilization of theunlabeled data and the base classifiers. As shown inTable 4, when the number of labeled positive andnegative training samples (i.e., m) from the target\f478IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 34,NO. 3,MARCH 2012domain increases, DTMKL_f becomes better on the20 Newsgroups data set. Moreover, judged by thet-test with a significance level of 0.1, DTMKL_f issignificantly better than other methods in all settings.We also compare our proposed method DTMKL_f withthe competitive methods, including MKL_AT, A-SVM, CDSVM, and KMM, by using different regularization parameters C 2 f0:1; 0:2; 0:5; 1; 2; 5; 10; 20; 50g. The results of allmethods are obtained by using m positive and m negativetraining samples from the target domain as well as thetraining data from the auxiliary domain, in which we setm \u00bc 5 and 10 for the 20 Newsgroups data set in Fig. 3. Fromthe figure, we observe that when C becomes larger, allmethods tend to have better performances. In addition, ourmethod DTMKL_f consistently outperforms other methodsin terms of the means of classification accuracies. Moreover,DTMKL_f is also relatively stable according to the standarddeviations of classification accuracies. We have similarobservations on this data set when using different m andalso on the email spam data set.Recall that the parameterin DTMKL_f balances thecosts from the labeled and unlabeled samples (see (15)).In Fig. 4, we take the 20 Newsgroups data set as anexample to investigate the performance variation ofDTMKL_f with respect to the parameter , in which weset m \u00bc 5 and the regularization parameter C \u00bc 2 and 5.Note the total number of labeled samples from twodomains and the number of unlabeled samples from thetarget domain are almost the same on the 20 Newsgroupsdata set. From Fig. 4, we have the following observations:1) The performance of DTMKL_f changes with differentin a large range (i.e., 2 \u00bd0:1; 10\u0002); 2) whenis quitesmall or quite large (i.e., the cost from labeled data orunlabeled data is more important), the performances ofDTMKL_f generally degrade a bit; and 3) when we set2 \u00bd0:5; 1:5\u0002, DTMKL_f achieves the best results and isnot sensitive to the parameter as well. In this case, boththe labeled data and the unlabeled data from the targetdomain can be effectively utilized to learn a robustclassifier. We have similar observations on this data setwhen using different C and m, and on the email spamdata set as well.linear combination of multiple base kernels, we alsodevelop a unified learning algorithm by using the secondorder derivatives to accelerate the convergence of theproposed framework. Most importantly, many existingkernel methods, including SVM, SVR, KRLS, and so on,can be readily incorporated into the framework of DTMKLto tackle cross-domain learning problems.Based on the DTMKL framework, we propose twomethods DTMKL_AT and DTMKL_f by using SVM andexisting classifiers, respectively. For DTMKL_f, manymachine learning methods (e.g., SVM and SVR) can beused to learn the base classifiers. Specifically, in DTMKL_f,we enforce that 1) for the unlabeled target data, the targetclassifier produces similar decision values with thoseobtained from the base classifiers; and 2) for the labeledtarget data, the decision values obtained from the targetclassifier are close to the true labels. Experimental resultsshow that DTMKL_f outperforms existing cross-domainlearning and multiple kernel learning methods on thechallenging TRECVID data set for video concept detectionas well as on the 20 Newsgroups and email spam data setsfor text classification.In this work, we randomly select a number of unlabeledtarget patterns as the training data for DTMKL_f. Considering that it is beneficial to establish the optimal balancebetween the labeled and unlabeled patterns [10], we willinvestigate how to determine such optimal balance in thefuture. Moreover, we will also study how to automaticallydetermine the optimal parameters for DTMKL_AT andDTMKL_f.4.5 ConvergenceIn Theorem 1, we theoretically prove that DTMKL_AT isjointly convex with respect to d, vm , b, and \u0007i . Here, we taketwo concepts \u201cPerson\u201d and \u201cAirplane\u201d from the TRECVIDdata set as examples to experimentally demonstrate theconvergence of DTMKL_AT. As shown in Fig. 5, the objectivevalues of DTMKL_AT converge after less than five iterations.We have similar observations for other concepts as well.[2]ACKNOWLEDGMENTSThis material is based upon work funded by SingaporeA*STAR SERC Grant (082 101 0018) and MOE AcRF Tier-1Grant (RG15/08).REFERENCES[1][3][4][5]5CONCLUSIONS AND FUTURE WORKIn this work, we have proposed a unified cross-domainlearning framework Domain Transfer Multiple KernelLearning to explore the single auxiliary domain and singletarget domain problem. DTMKL simultaneously learns akernel function and a target classifier by minimizing thestructural risk functional as well as the distributionmismatch between the samples from the auxiliary andtarget domains. By assuming that the kernel function is a[6][7][8]F.R. Bach, G.R.G. lanckriet, and M. Jordan, \u201cMultiple KernelLearning, Conic Duality, and the SMO Algorithm,\u201d Proc. Int\u2019l Conf.Machine Learning, 2004.J. Blitzer, M. Dredze, and F. Pereira, \u201cBiographies, Bollywood,Boom-Boxes and Blenders: Domain Adaptation for SentimentClassification,\u201d Proc. Ann. Meeting Assoc. for ComputationalLinguistics, pp. 440-447, 2007.A. Blum and T. Mitchell, \u201cCombining Labeled and UnlabeledData with Co-Training,\u201d Proc. Ann. Conf. Learning Theory, pp. 92100, 1998.K.M. Borgwardt, A. Gretton, M.J. Rasch, H.-P. Kriegel, B.Scho\u0308lkopf, and A.J. Smola, \u201cIntegrating Structured BiologicalData by Kernel Maximum Mean Discrepancy,\u201d Bioinformatics,vol. 22, no. 4, pp. 49-57, 2006.S. Boyd and L. Vandenberghe, Convex Optimization. CambridgeUniv. Press, 2004.L. Bruzzone and M. Marconcini, \u201cDomain Adaptation Problems:A DASVM Classification Technique and a Circular ValidationStrategy,\u201d IEEE Trans. Pattern Analysis and Machine Intelligence,vol. 32, no. 5, pp. 770-787, May 2010.C.-C. Chang and C.-J. Lin, \u201cLIBSVM: A Library for Support VectorMachines,\u201d https://www.csie.ntu.edu.tw/~cjlin/libsvm, 2001.S.-F. Chang, J. He, Y.-G. Jiang, E.E. Khoury, C.-W. Ngo, A.Yanagawa, and E. Zavesky, \u201cColumbia University/VIREOCityU/IRIT TRECVID2008 High-Level Feature Extraction andInteractive Video Search,\u201d Proc. TREC Video Retrieval EvaluationWorkshop, 2008.\fDUAN ET AL.: DOMAIN TRANSFER MULTIPLE KERNEL LEARNING[9][10][11][12][13][14][15][16][17][18][19][20][21][22][23][24][25][26][27][28][29][30][31][32]B. Chen, W. Lam, I.W. Tsang, and T.L. Wong, \u201cExtractingDiscriminative Concepts for Domain Adaptation in Text Mining,\u201dProc. ACM SIGKDD Int\u2019l Conf. Knowledge Discovery and DataMining, pp. 179-188, 2009.A. Corduneanu and T. Jaakkola, \u201cContinuation Methods forMixing Heterogeneous Sources,\u201d Proc. Ann. Conf. Uncertainty inArtificial Intelligence, pp. 111-118, 2002.H. Daume\u0301 III, \u201cFrustratingly Easy Domain Adaptation,\u201d Proc.Ann. Meeting Assoc. for Computational Linguistics, pp. 256-263, 2007.L. Duan, I.W. Tsang, D. Xu, and T.-S. Chua, \u201cDomain Adaptationfrom Multiple Sources via Auxiliary Classifiers,\u201d Proc. Int\u2019l Conf.Machine Learning, pp. 289-296, 2009.L. Duan, I.W. Tsang, D. Xu, and S.J. Maybank, \u201cDomain TransferSVM for Video Concept Detection,\u201d Proc. IEEE Int\u2019l Conf. ComputerVision and Pattern Recognition, pp. 1375-1381, 2009.L. Duan, D. Xu, I.W. Tsang, and J. Luo, \u201cVisual Event Recognitionin Videos by Learning from Web Data,\u201d Proc. IEEE Int\u2019l Conf.Computer Vision and Pattern Recognition, pp. 1959-1966, 2010.J. Huang, A.J. Smola, A. Gretton, K.M. Borgwardt, and B.Scho\u0308lkopf, \u201cCorrecting Sample Selection Bias by Unlabeled Data,\u201dProc. Advances in Neural Information Processing Systems 19, pp. 601608, 2007.W. Jiang, E. Zavesky, S.-F. Chang, and A. Loui, \u201cCross-DomainLearning Methods for High-Level Visual Concept Classification,\u201dProc. IEEE Int\u2019l Conf. Image Processing, pp. 161-164, 2008.Y.-G. Jiang, J. Wang, S.-F. Chang, and C.-W. Ngo, \u201cDomainAdaptive Semantic Diffusion for Large Scale Context-Based VideoAnnotation,\u201d Proc. IEEE Int\u2019l Conf. Computer Vision, pp. 1420-1427,2009.G. Lanckriet, N. Cristianini, P. Bartlett, L.E. Ghaoui, and M.I.Jordan, \u201cLearning the Kernel Matrix with Semidefinite Programming,\u201d J. Machine Learning Research, vol. 5, pp. 27-72, 2004.Y. Liu, D. Xu, I.W. Tsang, and J. Luo, \u201cTextual Query of PersonalPhotos Facilitated by Large-Scale Web Data,\u201d IEEE Trans. PatternAnalysis and Machine Intelligence, vol. 33, no. 5, pp. 1022-1036, May2011.M. Naphade, J.R. Smith, J. Tesic, S.-F. Chang, W. Hsu, L. Kennedy,A. Hauptmann, and J. Curtis, \u201cLarge-Scale Concept Ontology forMultimedia,\u201d IEEE Multimedia, vol. 13, no. 3, pp. 86-91, July-Sept.2006.S.J. Pan, J.T. Kwok, and Q. Yang, \u201cTransfer Learning viaDimensionality Reduction,\u201d Proc. Assoc. for the Advancement ofArtificial Intelligence, pp. 677-682, 2008.S.J. Pan and Q. Yang, \u201cA Survey on Transfer Learning,\u201d IEEETrans. Knowledge and Data Eng., vol. 22, no. 10, pp. 1345-1359, Oct.2010.J.C. Platt, \u201cFast Training of Support Vector Machines UsingSequential Minimal Optimization,\u201d Advances in Kernel Methods:Support Vector Learning, pp. 185-208, MIT Press, 1999.A. Rakotomamonjy, F.R. Bach, S. Canu, and Y. Grandvalet,\u201cSimpleMKL,\u201d J. Machine Learning Research, vol. 9, pp. 2491-2521,2008.B. Scho\u0308lkopf and A. Smola, Learning with Kernels. MIT Press, 2002.G. Schweikert, C. Widmer, B. Scho\u0308lkopf, and G. Ra\u0308tsch, \u201cAnEmpirical Analysis of Domain Adaptation Algorithms forGenomic Sequence Analysis,\u201d Proc. Advances in Neural InformationProcessing Systems, pp. 1433-1440, 2008.A.F. Smeaton, P. Over, and W. Kraaij, \u201cEvaluation Campaigns andTRECVid,\u201d Proc. ACM Int\u2019l Workshop Multimedia InformationRetrieval, 2006.S. Sonnenburg, G. Ra\u0308tsch, C. Scha\u0308fer, and B. Scho\u0308lkopf, \u201cLargeScale Multiple Kernel Learning,\u201d J. Machine Learning Research,vol. 7, pp. 1531-1565, 2006.A.J. Storkey and M. Sugiyama, \u201cMixture Regression for CovariateShift,\u201d Proc. Advances in Neural Information Processing Systems 19,pp. 1337-1344, 2007.J. Sun, X. Wu, S. Yan, L.-F. Cheong, T.-S. Chua, and J. Li,\u201cHierarchical Spatio-Temporal Context Modeling for ActionRecognition,\u201d Proc. IEEE Int\u2019l Conf. Computer Vision and PatternRecognition, pp. 2004-2011, 2009.P. Wu and T.G. Dietterich, \u201cImproving SVM Accuracy by Trainingon Auxiliary Data Sources,\u201d Proc. Int\u2019l Conf. Machine Learning,pp. 871-878, 2004.X. Wu, D. Xu, L. Duan, and J. Luo, \u201cAction Recognition UsingContext and Appearance Distribution Features,\u201d Proc. IEEE Int\u2019lConf. Computer Vision and Pattern Recognition, 2011.479[33] A. Vedaldi, V. Gulshan, M. Varma, and A. Zisserman, \u201cMultipleKernels for Object Detection,\u201d Proc. IEEE Int\u2019l Conf. ComputerVision, pp. 606-613, 2009.[34] D. Xu and S.-F. Chang, \u201cVideo Event Recognition Using KernelMethods with Multilevel Temporal Alignment,\u201d IEEE Trans.Pattern Analysis and Machine Intelligence, vol. 30, no. 11, pp. 19851997, Nov. 2008.[35] A. Yanagawa, W. Hsu, and S.-F. Chang, \u201cColumbia University\u2019sBaseline Detectors for 374 LSCOM Semantic Visual Concepts,\u201dColumbia Univ. ADVENT technical report, 2007.[36] J. Yang, R. Yan, and A.G. Hauptmann, \u201cCross-Domain VideoConcept Detection Using Adaptive SVMs,\u201d Proc. ACM Int\u2019l Conf.Multimedia, pp. 188-197, 2007.[37] X. Zhu, \u201cSemi-Supervised Learning Literature Survey,\u201d technicalreport, Univ. of Wisconsin-Madison, 2008.[38] A. Zien and C.S. Ong, \u201cMulticlass Multiple Kernel Learning,\u201dProc. Int\u2019l Conf. Machine Learning, pp. 1191-1198, 2007.Lixin Duan received the BE degree from theUniversity of Science and Technology of Chinain 2008. He is currently working toward the PhDdegree in the School of Computer Engineeringat Nanyang Technological University. He wasawarded the Microsoft Research Asia Fellowship in 2009 and his work won the Best StudentPaper Award at CVPR 2010.Ivor W. Tsang received the PhD degree incomputer science from the Hong Kong University of Science and Technology in 2007. He iscurrently an assistant professor with the Schoolof Computer Engineering, Nanyang Technological University (NTU), Singapore. He is also thedeputy director of the Center for ComputationalIntelligence, NTU. He received the prestigiousIEEE Transactions on Neural Networks Outstanding 2004 Paper Award in 2006, and thesecond class prize of the National Natural Science Award 2008, China,in 2009. His research also earned him the Best Paper Award atICTA \u201911, the Best student Paper Award at CVPR \u201910, and the BestPaper Award from the IEEE Hong Kong Chapter of Signal ProcessingPostgraduate Forum in 2006. The Microsoft Fellowship was conferredupon him in 2005.Dong Xu received the BE and PhD degreesfrom the University of Science and Technologyof China in 2001 and 2005, respectively. Whileworking toward the PhD degree, he was withMicrosoft Research Asia, Beijing, China, and theChinese University of Hong Kong, Shatin, formore than two years. He was a postdoctoralresearch scientist with Columbia University,New York, for one year. He is currently anassistant professor with Nanyang TechnologicalUniversity, Singapore. His current research interests include computervision, statistical learning, and multimedia content analysis. He was thecoauthor of a paper that won the Best Student Paper Award at theprestigious IEEE International Conference on Computer Vision andPattern Recognition in 2010. He is a member of the IEEE.. For more information on this or any other computing topic,please visit our Digital Library at www.computer.org/publications/dlib.\f", "Transfer Learning Based Visual Trackingwith Gaussian Processes RegressionJin Gao1,2 , Haibin Ling2 , Weiming Hu1 , and Junliang Xing112National Laboratory of Pattern Recognition, Institute of Automation, CAS, Beijing, China{jin.gao,wmhu,jlxing}@nlpr.ia.ac.cnDepartment of Computer and Information Sciences, Temple University, Philadelphia, USAhbling@temple.eduAbstract. Modeling the target appearance is critical in many modern visual tracking algorithms. Many tracking-by-detection algorithms formulate the probabilityof target appearance as exponentially related to the confidence of a classifier output. By contrast, in this paper we directly analyze this probability using GaussianProcesses Regression (GPR), and introduce a latent variable to assist the tracking decision. Our observation model for regression is learnt in a semi-supervisedfashion by using both labeled samples from previous frames and the unlabeledsamples that are tracking candidates extracted from the current frame. We furtherdivide the labeled samples into two categories: auxiliary samples collected fromthe very early frames and target samples from most recent frames. The auxiliarysamples are dynamically re-weighted by the regression, and the final tracking result is determined by fusing decisions from two individual trackers, one derivedfrom the auxiliary samples and the other from the target samples. All these ingredients together enable our tracker, denoted as TGPR, to alleviate the drifting issuefrom various aspects. The effectiveness of TGPR is clearly demonstrated by itsexcellent performances on three recently proposed public benchmarks, involving161 sequences in total, in comparison with state-of-the-arts.1 IntroductionVisual tracking is a fundamental problem in computer vision with a wide range of applications such as augmented reality, event detection and human-computer interaction,to name a few. Due to the challenges in tracking arbitrary objects, especially the drasticobject appearance changes caused by lighting conditions, object pose variations, andocclusion, a tracking system needs to adaptively update the observation model on-thefly. A well-known danger of this updating over time, however, is the tendency to \u201cdrift\u201d.There are several popular strategies in previous studies toward alleviating drift (\u00a72).First, background information should be take into consideration to develop a discriminative tracker, as followed by many tracking-by-detection methods. Second, unlabeledsamples from the current frame provide rich information in a semi-supervised manor,and can be used for enhancing the tracking inference. Third, re-weighting the trainingsamples appropriately may help reduce the impact of the noisy and potential samplemisalignment during model updating. Fourth, training samples should be adaptively toavoid the loss of sample diversity. Fifth, using the auxiliary data to assist the current online tracking task (e.g., using a transfer learning strategy) is preferable, because it canD. Fleet et al. (Eds.): ECCV 2014, Part III, LNCS 8691, pp. 188\u2013203, 2014.c Springer International Publishing Switzerland 2014\u0002\fTransfer Learning Based Visual Tracking with GPR189[\\WCurrent frame\u0003XSGDWHG\u0003VORZO\\XSGDWHG\u0003DJJUHVVLYHO\\Target SamplesAuxiliary Samples++--UpdateUnlabeled Samples(candidates)UpdateTrackingresultTransfer Learning Extension of GPRPrior ofGPRRe-weightingKnowledgeTrackingDecisionFusionFig. 1. Overview of the proposed TGPR tracking algorithmreduce the drift resulting from the direct Maximum a Posterior (MAP) estimation overthe noisy observation. Sixth, some part-based local representation methods are robustto the partial occlusion and small non-rigid deformation. Although these strategies havebeen exploited before, integrating all of them together remains challenging.In this paper, we attack the challenge by proposing a new transfer learning basedvisual tracker using Gaussian Processes Regression (GPR). The new tracker, denotedas TGPR, naturally addresses the drifting issue from six aforementioned aspects.First, we explicitly model the probability of target appearances in a GPR framework,and then a latent variable is naturally introduced to locate the best tracking candidates.In this process, the background information consists of the negative samples for regression. Also, the unlabeled samples (tracking candidates) are exploited when the prior ofGPR is defined, so that the observation model is inferred in a semi-supervised fashion.Second, we divide the training samples into two categories and treat them differently: the auxiliary samples (collected from the very early frames) are updated slowlyand carefully; the target samples (from most recent frames) are updated quickly and aggressively. Such strategy allows us to re-weight the auxiliary samples, which is closelyrelated to the current tracking status. The re-weighting helps to reduce the impact of thenoisy and potential sample misalignment when the auxiliary samples are locate the besttracking candidates.Third, the re-weighting of the auxiliary samples can be viewed as the knowledge thatcan be effectively exploited in a transfer learning framework. In particular, we adopt thetask-transfer strategy [38], where the tracking decision using the re-weighted auxiliarysamples assists the decision using target samples by fusing these two decisions. Theircollaboration circumvents the direct Maximum a Posterior (MAP) estimation over themost likely noisy observation model, and allows the use of a new strategy similar to theMinimum Uncertainty Gap (MUG) estimation [19]. In addition, we define the prior ofGPR by a local patch representation method to achieve robustness against occlusion.Figure 1 overviews the proposed approach. For fairly evaluating the proposed trackerand reducing subjective bias as suggested by [28], we test TGPR on three recentlyproposed online tracking benchmarks: the CVPR2013 Visual Tracker Benchmark [35],\f190J. Gao et al.the Princeton Tracking Benchmark [30], and the VOT2013 Challenge Benchmark [16].On all three benchmarks, involving in total 161 sequences, TGPR has achieved verypromising results and outperforms previously tested state-of-the-arts.2 Related WorkModel-Free Tracking. Single target visual tracking has long been attracting largeamounts of research efforts [39]. It is impractical to enumerate all previous work, instead we sample some recent interests related to our work: i) linear representation witha dictionary, e.g., a set of basis vectors based on subspace learning [29,12] or leastsoft-threshold squares linear regression [32], a series of raw pixel templates based onsparse coding [25,24,44,43,36] or non-sparse linear representation [22]; ii) collaboration of multiple tracking models, e.g., Interacting Markov Chain Monto Carlo (MCMC)based [17,18,19], local/global combination based [45]; iii) part-based models, e.g., fragments voting based [1,9,5], incorporating spatial constraints between the parts [42,37],alignment-pooling across the local patches [14]; iv) and the widely followed trackingby-detection (or discriminative) methods [6,7,20,2,8,21,31,45], which treat the trackingproblem as a classification task. All these trackers adaptively update tracking models toaccommodate the appearance changes and new information during tracking.Alleviate Drifts. Much progress has been made in alleviating drifts. Previous strategiesmainly consist of following aspects. i) Some studies [14,36,23] observe that straightforward and frequent update of new observations may cause gradual drifting due toaccumulated errors and loss of sample diversity. So some strategies, e.g., slow update of old templates and quick update of new ones by assigning different updateprobability to them [14], multi-lifespan setting [36,23], are adopted. ii) Some studies [7,41,45,19] notice that appearance models are often updated with noisy and potentially misaligned samples, which often leads to drifting. So their solutions incorporatethe data-independent knowledge, e.g., a fixed prior classifier trained by the labeled samples from the first frame [7], a measurement matrix for compressive sensing [41], a fixeddictionary for histogram generation [45], or utilize the MUG estimation instead of theMAP estimation [19]. iii) Some work [9,14], based on the part-based model, focuseson selectively updating the parts of the object to handle the tracking drift caused byheavy occlusion; other work [26,3,45] use occlusion detection strategy to determinewhether the template should be updated with the new observation. iv) Many trackingby-detection methods and some others [43,22] reduce the drifting effects by incorporating background samples.Re-weight the Training Samples. Re-weighting tracking samples has been widely usedin the sparse coding based tracking methods (e.g., [44,43]), however the importance ofre-weighting the training samples is hardly observed in the tracking-by-detection methods with a few exceptions such as [22,8,31]. In [22] larger weights are assigned tothe recently added samples while smaller weights to old ones using a time-weightedreservoir sampling strategy. Their re-weighting method is prone to drifting when the recently added samples are noisy or misaligned with the current tracking. In [8] the focus\fTransfer Learning Based Visual Tracking with GPRAuxiliaryy SamplesAUnlabeled Samples(candidates)Target SamplesT191Sample SetPrior of GPRObservation Model InferenceRe-weighting KnowledgeTarget DecisionAuxiliary DecisionUpdateFusionTracking resultFig. 2. The relationship among the components of the proposed TGPR trackeris on re-weighting the support vectors by taking into account the current learner and abounding box overlap based loss function. In [31] \u201cgood\u201d frames are selected to learna new model while revisiting past frames to correct mistakes made by previous models,which means that past frames are re-weighted to learn a new model. By contrast, ourGPR-based solution re-weights all auxiliary samples by considering distances betweenall pairs of samples. Thus, distribution of unlabeled samples collected from the currentframe strongly influences the modelling process.Transfer Learning Based Tracking. Transfer learning has recently been applied tovisual tracking (e.g., [20,34,33]). In [20], the \u201cCovariate Shift\u201d extension of the semisupervised on-line boosting tracker [7] is proposed. Different than in our work, theauxiliary samples\u2019 re-weighting in [20] is based on the online boosting classifier. Themethods in [34,33] transfer the prior knowledge from offline training on the real-worldnatural images to the current online target tracking task. By contrast, in our algorithmthe prior knowledge is based on the online regression on the auxiliary samples.3 The Proposed Tracking ApproachIn this section, we first analyze the probability of the observation model in the Bayesiantracking framework and re-formulate it as a new objective. Then, we use GPR to solvethis new formulation. Fig. 2 depicts the whole process.3.1 New Objective of the Observation ModelVisual tracking can be cast as a sequential Bayesian inference problem [13]. Given aset of observed image patches It up to the t-th frame, we aim to estimate the value ofthe state variable \u0002t , which describes the target location at time t. The true posteriorstate distribution Pr (\u0002t |It ) is commonly approximated by a set of nU samples, calledtracking candidates, {\u0002it , i = 1, 2, . . . , nU }, and \u0002t is estimated by MAP:\u0003\u0002(1)\u0002\u02c6t = arg max Pr \u0002it |It ,\u0002it\f192J. Gao et al.where \u0002it indicates the state of the i-th candidate of the state \u0002t on the t-th frame. Theposterior probability Pr (\u0002t |It ) can be inferred recursively,\u0004(2)Pr (\u0002t |It ) \u221d Pr (Xt |\u0002t ) Pr (\u0002t |\u0002t\u22121 ) Pr (\u0002t\u22121 |It\u22121 ) d\u0002t\u22121 ,where Pr (\u0002t |\u0002t\u22121 ) denotes the dynamic model, Pr (Xt |\u0002t ) the observation model, andXt the observation on the t-th frame. We use the same dynamic model as in [29], whilefocusing on the observation model.Suppose we have stochastically generated a set of samples to model the distributionof the object location, i.e., XU = {Xit , i = 1, 2, . . . , nU } at the states (tracking candidates) {\u0002it , i = 1, 2, . . . , nU }. We use an indicator variable yi \u2208 {1, \u22121} to indicate\u201csame\u201d (yi = +1) or \u201ccompletely different\u201d (yi = \u22121) for Xit . We call XU as theunlabeled sample set. Then, we can re-formulate the observation model as\u0002\u0003\u0002\u0003Pr Xit |\u0002it \u221d Pr yi = +1|Xit(3)where the right hand is the likelihood that an observed image patch Xit having the\u201csame\u201d observation of the tracking object.From the tracking results {\u0002\u02c6f , f = 1, 2, . . . , t \u2212 1} up to the (t \u2212 1)-th frame, weextract nL labeled training samples with the labels in {\u22121, +1}. Furthermore, we divide these samples into two categories and treat them differently: the auxiliary samples (from the very early frames) are updated slowly and carefully; the target samples(from most recent frames) are updated quickly and aggressively. Hereafter we denoteDT = {(Xj , yj ), j = 1, 2, . . . , nT } as the target sample set, and DA = {(Xj , yj ), j =nT + 1, nT + 2, . . . , nT + nA } the auxiliary sample set, where nL = nT + nA and yj\u0002is the label in the sense of Eq. (3). Let 1 = [+1, +1, . . . , +1] , the regression function\u0002for the indicators of the unlabeled samples yU = [y1 , y2 , . . . , ynU ] can be written asR = Pr (yU = 1|XU , DA , DT ) .(4)3.2 AnalysesTo analyze the regression R directly, we introduce two real valued latent vectors zA \u2208RnA and zU \u2208 RnU , underpinning the labels in yA and yU , respectively. This way, Rcan be derived as marginalize over zA , zU :\u0004 \u0004Pr (yU = 1|XU , DA , DT ) =Pr (yU = 1|zA , zU , XU , DA , DT ) dzA dzU\u0004 \u0004(5)=Pr (yU = 1|zU ) f (zA , zU |XU , DA , DT ) dzA dzU ,where f (zA , zU |XU , DA , DT ) is the joint probability density.Analysis 1. Let zU = [z1 , z2 , . . . , znU ]\u0002 , we model Pr (yU |zU ) as a noisy label generation process XU \u2192 zU \u2192 yU with the following sigmoid noise output model:Pr (yi |zi ) =e\u03b3zi yi1=,+ e\u2212\u03b3zi yi1 + e\u22122\u03b3zi yie\u03b3zi yi\u2200i = 1, 2, . . . , nU(6)\fTransfer Learning Based Visual Tracking with GPR193where \u03b3 is a parameter controlling the steepness of the sigmoid.The label generation process is similar for the auxiliary data, i.e., XA \u2192 zA \u2192yA , where XA = {Xj , j = nT + 1, nT + 2, . . . , nT + nA }, zA = [znT +1 , znT +2 ,\u0002. . . , znT +nA ]\u0002 , and yA = [ynT +1 , ynT +2 , . . . , ynT +nA ] . In this case, zA can be viewedas the re-weighting knowledge extracted from the regression R. Thus, zA bridges thegap between the regression of the current tracking task and the indicators of the auxiliary samples. zA can also be viewed as a soft substitution of yA , and is therefore lesssensitive to noisy and potential sample misalignment.Analysis 2. Applying the Bayes\u2019 theorem to f (zA , zU |XU , DA , DT ), we havef (zA , zU |XU , DA , DT ) = f (zA , zU |XU , XA , yA , DT )Pr (yA |zA , zU , XA , XU , DT ) \u2022 f (zA , zU |XA , XU , DT )Pr (yA |XA , XU , DT )(7)\u221d Pr (yA |zA ) \u2022 f (zA , zU |XA , XU , DT ) .=We model f (zA , zU |XA , XU , DT ) with a Gaussian process, which can be specified bythe mode \u03bc and the covariance matrix G \u2208 R(nA +nU )\u00d7(nA +nU ) , i.e.,Pr (zA , zU |XA , XU , DT ) \u223c N (\u03bc, G) .(8)The non-Gaussianity of Pr (yA |zA ) (see Analysis 1) makes the f (zA , zU |XU , DA ,DT ) no longer Gaussian, consequently Eq. (5) becomes analytically intractable. According to [11], assuming f (zA , zU |XU , DA , DT ) to be uni-modal, we can considerinstead its Laplace approximation. In place of the correct density we use an (nA +nU )-dimensional Gaussian measure with mode \u03bc\u0003 \u2208 RnA +nU and covariance \u03a3 \u2208R(nA +nU )\u00d7(nA +nU ) , where \u03bc\u0003 = arg maxzA \u2208RnA ,zU \u2208RnU f (zA , zU |XU , DA , DT ). Inthe next we decompose this maximization over zA and zU separately.Taking the logarithm of Eq. (7), we get the following objective function to maximizeJ (zA , zU ) = ln (Pr (yA |zA )) + ln (f (zA , zU |XA , XU , DT )) .\u0005\u0006\u0007\b \u0005\u0006\u0007\bQ1 (zA )Q2 (zA ,zU )(9)\u0002\u0002\u0003 \u0002\u0003\u0002\u0002Denote z\u0002 = z\u0002= yT\u0002 z\u0002A zU , yA , where yT = [y1 , y2 , . . . , ynT ] . Accordingto Eq. (8), we define Q2 as\u0002\u0003\u0003\u0002\u0003\u00021\u0002Q2 (zA , zU ) = \u2212 ln(2\u03c0)nA +nU + ln|G| + z \u2212 \u03bc G\u22121 z \u2212 \u03bc2\u0003\u00021\u0002yT \u0003+ c1= \u2212 ln|Gall | + yT\u0002 z\u0002 G\u22121(10)allz2\u0003 \u22121 y \u0003\u00021\u0002+ c1 ,= \u2212 ln|Gall | + y\u0002 z\u0002(11)U GallzU2A BGLL GLUand G\u22121are the (nL + nU ) \u00d7 (nL + nU )all =GUL GUUB\u0002 MGram matrix (symmetric, non-singular) and its inverse, and c1 \u2208 R summarizes allterms independent of z. As the prior of GPR for our observation model, the matrix Gallis defined over all samples. \u03bc and G in Eq. (8) can be derived from Gall as follows.where Gall =\f194J. Gao et al.Proposition 1. By defining the prior Gram matrix Gall over all samples, we can determine \u03bc and G in Eq. (8) by \u03bc = \u2212M\u22121 B\u0002 yT and G = M\u22121 .The derivation is based on Eq. (10) and can be found in the supplementary material1 .Note zU appears only in Q2 , and we can independently optimize Q2 (zA , \u2022) w.r.t.zU given z\u0302A , where (z\u0302A , z\u0302U ) = arg maxzA ,zU J . According to [11,47], by takingderivative of Q2 (zA , \u2022) w.r.t. zU , the optimal value z\u0302U can be derived as:yTz\u0302Az\u0302U = GUL G\u22121LLThen, let zU = GUL G\u22121LLyTzA(12).in Eq. (11), we can derive z\u0302A by Proposition 2.Proposition 2. The optimal value z\u0302A is given bynLz\u0302A = arg max J = arg maxzA \u2208RnAwhere Q1 (zA ) =zA \u2208RnA j=n +1TnLj=nT +1ln (Pr (yi |zi )) \u22121 \u0002 \u0002 \u0002 \u0003 \u22121 yTy z G2 T A LL zA+ c2 ,(13)ln (Pr (yi |zi )) and c2 = c1 \u221212 ln|Gall |.The derivation is based on Eq. (11) and can be found in the supplementary material1 .The above derivations in (12) and (13) help us to estimate the mode \u03bc\u0003 . In fact,we can also estimate the covariance \u03a3 and thus Eq. (5) is computationally feasible.That is because determining Eq. (5) reduces to computing Pr (yU = 1|XU , DA , DT ) =Pr (yU = 1|zU ) f (zU |z\u0302A , XU , DA , DT ) dzU , and f (zU |z\u0302A , XU , DA , DT ) is approximated by a Gaussian parameterized by \u03bc\u0003 and \u03a3 (see [11] for more details).Analysis 3. We use an iterative Newton-Raphson scheme to find the optimal value z\u0302Ain Proposition 2. Let \u03c1(zj ) = (1 + e\u22122\u03b3zj )\u22121 , where j = nT + 1, nT + 2, . . . , nT + nA .Since yj \u2208 {\u22121, +1}, the auxiliary data generation model can be written asPr (yj |zj ) =yj +11\u2212yje\u03b3zj yj= \u03c1(zj ) 2 (1 \u2212 \u03c1(zj )) 2 ,\u03b3zy\u2212\u03b3zyjjjje+e(14)therefore\u0002nLQ1 (zA ) = \u03b3 (yA \u2212 1) zA \u2212\u0002\u0003ln 1 + e\u22122\u03b3zj .(15)j=nT +1Let G\u22121LL =FT T FT A, we can estimate z\u0302A by taking derivative of J w.r.t. zA ,FAT FAA\u2202J11= \u03b3(yA \u2212 1) + 2\u03b3 (1 \u2212 \u03c1(zA )) \u2212 FAA zA \u2212 F\u0002y \u2212 FAT yT ,\u2202zA2 TA T21https://www.dabi.temple.edu/\u02dchbling/code/TGPR.htm(16)\fTransfer Learning Based Visual Tracking with GPR195where \u03c1(zA ) = [\u03c1(znT +1 ), \u03c1(znT +2 ), . . . , \u03c1(znL )]\u0002 . The term \u03c1(zA ) makes it impossible to compute z\u0302A in a closed form. Instead we use Newton-Raphson algorithm,\u22121zm+1\u2190 zmA \u2212 \u03b7HA\u2202J \u000e\u000e\u000e\u2202zA zmA(17)where \u03b7 \u2208 R+ is chosen so that J m+1 > J m , and H is the Hessian matrix defined as\u000f 2\u0010\u2202 J \u000e\u000e(18)H== \u2212FAA \u2212 P\u000e\u2202zi \u2202zj zAwhere P is a diagonal matrix with elements Pii = 4\u03b3 2 \u03c1(zi )(1 \u2212 \u03c1(zi )).Analysis 4. An important aspect of GPR in our model lies in constructing the priorGram or kernel matrix Gall in (11). A popular way is to define the matrix entries ina \u201clocal\u201d manner. For example, in a radial basis function (RBF) kernel K, the matrixelement kij = exp(\u2212d2ij /\u03b12 ) depends only on the distance dij between the i, j-thitems. Such definition ignores the information encoded in unlabeled samples. Addressing this issue, we define the Gram matrix Gall based on a weighted graph to explore themanifold structure of all samples (both labelled and unlabeled), as suggested in [46,47]following the intuition that similar samples often share similar labels.Consider a graph G = (V, E) with the node set V = T \u222a A \u222a U corresponding to alln = nL + nU samples, where T = {1, . . . , nT } denotes labeled target samples, A ={nT + 1, . . . , nT + nA } the labeled auxiliary samples, and U = {nL + 1, . . . , nL + nU }the unlabeled samples. We define weight matrix W = [wij ] \u2208 Rn\u00d7n on the edges ofthe graph using the local patch representation in [12]. This benefits the robust tracking, especially under partial occlusion. For the i-th and j-th samples, the weight wij isdefined by the spatially weighted log-Euclidean Riemannian Metric over block-basedcovariance descriptors. Specifically, for the i-th sample, we first divide its image patchinto Nr \u00d7 Nc blocks, and then describe its (p, q)-th block by a covariance matrix Cpqi .Specifically, wij is defined aswij =1p,q\u03b2p,qp,qpq\u0011logCpqi \u2212 logCj\u03b2p,q exp \u2212pq pq\u03c3i \u03c3j2\u0012(19)pqo 2where \u03c3ipq is a local scaling factor proposed by [40]; \u03b2p,q = exp(\u2212 \u0005pos2\u03c32\u2212pospqspatial\u0005o) isthe spatial weight, in which pos indicates the position of the (p, q)-th block, pos theposition of the block center, and \u03c3spatial the scaling factor.Instead of connecting all pairs of nodes in V , we restrict the edges to be within thek-nearest-neighborhood, where k controls the density of the graph and the sparsity ofW. We can hence define the combinatorial Laplacian \u0394 of G in the matrix form as\u0394 = D \u2212 W, where D = diag(Dii ) is the diagonal matrix with Dii = j wij .Finally, we define the Gram matrix as Gall = (\u0394+I/\u03bb2 )\u22121 , where the regularizationterm I/\u03bb2 guards \u0394 + I/\u03bb2 from being singular. From the definition of Gall we can seethat, the prior covariance in Eq. (11) between any two samples i, j in general depends\f196J. Gao et al.Algorithm 1. Transfer with GPR for TrackingInput: Target sample set DT , auxiliary sample set DA , and unlabeled sample dataset XUOutput: The node set Vres (with size limit nV ) of the unlabeled samples that are most likely tobelong to the tracking object.1: if nA \u2264 Threshold then2:Calculate Wt over the target and unlabeled samples from Eq. (19);3:Construct Gtall according to Analysis 4;4:Target tracking: z\u02c6tU = GU T G\u22121T T yT ;5:[\u2022, Idxt ] = sort(z\u02c6tU , \u2019descend\u2019);6:Vres = Idxt (1 : nV );7: else8:Calculate W over all the target, auxiliary and unlabeled samples from Eq. (19);9:Construct Gall according to Analysis 4;10:Calculate z\u02c6A from Eq. (17) until convergence;11:Let Wa = W(nT + 1 : n, nT + 1 : n) and construct Gaall according to Analysis 4;\u22121\u02c6a12:Auxiliary tracking:\u0003\u0002 zU = GU A GAA z\u0302A ;W(1 : nT , nL + 1 : n)W(1 : nT , 1 : nT );13:Construct Wt =W(nL + 1 : n, 1 : nT ) W(nL + 1 : n, nL + 1 : n)14:Construct Gtall according to Analysis 4;15:Target tracking: z\u02c6tU = GU T G\u22121T T yT ;16:/* Fusing two trackers, \u2018pool\u2019 is the size of candidate pool */17:[\u2022, Idxa ] = sort(z\u02c6aU , \u2019descend\u2019);18:[\u2022, Idxt ] = sort(z\u02c6tU , \u2019descend\u2019);/ Idxt (1 : pool)};19:VA = Idxa (1 : pool) \\ {i : Idxa (i) \u2208/ Idxa (1 : pool)};20:VT = Idxt (1 : pool) \\ {i : Idxt (i) \u220821:if |VA | > pool/2 then22:Vres = VA (1 : min(nV , pool/2));23:else if |VA | = 0 then24:Vres = Idxa (1 : nV );25:else26:Vres = VT (1 : min(nV , |VA |));27:end if28: end ifon all samples \u2013 all the target and unlabeled samples are used to define the prior. Thus,distribution of target and unlabeled samples may strongly influence the kernel, which isdesired when we extract the re-weighting knowledge zA .3.3 Fusion Based Transfer Learning ExtensionThe value of a latent variable in z\u0302U can be viewed as a soft version of tracking decision. Consequently, our tracker can be based on using z\u0302U to decide which samplesmost likely have the \u201csame\u201d observations to the object. The larger the value of z\u0302i in z\u0302U ,the more likely the sample has the \u201csame\u201d observation. However, we do not directlyuse Eq. (12) to compute z\u0302U for tracking. This is because the unlabeled samples relatemore to the target samples than to the auxiliary ones, and direct use of Eq. (12) may\fTransfer Learning Based Visual Tracking with GPR197overfit the target samples and is vulnerable to the misaligned target samples or occlusion. Alternatively, we use the re-weighted auxiliary samples and the target samples tobuild two individual trackers. Then, the auxiliary decision (made by the re-weightedauxiliary samples) assists the target decision (made by the target samples) by fusing thetwo trackers. This can be thought as a task-transfer process, in which the re-weightingknowledge is transferred from the auxiliary decision to the target decision.These two trackers can be derived based on \u00a73.2. Given all the labeled (auxiliaryand target) and unlabeled samples, i.e., (XL , yL ) and XU , Eq. (5) can be reduced toPr (yU = 1|XU , XL , yL ) = Pr (yU = 1|zU ) f (zU |XU , XL , yL ) dzU . Meanwhile,the Gaussian distribution in Eq. (8) is reduced to Pr (zU |XU , XL , yL ) \u223c N (\u03bcL , GL ).According to Proposition 1, let yT = yL and z = zU in Eq. (11), we can find theGLL GLU\u0002optimal estimation of zU by z\u0302U = \u03bcL = \u2212M\u22121L BL yL , where Gall =GUL GUUAL BLare the Gram matrix and its inverse over all samples. Theand G\u22121all =B\u0002L ML\u22121\u0002blocks in G\u22121all can be derived as BL = \u2212ML GUL GLL . Consequently, we have z\u0302U =\u22121GUL GLL yL . This is consistent to the harmonic property proposed in [46,47], whichshows that the value of soft label z\u02c6i at each unlabeled sample is the average of labelvalues from its neighborhood.With the above derivation, we can perform the two tracking algorithms respectivelyusing the re-weighted auxiliary samples and the target samples:\u2013 Auxiliary Tracking Using z\u02c6aU : use the auxiliary samples XA as labeled samplesGAA GAUwith labels z\u0302A ; construct the prior Gram matrix Gaall =accordingGUA GUUto Analysis 4; then the soft labels of unlabeled samples can be determined by theauxiliary samples as z\u02c6aU = GUA G\u22121A.AA z\u02c6\u2013 Target Tracking Using z\u02c6tU : use the target samples XT as labeled samples withGT T GT Ulabels yT ; construct the prior Gram matrix Gtall =according toGUT GUUAnalysis 4; then the soft labels of unlabeled samples can be determined by thetarget samples as z\u02c6tU = GUT G\u22121T T yT .Finally, we use a heuristic fusion method to regularize the target decision with theassistance of the auxiliary decision. Specifically, when obtaining two positive candidatesets according to these two decisions separately, we check the two sets\u2019 coincidencedegree, e.g., |VA | in Algorithm 1. When the degree is high, it does not matter whetherwe rely on the auxiliary decision or the target decision; when the degree is small, werely more on the target decision to ensure the consistency of the tracking results; whenthe degree is zero, we rely more on the auxiliary decision to recover from the severeappearance variation and heavy occlusion. We detail this procedure in Algorithm 1.When the node set Vres in Algorithm 1 is obtained, the object location can be determinedby the average over locations of the samples indexed by these nodes.\f198J. Gao et al.4 ExperimentsIt is not easy to thoroughly evaluate a tracking algorithm without subjective bias [28],due to the influence from many factors such as sequence selection and parameter tuning. Several notable recent efforts [35,30,16] have been devoted to address this issue byproposing tracking benchmarks. Aligning with these efforts, we evaluate the proposedTGPR tracker over these benchmarks by following rigorously their evaluation protocols. In summary, TGPR is run on a total of 161 sequences and has achieved excellentperformances in all the benchmarks.4.1 Implementation DetailsThe proposed algorithm is implemented in C++ and evaluated on a desktop with a3.40GHz CPU and 8GB RAM. The running time is about 3\u223c4 frames per second. ThisC++ implementation of TGPR is publicly available1 .Samples Collection. We use the dynamic model proposed by [29] for collecting unlabeled samples XU from the current frame It , where we only consider the variations\u0002\u0002of 2D translation (xt , y t ) and scale (st ) in the affine transformation, and set the number nU of particles to 300. When the conditions of lines 22 and 24 in Algorithm 1 are\u0002\u0002met, the parameter settings of (xt , y t ) and nU are increased by a factor of 1.5. As forDT , we use the tracking results of past 10 frames It\u221210 , . . . , It\u22121 (or less than 10 inthe beginning of tracking) as the positive target samples; the negative target samples\u0002\u2217\u0002\u2217are sampled from the frame It\u22121 around its tracking result (xt\u22121 , y t\u22121 , s\u2217t\u22121 ), usingdense sampling method similar to [20] (overlap ratio is 0.11) in the sliding region, i.e.,\u0002\u2217\u0002\u2217\u0002\u2217\u0002\u2217{X : \u0002(X) \u2208 (R(xt\u22121 , y t\u22121 , 2s\u2217t\u22121 ) \u2212 R(xt\u22121 , y t\u22121 , s\u2217t\u22121 ))}, where \u0002(X) denotes thelocation of negative target sample X, \u2208 means the center location of X lies in a cer\u0002 \u0002tain image region, and R(x, y, s) denotes the image region corresponding to the affine\u0002 \u0002transformation (x, y, s). Then, we randomly sample 64 negative target samples. For thepurpose of updating the auxiliary set slowly, we collect the auxiliary samples DA fromthe frames before t \u2212 10 at intervals of 3 (or 6 for long-term tracking) frames, if theseframes are available. The collection in such frames is the same to the collection of labeled samples in [20]. We set the size limit of positive auxiliary sample buffer to 50,and negative auxiliary sample buffer to 200.Parameter Settings. Note that these settings are fixed for all experiments. In Analysis4, the weight (Eq. (19)) of W is calculated by setting Nr = Nc = 3, \u03c3spatial = 3.9 and\u03c3ipq calculated from the 7th nearest neighbor. The hyperparameter k for controlling thesparsity of W is set to 50. The Gram matrix is defined by setting \u03bb = 1000. In Analysis3, \u03b3 in Eq. (6) is set to be 10, \u03b7 in Eq. (17) is 0.4, and the number of iterations forcalculating z\u02c6A from Eq. (17) is 15. In Algorithm 1, the size limit nV of the output Vresis set to be 5, Threshold is 30, and pool is 20.4.2 Experiment 1: CVPR2013 Visual Tracker BenchmarkThe CVPR2013 Visual Tracker Benchmark [35] contains 50 fully annotated sequences.These sequences include many popular sequences used in the online tracking literature\fTransfer Learning Based Visual Tracking with GPR199Fig. 3. Plots of OPE on the CVPR2013 Visual Tracker Benchmark. The performance scorefor each tracker is shown in the legend. For each figure, the top 10 trackers are presented forclarity (best viewed on high-resolution display.over the past several years. For better evaluation and analysis of the strength and weakness of tracking approaches, these sequences are annotated with the 11 attributes including illumination variation, scale variation, occlusion, deformation, motion blur, fastmotion, in-plane rotation, out-of-plane rotation, out-of-view, background clutters, andlow resolution.The providers have evaluated 29 tracking algorithms and released their results alongwith the sequences. To analyze the performances of different algorithms, the precisionplots based on the location error metric and the success plots based on the overlapmetric are adopted. In addition, the providers propose three kinds of robustness evaluation strategies: OPE (one-pass evaluation), TRE (temporal robustness evaluation),SRE (spatial robustness evaluation).Results. Due to space limitations, we only show the overall performance of OPE forour tracker and compare it with some other state-of-the-arts (ranked within top 10) asshown in Fig. 3. These trackers include Struck [8], SCM [45], TLD [15], ASLA [14],VTD [17], VTS [18], CXT [4], LSK [24], CSK [10], MTT [44] and LOT [27]. Note thatall the plots are automatically generated by the code library supported by the benchmarkproviders. From Fig. 3, we see that: (1) in the success plot, our proposed tracker TGPRoutperforms the second best tracker SCM by 8.0%; and (2) in the precision plot, TGPRoutperforms the second best tracker Struck by 15.7%.Note that due to space limitation, we only include the above representative resultsand leaves more details in the supplementary material. It worth pointing out that, asshown in [35], the results (especially the top ones) in OPE are in general consistentwith those in TRE and SRE.4.3 Experiment 2: Princeton Tracking BenchmarkIn the Princeton Tracking Benchmark [30], the providers captured a new benchmark byrecording 100 video clips with both RGB and depth data using a standard MicrosoftKinect 1.0. In spite of some constraints due to acquisition (e.g., captured indoors, with\f200J. Gao et al.Table 1. Results on the Princeton Tracking Benchmark: successful rates and rankings (inparentheses) for different categorizations. The best results are in red and the second best in blue.Alg.TGPRStruckVTDRGBdetCTTLDMILSemiBOFAvg.target typeRank human animal rigid1.092.823.184.365.365.645.827.739.000.46(1)0.35(2)0.31(5)0.27(7)0.31(4)0.29(6)0.32(3)0.22(8)0.18(9)0.49(2)0.47(3)0.49(1)0.41(5)0.47(4)0.35(7)0.37(6)0.33(8)0.11(9)0.67(1)0.53(4)0.54(3)0.55(2)0.37(7)0.44(5)0.38(6)0.33(8)0.23(9)target sizelarge small0.56(1)0.45(2)0.39(4)0.32(7)0.39(3)0.32(6)0.37(5)0.24(8)0.20(9)0.53(1)0.44(4)0.46(2)0.46(3)0.34(7)0.38(5)0.35(6)0.32(8)0.17(9)movementslowfast0.66(1)0.58(2)0.57(3)0.51(5)0.49(6)0.52(4)0.46(7)0.38(8)0.18(9)0.50(1)0.39(2)0.37(3)0.36(4)0.31(5)0.30(7)0.31(6)0.24(8)0.19(9)occlusionyesno0.44(1)0.30(4)0.28(5)0.35(2)0.23(8)0.34(3)0.26(6)0.25(7)0.16(9)0.69(1)0.64(2)0.63(3)0.47(6)0.54(4)0.39(7)0.49(5)0.33(8)0.22(9)motion typepassive active0.67(1)0.54(4)0.55(3)0.56(2)0.42(7)0.50(5)0.40(8)0.42(6)0.23(9)0.50(1)0.41(2)0.38(3)0.34(5)0.34(4)0.31(7)0.34(6)0.23(8)0.17(9)object depth values ranging from 0.5 to 10 meters), the dataset is valuable for evaluatingthe state-of-the-art visual tracking algorithms (only use the RGB data). This benchmarkdataset presents varieties in the following aspects: target type, scene type, presence ofocclusion, bounding box location and size distribution, and bounding box variation overtime.Along with the dataset, the providers also provide the evaluation results of the success rates measured by overlap ratio for eight state-of-the-art trackers (with RGB input)and eight RGBD competitors (with RGBD input). For fair comparison, we only compare the proposed TGPR tracker with the eight RGB competitors, including Struck [8],VTD [17], CT [41], TLD [15], MIL [2], SemiB [7] and the other 2 RGB baseline algorithms provided by the benchmark providers, RGBdet [30] and OF [30].Results. The groundtruth of 95 out of the 100 sequences is reserved by theproviders to reduce the chance for data-specific tuning. Following the instructionin https://tracking.cs.princeton.edu/submit.php, we submitted ourtracking results online and obtained the evaluation results compared with the otherRGB trackers as shown in Table 1. The results show that TGPR again outperformsother state-of-the-arts in almost all categories.4.4 Experiment 3: VOT2013 Challenge BenchmarkThe visual object tracking VOT2013 Challenge Benchmark [16] provides an evaluationkit and the dataset with 16 fully annotated sequences for evaluating tracking algorithmsin realistic scenes subject to various common conditions. Following the protocol, weintegrate our tracker TGPR into the VOT2013 evaluation kit, which automatically performs a standardized experiment on the tracking algorithm.The tracking performance in the VOT2013 Challenge Benchmark is primarily evaluated by the following measures with a different view from the common evaluationcriteria. Accuracy (acc.): This measure is the average of the overlap ratios over thevalid frames of each sequence. The possible values are in the range of [0, 1]. Robustness (rob.): The tracker\u2019s robustness is evaluated by the total number of failures over\fTransfer Learning Based Visual Tracking with GPR201Table 2. The results of our tracker TGPR on the VOT2013 Challenge Benchmark. All thevalues are averaged by running each test on each sequence 15 times.bicycle bolt car cup david diving face gym. hand iceskater juice jump singer sunshade torus womanacc. 0.60 0.57 0.45 0.83 0.58Arob.01.27 0.40 0 0.270.33 0.85 0.57 0.562.87 0 2.87 1.670.6000.76 0.59000.650.600.730.200.780.130.741.00acc. 0.57 0.57 0.41 0.75 0.58rob.01.27 0.20 0 0.270.32 0.77 0.53 0.532.87 0.07 3.00 2.070.5700.73 0.57000.450.330.640.070.650.600.671.00B15 runs. In particular, a failure is detected once the overlap ratio measure drops to zero.When a failure happens, an operator re-initializes the tracker so it can continue. Anequivalent of the number of required manual interventions per sequence is recordedand used as a comparative score.We run TGPR in two types of test following the benchmark protocol. Test A: TGPRwas run on each sequence in the dataset 15 times by initializing it on the ground truthbounding box, obtaining average statistic scores of the measures. Test B: TGPR wasrun, initialized with 15 noisy bounding boxes in each sequence, i.e., bounding boxesrandomly perturbed in order of ten percent of the ground truth bounding box size. Then,average statistic scores of the measures are obtained.Results. Because the VOT does not provide their ranking-based evaluation systems topublic, we can report the results of our tracker in Table 2. That said, the table shows thegreat effectiveness of TGPR, with the failure rate often equal to 0, and most overlappingratios above 0.5. Meanwhile, Table 2 shows that our tracker is not that sensitive todifferent initializations.5 ConclusionWe proposed a new transfer learning based tracking algorithm with Gaussian ProcessesRegression (GPR). Specifically, GPR is innovatively exploited to make a new objectiveof the observation model, and then a simple but effective task-transfer tracking framework is extended so that drift problems can be alleviated from various aspects. Wehave also used a local patch representation method based graph Laplacian to define theprior Gram matrix in GPR, so that the distribution of target and unlabeled samples maystrongly influence the transferred re-weighting knowledge. We have performed thorough evaluations on three public benchmarks and TGPR has generated very promisingresults by outperforming many state-of-the-arts.Acknowledgement. Ling is supported in part by the US NSF Grant IIS-1218156 andthe US NSF CAREER Award IIS-1350521. The others are partially supported by NSFC(Grant No. 60935002, Grant No. 61303178), the National 863 High-Tech R&D Program of China (Grant No. 2012AA012504), the Natural Science Foundation of Beijing(Grant No. 4121003), and The Project Supported by Guangdong Natural Science Foundation (Grant No. S2012020011081).\f202J. Gao et al.References1. Adam, A., Rivlin, E., Shimshoni, I.: Robust fragments-based tracking using the integral histogram. In: CVPR (2006)2. Babenko, B., Yang, M.-H., Belongie, S.: Visual tracking with online multiple instance learning. In: CVPR (2009)3. Bao, C., Wu, Y., Ling, H., Ji, H.: Real time robust \u00021 tracker using accelerated proximalgradient approach. In: CVPR (2012)4. Dinh, T.B., Vo, N., Medioni, G.: Context tracker: Exploring supporters and distracters inunconstrained environments. In: CVPR (2011)5. Erdem, E., Dubuisson, S., Bloch, I.: Fragments based tracking with adaptive cue integration.Computer Vision and Image Understanding 116(7), 827\u2013841 (2012)6. Grabner, H., Grabner, M., Bischof, H.: Real-time tracking via on-line boosting. In: BMVC(2006)7. Grabner, H., Leistner, C., Bischof, H.: Semi-supervised on-line boosting for robust tracking.In: Forsyth, D., Torr, P., Zisserman, A. (eds.) ECCV 2008, Part I. LNCS, vol. 5302, pp.234\u2013247. Springer, Heidelberg (2008)8. Hare, S., Saffari, A., Torr, P.H.S.: Struck: Structured output tracking with kernels. In: ICCV(2011)9. He, S., Yang, Q., Lau, R., Wang, J., Yang, M.-H.: Visual tracking via locality sensitive histograms. In: CVPR (2013)10. Henriques, J.F., Caseiro, R., Martins, P., Batista, J.: Exploiting the circulant structure oftracking-by-detection with kernels. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y.,Schmid, C. (eds.) ECCV 2012, Part IV. LNCS, vol. 7575, pp. 702\u2013715. Springer, Heidelberg(2012)11. Herbrich, R.: Kernel classifiers from a bayesian perspective. Learning Kernel Classifiers:Theory and Algorithms. MIT Press (2002)12. Hu, W., Li, X., Luo, W., Zhang, X., Maybank, S., Zhang, Z.: Single and multiple object tracking using log-euclidean riemannian subspace and block-division appearance model. Trans.on PAMI 34(12), 2420\u20132440 (2012)13. Isard, M., Blake, A.: Condensation - conditional density propagation for visual tracking.International Journal of Computer Vision 29(1), 5\u201328 (1998)14. Jia, X., Lu, H., Yang, M.-H.: Visual tracking via adaptive structural local sparse appearancemodel. In: CVPR (2012)15. Kalal, Z., Mikolajczyk, K., Matas, J.: Tracking-learning-detection. Trans. on PAMI 34(7),1409\u20131422 (2012)16. Kristan, M., Pflugfelder, R., et al.: The visual object tracking vot2013 challenge results. In:Vis. Obj. Track. Challenge VOT 2013, In conjunction with ICCV (2013)17. Kwon, J., Lee, K.M.: Visual tracking decomposition. In: CVPR (2010)18. Kwon, J., Lee, K.M.: Tracking by sampling trackers. In: ICCV (2011)19. Kwon, J., Lee, K.M.: Minimum uncertainty gap for robust visual tracking. In: CVPR (2013)20. Li, G., Qin, L., Huang, Q., Pang, J., Jiang, S.: Treat samples differently: object tracking withsemi-supervised online covboost. In: ICCV (2011)21. Li, X., Shen, C., Dick, A., van den Hengel, A.: Learning compact binary codes for visualtracking. In: CVPR (2013)22. Li, X., Shen, C., Shi, Q., Dick, A., van den Hengel, A.: Non-sparse linear representations forvisual tracking with online reservoir metric learning. In: CVPR (2012)23. Li, Y., Ai, H., Yamashita, T., Lao, S., Kawade, M.: Tracking in low frame rate video: Acascade particle filter with discriminative observers of different lifespans. In: CVPR (2007)\fTransfer Learning Based Visual Tracking with GPR20324. Liu, B., Huang, J., Yang, L., Kulikowsk, C.: Robust tracking using local sparse appearancemodel and k-selection. In: CVPR (2011)25. Mei, X., Ling, H.: Robust visual tracking and vehicle classification via sparse representation.Trans. on PAMI 33(11), 2259\u20132272 (2011)26. Mei, X., Ling, H., Wu, Y., Blasch, E., Bai, L.: Minimum error bounded efficient \u00021 trackerwith occlusion detection. In: CVPR (2011)27. Oron, S., Bar-Hillel, A., Levi, D., Avidan, S.: Locally orderless tracking. In: CVPR (2012)28. Pang, Y., Ling, H.: Finding the best from the second bests - inhibiting subjective bias inevaluation of visual tracking algorithms. In: ICCV (2013)29. Ross, D.A., Lim, J., Lin, R., Yang, M.-H.: Incremental learning for robust visual tracking.Int. J. Comp. Vis. 77(1), 125\u2013141 (2008)30. Song, S., Xiao, J.: Tracking revisited using rgbd camera: Unified benchmark and baselines.In: ICCV (2013)31. Supanc\u030cic\u030c, J.S., Ramanan, D.: Self-paced learning for long-term tracking. In: CVPR (2013)32. Wang, D., Lu, H., Yang, M.-H.: Least soft-thresold squares tracking. In: CVPR (2013)33. Wang, N., Yeung, D.Y.: Learning a deep compact image representation for visual tracking.In: NIPS (2013)34. Wang, Q., Chen, F., Yang, J., Xu, W., Yang, M.-H.: Transferring visual prior for online objecttracking. Trans. on IP 21(7), 3296\u20133305 (2012)35. Wu, Y., Lim, J., Yang, M.-H.: Online object tracking: A benchmark. In: CVPR (2013)36. Xing, J., Gao, J., Li, B., Hu, W., Yan, S.: Robust object tracking with online multi-lifespandictionary learning. In: ICCV (2013)37. Yao, R., Shi, Q., Shen, C., Zhang, Y., van den Hengel, A.: Part-based visual tracking withonline latent structural learning. In: CVPR (2013)38. Yao, Y., Doretto, G.: Boosting for transfer learning with multiple sources. In: CVPR (2010)39. Yilmaz, A., Javed, O., Shah, M.: Object tracking: A survey. ACM Comput. Surv. 38(4) (2006)40. Zelnik-Manor, L., Perona, P.: Self-tuning spectral clustering. In: NIPS (2005)41. Zhang, K., Zhang, L., Yang, M.-H.: Real-time compressive tracking. In: Fitzgibbon, A.,Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012, Part III. LNCS, vol. 7574,pp. 864\u2013877. Springer, Heidelberg (2012)42. Zhang, L., van der Maaten, L.: Structure preserving object tracking. In: CVPR (2013)43. Zhang, T., Ghanem, B., Liu, S., Ahuja, N.: Low-rank sparse learning for robust visual tracking. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012, PartVI. LNCS, vol. 7577, pp. 470\u2013484. Springer, Heidelberg (2012)44. Zhang, T., Ghanem, B., Liu, S., Ahuja, N.: Robust visual tracking via multi-task sparse learning. In: CVPR (2012)45. Zhong, W., Lu, H., Yang, M.-H.: Robust object tracking via sparsity-based collaborativemodel. In: CVPR (2012)46. Zhu, X., Ghahramani, Z., Lafferty, J.: Semi-supervised learning using gaussian fields andharmonic functions. In: ICML (2003)47. Zhu, X., Lafferty, J., Ghahramani, Z.: Semi-supervised learning: From gaussian fields togaussian processes. Tech. Rep. CMU-CS-03-175, School of Computer Science, CarnegieMellon University, Pittsburgh, Pennsylvania (August 2003)\f", "This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence1Long-term Recurrent Convolutional Networks forVisual Recognition and DescriptionJeff Donahue, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, Sergio Guadarrama,Kate Saenko, Trevor DarrellAbstract\u2014Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models whichare also recurrent are effective for tasks involving sequences, visual and otherwise. We describe a class of recurrent convolutionalarchitectures which is end-to-end trainable and suitable for large-scale visual understanding tasks, and demonstrate the value of thesemodels for activity recognition, image captioning, and video description. In contrast to previous models which assume a fixed visualrepresentation or perform simple temporal averaging for sequential processing, recurrent convolutional models are \u201cdoubly deep\u201d inthat they learn compositional representations in space and time. Learning long-term dependencies is possible when nonlinearities areincorporated into the network state updates. Differentiable recurrent models are appealing in that they can directly map variable-lengthinputs (e.g., videos) to variable-length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can beoptimized with backpropagation. Our recurrent sequence models are directly connected to modern visual convolutional networkmodels and can be jointly trained to learn temporal dynamics and convolutional perceptual representations. Our results show that suchmodels have distinct advantages over state-of-the-art models for recognition or generation which are separately defined or optimized.F1I NTRODUCTIONRecognition and description of images and videos isa fundamental challenge of computer vision. Dramaticprogress has been achieved by supervised convolutionalneural network (CNN) models on image recognition tasks,and a number of extensions to process video have beenrecently proposed. Ideally, a video model should allow processing of variable length input sequences, and also providefor variable length outputs, including generation of fulllength sentence descriptions that go beyond conventionalone-versus-all prediction tasks. In this paper we proposeLong-term Recurrent Convolutional Networks (LRCNs), a classof architectures for visual recognition and description whichcombines convolutional layers and long-range temporal recursion and is end-to-end trainable (Figure 1). We instantiate our architecture for specific video activity recognition,image caption generation, and video description tasks asdescribed below.Research on CNN models for video processing hasconsidered learning 3D spatio-temporal filters over rawsequence data [1], [2], and learning of frame-to-frame representations which incorporate instantaneous optic flow ortrajectory-based models aggregated over fixed windowsor video shot segments [3], [4]. Such models explore twoextrema of perceptual time-series representation learning:either learn a fully general time-varying weighting, or apply\u2022\u2022\u2022\u2022J. Donahue, L. A. Hendricks, M. Rohrbach, S. Guadarrama, and T. Darrellare with the Department of Electrical Engineering and Computer Science,UC Berkeley, Berkeley, CA.M. Rohrbach and T. Darrell are additionally affiliated with the International Computer Science Institute, Berkeley, CA.S. Venugopalan is with the Department of Computer Science, UT Austin,Austin, TX.K. Saenko is with the Department of Computer Science, UMass Lowell,Lowell, MA.Manuscript received November 30, 2015.InputVisualFeaturesSequenceLearningOutputCNNLSTMy1CNNLSTMy2CNNLSTMyTFig. 1. We propose Long-term Recurrent Convolutional Networks (LRCNs), a class of architectures leveraging the strengths of rapid progressin CNNs for visual recognition problems, and the growing desire toapply such models to time-varying inputs and outputs. LRCN processesthe (possibly) variable-length visual input (left) with a CNN (middleleft), whose outputs are fed into a stack of recurrent sequence models(LSTMs, middle-right), which finally produce a variable-length prediction(right). Both the CNN and LSTM weights are shared across time, resulting in a representation that scales to arbitrarily long sequences.simple temporal pooling. Following the same inspirationthat motivates current deep convolutional models, we advocate for video recognition and description models whichare also deep over temporal dimensions; i.e., have temporalrecurrence of latent variables. Recurrent Neural Network(RNN) models are \u201cdeep in time\u201d \u2013 explicitly so whenunrolled \u2013 and form implicit compositional representations0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence2in the time domain. Such \u201cdeep\u201d models predated deepspatial convolution models in the literature [5], [6].The use of RNNs in perceptual applications has been explored for many decades, with varying results. A significantlimitation of simple RNN models which strictly integratestate information over time is known as the \u201cvanishinggradient\u201d effect: the ability to backpropagate an error signalthrough a long-range temporal interval becomes increasingly difficult in practice. Long Short-Term Memory (LSTM)units, first proposed in [7], are recurrent modules whichenable long-range learning. LSTM units have hidden stateaugmented with nonlinear mechanisms to allow state topropagate without modification, be updated, or be reset,using simple learned gating functions. LSTMs have recentlybeen demonstrated to be capable of large-scale learning ofspeech recognition [8] and language translation models [9],[10].We show here that convolutional networks with recurrent units are generally applicable to visual time-seriesmodeling, and argue that in visual tasks where static or flattemporal models have previously been employed, LSTMstyle RNNs can provide significant improvement whenample training data are available to learn or refine the representation. Specifically, we show that LSTM type modelsprovide for improved recognition on conventional videoactivity challenges and enable a novel end-to-end optimizable mapping from image pixels to sentence-level naturallanguage descriptions. We also show that these modelsimprove generation of descriptions from intermediate visualrepresentations derived from conventional visual models.We instantiate our proposed architecture in three experimental settings (Figure 3). First, we show that directlyconnecting a visual convolutional model to deep LSTMnetworks, we are able to train video recognition modelsthat capture temporal state dependencies (Figure 3 left;Section 4). While existing labeled video activity datasetsmay not have actions or activities with particularly complex temporal dynamics, we nonetheless observe significantimprovements on conventional benchmarks.Second, we explore end-to-end trainable image to sentence mappings. Strong results for machine translationtasks have recently been reported [9], [10]; such modelsare encoder-decoder pairs based on LSTM networks. Wepropose a multimodal analog of this model, and describe anarchitecture which uses a visual convnet to encode a deepstate vector, and an LSTM to decode the vector into a naturallanguage string (Figure 3 middle; Section 5). The resultingmodel can be trained end-to-end on large-scale image andtext datasets, and even with modest training provides competitive generation results compared to existing methods.Finally, we show that LSTM decoders can be drivendirectly from conventional computer vision methods whichpredict higher-level discriminative labels, such as the semantic video role tuple predictors in [11] (Figure 3, right;Section 6). While not end-to-end trainable, such models offerarchitectural and performance advantages over previousstatistical machine translation-based approaches.We have realized a generic framework for recurrentmodels in the widely adopted deep learning frameworkCaffe [12], including ready-to-use implementations of RNNand LSTM units. (See https://jeffdonahue.com/lrcn/.)RNN Unitxtht-1\u03c3LSTM Unitht\u03c3OutputInputGatezt\u03d5gtOutputGate\u03c3it\u03c3ot+\u03d5ht = ztInput Modulation Gatextht-1ct-1\u03c3ftForget GatectFig. 2. A diagram of a basic RNN cell (left) and an LSTM memorycell (right) used in this paper (from [13], a slight simplification of thearchitecture described in [14], which was derived from the LSTM initiallyproposed in [7]).2BACKGROUND : R ECURRENT N ETWORKSTraditional recurrent neural networks (RNNs, Figure 2, left)model temporal dynamics by mapping input sequences tohidden states, and hidden states to outputs via the followingrecurrence equations (Figure 2, left):ht = g(Wxh xt + Whh ht\u22121 + bh )zt = g(Whz ht + bz )where g is an element-wise non-linearity, such as a sigmoidor hyperbolic tangent, xt is the input, ht \u2208 RN is the hiddenstate with N hidden units, and zt is the output at time t.For a length T input sequence hx1 , x2 , ..., xT i, the updatesabove are computed sequentially as h1 (letting h0 = 0), z1 ,h2 , z2 , ..., hT , zT .Though RNNs have proven successful on tasks suchas speech recognition [15] and text generation [16], it canbe difficult to train them to learn long-term dynamics,likely due in part to the vanishing and exploding gradientsproblem [7] that can result from propagating the gradientsdown through the many layers of the recurrent network,each corresponding to a particular time step. LSTMs providea solution by incorporating memory units that explicitlyallow the network to learn when to \u201cforget\u201d previous hidden states and when to update hidden states given newinformation. As research on LSTMs has progressed, hiddenunits with varying connections within the memory unithave been proposed. We use the LSTM unit as describedin [13] (Figure 2, right), a slight simplification of the onedescribed in [8], which was derived from the original LSTM\u22121unit proposed in [7]. Letting \u03c3(x) = (1 + e\u2212x )be thesigmoid non-linearity which squashes real-valued inputs tox\u2212xa [0, 1] range, and letting tanh(x) = eex \u2212e+e\u2212x = 2\u03c3(2x) \u2212 1be the hyperbolic tangent non-linearity, similarly squashingits inputs to a [\u22121, 1] range, the LSTM updates for time stept given inputs xt , ht\u22121 , and ct\u22121 are:itftotgtctht= \u03c3(Wxi xt + Whi ht\u22121 + bi )= \u03c3(Wxf xt + Whf ht\u22121 + bf )= \u03c3(Wxo xt + Who ht\u22121 + bo )= tanh(Wxc xt + Whc ht\u22121 + bc )= ft ct\u22121 + it gt= ot tanh(ct )0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence3xy denotes the element-wise product of vectors x and y .In addition to a hidden unit ht \u2208 RN , the LSTM includesan input gate it \u2208 RN , forget gate ft \u2208 RN , output gateot \u2208 RN , input modulation gate gt \u2208 RN , and memory cellct \u2208 RN . The memory cell unit ct is a sum of two terms: theprevious memory cell unit ct\u22121 which is modulated by ft ,and gt , a function of the current input and previous hiddenstate, modulated by the input gate it . Because it and ft aresigmoidal, their values lie within the range [0, 1], and itand ft can be thought of as knobs that the LSTM learnsto selectively forget its previous memory or consider itscurrent input. Likewise, the output gate ot learns how muchof the memory cell to transfer to the hidden state. Theseadditional cells seem to enable the LSTM to learn complexand long-term temporal dynamics for a wide variety ofsequence learning and prediction tasks. Additional depthcan be added to LSTMs by stacking them on top of each(`\u22121)other, using the hidden state htof the LSTM in layer` \u2212 1 as the input to the LSTM in layer `.Recently, LSTMs have achieved impressive results onlanguage tasks such as speech recognition [8] and machine translation [9], [10]. Analogous to CNNs, LSTMs areattractive because they allow end-to-end fine-tuning. Forexample, [8] eliminates the need for complex multi-steppipelines in speech recognition by training a deep bidirectional LSTM which maps spectrogram inputs to text. Evenwith no language model or pronunciation dictionary, themodel produces convincing text translations. [9] and [10]translate sentences from English to French with a multilayer LSTM encoder and decoder. Sentences in the sourcelanguage are mapped to a hidden state using an encodingLSTM, and then a decoding LSTM maps the hidden state toa sequence in the target language. Such an encoder-decoderscheme allows an input sequence of arbitrary length tobe mapped to an output sequence of different length. Thesequence-to-sequence architecture for machine translationcircumvents the need for language models.The advantages of LSTMs for modeling sequential datain vision problems are twofold. First, when integrated withcurrent vision systems, LSTM models are straightforwardto fine-tune end-to-end. Second, LSTMs are not confined tofixed length inputs or outputs allowing simple modelingfor sequential data of varying lengths, such as text or video.We next describe a unified framework to combine recurrentmodels such as LSTMs with deep convolutional networksto form end-to-end trainable networks capable of complexvisual and sequence prediction tasks.3 L ONG - TERM R ECURRENTN ETWORK (LRCN) MODEL\u03c6V (xt ). The outputs of \u03c6V are then passed into a recurrentsequence learning module.In its most general form, a recurrent model has parameters W , and maps an input xt and a previous time stephidden state ht\u22121 to an output zt and updated hidden stateht . Therefore, inference must be run sequentially (i.e., fromtop to bottom, in the Sequence Learning box of Figure 1), bycomputing in order: h1 = fW (x1 , h0 ) = fW (x1 , 0), thenh2 = fW (x2 , h1 ), etc., up to hT . Some of our models stackmultiple LSTMs atop one another as described in Section 2.To predict a distribution P (yt ) over outcomes yt \u2208 C(where C is a discrete, finite set of outcomes) at time stept, the outputs zt \u2208 Rdz of the sequential model are passedthrough a linear prediction layer y\u0302t = Wz zt + bz , whereWz \u2208 R|C|\u00d7dz and bz \u2208 R|C| are learned parameters. Finally,the predicted distribution P (yt ) is computed by taking theexp(y\u0302t,c )softmax of y\u0302t : P (yt = c) = softmax(y\u0302t ) = P exp(y\u0302.0)c0 \u2208C1)C ONVOLUTIONALThis work proposes a Long-term Recurrent ConvolutionalNetwork (LRCN) model combining a deep hierarchical visual feature extractor (such as a CNN) with a model that canlearn to recognize and synthesize temporal dynamics fortasks involving sequential data (inputs or outputs), visual,linguistic, or otherwise. Figure 1 depicts the core of ourapproach. LRCN works by passing each visual input xt(an image in isolation, or a frame from a video) througha feature transformation \u03c6V (.) with parameters V , usuallya CNN, to produce a fixed-length vector representationt,cThe success of recent deep models for object recognition [17], [18], [19] suggests that strategically composingmany \u201clayers\u201d of non-linear functions can result in powerfulmodels for perceptual problems. For large T , the aboverecurrence indicates that the last few predictions from arecurrent network with T time steps are computed by a very\u201cdeep\u201d (T layer) non-linear function, suggesting that theresulting recurrent model may have similar representationalpower to a T layer deep network. Critically, however, thesequence model\u2019s weights W are reused at every time step,forcing the model to learn generic time step-to-time stepdynamics (as opposed to dynamics conditioned on t, thesequence index) and preventing the parameter size fromgrowing in proportion to the maximum sequence length.In most of our experiments, the visual feature transformation \u03c6 corresponds to the activations in some layer ofa deep CNN. Using a visual transformation \u03c6V (.) whichis time-invariant and independent at each time step has theimportant advantage of making the expensive convolutionalinference and training parallelizable over all time steps ofthe input, facilitating the use of fast contemporary CNNimplementations whose efficiency relies on independentbatch processing, and end-to-end optimization of the visualand sequential model parameters V and W .We consider three vision problems (activity recognition,image description and video description), each of whichinstantiates one of the following broad classes of sequentiallearning tasks:2)3)Sequential input, static output (Figure 3, left):hx1 , x2 , ..., xT i 7\u2192 y . The visual activity recognitionproblem can fall under this umbrella, with videosof arbitrary length T as input, but with the goalof predicting a single label like running or jumpingdrawn from a fixed vocabulary.Static input, sequential output (Figure 3, middle):x 7\u2192 hy1 , y2 , ..., yT i. The image captioning problemfits in this category, with a static (non-time-varying)image as input, but a much larger and richer labelspace consisting of sentences of any length.Sequential input and output (Figure 3, right):hx1 , x2 , ..., xT i 7\u2192 hy1 , y2 , ..., yT 0 i. In tasks such asvideo description, both the visual input and outputare time-varying, and in general the number of0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence4Activity RecognitionSequences in the InputCNNLSTMAverageHighJump<BOS>CRFCNNLSTMVideo DescriptionSequences in the Input and OutputCNNCNNLSTMImage CaptioningSequences in the OutputLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMAmanruns<EOS>Amanjumpshigh<EOS><BOS>Fig. 3. Task-specific instantiations of our LRCN model for activity recognition, image description, and video description.input and output time steps may differ (i.e., we mayhave T 6= T 0 ). In video description, for example, thenumber of frames in the video should not constrainthe length of (number of words in) the naturallanguage description.In the previously described generic formulation of recurrent models, each instance has T inputs hx1 , x2 , ..., xT iand T outputs hy1 , y2 , ..., yT i. Note that this formulationdoes not align cleanly with any of the three problem classesdescribed above \u2013 in the first two classes, either the inputor output is static, and in the third class, the input lengthT need not match the output length T 0 . Hence, we describehow we adapt this formulation in our hybrid model to eachof the above three problem settings.With sequential inputs and static outputs (class 1), wetake a late-fusion approach to merging the per-time steppredictions hy1 , y2 , ..., yT i into a single prediction y for thefull sequence. With static inputs x and sequential outputs(class 2), we simply duplicate the input x at all T timesteps: \u2200t \u2208 {1, 2, ..., T } : xt := x. Finally, for a sequenceto-sequence problem with (in general) different input andoutput lengths (class 3), we take an \u201cencoder-decoder\u201dapproach, as proposed for machine translation by [9], [20].In this approach, one sequence model, the encoder, mapsthe input sequence to a fixed-length vector, and another sequence model, the decoder, unrolls this vector to a sequentialoutput of arbitrary length. Under this type of model, a runof the full system on one instance occurs over T +T 0 \u22121 timesteps. For the first T time steps, the encoder processes theinput x1 , x2 , ..., xT , and the decoder is inactive until timestep T , when the encoder\u2019s output is passed to the decoder,which in turn predicts the first output y1 . For the latter T 0 \u22121time steps, the decoder predicts the remainder of the output y2 , y3 , ..., yT 0 with the encoder inactive. This encoderdecoder approach, as applied to the video description task,is depicted in Section 6, Figure 5 (left).Under the proposed system, the parameters (V, W )of the model\u2019s visual and sequential components canbe jointly optimized by maximizing the likelihood ofthe ground truth outputs yt at each time step t, conditioned on the input data and labels up to that point(x1:t , y1:t\u22121 ). In particular, for a training set D of labeledsequences (xt , yt )Tt=1 \u2208 D, we optimize parameters (V, W )to minimize the expected negative log likelihood of asequence sampled from the training set L(V, W, D) =PT1 P\u2212 |D|t=1 log P (yt |x1:t , y1:t\u22121 , V, W ).(xt ,yt )Tt=1 \u2208DOne of the most appealing aspects of the described system is the ability to learn the parameters \u201cend-to-end,\u201d suchthat the parameters V of the visual feature extractor learnto pick out the aspects of the visual input that are relevantto the sequential classification problem. We train our LRCNmodels using stochastic gradient descent, with backpropagation used to compute the gradient \u2207V,W L(V, W, D\u0303) ofthe objective L with respect to all parameters (V, W ) overminibatches D\u0303 \u2282 D sampled from the training dataset D.We next demonstrate the power of end-to-end trainablehybrid convolutional and recurrent networks by exploringthree applications: activity recognition, image captioning,and video description.4ACTIVITY RECOGNITIONActivity recognition is an instance of the first class of sequential learning tasks described above: each frame in alength T sequence is the input to a single convolutionalnetwork (i.e., the convnet weights are tied across time). Weconsider both RGB and flow as inputs to our recognitionsystem. Flow is computed with [21] and transformed into a\u201cflow image\u201d by scaling and shifting x and y flow values toa range of [\u2212128, +128]. A third channel for the flow imageis created by calculating the flow magnitude.During training, videos are resized to 240 \u00d7 320 and weaugment our data by using 227 \u00d7 227 crops and mirroring.Additionally, we train the LRCN networks with video clipsof 16 frames, even though the UCF101 videos are generallymuch longer (on the order of 100 frames when extractingframes at 30 FPS). Training on shorter video clips can beseen as analogous to training on image crops and is a usefulmethod of data augmentation. LRCN is trained to predictthe video\u2019s activity class at each time step. To produce asingle label prediction for an entire video clip, we averagethe label probabilities \u2013 the outputs of the network\u2019s softmaxlayer \u2013 across all frames and choose the most probable label.At test time, we extract 16 frame clips with a stride of 8frames from each video and average across all clips from asingle video.The CNN base of LRCN in our activity recognitionexperiments is a hybrid of the CaffeNet [12] reference model(a minor variant of AlexNet [17]) and the network used0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence5by Zeiler & Fergus [22]. The network is pre-trained onthe 1.2M image ILSVRC-2012 [23] classification trainingsubset of the ImageNet [24] dataset, giving the network astrong initialization to facilitate faster training and avoidoverfitting to the relatively small video activity recognitiondatasets. When classifying center crops, the top-1 classification accuracy is 60.2% and 57.4% for the hybrid and CaffeNetreference models, respectively.We compare LRCN to a single frame baseline model.In our baseline model, T video frames are individuallyclassified by a CNN. As in the LSTM model, whole videoclassification is done by averaging scores across all videoframes.4.1ModelSingle frameLRCN-fc6Weighted1/2, 1/275.4680.90Average1/3, 2/378.9482.34TABLE 1Activity recognition: Comparing single frame models to LRCN networksfor activity recognition on the UCF101 [25] dataset, with RGB and flowinputs. Average values across all three splits are shown. LRCNconsistently and strongly outperforms a model based on predictionsfrom the underlying convolutional network architecture alone.LabelBoxingPunchingBagHighJumpJumpRopeCricketShotBasketballWallPushupsNunchucksApplyEyeMakeupHeadMassageDrummingEvaluationWe evaluate our architecture on the UCF101 dataset [25]which consists of over 12,000 videos categorized into 101human action classes. The dataset is split into three splits,with just under 8,000 videos in the training set for each split.We explore various hyperparameters for the LRCN activity recognition architecture. To explore different variants, wedivide the first training split of UCF101 into a smaller training set (\u22486,000 videos) and a validation set (\u22483,000 videos).We find that the most influential hyperparameters includethe number of hidden units in the LSTM and whether f c6or f c7 features are used as input to the LSTM. We comparenetworks with 256, 512, and 1024 LSTM hidden units. Whenusing flow as an input, more hidden units leads to betterpeformance with 1024 hidden units yielding a 1.7% boost inaccuracy in comparison to a network with 256 hidden unitson our validation set. In contrast, for networks with RGBinput, the number of hidden units has little impact on theperformance of the model. We thus use 1024 hidden unitsfor flow inputs, and 256 for RGB inputs. We find that usingf c6 as opposed to f c7 features improves accuracy whenusing flow as input on our validation set by 1%. When usingRGB images as input, the difference between using f c6 orf c7 features is quite small; using f c6 features only increasesaccuracy by 0.2%. Because both models perform better withf c6 features, we train our final models using f c6 features(denoted by LRCN-f c6 ). We also considered subsamplingthe frames input to the LSTM, but found that this hurtsperformance compared with using all frames. Additionally,when training the LRCN network end-to-end, we found thataggressive dropout (0.9) was needed to avoid overfitting.Table 1 reports the average accuracy across the threestandard test splits of UCF101. Columns 2-3, compare videoclassification of LRCN against the baseline single framearchitecture for both RGB and flow inputs. LRCN yields thebest results for both RGB and flow and improves upon thebaseline network by 0.83% and 2.91% respectively. RGB andflow networks can be combined by computing a weightedaverage of network scores as proposed in [4]. Like [4],we report two weighted averages of the predictions fromthe RGB and flow networks in Table 1 (right). Since theflow network outperforms the RGB network, weighting theflow network higher unsurprisingly leads to better accuracy.In this case, LRCN outperforms the baseline single-framemodel by 3.40%.Table 2 compares LRCN\u2019s accuracy with the single framebaseline model for individual classes on Split 1 of UCF101.Single Input TypeRGBFlow67.3774.3768.2077.28\u220640.8229.7328.9528.5728.5725.7122.8622.7321.9517.78LabelBoxingSpeedBagMixingKnittingTypingSkiingBaseballPitchBrushingTeethSkijetHaircutTennisSwing\u2206-16.22-15.56-14.71-13.95-12.50-11.63-11.11-10.71-9.10-8.16TABLE 2Activity recognition: comparison of improvement \u2206 in LRCN\u2019s per-classrecognition accuracy versus the single-frame baseline. Here we reportresults on all three splits of UCF101 (only results on the first split werepresented in the paper). \u2206 is the difference between LRCN\u2019s accuracyand the single-frame model\u2019s accuracy.For the majority of classes, LRCN improves performanceover the single frame model. Though LRCN performs worseon some classes including Knitting and Mixing, in generalwhen LRCN performs worse, the loss in accuracy is notas substantial as the gain in accuracy for classes like BoxingPunchingBag and HighJump. Consequently, accuracy ishigher overall.Table 3 compares accuracies for the LRCN flow andLRCN RGB models for individual classes on Split 1 ofUCF101. Note that for some classes the LRCN flow modeloutperforms the LRCN RGB model and vice versa. Oneexplanation is that activities which are better classified bythe LRCN RGB model are best determined by which objectsare present in the scene, while activities which are betterclassified by the LRCN flow model are best classified by thekind of motion in the scene. For example, activity classeslike Typing are highly correlated with the presence of certainobjects, such as a keyboard, and are thus best learned by theLRCN RGB model. Other activities such as SoccerJugglinginclude more generic objects which are frequently seenin other activities (soccer balls, people) and are thus bestidentified from class-specific motion cues. Because RGB andflow signals are complementary, the best models take bothinto account.LRCN shows clear improvement over the baselinesingle-frame system and is comparable to accuracy achievedby other deep models. [4] report the results on UCF101by computing a weighted average between flow and RGBnetworks and achieve 87.6%. [3] reports 65.4% accuracy onUCF101, which is substantially lower than LRCN.5I MAGE CAPTIONINGIn contrast to activity recognition, the static image captioning task requires only a single invocation of a convolutionalnetwork since the input consists of a single image. At eachtime step, both the image features and the previous word0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence6LabelBoxingPunchingBagPushUpsJumpRopeSoccerJugglingHandstandWalkingBasketballBodyWeightSquatsLungesNunchucksWallPushups\u220657.1453.3350.0048.7244.1240.0038.4637.8434.2934.29LabelTypingTennisSwingFieldHockeyPenaltyBrushingTeethCuttingInKitchenSkijetMixingSkiingKnittingFloorGymnasticsR@1\u2206-44.19-42.86-32.50-30.56-30.30-28.57-26.67-25.00-20.59-19.44DeViSE [30]SDT-RNN [29]DeFrag [28]m-RNN [27]ConvNet [31]LRCN2f (ours)R@10Medr6.78.910.312.611.817.521.929.831.431.234.040.332.741.144.541.546.350.825161316139Image to Caption (Flickr30k)DeViSE [30]SDT-RNN [29]DeFrag [28]m-RNN [27]ConvNet [31]LRCN2f (ours)TABLE 3Activity recognition: comparison of per-class recognition accuracybetween the flow and RGB LRCN models. \u2206 is the difference betweenLRCN flow accuracy and LRCN RGB accuracy.are provided as inputs to the sequence model, in this case astack of LSTMs (each with 1000 hidden units), which is usedto learn the dynamics of the time-varying output sequence,natural language.At time step t, the input to the bottom-most LSTM is theembedded word from the previous time step yt\u22121 . Inputwords are encoded as \u201cone-hot\u201d vectors: vectors y \u2208 RKwith a single non-zero component yi = 1 denoting the ithword in the vocabulary, where K is the number of wordsin the vocabulary, plus one additional entry for the <BOS>(beginning of sequence) token which is always taken as y0 ,the \u201cprevious word\u201d at the first time step (t = 1). Theseone-hot vectors are then projected into an embedding spacewith dimension de by multiplication We yt with a learnedparameter matrix We \u2208 Rde \u00d7K . The result of a matrixvector multiplication with a one-hot vector is the columnof the matrix corresponding to the index of the single nonzero component of the one-hot vector. We can therefore bethought of as a \u201clookup table,\u201d mapping each of the Kwords in the vocabulary to a de -dimensional vector.The visual feature representation \u03c6V (x) of the image xmay be input to the sequence model \u2013 a stack of L LSTMs\u2013 by concatenating it at each time step either with (1) theembedded previous word We yt\u22121 and fed into the first(`\u22121)LSTM of the stack, or (2) the hidden state htoutputfrom LSTM ` \u2212 1 and fed into LSTM `, for some ` \u2208 2, ..., L.These choices are depicted in Figure 4. We refer to thelatter choice as \u201cfactored,\u201d as it forces a sort of separationof responsibilities by \u201cblinding\u201d the first ` \u2212 1 LSTMs andforcing all of the capacity of their hidden states at time stept to represent only the partial caption y1:t\u22121 independentof the visual input, while the LSTMs starting from ` areresponsible for fusing the lower layer\u2019s hidden state givenby the partial caption with the visual feature representation(`)\u03c6V (x) to produce a joint hidden state representation htof the visual and language inputs up to time step t fromwhich the next word yt can be predicted. In the factoredcase, the hidden state ht for the lower layers is conditionallyindependent of the image x given the partial caption y1:t\u22121 .The outputs of the final LSTM in the stack are theinputs to a learned linear prediction layer with a softmaxproducing a distribution P (yt |y1:t\u22121 , \u03c6V (x)) over words ytin the model\u2019s vocabulary, including the <EOS> token denoting the end of the caption, allowing the model to predictcaptions of varying length. The visual model \u03c6V used forour image captioning experiments is either the CaffeNet [12]reference model, a variant of AlexNet [17], or the moreR@5Caption to Image (Flickr30k)4.59.616.418.414.823.618.129.840.240.239.246.629.241.154.750.950.958.32616810107TABLE 4Image description: retrieval results for the Flickr30k [32] datasets.R@K is the average recall at rank K (high is good). Medr is themedian rank (low is good).modern and computationally expensive VGGNet [18] modelpre-trained for ILSVRC-2012 [23] classification.Without any explicit language modeling or impositionson the structure of the generated captions, the describedLRCN system learns mappings from images input as pixelintensity values to natural language descriptions that areoften semantically descriptive and grammatically correct.At training time, the previous word inputs y1:t\u22121 at timestep t are from the ground truth caption. For inference ofcaptions on a novel image x, the input is a sample y\u0303t \u223cP (yt |y\u03031:t\u22121 , \u03c6V (x)) from the model\u2019s predicted distributionat the previous time step, and generation continues until an<EOS> (end of sequence) token is generated.5.1EvaluationWe evaluate our image description model for retrieval andgeneration tasks. We first demonstrate the effectiveness ofour model by quantitatively evaluating it on the image andcaption retrieval tasks proposed by [26] and seen in [27],[28], [29], [30], [31]. We report results on Flickr30k [32], andCOCO 2014 [33] datasets, both with five captions annotatedper image.5.1.1RetrievalRetrieval results on the Flickr30k [32] dataset are recorded inTable 4. We report median rank, Medr, of the first retrievedground truth image or caption and Recall@K , the numberof images or captions for which a correct caption or image isretrieved within the top K results. Our model consistentlyoutperforms the strong baselines from recent work [27],[28], [29], [30], [31] as can be seen in Table 4. Here, wenote that the VGGNet model in [31] (called OxfordNet intheir work) outperforms our model on the retrieval task.However, VGGNet is a stronger convolutional network [18]than that used for our results on this task. The strengthof our sequence model (and integration of the sequenceand visual models) can be more directly measured againstthe ConvNet [31] result, which uses a very similar baseCNN architecture (AlexNet [17], where we use CaffeNet)pretrained on the same data.We also ablate the model\u2019s retrieval performance on arandomly chosen subset of 1000 images (and 5000 captions) from the COCO 2014 [33] validation set. Results are0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence7CNNCNNCNN<BOS>LSTMLSTMAmanSingle Layer (L = 1)LRCN1u<BOS>LSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMAmanAman<BOS>Two Layers (L = 2), UnfactoredLRCN2uTwo Layers (L = 2), FactoredLRCN2fFig. 4. Three variants of the LRCN image captioning architecture that we experimentally evaluate. We explore the effect of depth in the LSTMstack, and the effect of the \u201cfactorization\u201d of the modalities.recorded in Table 5. The first group of results for eachtask examines the effectiveness of an LSTM compared witha \u201cvanilla\u201d RNN as described in Section 2. These resultsdemonstrate that the use of the LSTM unit compared tothe simpler RNN architecture is an important element ofour model\u2019s performance on this task, justifying the additional complexity and suggesting that the LSTM\u2019s gatingmechanisms allowing for \u201clong-term\u201d memory may be quiteuseful, even for relatively simple sequences.Within the second and third result groups, we compareperformance among the three sequence model architecturalvariants depicted in Figure 4. For both tasks and under allmetrics, the two layer, unfactored variant (LRCN2u ) performs worse than the other two. The fact that LRCN1u outperforms LRCN2u indicates that stacking additional LSTMlayers alone is not beneficial for this task. The other twovariants (LRCN2f and LRCN1u ) perform similarly acrossthe board, with LRCN2f appearing to have a slight edgein the image to caption task under most metrics, but thereverse for caption to image retrieval.Unsurprisingly, finetuning the CNN (indicated by the\u201cFT?\u201d column of Table 5) and using a more powerful CNN(VGGNet [18] rather than CaffeNet) each improve resultssubstantially across the board. Finetuning boosts the R@kmetrics by 3-5% for CaffeNet, and 5-8% for VGGNet. Switching from CaffeNet to VGGNet improves results by around8-12% for the caption to image task, and by roughly 11-17%for the image to caption task.5.1.2 GenerationWe evaluate LRCN\u2019s caption generation performance onthe COCO2014 [33] dataset using the official metrics onwhich COCO image captioning submissions are evaluated.The BLEU [34] and METEOR [36] metrics were designedfor automatic evaluation of machine translation methods.ROUGE-L [37] was designed for evaluating summarizationperformance. CIDEr-D [35] was designed specifically toevaluate the image captioning task.In Table 6 we evaluate variants of our model along thesame axes as done for the retrieval tasks in Table 5. In thelast of the three groups of results, we additionally exploreand evaluate various caption generation strategies that canVision ModelSequence ModelRetrieval PerformanceCNNFT?UnitLFactor?R@1R@5R@10MedrCaffeNetCaffeNet-RNNLSTM22XX21.325.051.756.267.270.654CaffeNetCaffeNetCaffeNet-LSTMLSTMLSTM122X25.223.425.056.254.856.270.869.370.6454CaffeNetCaffeNetCaffeNetXXXLSTMLSTMLSTM122X28.525.627.260.057.259.674.572.274.7444VGGNetVGGNetXLSTMLSTM22XX33.539.368.174.780.885.932CaffeNetCaffeNet-RNNLSTM22XX30.233.861.065.372.675.343CaffeNetCaffeNetCaffeNet-LSTMLSTMLSTM122X32.329.933.864.560.865.375.672.775.3333CaffeNetCaffeNetCaffeNetXXXLSTMLSTMLSTM122X36.133.136.368.463.767.379.576.980.6332VGGNetVGGNetXLSTMLSTM22XX46.053.377.484.388.391.921Caption to ImageImage to CaptionTABLE 5Retrieval results (image to caption and caption to image) for a randomlychosen subset (1000 images) of the COCO 2014 [33] validation set.R@K is the average recall at rank K (high is good). Medr is themedian rank (low is good).be employed for a given network. The simplest strategy,and the one employed for most of our generation resultsin our prior work [43], is to generate captions greedily;i.e., by simply choosing the most probable word at eachtime step. This is equivalent to (and denoted in Table 6 by)beam search with beam width 1. In general, beam searchwith beam width N approximates the most likely captionby retaining and expanding only the N current most likelypartial captions, according to the model. We find that of thebeam search strategies, a beam width of 3-5 gives the bestgeneration numbers \u2013 performance saturates quickly andeven degrades for larger beam width (e.g., 10).An alternative, non-deterministic generation strategy isto randomly sample N captions from the model\u2019s distribution and choose the most probable among these. Under0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence8Generation StrategyVision ModelBeamWidthCNNFT?UnitLFactor?B1B2B3B4CMRSampleNTSequence ModelGeneration Performance (COCO 2014 [33] Validation Set)11--CaffeNetCaffeNet-RNNLSTM22XX0.6380.6460.4540.4620.3150.3210.2200.2240.6600.6740.2090.2100.4730.477111--CaffeNetCaffeNetCaffeNet-LSTMLSTMLSTM122X0.6540.6530.6460.4750.4700.4620.3330.3280.3210.2310.2300.2240.6610.6820.6740.2090.2120.2100.4800.4800.477111--CaffeNetCaffeNetCaffeNetXXXLSTMLSTMLSTM122X0.6610.6590.6590.4850.4780.4780.3440.3380.3360.2410.2380.2370.7020.7160.7170.2160.2170.2180.4890.4860.48611--VGGNetVGGNetXLSTMLSTM22XX0.6740.6950.4940.5190.3510.3740.2480.2680.7730.8390.2270.2370.4970.512-1001001.51.5CaffeNetCaffeNet-RNNLSTM22XX0.6470.6570.4660.4780.3340.3440.2440.2510.7030.7200.2120.2150.4790.485-1001001001.51.51.5CaffeNetCaffeNetCaffeNet-LSTMLSTMLSTM122X0.6640.6640.6570.4900.4860.4780.3540.3520.3440.2540.2570.2510.7040.7320.7200.2110.2160.2150.4880.4890.485-1001001001.51.51.5CaffeNetCaffeNetCaffeNetXXXLSTMLSTMLSTM122X0.6790.6720.6700.5070.4950.4930.3700.3610.3580.2680.2650.2640.7530.7620.7640.2190.2220.2220.4990.4950.495-1001001.51.5VGGNetVGGNetXLSTMLSTM22XX0.6900.7110.5140.5410.3770.4020.2780.3000.8280.8960.2310.2420.5080.5241234510--VGGNetVGGNetVGGNetVGGNetVGGNetVGGNetXXXXXXLSTMLSTMLSTMLSTMLSTMLSTM222222XXXXXX0.6950.7070.7080.7060.7040.6990.5190.5330.5360.5340.5330.5280.3740.3940.3990.3980.3980.3950.2680.2910.2980.2990.3000.2980.8390.8790.8880.8880.8880.8860.2370.2420.2430.2430.2420.2410.5120.5200.5210.5210.5200.518-110251002.02.02.02.0VGGNetVGGNetVGGNetVGGNetXXXXLSTMLSTMLSTMLSTM2222XXXX0.6580.7080.7120.7140.4720.5340.5400.5430.3270.3910.3980.4020.2240.2860.2940.2970.7330.8680.8850.8890.2220.2390.2410.2420.4830.5190.5230.524-1001001001.01.52.0VGGNetVGGNetVGGNetXXXLSTMLSTMLSTM222XXX0.6740.7110.7140.4940.5410.5430.3570.4020.4020.2610.3000.2970.8050.8960.8890.2280.2420.2420.4940.5240.524TABLE 6Image caption generation performance (under the BLEU 1-4 [34] (B1-B4), CIDEr-D [35] (C), METEOR [36] (M), and ROUGE-L [37] (R) metrics)across various network architectures and generation strategies. In the topmost set of results, we show performance across various CNN andrecurrent architectures for a simple generation strategy \u2013 beam search with beam width 1 (i.e., simply choosing the most probable word at eachtime step). In the middle set of results, we show performance across the same set of architectures for a more sophisticated and computationallyintensive generation strategy found to be the best performing (in terms of performance under the CIDEr-D metric) among those explored in thebottom-most set of results, which explores various generation strategies while fixing the choice of network. In the first two sets of results, we varythe visual input CNN architecture (either CaffeNet [12], an architecture similar to AlexNet [17], or the more modern VGGNet [18]) and whether itsweights are finetuned (FT?). Keeping the visual input CNN fixed with CaffeNet, we also vary the choice of recurrent architecture, comparing astack of \u201cvanilla\u201d RNNs with LSTMs [7], as well as the number of layers in the stack L, and (for L = 2) whether the layers are \u201cfactored\u201d (i.e.,whether the visual input is passed into the second layer). In the last set of results, we explore two generation strategies \u2013 beam search, andchoosing the best (highest log-likelihood) among N samples from the model\u2019s predicted distribution. For beam search we vary the beam widthfrom 1-10. For the sampling strategy we explore the effect of sample size N as well as the effect of applying various choices of scalar factor T(inverse of the \u201ctemperature\u201d) to the logits input to the softmax producing the distribution.this strategy we also examine the effect of applying variouschoices of scalar factors (inverse of the \u201ctemperature\u201d) T tothe real-valued predictions input to the softmax producingthe distribution. For larger values of T the samples aregreedier and less diverse, with T = \u221e being equivalent tobeam search with beam width 1. Larger values of N suggestusing smaller values of T , and vice versa \u2013 for example,with large N and large T , most of the O(N ) computation iswasted as many of the samples will be redundant. We assesssaturation as the number of samples N grows, and find thatN = 100 samples with T = 2 improves little over N = 25.We also varied the temperature T among values 1, 1.5, and2 (all with N = 100) and found T = 1.5 to perform the best.We adopt the best-performing generation strategy fromthe bottom-most set of results in Table 6 (sampling withT = 1.5, N = 100) as the strategy for the middle setof results in the table, which ablates LRCN architectures.We also record generation performance for all architectures(Table 6, top set of results) with the simpler generationstrategy used in our earlier work [43] for ease of comparisonwith this work and for future researchers. For the remainderof this discussion, we will focus on the middle set ofresults, and particularly on the CIDEr-D [35] (C) metric,as it was designed specifically for automatic evaluation ofimage captioning systems. We see again that the LSTM unitoutperforms an RNN unit for generation, though not assignificantly as for retrieval. Between the sequence modelarchitecture choices (depicted in Figure 4) of the numberof layers L and whether to factor, we see that in thiscase the two-layer models (LRCN2f and LRCN2u ) performsimilarly, outperforming the single layer model (LRCN1u ).Interestingly, of the three variants, LRCN2f is the only one0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence9Generation Performance (COCO 2014 [33] Test Set)Method(Ours)(Ours)[38][39][40]*[41][42][33][27][43][44][31][45]NICMSR Captivatorm-RNN (2015)LRCN, this work (sample)MSRNearest NeighborHumanm-RNN (2014)LRCN (greedy)Show, Attend, and TellMLBLNeuralTalkB1B2B3B4CMR0.8950.9070.8900.8950.8800.8720.8800.8900.8710.8720.8480.8280.8020.8190.7980.8040.7890.7700.7440.8010.7720.7680.7470.7010.6940.7100.6870.6950.6780.6550.6030.6900.6530.6440.6330.5660.5870.6010.5750.5850.5670.5420.4710.5780.5340.5230.5170.4460.9460.9370.9350.9340.9250.9160.9100.8960.8910.8780.7520.6920.3460.3390.3250.3350.3310.3180.3350.3200.3220.3230.2940.2800.6820.6800.6660.6780.6620.6480.6260.6680.6560.6510.6350.603TABLE 7Image caption generation results from top-performing methods in the 2015 COCO caption challenge competition, sorted by performance under theCIDEr-D metric. (We omit submissions that did not provide a reference to a report describing their method; see full results athttps://mscoco.org/dataset/#captions-leaderboard.) All results except for our updated result (denoted by LRCN, this work) were competition entries(submitted by May 2015). Our updated result differs from our original competition entry only by generation strategy (sampling with N = 100,T = 1.5, rather than beam search with width 1; i.e., greedy search); the visual and recurrent architectures (and trained weights) are the same.to perform best for both retrieval and generation.We see again that fine-tuning (FT) the visual representation and using a stronger vision model (VGGNet [18])improves results significantly. Fine-tuning improves CIDErD by roughly 0.04 points for CaffeNet, and by roughly 0.07points for VGGNet. Switching from finetuned CaffeNet toVGGNet improves CIDEr-D by 0.13 points.In Table 7 we compare generation performance withcontemporaneous and recent work submitted to the 2015COCO caption challenge using our best-performing method(under the CIDEr-D metric) from the results on the validation set described above \u2013 generating a caption for a singleimage by taking the best of N = 100 samples with a scalarfactor of T = 1.5 applied to the softmax inputs, using anLRCN model which pairs a fine-tuned VGGNet with ourLRCN2f (two layer, factored) sequence model architecture.Our results are competitive with the contemporary work,performing 4th best in CIDEr-D (0.934, compared with thebest result of 0.946 from [38]), and 3rd best in METEOR(0.335, compared with 0.346 from [38]).In addition to standard quantitative evaluations, we alsoemploy Amazon Mechnical Turk workers (\u201cTurkers\u201d) toevaluate the generated sentences. Given an image and aset of descriptions from different models, we ask Turkersto rank the sentences based on correctness, grammar andrelevance. We compared sentences from our model to theones made publicly available by [31]. As seen in Table 8,our fine-tuned (FT) LRCN model performs on par with theNearest Neighbour (NN) on correctness and relevance, andbetter on grammar.We show sample captions in Figure 6. We additionallynote some properties of the captions our model generates.When using the VGG model to generate sentences in thevalidation set, we find that 33.7% of our generated setencesexactly match a sentence in the training set. Furthermore,we find that when using a beam size of one, our modelgenerates 42% of the vocabulary words used by humanannotators when describing images in the validation set.Some words, such as \u201clady\u201d and \u201cguy\u201d, are not generatedby our model but are commonly used by human annotators,but synonyms such as \u201cwoman\u201d and \u201cman\u201d are two of themost common words generated by our model.CorrectnessGrammarRelevanceTreeTalk [46]VGGNet [31]NN [31]LRCN fc8 (ours)LRCN FT (ours)4.083.713.443.743.474.353.463.203.193.013.983.703.493.723.50Captions2.553.722.59TABLE 8Image description: Human evaluator rankings from 1-6 (low is good)averaged for each method and criterion. We evaluated on 785 Flickrimages selected by the authors of [31] for the purposes of comparisonagainst this similar contemporary approach.6V IDEO DESCRIPTIONIn video description the LSTM framework allows us tomodel the video as a variable length input stream. However, due to the limitations of available video descriptiondatasets, we rely on more \u201ctraditional\u201d activity and videorecognition processing for the input and use LSTMs forgenerating a sentence. We first distinguish the followingarchitectures for video description (see Figure 5). For eacharchitecture, we assume we have predictions of activity, tool,object, and locations present in the video from a CRF basedon the full video input. In this way, we observe the video aswhole at each time step, not incrementally frame by frame.(a) LSTM encoder & decoder with CRF max. (Figure 5(a)) This architecture is motivated by the video description approach presented in [11]. They first recognizea semantic representation of the video using the maximuma posteriori (MAP) estimate of a CRF with video featuresas unaries. This representation, e.g., hknife,cut,carrot,cuttingboardi, is concatenated into an input sequence (knife cutcarrot cutting board) which is translated to a natural languagesentence (a person cuts a carrot on the board) using statisticalmachine translation (SMT) [47]. We replace SMT with anencoder-decoder LSTM, which encodes the input sequenceas a fixed length vector before decoding to a sentence.(b) LSTM decoder with CRF max. (Figure 5(b)) In thisvariant we provide the full visual input representation ateach time step to the LSTM, analogous to how an image isprovided as an input to the LSTM in image captioning.(c) LSTM decoder with CRF probabilites. (Figure 5(c))A benefit of using LSTMs for machine translation compared0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence10VisualInputCRF-maxboard[0, 1, 0, 0\u2026]LSTMLSTMCRFcuttingboardcutting[1, 0, 0, 0\u2026]LSTMLSTMcutcut[0, 0, 1, 0...]LSTMLSTMknifeknife[0, 0, 0, 1\u2026]LSTMLSTMLSTMLSTMALSTMLSTMLSTMLSTMDecoderEncoderInputOne HotSentenceVisualInput[0, 1, 0, 0\u2026] [0, 0, 1, 0...] [0, 0, 0, 1\u2026]LSTMLSTMman[0, 1, 0, 0\u2026] [0, 0, 1, 0...] [0, 0, 0, 1\u2026]LSTMLSTMcuts[0, 1, 0, 0\u2026] [0, 0, 1, 0...] [0, 0, 0, 1\u2026]LSTM<EOS>[0, 1, 0, 0\u2026] [0, 0, 1, 0...] [0, 0, 0, 1\u2026](a)LSTM Encoder-DecoderCRF-probcuttingboardcutknife[0, 0.8, 0.2, 0\u2026][0.3, 0, 0.7, 0\u2026][0, 0.1, 0.2, 0.7\u2026]LSTMLSTMALSTM[0, 0.8, 0.2, 0\u2026][0.3, 0, 0.7, 0\u2026][0, 0.1, 0.2, 0.7\u2026]LSTMLSTMmanLSTMLSTM[0, 0.8, 0.2, 0\u2026][0.3, 0, 0.7, 0\u2026][0, 0.1, 0.2, 0.7\u2026]LSTMLSTMcutsLSTMLSTM[0, 0.8, 0.2, 0\u2026][0.3, 0, 0.7, 0\u2026][0, 0.1, 0.2, 0.7\u2026]LSTMLSTM<EOS>(b)LSTM Decoder (CRF-max)CRF(c)LSTM Decoder (CRF-prob)Fig. 5. Our approaches to video description. (a) LSTM encoder & decoder with CRF max (b) LSTM decoder with CRF max (c) LSTM decoder withCRF probabilities.ArchitectureInputSMT [11]SMT [48](a) LSTM Encoder-Decoder (ours)(b) LSTM Decoder (ours)(c) LSTM Decoder (ours)CRF maxCRF probCRF maxCRF maxCRF probBLEU24.926.925.327.428.8TABLE 9Video description: Results on detailed description of TACoS multilevel[48], in %, see Section 6 for details.to phrase-based SMT [47] is that it can naturally incorporateprobability vectors during training and test time whichallows the LSTM to learn uncertainties in visual generationrather than relying on MAP estimates. The architecture isthe the same as in (b), but we replace max predictions withprobability distributions.6.1EvaluationWe evaluate our approach on the TACoS multilevel [48]dataset, which has 44,762 video/sentence pairs (about40,000 for training/validation). We compare to [11] who usemax prediction as well as a variant presented in [48] whichtakes CRF probabilities at test time and uses a word latticeto find an optimal sentence prediction. Since we use themax prediction as well as the probability scores providedby [48], we have an identical visual representation. [48]uses dense trajectories [49] and SIFT features as well astemporal context reasoning modeled in a CRF. In this setof experiments we use the two-layered, unfactored versionof LRCN, as described for image description.Table 9 shows the BLEU-4 score. The results show that(1) the LSTM outperforms an SMT-based approach to videodescription; (2) the simpler decoder architecture (b) and(c) achieve better performance than (a), likely because theinput does not need to be memorized; and (3) our approachachieves 28.8%, clearly outperforming the best reportednumber of 26.9% on TACoS multilevel by [48].More broadly, these results show that our architecture isnot restricted only to input from deep networks, but can becleanly integrated with fixed or variable length inputs fromother vision systems.7R ELATED W ORKWe present previous literature pertaining to the three tasksdiscussed in this work. Additionally, we discuss subsequentextensions which combine convolutional and recurrent networks to achieve improved results on activity recognition,image captioning, and video description as well as relatednew tasks such as visual question answering.7.1Prior WorkActivity Recognition. State-of-the-art shallow models combine spatio-temporal features along dense trajectories [50]and encode features as bags of words or Fisher vectorsfor classification. Such shallow features track how lowlevel features change through time but cannot track higherlevel features. Furthermore, by encoding features as bags ofwords or Fisher vectors, temporal relationships are lost.Many deep architectures proposed for activity recognition stack a fixed number of video frames for input to adeep network. [3] propose a fusion convolutional networkwhich fuses layers which correspond to different inputframes at various levels of a deep network. [4] proposesa two stream CNN which combines one CNN trainedon RGB frames and one CNN trained on a stack of 10flow frames. When combining RGB and flow by averagingsoftmax scores, results are comparable to state-of-the-artshallow models on UCF101 [25] and HMDB51 [51]. Resultsare further improved by using an SVM to fuse RGB andflow as opposed to simply averaging scores. Alternatively,[1] and [2] propose learning deep spatio-temporal featureswith 3D convolutional neural networks. [2], [52] proposeextracting visual and motion features and modeling temporal dependencies with recurrent networks. This architecturemost closely resembles our proposed architecture for activity classification, though it differs in two key ways. First, weintegrate 2D CNNs that can be pre-trained on large imagedatasets. Second, we combine the CNN and LSTM into asingle model to enable end-to-end fine-tuning.Image Captioning. Several early works [53], [54], [55],[56] on image captioning combine object and scene recognition with template or tree based approaches to generatecaptions. Such sentences are typically simple and are easilydistinguished from more fluent human generated descriptions. [46], [57] address this by composing new sentencesfrom existing caption fragments which, though more humanlike, are not necessarily accurate or correct.More recently, a variety of deep and multi-modal models[27], [29], [30], [58] have been proposed for image and caption retrieval, as well as caption generation. Though some ofthese models rely on deep convolutional nets for image feature extraction [30], [58], recently researchers have realizedthe importance of also including temporally deep networks0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence11to model text. [29] propose an RNN to map sentences intoa multi-modal embedding space. By mapping images andlanguage into the same embedding space, they are able tocompare images and descriptions for image and annotationretrieval tasks. [27] propose a model for caption generationthat is more similar to the model proposed in this work:predictions for the next word are based on previous wordsin a sentence and image features. [58] propose an encoderdecoder model for image caption retrieval which relies onboth a CNN and LSTM encoder to learn an embedding ofimage-caption pairs. Their model uses a neural languagedecoder to enable sentence generation. As evidenced by therapid growth of image captioning, visual sequence modelslike LRCN are increasingly important for describing thevisual world using natural language.Video Description. Recent approaches to describingvideo with natural language have made use of templates,retrieval, or language models [11], [59], [60], [60], [61], [62],[63], [64]. To our knowledge, we present the first applicationof deep models to the video description task. Most similarto our work is [11], which use phrase-based SMT [47] togenerate a sentence. In Section 6 we show that phrase-basedSMT can be replaced with LSTMs for video description ashas been shown previously for language translation [9], [65].7.2Contemporaneous and Subsequent WorkSimilar work in activity recognition and visual descriptionwas conducted contemporaneously with our work, and avariety of subsequent work has combined convolutional andrecurrent networks to both improve upon our results andachieve exciting results on other sequential visual tasks.Activity Recognition. Contemporaneous with our work,[66] train a network which combines CNNs and LSTMs foractivity recognition. Because activity recognition datasetslike UCF101 are relatively small in comparison to imagerecognition datasets, [66] pretrain their network using theSports-1M [3] dataset which includes over a million videosmined from YouTube. By training a much larger network(four stacked LSTMs) and pretraining on a large videodataset, [66] achieve 88.6% on the UCF101 dataset.[67] also combines a convolutional network with anLSTM to predict multiple activities per frame. Unlike LRCN,[67] focuses on frame-level (rather than video-level) predictions, which allows their system to label multiple activitiesthat occur in different temporal locations of a video clip.Like we show for activity recognition, [67] demonstratesthat including temporal information improves upon a single frame baseline. Additionally, [67] employ an attentionmechanism to further improve results.Image Captioning. [45] and [38] also propose modelswhich combine a CNN with a recurrent network for imagecaptioning. Though similar to LRCN, the architectures proposed in [45] and [38] differ in how image features are inputinto the sequence model. In contrast to our system, in whichimage features are input at each time step, [45] and [38]only input image features at the first time step. Furthermore,they do not explore a \u201cfactored\u201d representation (Figure 4).Subsequent work [44] has proposed attention to focus onwhich portion of the image is observed during sequencegeneration. By including attention, [44] aim to visuallyfocus on the current word generated by the model. Otherworks aim to address specific limitations of captioningmodels based on combining convolutional and recurrentarchitectures. For example, methods have been proposedto integrate new vocabulary with limited [40] or no [68]examples of images and corresponding captions.Video Description. In this work, we rely on intermediate features for video description, but end-to-end trainablemodels for visual captioning have since been proposed. [69]propose creating a video feature by pooling high level CNNfeatures across frames. The video feature is then used togenerate descriptions in the same way an image is used togenerate a description in LRCN. Though achieving goodresults, by pooling CNN features, temporal informationfrom the video is lost. Consequently, [70] propose an LSTMto encode video frames into a fixed length vector beforesentence generation with an LSTM. Using an end-to-endtrainable \u201csequence-to-sequence\u201d model which can exploittemporal structure in video, [70] improve upon results forvideo description. [71] propose a similar model, adding atemporal attention mechanism which weights video framesdifferently when generating each word in a sentence.Visual Grounding. [72] combine CNNs with LSTMs forvisual grounding. The model first encodes a phrase whichdescribes part of an image using an LSTM, then learns toattend to the appropriate location in the image to accuratelyreconstruct the phrase. In order to reconstruct the phrase,the model must learn to visually ground the input phrase tothe appropriate location in the image.Natural Language Object Retrieval. In this work, wepresent methods for image retrieval based on a naturallanguage description. In contrast, [73] use a model based onLRCN for object retrieval, which returns the bounding boxaround a given object as opposed to an entire image. In order to adapt LRCN to the task of object retrieval, [73] includelocal convolutional features which are extracted from objectproposals and the spatial configuration of object proposalsin addition to a global image feature. By including localfeatures, [73] effectively adapt LRCN for object retrieval.8C ONCLUSIONWe\u2019ve presented LRCN, a class of models that is bothspatially and temporally deep, and flexible enough to beapplied to a variety of vision tasks involving sequentialinputs and outputs. Our results consistently demonstratethat by learning sequential dynamics with a deep sequencemodel, we can improve upon previous methods which learna deep hierarchy of parameters only in the visual domain,and on methods which take a fixed visual representationof the input and only learn the dynamics of the outputsequence.As the field of computer vision matures beyond taskswith static input and predictions, deep sequence modelingtools like LRCN are increasingly central to vision systemsfor problems with sequential structure. The ease with whichthese tools can be incorporated into existing visual recognition pipelines makes them a natural choice for perceptual problems with time-varying visual input or sequentialoutputs, which these methods are able to handle with littleinput preprocessing and no hand-designed features.0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence12A female tennis player in action onthe court.A group of young men playing agame of soccerA man riding a wave on top of asurfboard.A baseball game in progress with thebatter up to plate.A brown bear standing on top of alush green field.A person holding a cell phone intheir hand.A close up of a person brushing histeeth.A woman laying on a bed in a bedroom.A black and white cat is sitting on achair.A large clock mounted to the side ofa building.A bunch of fruit that are sitting on atable.A toothbrush holder sitting on top ofa white sink.Fig. 6. Image description: images with corresponding captions generated by our finetuned LRCN model. These are images 1-12 of our randomlychosen validation set from COCO 2014 [33]. We used beam search with a beam size of 5 to generate the sentences, and display the top (highestlikelihood) result above.0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence13ACKNOWLEDGMENTSThe authors thank Oriol Vinyals for valuable advice andhelpful discussion throughout this work. This work wassupported in part by DARPA\u2019s MSEE and SMISC programs,NSF awards IIS-1427425 and IIS-1212798, and the BerkeleyVision and Learning Center. The GPUs used for this researchwere donated by NVIDIA. Marcus Rohrbach was supportedby a fellowship within the FITweltweit-Program of theGerman Academic Exchange Service (DAAD). Lisa AnneHendricks was supported by the NDSEG.R EFERENCES[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22][23]S. Ji, W. Xu, M. Yang, and K. Yu, \u201c3D convolutional neuralnetworks for human action recognition,\u201d in IEEE Trans. PatternAnal. Mach. Intell., 2013.M. Baccouche, F. Mamalet, C. Wolf, C. Garcia, and A. Baskurt, \u201cSequential deep learning for human action recognition,\u201d in HumanBehavior Understanding, 2011.A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, andL. Fei-Fei, \u201cLarge-scale video classification with convolutionalneural networks,\u201d in CVPR, 2014.K. Simonyan and A. Zisserman, \u201cTwo-stream convolutional networks for action recognition in videos,\u201d in NIPS, 2014.D. E. Rumelhart, G. E. Hinton, and R. J. Williams, \u201cLearninginternal representations by error propagation,\u201d DTIC Document,Tech. Rep., 1985.R. J. Williams and D. Zipser, \u201cA learning algorithm for continuallyrunning fully recurrent neural networks,\u201d in Neural Computation,1989.S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d inNeural Computation. MIT Press, 1997.A. Graves and N. Jaitly, \u201cTowards end-to-end speech recognitionwith recurrent neural networks,\u201d in ICML, 2014.I. Sutskever, O. Vinyals, and Q. V. Le, \u201cSequence to sequencelearning with neural networks,\u201d in NIPS, 2014.K. Cho, B. van Merrie\u0308nboer, D. Bahdanau, and Y. Bengio, \u201cOnthe properties of neural machine translation: Encoder-decoderapproaches,\u201d in SSST Workshop, 2014.M. Rohrbach, W. Qiu, I. Titov, S. Thater, M. Pinkal, and B. Schiele,\u201cTranslating video content to natural language descriptions,\u201d inICCV, 2013.Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick,S. Guadarrama, and T. Darrell, \u201cCaffe: Convolutional architecturefor fast feature embedding,\u201d in ACM MM, 2014.W. Zaremba and I. Sutskever, \u201cLearning to execute,\u201d in arXivpreprint arXiv:1410.4615, 2014.A. Graves, \u201cGenerating sequences with recurrent neural networks,\u201d in arXiv preprint arXiv:1308.0850, 2013.O. Vinyals, S. V. Ravuri, and D. Povey, \u201cRevisiting recurrent neuralnetworks for robust ASR,\u201d in ICASSP, 2012.I. Sutskever, J. Martens, and G. E. Hinton, \u201cGenerating text withrecurrent neural networks,\u201d in ICML, 2011.A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u201cImageNet classification with deep convolutional neural networks,\u201d in NIPS, 2012.K. Simonyan and A. Zisserman, \u201cVery deep convolutional networks for large-scale image recognition,\u201d in ICLR, 2015.C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,D. Erhan, V. Vanhoucke, and A. Rabinovich, \u201cGoing deeper withconvolutions,\u201d in CVPR, 2015.K. Cho, B. van Merrienboer, C. Gulcehre, F. Bougares, H. Schwenk,and Y. Bengio, \u201cLearning phrase representations using rnnencoder-decoder for statistical machine translation,\u201d in EMNLP,2014.T. Brox, A. Bruhn, N. Papenberg, and J. Weickert, \u201cHigh accuracyoptical flow estimation based on a theory for warping,\u201d in ECCV,2004.M. D. Zeiler and R. Fergus, \u201cVisualizing and understanding convolutional networks,\u201d in ECCV, 2014.O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, andL. Fei-Fei, \u201cImageNet Large Scale Visual Recognition Challenge,\u201din IJCV, vol. 115, no. 3, 2015.[24] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, \u201cImageNet: A large-scale hierarchical image database,\u201d in CVPR, 2009.[25] K. Soomro, A. R. Zamir, and M. Shah, \u201cUCF101: A dataset of 101human actions classes from videos in the wild,\u201d CRCV-TR-12-01,Tech. Rep., 2012.[26] P. Y. Micah Hodosh and J. Hockenmaier, \u201cFraming image description as a ranking task: Data, models and evaluation metrics,\u201d inJAIR, vol. 47, 2013.[27] J. Mao, W. Xu, Y. Yang, J. Wang, and A. Yuille, \u201cDeep captioningwith multimodal recurrent neural networks (m-RNN),\u201d in ICLR,2015.[28] A. Karpathy, A. Joulin, and L. Fei-Fei, \u201cDeep fragment embeddings for bidirectional image sentence mapping,\u201d in NIPS, 2014.[29] R. Socher, A. Karpathy, Q. V. Le, C. D. Manning, and A. Y. Ng,\u201cGrounded compositional semantics for finding and describingimages with sentences,\u201d in TACL, vol. 2, 2014.[30] A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, T. Mikolovet al., \u201cDevise: A deep visual-semantic embedding model,\u201d inNIPS, 2013.[31] R. Kiros, R. Salakhuditnov, and R. S. Zemel, \u201cUnifying visualsemantic embeddings with multimodal neural language models,\u201din TACL, 2015.[32] M. H. Peter Young, Alice Lai and J. Hockenmaier, \u201cFrom imagedescriptions to visual denotations: New similarity metrics forsemantic inference over event descriptions,\u201d in TACL, vol. 2, 2014.[33] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,P. Dolla\u0301r, and C. L. Zitnick, \u201cMicrosoft COCO: Common objects incontext,\u201d arXiv preprint arXiv:1405.0312, Tech. Rep., 2014.[34] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \u201cBLEU: a methodfor automatic evaluation of machine translation,\u201d in ACL, 2002.[35] R. Vedantam, C. L. Zitnick, and D. Parikh, \u201cCIDEr: Consensusbased image description evaluation,\u201d in CVPR, 2015.[36] S. Banerjee and A. Lavie, \u201cMETEOR: An automatic metric for MTevaluation with improved correlation with human judgments,\u201d inProceedings of the ACL Workshop on Intrinsic and Extrinsic EvaluationMeasures for Machine Translation and/or Summarization, 2005.[37] C.-Y. Lin, \u201cRouge: A package for automatic evaluation of summaries,\u201d in Text Summarization Branches Out: Proceedings of the ACL04 Workshop, 2004.[38] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, \u201cShow and tell: Aneural image caption generator,\u201d in CVPR, 2015.[39] J. Devlin, H. Cheng, H. Fang, S. Gupta, L. Deng, X. He, G. Zweig,and M. Mitchell, \u201cLanguage models for image captioning: Thequirks and what works,\u201d in ACL, 2015.[40] J. Mao, W. Xu, Y. Yang, J. Wang, Z. Huang, and A. Yuille, \u201cLearninglike a child: Fast novel visual concept learning from sentencedescriptions of images,\u201d in ICCV, 2015.[41] H. Fang, S. Gupta, F. Iandola, R. Srivastava, L. Deng, P. Dolla\u0301r,J. Gao, X. He, M. Mitchell, J. Platt et al., \u201cFrom captions to visualconcepts and back,\u201d in CVPR, 2015.[42] J. Devlin, S. Gupta, R. Girshick, M. Mitchell, and C. L. Zitnick,\u201cExploring nearest neighbor approaches for image captioning,\u201darXiv preprint arXiv:1505.04467, Tech. Rep., 2015.[43] J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach,S. Venugopalan, K. Saenko, and T. Darrell, \u201cLong-term recurrentconvolutional networks for visual recognition and description,\u201d inCVPR, 2015.[44] K. Xu, J. Ba, R. Kiros, A. Courville, R. Salakhutdinov, R. Zemel, andY. Bengio, \u201cShow, attend and tell: Neural image caption generationwith visual attention,\u201d in ICML, 2015.[45] A. Karpathy and L. Fei-Fei, \u201cDeep visual-semantic alignments forgenerating image descriptions,\u201d in CVPR, 2015.[46] P. Kuznetsova, V. Ordonez, T. L. Berg, U. C. Hill, and Y. Choi,\u201cTreeTalk: Composition and compression of trees for image descriptions,\u201d in TACL, vol. 2, no. 10, 2014.[47] P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico,N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer,O. Bojar, A. Constantin, and E. Herbst, \u201cMoses: Open sourcetoolkit for statistical machine translation,\u201d in ACL, 2007.[48] A. Rohrbach, M. Rohrbach, W. Qiu, A. Friedrich, M. Pinkal,and B. Schiele, \u201cCoherent multi-sentence video description withvariable level of detail,\u201d in German Conference on Pattern Recognition(GCPR). Springer, 2014.[49] H. Wang, A. Kla\u0308ser, C. Schmid, and C. Liu, \u201cDense trajectoriesand motion boundary descriptors for action recognition,\u201d in IJCV,2013.0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2599174, IEEETransactions on Pattern Analysis and Machine Intelligence14[50] H. Wang and C. Schmid, \u201cAction recognition with improvedtrajectories,\u201d in ICCV, 2013.[51] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre, \u201cHMDB:a large video database for human motion recognition,\u201d in ICCV,2011.[52] M. Baccouche, F. Mamalet, C. Wolf, C. Garcia, and A. Baskurt, \u201cAction classification in soccer videos with long short-term memoryrecurrent neural networks,\u201d in International Conference on ArtificialNeural Networks (ICANN), 2010.[53] A. Farhadi, M. Hejrati, M. Sadeghi, P. Young, C. Rashtchian,J. Hockenmaier, and D. Forsyth, \u201cEvery picture tells a story:Generating sentences from images,\u201d in ECCV, 2010.[54] G. Kulkarni, V. Premraj, S. Dhar, S. Li, Y. Choi, A. C. Berg, and T. L.Berg, \u201cBaby talk: Understanding and generating simple imagedescriptions,\u201d in CVPR, 2011.[55] Y. Yang, C. L. Teo, H. Daume\u0301 III, and Y. Aloimonos, \u201cCorpusguided sentence generation of natural images,\u201d in EMNLP, 2011.[56] M. Mitchell, X. Han, J. Dodge, A. Mensch, A. Goyal, A. Berg,K. Yamaguchi, T. Berg, K. Stratos, and H. Daume\u0301 III, \u201cMidge:Generating image descriptions from computer vision detections,\u201din Proceedings of the 13th Conference of the European Chapter of theAssociation for Computational Linguistics, 2012.[57] P. Kuznetsova, V. Ordonez, A. C. Berg, T. L. Berg, and Y. Choi,\u201cCollective generation of natural image descriptions,\u201d in ACL,2012.[58] R. Kiros, R. Salakhutdinov, and R. Zemel, \u201cMultimodal neurallanguage models,\u201d in ICML, 2014.[59] S. Guadarrama, N. Krishnamoorthy, G. Malkarnenkar, S. Venugopalan, R. Mooney, T. Darrell, and K. Saenko, \u201cYouTube2Text:Recognizing and describing arbitrary activities using semantichierarchies and zero-shoot recognition,\u201d in ICCV, 2013.[60] M. U. G. Khan, L. Zhang, and Y. Gotoh, \u201cHuman focused videodescription,\u201d in ICCV Workshops, 2011.[61] A. Barbu, A. Bridge, Z. Burchill, D. Coroian, S. Dickinson, S. Fidler,A. Michaux, S. Mussman, S. Narayanaswamy, D. Salvi, L. Schmidt,J. Shangguan, J. M. Siskind, J. Waggoner, S. Wang, J. Wei, Y. Yin,and Z. Zhang, \u201cVideo in sentences out,\u201d in The Conference onUncertainty in Artificial Intelligence (UAI), 2012.[62] P. Das, C. Xu, R. Doell, and J. Corso, \u201cThousand frames in justa few words: Lingual description of videos through latent topicsand sparse object stitching,\u201d in CVPR, 2013.[63] C. C. Tan, Y.-G. Jiang, and C.-W. Ngo, \u201cTowards textually describing complex video contents with audio-visual concept classifiers,\u201din ACM MM, 2011.[64] J. Thomason, S. Venugopalan, S. Guadarrama, K. Saenko, and R. J.Mooney, \u201cIntegrating language and vision to generate naturallanguage descriptions of videos in the wild,\u201d in InternationalConference on Computational Linguistics (COLING), 2014.[65] H. Sak, O. Vinyals, G. Heigold, A. Senior, E. McDermott, R. Monga,and M. Mao, \u201cSequence discriminative distributed training of longshort-term memory recurrent neural networks,\u201d in Interspeech,2014.[66] J. Y.-H. Ng, M. Hausknecht, S. Vijayanarasimhan, O. Vinyals,R. Monga, and G. Toderici, \u201cBeyond short snippets: Deep networks for video classification,\u201d in CVPR, 2015.[67] S. Yeung, O. Russakovsky, N. Jin, M. Andriluka, G. Mori, andL. Fei-Fei, \u201cEvery moment counts: Dense detailed labeling ofactions in complex videos,\u201d arXiv preprint arXiv:1507.05738, Tech.Rep., 2015.[68] L. A. Hendricks, S. Venugopalan, M. Rohrbach, R. Mooney,K. Saenko, and T. Darrell, \u201cDeep compositional captioning: Describing novel object categories without paired training data,\u201d inCVPR, 2016.[69] S. Venugopalan, H. Xu, J. Donahue, M. Rohrbach, R. Mooney, andK. Saenko, \u201cTranslating videos to natural language using deeprecurrent neural networks,\u201d in NAACL, 2015.[70] S. Venugopalan, M. Rohrbach, J. Donahue, R. Mooney, T. Darrell,and K. Saenko, \u201cSequence to sequence\u2013video to text,\u201d in ICCV,2015.[71] L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, andA. Courville, \u201cDescribing videos by exploiting temporal structure,\u201d in CVPR, vol. 1050, 2015.[72] A. Rohrbach, M. Rohrbach, R. Hu, T. Darrell, and B. Schiele,\u201cGrounding of textual phrases in images by reconstruction,\u201d arXivpreprint arXiv:1511.03745, Tech. Rep., 2015.[73] R. Hu, H. Xu, M. Rohrbach, J. Feng, K. Saenko, and T. Darrell,\u201cNatural language object retrieval,\u201d in CVPR, 2016.Jeff Donahue is a PhD student at the University of California, Berkeley,advised by Prof. Trevor Darrell. His research focuses on the use of deeplearning for computer vision applications. He graduated with a BS incomputer science from the University of Texas at Austin, where he wasadvised by Prof. Kristen Grauman.Lisa Anne Hendricks is a PhD student at the University of California,Berkeley. Her research focuses on deep learning for sequential modelsas well as applications at the intersection of language and vision. She isadvised by Prof. Trevor Darrell. Lisa Anne holds a Bachelor\u2019s of Sciencein Electrical Engineering (B.S.E.E.) from Rice University.Marcus Rohrbach\u2019s research focuses on visual recognition, languageunderstanding, and machine learning. He received his BSc and MScdegree in Computer Science from the University of Technology Darmstadt, Germany, in 2006 and 2009, respectively. From 2006-2007, hespent one year at the University of British Columbia as a graduatevisiting student. During his PhD he worked at the Max Planck Institutefor Informatics, Saarbru\u0308cken, Germany with Bernt Schiele and ManfredPinkal. He completed it in 2014 with summa cum laude at SaarlandUniversity and received the DAGM MVTec Dissertation Award 2015 forit. He currently works as a post-doc with Trevor Darrell at UC Berkeley.Subhashini Venugopalan is a PhD student at the University of Texas atAustin. Her research focuses on deep learning techniques to generatedescriptions for events in videos. She is advised by Prof. RaymondMooney. Subhashini holds a master\u2019s degree in Computer Science fromIIT Madras and a bachelor\u2019s degree from NIT Karnataka, India.Sergio Guadarrama is a Software Engineer at Google Research, wherehe works in Machine Perception as a member of the Vale team. Hereceived his PhD from the Technical University of Madrid, followed bypostdoctoral work at the European Center for Soft Computing. Afterthat, he was first a Visiting Scholar and then a Research Scientist atUC Berkeley EECS. His research spans the areas of computer vision,language and deep learning. Dr. Guadarrama\u2019s current research focusis on new network architectures for multi-task dense predictions, suchas object detection, instance segmentation, depth prediction and visualquestion-answering. He has received research grants from the Government of Spain, such as the Juan de la Cierva Award (Early Career Awardin Computer Science), and the Mobility Grant for Postdoctoral Research.Kate Saenko is an Assistant Professor of Computer Science at theUniversity of Massachusetts Lowell, where she leads the ComputerVision and Learning Group. She received her PhD from MIT, followedby postdoctoral work at UC Berkeley EECS and Harvard SEAS. Herresearch spans the areas of computer vision, machine learning, andhuman-robot interfaces. Dr. Saenko\u2019s current research interests includedomain adaptation of machine learning models and joint modeling oflanguage and vision. She is the recipient of research grant awards fromthe National Science Foundation, DARPA, and other government andindustry agencies.Trevor Darrell is on the faculty of the CS Division of the EECS Department at UC Berkeley and is also appointed at the UCB-affiliated International Computer Science Institute (ICSI). He is the director of the Berkeley Vision and Learning Center (BVLC) and is the faculty director of thePATH center in the UCB Institute of Transportation Studies PATH. Hisinterests include computer vision, machine learning, computer graphics,and perception-based human computer interfaces. Prof. Darrell receivedthe SM and PhD degrees from MIT in 1992 and 1996, respectively. Hewas previously on the faculty of the MIT EECS department from 19992008, where he directed the Vision Interface Group. He was a memberof the research staff at Interval Research Corporation from 1996-1999.He obtained the BSE degree from the University of Pennsylvania in1988, having started his career in computer vision as an undergraduateresearcher in Ruzena Bajcsy\u2019s GRASP lab.0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\f", "Knowledge-Based Systems 80 (2015) 14\u201323Contents lists available at ScienceDirectKnowledge-Based Systemsjournal homepage: www.elsevier.com/locate/knosysTransfer learning using computational intelligence: A surveyJie Lu \u21d1, Vahid Behbood, Peng Hao, Hua Zuo, Shan Xue, Guangquan ZhangDecision Systems & e-Service Intelligence Lab, Centre for Quantum Computation & Intelligent Systems, Faculty of Engineering and Information Technology, University ofTechnology Sydney, PO Box 123, Broadway, NSW 2007, Australiaa r t i c l ei n f oArticle history:Received 3 December 2014Received in revised form 7 January 2015Accepted 17 January 2015Available online 22 January 2015Keywords:Transfer learningComputational intelligenceNeural networkBayesFuzzy sets and systemsGenetic algorithma b s t r a c tTransfer learning aims to provide a framework to utilize previously-acquired knowledge to solve new butsimilar problems much more quickly and effectively. In contrast to classical machine learning methods,transfer learning methods exploit the knowledge accumulated from data in auxiliary domains to facilitatepredictive modeling consisting of different data patterns in the current domain. To improve the performance of existing transfer learning methods and handle the knowledge transfer process in real-worldsystems, computational intelligence has recently been applied in transfer learning. This paper systematically examines computational intelligence-based transfer learning techniques and clusters relatedtechnique developments into four main categories: (a) neural network-based transfer learning; (b)Bayes-based transfer learning; (c) fuzzy transfer learning, and (d) applications of computationalintelligence-based transfer learning. By providing state-of-the-art knowledge, this survey will directlysupport researchers and practice-based professionals to understand the developments in computationalintelligence-based transfer learning research and applications.\u00d3 2015 Elsevier B.V. All rights reserved.1. IntroductionAlthough machine learning technologies have attracted aremarkable level of attention from researchers in different computational \ufb01elds, most of these technologies work under the commonassumption that the training data (source domain) and the testdata (target domain) have identical feature spaces with underlyingdistribution. As a result, once the feature space or the feature distribution of the test data changes, the prediction models cannot beused and must be rebuilt and retrained from scratch using newlycollected training data, which is very expensive and sometimes notpractically possible. Similarly, since learning-based models needadequate labeled data for training, it is nearly impossible to establish a learning-based model for a target domain which has very fewlabeled data available for supervised learning. If we can transferand exploit the knowledge from an existing similar but not identical source domain with plenty of labeled data, however, we canpave the way for construction of the learning-based model forthe target domain. In real world scenarios, there are many situations in which very few labeled data are available, and collecting\u21d1 Corresponding author.E-mail addresses: jie.lu@uts.edu.au (J. Lu), vahid.behbood@uts.edu.au(V. Behbood), peng.hao@student.uts.edu.au (P. Hao), hua.zuo@student.uts.edu.au(H. Zuo), shan.xue@student.uts.edu.au (S. Xue), guangquan.zhang@uts.edu.au(G. Zhang).https://dx.doi.org/10.1016/j.knosys.2015.01.0100950-7051/\u00d3 2015 Elsevier B.V. All rights reserved.new labeled training data and forming a particular model are practically impossible.Transfer learning has emerged in the computer science literature as a means of transferring knowledge from a sourcedomain to a target domain. Unlike traditional machine learningand semi-supervised algorithms [1\u20134], transfer learning considersthat the domains of the training data and the test data may be different [5]. Traditional machine learning algorithms make predictions on the future data using mathematical models that aretrained on previously collected labeled or unlabeled training datawhich is the same as future data [6\u20138]. Transfer learning, in contrast, allows the domains, tasks, and distributions used in trainingand testing to be different. In the real world, we observe manyexamples of transfer learning. We may \ufb01nd that learning to recognize apples might help us to recognize pears, or learning to play theelectronic organ may facilitate learning the piano. The study oftransfer learning has been inspired by the fact that human beingscan utilize previously-acquired knowledge to solve new but similarproblems much more quickly and effectively. The fundamentalmotivation for transfer learning in the \ufb01eld of machine learningfocuses on the need for lifelong machine learning methods thatretain and reuse previously learned knowledge. Research on transfer learning has been undertaken since 1995 under a variety ofnames: learning to learn; life-long learning; knowledge transfer;meta learning; inductive transfer; knowledge consolidation; context sensitive learning and multi-task learning [9]. In 2005, the\f15J. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323Broad Agency Announcement of the Defense Advanced ResearchProjects Agency\u2019s Information Processing Technology Of\ufb01ce gavea new mission to transfer learning: the ability of a system to recognize and apply knowledge and skills learned in previous tasks tonovel tasks. In this de\ufb01nition, transfer learning aims to extractthe knowledge from one or more source tasks and then apply theknowledge to a target task. Traditional machine learning techniques only try to learn each task from scratch, while transferlearning techniques try to transfer the knowledge from other tasksand/or domains to a target task when the latter has few high-quality training data.Several survey papers on transfer learning have been publishedin the last few years. For example, the paper by [9] presented anextensive overview of transfer learning and different categories.However, these papers focus on transfer learning techniques andapproaches only; none of them discusses how the computationalintelligence approach can be used in transfer learning. Since thecomputational intelligence approach has been applied in transferlearning more recently and has already demonstrated its advantage, this survey is timely.There are three main types of articles being reviewed in thissurvey: Type 1 \u2013 articles on transfer learning techniques (includingrelated methods and approaches) and Type 2 \u2013 articles on transferlearning using computational intelligence techniques. Type 3 \u2013articles on related computational intelligence techniques. Thesearch and selection of these articles were performed accordingto the following \ufb01ve steps:Step 1. Publication database identi\ufb01cation and determination:The eminent publication databases such as Science Direct,ACM Digital Library, IEEE Xplore and SpringerLink, weresearched to provide a comprehensive bibliography of researchpapers on transfer learning and transfer learning using computational intelligence.Step 2. Type 1 article selection: These papers were selectedaccording to the two criteria: (1) novelty; and (2) impact- published in high quality (high impact factor) journals, or in conference proceedings or book chapters but with high citations1.These types of article are mainly used in Section 2.Step 3. Preliminary screening of Type 2 articles: The search was\ufb01rst performed based on related keywords of computationalintelligence in transfer learning.Step 4. Result \ufb01ltering for Type 2 articles: The keywords of thepreliminary references were extracted and clustered manually.Based on the keywords related to application domain, thesepapers were divided, using \u2018\u2018topic clustering\u2019\u2019, into four groups:(a) Neural Network in transfer learning; (b) Bayes in transferlearning; (c) fuzzy and genetic algorithm in transfer learningand (d) application of transfer learning. This article selectionprocess was based on the following criteria: (1) novelty \u2013 published within the last few years; (2) impact \u2013 see Step 2; (3)coverage \u2013 reported a new or particular application domain;and (4) typicality \u2013 only the most typical methodology andapplications were retained.Step 5. Type 3 article selection: These papers were selectedaccording to the requirement of Step 4, aiming to introducerelated concepts of computational intelligence techniques.The main contributions of this paper are: (1) it comprehensivelyand perceptively summarizes research achievements on transferlearning from the point of view of applications of computationalintelligence, and strategically clusters the transfer learning into1\u2018\u2018high citation\u2019\u2019 means that the citation of the paper is greater than the averagecitation rates listed in the \u2018\u2018ISI Web of Knowledge \u2013 Essential Science Indicators\u2019\u2019, andthe citation per year of the paper is larger than 1.four computational intelligence application domains; (2) for eachcomputational intelligence technique it carefully analyses typicaltransfer learning frameworks and effectively identi\ufb01es the speci\ufb01crequirements of computational intelligence techniques in transferlearning. This will directly support researchers and practitionersto promote the popularization and application of computationalintelligence in transfer learning in different domains; and (3) it alsocovers several very new transfer learning techniques with computational intelligence, and reveals their successful applications.The remainder of this paper is structured as follows. In Section 2,the transfer learning techniques are reviewed and analyzed. Sections 3\u20135 respectively present the 4 main application domains oftransfer learning. Section 6 discusses the applications of computational intelligence-based transfer learning methods. Section 7presents our analysis and main \ufb01ndings.2. Basic transfer learning techniquesTo understand and analyze the application developments oftransfer learning by using computational intelligence, this section\ufb01rst reviews the main transfer learning techniques. The notationsand de\ufb01nitions that will be used throughout the section are introduced. According to the de\ufb01nitions, we then categorize the varioussettings of transfer learning methods that exist in the literature ofmachine learning.De\ufb01nition 2.1 (Domain [9]). A domain, which is denoted byD \u00bc fv; P\u00f0X\u00deg, consists of two components:(1) Feature space v; and(2) MarginalprobabilityX \u00bc fx1 ; . . . ; xn g 2 v.distributionP\u00f0X\u00de,whereDe\ufb01nition 2.2 (Task [9]). A task, which is denoted by T \u00bc fY; f \u00f0\u0002\u00deg,consists of two components:(1) A label space Y \u00bc fy1 ; . . . ; ym g; and(2) An objective predictive function f \u00f0\u0002\u00de which is not observedand is to be learned by pairs fxi ; yi g.The function f \u00f0\u0002\u00de can be used to predict the corresponding label,f \u00f0xi \u00de, of a new instance xi . From a probabilistic viewpoint, f \u00f0xi \u00de canbe written as P\u00f0yi jxi \u00de. In the bank failure prediction example, whichis a binary prediction task, yi can be the label of failed or survived.More speci\ufb01cally, the source domain can be denoted asDs \u00bc f\u00f0xs1 ; ys1 \u00de; . . . ; \u00f0xsn ; ysn \u00deg where xsi 2 vs is the source instance orbank in the bank failure prediction example and ysi 2 Y s is the corresponding class label which can be failed or survived for bank failureprediction. Similarly, the target domain can be denoted asDt \u00bc f\u00f0xt1 ; yt1 \u00de; . . . ; \u00f0xtn ; ytn \u00deg where xt 2 vt is the target instance andyti 2 Y t is the corresponding class label and in most scenarios tn \u0003 sn .De\ufb01nition 2.3 (Transferand learning task T s , atransfer learning aimspredictive function f t \u00f0\u0002\u00dewhere Ds \u2013Dt or T s \u2013T t .learning [9]). Given a source domain Dstarget domain Dt and learning task T t ,to improve the learning of the targetin Dt using the knowledge in Ds and T sIn the above de\ufb01nition, the condition Ds \u2013Dt implies that eithervs \u2013vt or Ps \u00f0X\u00de\u2013Pt \u00f0X\u00de. Similarly, the condition T s \u2013T t implies thateither Y s \u2013Y t or f s \u00f0\u0002\u00de\u2013f t \u00f0\u0002\u00de. In addition, there are some explicit orimplicit relationships between the feature spaces of two domainssuch that we imply that the source domain and target domainare related. It should be mentioned that when the target and\f16J. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323source domains are the same (Ds \u00bc Dt ) and their learning tasks arealso the same (T s \u00bc T t ), the learning problem becomes a traditionalmachine learning problem.According to the uniform de\ufb01nition of transfer learning introduced by De\ufb01nition 2.3, transfer learning techniques can be divided into three main categories [9]: (1) Inductive transfer learning, inwhich the learning task in the target domain is different from thetarget task in the source domain (T s \u2013T t ); (2) Unsupervised transferlearning which is similar to inductive transfer learning but focuseson solving unsupervised learning tasks in the target domain suchas clustering, dimensionality reduction and density estimation(T s \u2013T t ); and (3) Transductive transfer learning, in which the learning tasks are the same in both domains, while the source and targetdomains are different (T s \u00bc T t ; Ds \u2013Dt \u00de. In the literature, transductive transfer learning, domain adaptation, covariate shift, sampleselection bias, transfer learning, multi-task learning, robust learning, and concept drift are all terms which have been used to handlethe related scenarios. More speci\ufb01cally, when the method aims tooptimize the performance on multiple tasks or domains simultaneously, it is considered to be multi-task learning. If it optimizes performance on one domain, given training data that is from adifferent but related domain, it is considered to be transductivetransfer learning or domain adaptation. Transfer learning andtransductive transfer learning have often been used interchangeably with domain adaptation. Concept drift refers to a scenario inwhich data arrives sequentially with changing distribution, andthe goal is to predict the next batch given the previously-arriveddata [10]. The goal of robust learning is to build a classi\ufb01er thatis less sensitive to certain types of change, such as feature changeor deletion in the test data. In addition, unsupervised domain adaptation can be considered as a form of semi-supervised learning, butit assumes that the labeled training data and the unlabeled testdata are drawn from different distributions. The existing techniques and methods, which have thus far been used to handlethe domain adaptation problem, can be divided into four mainclasses [11]:(1) Instance weighting for covariate shift methods which weightsamples in the source domain to match the target domain.The covariate shift scenario might arise in cases where thetraining data has been biased toward one region of the inputspace or is selected in a non-I.I.D. manner. It is closely related to the idea of sample-selection bias which has long beenstudied in statistics [12] and in recent years it has beenexplored for machine-learning. Huang et al. [13] proposeda novel procedure called Kernel Mean Matching (KMM) toestimate weights on each instance in the source domain,based on the goal of making the weighted distribution ofthe source domain look similar to the distribution of thetarget domain. Sugiyama et al. [14] and Tsuboi et al. [15]proposed a similar idea called the Kullback\u2013Leibler Importance Estimation Procedure (KLIEP). Here too the goal is toestimate weights to maximize similarity between the targetand weight-corrected source distributions.(2) Self-labeling methods which include unlabeled targetdomain samples in the training process and initialize theirlabels and then iteratively re\ufb01ne the labels. Self-traininghas a close relationship with the Expectation Maximization(EM) algorithm, which has hard and soft versions. The hardversion adds samples with single certain labels while thesoft version assigns label con\ufb01dences when \ufb01tting the model. Tan et al. [16] modi\ufb01ed the relative contributions of thesource and target domains in EM. They increased the weighton the target data at each iteration, while Dai et al. [17] speci\ufb01ed the tradeoff between the source and target data termsby estimating KL divergence between the source and targetdistributions, placing more weight on the target data as KLdivergence increases. Self-training methods have beenapplied to domain adaptation on Natural Language Processing (NLP) tasks including parsing [18\u201321]; part-of-speechtagging [22]; conversation summarization [23]; entityrecognition [22,24,25]; sentiment classi\ufb01cation [26]; spamdetection [22]; cross-language document classi\ufb01cation[27,28]; and speech act classi\ufb01cation [29].(3) Feature representation methods which try to \ufb01nd a new feature representation of the data, either to make the target andsource distributions look similar, or to \ufb01nd an abstractedrepresentation for domain-speci\ufb01c features. The feature representation approaches can be categorized into two classes[11]: (A) Distribution similarity approaches aim explicitly tomake the source and target domain sample distributionssimilar, either by penalizing or removing features whosestatistics vary between domains [24,30\u201332] or by learninga feature space projection in which a distribution divergencestatistic is minimized [33\u201335]; (B) Latent feature approachesaim to construct new features by analyzing large amounts ofunlabeled source and target domain data [25,36\u201342].(4) Cluster-based learning methods rely on the assumption thatsamples connected by high-density paths are likely to havethe same label if there is a high density path between them[43]. These methods aim to construct a graph in which thelabeled and unlabeled samples are the nodes, with the edgeweights among samples based on their similarity. Dai et al.[17] proposed a co-clustering based algorithm to propagatethe label information across domains for document classi\ufb01cation. Xue et al. [44] proposed a cross-domain text classi\ufb01cation algorithm known as TPLSA to integrate labeled andunlabeled data from different but related domains.3. Transfer learning using neural networkNeural Network aims to solve complex non-linear problemsusing a learning-based method inspired by human brain structureand processes. In classical machine learning problems, many studies have demonstrated the superior performance of neural networkcompared to statistical methods. This fact has encouraged manyresearchers to use neural network for transfer learning, particularly in complicated problems. To address the problem in transferlearning, a number of neural network-based transfer learning algorithms have been developed in recent years. This section reviewsthree of the principal Neural Network techniques: Deep Neural Network, Multiple Tasks Neural Network, and Radial Basis Function Neural Network, and presents their applications in transfer learning.3.1. Transfer learning using deep neural networkDeep neural network is considered to be an intelligent featureextraction module that offers great \ufb02exibility in extracting highlevel features in transfer learning. The prominent characteristicof deep neural network is its multiple hidden layers, which cancapture the intricate non-linear representations of data. The coreidea of a deep neural network is that unsupervised learning is usedto pre-train each layer, and the output is then the input of the nextlayer. Ultimately, all layers are \ufb01ne-tuned in a supervised learningway. Hubel and Wiesel [45] proposed multi-stage Hubel\u2013Wieselarchitectures that consist of alternating layers of convolutionsand max pooling to extract data features. A new model blendingthe above structure and multiple tasks is proposed for transferlearning [46]. In this model, a target task and related tasks aretrained together with shared input and hidden layers, andseparately output neurons. The model is then extended to the casein which each task has multiple output neurons [47]. Likewise,\fJ. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323based on the multi-stage Hubel\u2013Wiesel architectures, whethershared hidden layers trained by the source task can be reused ona different target task is detected. For the target task model, onlythe last classi\ufb01cation layer needs to be retrained, but any layer ofthe new model could be \ufb01ne-tuned if desired. In this case, the parameters of hidden layers in the source task model act as initialization parameters of the new target task model, and this strategyis especially promising for a model in which good initialization isvery important [48]. As mentioned above, generally all the layersexcept the last layer are treated as feature extractors in a deep neural network. In contrast to this network structure, a new featureextractor structure is proposed by Collobert and Weston [49]. Onlythe \ufb01rst two layers are used to extract features at different levels,such as word level and sentence level in Natural Language Processing. Subsequent layers are classical neural network layers used forprediction. The Stacked Denoising Autoencoder (SDA) is anotherstructure that is presented in deep neural network [50]. Based onthe SDA model, different feature transference strategies are introduced to target tasks with varying degrees of complexity. Thenumber of layers transferred to the new model depends on thehigh-level or low-level feature representations that are needed.This means if low-level features are needed, only the \ufb01rst layerparameters are transferred to the target task [50]. In addition, aninterpolating path is presented to transfer knowledge from thesource task to the target task in a deep neural network. The originalhigh dimensional features of the source and target domains areprojected to lower dimensional subspaces that lie on the Grassmanmanifold, which presents a way to interpolate smoothly betweenthe source and target domains; thus, a series of feature sets is generated on the interpolating path and intermediate feature extractors are formed based on deep neural network [51]. Deep neuralnetworks can also combine with other technology to promotethe performance of transfer learning. Swietojanski et al. [52]applied restricted Boltzmann machine to pre-train deep neuralnetwork, and the outputs of the network are used as features fora hidden Markov model.17an example with a particular task. In light of these problems, Silverand Poirier [58] proposed context-sensitive multiple task learning(csMTL) with two major differences. To eliminate the redundantoutputs and reduce the free parameters, only one neuron is included in the output layer. Another difference is re\ufb02ected in the inputlayer, which can be divided into two parts. Apart from the set ofinput variables for the tasks, the input layer also contains a set ofcontext inputs that associates each training example with a particular task. To verify the effectiveness of csMTL, a set of experiments was designed to detect csMTL and MTL neural networks intheir ability to transfer knowledge [59]. The above model makesthe assumption that each task only has one output neuron. Further,csMTL is extended to learn tasks that have multiple output neurons[60].3.3. Transfer learning using radial basis function neural networksYamauchi [61] considered covariate shift, one category of transfer learning, and incremental learning. Under the assumption thatincremental learning environments are a subset of covariate shift, anovel incremental learning method is presented on the basis ofradial basis function neural network. Further, a number of model-selection criteria are set up to optimize the network; for example, the information criterion [62] is applied to determine thenumber of hidden neurons [63]. In some literatures, neural network acts as a part of the whole algorithm. Liu et al. [64] appliedneural network to initialize the weights of labeled data in thesource domain. Each instance in the source domain is input intothe neural network trained by limited target labeled data to gainthe contribution degree based on the error value. In addition, theneural network is used as pre-processing technique to extract features from high dimensional space to low dimensional space [65].Sometimes, neural network is combined with other intelligenttechniques to form an integrated model to improve the performance of transfer learning [66].3.2. Transfer learning using multiple task neural network4. Transfer learning using BayesTo improve the learning for the target task, multiple task learning (MTL) is proposed. Information contained in other related tasksis used to promote the performance of target task [53]. In multipletask neural network learning, all tasks are trained in parallel usingthe shared input and hidden neurons and separate output neuronsdepending on different tasks [54]. The biggest difference betweenthe MTL here and the MTL in deep neural network is the numberof hidden layers. Generally, the number of hidden layers in MTLis much smaller than in deep neural networks. In MTL, secondarytasks as auxiliary information help the primary task to improveperformance. However, due to different relatedness between secondary tasks and the primary task, the contributions of secondarytasks should be distinguished. Therefore, a modi\ufb01ed version ofmultitask learning called g MTL is introduced. Based on a measureof relatedness between secondary tasks and the primary task, gMTL applies a separate learning rate for each task output neuron[55]. Silver and Mercer [56] presented a task rehearsal method(TRM) to transfer knowledge of secondary tasks to the primary taskat a functional level. Instead of the interrelation between representations of various tasks, the relationship between functions of tasksis the core content in their new model. After demonstrating thegood performance of g MTL and TRM on synthetic tasks, they werepractically applied to a series of medical diagnostic tasks [57]. Inthe MTL model, the output layer consists of a separate neuroncorresponding to each task, which may lead to redundant outputsand overlapping information. In addition, for the continuous tasks,contextual cues must be provided to guide the system to associateBayesian techniques refer to methods that are related to statistical inference and are developed based on Bayesian theorem. ABayesian classi\ufb01er is a probabilistic methodology for solving classi\ufb01cation problems. Since probability is a useful tool for modelingthe uncertainty in the real world and is adequate for quantifyingthe certainty degree of an uncertain truth, Bayesian classi\ufb01er ispopular in the machine learning community. When it comes tothe transfer learning setting, the distribution of the training dataand test data is not identical, so a Bayesian classi\ufb01er trained ontraining data may not be predictive for the test data. To addressthis challenging problem, many Bayesian-based transfer learningalgorithms have been developed in recent years. This sectionreviews three of the main Bayesian techniques: na\u00efve Bayes classi\ufb01er, Bayesian network and the hierarchical Bayesian model, andillustrates their application within the framework of transferlearning.4.1. Transfer learning using Na\u00efve BayesThe na\u00efve Bayes classi\ufb01ers [67] are among the most popularclassi\ufb01ers in real world application. They pose a simple but strongassumption that there is independence between each pair of features (attributes) given the class variables. Though this assumptionis not suitable in most real scenarios, na\u00efve Bayes classi\ufb01ers havenevertheless been proved to work quite well in some complicatedapplications, especially automatic medical diagnosis [68], spam \ufb01ltering [69] and text categorization [70], in which they may even\f18J. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323outperform more advanced algorithms, such as support vectormachine, or random forests. Normally, the probabilistic model fora classi\ufb01er isp\u00f0CjF 1 ; . . . ; F n \u00de \u00bcp\u00f0C\u00dep\u00f0F 1 ; . . . ; F n jC\u00dep\u00f0F 1 ; . . . ; F n \u00de\u00f01\u00dewhere p\u00f0CjF 1 ; . . . ; F n \u00de indicates a posteriori probability of class variable C, conditional on feature variables F1 through Fn. Sincep\u00f0F 1 ; . . . ; F n \u00de has no relation with the class variable and the valueof Fi (i = 1, . . . , n) is observable, the above equation can be expressedasp\u00f0CjF 1 ; . . . ; F n \u00de / p\u00f0C\u00dep\u00f0F 1 ; . . . ; F n jC\u00de\u00f02\u00deUnder the independence assumption adopted by na\u00efve Bayes classi\ufb01er, which meansp\u00f0CjF 1 ; . . . ; F n \u00de / p\u00f0C\u00denYp\u00f0F i jC\u00de\u00f03\u00dei\u00bc1From Eq. (3) we \ufb01nd that a prediction made by a classi\ufb01er dependson the prior probability of the class variable and the product of thelikelihood of each feature variable given a speci\ufb01c class variable. Toestimate each feature\u2019s distribution, it is necessary to make parameter estimation, assuming a prede\ufb01ned distribution (i.e., multinomial distribution or multivariate Bernoulli distribution) orgenerating a non-parametric model for a feature that comes fromtraining data. However, if the test data (new-domain data) followa different distribution from the training data (old-domain data),we cannot obtain an accurate feature distribution estimation forthe new-domain data based on the parameter learned from theold-domain data, which leads to bad prediction performance inthe result. Estimating the feature distribution for new-domain unlabeled data limits the application of the na\u00efve Bayes classi\ufb01er in thetransfer learning setting.To adapt the na\u00efve Bayes classi\ufb01er from the training data to thetest data, [17] proposed a novel na\u00efve Bayes transfer learning(NBTL) classi\ufb01cation algorithm for text categorization. NBTL \ufb01rsttrains a na\u00efve Bayes classi\ufb01er on the training data and appliesthe learned classi\ufb01er on the test data to obtain a pseudo label forthe test data during learning, thereby providing an initial modelestimation for the test data under target distribution. The Expectation\u2013Maximization (EM) algorithm is then applied in iteration to\ufb01nd a local optimal model only for \ufb01tting the target distribution,meaning that the na\u00efve Bayes classi\ufb01er trained on the training datais adapted to the test data. To measure the difference between thedifferent distributions, KL divergence is used to estimate a tradeoff parameter in the NBTL model, and the experiment results showthat the performance of NBTL increases when the distributionbetween the training data and the test data is signi\ufb01cantly different. The main disadvantage of NBTL lies in the fact that the in\ufb02uence of new-domain speci\ufb01c features is ignored. Instead oftreating both old-domain and new-domain data equally, an adaptive na\u00efve Bayes is proposed in [16]. It uses a weighted EM algorithm to dynamically increase the importance of new-domaindata and decrease the weight of old data, while at the same timeemphasizing the usage of both generalizable features drawn fromthe old-domain data and all the features from the new-domaindata for tackling the cross-domain sentiment classi\ufb01cation problem. Roy and Kaelbling [71] developed an alternative method oftransferring the na\u00efve Bayes classi\ufb01er. They \ufb01rst partition the dataset into a number of clusters, such that the data for each cluster forall tasks has the same distribution. Then they train one classi\ufb01erfor each partition; all classi\ufb01ers are then combined using a Dirichlet process.In addition to text classi\ufb01cation, [72] developed a transfer na\u00efveBayes (TNB) algorithm to predict cross-company software defects.The implementation can be summarized in three steps: it \ufb01rst collects maximum and minimum value vectors of the target featurefrom test data, then each feature of a training sample is comparedwith the corresponding part of those two vectors to calculate thenumber of similar attributes and the weight of that traininginstance is computed through a gravitational analogy. After obtaining all the weights for the training data, a prediction model can bebuilt with those weighted training data to classify the test dataset.4.2. Transfer learning using Bayesian networkAssuming total independence between features is not applicable for many real world problems, because the occurrence of anevent may arise as the result of a number of relevant factors. Inother words, there are correlations between features in a decisionregion and the Bayesian network is a suitable representation to thisfact. A Bayesian network is a graphical model that encodesprobabilistic relationships among variables of interest. It consistsof two components: (1) a directed acyclic graph (DAG), which contains nodes and arcs. In particular, the nodes can be observedquantities, latent variables, or unknown parameters, while thedirected arcs re\ufb02ect conditional dependencies among variables,and (2) conditional probability tables (CPTs), which record localprobability distributions associated with each node. Bayesian networks have four distinct advantages when compared to other datamining methods, namely, the ability to handle incomplete datasets, to discover causal relationships hidden in the data, to incorporate both domain knowledge and data into one model, and to avoiddata over-\ufb01tting [73].In a simple case, the graphical model of a Bayesian network canbe constructed by the prior knowledge of an expert. However insome complex applications, the de\ufb01nition of \u2018\u2018network\u2019\u2019 is dif\ufb01cultfor humans, so it is necessary to learn the network structure andparameters of the local distributions from data [74]. To learn aBayesian network from data, one needs to consider two importantphases: structure learning and parameter learning, respectively.The former relates to the learning of a graphical model from data,while the latter deals with the evaluation of condition probabilitydistribution for each variable given the model. To our knowledge,most works focus on structure learning by leveraging previousdata, and less effort is expended on parameter learning.When the training data in a task is scarce, learning a reliableBayesian network is dif\ufb01cult; therefore transfer learning can helpimprove the robustness of learned networks through exploitingdata from related tasks or knowledge from domain experts. In[75], the authors extended the Bayesian network learning from asingle domain (task) to multiple domains (tasks). In this case,instead of learning a structure in isolation, the relationshipsbetween tasks should be taken into account. Similar to the multitask learning scenario, multiple Bayesian network structures arejointly built from multiple related datasets. To make learning ef\ufb01cient, the parameters of Bayesian networks from related tasks areassumed to be independent. The prior is de\ufb01ned in such a way thatit penalizes structures that are different from one another. A scoreand search approach is then performed on the space of multipleBayesian networks to \ufb01nd the best structures, in particular, byde\ufb01ning a suitable search space and devising a branch and boundprocedure that enables ef\ufb01cient moves in this search space. In contrast to learning optimal models simultaneously for different tasks,[76] proposed learning models from auxiliary tasks to improverelated tasks. In this paper, without giving suf\ufb01cient data for independence test, a PC\u2013TL algorithm is developed with considerationof both the con\ufb01dence of the independence tests and the similarityof the auxiliary tasks to the target task in a combined function. Anexample that uses transfer learning to strengthen the quality oflearned Bayesian networks through the use of an inductive bias\fJ. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323may also be found in [77]. The main limitation of such multi-tasknetwork structure learning algorithms lies in the assumption thatall pairs of tasks are equally related, which violates the truth thatdifferent pairs of tasks can differ in their degree of relatedness. Asa result, Oyen and Lane [78] relaxed this assumption by adding atask relatedness metric, which explicitly controls the amount ofinformation sharing between tasks, into a learning objective toincorporate domain knowledge about task-relatedness. Experimental results show that leveraging domain knowledge produces models that are both robust and in accordance with a domain expert\u2019sobjective. Recently, Oyen and Lane [79] pointed out that it is moreappropriate to estimate a posterior distribution over multiplelearned Bayesian networks rather than a single posteriori. In theirpaper, the authors proposed the incorporation of structure bias intoorder-conditional network discovery algorithms to extend networkdiscovery in individual Bayesian network learning [80,81] for transfer network learning.Given a Bayesian network structure, the work of parameterlearning is to estimate the conditional probability tables (CPTs)for each node given the combination of its parent\u2019s nodes. If wehave data from all tasks, then we can directly estimate the CPTsfrom data. However in some cases we only have models from related tasks and need to estimate the CPT for the target task. In [76],two novel aggregation methods were de\ufb01ned. The \ufb01rst calculatesa weighted average of the probabilities from the data of the auxiliary tasks based on the con\ufb01dence of the probability estimatedfrom the auxiliary tasks and the similarity with the target estimates. This average is then combined with the target probabilityestimate, weighted by a factor that depends on its similarity tothe target probability. The second method works similarly, butthe average of probabilities is obtained from those closer to the target rather than from all the data of the auxiliary tasks. In addition,the average is combined to the target estimate with a con\ufb01dencefactor, which is based on the amount of data.4.3. Transfer learning using hierarchical Bayesian modelHierarchical Bayesian models are considered to be a particulartype of Bayesian network and are used when the data are structured in groups. This hierarchical model can represent and reasonabout knowledge at multiple levels of abstraction, therefore a hierarchical Bayesian model provides a uni\ufb01ed framework to explainboth how abstract knowledge is used for induction and howabstract knowledge can be acquired.In considering the problem of multi-task learning, Wilson et al.[82] used a hierarchical Bayesian in\ufb01nite mixture model to modelthe distribution over multiple Markov Decision Processes (MDPs)such that the characteristics of new environments can be quicklyinferred based on the learned distribution as an informed prior.This idea is extended to solve the problem of sequential decision-making tasks [83]. Yang et al. [84] combined all the tasks ina single RBF network and de\ufb01ned a novel Bayesian multi-tasklearning model for non-linear regression. Meanwhile, Raykaret al. [85] presented a novel Bayesian multiple instance learning(MIL) algorithm, which performs feature selection and classi\ufb01erconstruction simultaneously. The results show that the proposedmethod is more accurate and effective when a smaller set of usefulfeatures is selected.In reference to the domain adaptation problem, a novel hierarchical Bayesian domain adaptation model was developed based onthe use of a hierarchical Bayes prior [86]. In the proposed model,several parameters are set to each feature in each domain, andtop level parameters are proposed on the upper level such thatthe Gaussian prior over the parameter values in each domain isnow centered around these top level parameters instead of aroundzero, while the zero-mean Gaussian prior is placed over the top19level parameters. At the same time, Wood and Teh [87] designeda doubly hierarchical Pitman\u2013Yor process language model, inwhich the bottom layer utilizes multiple hierarchical Pitman\u2013Yorprocess language models to represent a number of domains whilethe top layer is responsible for sharing the statistical strength. Amore special case is considered in [88], where only a single example from a new category is provided; thus, it is more dif\ufb01cult toestimate the variance and similarity metric for categorizing anobject in this case. It is possible with this model to encode priorsfor new classes into super-categories. Following the inference ofthe sub-category to which the novel category belongs, the modelcan estimate not only the mean of the new category but also anappropriate similarity metric based on parameters inherited fromthe super-category.5. Transfer learning using fuzzy system and genetic algorithmImprecision, approximation, vagueness and ambiguity of information are driven by the variability encountered when trying tolearn an activity with little information. There is a clear co-dependency on the level of certainty in any learning activity and theamount of information that is available, and problems with littleinformation, can have a high degree of uncertainty.This is why couple of researches appears very recently to applyfuzzy techniques into transfer learning. The use of fuzzy logicallows for the incorporation of approximation and a greaterexpressiveness of the uncertainty within the knowledge transfer.Zadeh [89] introduced the concept of fuzzy sets which he laterexpanded on by introducing further aspects of Fuzzy Logic, including fuzzy rules in [90]. The two primary elements within fuzzy logic, the linguistic variable and the fuzzy if-then rule, are able tomimic the human ability to capture imprecision and uncertaintywithin knowledge transfer. Fuzzy logic forms a major componentof the published Fuzzy Transfer Learning techniques. Behboodet al. [91,92] developed a fuzzy-based transductive transfer learning for long term bank failure prediction in which the distributionof data in the source domain differs from that in the target domain.They applied three classical predictors, Neural Network, SupportVector Machine and Fuzzy Neural Network, to predict the initiallabels for samples in the target domain, then attempted to re\ufb01nethe labels using fuzzy similarity measures. The authors subsequently improved the performance of the fuzzy re\ufb01nement domainadaptation method [93] by developing a novel fuzzy measure tosimultaneously take account of the similarity and dissimilarity inthe re\ufb01nement process. The proposed method has been appliedto text categorization and bank failure prediction. The experimental results demonstrated the superior performance of the proposedmethod compared to popular classical transductive transfer learning methods. Using fuzzy techniques in similarity measurementand label production, the authors revealed the advantage of fuzzylogic in knowledge transfer where the target domain lacks criticalinformation and involves uncertainty and vagueness. Shell andCoupland domains [94,95] proposed a framework of fuzzy transferlearning to form a prediction model in intelligent environments. Toaddress the issues of modeling environments in the presence ofuncertainty and noise, they introduced a fuzzy logic-based transferlearning that enables the absorption of the inherent uncertaintyand dynamic nature of transfer knowledge in intelligent environments. They created a transferable fuzzy inference system usinglabeled data in the source domain, then adapted and applied theresultant rule base to predict the labels for samples in the targetdomain. The source rules were adjusted and adapted to the targetdomain using the Euclidean distance measure. The proposedmethod was examined in two simulated intelligent environments.The experimental results demonstrated the superior performance\f20J. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323of fuzzy transfer learning compared to classical prediction models;however the method has not been compared with transfer learningmethods. Deng et al. [96] proposed the generalized hidden-mapping ridge regression (GHRR) method to train various types of classical intelligence models, including neural networks, fuzzy logicsystems and kernel methods. The knowledge-leverage based transfer learning mechanism is integrated with GHRR to realize theinductive transfer learning method called transfer GHRR (TGHRR).Since the information from the induced knowledge is much clearerand more concise than the information from the data in the sourcedomain, it is more convenient to control and balance the similarityand difference of data distributions between the source and targetdomains. The proposed GHRR and TGHRR algorithms have beenevaluated experimentally by performing regression and classi\ufb01cation on synthetic and real world datasets. The results demonstrated that the performance of TGHRR is competitive with or evensuperior to existing state-of-the-art inductive transfer learningalgorithms.Genetic algorithm is an evolutionary method that simulates theprocess of natural selection to solve mainly optimization andsearch problems. This method uses techniques inspired by naturalevolution such as inheritance, mutation, selection and crossover.Ko\u00e7er and Arslan [97] introduced the use of genetic algorithmand transfer learning by extending a previously constructed algorithm. Their approach was to extend the transfer learning methodof producing a translation function. This process allows for differing value functions that have been learnt to be mapped fromsource to target tasks. The authors incorporated the use of a setof policies originally constructed by a genetic algorithm to formthe initial population for training the target task. They showed thatthe transfer of inter-task mappings can reduce the time required tolearn a second, more complex task.6. Applications of transfer learningTransfer learning approaches with the support of computationalintelligence methods such as neural network, Bayesian network,and fuzzy logic have been applied in real-world applications. Theseapplications largely fall into the following \ufb01ve categories: (1) Nature language processing; (2) Computer vision; (3) Biology; (4)Finance; and (5) Business management.6.1. Nature language processingNature language processing (NLP), which can be regarded as thestudy of human languages, is proposed to make natural languageprocessing interpretable by computers. In general, there arenumerous sub-learning tasks in NLP \ufb01elds, such as text-basedlearning problems (e.g., text classi\ufb01cation or non-topical text analysis), language knowledge understanding, etc.For text related analysis, i.e., exploring the useful informationfrom a given document, the learning problem of how to label thetext documents across different distributions is addressed [17].In this setting, the labeled training samples share different distributions from the unlabeled test data. Accordingly, a novel transferlearning algorithm based on an Expectation\u2013Maximization basedNaive Bayes model is proposed for further learning, which hasdemonstrated the best performance on three different types ofdata sets. Moreover, considering that most existing transfer learning methods assume that features and labels are numeric, and lackthe ability to handle the uncertainty property, Behbood et al. [98]proposed a Fuzzy Domain Adaptation (FDA) approach and carriedout an investigation of its applicability to text classi\ufb01cation. Inaddition, for sentiment classi\ufb01cation, which is a key challenge innon-topical text analysis, transfer learning technique is alsoapplicable, such as adapting na\u00efve Bayes to domain adaptationfor sentiment analysis by fully utilizing the information from boththe old-domain and unlabeled new-domain data sets [16].Furthermore, the transfer learning approach can be used to dealwith language knowledge understanding problems. For speechrecognition, for example, Swietojanski et al. [52] exploited untranscribed acoustic data to the target languages in a deep neural network on unsupervised cross-lingual knowledge transfer. Similarly,Huang et al. [47] dealt with the cross-language knowledge transferlearning tasks by a shared-hidden-layer multi-lingual deep neuralnetwork.6.2. Computer vision and image processingThe computer vision applied to transfer learning using computational intelligence includes methods for acquiring, processing,analysing, and understanding images, especially in high-dimensional data from the real world, for producing numerical or symbolic information. In this section, we summarize computer visualapplications for camera images processing, from digits to lettersprocessing, and video processing.In early camera image applications based on computationalintelligent transfer learning, all approaches used a database ofcamera images of different objects, each of which had a distinctcolor or size and was used for vision learning, such as ALVINN-likeroad-following vision recognition [54]. One challenge in imageobject recognition is that the distributions of the training imagesand test images are different. Thus, Chopra et al. [51] argued thatin the representation learning camp for images, existing deeplearning approaches could not encode the distributional shiftbetween the source and target domains. To this end, the authorsproposed a novel transfer deep learning method for object recognition which allows the application of deep learning for domainadaptation. Camera images were also used to solve robotics problems. A visual object tracking routine, which recognizes and tracksthe marker in real time, challenged robot researchers [99,100] thatrobot-mounted camera [54] was employed for task mappings, e.g.RoboCup soccer Keepaway [101]. Recently, image learning hasmainly been used for human facial recognition, e.g., gender andethnicity recognition based on facial appearance [46], emotionalfacial appearance recognition derived from synthetic images ofneutral faces to that of corresponding images of angry, happyand sad faces [60], age estimations from face images [65], and gazegesture recognition by eye tracking devices and eye gaze technologies [94]. Knowledge transfer between different handwritten character recognition tasks [48] is another kind of application oftransfer learning in computer vision. Kandaswamy et al. [50]trained a neural network to classify Latin digits (speci\ufb01c sourceproblem) and reused it to classify a lowercase letters (differentbut related target problem) without having to train it from scratch.In the empirical analysis, the authors used the proposed neuralnetwork to transfer knowledge from Arabic digits to Latin digitsas well. Authors [50] also considered a problem of classifyingimages of English lowercase a-to-z by reusing \ufb01ne-tuned featuresof English handwritten digits 0-to-9.By applying salient feature detection and tracking in videos tosimulate \ufb01xations and smooth pursuit in human vision, Zou et al.[102] successfully implemented an unsupervised learning algorithm in a self-taught learning setting. With concrete recognition,features learned from natural videos do not only apply to stillimages, but also give competitive results on a number of objectrecognition benchmarks.6.3. BiologyTransfer learning has been applied to biology \ufb01elds, includingmedical problems, biological modeling designs, ecology issues,\f21J. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323and so on. In applications related to medical issues, Caruana [54]suggested using multi-task learning in arti\ufb01cial neural networks,and proposed an inductive transfer learning approach for pneumonia risk prediction. A life-long inductive learning approach [56]retained task knowledge in a representational form and transferredknowledge in another form of virtual examples on three heart disease domains, through a neural network-based multi-task learningalgorithm. They also put forward another type of sequential inductive transfer model for a medical diagnostics task, i.e., coronaryartery disease diagnosis [57]. Recently, Oyen and Lane [79] arguedthat existing transfer learning methods for Bayesian networksfocus on a single posteriori estimation, and that in doing so, othermodels may be ignored. To this end, they proposed a transfer multi-Bayesian Networks model for whole-brain neuroimaging.From the aspect of biological modeling designs, e.g., robotbionics, Celiberto et al. [66] combined three arti\ufb01cial intelligencetechniques, case-based reasoning, heuristically accelerated reinforcement learning and neural networks, in a transfer learningproblem. They then proposed a novel model called L3 to speedup the reinforcement learning framework for a set of empiricalevaluations between two domains (the Acrobot and the Robocup3D). Another important biology domain, ecology, has attractedthe attention of researchers into transfer learning. For instance,Niculescu-Mizil and Caruana [75] proposed a multi-task Bayesiannetwork structure learning (i.e., inductive transfer) to re-evaluatethe performance of ALARM (a logical alarm reduction mechanism)and to handle a real bird ecology problem in North America.6.4. FinanceAnother application area of transfer learning is \ufb01nance, such asin the area of car insurance risk estimations and \ufb01nancial earlywarning systems. Niculescu-Mizil and Caruana [75] presented aninductive transfer learning approach, which jointly learns multipleBayesian network structures instead of adaptive probabilistic networks from multiple related data sets. The authors examined theproposed method using car insurance risk estimation networks.It is worth noticing that the works on intelligent \ufb01nancial warningsystems and long term prediction in banking ecosystems [91\u201393]are the \ufb01rst systematic studies to apply transfer learning approaches using fuzzy logic techniques of computational intelligence toreal-world \ufb01nancial applications to exploit the knowledge of thebanking system, e.g., transferring the information from one country to establish a prediction model in another country.6.5. Business managementTransfer learning using computational intelligence has beenapplied in business management. For instance, Roy and Kaelbling[71] proposed an ef\ufb01cient Bayesian task-level transfer learning totackle the user\u2019s behavior in the meeting domain. Jin and Sun[103] indicated that traditional neural network methods for traf\ufb01c\ufb02ow forecasting are based on a single task which cannot utilizeinformation from other tasks. To address this challenge, multi-taskbased neural network is proposed to transfer knowledge to dealwith traf\ufb01c \ufb02ow forecasting. Luis et al. [76] proposed the use of anovel transfer Bayesian network learning framework, includingstructure and parameter learning, to handle a product manufactureprocess issue. Recently, Ma et al. [72] studied the cross-companysoftware defect prediction scenario in which the source and targetdata sets come from different companies, and proposed a noveltransfer naive Bayes as the solution. A dynamic model for intelligent environments has been proposed to make use of the data fromdifferent feature spaces and domains [94,104], with a novel fuzzytransfer learning process.7. Comprehensive analysis and \ufb01ndingsIn this paper, we have reviewed several current trends of computational intelligence-based transfer learning. According to thereview, computational intelligence techniques used in transferlearning are classi\ufb01ed to three main groups of: Neural Network,Bayes and Fuzzy Logic and Genetic Algorithm. The number ofreviewed transfer learning papers for each computational intelligence technique in each application domain is summarized andpresented in Table 1. From the summary of transfer learning, it isconcluded that transfer learning with the use computational intelligence, as an emerging research topic, starts playing an importantrole in almost all kinds of application. Of the computational intelligence methods, neural network has been extensively used fortransfer learning, mainly in computer vision and image processingdomain. The main reason why neural network has been widelyused in transfer learning is that it does not have i.i.d. assumptionon data while almost all stochastic techniques have. It can alsobe identi\ufb01ed that Fuzzy-based transfer learning techniques haveplayed an increasingly important role in recent applications particularly \ufb01nance. Since many real world applications have noisyand uncertainty in data, researchers take fuzzy systems intoaccount for transfer learning more and more.In the future, several important research challenges in the \ufb01eldof computational intelligence-based transfer learning need to beaddressed. First, the computational complexity is a crucial issuein computational intelligence-based transfer learning. Almost, allreviewed studies have focused on accuracy as a measurement formodel performance. However, comparing with the statisticaltransfer learning methods, computational intelligence techniquesusually gain more computational complexity which should be handled. In addition, how to avoid negative transfer is an open problem in not only the classical transfer learning but also incomputational intelligence-based transfer learning. The transferability among source and target domains needs to be studied profoundly and a comprehensive and accurate transferabilitymeasures to be implemented that can guarantee the negativelearning will not happens. Moreover, all reviewed studies haveassumed that the feature spaces between the source and targetdomains are the same. However, in many applications, which wewish to transfer knowledge among domains, this assumption cannot be held. This type of transfer learning which is referred as theTable 1Summary of transfer learning techniques in each application domain.DomainsNatural language processingComputer vision & image processingBiologyFinanceBusiness managementTotalTechniquesArti\ufb01cial neural networksBayesFuzzy logicNo. of listed references2114011720213711032651264630\f22J. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323heterogeneous transfer learning has not been addressed in computational intelligence-based transfer learning literature. Finally, sofar the computational intelligence techniques are applied for smallscale transfer learning problems. Nonetheless, in the era of bigdata, there are many interesting applications such as social network analysis and web-based recommender systems that canexploit transfer learning and computational intelligence techniques. The capability of computational intelligence to handlenon-i.i.d. noisy data can pave the way to use these techniques inbig scale real world applications.Two important features of this paper clearly distinguish it fromother survey papers in the transfer learning area: Firstly, It targetsthe development of transfer learning methods that use computational intelligence. Secondly, it systematically examines the applications of transfer learning that are integrated with computationalintelligence.We believe that this paper can provide researchers and practicalprofessionals with state-of-the-art knowledge on transfer learningwith computational intelligence and give guidelines about how todevelop and apply transfer learning in different domains to support users in various decision activities.AcknowledgmentThe work presented in this paper was supported by theAustralian Research Council (ARC) under discovery grantDP140101366.References[1] X. Zhu, Semi-Supervised Learning Literature Survey, University of Wisconsin,Madison, USA, 2005.[2] K. Nigam, A.K. Mccallum, S. Thrun, T. Mitchell, Text classi\ufb01cation from labeledand unlabeled documents using EM, Mach. Learn. 39 (2\u20133) (2000) 103\u2013134.[3] A. Blum, T. Mitchell, Combining labeled and unlabeled data with co-training,in: Eleventh Annual Conference on Computational Learning Theory, Madison,USA, 1998.[4] T. Joachims, Transductive inference for text classi\ufb01cation using support vectormachines, in: Sixteenth International Conference on Machine Learning, Bled,USA, 1999.[5] G.P.C. Fung, J.X. Yu, H.J. Lu, P.S. Yu, Text classi\ufb01cation without negativeexamples revisit, IEEE Trans. Knowl. Data Eng. 18 (1) (2006) 6\u201320.[6] X. Yin, J. Han, J. Yang, P.S. Yu, Ef\ufb01cient classi\ufb01cation across multiple databaserelations: a CrossMine approach, IEEE Trans. Knowl. Data Eng. 18 (6) (2006)770\u2013783.[7] L.I. Kuncheva, J.J. Rodriguez, Classi\ufb01er ensembles with a random linear oracle,IEEE Trans. Knowl. Data Eng. 19 (4) (2007) 500\u2013508.[8] E. Baralis, S. Chiusano, P. Garza, A lazy approach to associative classi\ufb01cation,IEEE Trans. Knowl. Data Eng. 20 (2) (2008) 156\u2013171.[9] S.J. Pan, Q. Yang, A survey on transfer learning, IEEE Trans. Knowl. Data Eng.22 (10) (2010) 1345\u20131359.[10] R. Klinkenberg, T. Joachims, Detecting concept drift with support vectormachines, in: Seventeenth International Conference on Machine Learning,Stanford, USA, 2000.[11] A. Margolis, A Literature Review of Domain Adaptation with Unlabeled Data,Rapport Technique, University of Washington, 2011.[12] J.J. Heckman, Sample selection bias as a speci\ufb01cation error, Econometrica 47(1) (1979) 153\u2013162.[13] J. Huang, A.J. Smola, A.. Gretton, K.M. Borgwardt, B. Scholkopf, Correctingsample selection bias by unlabeled data, Adv. Neural Inf. Process. Syst. 19(2007) 601\u2013608.[14] M. Sugiyama, S. Nakajima, H. Kashima, P. Bunau, M. Kawanabe, Directimportance estimation with model selection and its application to covariateshift adaptation, Adv. Neural Inf. Process. Syst. 20 (2008) 1433\u20131440.[15] Y. Tsuboi, H. Kashima, S. Hido, S. Bickel, M. Sugiyama, Direct density ratioestimation for large-scale covariate shift adaptation, Inf. Media Technol. 4 (2)(2009) 529\u2013546.[16] S. Tan, X. Cheng, Y. Wang, H. Xu, Adapting naive Bayes to domain adaptationfor sentiment analysis, in: 31st European Conference on Advances inInformation Retrieval, Toulouse, France, 2009.[17] W. Dai, G. Xue, Q. Yang, Y. Yu, Transferring naive Bayes classi\ufb01ers for textclassi\ufb01cation, in: 22nd National Conference on Arti\ufb01cial Intelligence,Vancouver, Canada, 2007.[18] D. McClosky, E. Charniak, M. Johnson, Reranking and self-training for parseradaptation, in: 21st International Conference on Computational Linguistics,Sydney, Australia, 2006.[19] B. Roark, M. Bacchiani, Supervised and unsupervised PCFG adaptation tonovel domains, in: Conference of the North American Chapter of theAssociation for Computational Linguistics on Human Language, Edmonton,Canada, 2003.[20] K. Sagae, J. Tsujii, Dependency parsing and domain adaptation with LR modelsand parser ensembles, in: 11th Conference on Computational NaturalLanguage Learning, Prague, Czech Republic, 2007.[21] K. Sagae, Self-training without reranking for parser domain adaptation and itsimpact on semantic role labeling, in: Workshop on Domain Adaptation forNatural Language Processing, Uppsala, Sweden, 2010.[22] J. Jiang, C.X. Zhai, Instance weighting for domain adaptation in NLP, in: 45thAnnual Meeting of the Association of Computational Linguistics, Prague,Czech Republic, 2007.[23] O. Sandu, G. Carenini, G. Murray, R. Ng, Domain adaptation to summarizehuman conversations, in: Workshop on Domain Adaptation for NaturalLanguage Processing, Uppsala, Sweden, 2010.[24] J. Jiang, C.X. Zhai, A two-stage approach to domain adaptation for statisticalclassi\ufb01ers, in: Sixteenth ACM Conference on Information and KnowledgeManagement, Lisbon, Portugal, 2007.[25] M. Ciaramita, O. Chapelle, Adaptive parameters for entity recognition withperceptron HMMs, in: Workshop on Domain Adaptation for Natural LanguageProcessing, Uppsala, Sweden, 2010.[26] S. Tan, Y. Wang, G. Wu, X. Cheng, Using unlabeled data to handle domaintransfer problem of semantic detection, in: ACM Symposium on AppliedComputing, Fortaleza, Brazil, 2008.[27] L. Rigutini, M. Maggini, B. Liu, An EM based training algorithm for crosslanguage text categorization, in: IEEE/WIC/ACM International Conference onWeb Intelligence, Compiegne, France, 2005.[28] L. Shi, R. Mihalcea, M. Tian, Cross language text classi\ufb01cation by modeltranslation and semi-supervised learning, in: Conference on EmpiricalMethods in Natural Language Processing, Cambridge, USA, 2010.[29] M. Jeong, C.Y. Lin, G.G. Lee, Semi-supervised speech act recognition in emailsand forums, in: Conference on Empirical Methods in Natural LanguageProcessing, Singapore, Singapore, 2009.[30] A. Arnold, R. Nallapati, W.W. Cohen, A comparative study of methods fortransductive transfer learning, in: Seventh IEEE International Conference onData Mining Workshops, Omaha, USA, 2007.[31] A. Aue, M. Gamon, Customizing sentiment classi\ufb01ers to new domains: A casestudy, in: International Conference on Recent Advances in Natural LanguageProcessing, Borovets, Bulgaria, 2005.[32] S. Satpal, S. Sarawagi, Domain adaptation of conditional probability modelsvia feature subsetting, in: 11th European Conference on Principles andPractice of Knowledge Discovery in Databases, Warsaw, Poland, 2007.[33] B. Chen, W. Lam, I. Tsang, T.L. Wong, Extracting discriminative concepts fordomain adaptation in text mining, in: ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining, Paris, France, 2009.[34] S.J. Pan, J.T. Kwok, Q. Yang, Transfer learning via dimensionality reduction, in:23rd National Conference on Arti\ufb01cial Intelligence, Chicago, USA, 2008.[35] S.J. Pan, I.W. Tsang, J.T. Kwork, Q. Yang, Domain adaptation via transfercomponent analysis, IEEE Trans. Neural Networks 22 (2) (2011) 199\u2013210.[36] J. Blitzer, R. McOnald, F. Pereira, Domain adaptation with structuralcorrespondence learning, in: Conference on Empirical Methods in NaturalLanguage Processing, Sydney, Australia, 2006.[37] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, J. Wortman, Learning bounds fordomain adaptation, in: Twenty-First Annual Conference on NeuralInformation Processing Systems, Cambridge, USA, 2007.[38] S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, J.W. Vaughan, Atheory of learning from different domains, Mach. Learn. 79 (1) (2010) 151\u2013175.[39] F. Huang, A. Yates, Exploring representation-learning approaches to domainadaptation, in: Workshop on Domain Adaptation for Natural LanguageProcessing, Uppsala, Sweden, 2010.[40] F. Huang, A. Yates, Open-domain semantic role labeling by modeling wordspans, in: 48th Annual Meeting of the Association for ComputationalLinguistics, Uppsala, Sweden, 2010.[41] F. Huang, A. Yates, Distributional representations for handling sparsity insupervised sequence-labeling, in: Joint Conference of the 47th AnnualMeeting of the Association for Computational Linguistics and the 4thInternational Conference on Natural Language Processing, Singapore,Singapore, 2009.[42] S.J. Pan, X. Ni, J. Sun, Q. Yang, Z. Chen, Cross-domain sentiment classi\ufb01cationvia spectral feature alignment, in: 19th International Conference on WorldWide Web, Raleigh, USA, 2010.[43] J. Gao, W. Fan, J. Jiang, J. Han, Knowledge transfer via multiple model localstructure mapping, in: 14th ACM SIGKDD International Conference onKnowledge Discovery and Data Mining, Las Vegas, USA, 2008.[44] G.-R. Xue, W. Dai, Q. Yang, Y. Yu, Topic-bridged PLSA for cross-domain textclassi\ufb01cation, in: 31st Annual International ACM SIGIR Conference onResearch and Development in Information Retrieval, Singapore, Singapore,2008.[45] D.H. Hubel, T.N. Wiesel, Receptive \ufb01elds, binocular interaction andfunctional architecture in the cat\u2019s visual cortex, J. Physiol. 160 (1)(1962) 106\u2013154.[46] A. Ahmed, K. Yu, W. Xu, Y. Gong, E. Xing, Training Hierarchical Feed-ForwardVisual Recognition Models Using Transfer Learning from Pseudo-Tasks, inComputer Vision\u2013ECCV 2008, Springer, 2008. pp. 69\u201382.\fJ. Lu et al. / Knowledge-Based Systems 80 (2015) 14\u201323[47] J.-T. Huang, J. Li, D. Yu, L. Deng, Y. Gong, Cross-language knowledge transferusing multilingual deep neural network with shared hidden layers, in: IEEEInternational Conference on Acoustics, Speech and Signal Processing(ICASSP), Vancouver, Canada, 2013.[48] D.C. Ciresan, U. Meier, J. Schmidhuber, Transfer learning for Latin and Chinesecharacters with deep neural networks, in: International Joint Conference onNeural Networks (IJCNN), Brisbane, Australia, 2012.[49] R. Collobert, J. Weston, A uni\ufb01ed architecture for natural language processing:deep neural networks with multitask learning, in: 25th InternationalConference on Machine Learning, Helsinki, Finland, 2008.[50] C. Kandaswamy, L.M. Silva, L.A. Alexandre, J.M. Santos, J.M. de Sa, Improvingdeep neural network performance by reusing features trained withtransductive transference, in: Proceedings of the 24th InternationalConference on Arti\ufb01cial Neural Networks, Hamburg, Germany, 2014.[51] S. Chopra, S. Balakrishnan, R. Gopalan, DLID: deep learning for domainadaptation by interpolating between domains, in: ICML Workshop onChallenges in Representation Learning, Atlanta, USA, 2013.[52] P. Swietojanski, A. Ghoshal, S. Renals, Unsupervised cross-lingual knowledgetransfer in DNN-based LVCSR, in: IEEE Workshop on Spoken LanguageTechnology (SLT), Miami, USA, 2012.[53] R. Caruana, Multitask learning: a knowledge-based source of inductive bias,in: Tenth International Conference of Machine Learning, MA, USA, 1993.[54] R. Caruana, Multitask learning, Mach. Learn. 28 (1997) 41\u201375.[55] D. Silver, R. Mercer, Selective functional transfer: Inductive bias from relatedtasks, in: International Conference on Arti\ufb01cial Intelligence and SoftComputing (ASC), Cancun, Mexico, 2001.[56] D.L. Silver, R.E. Mercer, The task rehearsal method of life-long learning:overcoming impoverished data, in: Advances in Arti\ufb01cial Intelligence,Springer, 2002, pp. 90\u2013101.[57] D.L. Silver, R.E. Mercer, Sequential inductive transfer for coronary arterydisease diagnosis, in: International Joint Conference on Neural Networks(IJCNN), Orlando, USA, 2007.[58] D.L. Silver, R. Poirier, Context-sensitive MTL networks for machine lifelonglearning, in: 20th Florida Arti\ufb01cial Intelligence Research Society (FLAIRS)Conference, Key West, USA, 2007.[59] D.L. Silver, R. Poirier, D. Currie, Inductive transfer with context-sensitiveneural networks, Mach. Learn. 73 (3) (2008) 313\u2013336.[60] D.L. Silver, L. Tu, Image transformation: inductive transfer between multipletasks having multiple outputs, in: Advances in Arti\ufb01cial Intelligence, Springer,2008, pp. 296\u2013307.[61] K. Yamauchi, Covariate shift and incremental learning, in: Advances in NeuroInformation Processing, Springer, 2009, pp. 1154\u20131162.[62] H. Shimodaira, Improving predictive inference under covariate shift byweighting the log-likelihood function, J. Stat. Plann. Inference 90 (2) (2000)227\u2013244.[63] K. Yamauchi, Optimal incremental learning under covariate shift, MemeticComput. 1 (4) (2009) 271\u2013279.[64] W. Liu, H. Zhang, J. Li, Inductive transfer through neural network error anddataset regrouping, in: IEEE International Conference on IntelligentComputing and Intelligent Systems (ICIS), Shanghai, China, 2009.[65] K. Ueki, M. Sugiyama, Y. Ihara, Perceived age estimation under lightingcondition change by covariate shift adaptation, in: 20th InternationalConference on Pattern Recognition (ICPR), Istanbul, Turkey, 2010.[66] L.A. Celiberto Jr., L.A., J.P. Matsuura, R.L. de Mantaras, R.A.C. Bianchi, Usingcases as heuristics in reinforcement learning: a transfer learning application,in: IJCAI Proceedings-International Joint Conference on Arti\ufb01cial Intelligence,Barcelona, Spain, 2011.[67] D.D. Lewis, Representation and Learning in Information Retrieval, Universityof Massachusetts, 1992.[68] I. Kononenko, Inductive and Bayesian learning in medical diagnosis, Appl.Artif. Intell. Int. J. 7 (4) (1993) 317\u2013337.[69] I. Androutsopoulos, J. Koutsias, K.V. Chandrinos, C.D. Spyropoulos, Anexperimental comparison of naive Bayesian and keyword-based anti-spam\ufb01ltering with personal e-mail messages, in: 23rd Annual International ACMSIGIR Conference on Research and Development in Information Retrieval,Pisa, Italy, 2000.[70] F. Sebastiani, Machine learning in automated text categorization, ACMComput. Surveys (CSUR) 34 (1) (2002) 1\u201347.[71] D.M. Roy, L.P. Kaelbling, Ef\ufb01cient Bayesian task-level transfer learning, in:International Joint Conference on Arti\ufb01cial Intelligence, Hyderabad, India,2007.[72] Y. Ma, G. Luo, X. Zeng, A. Chen, Transfer learning for cross-company softwaredefect prediction, Inf. Softw. Technol. 54 (3) (2012) 248\u2013256.[73] D. Heckerman, A Tutorial on Learning with Bayesian Networks, Springer,1998.[74] W.L. Buntine, A guide to the literature on learning probabilistic networksfrom data, IEEE Trans. Knowl. Data Eng. 8 (2) (1996) 195\u2013210.23[75] A. Niculescu-Mizil, R. Caruana, Inductive transfer for Bayesian networkstructure learning, in: Eleventh International Conference on Arti\ufb01cialIntelligence and Statistics (AISTATS), San Juan, Puerto Rico, 2007.[76] R. Luis, L.E. Sucar, E.F. Morales, Inductive transfer for learning Bayesiannetworks, Mach. Learn. 79 (1\u20132) (2010) 227\u2013255.[77] M. Richardson, P. Domingos, Learning with knowledge from multiple experts,in: International Conference on Machine learning (ICML), Washington, USA,2003.[78] D. Oyen, T. Lane, Leveraging domain knowledge in multitask Bayesiannetwork structure learning, in: 26th Association for the Advancement ofArti\ufb01cial Intelligence (AAAI) Conference, Toronto, Canada, 2012.[79] D. Oyen, T. Lane, Bayesian discovery of multiple Bayesian networks viatransfer learning, in: 13th IEEE International Conference on Data Mining(ICDM), Dalla, USA, 2013.[80] N. Friedman, D. Koller, Being Bayesian about network structure: a Bayesianapproach to structure discovery in Bayesian networks, Mach. Learn. 50 (1\u20132)(2003) 95\u2013125.[81] M. Koivisto, K. Sood, Exact Bayesian structure discovery in Bayesiannetworks, J. Mach. Learn. Res. 5 (2004) 549\u2013573.[82] A. Wilson, A. Fern, S. Ray, P. Tadepalli, Multi-task reinforcement learning: ahierarchical Bayesian approach, in: 24th International Conference onMachine Learning, Corvallis, USA, 2007.[83] A. Wilson, A. Fern, P. Tadepalli, Transfer learning in sequential decisionproblems: a hierarchical Bayesian approach, in: International Conference ofMachine Learning, Edinburgh, Scotland, 2012.[84] P. Yang, Q. Tan, Y. Ding, Bayesian task-level transfer learning for non-linearregression, in: International Conference on Computer Science and SoftwareEngineering, Wuhan, China, 2008.[85] V.C. Raykar, B. Krishnapuram, J. Bi, M. Dundar, R.B. Rao, Bayesian multipleinstance learning: Automatic feature selection and inductive transfer, in:25th International Conference on Machine Learning, Helsinki, Finland, 2008.[86] J.R. Finkel, C.D. Manning, Hierarchical Bayesian domain adaptation, in:Annual Conference of the North American Chapter of the Association forComputational Linguistics, Los Angeles, USA, 2009.[87] F. Wood, Y.W. Teh, A hierarchical nonparametric Bayesian approach tostatistical language model domain adaptation, in: International Conferenceon Arti\ufb01cial Intelligence and Statistics, Las Vegas, USA, 2009.[88] R. Salakhutdinov, J. Tenenbaum, A. Torralba, One-shot learning with ahierarchical nonparametric Bayesian model, MIT-CSAIL-TR-2010-052,Editor, MIT, 2010.[89] L.A. Zadeh, Fuzzy sets, Inf. Control 8 (3) (1965) 338\u2013353.[90] R.E. Bellman, L.A. Zadeh, Decision-making in a fuzzy environment, Manage.Sci. 17 (4) (1970) 141\u2013164.[91] V. Behbood, J. Lu, G. Zhang, Long term bank failure prediction using fuzzyre\ufb01nement-based transductive transfer learning, in: IEEE InternationalConference on Fuzzy Systems (FUZZ), Taipei, Taiwan, 2011.[92] V. Behbood, J. Lu, G. Zhang, Fuzzy bridged re\ufb01nement domain adaptation:long-term bank failure prediction, Int. J. Comput. Intell. Appl. 12 (01) (2013).[93] V. Behbood, J. Lu, G. Zhang, Fuzzy re\ufb01nement domain adaptation for longterm prediction in banking ecosystem, IEEE Trans. Industr. Inf. 10 (2) (2014)1637\u20131646.[94] J. Shell, S. Coupland, Towards fuzzy transfer learning for intelligentenvironments, in: Ambient Intelligence, vol. 7683, 2012, pp. 145\u2013160.[95] J. Shell, S. Coupland, Fuzzy transfer learning: methodology and application,Inf. Sci. 293 (2015) 59\u201379.[96] Z. Deng, K. Choi, Y. Jiang, Generalized hidden-mapping ridge regression,knowledge-leveraged inductive transfer learning for neural networks, fuzzysystems and kernel method, IEEE Trans. Cybern. 44 (12) (2014) 2585\u20132599.[97] B. Ko\u00e7er, A. Arslan, Genetic transfer learning, Expert Syst. Appl. 37 (10) (2010)6997\u20137002.[98] V. Behbood, J. Lu, G. Zhang, Text categorization by fuzzy domain adaptation,in: IEEE International Conference on Fuzzy Systems, Hyderabad, India, 2013.[99] S. Thrun, Is learning the n-th thing any easier than learning the \ufb01rst?, AdvNeural Inf. Process. Syst. (1996) 640\u2013646.[100] S. Thrun, A lifelong learning perspective for mobile robot control, in: IEEE/RSJ/GI International Conference on Intelligent Robots and Systems, Munich,Germany, 1994.[101] M.E. Taylor, P. Stone, Y. Liu, Transfer learning via inter-task mappings fortemporal difference learning, J. Mach. Learn. Res. 8 (1) (2007) 2125\u20132167.[102] W. Zou, S. Zhu, A.Y. Ng, K. Yu, Deep learning of invariant features viasimulated \ufb01xations in video, in: Advances in Neural Information ProcessingSystems, Lake Tahoe, USA, 2012.[103] F. Jin, S. Sun, Neural network multitask learning for traf\ufb01c \ufb02ow forecasting,in: IEEE International Joint Conference on Neural Networks (IJCNN), HongKong, China, 2008.[104] J. Shell, Fuzzy transfer learning, Ph.D. Thesis, De Montfort University, 2013.\f", "Journal of Machine Learning Research 10 (2009) 1633-1685Submitted 6/08; Revised 5/09; Published 7/09Transfer Learning for Reinforcement Learning Domains: A SurveyMatthew E. Taylor\u2217TAYLORM @ USC . EDUComputer Science DepartmentThe University of Southern CaliforniaLos Angeles, CA 90089-0781Peter StonePSTONE @ CS . UTEXAS . EDUDepartment of Computer SciencesThe University of Texas at AustinAustin, Texas 78712-1188Editor: Sridhar MahadevanAbstractThe reinforcement learning paradigm is a popular way to address problems that have only limitedenvironmental feedback, rather than correctly labeled examples, as is common in other machinelearning contexts. While significant progress has been made to improve learning in a single task,the idea of transfer learning has only recently been applied to reinforcement learning tasks. Thecore idea of transfer is that experience gained in learning to perform one task can help improvelearning performance in a related, but different, task. In this article we present a framework thatclassifies transfer learning methods in terms of their capabilities and goals, and then use it to surveythe existing literature, as well as to suggest future directions for transfer learning work.Keywords: transfer learning, reinforcement learning, multi-task learning1. Transfer Learning ObjectivesIn reinforcement learning (RL) (Sutton and Barto, 1998) problems, leaning agents take sequentialactions with the goal of maximizing a reward signal, which may be time-delayed. For example,an agent could learn to play a game by being told whether it wins or loses, but is never given the\u201ccorrect\u201d action at any given point in time. The RL framework has gained popularity as learningmethods have been developed that are capable of handling increasingly complex problems. However, when RL agents begin learning tabula rasa, mastering difficult tasks is often slow or infeasible,and thus a significant amount of current RL research focuses on improving the speed of learningby exploiting domain expertise with varying amounts of human-provided knowledge. Common approaches include deconstructing the task into a hierarchy of subtasks (cf., Dietterich, 2000); learningwith higher-level, temporally abstract, actions (e.g., options, Sutton et al. 1999) rather than simpleone-step actions; and efficiently abstracting over the state space (e.g., via function approximation)so that the agent may generalize its experience more efficiently.The insight behind transfer learning (TL) is that generalization may occur not only within tasks,but also across tasks. This insight is not new; transfer has long been studied in the psychologicalliterature (cf., Thorndike and Woodworth, 1901; Skinner, 1953). More relevant are a number of\u2217. The first author wrote the majority of this article while a graduate student at the University of Texas at Austin.c 2009 Matthew E. Taylor and Peter Stone.\fTAYLOR AND S TONEScaling up RLState AbstractionTransfer LearningCase based reasoningNeural NetworkTransferTemporal AbstractionHypothesis SpaceTransferHierarchical Learningetc.etc.This SurveyFigure 1: This article focuses on transfer between reinforcement learning tasks.approaches that transfer between machine learning tasks (Caruana, 1995; Thrun, 1996), for planningtasks (Fern et al., 2004; Ilghami et al., 2005), and in the context of cognitive architectures (Lairdet al., 1986; Choi et al., 2007). However, TL for RL tasks has only recently been gaining attentionin the artificial intelligence community. Others have written surveys for reinforcement learning(Kaelbling et al., 1996), and for transfer across machine learning tasks (Thrun and Pratt, 1998),which we will not attempt to duplicate; this article instead focuses on transfer between RL tasks (seeFigure 1) to provide an overview of a new, growing area of research.Transfer learning in RL is an important topic to address at this time for three reasons. First, inrecent years RL techniques have achieved notable successes in difficult tasks which other machinelearning techniques are either unable or ill-equipped to address (e.g., TDGammon Tesauro 1994,job shop scheduling Zhang and Dietterich 1995, elevator control Crites and Barto 1996, helicoptercontrol Ng et al. 2004, marble maze control Bentivegna et al. 2004, Robot Soccer Keepaway Stoneet al. 2005, and quadruped locomotion Saggar et al. 2007 and Kolter et al. 2008). Second, classicalmachine learning techniques such as rule induction and classification are sufficiently mature thatthey may now easily be leveraged to assist with TL. Third, promising initial results show that notonly are such transfer methods possible, but they can be very effective at speeding up learning.The 2005 DARPA Transfer Learning program (DARPA, 2005) helped increase interest in transferlearning. There have also been some recent workshops providing exposure for RL techniques thatuse transfer. The 2005 NIPS workshop, \u201cInductive Transfer: 10 Years Later,\u201d (Silver et al., 2005)had few RL-related transfer papers, the 2006 ICML workshop, \u201cStructural Knowledge Transfer forMachine Learning,\u201d (Banerjee et al., 2006) had many, and the 2008 AAAI workshop, \u201cTransferLearning for Complex Tasks,\u201d (Taylor et al., 2008a) focused on RL.1.1 Paper OverviewThe goals of this survey are to introduce the reader to the transfer learning problem in RL domains,to organize and discuss current transfer methods, and to enumerate important open questions inRL transfer. In transfer, knowledge from one or more source task(s) is used to learn one or moretarget task(s) faster than if transfer was not used. The literature surveyed is structured primarilyby grouping methods according to how they allow source and target tasks to differ. We further1634\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYdistinguish methods according to five different dimensions (see Section 2.2). Some of the questionsthat distinguish transfer methods include:\u2022 What are the goals of the transfer method? By what metric(s) will success be measured? Section 2 examines commonly used metrics, as well as different settings where transfer learningcan improve learning.\u2022 What assumptions, if any, are made regarding the similarity between the tasks? Section 3.2.1enumerates common differences, such as changes to the space in which agents operate, allowing the agents to have different goals, or letting agents have different sets of actions.\u2022 How does a transfer method identify what information can/should be transferable? Section 3.2.2 enumerates possibilities ranging from assuming all previously seen tasks are directly useful to autonomously learning which source task(s) are useful for learning in thecurrent target task.\u2022 What information is transferred between tasks? Section 3.2.3 discusses possibilities rangingfrom very low-level information (such as direct control knowledge) to high-level information(such as rules regarding how a particular domain functions).The following section presents a discussion about how to best evaluate transfer in RL. There aremany different situations in which transfer can be useful and these different situations may entaildifferent metrics. This discussion will prepare the reader to better understand how transfer may beused. Section 3.1 will briefly discuss reinforcement learning and the notation used in the article.Section 3.2 enumerates the ways in which transfer methods can differ, providing a skeleton for thestructure of this survey. Sections 3.3 and 3.4 provide additional high-level categorization of TLmethods and Section 3.5 discusses related learning paradigms which are explicitly not discussed inthis survey.The bulk of the remainder of the article (Sections 4\u20138) discuss contemporary TL methods, arranged by the goals of, and methods employed by, the designers. Lastly, Section 9 discusses currentopen questions in transfer and concludes.2. Evaluating Transfer Learning MethodsTransfer techniques assume varying degrees of autonomy and make many different assumptions. Tobe fully autonomous, an RL transfer agent would have to perform all of the following steps:1. Given a target task, select an appropriate source task or set of tasks from which to transfer.2. Learn how the source task(s) and target task are related.3. Effectively transfer knowledge from the source task(s) to the target task.While the mechanisms used for these steps will necessarily be interdependent, TL research hasfocused on each independently, and no TL methods are currently capable of robustly accomplishingall three goals.A key challenge in TL research is to define evaluation metrics, precisely because there are manypossible measurement options and algorithms may focus on any of the three steps above. Thissection focuses on how to best evaluate TL algorithms so that the reader may better understand the1635\fTAYLOR AND S TONEdifferent goals of transfer and the situations where transfer may be beneficial.1 For instance, it is notalways clear how to treat learning in the source task: whether to charge it to the TL algorithm or toconsider it as a \u201csunk cost.\u201d On the one hand, a possible goal of transfer is to reduce the overall timerequired to learn a complex task. In this scenario, a total time scenario, which explicitly includesthe time needed to learn the source task or tasks, would be most appropriate. On the other hand,a second reasonable goal of transfer is to effectively reuse past knowledge in a novel task. In thiscase, a target task time scenario, which only accounts for the time spent learning in the target task,is reasonable.The total time scenario may be more appropriate when an agent is explicitly guided by a human.Suppose that a user wants an agent to learn to perform a task, but recognizes that the agent may beable to learn a sequence of tasks faster than if it directly tackled the difficult task. The human canconstruct a series of tasks for the agent, suggesting to the agent how the tasks are related. Thusthe agent\u2019s TL method will easily accomplish steps 1 and 2 above, but it must efficiently transferknowledge between tasks (step 3). To successfully transfer in this setting, the agent would have tolearn the entire sequence of tasks faster than if it had spent its time learning the final target taskdirectly (see the total time scenario in Figure 2).The target task time scenario is more appropriate for a fully autonomous learner. A fully autonomous agent must be able to perform steps 1\u20133 on its own. However, metrics for this scenario donot need to take into account the cost of learning source tasks. The target task time scenario emphasizes the agent\u2019s ability to use knowledge from one or more previously learned source tasks withoutbeing charged for the time spent learning them (see the target task time scenario in Figure 2). Inthis survey we will see that the majority of existing transfer algorithms assume a human-guided scenario, but disregard time spent training in the source task. When discussing individual TL methods,we will specifically call attention to the methods that do account for the total training time and donot treat the time spent learning a source task as a sunk cost.Many metrics to measure the benefits of transfer are possible (shown in Figure 3, replicatedfrom our past transfer learning work, Taylor and Stone 2007b):1. Jumpstart: The initial performance of an agent in a target task may be improved by transferfrom a source task.2. Asymptotic Performance: The final learned performance of an agent in the target task may beimproved via transfer.3. Total Reward: The total reward accumulated by an agent (i.e., the area under the learningcurve) may be improved if it uses transfer, compared to learning without transfer.4. Transfer Ratio: The ratio of the total reward accumulated by the transfer learner and the totalreward accumulated by the non-transfer learner.5. Time to Threshold: The learning time needed by the agent to achieve a pre-specified performance level may be reduced via knowledge transfer.Metrics 1\u20134 are most appropriate in the fully autonomous scenario as they do not charge the agentfor time spent learning any source tasks. To measure the total time, the metric must account for time1. Evaluation is particularly important because there are very few theoretical results supporting TL for RL methods,as discussed further in Section 9.3. Instead, practitioners rely on empirical methods to evaluate the efficacy of theirmethods.1636\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYSource Task TimeTransfer ImprovementTarget Task Timewith transferTransfer ImprovementTarget Task Time without transferTraining Time RequiredTarget Task Time ScenarioTarget Task Timewith transferTarget Task Time without transferTraining Time RequiredTotal Time ScenarioFigure 2: Successful TL methods may be able to reduce the total training time (left). In somescenarios, it is more appropriate to treat the source task time as a sunk cost and testwhether the method can effectively reuse past knowledge to reduce the target task time(right).spent learning one or more source tasks, which is natural when using metric 5. Other metrics havebeen proposed in the literature, but we choose to focus on these five because they are sufficient todescribe the methods surveyed in this article.For this article, we may think of learning time as a surrogate for sample complexity. Samplecomplexity (or data complexity) in RL refers to the amount of data required by an algorithm tolearn. It is strongly correlated with learning time because RL agents only gain data by collecting itthrough repeated interactions with an environment.2.1 Empirical Transfer ComparisonsThe previous section enumerated five possible TL metrics, and while others are possible, theserepresent the methods most commonly used. However, each metric has drawbacks and none aresufficient to fully describe the benefits of any transfer method. Rather than attempting to create atotal order ranking of different methods, which may indeed by impossible, we instead suggest that amulti-dimensional evaluation with multiple metrics is most useful. Specifically, some methods may\u201cwin\u201d on a set of metrics relative to other methods, but \u201close\u201d on a different set. As the field betterunderstands why different methods achieve different levels of success on different metrics, it shouldbecome easier to map TL methods appropriately to TL problems. Although the machine learningcommunity has defined standard metrics (such as precision vs. recall curves for classification andmean squared error for regression), RL has no such standard. Empirically comparing two RL algorithms is a current topic of debate within the community, although there is some process towardsstandardizing comparisons (Whiteson et al., 2008). Theoretical comparisons are also not clear-cut,as samples to convergence, asymptotic performance, and the computational complexity are all validaxes along which to evaluate RL algorithms.1637\fTAYLOR AND S TONEFigure 3: Many different metrics for measuring TL are possible. This graph show benefits to thejumpstart, asymptotic performance, time to threshold, and total reward (the area underthe learning curve).The first proposed transfer measure considers the agent\u2019s initial performance in a target task andanswers the question, \u201ccan transfer be used so that the initial performance is increased relative tothe performance of an initial (random) policy?\u201d While such an initial jumpstart is appealing, sucha metric fails to capture the behavior of learning in the target task and instead only focuses on theperformance before learning occurs.Asymptotic performance, the second proposed metric, compares the final performance of learners in the target task both with and without transfer. However, it may be difficult to tell when thelearner has indeed converged (particularly in tasks with infinite state spaces) or convergence maytake prohibitively long. In many settings the number of samples required to learn is most critical,not the performance of a learner with an infinite number of samples. Further, it is possible for different learning algorithms to converge to the same asymptotic performance but require very differentnumbers of samples to reach the same performance.A third possible measure is that of the total reward accumulated during training. Improvinginitial performance and achieving a faster learning rate will help agents accumulate more on-linereward. RL methods are often not guaranteed to converge with function approximation and evenwhen they do, learners may converge to different, sub-optimal performance levels. If enough samples are provided to agents (or, equivalently, learners are provided sufficient training time), a learning method which achieves a high performance relatively quickly will have less total reward than alearning method which learns very slowly but eventually plateaus at a slightly higher performancelevel. This metric is most appropriate for tasks that have a well-defined duration.1638\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYA fourth measure of transfer efficacy is that of the ratio of areas defined by two learning curves.Consider two learning curves in the target task where one uses transfer and one does not. Assumingthat the transfer learner accrues more reward, the area under the transfer leaning curve will be greaterthan the area under the non-transfer learning curve. The ratior=area under curve with transfer - area under curve without transferarea under curve without transfergives a metric that quantifies improvement from TL. This metric is most appropriate if the samefinal performance is achieved, or there is a predetermined time for the task. Otherwise the ratio willdirectly depend on how long the agents act in the target task.While such a metric may be appealing as a candidate for inter-task comparisons, we note thatthe transfer ratio is not scale invariant. For instance, if the area under the transfer curve were 1000units and the area under the non-transfer curve were 500, the transfer ratio would be 1.0. If allrewards were multiplied by a constant, this ratio would not change. But if an offset were added(e.g., each agent is given an extra +1 at the end of each episode, regardless of the final state), theratio would change. The evaluation of a TL algorithm with the transfer ratio is therefore closelyrelated to the reward structure of the target task being tested. Lastly, we note that although none ofthe papers surveyed in this article use such a metric, we hope that it will be used more often in thefuture.The final metric, Time to Threshold, suffers from having to specify a (potentially arbitrary) performance agents must achieve. While there have been some suggestions how to pick such thresholdsappropriately (Taylor et al., 2007a), the relative benefit of TL methods will clearly depend on theexact threshold chosen, which will necessarily be domain- and learning method-dependent. Whilechoosing a range of thresholds to compare over may produce more representative measures (cf.,Taylor et al., 2007b), this leads to having to generating a time vs. threshold curve rather than producing a single real valued number that evaluates a transfer algorithm\u2019s efficacy.A further level of analysis that could be combined with any of the above methods would be tocalculate a ratio comparing the performance of a TL algorithm with that of a human learner. Forinstance, a set of human subjects could learn a given target task with and without having first trainedon a source task. By averaging over their performances, different human transfer metrics could becalculated and compared to that of a TL algorithm. However, there are many ways to manipulatesuch a meta-metric. For instance, if a target task is chosen that humans are relatively proficientat, transfer will provide them very little benefit. If that same target task is difficult for a machinelearning algorithm, it will be relatively easy to show that the TL algorithm is quite effective relativeto human transfer, even if the agent\u2019s absolute performance is extremely poor.A major drawback of all the metrics discussed is that none are appropriate for inter-domain comparisons. The vast majority of papers in this survey compare learning with and without transfer\u2014their authors often do not attempt to directly compare different transfer methods. Developing fairmetrics that apply across multiple problem domains would facilitate better comparisons of methods.Such inter-domain metrics may be infeasible in practice, in which case standardizing on a set of testdomains would assist in comparing different TL methods (as discussed further in Section 9). Inthe absence of either a set of inter-domain metrics or a standard benchmark suite of domains, welimit our comparisons of different TL methods in this survey to their applicability, assumptions, andalgorithmic differences. When discussing different methods, we may opine on the method\u2019s relative1639\fTAYLOR AND S TONEperformance, but we remind the reader that such commentary is largely based on intuition ratherthan empirical data.2.2 Dimensions of ComparisonIn addition to differing on evaluation metrics, we categorize TL algorithms along five dimensions,which we use as the main organizing framework for our survey of the literature:I Task difference assumptions: What assumptions does the TL method make about how thesource and target are allowed to differ? Examples of things that can differ between the sourceand target tasks include different system dynamics (i.e., the target task becomes harder tosolve is some incremental way), or different sets of possible actions at some states. Suchassumptions define the types of source and target tasks that the method can transfer between.Allowing transfer to occur between less similar source and target tasks gives more flexibilityto a human designer in the human-guided scenario. In the fully autonomous scenario, moreflexible methods are more likely to be able to successfully apply past knowledge to noveltarget tasks.II Source task selection: In the simplest case, the agent assumes that a human has performedsource task selection (the human-guided scenario), and transfers from one or more selectedtasks. More complex methods allow the agent to select a source task or set of source tasks.Such a selection mechanism may additionally be designed to guard against negative transfer,where transfer hurts the learner\u2019s performance. The more robust the selection mechanism,the more likely it is that transfer will be able to provide a benefit. While no definitive answerto this problem exists, successful techniques will likely have to account for specific targettask characteristics. For instance, Carroll and Seppi (2005) motivate the need for general tasksimilarity metrics to enable robust transfer, propose three different metrics, and then proceedto demonstrate that none is always \u201cbest,\u201d just as there is never a \u201cbest\u201d inductive bias in alearning algorithm.III Task Mappings: Many methods require a mapping to transfer effectively: in addition to knowing that a source task and target task are related, they need to know how they are related.Inter-task mappings (discussed in detail later in Section 3.4) are a way to define how twotasks are related. If a human is in the loop, the method may assume that such task mappingsare provided; if the agent is expected to transfer autonomously, such mappings have to belearned. Different methods use a variety of techniques to enable transfer, both on-line (whilelearning the target task) and offline (after learning the source task but before learning the target task). Such learning methods attempt to minimize the number of samples needed and/orthe computational complexity of the learning method, while still learning a mapping to enableeffective transfer.IV Transferred Knowledge: What type of information is transferred between the source andtarget tasks? This information can range from very low-level information about a specifictask (i.e., the expected outcome when performing an action in a particular location) to generalheuristics that attempt to guide learning. Different types of knowledge may transfer better orworse depending on task similarity. For instance, low-level information may transfer acrossclosely related tasks, while high-level concepts may transfer across pairs of less similar tasks.The mechanism that transfers knowledge from one task to another is closely related to what1640\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYis being transferred, how the task mappings are defined (III), and what assumptions about thetwo tasks are made (I).V Allowed Learners: Does the TL method place restrictions on what RL algorithm is used,such as applying only to temporal difference methods? Different learning algorithms havedifferent biases. Ideally an experimenter or agent would select the RL algorithm to use basedon characteristics of the task, not on the TL algorithm. Some TL methods require that thesource and target tasks be learned with the same method, other allow a class of methods to beused in both tasks, but the most flexible methods decouple the agents\u2019 learning algorithms inthe two tasks.An alternate TL framework may be found in the related work section of Lazaric (2008), arecent PhD thesis on TL in RL tasks. Lazaric compares TL methods in terms of the type of benefit(jumpstart, total reward, and asymptotic performance), the allowed differences between source andtarget (different goal states, different transition functions but the same reward function, and differentstate and action spaces) and the type of transferred knowledge (experience or structural knowledge).Our article is more detailed both in the number of approaches considered, the depth of descriptionabout each approach, and also uses a different organizational structure. In particular, we specifywhich of the methods improve which of five TL metrics, we note which of the methods accountfor source task training time rather than treating it as a sunk cost, and we differentiate methodsaccording to five dimensions above.3. Transfer for Reinforcement LearningIn this section we first give a brief overview of notation. We then summarize the methods discussedin this survey using the five dimensions previously discussed, as well as enumerating the possible attributes for these dimensions. Lastly, learning paradigms with goals similar to transfer are discussedin Section 3.5.3.1 Reinforcement Learning BackgroundRL problems are typically framed in terms of Markov decision processes (MDPs) (Puterman, 1994).For the purposes of this article, MDP and task are used interchangeably. In an MDP, there is some setof possible perceptions of the current state of the world, s \u2208 S, and a learning agent has one or moreinitial starting states, sinitial . The reward function, R : S 7\u2192 R, maps each state of the environmentto a single number which is the instantaneous reward achieved for reaching the state. If the task isepisodic, the agent begins at a start state and executes actions in the environment until it reachesa terminal state (one or more of the states in s f inal , which may be referred to as a goal state), atwhich point the agent is returned to a start state. An agent in an episodic task typically attempts tomaximize the average reward per episode. In non-episodic tasks, the agent attempts to maximizethe total reward, which may be discounted. By using a discount factor, \u03b3, the agent can weighimmediate rewards more heavily than future rewards, allowing it to maximize a non-infinite sum ofrewards.1641\fTAYLOR AND S TONEAn agent knows its current state in the environment, s \u2208 S.2 TL methods are particularly relevantin MDPs that have a large or continuous state, as these are the problems which are slow to learntabula rasa and for which transfer may provide substantial benefits. Such tasks typically factorthe state using state variables (or features), so that s = hx1 , x2 , . . . , xn i (see Figure 4). The agent\u2019sobserved state may be different from the true state if there is perceptual noise. The set A describesthe actions available to the agent, although not every action may be possible in every state.3 Thetransition function, T : S \u00d7 A 7\u2192 S, takes a state and an action and returns the state of the environmentafter the action is performed. Transitions may be non-deterministic, making the transition functiona probability distribution function. A learner senses the current state, s, and typically knows A andwhat state variables comprise S; however, it is generally not given R or T .A policy, \u03c0 : S 7\u2192 A, fully defines how a learner interacts with the environment by mappingperceived environmental states to actions. The success of an agent is determined by how well itmaximizes the total reward it receives in the long run while acting under some policy \u03c0. An optimalpolicy, \u03c0\u2217 , is a policy which does maximize the expectation of this value. Any reasonable learningalgorithm attempts to modify \u03c0 over time so that the agent\u2019s performance approaches that of \u03c0\u2217 inthe limit.There are many possible approaches to learning such a policy (depicted as a black box in Figure 4), including:\u2022 Temporal difference (TD) methods, such as Q-learning (Sutton, 1988; Watkins, 1989) andSarsa (Rummery and Niranjan, 1994; Singh and Sutton, 1996), learn by backing up experienced rewards through time. An estimated action-value function, Q : S \u00d7 A 7\u2192 R is learned,where Q(s, a) is the expected return found when executing action a from state s, and greedilyfollowing the current policy thereafter. The current best policy is generated from Q by simply selecting the action that has the highest value for the current state. Exploration, when theagent chooses an action to learn more about the environment, must be balanced with exploitation, when the agent selects what it believes to be the best action. One simple approach thatbalances the two is \u03b5-greedy action selection: the agent selects an random action with chance\u03b5, and the current best action is selected with probability 1 \u2212 \u03b5 (where \u03b5 is in [0,1]).\u2022 Policy search methods, such as policy iteration (dynamic programming), policy gradient(Williams, 1992; Baxter and Bartlett, 2001), and direct policy search (Ng and Jordan, 2000),are in some sense simpler than TD methods because they directly modify a policy over timeto increase the expected long-term reward by using search or other optimization techniques.\u2022 Dynamic programming (Bellman, 1957) approaches assume that a full model of the environment is known (i.e., S, A, T , and R are provided to the agent and are correct). No interactionwith the environment is necessary, but the agent must iteratively compute approximations forthe true value or action-value function, improving them over time.\u2022 Model-based or Model-learning methods (Moore and Atkeson, 1993; Kearns and Singh,1998) attempt to estimate the true model of the environment (i.e., T and R) by interacting2. If the agent only receives observations and does not know the true state, the agent may treat approximate its true stateas the observation (cf., Stone et al., 2005), or it may learn using the Partially Observable Markov Decision Process(POMDP) (cf., Kaelbling et al., 1998) problem formulation, which is beyond the scope of this survey.3. Although possible in principle, we are aware of no TL methods currently address MDPs with continuous actions.1642\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYEnvironmentT, Rsrax1x2x3...xnAgentFigure 4: An agent interacts with an environment by sequentially selecting an action in an observedstate, with the objective of maximizing an environmental reward signal.with the environment over time. Instance based methods (Ormoneit and Sen, 2002) saveobserved interactions with the environment and leverage the instance directly to predict themodel. Bayesian RL (Dearden et al., 1999) approaches use a mathematical model to explicitly represent uncertainty in the components of the model, updating expectations over time.The learned model is then typically used to help the agent decide how to efficiently explore orplan trajectories so that it can accrue higher rewards. While very successful in small tasks, fewsuch methods handle continuous state spaces (cf., Jong and Stone, 2007), and they generallyhave trouble scaling to tasks with many state variables due to the \u201ccurse of dimensionality.\u201d\u2022 Relational reinforcement learning (RRL) (Dzeroski et al., 2001) uses a different learningalgorithm as well as a different state representation. RRL may be appropriate if the stateof an MDP can be described in a relational or first-order language. Such methods work byreasoning over individual objects (e.g., a single block in a Blocksworld task) and thus may berobust to changes in numbers of objects in a task.\u2022 Batch learning methods (e.g., Least Squares Policy Iteration (Lagoudakis and Parr, 2003)and Fitted-Q Iteration (Ernst et al., 2005) are offline and do not attempt to learn as the agentinteracts with the environment. Batch methods are designed to be more sample efficient, asthey can store a number of interactions with the environment and use the data multiple timesfor learning. Additionally, such methods allow a clear separation of the learning mechanismfrom the exploration mechanism (which much decide whether to attempt to gather more dataabout the environment or exploit the current best policy).In tasks with small, discrete state spaces, Q and \u03c0 can be fully represented in a table. As thestate space grows, using a table becomes impractical, or impossible if the state space is continuous.In such cases, RL learning methods use function approximators, such as artificial neural networks,which rely on concise, parameterized functions and use supervised learning methods to set theseparameters. Function approximation is used in large or continuous tasks to better generalize experience. Parameters and biases in the approximator are used to abstract the state space so that observed1643\fTAYLOR AND S TONEdata can influence a region of state space, rather than just a single state, and can substantially increase the speed of learning.Some work in RL (Dean and Givan, 1997; Li et al., 2006; Mahadevan and Maggioni, 2007)has experimented with more systematic approaches to state abstractions (also called structural abstraction). Temporal abstractions have also been successfully used to increase the speed of learning.These macro-actions or options (Sutton et al., 1999) may allow the agent to leverage the sequenceof actions to learn its task with less data. Lastly, hierarchical methods, such as MAXQ (Dietterich,2000), allow learners exploit a task that is decomposed into different sub-tasks. The decompositiontypically enables an agent to learn each subtask relatively quickly and then combine them, resultingin an overall learning speed improvement (compared to methods that do not leverage such a sub-taskhierarchy).3.2 Transfer ApproachesHaving provided a brief overview of the RL notation used in this survey, we now enumerate possibleapproaches for transfer between RL tasks. This section lists attributes of methods used in the TLliterature for each of the five dimensions discussed in Section 2.2, and summarizes the surveyedworks in Table 1. The first two groups of methods apply to tasks which have the same state variablesand actions. (Section 4 discusses the TL methods in the first block, and Section 5 discusses themulti-task methods in the second block.) Groups three and four consider methods that transferbetween tasks with different state variables and actions. (Section 6 discusses methods that use arepresentation that does not change when the underlying MDP changes, while Section 7 presentsmethods that must explicitly account for such changes.) The last group of methods (discussedin Section 8) learns a mapping between tasks like those used by methods in the fourth group ofmethods. Table 2 concisely enumerates the possible values for the attributes, as well as providing akey to Table 1.In this section the mountain car task (Moore, 1991; Singh and Sutton, 1996), a standard RLbenchmark, will serve as a running example. In mountain car, an under-powered car moves alonga curve and attempts to reach a goal state at the top of the right \u201cmountain\u201d by selecting betweenthree actions on every timestep: {Forward, Neutral, Backward}, where Forward accelerates thecar in the positive x direction and Backward accelerates the car in the negative x direction. Theagent\u2019s state is described by two state variables: the horizontal position, x, and velocity, x\u0307. Theagent receives a reward of \u22121 on each time step. If the agent reaches the goal state the episode endsand the agent is reset to the start state (often the bottom of the hill, with zero velocity).3.2.1 A LLOWED TASK D IFFERENCESTL methods can transfer between MDPs that have different transition functions (denoted by t inTable 1), state spaces (s), start states (si ), goal states (s f ), state variables (v), reward functions (r),and/or action sets (a). For two of the methods, the agent\u2019s representation of the world (the agentspace, describing physical sensors and actuators) remains the same, while the true state variablesand actions (the problem-space, describing the task\u2019s state variables and macro-actions) can change(p in Table 1, discussed further in Section 6). There is also a branch of work that focuses on transferbetween tasks which are composed of some number of objects that may change between the sourceand the target task, such as when learning with RRL (# in Table 1). When summarizing the allowedtask differences, we will concentrate on the most salient features. For instance, when the source task1644\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYand target task are allowed to have different state variables and actions, the state space of the twotasks is different because the states are described differently, and the transition function and rewardfunction must also change, but we only indicate \u201ca\u201d and \u201cv.\u201dThese differences in the example mountain car task could be exhibited as:\u2022 t: using a more powerful car motor or changing the surface friction of the hill\u2022 s: changing the range of the state variables\u2022 si : changing where the car starts each episode\u2022 s f : changing the goal state of the car\u2022 v: describing the agent\u2019s state only by its velocity\u2022 r: rather than a reward of \u22121 on every step, the reward could be a function of the distancefrom the goal state\u2022 a: disabling the Neutral action\u2022 p: the agent could describe the state by using extra state variables, such as the velocity on theprevious timestep, but the agent only directly measures its current position and velocity\u2022 #: the agent may need to control two cars simultaneously on the hill3.2.2 S OURCE TASK S ELECTIONThe simplest method for selecting a source task for a given target task is to assume that only a singlesource task has been learned and that a human has picked it, assuring that the agent should use it fortransfer (h in Table 1). Some TL algorithms allow the agent to learn multiple source tasks and thenuse them all for transfer (all). More sophisticated algorithms build a library of seen tasks and useonly the most relevant for transfer (lib). Some methods are able to automatically modify a singlesource task so that the knowledge it gains from the modified task will likely be more useful in thetarget task (mod). However, none of the existing TL algorithms for RL can guarantee that the sourcetasks will be useful; a current open question is how to robustly avoid attempting to transfer from anirrelevant task.3.2.3 T RANSFERRED K NOWLEDGEThe type of knowledge transferred can be primarily characterized by its specificity. Low-levelknowledge, such as h s, a, r, s\u2032 i instances (I in Table 1), an action-value function (Q), a policy(\u03c0), a full task model (model), or prior distributions (pri), could all be directly leveraged by the TLalgorithm to initialize a learner in the target task. Higher level knowledge, such as what action touse in some situations (A: a subset of the full set of actions), partial policies or options (\u03c0 p ), rulesor advice (rule), important features for learning (fea), proto-value functions (pvf: a type of learnedfeature), shaping rewards (R), or subtask definitions (sub) may not be directly used by the algorithmto fully define an initial policy, but such information may help guide the agent during learning inthe target task.1645\fTAYLOR AND S TONE3.2.4 TASK M APPINGSThe majority of TL algorithms in this survey assume that no explicit task mappings are necessarybecause the source and target task have the same state variables and actions. In addition to havingthe same labels, the state variables and actions need to have the same semantic meanings in bothtasks. For instance, consider again the mountain car domain. Suppose that the source task hadthe actions A = {Forward, Neutral, Backward}. If the target task had the actions A = {Right,Neutral, Left}, a TL method would need some kind of mapping because the actions had differentlabels. Furthermore, suppose that the target task had the same actions as the source (A = {Forward,Neutral, Backward}) but the car was facing the opposite direction, so that Forward acceleratedthe car in the negative x direction and Backward accelerated the car in the positive x direction. Ifthe source and target task actions have different semantic meanings, there will also need to be somekind of inter-task mapping to enable transfer.Methods that do not use a task mapping are marked as \u201cN/A\u201d in Table 1. TL methods which aimto transfer between tasks with different state variables or actions typically rely on a task mapping todefine how the tasks are related (as defined in Section 3.4). Methods that use mappings and assumethat they are human-supplied mappings are marked as \u201csup\u201d in Table 1. A few algorithms leverageexperience gained in the source task and target task (exp) or a high-level description of the MDPsin order to learn task mappings.Methods using description-level knowledge differ primarily in what assumptions they makeabout what will be provided. One method assumes a qualitative understanding of the transitionfunction (T), which would correspond to knowledge like \u201ctaking the action Neutral tends to have apositive influence on the velocity in the positive x direction.\u201d Two methods assume knowledge ofone mapping (Ma : the \u201caction mapping\u201d) to learn a second mapping (the \u201cstate variable mapping\u201din Section 3.4). Three methods assume that the state variables are \u201cgrouped\u201d together to describeobjects (svg ). An example of the state variable grouping can be demonstrated in a mountain cartask with multiple cars: if the agent knew which position state variables referred to the same caras certain velocity state variables, it would know something about the grouping of state variables.These different assumptions are discussed in detail in Section 8.3.2.5 A LLOWED L EARNERSThe type of knowledge transferred directly affects the type of learner that is applicable (as discussed in Section 3.1). For instance, a TL method that transfers an action-value function wouldlikely require that the target task agent use a temporal difference method to exploit the transferredknowledge. The majority of methods in the literature use a standard form of temporal differencelearning (TD in Table 1), such as Sarsa. Other methods include Bayesian learning (B), hierarchicalapproaches (H), model-based learning (MB), direct policy search (PS), and relational reinforcementlearning (RRL). Some TL methods focus on batch learning (Batch), rather than on-line learning.Two methods use case based reasoning (CBR) (Aamodt and Plaza, 1994) to help match previouslylearned instances with new instances, and one uses linear programming (LP) to calculate a valuefunction from a given model (as part of a dynamic programming routine).3.3 Multi-Task LearningClosely related to TL algorithms, and discussed in Section 5, are multi-task learning (MTL) algorithms. The primary distinction between MTL and TL is that multi-task learning methods assume1646\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYAllowed SourceTaskTransferredTaskTaskMappings KnowledgeDifferences SelectionSame state variables and actions: Section 4Selfridge et al. (1985)thN/AQAsada et al. (1994)sihN/AQSingh (1992)rallN/AQAtkeson and Santamaria (1997)rallN/AmodelAsadi and Huber (2007)rhN/A\u03c0pAndre and Russell (2002)r, shN/A\u03c0pRavindran and Barto (2003b)s, thN/A\u03c0pFerguson and Mahadevan (2006)r, shN/ApvfSherstov and Stone (2005)sf , tmodN/AAMadden and Howley (2004)s, tallN/AruleLazaric (2008)s, tlibN/AIMulti-Task learning: Section 5Mehta et al. (2008)rlibN/A\u03c0pPerkins and Precup (1999)tallN/A\u03c0pFoster and Dayan (2004)sfallN/AsubFernandez and Veloso (2006)si , s flibN/A\u03c0Tanaka and Yamamura (2003)tallN/AQSunmola and Wyatt (2006)tallN/ApriWilson et al. (2007)r, s fallN/ApriWalsh et al. (2006)r, sallN/AfeaLazaric (2008)\u22c6rallN/AfeaDifferent state variables and actions \u2013 no explicit task mappings: Section 6Konidaris and Barto (2006)phN/ARKonidaris and Barto (2007)phN/A\u03c0pBanerjee and Stone (2007)a, vhN/AfeaGuestrin et al. (2003)#hN/AQCroonenborghs et al. (2007)#hN/A\u03c0pRamon et al. (2007)#hN/AQSharma et al. (2007)#hN/AQDifferent state variables and actions \u2013 inter-task mappings used: Section 7Taylor et al. (2007a)a, vhsupQTaylor et al. (2007b)a, vhsup\u03c0Taylor et al. (2008b)a, vhsupITorrey et al. (2005)a, r, vhsupruleTorrey et al. (2006)Torrey et al. (2007)a, r, vhsup\u03c0pTaylor and Stone (2007b)a, r, vhsupruleLearning inter-task mappings: Section 8Kuhlmann and Stone (2007)a, vhTQLiu and Stone (2006)a, vhTN/ASoni and Singh (2006)a, vhMa , svg , expN/ATalvitie and Singh (2007)a, vhMa , svg , expN/ATaylor et al. (2007b)\u22c6a, vhsvg , expN/ATaylor et al. (2008c)a, vhexpN/ACitationAllowedLearnersTLMetricsTDTDTDMBHHTDBatchTDTDBatchtt\u2020ttap, trap, j, trtttrtrtttrtt, trj, trHTDTD, HTDTDBBanyBatchtrttj, trtrj, trj, trj, trttap, trTDj, trTDj, trTDap, j, trLPjRRLap, j, trRRL ap, j, tt\u2020 , trTD, CBRj, trTDPSMBtt\u2020tt\u2020ap, trTDj, trTDany/TDj, trj, tt\u2020 , trTDallallallallallj, trN/Aap, j, trjtt\u2020j, trTable 1: This table lists all the TL methods discussed in this survey and classifies each in terms ofthe five transfer dimensions (the key for abbreviations is in Table 2). Two entries, markedwith a \u22c6, are repeated due to multiple contributions. Metrics that account for source tasklearning time, rather than ignoring it, are marked with a \u2020.1647\fTAYLOR AND S TONEaprsisftv#allhlibmodexpMaN/AsupsvgTAllowed Task Differencesaction set may differproblem-space may differ(agent-space must be identical)reward function may differthe start state may changegoal state may movetransition function may differstate variables may differnumber of objects in state may differSource Task Selectionall previously seen tasks are usedone source task is used (human selected)tasks are organized into a libraryand one or more may be useda human provides a source task thatthe agent automatically modifiesTask Mappingsagent learns the mappings from experiencethe method must be provided with anaction mapping (learns state variable mapping)no mapping is useda human supplies the task mappingsmethod is provided groupings of state variableshigher-level knowledge is providedabout transfer functions to learn mappingAfeaImodel\u03c0\u03c0ppripvfQRrulesubTransferred Knowledgean action settask featuresexperience instancestask modelpoliciespartial policies (e.g., options)distribution priorsproto-value functionaction-value functionshaping rewardrules or advicesubtask definitionsBBatchCBRHLPMBPSRRLTDAllowed LearnersBayesian learnerbatch learnercase based reasoninghierarchical value-function learnerlinear programmingmodel based learnerpolicy search learnerrelational reinforcement learningtemporal difference learnerapjtrttTL Metricsasymptotic performance increasedjumpstart demonstratedtotal reward increasedtask learning time reducedTable 2: This key provides a reference to the abbreviations in Table 1.all problems experienced by the agent are drawn from the same distribution, while TL methods mayallow for arbitrary source and target tasks. For example, a MTL task could be to learn a series ofmountain car tasks, each of which had a transition function that was drawn from a fixed distributionof functions that specified a range of surface frictions. Because of this assumption, MTL methodsgenerally do not need task mappings (dimension III in Section 2.2). MTL algorithms may be usedto transfer knowledge between learners, similar to TL algorithms, or they can attempt to learn howto act on the entire class of problems.When discussing supervised multitask learning (cf., Caruana, 1995, 1997), data from multipletasks can be considered simultaneously. In an RL setting, rather than trying to learn multiple problems simultaneously (i.e., acting in multiple MDPs), agents tackle a sequence of tasks which aremore closely related than in TL settings. It is possible that RL agents could learn multiple taskssimultaneously in a multiagent setting (Stone and Veloso, 2000), but this has not yet been exploredin the literature. For the purposes of this survey, we will assume, as in other transfer settings, thattasks are learned in a sequential order.1648\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYSutton et al. (2007) motivate this approach to transfer by suggesting that a single large taskmay be most appropriately tackled as a sequential series of subtasks. If the learner can track whichsubtask it is currently in, it may be able to transfer knowledge between the different subtasks, whichare all presumably related because they are part of the same overall task. Such a setting may providea well-grounded way of selecting a distribution of tasks to train over, either in the context of transferor for multi-task learning. Note also that the additional assumptions in an MTL setting may beleveraged to allow a more rigorous theoretical analysis than in TL (cf., Kalma\u0301r and Szepesva\u0301ri,1999).3.4 Inter-Task MappingsTransfer methods that assume the source and target tasks use the same state variables and actions, asis the case in MTL, typically do not need an explicit mapping between task. In order to enable TLmethods to transfer between tasks that do have such differences, the agent must know how the tasksare related. This section provides a brief overview of inter-task mappings (Taylor et al., 2007a), oneformulation of task mappings. Task mappings like these are used by transfer methods discussed inSection 7.To transfer effectively, when an agent is presented with a target task that has a set of actions(A\u2032 ), it must know how those actions are related to the action set in the source task (A). (For the sakeof exposition we focus on actions, but an analogous argument holds for state variables.) If the TLmethod knows that the two action sets are identical, no action mapping is necessary. However, ifthis is not the case, the agent needs to be told, or learn, how the two tasks are related. For instance,if the agent learns to act in a source task with the actions Forward and Backward, but the target taskuses the actions Right and Left, the correspondence between these action sets may not be obvious.Even if the action labels were the same, if the actions had different semantic meanings, the defaultcorrespondence may be incorrect. Furthermore, if the cardinality of A and A\u2032 are not equal, thereare actions without exact equivalences.One option is to define an action mapping (\u03c7A ) such that actions in the two tasks are mapped sothat their effects are \u201csimilar,\u201d where similarity depends on the transfer and reward functions in thetwo MDPs.4 Figure 5 depicts an action mapping as well as a state-variable mapping (\u03c7X ) betweentwo tasks. A second option is to define a partial mapping (Taylor et al., 2007b), such that any novelactions in the target task are ignored. Consider adding an action in a mountain car target task, pullhand brake, which did not have an analog in the source task. The partial mapping could mapForward to Forward, and Backward to Backward, but not map pull hand brake to any sourcetask action. Because inter-task mappings are not functions, they are typically assumed to be easilyinvertible (i.e., mapping source task actions into target task actions, rather than target task actionsto source task actions).It is possible that mappings between states, rather than between state variables, could be used fortransfer, although no work has currently explored this formulation.5 Another possible extension isto link the mappings rather than making them independent. For instance, the action mapping coulddepend on the state that the agent is in, or the state variable mapping could depend on the action4. An inter-task mapping often maps multiple entities in the target task to single entities in the source task because thetarget task is more complex than the source, but the mappings may be one-to-many, one-to-one, or many-to-many.5. However, there are many possibilities for using this approach for transfer learning, such as through bisimulation (seeSection 9).1649\fTAYLOR AND S TONESource Taska1a2\u03c7ATarget Taska1a2...a3...amanx1\u03c7Xx1x2x3x2......xjxkFigure 5: \u03c7A and \u03c7X are independent mappings that describe similarities between two MDPs. Thesemappings describe how actions in the target task are similar to actions in the source taskand how state variables in the target task are similar to state variables in the source task,respectively.selected. Though these extensions may be necessary based on the demands of particular MDPs,current methods have functioned well in a variety of tasks without such enhancements.For a given pair of tasks, there could be many ways to formulate inter-task mappings. Much ofthe current TL work assumes that a human has provided a (correct) mapping to the learner. Workthat attempts to learn a mapping that can be effectively used for transfer is discussed in Section 8.3.5 Related ParadigmsIn this survey, we consider transfer learning algorithms that use one or more source tasks to betterlearn in a different, but related, target task. There is a wide range of methods designed to improvethe learning speed of RL methods. This section discusses four alternate classes of techniques forspeeding up learning and differentiates them from transfer. While some TL algorithms may reasonably fit into one or more of the following categories, we believe that enumerating the types ofmethods not surveyed in this article will help clarify our subject of interest.3.5.1 L IFELONG L EARNINGThrun (1996) suggested the notion of lifelong learning where an agent may experience a sequenceof tasks. Others (cf., Sutton et al., 2007) later extended this idea to the RL setting, suggestingthan an agent interacting with the world for an extended period of time will necessarily have toperform in a sequence of tasks. Alternately, the agent may discover a series of spatially, ratherthan temporally, separated sub-tasks. Transfer would be a key component of any such system, butthe lifelong learning framework is more demanding than that of transfer. First, transfer algorithmsmay reasonably focus on transfer between a single pair of related tasks, rather than attempting toaccount for any future task that an agent could encounter. Second, transfer algorithms are typically1650\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYtold when a new task has begun, whereas in lifelong learning, agents may be reasonably expectedto automatically identify new sub-tasks within the global MDP (i.e., the real world).3.5.2 I MITATION L EARNINGThe primary motivations for imitation methods are to allow agents to learn by watching anotheragent with similar abilities (Price and Boutilier, 2003; Syed and Schapier, 2007) or a human (Abbeeland Ng, 2005; Kolter et al., 2008) perform a task. Such algorithms attempt to learn a policy byobserving an outside actor, potentially improving upon the inferred policy. In contrast, our definitionof transfer learning focuses on agents successfully reusing internal knowledge on novel problems.3.5.3 H UMAN A DVICEThere is a growing body of work integrating human advice into RL learners. For instance, a humanmay provide action suggestions to the agent (cf., Maclin and Shavlik, 1996; Maclin et al., 2005)or guide the agent through on-line feedback (cf., Knox and Stone, 2008). Leveraging humans\u2019background and task-specific knowledge can significantly improve agents\u2019 learning ability, but itrelies on a human being tightly integrated into the learning loop, providing feedback in an on-linemanner. This survey instead concentrates on transfer methods in which a human is not continuouslyavailable and agents must learn autonomously.3.5.4 S HAPINGReward shaping (Colombetti and Dorigo, 1993; Mataric, 1994) in an RL context typically refers toallowing agent to train on an artificial reward signal rather than R. For instance, in the mountaincar task, the agent could be given a higher reward as it gets closer to the goal state, rather thenreceiving \u22121 at every state except the goal. However, if the human can compute such a reward,s/he would probably already know the goal location, knowledge that the agent typically does nothave. Additionally, the constructed reward function must be a potential function. If it is not, theoptimal policy for the new MDP could be different from that of the original (Ng et al., 1999). Asecond definition of shaping follows Skinner\u2019s research (Skinner, 1953) where the reward functionis modified over time in order to direct the behavior of the learner. This method, as well as theapproach of using a static artificial reward, are ways of injecting human knowledge into the taskdefinition to improve learning efficacy.Erez and Smart (2008) have argued for a third definition of shaping as any supervised, iterative,process to assist learning. This includes modifying the dynamics of the task over time, modifying theinternal learning parameters over time, increasing the actions available to the agent, and extendingthe agent\u2019s policy time horizon (e.g., as done in value iteration). All of these methods rely on ahuman to intelligently assist the agent in its learning task and may leverage transfer-like methodsto successfully reuse knowledge between slightly different tasks. When discussing transfer, we willemphasize how knowledge is successfully reused rather than how a human may modify tasks toachieve the desired agent behavior improve agent learning performance.3.5.5 R EPRESENTATION T RANSFERTransfer learning problems are typically framed as leveraging knowledge learned on a source taskto improve learning on a related, but different, target task. Taylor and Stone (2007a) examine the1651\fTAYLOR AND S TONEAllowed SourceTaskTransferred Allowed TLTaskTaskMappings Knowledge Learners MetricsDifferences SelectionSame state variables and actions: Section 4Selfridge et al. (1985)thN/AQTDtt\u2020Asada et al. (1994)sihN/AQTDttSingh (1992)rallN/AQTDap, trAtkeson and Santamaria (1997)rallN/AmodelMBap, j, trAsadi and Huber (2007)rhN/A\u03c0pHttAndre and Russell (2002)r, shN/A\u03c0pHtrRavindran and Barto (2003b)s, thN/A\u03c0pTDtrFerguson and Mahadevan (2006)r, shN/ApvfBatchttSherstov and Stone (2005)sf , tmodN/AATDtrMadden and Howley (2004)s, tallN/AruleTDtt, trLazaric (2008)s, tlibN/AIBatchj, trCitationTable 3: This table reproduces the first group of methods from Table 1.complimentary task of transferring knowledge between agents with different internal representations (i.e., the function approximator or learning algorithm) of the same task. Allowing for suchshifts in representation gives additional flexibility to an agent designer; past experience may betransferred rather than discarded if a new representation is desired. A more important benefit isthat changing representations partway through learning can allow agents to achieve better performance in less time. Selecting a representation is often key for solving a problem (cf., the mutilatedcheckerboard problem McCarthy 1964 where humans\u2019 internal representations of a problem drastically changes the problem\u2019s solvability) and different representations may make transfer more orless difficult. However, representation selection is a difficult problem in RL in general and discussions of representation selection (or its applications to transfer efficacy) are beyond the scope of thisarticle.4. Transfer Methods for Fixed State Variables and ActionsTo begin our survey of TL methods, we examine the first group of methods in Table 1, reproducedin Table 3. These techniques may be used for transfer when the source and target tasks use the samestate variables and when agents in both tasks have the same set of actions (see Figure 6).In one of the earliest TL works for RL, Selfridge et al. (1985) demonstrated that it was fasterto learn to balance a pole on a cart by changing the task\u2019s transition function, T , over time. Thelearner was first trained on a long and light pole. Once it successfully learned to balance the polethe task was made harder: the pole was shortened and made heavier. The total time spent trainingon a sequence of tasks and reusing the learned function approximator was faster than training on thehardest task directly.6Similarly, the idea of learning from easy missions (Asada et al., 1994) also relies on a humanconstructing a set of tasks for the learner. In this work, the task (for example, a maze) is madeincrementally harder not by changing the dynamics of the task, but by moving the agent\u2019s initial6. As discussed in Section 3.5.3, we classify this work as transfer rather than as a \u201chuman advice\u201d method; while thehuman may assist the agent in task selection, s/he does not provide direct on-line feedback while the agent learns.1652\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYEnvironmentT, Rsrax1x2x3...xnAgentFigure 6: Methods in Section 4 are able to transfer between tasks that have different state spaces,different transition functions, and different reward functions, but only if the source andtarget tasks have the same actions and state variables. Dashed circles indicate the MDPcomponents which may differ between the source task and target task.state, sinitial , further and further from the goal state. The agent incrementally learns how to navigateto the exit faster than if it had tried to learn how to navigate the full maze directly. This methodrelies on having a known goal state from which a human can construct a series of source tasks ofincreasing difficulty.Selfridge et al. (1985) and Asada et al. (1994) provide useful methods for improving learning,which follow from Skinner\u2019s animal training work. While they require a human to be in the loop, andto understand the task well enough to provide the appropriate guidance to the learner, these methodsare relatively easy ways to leverage human knowledge. Additionally, they may be combined withmany of the transfer methods that follow.Rather than change a task over time, one could consider breaking down a task into a seriesof smaller tasks. This approach can be considered a type of transfer in that a single large targettask can be treated as a series of simpler source tasks. Singh (1992) uses a technique he labelscompositional learning to discover how to separate temporally sequential subtasks in a monolithictask. Each subtask has distinct beginning and termination conditions, and each subtask will besignificantly easier to learn in isolation than in the context of the full task. Only the reward function,R, is allowed to change between the different subtasks and none of the other MDP componentsmay vary, but the total reward can be increased. If subtasks in a problem are recognizable by statefeatures, such subtasks may be automatically identified via vision algorithms (Drummond, 2002).Again, breaking a task into smaller subtasks can improve both the total reward and the asymptoticperformance. This particular method is only directly applicable to tasks in which features clearlydefine subtasks due to limitations in the vision algorithm used. For instance, in a 2D navigationtask each room may be a subtask and the steep value function gradient between impassable walls iseasily identifiable. However, if the value function gradient is not distinct between different subtasks,or the subtask regions of state space are not polygonal, the algorithm will likely fail to automaticallyidentify subtasks.In Atkeson and Santamaria (1997), transfer between tasks in which only the reward functioncan differ are again considered. Their method successfully transfers a locally weighted regression1653\fTAYLOR AND S TONEmodel of the transition function, which is learned in a source task, by directly applying it to a targettask. Because their model enables planning over the transition function and does not account for thereward function, they show significant improvement to the jumpstart and total reward, as well as theasymptotic performance.The next three methods transfer partial policies, or options, between different tasks. First, Asadiand Huber (2007) have the agent identify states that \u201clocally form a significantly stronger \u2018attractor\u2019for state space trajectories\u201d as subgoals in the source task (i.e., a doorway between rooms that isvisited relatively often compared to other parts of the state space). The agent then learns options toreach these subgoals via a learned action-value function, termed the decision-level model. A secondaction-value function, the evaluation-level model, includes all actions and the full state space. Theagent selects actions by only considering the decision-level model but uses discrepancies betweenthe two models to automatically increase the complexity of the decision-level model as needed.The model is represented as a Hierarchical Bounded Parameter SMDP, constructed so that theperformance of an optimal policy in the simplified model will be within some fixed bound of theperformance of the optimal policy on the initial model. Experiments show that transferring boththe learned options and the decision-level representation allow the target task agent to learn fasteron a task with a different reward function. In the roughly 20,000 target task states, only 81 distinctstates are needed in the decision-level model, as most states do not need to be distinguished whenselecting from learned options.Second, Andre and Russell (2002) transfer learned subroutines between tasks, which are similarto options. The authors assume that the source and target tasks have a hierarchical structure, such asin the taxi domain (Dietterich, 2000). On-line analysis can uncover similarities between two tasksif there are only small differences in the state space (e.g., the state variables do not change) andthen directly copy over the subroutine, which functions as a partial policy, thereby increasing thetotal reward in the target task. This method highlights the connection between state abstraction andtransfer; if similarities can be found between parts of the state space in the two tasks, it is likely thatgood local controllers or local policies can be directly transferred.Third, Ravindran and Barto (2003b) learn relativized options in a small, human selected sourcetask. When learning in the target task, the agent is provided these options and a set of possibletransformations it could apply to them so that they were relevant in the target task. For instance, ifthe source task were a small grid navigation task, the target task could be a large grid composed ofrooms with similar shape to the source task and the transformations could be rotation and reflectionoperators. The agent uses experience in the target and Bayesian parameter estimation to selectwhich transformations to use so that the target task\u2019s total reward is increased. Learning time in thesource task is ignored, but is assumed to be small compared to the target task learning time.Next, Ferguson and Mahadevan (2006) take a unique approach to transfer information about thesource task\u2019s structure. Proto-value functions (PVFs) (Mahadevan and Maggioni, 2007) specify anortho-normal set of basis functions, without regard to R, which can be used to learn an action-valuefunction. After PVFs are learned in a small source task, they can be transferred to another discreteMDP that has a different goal or small changes to the state space. The target task can be learnedfaster and achieve higher total reward with the transferred PVFs than without. Additionally, thePVF can be scaled to larger tasks. For example, the target maze could have twice the width andheight of the source maze: R, S, and T are all scaled by the same factor. In all cases only the targettask time is counted.1654\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYThe goal of learning PVFs is potentially very useful for RL in general and TL in particular.It makes intuitive sense that high-level information about how to best learn in a domain, such asappropriate features to reason over, may transfer well across tasks. There are few examples of metalearners where TL algorithms learn high level knowledge to assist the agent in learning, rather thanlower-level knowledge about how to act. However, we believe that there is ample room for suchmethods, including methods to learn other domain-specific learning parameters, such as learningrates, function approximator representations, an so on.Instead of biasing the target task agent\u2019s learning representation by transferring a set of basisfunctions, Sherstov and Stone (2005) consider how to bias an agent by transferring an appropriateaction set. If tasks have large action sets, all actions could be considered when learning each task,but learning would be much faster if only a subset of the actions needed to be evaluated. If a reducedaction set is selected such that using it could produce near-optimal behavior, learning would be muchfaster with very little loss in final performance. The standard MDP formalism is modified so that theagent reasons about outcomes and classes. Informally, rather than reasoning over the probability ofreaching a given state after an action, the learner reasons over the actions\u2019 effect, or outcome. Statesare grouped together in classes such that the probability of a given outcome from a given action willbe the same for any state in a class. The authors then use their formalism to bound the value lost byusing their abstraction of the MDP. If the source and target are very similar, the source task can belearned with the full action set, the optimal action set can be found from the learned Q-values, andlearning the target with this smaller action set can speed up learning in the target task. The authorsalso introduce random task perturbation (RTP) which creates a series of source tasks from a singlesource task, thereby producing an action set which will perform well in target tasks that are lesssimilar to the source task. Transfer with and without RTP is experimentally compared to learningwithout transfer. While direct action transfer can perform worse than learning without transfer, RTPwas able to handle misleading source task experience so that performance was improved relative tono transfer in all target tasks and performance using the transferred actions approaches that of theoptimal target task action set. Performance was judged by the total reward accumulated in the targettask. Leffler et al. (2007) extends the work of Sherstov and Stone by applying the outcome/classframework to learn a single task significantly faster, and provides empirical evidence of correctnessin both simulated and physical domains.The idea of RTP is not only unique in this survey, but it is also potentially a very useful idea fortransfer in general. While a number of TL methods are able to learn from a set of source tasks, noothers attempt to automatically generate these source tasks. If the goal of an agent is perform as wellas possible in a novel target task, it makes sense that the agent would try to train on many sourcetasks, even if they are artificial. How to best generate such source tasks so that they are most likelyto be useful for an arbitrary target task in the same domain is an important area of open research.Similar to previously discussed work (Selfridge et al., 1985; Asada et al., 1994), ProgressiveRL (Madden and Howley, 2004) is a method for transferring between a progression of tasks of increasing difficulty, but is limited to discrete MDPs. After learning a source task, the agent performsintrospection where a symbolic learner extracts rules for acting based on learned Q-values from allpreviously learned tasks. The RL algorithm and introspection use different state features. Thus thetwo learning mechanisms learn in different state spaces, where the state features for the symboliclearner are higher-level and contain information otherwise hidden from the agent. When the agentacts in a novel task, the first time it reaches a novel state it initialize the Q-values of that state so thatthe action suggested by the learned rule is preferred. Progressive RL allows agents to learn infor1655\fTAYLOR AND S TONEmation in a set of tasks and then abstract the knowledge to a higher-level representation, allowingthe agent to achieve higher total reward and reach the goal state for the first time faster. Time spentin the source task(s) is not counted.Finally, Lazaric (2008) demonstrates that source task instances can be usefully transferred between tasks. After learning one or more source tasks, some experience is gathered in the target task,which may have a different state space or transition function. Saved instances (that is, observedhs, a, r, s\u2032 i tuples) are compared to instances from the target task. Instances from the source tasksthat are most similar, as judged by their distance and alignment with target task data, are transferred.A batch learning algorithm then uses both source instances and target instances to achieve a higherreward and a jumpstart. Region transfer takes the idea one step further by looking at similarity withthe target task per-sample, rather than per task. Thus, if source tasks have different regions of thestate space which are more similar to the target, only those most similar regions can be transferred.In these experiments, time spent training in the target task is not counted towards the TL algorithm.Region transfer is the only method surveyed which explicitly reasons about task similarity indifferent parts of the state space, and then selects source task(s) to transfer from. In domains wheretarget tasks have regions of the state space that are similar to one or more source tasks, and otherareas which are similar to other source tasks (or are similar to no source tasks), region transfer mayprovide significant performance improvements. As such, this method provides a unique approach tomeasuring, and exploiting, task similarity on-line. It is likely that this approach will inform futuretransfer methods, and is one possible way of accomplishing step # 1 in Section 2: Given a targettask, select an appropriate source task from which to transfer, if one exists.Taken together, these TL methods show that it is possible to efficiently transfer many differenttypes of information between tasks with a variety of differences. It is worth re-emphasizing thatmany TL methods may be combined with other speedup methods, such as reward shaping, or withother transfer methods. For instance, when transferring between maze tasks, basis functions couldbe learned (Ferguson and Mahadevan, 2006) in the source task, a set of actions to transfer couldbe selected after training on a set of additional generated source tasks (Sherstov and Stone, 2005),and then parts of different source tasks could be leveraged to learn a target task (Lazaric, 2008). Asecond example would be to start with a simple source task and change it over time by modifyingthe transition function (Selfridge et al., 1985) and start state (Asada et al., 1994), while learningoptions (Ravindran and Barto, 2003b), until a difficult target task is learned. By examining how thesource and target task differ and what base learning method is used, RL practitioners may selectone or more TL method to apply to their domain of interest. However, in the absence of theoreticalguarantees of transfer efficacy, any TL method has the potential to be harmful, as discussed furtherin Section 9.2.5. Multi-Task Learning MethodsThis section discusses scenarios where the source tasks and target task have the same state variablesand actions. However, these methods (see Table 4, reproduced from Table 1) are explicitly MTL,and all methods in this section are designed to use multiple source tasks (see Figure 7). Somemethods leverage all experienced source tasks when learning a novel target task and others are ableto choose a subset of previously experienced tasks. Which approach is most appropriate dependson the assumptions about the task distribution: if tasks are expected to be similar enough that allpast experience is useful, there is no need to select a subset. On the other hand, if the distribution of1656\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYAllowed SourceTaskTransferred Allowed TLTaskTaskMappings Knowledge Learners MetricsDifferences SelectionCitationMulti-Task learning: Section 5Mehta et al. (2008)Perkins and Precup (1999)Foster and Dayan (2004)Fernandez and Veloso (2006)Tanaka and Yamamura (2003)Sunmola and Wyatt (2006)Wilson et al. (2007)Walsh et al. (2006)Lazaric (2008)rtsfsi , s fttr, s fr, srliballallliballallallallall\u03c0p\u03c0psub\u03c0QpriprifeafeaN/AN/AN/AN/AN/AN/AN/AN/AN/AHTDTD, HTDTDBBanyBatchtrttj, trtrj, trj, trj, trttap, trTable 4: This table reproduces the group of MTL methods from Table 1.EnvironmentEnvironmentT, RsT, Rasrax1x1x2x2x3x3......xnxnEnvironmentT, RsraAgentAgentEnvironmentEnvironmentx3T, RT, Rxnrasrax1x1x2x2x3x3......xnxnAgentx1x2...srAgentAgentFigure 7: Multi-task learning methods assume tasks are chosen from a fixed distribution, use oneor more source tasks to help learn the current task, and assume that all the tasks have thesame actions and state variables. Dashed circles indicate the MDP components whichmay differ between tasks.tasks is multi-modal, it is likely that transferring from all tasks is sub-optimal. None of the methodsaccount for time spent learning in the source task(s) as the primary concern is effective learning onthe next task chosen at random from an unknown (but fixed) distribution of MDPs.Variable-reward hierarchical reinforcement learning (Mehta et al., 2008) assumes that the learnerwill train on a sequence of tasks which are identical except for different reward weights. The reward weights define how much reward is assigned via a linear combination of reward features. Theauthors provide the reward features to the agent for a given set of tasks. For instance, in a real-timestrategy domain different tasks could change the reward features, such as the benefit from collectingunits of gold or from damaging the enemy. However, it is unclear how many domains of interesthave reward features, which are provided to the agent at the start of each task. Using a hierarchicalRL method, subtask policies are learned. When a novel target task is encountered, the agent sets theinitial policy to that of the most similar source task, as determined by the dot product with previ1657\fTAYLOR AND S TONEously observed reward weight vectors. The agent then uses an \u03b5-greedy action selection method ateach level of the task hierarchy to decide whether to use the best known sub-task policy or explore.Some sub-tasks, such as navigation, will never need to be relearned for different tasks because theyare unaffected by the reward weights, but any suboptimal sub-task policies will be improved. As theagent experiences more tasks, the total reward in each new target task increases, relative to learningthe task without transfer.A different problem formulation is posed by Perkins and Precup (1999) where the transitionfunction, T , may change after reaching the goal. Upon reaching the goal, the agent is returned tothe start state and is not told if, or how, the transition function has changed, but it knows that T isdrawn randomly from some fixed distribution. The agent is provided a set of hand-coded optionswhich assist in learning on this set of tasks. Over time, the agent learns an accurate action-valuefunction over these options. Thus, a single action-value function is learned over a set of tasks,allowing the agent to more quickly reach the goal on tasks with novel transition functions.Instead of transferring options, Foster and Dayan (2004) aim to identify sub-tasks in a sourcetask and use this information in a target task, a motivation similar to that of Singh (1992). Tasksare allowed to differ in the placement of the goal state. As optimal value functions are learnedin source tasks, an expectation-maximization algorithm (Dempster et al., 1977) identifies different\u201cfragmentations,\u201d or sub-tasks, across all learned tasks. Once learned, the fragmentations are used toaugment the state of the agent. Each sub-problem can be learned independently; when encounteringa new task, much of the learning is already complete because the majority of sub-problems areunchanged. The fragmentations work with both a flat learner (i.e., TD) and an explicitly hierarchicallearner to improve the jumpstart and total reward.Probabilistic policy reuse (Fernandez and Veloso, 2006) also considers a distribution of tasks inwhich only the goal state differs, but is one of the most robust MTL methods in terms of appropriatesource task selection. Although the method allows a single goal state to differ between the tasks,it requires that S, A, and T remain constant. If a newly learned policy is significantly differentfrom existing policies, it is added to a policy library. When the agent is placed in a novel task, onevery timestep, it can choose to: exploit a learned source task policy, exploit the current best policyfor the target task, or randomly explore. If the agent has multiple learned policies in its library,it probabilistically selects between policies so that over time more useful policies will be selectedmore often. While this method allows for probabilistic mixing of the policies, it may be possibleto treat the past policies as options which can be executed until some termination condition is met,similar to a number of previously discussed methods. By comparing the relative benefits of mixingpast policies and treating them as options, it may be possible to better understand when each of thetwo approaches is most useful.The idea of constructing an explicit policy library is likely to be useful in future TL research,particularly for agents that train on a number of source tasks that have large qualitative differences(and thus very different learned behaviors). Although other methods also separately record information from multiple source tasks (cf., Mehta et al., 2008; Lazaric, 2008), Fernandez and Velosoexplicitly reason about the library. In addition to reasoning over the amount of information stored,as a function of number and type of source tasks, it will be useful to understand how many targettask samples are needed to select the most useful source task(s).Unlike probabilistic policy reuse, which selectively transfers information from a single sourcetask, Tanaka and Yamamura (2003) gather statistics about all previous tasks and use this amalgamated knowledge to learn novel tasks faster. Specifically, the learner keeps track of the average1658\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYand the deviation of the action value for each (s, a) pair observed in all tasks. When the agentencounters a new task, it initializes the action-value function so that every (s, a) pair is set to thecurrent average for that pair, which provides a benefit relative to uninformed initialization. As theagent learns the target task with Q-learning and prioritized sweeping,7 the agent uses the standarddeviation of states\u2019 Q-values to set priorities on TD backups. If the current Q-value is far from theaverage for that (s, a) pair, its value should be adjusted more quickly, since it is likely incorrect (andthus should be corrected before affecting other Q-values). Additionally, another term accounting forthe variance within individual trials is added to the priority; Q-values that fluctuate often within aparticular trial are likely wrong. Experiments show that this method, when applied to sets of discretetasks with different transition functions, can provide significant improvement to jumpstart and totalreward.The next two methods consider how priors can be effectively learned by a Bayesian MTL agent.First, Sunmola and Wyatt (2006) introduce two methods that use instances from source tasks to setpriors in a Bayesian learner. Both methods constrain the probabilities of the target task\u2019s transitionfunction by using previous instances as a type of prior. The first method uses the working prior togenerate possible models which are then tested against data in the target task. The second methoduses a probability perturbation method in conjunction with observed data to improve models generated by the prior. Initial experiments show that the jumpstart and total reward can be improved ifthe agent has an accurate estimation of the prior distributions of the class from which the target isdrawn. Second, Wilson et al. (2007) consider learning in a hierarchical Bayesian RL setting. Settingthe prior for Bayesian models is often difficult, but in this work the prior may be transferred frompreviously learned tasks, significantly increasing the learning rate. Additionally, the algorithm canhandle \u201cclasses\u201d of MDPs, which have similar model parameters, and then recognize when a novelclass of MDP is introduced. The novel class may then be added to the hierarchy and a distinct priormay be learned, rather than forcing the MDP to fit into an existing class. The location of the goalstate and the parameterized reward function may differ between the tasks. Learning on subsequenttasks shows a clear performance improvement in total reward, and some improvement in jumpstart.While Bayesian methods have been shown to be successful when transferring between classification tasks (Roy and Kaelbling, 2007), and in non-transfer RL (Dearden et al., 1999), only thetwo methods above use it in RL transfer. The learner\u2019s bias is important in all machine learningsettings. However, Bayesian learning makes such bias explicit. Being able to set the bias throughtransfer from similar tasks may prove to be a very useful heuristic\u2014we hope that additional transfermethods will be developed to initialize Bayesian learners from past tasks.Walsh et al. (2006) observe that \u201cdeciding what knowledge to transfer between environmentscan be construed as determining the correct state abstraction scheme for a set of source [tasks] andthen applying this compaction to a target [task].\u201d Their suggested framework solves a set of MDPs,builds abstractions from the solutions, extracts relevant features, and then applies the feature-basedabstraction function to a novel target task. A simple experiment using tasks with different statespaces and reward functions shows that the time to learn a target task is decreased by using MTL.Building upon their five defined types of state abstractions (as defined in Li et al. 2006), they givetheoretical results showing that when the number of source tasks is large (relative to the differences7. Prioritized sweeping (Moore and Atkeson, 1993) is an RL method that orders adjustments to the value function basedon their \u201curgency,\u201d which can lead to faster convergence than when updating the value function in the order of visitedstates.1659\fTAYLOR AND S TONEAllowed SourceTaskTransferred AllowedTLTaskTaskMappings Knowledge Learners MetricsDifferences SelectionDifferent state variables and actions \u2013 no explicit task mappings: Section 6Konidaris and Barto (2006)phN/ARTDj, trKonidaris and Barto (2007)phN/A\u03c0pTDj, trBanerjee and Stone (2007)a, vhN/AfeaTDap, j, trGuestrin et al. (2003)#hN/AQLPjCroonenborghs et al. (2007)#hN/A\u03c0pRRLap, j, trRamon et al. (2007)#hN/AQRRL ap, j, tt\u2020 , trSharma et al. (2007)#hN/AQTD, CBRj, trCitationTable 5: This table reproduces the third group of methods from Table 1.between the different tasks), four of the five types of abstractions are guaranteed to produce theoptimal policy in a target task using Q-learning.Similar to Walsh et al. (2006), Lazaric (2008) also discovers features to transfer. Rather thanlearning tasks sequentially, as in all the papers above, one could consider learning different tasksin parallel and using the shared information to learn the tasks better than if each were learned inisolation. Specifically, Lazaric (2008) learns a set of tasks with different reward functions usingthe batch method Fitted Q-iteration (Ernst et al., 2005). By leveraging a multi-task feature learningalgorithm (Argyrious et al., 2007), the problem can be formulated as a joint optimization problemto find the best features and learning parameters across observed data in all tasks. Experimentsdemonstrate that this method can improve the total reward and can help the agent to ignore irrelevant features (i.e., features which do not provide useful information). Furthermore, since it maybe possible to learn a superior representation, asymptotic performance may be improved as well,relative to learning tasks in isolation.The work in this section, as summarized in the second section of Table 1, explicitly assumesthat all MDPs an agent experiences are drawn from the same distribution. Different tasks in a singledistribution could, in principal, have different state variables and actions, and future work shouldinvestigate when allowing such flexibility would be beneficial.6. Transferring Task-Invariant Knowledge Between Tasks with Differing StateVariables and ActionsThis section, unlike the previous two, discusses methods that allow the source task and target task tohave different state variables and actions (see Figure 8 and the methods in Table 5). These methodsformulate the problem so that no explicit mapping between the tasks is needed. Instead the agentreasons over abstractions of the MDP that are invariant when the actions or state variables change.For example, Konidaris and Barto (2006) have separated the standard RL problem into agentspace and problem-space representations. The agent-space is determined by the agent\u2019s capabilities, which remain fixed (e.g., physical sensors and actuators), although such a space may benon-Markovian.8 The problem-space, on the other hand, may change between source and target8. A standard assumption is that a task is Markovian, meaning that the probability distribution over next states is independent of the agent\u2019s state and action history. Thus, saving a history would not assist the agent when selectingactions, and it can consider each state in isolation.1660\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYEnvironmentT, Rsrax1x2x3...xnAgentFigure 8: Methods in Section 6 are able to transfer between tasks with different state spaces. Although T , R, A, and the state variables may also technically change, the agent\u2019s internalrepresentation is formulated so that they remain fixed between source and target tasks.MDP components with a dashed circle may change between the source task and targettask.problems and is assumed to be Markovian. The authors\u2019 method learns a shaping reward on-line inagent-space while learning a source task. If a later target task has a similar reward structure and action set, the learned shaping reward will help the agent achieve a jumpstart and higher total reward.For example, suppose that one of the agent\u2019s sensors measures the distance between it and a particular important state (such as a beacon located near the goal state). The agent may learn a shapingreward that assigns reward when the state variable describing its distance to the beacon is reduced,even in the absence of an environmental reward. The authors assume that there are no novel actions(i.e., actions which are not in the source task\u2019s problem-space) but any new state variables can behandled if they can be mapped from the novel problem-space into the familiar agent-space. Additionally, the authors acknowledge that the transfer must be between reward-linked tasks, where \u201cthereward function in each environment consistently allocates rewards to the same types of interactionsacross environments.\u201d Determining whether or not a sequence of tasks meet this criterion is left forfuture work.In later work (Konidaris and Barto, 2007), the authors assume knowledge of \u201cpre-specifiedsalient events,\u201d which make learning options tractable. While it may be possible to learn optionswithout requiring such events to be specified, the paper focuses on how to use such options ratherthan option learning. Specifically, when the agent achieves one of these subgoals, such as unlocking a door or moving through a doorway, it may learn an option to achieve the event again in thefuture. As expected, problem-space options speed up learning a single task. More interesting, whenthe agent trains on a series of tasks, options in both agent-space and problem-space significantlyincrease the jumpstart and total reward in the target task (time spent learning the source task is discounted). The authors suggest that agent-space options will likely be more portable than problemspace options in cases where the source and target tasks are less similar\u2014indeed, problem-spaceoptions will only be portable when source and target tasks are very similar.In our opinion, agent- and problem-space are ideas that should be further explored as they willlikely yield additional benefits. Particularly in the case of physical agents, it is intuitive that agentsensors and actuators will be static, allowing information to be easily reused. Task-specific items,1661\fTAYLOR AND S TONEsuch as features and actions, may change, but should be faster to learn if the agent has alreadylearned something about its unchanging agent-space.If transfer is applied to game trees, changes in actions and state variables may be less problematic. Banerjee and Stone (2007) are able to transfer between games by focusing on this moreabstract formulation. For instance, in experiments the learner identified the concept of a fork, a statewhere the player could win on the subsequent turn regardless of what move the opponent took next.After training in the source task, analyzing the source task data for such features, and then settingthe value for a given feature based on the source task data, such features of the game tree were usedin a variety of target tasks. This analysis focuses on the effects of actions on the game tree and thusthe actions and state variables describing the source and target game can differ without requiringan inter-task mapping. Source task time is discounted, but jumpstart, total reward, and asymptoticperformance are all improved via transfer. Although the experiments in the paper use only temporaldifference learning, it is likely that this technique would work well with other types of learners.Guestrin et al. (2003) examine a similar problem in the context of planning in what they terma relational MDP. Rather than learning a standard value function, an agent-centered value functionfor each class of agents is calculated in a source task, forcing all agents of a given class type toall have the same value function. However, these class value functions are defined so that they areindependent of the number of agents in a task, allowing them to be directly used in a target taskwhich has additional (or fewer) agents. No further learning is done in the target task, but the transferred value functions perform better than a handcoded strategy provided by the authors, despitehaving additional friendly and adversarial agents. However, the authors note that the technique willnot perform well in heterogeneous environments or domains with \u201cstrong and constant interactionsbetween many objects.\u201dRelational Reinforcement Learning may also be used for effective transfer. Rather than reasoning about states as input from an agent\u2019s sensors, an RRL learner typically reasons about a statein propositional form by constructing first-order rules. The learner can easily abstract over specificobject identities as well as the number of objects in the world; transfer between tasks with differentnumber of objects is simplified. For instance, Croonenborghs et al. (2007) first learn a source taskpolicy with RRL. The learned policy is used to create examples of state-action pairs, which are thenused to build a relational decision tree. This tree predicts, for a given state, which action would beexecuted by the policy. Lastly, the trees are mined to produce relational options. These options aredirectly used in the target task with the assumption that the tasks are similar enough that no translation of the relational options is necessary. The authors consider three pairs of source/target taskswhere relational options learned in the source directly apply to the target task (only the number ofobjects in the tasks may change), and learning is significantly improved in terms of jumpstart, totalreward, and asymptotic performance.Other work using RRL for transfer (Ramon et al., 2007) introduces the T G R algorithm, a relational decision tree algorithm. T G R incrementally builds a decision tree in which internal nodes usefirst-order logic to analyze the current state and where the tree\u2019s leaves contain action-values. Thealgorithm uses four tree-restructuring operators to effectively use available memory and increasesample efficacy. Both target task time and total time are reduced by first training on a simple sourcetask and then on a related target task. Jumpstart, total reward, and asymptotic performance alsoappear to improve via transfer.RRL is a particularly attractive formulation in the context of transfer learning. In RRL, agentscan typically act in tasks with additional objects without reformulating their, although additional1662\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYtraining may be needed to achieve optimal (or even acceptable) performance levels. When it ispossible to frame a domain of interest as an RRL task, transfer between tasks with different numbersof objects or agents will likely be relatively straightforward.With motivation similar to that of RRL, some learning problems can be framed so that agentschoose between high-level actions that function regardless of the number of objects being reasonedabout. Sharma et al. (2007) combines case-based reasoning with RL in the CAse-Based Reinforcement Learner (CARL), a multi-level architecture includes three modules: a planner, a controller,and a learner. The tactical layer uses the learner to choose between high-level actions which are independent of the number of objects in the task. The cases are indexed by: high-level state variables(again independent of the number of objects in the task), the actions available, the Q-values of theactions, and the cumulative contribution of that case on previous timesteps. Similarity between thecurrent situation and past cases is determined by Euclidean distance. Because the state variables andactions are defined so that the number of objects in the task can change, the source and target taskscan have different numbers of objects (in the example domain, the authors use different numbersof player and opponent troops in the source and target tasks). Time spent learning the source taskis not counted, but the target task performance is measured in terms of jumpstart, asymptotic gain(a metric related to the improvement in average reward over learning), and overall gain (a metricbased on the total reward accrued).In summary, methods surveyed in this section all allow transfer between tasks with differentstate variables and actions, as well as transfer functions, state spaces, and reward functions. Byframing the task in an agent-centric space, limiting the domain to game trees, or using a learningmethod that reasons about variable numbers of objects, knowledge can be transferred between taskswith relative ease because problem representations do not change from the learner\u2019s perspective.In general, not all tasks may be formulated so that they conform to the assumptions made by TLmethods presented in this section.7. Explicit Mappings to Transfer between Different Actions and StateRepresentationsThis section of the survey focuses on a set of methods which are more flexible than those previouslydiscussed as they allow the state variables and available actions to differ between source and targettasks (see Table 6 and Figure 9). All methods in this section use inter-task mappings, enablingtransfer between pairs of tasks that could not be addressed by methods in the previous section. Notethat because of changes in state variables and actions, R, S, and T , all technically change as well(they are functions defined over actions and state variables). However, as we elaborate below, someof the methods allow for significant changes in reward functions between the tasks, while most donot.In Taylor et al. (2007a), the authors assume that a mapping between the source and target tasksis provided to the learner. The learner first trains in a source task using a value-function-learningmethod. Before learning begins in the target task, every action-value for each state in the targettask is initialized via learned source task values. This work experimentally demonstrates that valuefunction transfer can cause significant speedup by transferring between tasks that have different statevariables and actions. Additionally, different methods for performing the value-function transferare examined, different function approximators are successfully used, and multi-step transfer isdemonstrated (i.e., transfer from task A to task B to task C). This TL method demonstrates that when1663\fTAYLOR AND S TONEAllowed SourceTaskTransferred Allowed TLTaskTaskMappings Knowledge Learners MetricsDifferences SelectionDifferent state variables and actions \u2013 inter-task mappings used: Section 7Taylor et al. (2007a)a, vhsupQTDtt\u2020Taylor et al. (2007b)a, vhsup\u03c0PStt\u2020Taylor et al. (2008b)a, vhsupIMBap, trTorrey et al. (2005)a, r, vhsupruleTDj, trTorrey et al. (2006)Torrey et al. (2007)a, r, vhsup\u03c0pTDj, trTaylor and Stone (2007b)a, r, vhsupruleany/TD j, tt\u2020 , trCitationTable 6: This table reproduces the fourth group of methods from Table 1.EnvironmentT, Rsrax1x2x3...xnAgentFigure 9: Methods in Section 7 focus on transferring between tasks with different state features,action sets, and possible reward functions (which, in turn, causes the state space andtransition function to differ as well). As in previous figures, MDP components with adashed circle may change between the source task and target task.faced with a difficult task, it may be faster overall to first train on an artificial source task or tasksand then transfer the knowledge to the target task, rather than training on the target task directly.The authors provide no theoretical guarantees about their method\u2019s effectiveness, but hypothesizeconditions under which their TL method will and will not perform well, and provide examples ofwhen their method fails to reduce the training time via transfer.In subsequent work, Taylor et al. (2007b) transfer entire policies between tasks with differentstate variables and actions, rather than action-value functions. A set of policies is first learned viaa genetic algorithm in the source task and then transformed via inter-task mappings. Additionally,partial inter-task mappings are introduced, which may be easier for a human to intuit in manydomains. Specifically, those actions and state variables in the target which have \u201cvery similar\u201dactions and state variables in the source task are mapped, while novel state variables and actions inthe target task are left unmapped. Policies are transformed using one of the inter-task mappings andthen used to seed the learning algorithm in the target task. As in the previous work, this TL methodcan successfully reduce both the target task time and the total time.1664\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYLater, Taylor et al. (2008b) again consider pairs of tasks where the actions differ, the state variables differ, and inter-task mappings are available to the learner. In this work, the authors allowtransfer between model-learning methods by transferring instances, which is similar in spirit toLazaric (2008). Fitted R-MAX (Jong and Stone, 2007), an instance-based model-learning methodcapable of learning in continuous state spaces, is used as the base RL method, and source taskinstances are transferred into the target task to better approximate the target task\u2019s model. Experiments in a simple continuous domain show that transfer can improve the jumpstart, total reward,and asymptotic performance in the target task.Another way to transfer is via learned advice or preferences. Torrey et al. (2005) automaticallyextract such advice from a source task by identifying actions which have higher Q-values than otheravailable actions.9 Such advice is mapped via human-provided inter-task mappings to the target taskas preferences given to the target task learner. In this work, Q-values are learned via support vectorregression, and then Preference Knowledge Based Kernel Regression (KBKR) (Maclin et al., 2005)adds the advice as soft constraints in the target, setting relative preferences for different actions indifferent states. The advice is successfully leveraged by the target task learner and decreases thetarget task learning time, even when the source task has different state variables and actions. Additionally, the reward structure of the tasks may differ substantially: their experiments use a sourcetask whose reward is an unbounded score based on episode length, while the target task\u2019s reward isbinary, depending on if the agents reached a goal state or not. Source task time is discounted andthe target task learning is improved slightly in terms of total reward and asymptotic performance.Later work (Torrey et al., 2006) improves upon this method by using inductive logic programming (ILP) to identify skills that are useful to the agent in a source task. A trace of the agent in thesource task is examined and both positive and negative examples are extracted. Positive and negative examples are identified by observing which action was executed, the resulting outcome, theQ-value of the action, and the relative Q-value of other available actions. Skills are extracted usingthe ILP engine Aleph (Srinivasan, 2001) by using the F1 score (the harmonic mean of precision andrecall). These skills are then mapped by a human into the target task, where they improve learningvia KBKR. Source task time is not counted towards the target task time, jumpstart may be improved,and the total reward is improved. The source and target tasks again differ in terms of state variables,actions, and reward structure. The authors also show how human-provided advice may be easilyincorporated in addition to advice generated in the source task. Finally, the authors experimentallydemonstrate that giving bad advice to the learner is only temporarily harmful and that the learnercan \u201cunlearn\u201d bad advice over time, which may be important for minimizing the impact of negativetransfer.Torrey et al. (2007) further generalize their technique to transfer strategies, which may requirecomposing several skills together, and are defined as a finite-state machine (FSM). The structurelearning phase of their algorithm analyzes source task data to find sequences of actions that distinguish between successful and unsuccessful games (e.g., whether or not a goal was reached), andcomposes the actions into a FSM. The second phase, ruleset learning, learns when each action inthe strategy should be taken based on state features, and when the FSM should transition to thenext state. Experience in the source task is again divided into positive and negative sequences forAleph. Once the strategies are re-mapped to the target task via a human-provided mapping, they areused to demonstrate a strategy to the target task learner. Rather than explore randomly, the target9. While this survey focuses on automatically learned knowledge in a source task, rather than human-provided knowledge, Torrey et al. (2005) show that both kinds of knowledge can be effectively leveraged.1665\fTAYLOR AND S TONEtask learner always executes the transferred strategies for the first 100 episodes and thus learns toestimate the Q-values of the actions selected by the transferred strategies. After this demonstrationphase, the learner chooses from the MDP\u2019s actions, not the high-level strategies, and can learn toimprove on the transferred strategies. Experiments demonstrate that strategy transfer significantlyimproves the jumpstart and total reward in the target task when the source and target tasks havedifferent state variables and actions (source task time is again discounted).Similar to strategy transfer, Taylor and Stone (2007b) learn rules with RIPPER (Cohen, 1995)that summarize a learned source task policy. The rules are then transformed via handcoded intertask mappings so that they could apply to a target task with different state variables and actions.The target task learner may then bootstrap learning by incorporating the rules as an extra action,essentially adding an ever-present option \u201ctake the action suggested by the source task policy,\u201dresulting in an improved jumpstart and total reward. By using rules as an intermediary betweenthe two tasks, the authors argue that the source and target tasks can use different learning methods,effectively de-coupling the two learners. Similarities with Torrey et al. (2007) include a significantimprovement in initial performance and no provision to automatically handle scale differences.10The methods differ primarily in how advice is incorporated into the target learner and the choice ofrule learner.Additionally, Taylor and Stone (2007b) demonstrated that inter-domain transfer is possible.The two source tasks in this paper were discrete, fully observable, and one was deterministic. Thetarget task, however, had a continuous state space, was partially observable, and had stochasticactions. Because the source tasks required orders of magnitude less time, the total time was roughlyequal to the target task time. Our past work has used the term \u201cinter-domain transfer\u201d for transferbetween qualitatively different domains, such as between a board game and a soccer simulation.However, this term is not well defined, or even agreed upon in the community. For instance, Swarupand Ray (2006) use the term \u201ccross-domain transfer\u201d to describe the reuse of a neural networkstructure between classification tasks with different numbers of boolean inputs and a single output.However, our hope is that researchers will continue improve transfer methods so that they mayusefully transfer from very dissimilar tasks, similar to the way that humans may transfer high levelideas between very different domains.This survey has discussed examples of of low- and high-level knowledge transfer. For instance,learning general rules or advice may be seen as relatively high level, whereas transferring specific Qvalues or observed instances is quite task-specific. Our intuition is that higher-level knowledge maybe more useful when transferring between very dissimilar tasks. For instance, it is unlikely that Qvalues learned for a checkers game will transfer to chess, but the concept of a fork may transfer well.This has not been definitely shown, however, nor is there a quantitative way to classify knowledge interms of low- or high-level. We hope that future work will confirm or disconfirm this hypothesis, aswell as generate guidelines as to when different types of transferred knowledge is most appropriate.All methods in this section use some type of inter-task mapping to allow transfer between MDPswith very different specifications. While these results show that transfer can provide a significantbenefit, they presuppose that the mappings are provided to the learner. The following section considers methods that work to autonomously learn such inter-task mappings.10. To our knowledge, there is currently no published method to automatically scale rule constants. Such scaling wouldbe necessary if, for instance, source task distances were measured in feet, but target task distances were measured inmeters.1666\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYAllowed SourceTaskTransferred Allowed TLTaskTaskMappings Knowledge Learners MetricsDifferences SelectionLearning inter-task mappings: Section 8Kuhlmann and Stone (2007)a, vhTQTDj, trLiu and Stone (2006)a, vhTN/AallN/ASoni and Singh (2006)a, vhMa , svg , expN/Aallap, j, trTalvitie and Singh (2007)a, vhMa , svg , expN/AalljTaylor et al. (2007b)\u22c6a, vhsvg , expN/Aalltt\u2020Taylor et al. (2008c)a, vhexpN/Aallj, trCitationTable 7: This table reproduces the group of inter-task learning methods from Table 1.8. Learning Task MappingsThe transfer algorithms considered thus far have assumed that a hand-coded mapping between taskswas provided, or that no mapping was needed. In this section we consider the less-well exploredquestion of how a mapping between tasks can be learned, such that source task knowledge maybe exploited in a novel target task with different state variables and actions (see Figure 10 andthe final group in Table 1). Note that in this section, all but one of the methods have N/A fortransfer method\u2014with the exception of Kuhlmann and Stone (2007), the papers covered in thissection introduce mapping-learning methods and then use existing methods to validate the mappingefficacy.One current challenge of TL research is to reduce the amount of information provided to thelearner about the relationship between the source and target tasks. If a human is directing the learnerthrough a series of tasks, the similarities (or analogies) between the tasks will likely be providedby the human\u2019s intuition. If transfer is to succeed in an autonomous setting, however, the learnermust first determine how (and whether) two tasks are related, and only then may the agent leverageits past knowledge to learn in a target task. Learning task relationships is critical if agents are totransfer without human input, either because the human is outside the loop, or because the humanis unable to provide similarities between tasks. Methods in this section differ primarily in whatinformation must be provided. At one end of the spectrum, Kuhlmann and Stone (2007) assumethat a complete description of R, S, and T are given, while at the other, Taylor et al. (2008c) learnthe mapping exclusively from experience gathered via environmental interactions.Given a complete description of a game (i.e., the full model of the MDP), Kuhlmann and Stone(2007) analyze the game to produce a rule graph, an abstract representation of a deterministic, fullinformation game. A learner first trains on a series of source task games, storing the rule graphs andlearned value functions. When a novel target task is presented to the learner, it first constructs thetarget task\u2019s rule graph and then attempts to find a source task that has an isomorphic rule graph.The learner assumes that a transition function is provided and uses value-function-based learning toestimate values for afterstates of games. Only state variables need to be mapped between source andtarget tasks, and this is exactly the mapping found by graph matching. For each state in the targettask, initial Q-values are set by finding the value of the corresponding state in the source task. Threetypes of transfer are considered: direct, which copies afterstate values over without modification;inverse, which accounts for a reversed goal or switched roles; and average, with copies the average1667\fTAYLOR AND S TONEEnvironmentT, RsrEnvironment?aT, Rsrax1x1x2x2x3x3......xnxnAgent?AgentFigure 10: Section 8 presents methods to learn the relationship between tasks with different statevariables and actions. As in previous figures, MDP components with a dashed circlemay change between the source task and target task.of a set of Q-values and can be used for boards with different sizes. Source task time is ignored butjumpstart and total reward can both be improved in the target task.The previous work assumes full knowledge of a transition function. A more general approachcould assume that the agent has only a qualitative understanding of the transition function. Forinstance, qualitative dynamic Bayes networks (QDBNs) (Liu and Stone, 2006), summarize the effects of actions on state variables but are not precise (for instance, they could not be used as agenerative model for planning). If QDBNs are provided to an agent, a graph mapping techniquecan automatically find a mapping between actions and state variables in two tasks with relativelylittle computational cost. The authors show that mappings can be learned autonomously, effectivelyenabling value function transfer between tasks with different state variables and actions. However,it remains an open question as to whether or not QDBNs are learnable from experience, rather thanbeing hand-coded.The next three methods assume knowledge about how state variables are used to describe objectsin a multi-player task. For instance, an agent may know that a pair of state variables describe\u201cdistance to teammate\u201d and \u201cdistance from teammate to marker,\u201d but the agent is not told whichteammate the state variables describe. First, Soni and Singh (2006) supply an agent with a series ofpossible state transformations and an inter-task action mapping. There is one such transformation,X, for every possible mapping of target task variables to source task variables. After learning thesource task, the agent\u2019s goal is to learn the correct transformation: in each target task state s, theagent can randomly explore the target task actions, or it may choose to take the action \u03c0source (X(s)).This method has a similar motivation to that of Fernandez and Veloso (2006), but here the authorsare learning to select between possible mappings rather than possible previous policies. Over timethe agent uses Q-learning to select the best state variable mapping as well as learn the actionvalues for the target task. The jumpstart, total reward, and asymptotic performance are all slightlyimproved when using this method, but its efficacy will be heavily dependent on the number ofpossible mappings between any source and target task.Second, AtEase (Talvitie and Singh, 2007) also generates a number of possible state variablemappings. The action mapping is again assumed and the target task learner treats each of thepossible mappings as an arm on a multi-armed bandit (Bellman, 1956). The authors prove theiralgorithm learns in time proportional to the number of possible mappings rather than the size ofthe problem: \u201cin time polynomial in T , [the algorithm] accomplishes an actual return close to the1668\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYasymptotic return of the best expert that has mixing time at most T .\u201d This approach focuses efficientselection of a proposed state variable mappings and does not allow target task learning.Third, these assumptions are relaxed slightly by Taylor et al. (2007b), who show that it is possible to learn both the action and state variable mapping simultaneously by leveraging a classificationtechnique, although it again relies on the pre-specified state variable groupings (i.e., knowing that\u201cdistance to teammate\u201d refers to a teammate, but not which teammate). Action and state variableclassifiers are trained using recorded source task data. For instance, the source task agent recordsssource , asource , s\u2032source tuples as it interacts with the environment. An action classifier is trained sothat C(ssource,ob ject , s\u2032source,ob ject ) = asource for each object present in the source task. Later, the target\u2032tuples. Then the action classifier can again be usedtask agent again records starget , atarget , starget\u2032for to classify tuples for every target task object: C(starget,ob ject , starget,object ) = asource , where such aclassification would indicate a mapping between atarget and asource . Relatively little data is neededfor accurate classification; the number of samples needed to learn in the target task far outweighsthe number of samples used by the mapping-leaning step. While the resulting mappings are notalways optimal for transfer, they do serve to effectively reduce target task training time as well asthe total training time.The MASTER algorithm (Taylor et al., 2008c) was designed to further relax the knowledge requirements of Taylor et al. (2007b): no state variable groupings are required. The key idea ofMASTER is to save experienced source task instances, build an approximate transition model from asmall set of experienced target task instances, and then test possible mappings offline by measuringthe prediction error of the target-task models on source task data. This approach is sample efficientat the expense of high computational complexity, particularly as the number of state variables andactions increase. The method uses an exhaustive search to find the inter-task mappings that minimizethe prediction error, but more sophisticated (e.g., heuristic) search methods could be incorporated.Experiments show that the learned inter-task mappings can successfully improve jumpstart and totalreward. A set of experiments also shows how the algorithm can assist with source task selection byselecting the source task which is best able to minimize the offline prediction error. The primarycontribution of MASTER is to demonstrate that autonomous transfer is possible, as the algorithmcan learn inter-task mappings autonomously, which may then be used by any of the TL methodsdiscussed in the previous section of this survey (Section 7).In summary, this last section of the survey has discussed several methods able to learn intertask mappings with different amounts of data. Although all make some assumptions about theamount of knowledge provided to the learner or the similarity between source and target tasks,these approaches represent an important step towards achieving fully autonomous transfer.The methods in the section have been loosely ordered in terms of increasing autonomy. Bylearning inter-task mappings, these algorithms try to enable a TL agent to use past knowledge on anovel task without human intervention, even if the state variables or actions change. However, thequestion remains whether fully autonomous transfer would ever be useful in practice. Specifically,if there are no restrictions on the type of target task that could be encountered, why would oneexpect that past knowledge (a type of bias) would be useful when learning an encountered task, oreven on the majority of tasks that could be encountered? This question is directly tied to the abilityof TL algorithms to recognize when tasks are similar and when negative transfer may occur, both ofwhich are discussed in more detail in the following section.1669\fTAYLOR AND S TONE9. Open QuestionsAlthough transfer learning in RL has made significant progress in recent years, there are still a number of open questions to be addressed. This section presents a selection of questions that we findparticularly important. Section 9.1 discusses ways in which methods in the survey could potentiallybe extended and serves to highlight some of the methods most promising for future work. Section 9.2 then discusses the problem of negative transfer, currently one of the most troubling openquestions. Lastly, Section 9.3 presents a set of possible research directions that the authors\u2019 believewill be most beneficial to the field of TL.9.1 Potential EnhancementsOne apparent gap in our taxonomy is a dearth of model-learning methods. Because model-learningalgorithms are often more sample efficient than model-free algorithms, it is likely that TL will havea large impact on sample complexity when coupled with such efficient RL methods. Moreover,when a full model of the environment is learned in a source task, it may be possible for the targettask learner to explicitly reason about how to refine or extend the model as it encounters disparitiesbetween it and the target task.As mentioned in Section 5, transfer is an appealing way to set priors in a Bayesian setting.When in a MTL setting, it may be possible to accurately learn priors over a distribution of tasks,enabling a learner to better avoid negative transfer. One of the main benefits of transfer learningis the ability to bias learners so that they may find better solutions with less data; making these biases explicit through Bayesian priors may allow more efficient (and human-understandable) transfermethods. While there will likely be difficulties associated with scaling up current methods to handlecomplex tasks, possibly with a complex distribution hierarchy, it seems like Bayesian methods areparticularly appropriate for transfer.The idea of automatically modifying source tasks (cf., RTP Sherstov and Stone 2005, and suggested by Kuhlmann and Stone 2007) has not yet been widely adopted. However, such methodshave the potential to improving transfer efficacy in settings where the target task learning performance is paramount. By developing methods that allow training on a sequence of automaticallygenerated variations, TL agents may be able to train autonomously and gain experience that is exploitable in a novel task. Such an approach would be particularly relevant in the multi-task learningsetting where the agent could leverage some assumptions about the distribution of the target task(s)it will see in the future.None of the transfer methods in this survey are able to explicitly take advantage of any knowledge about changes in the reward function between tasks, and it may be particularly easy for humansto identify qualitative changes in reward functions. For example, if it was known that the target taskrewards were twice that of the source task, it is possible that value-function methods may be ableto automatically modify the source task value function with this background knowledge to enhancelearning. As a second example, consider a pair of tasks where the goal state were moved fromone edge of the state space to the opposite edge. While the learned transition information could bereused, the policy or value-function would need to be significantly altered to account for the newreward function. It is possible that inter-task mappings could be extended to account for changes inR between tasks, in addition to changes in A and in state variables.Ideas from theory revision (Ginsberg, 1988) (also theory refinement) may help inform the automatic construction of inter-task mappings. For example, many methods initialize a target task1670\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYagent to have Q-values similar to those in the source task agent. Transfer is likely to be successful (Taylor et al., 2007a) if the target task Q-values are close enough to the optimal Q-valuesthat learning is improved, relative to not using transfer. There are also situations where a syntactic change to the knowledge would produce better transfer. For instance, if the target task\u2019sreward function were the inverse of the source task function, direct transfer of Q-values would befar from optimal. However, a TL algorithm that could recognize the inverse relationship may beable to use the source task knowledge more appropriately (such as initializing its behavior so that\u03c0target (starget ) 6= \u03c0source (\u03c7X (starget )).Given a successful application of transfer, there are potentially two distinct benefits for theagent. First, transfer may help improve the agent\u2019s exploration so that it discovers higher-valuedstates more quickly. Secondly, transfer can help bias the agent\u2019s internal representation (e.g., itsfunction approximator) so that it may learn faster. It will be important for future work to betterdistinguish between these two effects; decoupling the two contributions should allow for a betterunderstanding of TL\u2019s benefits, as well as provide avenues for future improvements.Of the thirty-four transfer methods discussed, only five (Tanaka and Yamamura, 2003; Sunmolaand Wyatt, 2006; Ferguson and Mahadevan, 2006; Lazaric, 2008; Wilson et al., 2007) attempt todiscover internal learning parameters (e.g., appropriate features or learning rate) so that future tasksin the same domain may be learned more efficiently. It is likely that other \u201cmeta-learning\u201d methodscould be useful. For instance, it may be possible to learn to use an appropriate function approximator, an advantageous learning rate, or even the most appropriate RL method. Although likely easierto accomplish in a MTL setting, such meta-learning may also be possible in transfer, given sufficiently strong assumptions about task similarity. Multiple heuristics regarding the best way to selectRL methods and learning parameter settings for a particular domain exist, but typically such settingsare chosen in an ad hoc manner. Transfer may be able to assist when setting such parameters, ratherthan relying on human intuition.Section 8 discussed methods that learned an inter-task mapping, with the motivation that such amapping could enable autonomous transfer. However, it is unclear if fully autonomous TL is realistic in an RL setting, or indeed is useful. In the majority of situations, a human will be somewherein the loop and full autonomy is not necessary. Instead, it could be that mappings may be learned tosupplement a human\u2019s intuition regarding appropriate mappings, or that a set of learned mappingscould be proposed and then one selected by a human. It would be worthwhile to define realistic scenarios when fully autonomous transfer will be necessary, or to instead specify how (limited) humaninteraction will be coupled with mapping-learning methods.Lastly, we hope that the idea of task-invariant knowledge will be extended. Rather than learningan appropriate representation across tasks, agent-space (Konidaris and Barto, 2007) and RRL techniques attempt to discover knowledge about the agent or the agent\u2019s actions which can be directlyreused in novel tasks. The better techniques can successfully compartmentalize knowledge, separating what will usefully transfer and what will not will not, the easier it will be to achieve successfultransfer without having to un-learn irrelevant biases.9.2 Negative TransferThe majority of TL work in the literature has concentrated on showing that a particular transferapproach is plausible. None, to our knowledge, has a well-defined method for determining when anapproach will fail according to one or more metrics. While we can say that it is possible to improve1671\fTAYLOR AND S TONESource Task+1BIACTarget TaskB\u2019I\u2019A\u2019C\u2019+1Figure 11: This figure depicts a pair of tasks that are likely to result in negative transfer for TLmethods.learning in a target task faster via transfer, we cannot currently decide if an arbitrary pair of tasks areappropriate for a given transfer method. Therefore, transfer may produce incorrect learning biasesand result in negative transfer.Methods such as MASTER (Taylor et al., 2008c), which can measure task similarity via modelprediction error, or region transfer (Lazaric, 2008), which examines the similarity of tasks at a locallevel rather than at a per-task level, can help assist when deciding if the agent should transfer orwhat the agent should transfer. However, neither method provides any theoretical guarantees aboutits effectiveness.As an example of why it is difficult to define a metric for task similarity, consider the pair of tasksshown in Figure 11, which are extremely similar, but where direct transfer of a policy or action-valuefunction will be detrimental. The source task in Figure 11 (top) is deterministic and discrete. Theagent begins in state I and has one action available: East. Other states in the \u201challway\u201d have twoapplicable actions: East and West, except for state A, which also has the actions North and South.Once the agent executes North or South in state A, it will remain in state B or C (respectively) andcontinue self-transitioning. No transition has a reward, except for the self-transition in state B.Now consider the target task in Figure 11 (bottom), which is the same as the source task, exceptthat the self-transition from C\u2032 is the only rewarded transition in the MDP. Q\u22c6 (I\u2032 ,East) in the targettask (the optimal action-value function, evaluated at the state I\u2032 ) is the same as Q\u22c6 (I, East) in thesource task. Indeed, the optimal policy in the target task differs at only a single state, A\u2032 , and theoptimal action-value functions differ only at states A\u2032 , B\u2032 , and C\u2032 .One potential method for avoiding negative transfer is to leverage the ideas of bisimulation(Milner, 1982). Ferns et al. (2006) point out that:1672\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYIn the context of MDPs, bisimulation can roughly be described as the largest equivalence relation on the state space of an MDP that relates two states precisely when forevery action, they achieve the same immediate reward and have the same probabilityof transitioning to classes of equivalent states. This means that bisimilar states lead toessentially the same long-term behavior.However, bisimulation may be too strict because states are either equivalent or not, and may be slowto compute in practice. The work of Ferns et al. (2005, 2006) relaxes the idea of bisimulation tothat of a (pseudo)metric that can be computed much faster, and gives a similarity measure, ratherthan a boolean. It is possible, although not yet shown, that bisimulation approximations can be usedto discover regions of state space that can be transferred from one task to another, or to determinehow similar two tasks are in toto. In addition to this, or perhaps because of it, there are currently nomethods for automatically constructing a source task given a target task.11Homomorphisms (Ravindran and Barto, 2002) are a different abstraction that can define transformations between MDPs based on transition and reward dynamics, similar in spirit to inter-taskmappings, and have been used successfully for transfer (Soni and Singh, 2006). However, discovering homomorphisms is NP-hard (Ravindran and Barto, 2003a) and homomorphisms are generallysupplied to a learner by an oracle. While these two theoretical frameworks may be able to help avoidnegative transfer, or determine when two tasks are \u201ctransfer compatible,\u201d significant work needs tobe done to determine if such approaches are feasible in practice, particularly if the agent is fullyautonomous (i.e., is not provided domain knowledge by a human) and is not provided a full modelof the MDP.9.3 New DirectionsAs suggested above, TL in RL domains is one area of machine learning where the empirical workhas outpaced the theoretical. While there has been some work on the theory of transfer betweenclassification tasks (cf., Baxter, 2000; Ben-David and Borbely, 2008), such analyses do not directlyapply to RL settings. To our knowledge, there is only a single work analyzing the theoreticalproperties of transfer in RL (Phillips, 2006), where the authors use the Kantorovich and full modelsof two MDPs to calculate how well an optimal policy in one task will perform in a second task.Unfortunately, this calculation of policy performance may require more computation than directlylearning in the target task. There is considerable room, and need for, more theoretical work in RL(cf., Bowling and Veloso, 1999). For example:1. Provides guarantees about whether a particular source task can improve learning in a targettask (given a particular type of knowledge transfer).2. Correlates the amount of knowledge transferred (e.g., the number of samples) with the improvement in the source task.3. Defines what an optimal inter-task mapping is, and demonstrates how transfer efficacy isimpacted by the inter-task mapping used.11. We distinguish this idea from Sherstov and Stone\u2019s 2005 approach. Their paper shows it is possible to constructsource task perturbations and then allow an agent to spend time learning the set of tasks to attempt to improvelearning on an (unknown) source task. Instead, it may be more effective to tailor a source task to a specific targettask, effectively enabling an agent to reduce the total number of environmental interactions needed to learn.1673\fTAYLOR AND S TONEThe remainder of this section suggests other open areas.Concept drift (Widmer and Kubat, 1996) in RL has not been directly addressed by any workin this survey. The idea of concept drift is related to a non-stationary environment: at certainpoints in time, the environment may change arbitrarily. As Ramon et al. (2007) note, \u201cfor transferlearning, it is usually known when the context change takes place. For concept drift, this change isusually unannounced.\u201d Current on-line learning methods may be capable of handling such changesby continually learning. However, it is likely that RL methods developed specifically to convergeto a policy and then re-start learning when the concept changes will achieve higher performance,whether such drift is announced or unannounced.Another question no work in this survey directly addresses is how to determine the optimalamount of source task training to minimize the target task training time or total training time. If thesource task and target task were identical, the goal of reducing the target task training time wouldbe trivial (by maximizing the source task training time) and the goal of minimizing total trainingtime would be impossible. On the other hand, if the source task and target task were unrelated, itwould be impossible to reduce the target task training time through transfer and the total trainingtime would be minimized by not training in the source task at all. It is likely that a calculation orheuristic for determining the optimal amount of source task training time will have to consider thestructure of the two tasks, their relationship, and what transfer method is used. This optimizationbecomes even more difficult in the case of multi-step transfer, as there are two or more tasks thatcan be trained for different amounts of time.Transfer methods in this survey have used source task knowledge in many forms to better learnin a target task. However, none explicitly account for scaling differences between the two tasks.For instance, if a source task measured distance in meters and the target task measured distance ininches, constants would have to be updated manually rather than learned.Another question not addressed is how to best explore in a source task if the explicit purpose ofthe agent is to speed up learning in a target task. One could imagine that a non-standard learning orexploration strategy may produce better transfer results, relative to standard strategies. For instance,it may be better to explore more of the source task\u2019s state space than to learn an accurate action-valuefunction for only part of the state space. While no current TL algorithms take such an approach,there has been some work on the question of learning a policy that is exploitable (without attemptto maximize the on-line reward accrued while learning) in non-transfer contexts (S\u0327ims\u0327ek and Barto,2006).Similarly, instead of always transferring information from the end of learning in the source task,an agent that knows its information will be used in a target task may decide to record information totransfer partway through training in the source task. For instance Taylor et al. (2007b) showed thattransfer may be more effective when using policies trained for less time in the source task than whenusing those trained for more time. Although others have also observed similar behavior Mihalkovaand Mooney (2008), the majority of work shows that increased performance in the source task iscorrelated with increased target task performance. Understanding how and why this effect occurswill help determine the most appropriate time to transfer information from one task to another.We now present four possibilities for extending the current RL transfer work to different learningsettings in which transfer has not been successfully applied.\u2022 First, although two of the papers (Banerjee and Stone, 2007; Kuhlmann and Stone, 2007)in this survey have examined extensive games, none consider repeated normal form gamesor stochastic games (Shapley, 1953). For instance, one could consider learning how to play1674\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYagainst a set of opponents so that when a new opponent is introduced, the learner may quicklyadapt one of its previous strategies rather than completely re-learning a strategy. Another option would be for an agent to learn how to play one game and then transfer the knowledgeto a different stochastic game. Due to similarities between RL and these two game playing settings, transfer methods described in this survey may be applied with relatively littlemodification.\u2022 A second possibility for extending transfer is into the realm of partially observable MDPs(POMDPs). It may possible to learn a source POMDP and then use knowledge gained toheuristically speed up planning in a target POMDP. Additionally, because it is typically assumed that POMDP planners are given a complete and accurate model of a task, it may bepossible to analytically compare source and target tasks before learning in order to determineif transfer would be beneficial, and if so, how best to use the past knowledge.\u2022 Third, multi-agent MDP and POMDP learners may also be able to successfully exploit transfer. None of the work surveyed in this article focuses on explicit multi-agent learning (i.e.,learning over the joint action space, or in an (adaptive) adversarial setting, as in Stone andVeloso 2000), but it is likely existing methods may be extended to the cooperative multiagent setting. For instance, when formulating a problem as an MMDP or DEC-MDP, theagents must either reason over a joint action space or explicitly reason about how their actions affect others. It may be possible for agents to learn over a subset of actions first, andthen gradually add actions (or joint actions) over time, similar to transferring between taskswith different action sets. The need for such speedups is particularly critical in distributedPOMDPs, as solving them optimally as been shown to be NEXP-Complete (Bernstein et al.,2002). Transfer is one possible approach to making such problems more tractable, but to ourknowledge, no such methods have yet been proposed.\u2022 Fourth, as mentioned in Section 3.3, MTL methods in RL consider a sequence of tasks that aredrawn sequentially from the same distribution. However, in supervised learning, multi-tasklearning typically involves learning multiple tasks simultaneously. There may be contexts inwhich an agent must learn multiple tasks concurrently, such as in hierarchical RL or when theagent has multiple reward functions or goals. Fully specifying such a scenario, and extendingMTL methods to encompass this setting, could bring additional tools to RL researchers andhelp move TL in RL closer to TL in classification.Lastly, in order to better evaluate TL methods, it would be helpful to have a standard set ofdomains and metrics. Ideally there would be a domain-independent metric for transfer learning, butit is unclear that such a metric can exist (see Section 2). Furthermore, it is unclear what optimaltransfer would mean, but would likely depend on the scenario considered. Classification and regression have long benefited from standard metrics, such as precision and recall, and it is likely thatprogress in transfer will be likewise enhanced once standard metrics are agreed upon.Standard test sets, such as the Machine Learning Repository at the University of California,Irvine (Asuncion and Newman, 2007), have also assisted the growth and progress of supervisedlearning, but there are currently no equivalents for RL. Furthermore, while there are some standarddata sets for for transfer learning in classification,12 none exist for transfer in RL. While there is12. Found at https://multitask.cs.berkeley.edu.1675\fTAYLOR AND S TONEsome work in the RL community to standardize on a common interface and set of benchmark tasks(Tanner et al., 2008; Whiteson et al., 2008), no such standardization has been proposed for thetransfer learning in RL community. Even in the absence of such a framework, we suggest that it isimportant for authors working in this area to:\u2022 Clearly specify the setting: Is the source task learning time discounted? What assumptionsare made about the relationship between the source target and target task?\u2022 Evaluate the algorithm with a number of metrics: No one metric captures all possible benefitsfrom transfer.\u2022 Empirically or theoretically compare the performance of novel algorithms: To better evaluatenovel algorithms, existing algorithms should be compared using standard metrics on a singletask task.13As discussed in Section 2.1, we do not think that TL for RL methods can be strictly ordered interms of efficacy, due to the many possible goals of transfer. However, by standardizing on reportingmethodology, TL algorithms can be more easily compared, making it easier to select an appropriatemethod in a given experimental setting.Our hope is that TL questions, such as those presented in this section, will be addressed in thenear future; our expectation is that transfer learning will become an increasingly powerful tool forthe machine learning community.AcknowledgmentsWe would like to thank Cynthia Matuszek and the anonymous reviewers for helpful comments andsuggestions over multiple revisions. This work has taken place in the Learning Agents ResearchGroup (LARG) at the Artificial Intelligence Laboratory, The University of Texas at Austin. LARGresearch is supported in part by grants from the National Science Foundation (CNS-0615104),DARPA (FA8750-05-2-0283 and FA8650-08-C-7812), the Federal Highway Administration (DTFH6107-H-00030), and General Motors.ReferencesAgnar Aamodt and Enric Plaza. Case-based reasoning: foundational issues, methodological variations, and system approaches, 1994.Pieter Abbeel and Andrew Y. Ng. Exploration and apprenticeship learning in reinforcement learning. In ICML \u201905: Proceedings of the 22nd International Conference on Machine Learning,pages 1\u20138, 2005.13. One of the difficulties inherent in this proposal is that small variations in domain implementation may result in verydifferent learning performances. While machine learning practitioners are able to report past results verbatim whenusing the same data set, many RL domains used in papers are not released. In order to compare with past work,RL researchers must reimplement, tune, and test past algorithms to compare with their algorithm on their domainimplementation.1676\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYDavid Andre and Stuart J. Russell. State abstraction for programmable reinforcement learningagents. In Proc. of the Eighteenth National Conference on Artificial Intelligence, pages 119\u2013125,2002.Andreas Argyrious, Theodoros Evgenion, and Massimiliano Pontil. Multitask reinforcement learning on the distribution of MDPs. Machine Learning, 2007.Minoru Asada, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda. Vision-based behavioracquisition for a shooting robot by using a reinforcement learning. In Proceedings of IAPR/IEEEWorkshop on Visual Behaviors-1994, pages 112\u2013118, 1994.Mehran Asadi and Manfred Huber. Effective control knowledge transfer through learning skill andrepresentation hierarchies. In Proceedings of the 20th International Joint Conference on ArtificialIntelligence, pages 2054\u20132059, 2007.Authur Asuncion and David J. Newman. UCI machine learning repository, 2007. URL https://www.ics.uci.edu/\u02dcmlearn/MLRepository.html.Christopher G. Atkeson and Juan C. Santamaria. A comparison of direct and model-based reinforcement learning. In Proceedings of the 1997 International Conference on Robotics and Automation,1997.Bikramjit Banerjee and Peter Stone. General game learning using knowledge transfer. In The 20thInternational Joint Conference on Artificial Intelligence, pages 672\u2013677, January 2007.Bikramjit Banerjee, Yaxin Liu, and G. Michael Youngblood. ICML workshop on \u201cStructural knowledge transfer for machine learning\u201d, June 2006.Jonathan Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research,12:149\u2013198, 2000.Jonathan Baxter and Peter L. Bartlett. Infinite-horizon policy-gradient estimation. Journal of Artificial Intelligence Research, 15:319\u2013350, 2001.Richard E. Bellman. Dynamic Programming. Princeton University Press, 1957.Richard E. Bellman. A problem in the sequential design of experiments. Sankhya, 16:221\u2013229,1956.Shai Ben-David and Reba Schuller Borbely. A notion of task relatedness yielding provable multipletask learning guarantees. Machine Learning, 73:273\u2013287, 2008.Darrin C. Bentivegna, Christopher G. Atkeson, and Gordon Cheng. Learning from observation andpractice using primitives. In AAAI 2004 Fall Symposium on Real-life Reinforcement Learning,October 2004.Daniel S. Bernstein, Robert Givan, Neil Immerman, and Shlomo Zilberstein. The complexity ofdecentralized control of Markov decision processes. Mathematics of Operations Research, 27(4):819\u2013840, November 2002.1677\fTAYLOR AND S TONEMichael H. Bowling and Manuela M. Veloso. Bounding the suboptimality of reusing subproblem.In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages1340\u20131347, San Francisco, CA, USA, 1999.James L. Carroll and Kevin Seppi. Task similarity measures for transfer in reinforcement learningtask libraries. Proceedings of 2005 IEEE International Joint Conference on Neural Networks, 2:803\u2013808, 2005.Rich Caruana. Learning many related tasks at the same time with backpropagation. In Advances inNeural Information Processing Systems 7, pages 657\u2013664, 1995.Rich Caruana. Multitask learning. Machine Learning, 28:41\u201375, 1997.Dongkyu Choi, Tolgo Konik, Negin Nejati, Chunki Park, and Pat Langley. Structural transfer ofcognitive skills. In Proceedings of the Eighth International Conference on Cognitive Modeling,2007.William W. Cohen. Fast effective rule induction. In International Conference on Machine Learning,pages 115\u2013123, 1995.Marco Colombetti and Marco Dorigo. Robot shaping: developing situated agents through learning.Technical Report TR-92-040, International Computer Science Institute, Berkeley, CA, 1993.Robert H. Crites and Andrew G. Barto. Improving elevator performance using reinforcement learning. In D. S. Touretzky, M. C. Mozer, and M. E. Hasselmo, editors, Advances in Neural Information Processing Systems 8, pages 1017\u20131023, Cambridge, MA, 1996. MIT Press.Tom Croonenborghs, Kurt Driessens, and Maurice Bruynooghe. Learning relational options forinductive transfer in relational reinforcement learning. In Proceedings of the Seventeenth Conference on Inductive Logic Programming, 2007.DARPA. Transfer learning proposer information pamphlet, BAA #05-29, 2005.Thomas Dean and Robert Givan. Model minimization in Markov decision processes. In Proceedingsof the Thirteenth National Conference on Artificial Intelligence, pages 106\u2013111, 1997.Richard Dearden, Nir Friedman, and David Andre. Model based Bayesian exploration. In Proceedings of the 1999 Conference on Uncertainty in Artificial Intelligence, pages 150\u2013159, 1999.AArthur Dempster, Nan Laird, and Donald Rubin. Maximum-likelihood from incomplete data viathe EM algorithm. J. Royal Statistical Soc. Set. B (methodological), 39:1\u201338, 1977.Thomas G. Dietterich. Hierarchical reinforcement learning with the MAXQ value function decomposition. Journal of Artificial Intelligence Research, 13:227\u2013303, 2000.Chris Drummond. Accelerating reinforcement learning by composing solutions of automaticallyidentified subtasks. Journal of Artificial Intelligence Research, 16:59\u2013104, 2002.Saso Dzeroski, Luc De Raedt, and Kurt Driessens. Relational reinforcement learning. MachineLearning, 43(1/2):5\u201352, April 2001.1678\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYTom Erez and William D. Smart. What does shaping mean for computational reinforcement learning? In Proceedings of the Seventh IEEE International Conference on Development and Learning, pages 215\u2013219, 2008.Damien Ernst, Pierre Geurts, and Louis Wehenkel. Tree-based batch mode reinforcement learning.Journal of Machine Learning Research, 6:503\u2013556, 2005.Kimberly Ferguson and Sridhar Mahadevan. Proto-transfer learning in Markov decision processesusing spectral methods. In Proceedings of the ICML-06 Workshop on Structural KnowledgeTransfer for Machine Learning, June 2006.Alan Fern, Sungwook Yoon, and Robert Givan. Approximate policy iteration with a policy languagebias. In Sebastian Thrun, Lawrence Saul, and Bernhard Scho\u0308lkopf, editors, Advances in NeuralInformation Processing Systems 16. MIT Press, Cambridge, MA, 2004.Fernando Fernandez and Manuela Veloso. Probabilistic policy reuse in a reinforcement learningagent. In Proceedings of the 5th International Conference on Autonomous Agents and MultiagentSystems, 2006.Norm Ferns, Pablo Castro, Prakash Panangaden, and Doina Precup. Methods for computing statesimilarity in Markov decision processes. In Proceedings of the 22nd Conference on Uncertaintyin Artificial intelligence, pages 174\u2013181, 2006.Norm Ferns, Prakash Panangaden, and Doina Precup. Metrics for Markov decision processes withinfinite state spaces. In Proceedings of the 2005 Conference on Uncertainty in Artificial Intelligence, pages 201\u2013208, 2005.David Foster and Peter Dayan. Structure in the space of value functions. Machine Learning, 49(1/2):325\u2013346, 2004.Allen Ginsberg. Theory revision via prior operationalization. In Proceedings of the 1988 NationalConference on Artificial Intelligence, pages 590\u2013595, 1988.Carlos Guestrin, Daphne Koller, Chris Gearhart, and Neal Kanodia. Generalizing plans to newenvironments in relational MDPs. In International Joint Conference on Artificial Intelligence(IJCAI-03), Acapulco, Mexico, August 2003.Okhtay Ilghami, Hector Munoz-Avila, Dana S. Nau, and David W. Aha. Learning approximate preconditions for methods in hierarchical plans. In ICML \u201905: Proceedings of the 22nd InternationalConference on Machine learning, pages 337\u2013344, 2005.Nicholas K. Jong and Peter Stone. Model-based exploration in continuous state spaces. In TheSeventh Symposium on Abstraction, Reformulation, and Approximation, July 2007.Leslie Pack Kaelbling, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: asurvey. Journal of Artificial Intelligence Research, 4:237\u2013285, May 1996.Leslie Pack Kaelbling, Michael L. Littman, and Anthony R. Cassandra. Planning and acting inpartially observable stochastic domains. Artificial Intelligence, 101(1-2):99\u2013134, 1998.1679\fTAYLOR AND S TONEZsolt Kalma\u0301r and Csaba Szepesva\u0301ri. An evaluation criterion for macro learning and some results.Technical Report TR-99-01, Mindmaker Ltd., 1999.Michael Kearns and Satinder Singh. Near-optimal reinforcement learning in polynomial time. InProc. 15th International Conf. on Machine Learning, pages 260\u2013268. Morgan Kaufmann, SanFrancisco, CA, 1998.W. Bradley Knox and Peter Stone. TAMER: training an agent manually via evaluative reinforcement. In IEEE 7th International Conference on Development and Learning, August 2008.J. Zico Kolter, Pieter Abbeel, and Andrew Ng. Hierarchical apprenticeship learning with applicationto quadruped locomotion. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances inNeural Information Processing Systems 20, pages 769\u2013776. MIT Press, Cambridge, MA, 2008.George Konidaris and Andrew Barto. Autonomous shaping: knowledge transfer in reinforcementlearning. In Proceedings of the 23rd International Conference on Machine Learning, pages 489\u2013496, 2006.George Konidaris and Andrew G. Barto. Building portable options: skill transfer in reinforcementlearning. In Proceedings of the 20th International Joint Conference on Artificial Intelligence,pages 895\u2013900, 2007.Gregory Kuhlmann and Peter Stone. Graph-based domain mapping for transfer learning in generalgames. In Proceedings of The Eighteenth European Conference on Machine Learning, September2007.Michail G. Lagoudakis and Ronald Parr. Least-squares policy iteration. Journal of Machine Learning Research, 4:1107\u20131149, 2003.John E. Laird, Paul S. Rosenbloom, and Allen Newell. Chunking in soar: the anatomy of a generallearning mechanism. Machine Learning, 1(1):11\u201346, 1986.Alessandro Lazaric. Knowledge Transfer in Reinforcement Learning. PhD thesis, Politecnico diMilano, 2008.Bethany R. Leffler, Michael L. Littman, and Timothy Edmunds. Efficient reinforcement learningwith relocatable action models. In Proceedings of the 22nd AAAI Conference on Artificial Intelligence, pages 572\u2013577, 2007.Lihong Li, Thomas J. Walsh, and Michael L. Littman. Towards a unified theory of state abstractionfor MDPs. In Proceedings of the Ninth International Symposium on Artificial Intelligence andMathematics, pages 531\u2013539, 2006.Yaxin Liu and Peter Stone. Value-function-based transfer for reinforcement learning using structuremapping. In Proceedings of the Twenty-First National Conference on Artificial Intelligence, pages415\u201320, July 2006.Richard Maclin and Jude W. Shavlik. Creating advice-taking reinforcement learners. MachineLearning, 22(1-3):251\u2013281, 1996.1680\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYRichard Maclin, Jude Shavlik, Lisa Torrey, Trevor Walker, and Edward Wild. Giving advice aboutpreferred actions to reinforcement learners via knowledge-based kernel regression. In Proceedings of the 20th National Conference on Artificial Intelligence, 2005.Michael G. Madden and Tom Howley. Transfer of experience between reinforcement learningenvironments with progressive difficulty. Artificial Intelligence Review, 21(3-4):375\u2013398, 2004.Sridhar Mahadevan and Mauro Maggioni. Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes. Journal of Machine Learning Research, 8:2169\u20132231, 2007.Maja J. Mataric. Reward functions for accelerated learning. In International Conference on MachineLearning, pages 181\u2013189, 1994.John McCarthy. A tough nut for proof procedures. Technical Report Sail AI Memo 16, ComputerScience Department, Stanford University, 1964.Neville Mehta, Sriraam Natarajan, Prasad Tadepalli, and Alan Fern. Transfer in variable-rewardhierarchical reinforcement learning. Machine Learning, 73(3):289\u2013312, 2008.Lilyana Mihalkova and Raymond J. Mooney. Transfer learning by mapping with minimal targetdata. In Proceedings of the AAAI-08 Workshop on Transfer Learning for Complex Tasks, July2008.Robin Milner. A Calculus of Communicating Systems. Springer-Verlag New York, Inc., Secaucus,NJ, USA, 1982.Andrew Moore. Variable resolution dynamic programming: efficiently learning action maps in multivariate real-valued state-spaces. In Machine Learning: Proceedings of the Eighth InternationalConference, June 1991.Andrew W. Moore and Christopher G. Atkeson. Prioritized sweeping: reinforcement learning withless data and less real time. Machine Learning, 13:103\u2013130, October 1993.Andrew Y. Ng and Michael Jordan. PEGASUS: a policy search method for large MDPs andPOMDPs. In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, 2000.Andrew Y. Ng, Daishi Harada, and Stuart Russell. Policy invariance under reward transformations:theory and application to reward shaping. In Proceedings of the 16th International Conferenceon Machine Learning, 1999.Andrew Y. Ng, Adam Coates, Mark Diel, Varun Ganapathi, Jamie Schulte, Ben Tse, Eric Berger,and Eric Liang. Inverted autonomous helicopter flight via reinforcement learning. In International Symposium on Experimental Robotics, 2004.Dirk Ormoneit and Saunak Sen. Kernel-based reinforcement learning. Machine Learning, 49(2-3):161\u2013178, 2002.Theodore J. Perkins and Doina Precup. Using options for knowledge transfer in reinforcement learning. Technical Report UM-CS-1999-034, The University of Massachusetts at Amherst, 1999.1681\fTAYLOR AND S TONECaitlin Phillips. Knowledge transfer in Markov decision processes. Technical report, McGill University, School of Computer Science, 2006. URL https://www.cs.mcgill.ca/\u02dccphill/CDMP/summary.pdf.Bob Price and Craig Boutilier. Accelerating reinforcement learning through implicit imitation.Journal of Artificial Intelligence Research, 19:569\u2013629, 2003.Martin L. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Programming. JohnWiley & Sons, Inc., 1994.Jan Ramon, Kurt Driessens, and Tom Croonenborghs. Transfer learning in reinforcement learningproblems through partial policy recycling. In Proceedings of The Eighteenth European Conference on Machine Learning, September 2007.Balaraman Ravindran and Andrew G. Barto. Model minimization in hierarchical reinforcementlearning. In Proceedings of the Fifth Symposium on Abstraction, Reformulation and Approximation, 2002.Balaraman Ravindran and Andrew G. Barto. An algebraic approach to abstraction in reinforcementlearning. In Proceedings of the Twelfth Yale Workshop on Adaptive and Learning Systems, pages109\u2013114, 2003a.Balaraman Ravindran and Andrew G. Barto. Relativized options: choosing the right transformation.In Proceedings of the Twentieth International Conference on Machine Learning (ICML 2003),pages 608\u2013615, Menlo Park, CA, August 2003b. AAAI Press.Daniel M. Roy and Leslie P. Kaelbling. Efficient Bayesian task-level transfer learning. In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, Hyderabad, India,2007.Gavin Rummery and Mahesan Niranjan. On-line Q-learning using connectionist systems. TechnicalReport CUED/F-INFENG-RT 116, Engineering Department, Cambridge University, 1994.Manish Saggar, Thomas D\u2019Silva, Nate Kohl, and Peter Stone. Autonomous learning of stablequadruped locomotion. In Gerhard Lakemeyer, Elizabeth Sklar, Domenico Sorenti, and TomoichiTakahashi, editors, RoboCup-2006: Robot Soccer World Cup X, volume 4434 of Lecture Notesin Artificial Intelligence, pages 98\u2013109. Springer Verlag, Berlin, 2007.Oliver G. Selfridge, Richard S. Sutton, and Andrew G. Barto. Training and tracking in robotics.In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, pages 670\u2013672, 1985.Lloyd S. Shapley. Stochastic games. Proceedings of the National Academy of Sciences of the UnitedStates of America, 39(10):1095\u20131100, October 1953.Manu Sharma, Michael Holmes, Juan Santamaria, Arya Irani, Charles Isbell, and Ashwin Ram.Transfer learning in real-time strategy games using hybrid CBR/RL. In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, 2007.1682\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYAlexander A. Sherstov and Peter Stone. Improving action selection in MDP\u2019s via knowledge transfer. In Proceedings of the Twentieth National Conference on Artificial Intelligence, July 2005.Danny Silver, Goekhan Bakir, Kristin Bennett, Rich Caruana, Massimiliano Pontil, Stuart Russell,and Prasad Tadepalli. NIPS workshop on \u201cInductive transfer: 10 years later\u201d, December 2005.O\u0308zgu\u0308r S\u0327ims\u0327ek and Andrew G. Barto. An intrinsic reward mechanism for efficient exploration. InProceedings of the Twenty-Third International Conference on Machine Learning, 2006.Satinder Singh and Richard S. Sutton. Reinforcement learning with replacing eligibility traces.Machine Learning, 22:123\u2013158, 1996.Satinder P. Singh. Transfer of learning by composing solutions of elemental sequential tasks. Machine Learning, 8:323\u2013339, 1992.Burrhus F. Skinner. Science and Human Behavior. Colliler-Macmillian, 1953.Vishal Soni and Satinder Singh. Using homomorphisms to transfer options across continuous reinforcement learning domains. In Proceedings of the Twenty First National Conference on ArtificialIntelligence, July 2006.Ashwin Srinivasan. The aleph manual, 2001.Peter Stone and Manuela Veloso. Multiagent systems: a survey from a machine learning perspective.Autonomous Robots, 8(3):345\u2013383, July 2000.Peter Stone, Richard S. Sutton, and Gregory Kuhlmann. Reinforcement learning for RoboCupsoccer keepaway. Adaptive Behavior, 13(3):165\u2013188, 2005.Funlade T. Sunmola and Jeremy L. Wyatt. Model transfer for Markov decision tasks via parametermatching. In Proceedings of the 25th Workshop of the UK Planning and Scheduling SpecialInterest Group (PlanSIG 2006), December 2006.Richard S. Sutton. Learning to predict by the methods of temporal differences. Machine Learning,3:9\u201344, 1988.Richard S. Sutton and Andrew G. Barto. Introduction to Reinforcement Learning. MIT Press, 1998.Richard S. Sutton, Doina Precup, and Satinder P. Singh. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial Intelligence, 112(1-2):181\u2013211, 1999.Richard S. Sutton, Anna Koop, and David Silver. On the role of tracking in stationary environments.In Proceedings of the 24th International Conference on Machine Learning, 2007.Samarth Swarup and Sylvian R. Ray. Cross-domain knowledge transfer using structured representations. In Proceedings of the Twenty First National Conference on Artificial Intelligence, July2006.Umar Syed and Robert Schapier. A multiplicative weights algorithm for apprenticeship learning. InAdvances in Neural Information Processing Systems 21, 2007.1683\fTAYLOR AND S TONEErik Talvitie and Satinder Singh. An experts algorithm for transfer learning. In Proceedings of theTwentieth International Joint Conference on Artificial Intelligence, 2007.Fumihide Tanaka and Masayuki Yamamura. Multitask reinforcement learning on the distributionof MDPs. Transactions of the Institute of Electrical Engineers of Japan. C, 123(5):1004\u20131011,2003.Brian Tanner, Adam White, and Richard S. Sutton. RL Glue and codecs, 2008. https://mloss.org/software/view/151/.Matthew E. Taylor and Peter Stone. Representation transfer for reinforcement learning. In AAAI2007 Fall Symposium on Computational Approaches to Representation Change during Learningand Development, November 2007a.Matthew E. Taylor and Peter Stone. Cross-domain transfer for reinforcement learning. In Proceedings of the Twenty-Fourth International Conference on Machine Learning, June 2007b.Matthew E. Taylor, Peter Stone, and Yaxin Liu. Transfer learning via inter-task mappings for temporal difference learning. Journal of Machine Learning Research, 8(1):2125\u20132167, 2007a.Matthew E. Taylor, Shimon Whiteson, and Peter Stone. Transfer via inter-task mappings in policy search reinforcement learning. In The Sixth International Joint Conference on AutonomousAgents and Multiagent Systems, May 2007b.Matthew E. Taylor, Alan Fern, Kurt Driessens, Peter Stone, Richard Maclin, and Jude Shavlik.AAAI workshop on \u201cTransfer learning for complex tasks\u201d, July 2008a.Matthew E. Taylor, Nicholas Jong, and Peter Stone. Transferring instances for model-based reinforcement learning. In Proceedings of the Adaptive Learning Agents and Multi-Agent Systems(ALAMAS+ALAG) workshop at AAMAS-08, May 2008b.Matthew E. Taylor, Nicholas K. Jong, and Peter Stone. Transferring instances for model-basedreinforcement learning. In Proceedings of the European Conference on Machine Learning andPrinciples and Practice of Knowledge Discovery in Databases (ECML PKDD), pages 488\u2013505,September 2008c.Gerald Tesauro. TD-Gammon, a self-teaching backgammon program, achieves master-level play.Neural Computation, 6(2):215\u2013219, 1994.Edward L. Thorndike and Robert S. Woodworth. The influence of improvement in one mentalfunction upon the efficiency of other functions. Psychological Review, 8:247\u2013261, 1901.Sebastian Thrun. Is learning the n-th thing any easier than learning the first? In Advances in NeuralInformation Processing Systems, volume 8, pages 640\u2013646, 1996.Sebastian Thrun and Lorien Pratt, editors. Learning to learn. Kluwer Academic Publishers, Norwell, MA, USA, 1998.Lisa Torrey, Trevor Walker, Jude W. Shavlik, and Richard Maclin. Using advice to transfer knowledge acquired in one reinforcement learning task to another. In Proceedings of the SixteenthEuropean Conference on Machine Learning, pages 412\u2013424, 2005.1684\fT RANSFER L EARNING FOR R EINFORCEMENT L EARNING D OMAINS : A S URVEYLisa Torrey, Jude W. Shavlik, Trevor Walker, and Richard Maclin. Skill acquisition via transferlearning and advice taking. In Proceedings of the Sixteenth European Conference on MachineLearning, pages 425\u2013436, 2006.Lisa Torrey, Jude W. Shavlik, Trevor Walker, and Richard Maclin. Relational macros for transferin reinforcement learning. In Proceedings of the Seventeenth Conference on Inductive LogicProgramming, 2007.Thomas J. Walsh, Lihong Li, and Michael L. Littman. Transferring state abstractions betweenMDPs. In Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for MachineLearning, June 2006.Christopher J. C. H. Watkins. Learning from Delayed Rewards. PhD thesis, King\u2019s College, Cambridge, UK, 1989.Shimon Whiteson, Adam White, Brian Tanner, Richard S. Sutton Sutton, Doina Precup, Peter Stone,Michael Littman, Nikos Vlassis, and Martin Riedmiller. ICML workshop on \u201cThe 2008 RLcompetition\u201d, July 2008.Gerhard Widmer and Miroslav Kubat. Learning in the presence of concept drift and hidden contexts.Machine Learning, 23(1):69\u2013101, 1996.Ronald J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8:229\u2013256, 1992.Aaron Wilson, Alan Fern, Soumya Ray, and Prasad Tadepalli. Multi-task reinforcement learning: ahierarchical Bayesian approach. In ICML \u201907: Proceedings of the 24th international conferenceon Machine learning, pages 1015\u20131022, 2007.Wei Zhang and Thomas G. Dietterich. A reinforcement learning approach to job-shop scheduling.In Proceedings of the International Joint Conference on Artificial Intelligence, 1995.1685\f", "Int J Comput Vis (2014) 109:42\u201359DOI 10.1007/s11263-014-0703-yWeakly-Supervised Cross-Domain Dictionary Learningfor Visual RecognitionFan Zhu \u00b7 Ling ShaoReceived: 15 March 2013 / Accepted: 14 February 2014 / Published online: 12 March 2014\u00a9 Springer Science+Business Media New York 2014Abstract We address the visual categorization problemand present a method that utilizes weakly labeled data fromother visual domains as the auxiliary source data for enhancing the original learning system. The proposed method aimsto expand the intra-class diversity of original training datathrough the collaboration with the source data. In orderto bring the original target domain data and the auxiliarysource domain data into the same feature space, we introduce a weakly-supervised cross-domain dictionary learningmethod, which learns a reconstructive, discriminative anddomain-adaptive dictionary pair and the corresponding classifier parameters without using any prior information. Sucha method operates at a high level, and it can be applied to different cross-domain applications. To build up the auxiliarydomain data, we manually collect images from Web pages,and select human actions of specific categories from a different dataset. The proposed method is evaluated for humanaction recognition, image classification and event recognition tasks on the UCF YouTube dataset, the Caltech101/256datasets and the Kodak dataset, respectively, achieving outstanding results.Communicated by Dr. Trevor Darrell.F. Zhu \u00b7 L. Shao (B)College of Electronic and Information Engineering,Nanjing University of Information Science and Technology,Nanjing 210044, Chinae-mail: ling.shao@ieee.orgF. Zhu \u00b7 L. ShaoDepartment of Electronic and Electrical Engineering,The University of Sheffield, Sheffield S1 3JD, UKe-mail: ling.shao@sheffield.ac.ukF. Zhue-mail: fan.zhu@sheffield.ac.uk123Keywords Visual categorization \u00b7 Image classification \u00b7Human action recognition \u00b7 Event recognition \u00b7 Transferlearning \u00b7 Weakly-supervised dictionary learning1 IntroductionIn the past few years, along with the explosion of onlineimage and video data (Flickr1 , YouTube2 ), the computervision community has witnessed a significant amount ofapplications in content-based image/video search andretrieval, human\u2013computer interaction, sport events analysis, etc. These applications are built upon the developmentof several aspects of classical computer vision tasks, such ashuman action recognition, object localization and image classification, which, however, remain challenging in real-worldscenarios due to cluttered background, view point changes,occlusion, and geometric and photometric variations of thetarget (Su and Jurie 2012; Yao et al. 2012; Wang and Mori2011, 2009; J\u00e9gou et al. 2010; Junejo et al. 2011; Duchenne etal. 2009; Marszalek et al. 2009). These issues result in eitherimposing irrelevant information to the target introduced by,e.g., cluttered background, or producing very different representations for the same target caused by, e.g., geometric andphotometric changes. Many previous methods that manageto deal with these issues are proposed and state-of-the-artapproaches include semantic attributes (Su and Jurie 2012),estimated pose features (Yao et al. 2012), and mined hierarchical features (Gilbert et al. 2011). The conventional framework applies a robust classifier using human annotated training data, but it makes the assumption that the testing data stayin the same feature space or share the same distribution with1https://www.flickr.com/2https://www.youtube.com/\fInt J Comput Vis (2014) 109:42\u201359the training data. However, in real-world applications, due tothe high price of human manual annotation and environmental restrictions, sufficient training data that stay in the samefeature space or share the same distribution with the testingdata cannot always be guaranteed, in which case insufficienttraining data can limit the potential discriminability of thetrained model. Typical examples are Cao et al. (2013), Gaoet al. (2011), and Orrite et al. (2011), where only one actiontemplate is provided for each action class for training, and Liuet al. (2011), where training samples are captured from a different viewpoint. In these situations, obtaining more labeleddata is either impossible or expensive, while seeking for analternative way of using data from other domains as compensation can be seen as a possible and economic solution.Our work is inspired by two facts of the human visionsystem. The first fact is that humans are able to learn tensof thousands of visual categories in their life, which leadsto the hypothesis that humans achieve such a capability byaccumulated information and knowledge (Fei-Fei 2006), asshown in Fig. 1. Another fact is human\u2019s visual impressionstowards the same action or the same object comes from awide range, e.g., an action seen from 2D static images versusthe same action seen from 3D dynamic movies or an objectseen from real-world scenes versus the same object seen fromlow-resolution online images. However, the human visionsystem is still able to correctly distinguish such actions orobjects regardless of their visual diversities, which, in otherwords, can be explained in the computer vision language thatthe human vision system possesses the ability to span theintra-class diversity of the original training data. In a similarway, we argue that the computer-based visual categorization43system can also gain more discriminative power by spanningthe coverage of training samples\u2019 intra-class variations, asshown in Fig. 2.Motivated by the above two facts, we introduce a newvisual categorization framework that utilizes weakly labeleddata from other domains as the source data (motivated bythe first fact) to span the intra-class diversity of the originallearning system (motivated by the second fact). Followingthe classical single-task cross-domain learning setup (Panand Yang 2010), our aim is to complete the visual categorization task in the target domain. In addition to the manually labeled training data in the target domain, the sourcedomain data are utilized as extensions of category prototypesin the target domain. Based on the recent success of dictionary learning methods in solving computer vision problems, we present a weakly-supervised cross-domain dictionary learning method to learn a reconstructive, discriminativeand domain-adaptive dictionary pair and an optimal linearclassifier simultaneously. In order to demonstrate the effectiveness of our method, we gather supportive evidence byevaluating our method on action recognition, image classification and event recognition tasks. The UCF YouTubedataset (Liu et al. 2009), the Caltech101 dataset (Fei-Fei etal. 2007), the Caltech 256 dataset (Griffin et al. 2007) andthe Kodak consumer video dataset (Loui et al. 2007) are usedas the target domain data in our experiments, while selectedactions in the HMDB51 dataset (Kuehne et al. 2011) andsome indexed Web images or YouTube videos are used asthe source domain data in our experiments. The preliminaryresults of our method have been presented in Zhu and Shao(2013).Fig. 1 Illustration of how anew object is accumulated to thehuman visual system as priorknowledge for future usage. Thegiven unknown object is a futurecar, which is unacquainted to theviewer. Since the viewer\u2019s priorknowledge towards cars spans awild coverage of target samples,shared information (e.g., carshape and wheels) between thenew object and prior knowledgeis easily discovered.123\f44Int J Comput Vis (2014) 109:42\u201359Fig. 2 Illustration of how the categorization system can gain morediscriminative power through the collaboration with the source domaindata in the 2-dimensional feature space. The purple triangles, the orangecircles and the red squares denote the training samples from Classes1, 2 and 3 respectively, and the corresponding hollow shapes denotethe auxiliary training samples from Classes 1, 2 and 3. Original decision boundaries are represented by the solid lines and the new decisionboundaries are represented by the dashed lines. The testing sample,which is denoted as a red square with black borders, is misclassified asClass 1 according to the original decision boundaries. Proper auxiliarysamples lead to more rational decision boundaries, so that the coverageof Class 1 spans against the centre of Class 2. Thus, the testing samplecan be correctly labeled (Color figure online)Fig. 3 Flowchart of the proposed approach. The target domain dataare split into the training part and the testing part, where the trainingdata are used as a set of queries to rank the source domain data withinselected categories. A pre-defined number of most relevant source samples are chosen to construct the transformation matrix, which describesthe connections between the source domain data and the target domaindata. With the label information of the target domain training samples,weakly-supervised cross-domain dictionary learning is performed. Areconstructive, discriminative and domain-adaptive dictionary pair islearned together with the target classifier. The target domain testingdata can be encoded with the learned target domain dictionary, following which the labels can be predicted by feeding the new representationsinto the learned classifierOur proposed method is illustrated in Fig. 3 and it offersthe following two main contributions. Firstly, it attempts tomake use of as much as possible existing knowledge by anovel weakly-supervised visual categorization framework.An efficient manifold ranking method is applied to the sourcedomain for the selection of a pre-defined number of most relevant instances per category according to the target domaintraining data, following which correspondences connectingthe source domain and the target domain are establishedbased on the selected source domain data and the targetdomain training data. Secondly, we propose a new crossdomain dictionary learning method to cope with the featuredistribution mismatch problem across the source domain andthe target domain. Specifically, we perform dictionary learning upon the correspondences built from both domains sothat the projections of data from different domains can obeythe same distribution when limited by the learning function.In addition to the dictionary, classifier parameters are learnedjointly during the discriminative dictionary function learningprocess. Thus, knowledge transfer of the proposed framework is accomplished through both the feature level andthe classifier level. As the samples from the source domainsare weakly labeled rather than being manually (correctly)labeled, we call our algorithm \u201cWeakly-Supervised CrossDomain Dictionary Learning\u201d(WSCDDL).The remainder of this paper is organized in the following way. Related works are reviewed in Sect. 2. InSects. 3 and 4, we first extensively discuss related dictionary learning techniques and then introduce the proposed cross-domain dictionary learning method. Experimental results on human action recognition, image classification and event recognition are comprehensively presentedin Sect. 5. Finally, the conclusion of this work is given inSect. 6.123\fInt J Comput Vis (2014) 109:42\u2013592 Background WorkA considerable number of methods have been proposed toaddress visual categorization problems (Maji et al. 2013; Ji etal. 2013; Zafeiriou et al. 2012; Liwicki et al. 2012; Xiang et al.2012; Liu et al. 2012). Reasonable results are achieved usingtraditional machine learning approaches without considering the data distribution mismatch among the training dataand the testing data when training data are abundant. Transfer learning (a.k.a., cross-domain learning, domain transfer,domain adaptation) approaches begin to attract increasinginterests in the computer vision community in recent yearsdue to the data explosion on the Internet and the growingdemands for visual computational tasks. In Cao et al. (2010),action detection is conducted across datasets from different visual domains, where the KTH dataset (Schuldt 2004),which has a clean background and limited viewpoint andscale changes, is set as the source domain, and the MicrosoftResearch Action Dataset3 and the TRECVID surveillancedata (Dikmen et al. 2008), which are captured from realisticscenarios, are used as the target domain. Yang et al. (2007)and Duan et al. (2012a) addressed the problem of video concept detection using domain transfer approaches. The formerone utilized the Adaptive Support Vector Machine (A-SVM)to adapt one or more existing classifiers of any type to a newdataset, and the latter proposed a Domain Transfer MultipleKernel Learning (DTMKL) method to simultaneously learna kernel function and a robust SVM classifier by minimizingboth the structural risk function of SVM and the distributionmismatch of labeled and unlabeled data in different domains.Liu et al. (2011) and Li and Zickler (2012) constructed crossdomain representations to cope with the cross-view actionrecognition problem, where the divergences across domainsare caused by view-point changes. Liu et al. (2011) builta bipartite graph via unsupervised co-clustering to measurethe visual-word to visual-word relationship across the target view and the source view so that a high-level semantic feature that bridges the semantic gap between the twovocabularies can be filled. Similarly, Li and Zickler (2012)captured the conceptual idea of \u201cvirtual views\u201dto representan action descriptor continuously from an observer\u2019s viewpoint to another. Duan et al. (2012b) considered to leveragelarge amounts of loosely labeled web videos for visual eventrecognition using the Adaptive Multiple Kernel Learning (AMKL) to fuse the information from multiple pyramid levelsand features and cope with the considerable variation in feature distributions between videos across two domains.Recently, dictionary learning for sparse representation hasattracted much attention. It has been successfully appliedto a variety of computer vision tasks, e.g., face recognition (Wright et al. 2009) and image denoising (Zhou et al.3https://research.microsoft.com/~zliu/ActionRecoRsrc452009). Using an over-complete dictionary, sparse modelingof signals can approximate the input signal by a sparse linear combination of items from the dictionary. Many algorithms (Lee et al. 2007; Wang et al. 2010; Wright et al. 2009)have been proposed to learn such a dictionary according todifferent criteria. The K-Singular Value Decomposition (KSVD) algorithm (Aharon et al. 2006) is a classical dictionarylearning algorithm that generalizes the K-means clusteringprocess for adapting dictionaries to efficiently learn an overcomplete dictionary from a set of training signals. The KSVD method focuses on the reconstructive ability, however,since the learning process is unsupervised, the discriminative capability is not taken into consideration. Consequently,methods that incorporate the discriminative criteria into dictionary learning were proposed in Zhang and Li (2010), Yanget al. (2010), Mairal et al. (2008a, 2008b, 2009), Boureau etal. (2010). In addition to the discriminative capability of thelearned dictionary, other criteria designed on top of the prototype dictionary learning objective function include multipledictionary learning (Zhang et al. 2009), category-specific dictionary learning (Yang et al. 2008), etc. Different from mostdictionary learning methods, which learned the dictionaryand the classifier separately, Zhang and Li (2010) and Jianget al. (2011) unified these two learning procedures into a single supervised optimization problem and learned a discriminative dictionary and the corresponding classifier simultaneously. Taking a step further, Qiu et al. (2012) and Zheng et al.(2012) designed dictionaries for the situations that the presenttraining instances are different from the testing instances. Theformer presented a general joint optimization function thattransforms a dictionary learned from one domain to the other,and applied such a framework to applications such as posealignment, pose and illumination estimation and face recognition. The latter achieved promising results on the crossview action recognition problem with pairwise dictionariesconstructed using correspondences between the target viewand the source view. To make use of some data that maynot be relevant to the target domain data, Raina et al. (2007)proposed a method that applies sparse coding to unlabeleddata to break the tremendous amount of data in the sourcedomain into basic patterns (e.g., edges in the task of imageclassification) so that knowledge can be transferred throughthe bottom level to a high level representation.Our approach differs from the above approaches in suchaspects that it more comprehensively learns pairwise dictionaries and a classifier while considering the capacity of thedictionaries in terms of reconstructability, discriminabilityand domain adaptability. Additionally, corresponding observations across the domains are not required in our framework.While most previous knowledge transfer algorithm focus onthe situations where the target domain is incomplete, but havenot attempted to utilize other domain data as an aide forenhancing present categorization systems, in our approach,123\f46Int J Comput Vis (2014) 109:42\u201359the learned classifier in the target domain becomes more discriminative against intra-class variations as a result of thelearning process that integrates with source domain data.3 Dictionary Learningunder the sparsity constraint, thus one has to seek alternative methods to approximate the solution, e.g., the greedyalgorithms Matching Pursuit (MP) (Mallat and Zhang 1993)and Orthogonal Matching Pursuit (OMP) (Pati et al. 1993),which sequentially select the dictionary atoms. More detailson optimizing the objective function under the l0 -norm constraint are given in Sect. 3.3.3.1 Reconstruction3.2.2 Dictionary Learning with l1 -NormLet y \u2208 \u0003n denote an n-dimensional input signal, and suppose it can be reconstructed by the linear transformation of anN -dimensional projection coefficient x \u2208 \u0003 N via a projection dictionary D \u2208 \u0003n\u00d7N . Considering the reconstructionerror, the transformation can be formulated as:The Basis Pursuit (BP) (Chen et al. 1993) suggests an alternative sparse solution by relaxing the l0 -norm with the higherorder l1 -norm. The dictionary learning problem in Eq. (3) canbe reformulated as follows with the l1 -norm constraint:y = Dx + E(x).E(x) = \u0004y \u2212 Dx\u000422 , s.t.\u0004x\u00041 \u2264 T.(1)where we use E(x) to represent the reconstruction error, thenthe optimal dictionary and coefficient can be obtained byminimizing E(x). We quantitatively measure E(x) using:E(x) = \u0004y \u2212 Dx\u000422 .(2)It is worth to point out that if the dimension of the projectioncoefficient x is larger than the dimension of input signal y,i.e., N > n, the solution to the unconstrained optimizationproblem in Eq. (2) is not unique, thus it leads to the overfitting problem.The sparsity constraints for dictionary learning attract moreattention recently, and applications that can benefit from sparsity include compression, regularization in inverse problems,etc. The commonly used sparsity constraints are l0 -norm andl1 -norm.3.2.1 Dictionary Learning with l0 -Norml0 -norm is the lowest normalization form, and it indicatesthe solution with fewest non-zero entries. When learning adictionary with the l0 -norm sparse constraint, Eq. (2) can beformulated as:(3)where T is the sparsity constraint factor that limits the numberof non-zero elements in the sparse codes, so that the number of items in the decomposition of each x is less than T .Updating both x and D simultaneously is generally NP-hard;however, we can manage to seek an improved D when fixingx, or seek an optimal x when fixing D. Thus, the constructionof dictionary D is achieved through iteratively minimizingthe reconstruction error and learning a reconstructive dictionary for sparse representations (Aharon et al. 2006). Given D,the computation of the sparse code x is generally NP-hard123Again, such a problem can be solved iteratively by alternatingly optimizing D or the sparse code x while fixing theother. When the dictionary D is fixed, the optimization problem is equivalent to a linear regression problem with l1 -normregularization on the coefficients, which can be solved bythe feature-sign search algorithm (Lee et al. 2006). Whenthe sparse code x is fixed, the problem is reduced to a Leastsquare problem with quadratic constraints, so that it can besolved by the Lagrange dual as in Lee et al. (2006).3.3 Classification via Dictionary Learning3.2 Sparsity ConstraintsE(x) = \u0004y \u2212 Dx\u000422 , s.t.\u0004x\u00040 \u2264 T,(4)A classifier f (x) can be directly employed to the sparserepresentation x for classification, and the classifier can beobtained by satisfying:W = arg min L{h, f (x, W )} + \u03bb\u0004W \u00042F ,W(5)where L is the classification loss function, e.g., quadratic lossfunction and hinge loss function, h indicates the label of x,W denotes the classifier parameters and \u03bb is a regularizationparameter for preventing overfitting. However, separating thedictionary learning stage from the classification proceduremight lead to a suboptimal D. Previous approaches (Zhangand Li 2010; Yang et al. 2010; Mairal et al. 2008a,b, 2009;Jiang et al. 2011) attempt to jointly learn a dictionary and aclassifier for classification tasks. In this case, the dictionarylearning problem can be formulated as:< D, W, x > = arg min \u0004y \u2212 Dx \u000422 + L{h, f (x, W )}D,W,x(6)+ \u03bb\u0004W \u000422 , s.t.\u0004x\u00040 \u2264 T.An extra classification term can encourage the data to besmooth. However, if we deal with data from two domains, theclassification term can only guarantee the local smoothnessin each respective domain. Thus, we introduce a new term toseek the global smoothness across both domains.\fInt J Comput Vis (2014) 109:42\u201359474 Domain Adaptation via Dictionary LearningWe denote Yt as L n-dimensional target domain instances,and Ys as M source domain n-dimensional instances, i.e.,Yt = [yt1 , . . . , ytL ] \u2208 \u0003n\u00d7L and Ys = [ys1 , . . . , ysM ] \u2208\u0003n\u00d7M . Learning a reconstructive dictionary pair while pursuing the global smoothness can be accomplished by solvingthe following optimization problems:< Dt , Ds , X t , X s > = argminDt ,Ds ,X t ,X s\u0004Yt \u2212 Dt X t \u000422+ \u0004Ys \u2212 Ds X s \u000422 + \u03a6([X t X s ])s.t.\u2200i, [ \u0004xti \u00040 , \u0004xsi \u00040 ] \u2264 T,(7)where \u03a6(\u00b7) is designed to measure the distances of similar cross-domain instances of the same category, Dt =[dt1 , . . . , dtN ] \u2208 \u0003n\u00d7N is the learned target domain dictionary, X t = [xt1 , . . . , xtL ] \u2208 \u0003 N \u00d7L is the set of target domainsparse codes, Ds = [ds1 , . . . , dsN ] \u2208 \u0003n\u00d7N is the learnedsource domain dictionary and X s = [xs1 , . . . , xsM ] \u2208 \u0003 N \u00d7Mis the set of source domain sparse codes, respectively. Thenumber of dictionary items N is set to be larger than eitherL or M to ensure that the dictionaries are over-complete. Todefine \u03a6(\u00b7), we aim to force the sparse codes that possess thesame class label to be close to each other, and thus geometrically simple decision boundaries are preferred. To this end,Zheng et al. (2012) presented a strategy that manually setsup a set of correspondence training instances for cross-viewaction recognition, where the same action pair performed indifferent views are encouraged to share the same representation when being projected onto the cross-view dictionary pair.Inspired by such a strategy, we measure the cross-domaindivergence by constructing virtual correspondences acrossboth domains through a transformation matrix A. Given\u03a6([X t X s ]) = \u0004X tT \u2212 AX sT \u000422 , Eq. (7) can be written as:< Dt , Ds , X t , X s > = argminDt ,Ds ,X t ,X s\u0004Yt \u2212 Dt X t \u000422s.t.\u2200i, [] \u2264 T.Once the set of transformation matrices for all the C categories are computed, the global transformation matrix A \u2208\u0003 L\u00d7M can be obtained by filling all the category-specificsub-matrices into A:\u239e\u239bA1\u239f\u239cA2\u239f\u239c(10)A=\u239c\u239f,..\u23a0\u239d.ACwhere all the blank elements are set to 0, so that A is a binarymatrix. Since A is computed in a category-specific manner,target domain training samples can only be connected tothose source domain samples of the same category. Thus,overall smoothness across both domains can be guaranteedafter such a transformation. Assuming A leads to a perfectmapping across the sparse codes X t and X s and each matchedpair of samples in different domains possesses an identicalrepresentation after encoding, then \u0004X tT \u2212AX sT \u000422 = 0. Sincethese two terms are computed with l2 normalization, if theyequal to zero, we can obtain X tT = AX sT , i.e., X t = X s AT .By transforming the source domain data to match the targetdomain data, we formulate the new objective function as:< Dt , Ds , X t , X s >= argminDt ,Ds ,X t ,X s\u0004Yt \u2212 Dt X t \u000422 + \u0004(Ys \u2212 Ds X s )AT \u000422= arg min \u0004Yt \u2212 Dt X t \u000422 + \u0004Ys AT \u2212 Ds X s AT \u000422Dt ,Ds ,X t= arg min \u0004Yt \u2212 Dt X t \u000422 + \u0004Ys AT \u2212 Ds X t \u000422Dt ,Ds ,X ts.t.\u2200i, \u0004xti \u00040 \u2264 T.+\u0004Ys \u2212 Ds X s \u000422 + \u0004X tT \u2212 AX sT \u000422\u0004xti \u00040 , \u0004xsi \u00040element in each column of Gc while discarding the remainelements, i.e., we only ensure a one-to-one correspondencefor each source domain instance:\u00021, if Gc (i, j) = max(Gc (:, j))(9)Ac (i, j) =0, otherwise.(8)However, in our case, rather than cross-view action pairs,the data we are dealing with come from different datasets,so that setting up correspondence instances is not possible.We turn to seek an alternative solution to building up suchcorrespondences. For each category, we introduce a transformation matrix Ac . The general sense of Ac is that it mapsthe most similar source domain instance to a target domaininstance of the same category. We adopt a fuzzy categoryspecific searching method to compute each Ac . Consideringthat Ytc and Ysc are the c-th category data from both domains,we first compute the Gaussian distances between each pairof data between Ytc and Ysc , and store the result in a matrixGc . Then Ac can be computed by preserving the maximum(11)Following Zhang and Li (2010), Mairal et al. (2008a;2008b, 2009), and Jiang et al. (2011), we include a labelconsistency regularization term and the classification errorof a linear predictive classifier f (x) into the objective function to further enhance the global smoothness. Thus, the newobjective function for cross-domain dictionary learning isupdated as:< Dt , Ds , X t , A, W >= argminDt ,Ds ,X t ,A,W\u0004Yt \u2212 Dt X t \u000422+ \u0004Ys AT \u2212 Ds X t \u000422 + \u03b1\u0004Q \u2212 \u03d1 X t \u00042 + \u03b2\u0004H \u2212 W X t \u000422s.t.\u2200i, \u0004xti \u00040 \u2264 T,(12)where W are the coefficients of the linear classifier f (x), Hare the class labels of target domain data, \u03d1 is a linear transformation matrix that maps the the original sparse codes to bein correspondence with the target discriminative sparse codes123\f48Int J Comput Vis (2014) 109:42\u201359Q = [q1 , q2 , . . . , q L ] \u2208 \u0003 L\u00d7L of the input signal Yt . Specifically, qi = [qi1 , qi2 , . . . , qiK ]T = [0, . . . , 1, 1, . . . , 0]T \u2208\u0003 L\u00d71 , and the non-zeros occur at those indices where yti \u2208 Ytand X tk \u2208 X t share the same class label. Given X t =[x1 , x2 , . . . , x6 ] and Yt = [y1 , y2 , . . . , y6 ], and assuming x1 ,x2 , y1 and y2 are from class 1, x3 , x4 , y3 and y4 are fromclass 2, x5 , x6 , y5 and y6 are from class 3, Q is then definedwith the following form:\u239b\u239e1 1 0 0 0 0\u239c1 1 0 0 0 0 \u239f\u239c\u239f\u239c0 0 1 1 0 0 \u239f\u239c\u239f(13)\u239c0 0 1 1 0 0 \u239f,\u239c\u239f\u239d0 0 0 0 1 1 \u23a00 0 0 0 1 1and H = [h 1 , h 2 , . . . , h L ] \u2208 \u0003C\u00d7L are the class labels ofYt , where the non-zero element indicates the class of an inputsignal within each column h i = [0, . . . , 1, . . . , 0]T \u2208 \u0003C\u00d71 .Following the same example in (13), H can be defined as:\u239b\u239e1 1 0 0 0 0\u239d0 0 1 1 0 0 \u23a0 .(14)0 0 0 0 1 1Scalers \u03b1 and \u03b2 are set to control the relative contributionof the terms \u0004Q \u2212 \u03d1 X t \u00042 and \u0004H \u2212 W X t \u000422 . By solvingthe optimization problem in Eq. (12), the reconstructive, discriminative and domain-adaptive dictionary pair Dt and Dsas well as the optimal classifier parameter W can be obtained.4.1 Optimization4.1.1 Solving WSCDD with the K-SVD algorithmWe rewrite Eq. (12) as:< Dt , Ds , X t , W >= arg minDt ,Ds ,X t ,W\u239b\u239e \u239b\u239eYtDt\u239c Ys AT \u239f \u239c Ds \u239f2i\u239f \u239c\u239f\u0004\u239c\u239d \u221a\u03b1 Q \u23a0 \u2212 \u239d \u221a\u03b1\u03d1 \u23a0 X t \u00042 , s.t.\u2200i, \u0004xt \u00040 \u2264 T, (15)\u221a\u221a\u03b2H\u03b2WTo make it clear, we write the left side of Eq. (15) as\u221a\u221aY = (YtT , (Ys AT )T , \u03b1 Q T , \u221a \u03b2 H T )T \u221aand the right sideof Eq. (15) as D = (DtT , DsT , (\u03b1)\u03d1 T , (\u03b2)W T )T , wherecolumn-wise l2 normalization is applied to D, so that optimizing Eq. (15) is cast as optimizing Eq. (16):< D, X t >= arg min \u0004Y \u2212 D X t \u000422 , s.t.\u2200i, \u0004xti \u00040 \u2264 T.D,X t(16)Such an optimization problem can be solved using the KSVD (Aharon et al. 2006) algorithm. Specifically, Eq. (16)can be solved in an iterative manner through both dictionary123updating stage and sparse coding stage. In the dictionaryupdating stage, each dictionary element is updated sequentially to better represent the original data in both the sourcedomain and the target domain as well as the discriminativeproperty along with the training data. When pursuing a betterdictionary D, the sparse codes X t are frozen, and each dictionary element is updated through a straightforward solutionwhich tracks down a rank-one approximation to the matrixof residuals. Following K-SVD, the kth element of the dictionary D and its corresponding coefficients, i.e. the kth rowin the coefficient matrix X t , are denoted as dk and xk respecjtively. Let Sk = Y \u2212 j\b=k d j xt and we further denote xkand Sk as the results we obtain when all zero entries in xkand Sk are discarded, respectively. Thus, each dictionary element dk and its correspondingly non-zero coefficients xk canbe computed by< dk , xk >= arg min \u0004 Sk \u2212 dk xk \u00042F .dk , x k(17)The approximation in Eq. (17) is achieved through performing Singular Value Decomposition (SVD) on Sk :SV D( Sk ) = U \u03a3 V Tdk = U (:, 1)xk = \u03a3(1, 1)V (1, :),(18)where U (:, 1) indicates the first column of U and V (1, :)indicates the first row of V .At the sparse coding stage, we compute the \u201cbest matching\u201d projections X t of the multidimensional training dataonto the updated dictionary D using an appropriate pursuitalgorithm. As introduced above, given the fixed D, the optimization of Eq. (16) remains NP-hard under the l0 -norm constraint. Therefore the OMP algorithm is adopted to approximate the solution in a computationally efficient way. Theproposed cross-domain dictionary learning method is summarized in Algorithm 1.4.1.2 InitializationTo initialize Dt and Ds , we run the K-SVD algorithm severaltimes on both of them within each category, and then combineall K-SVD outputs in each respective domain. To initialize \u03d1and W , we employ the multivariate ridge regression model(Golub et al. 1999) with l2 -norm regularization as follows:\u03d1 = arg min \u0004Q \u2212 \u03d1 X t \u00042 + \u03d51 \u0004\u03d1\u000422 ,\u03d1W = arg min \u0004H \u2212 W X t \u00042 + \u03d52 \u0004W \u000422 ,(19)Wwhich yields the following solutions:\u03d1 = Q X tT (X t X tT + \u03d51 I )\u22121 ,W = H X tT (X t X tT + \u03d52 I )\u22121 ,where X t can be computed given the initialized Dt .(20)\fInt J Comput Vis (2014) 109:42\u20135949Input : Input signals Yt and Ys , discriminative sparse code Q,target domain class label H , sparsity constraintparameter T , balancing parameters \u03b1 and \u03b2, dictionarysize N and maximum iteration Max.iter .Output: Cross-domain dictionary pair D\u0303t and D\u0303s , transformationmatrixes A and \u03d1\u0303, and linear classifier parameter W\u0303 .12345678Compute A by combining each transformation matrix Ac for allC classes;Initialize Dt , Ds , \u03d1 and W ;\u239e\u239e\u239b\u239bYtDt\u239c Ys AT \u239f\u239c Ds \u239f\u239c\u221a \u239f\u221a \u239fReformulate Y = \u239c\u239d \u03b1 Q \u23a0 and D = \u239d \u03b1\u03d1 \u23a0;\u221a\u221a\u03b2W\u03b2HD 0 \u2190 D;for i \u2190 1 to Max.iter doSparse coding stage:Compute X t using OMP according to:E(x) = \u0004Y \u2212 D91011121314151617181920(i\u22121)X t \u000422 , s.t.\u2200i, \u0004xti \u00040\u2264 T,Dictionary updating stage:for k \u2190 1 to N dojCompute Sk = Y \u2212 j\b=k d j xt ;Discard all zero entries in xk and Sk , and obtain xk and Sk ;Apply a Singular Value Decomposition (SVD) operationon Sk :SV D( Sk ) = U V T ,dk \u2190 U (:, 1), xk \u2190 (1, 1)V (1, :)endD i \u2190 D updatedendDecompose D to obtain Ds , Dt , \u03d1 and W ;Compute D\u0303t , D\u0303s , \u03d1\u0303 and W\u0303 according to Equation (21).Algorithm 1: Weakly-Supervised Cross-Domain Dictionary Learning.tialize the dictionary with a few different random matrices in several runs. Such a strategy is applied in ourapproach.4.2 ClassificationSince Dt , Ds , \u03d1 and W are jointly normalized in the optimization procedure, they cannot be directly applied to construct the classification framework. Also, since W is obtainedwith the un-normalized D, simply re-normalizing D is notapplicable. According to the lemma in Zhang and Li (2010),D\u0303t , D\u0303s , \u03d1\u0303 and W\u0303 can be computed as:D\u0303t =dt1d2dK, 2t , . . . , Kt1\u0004dt \u00042 \u0004dt \u00042\u0004dt \u00042D\u0303s =ds1d2dK, 2s , . . . , Ks1\u0004ds \u00042 \u0004ds \u00042\u0004ds \u00042\u03d11\u03d12\u03d1K\u03d1\u0303 =,,...,\u0004\u03d1 1 \u00042 \u0004\u03d1 2 \u00042\u0004\u03d1 K \u00042W\u0303 =(21)w1w2wK,,...,\u0004w 1 \u00042 \u0004w 2 \u00042\u0004w K \u00042Given a target domain query sample yti , its sparse representation xti can be computed through ( D\u0303)t . With the linearclassifier f (x), the label l of yti can be predicted as:l = arg min(l j = W\u0303 xti ).j(22)5 Experiments5.1 Experimental Data Preparation4.1.3 Convergence AnalysisThe convergence proof of the proposed WSCDD methodcan be given similarly as the K-SVD algorithm (Aharonet al. 2006). At the dictionary updating stage, each dictionary element and its corresponding coefficients are updatedby minimizing quadratic functions, and the remaining dictionary elements are updated upon the previous updates.Consequently, the MSE of the overall reconstruction erroris monotonically decreasing with respect to the dictionaryupdating iterations. At the sparse coding stage, computation of the \u201cbest matched\u201d coefficients under the l0 -normconstraint also leads to a reduction in MSE conditionedon the success of the OMP algorithm. Finally, since MSEis non-negative, the optimization procedure is monotonically decreasing and bounded by zero from below, thusthe convergence of the proposed dictionary learning methodis guaranteed. The typical strategy to avoid the optimization procedure getting stuck in a local minimum is to ini-To demonstrate the effectiveness of the proposed method,we evaluate it on action recognition, image classificationand event recognition tasks. For event recognition and actionrecognition, the source domain data are obtained from anexisting dataset or selected categories of an existing dataset.For image classification, the source domains are constructedby choosing 20 image categories (chosen according to theascending alphabetic order) and use the first 100 resultsreturned from Google Image Search for each chosen categoryas the source domain data, where the indexing procedure isperformed by simply searching the category names. Since theretrieved images are very noisy, we apply the manifold ranking (Zhou et al. 2004a,b) algorithm as a pre-processing stagefor the source domain data. As the source domain data areweakly labeled, we allow 5 samples per category as labeledin the source domain. The average ranking scores of the unlabeled source domain data are obtained by treating both thetarget domain data and the labeled source domain data asqueries, and rank the unlabeled source domain data. We keep123\f50Int J Comput Vis (2014) 109:42\u201359Fig. 4 Example images fromvideo sequences in the UCFYouTube datasetthe first 20\u221230 % instances from the ranked source domaindata for each image category, and filter out the remainingretrieved data. The same ranking procedure is applied to theaction recognition and the event recognition task, where wekeep the most highly ranked 30 instances from the sourcedomain dataset for the former, and the most highly ranked80 % instances from the source domain dataset for the latter.We denote both scenarios of the proposed WSCDDL methodwhen manifold ranking is utilized or not as WSCDDLMR and WSCDDL-EU respectively in image classification,action recognition and event recognition experiments.5.2 Action RecognitionThe UCF YouTube dataset and the HMDB51 dataset areused for the action recognition task, where the UCF YouTubedataset is used as the target domain and the HMDB51 datasetis used as the source domain. The UCF YouTube dataset(shown in Fig. 4) is a realistic dataset that contains camerashaking, cluttered background, variations in actors\u2019 scale,variations in illumination and view point changes. There are11 actions including cycling, diving, golf swinging, soccerjuggling, jumping, horse-back riding, basketball shooting,volleyball spiking, swinging, tennis swinging and walkingwith a dog, and these actions are performed by 25 actors.The HMDB51 dataset (shown in Fig. 5) contains videosequences which are extracted from commercial movies aswell as YouTube, and it represents a fine multifariousness oflight conditions, situations and surroundings in which actionscan appear, different recording camera types and viewpointchanges. Since the HMDB51 dataset is a more challeng-123ing dataset, our case closely resembles real-world scenarios,where the source domain data can contain a wide range ofnoise levels. In correspondence with the target domain actioncategories, we choose 7 body movements from the HMDB51dataset, including ride bike, dive, golf, jump, kick ball, ridehorse and shoot ball.We adopt the dense trajectories (Wang et al. 2011) asthe low-level action video representation to distinguish themotion of interest. To leverage the motion information inthe dense trajectories, a set of local descriptors are computed within space-time volumes around the trajectoriesat multiple spatial and temporal scales, and these featuresinclude the HOGHOF (Laptev et al. 2008), the optical flow(Ikizler-Cinbis and Sclaroff 2010) and the Motion Boundary Histogram (MBH) (Dalal et al. 2006). Specifically, theHOGHOF feature is a combination of appearance information (captured by HOG Dalal and Triggs 2005) and localmotion probabilities (captured by Histogram of Optical Flow(HOF)). Since motion is the most important cue for analyzing actions, the optical flow works effectively by computing the relative motion between the observer and the scene.MBH represents the gradient of the optical flow by separately computing the derivatives for the horizontal and vertical components of the optical flow, so that relative motionbetween pixels is encoded. Changes in the optical flow fieldbeing preserved and constant motion information being suppressed, the MBH descriptor can effectively eliminate noisecaused by background motion compared with video stabilization (Ikizler-Cinbis and Sclaroff 2010) and motion compensation (Uemura et al. 2008) approaches (Wang et al. 2011).Despite its powerful capability of describing action motions,\fInt J Comput Vis (2014) 109:42\u20135951Fig. 5 Example images fromvideo sequences in the selectedbody movements of theHMDB51 datasetthe dense trajectories come with two weaknesses: (1) trajectories tend to drift from their initial locations during motiontracking, which is a common problem in tracking; (2) thelarge quantity of local trajectory descriptors leads to highcomputational complexity and memory consumption for thecoding methods, such as VQ and SC. To cope with the firstissue, the length of a trajectory is limited to a pre-definednumber of frames. Taking the second issue into account,a Locality-constrained Linear Coding (LLC) (Wang et al.2010) scheme is adopted instead of VQ and SC. LLC represents the low-level dense trajectories by multiple bases.In addition to achieving less quantization error, the explicitlocality adaptor in LLC guarantees the local smooth sparsity.Dense trajectories are extracted from raw action video\u221asequences with 8 spatial scales spaced by a factor of 1/ 2,and feature points are sampled on a grid spaced by 5 pixelsand tracked in each scale, separately. Each point at frame tis tracked to the next frame t + 1 by median filtering in adense optical flow field. To avoid the drifting problem, thelength of a trajectory is limited to 15 frames. HOGHOF andMBH are computed within a 32 \u00d7 32 \u00d7 15 volume along thedense trajectories, where each volume is sub-divided into aspatio-temporal grid of size 2 \u00d7 2 \u00d7 3 to impose more structural information in the representation. Considering both efficiency and the construction error, LLC coding scheme isapplied to the low-level local dense trajectories features with30 local bases, and the codebook size is set to be 4,000 forall training-testing partitions. To reduce the complexity, only200 local dense trajectories features are randomly selectedfrom each video sequence when constructing the codebook.We run our method on five different partitions of the UCFYouTube dataset, where we randomly choose all action categories performed by the number of 5/9/16/20/24 actors asthe training actions while using the remaining actions as thetesting actions for each partition. 30 most relevant actions arechosen from each of the 7 source domain categories usingmanifold ranking, and they are represented in the same manner as the target domain actions and coded with the samecodebook. The weight \u03b1 on the label constraint term and theweight \u03b2 on the classification error term are set as 4 and2 respectively, and 50 iterations of SVD decomposition areexecuted during optimization (We use the same values of \u03b1,\u03b2 and K-SVD maximum iteration for the image classification and event recognition tasks). To avoid over-fitting, thedictionary size is set to be larger when more training dataare available at the training stage. The results are demonstrated in Table 1 for all five partitions, where we use the sizeof 200, 300, 500, 700 and 900 for each partition. We compare the performance of the baseline LLC, sparse codingmethods K-SVD (Aharon et al. 2006) and LC-SVD (Jiang etal. 2011), and transfer learning methods FR (Daum\u00e9 2007)and A-SVM (Yang et al. 2007) with the proposed WSCDDLmethod. Results are reported on both scenarios where thesource domain data are included or excluded in Tables 1 and2 respectively. Comparing Tables 1 and 2, we can discoverthat for many cases, brute-forcing the knowledge from the123\f52Int J Comput Vis (2014) 109:42\u201359Table 1 Performancecomparison between theWSCDDL and other methods onthe UCF YouTube dataset whenthe source domain data are onlyused by the WSCDDLAlgorithmLLC (Wang K-SVD (Aharon LC-KSVD (Jiang WSCDDLet al. 2010) et al. 2006)et al. 2011)EUWSCDDL-MRDictionary learningN/ASupervisedUnsupervisedSupervisedSupervisedSource dataNoNoNoYesYes24 actors (%)86.6782.2286.6788.8991.1120 actors (%)75.4268.7575.4277.5078.3016 actors (%)70.8863.9672.0873.0373.0309 actors (%)61.4155.7065.2566.3166.0505 actors (%)54.1050.0556.5556.6657.19Best results are in boldTable 2 Recognition results on the UCF YouTube dataset when using the HMDB dataset as the source domainAlgorithmLLC (Wanget al. 2010)K-SVD (Aharonet al. 2006)LC-KSVD (Jianget al. 2011)FR (Daum\u00e92007)A-SVM (Yang etal. 2007)WSCDDL-EUWSCDDL-MRDictionary learningN/AUnsupervisedSupervisedSupervisedSupervisedSupervisedSupervisedSource dataYesYesYesYesYesYesYes24 actors (%)86.6777.7882.2283.7482.5188.8991.1120 actors (%)70.2172.0875.4274.8879.0577.5078.3016 actors (%)70.1767.5472.0871.5672.4673.0373.0309 actors (%)61.8059.1564.7262.7761.6566.3166.0505 actors (%)53.3548.8854.1054.0951.5456.6657.19Best results are in boldTable 3 Performance comparison of the WSCDDL with state-of-the-art methods under the leave-one-actor-out setting on the UCF YouTube datasetMethodsLiu et al. (2009)Ikizler-Cinbis and Sclaroff (2010)BoFWSCDDL-EUWSCDDL-MRResults (%)71.275.2180.0281.1382.32Best result is in boldsource domain into the target domain irrespective of theirdivergence can cause certain performance degeneration. Onthe other hand, the proposed WSCDDL method consistentlyleads to the best performance over all the partitions. Figure 7shows the convergence analysis and performance of varying dictionary size of the WSCDDL-MR method. Figure 10shows the confusion matrix comparisons between the LLCmethod and the WSCDDL-MR method for all five partitions.In order to compare the WSCDDL method with state-of-theart methods, we further demonstrate its performance underthe leave-one-actor-out setting in Table 3.5.3 Image ClassificationWe utilize the Caltech101 dataset as the target domain andsome collected Web images as the source domain for theimage classification task. The Caltech101 image dataset(shown in Fig. 6) consists of 101 categories (e.g., accordion, cannon, and chair), and each category contains 30\u2013800images. The source domain data of the Caltech101 datasetare constructed by a set of images returned by Google ImageSearch (shown in Fig. 6) (Fig. 7).123For image representations, we choose the dense SIFT(Lowe et al. 2004) plus LLC (Wang et al. 2010) model. TheSIFT descriptors are extracted from 16 \u00d7 16 pixel patchesand densely sampled from each image on a grid with the stepsize of 8 pixels. We evaluate our method with both dictionary sizes 1024 and 4096. The same values of the weights\u03b1, \u03b2 and K-SVD iterations are adopted as in the actionrecognition task. We compare the performance of the proposed WSCDDL approach and state-of-the-art approachesin Table 4. Results on six different numbers of training dataare reported, and all the results are averaged over 5 timesof different randomly selected training and testing imagesto guarantee the reliability. For the LLC (Wang et al. 2010),K-SVD (Aharon et al. 2006) and LC-SVD (Jiang et al. 2011)methods, we consider both scenarios of whether the sourcedomain data are included. For fair comparisons, we chooseboth dictionary size 1,024 and 4,096 to test the proposedmethod. Figure 6 shows samples of 6 categories with highclassification accuracies when using 30 training images percategory. As shown in Fig. 8, the proposed WSCDDL methodresults in larger improvements over others when fewer samples are used for training, which demonstrates its effective-\fInt J Comput Vis (2014) 109:42\u20135953Fig. 6 Example images from classes with high classification accuracy from the Caltech101 datasetFig. 7 Performance analysis on the UCF YouTube dataset when actions performed by 24 actors are used in the training data. a The optimizationprocess of the objective function for WSCDDL-MR with 50 iterations. b Performance when varying the dictionary sizeness in terms of utilizing the source domain data. Figure 9demonstrates the performance of all the 101 image categories(Fig. 10).We further evaluate our method on the more challenging Caltech 256 dataset (Griffin et al. 2007), which contains 30,607 images of 256 categories. Compared to the Caltech101 dataset, it is much more difficult due to the largevariations on object location, pose, and size. Similar as thestrategy adopted in constructing the source domain for theCaltech101 dataset, 400 images from 20 categories indexedby Google Images are used as the source domain. We evaluateour approach on both 15 and 30 training images per class,and set the dictionary size to 1,024 or 4,096 respectively.We compare our method with state-of-the-art approaches as123\f54Table 4 Comparison with thestate-of-the-art methods on theCaltech101 datasetBest results are in boldInt J Comput Vis (2014) 109:42\u201359Number of training samples5 (%)10 (%)15 (%)20 (%)25 (%)30 (%)Malik (Zhang et al. 2006)46.655.859.162.0\u221266.2Griffin (Griffin et al. 2007)44.254.559.063.365.867.6SRC (Wright et al. 2009)48.860.164.967.769.270.7LLC (Wang et al. 2010)51.1559.7765.4367.7470.1673.44LLC (Wang et al. 2010) (source)21.4336.3751.1160.0267.5572.17K-SVD (Aharon et al. 2006)39.6350.3058.8264.7367.9271.0466.07K-SVD (Aharon et al. 2006) (source)20.4235.6444.9353.6960.07LC-KSVD (Jiang et al. 2011)46.2557.7368.4570.7972.8373.75LC-KSVD (Jiang et al. 2011) (source)48.9562.7167.1470.1773.3975.05WSCDDL-EU (N = 1,024)60.6267.8170.0972.9876.1777.30WSCDDL-MR (N = 1,024)61.3168.6971.5974.7376.8278.44CRBM (Sohn et al 2011) (N = 4,096)56.766.771.374.276.277.8WSCDDL-EU (N = 4,096)63.4768.9070.8874.0177.5478.68WSCDDL-MR (N = 4,096)64.0569.3172.3975.2278.4079.02Fig. 8 Performance analysis on the Caltech101 dataset. a The optimization process of the objective function for WSCDDL-MR with 50iterations. b Means and standard deviations of different methods whenthe number of training samples per class varies from 5 to 30 (The dictionary size of WSCDDL-MR is set to 1,024)Fig. 9 Performance on all the categories of the Caltech101 dataset achieved by the WSCDDL-MR (The dictionary size of WSCDDL-MR is setto 1,024) method when using 30 training images per category123\fInt J Comput Vis (2014) 109:42\u20135955Fig. 10 Comparison of theconfusion matrixes between thebaseline ScSPM and theWSCDDL on five different datapartitions of the UCF YouTubedataset123\f56Int J Comput Vis (2014) 109:42\u201359Table 5 Recognition results on the Caltech256 datasetNumber of training samples15 (%)30 (%)Griffin et al. (2007)28.334.10Yang et al. (2009)27.7334.02K-SVD (Aharon et al. 2006)25.3330.62SRC (Wright et al. 2009)27.8633.33WSCDDL-EU (N = 1,024)29.6835.78WSCDDL-MR (N = 1,024)31.8936.86LLC (Wang et al. 2010) (N = 4,096)34.3641.19CRBM (Sohn et al 2011) (N = 4,096)35.0942.05WSCDDL-EU (N = 4,096)36.2142.33WSCDDL-MR (N = 4,096)37.4242.80Best results are in boldshown in Table 5, where our approach consistently leads tothe best performance. Figure 11 shows samples from 5 categories with high classification accuracies when using 30images per category.5.4 Event RecognitionWe compare our proposed method WSCDDL with stateof-the-art transfer learning methods on the event recognition task using the Kodak Consumer Videos and a set ofadditional videos. The Kodak consumer video benchmarkdataset was collected by Kodak from about 100 real usersover the period of one year, and it includes two video subsets from two different sources, where the first part containsKodak\u2019s video data which includes 1,358 video clips contributed by involved users and the second part contains 1,873clips downloaded from the YouTube website after removingTV commercial videos and low-quality videos. Similarly,the additional videos collected by Duan et al. (2012b) contain two parts, which are the self-collected consumer videosand downloaded YouTube videos. To resemble the real-worldscenario, the downloaded YouTube videos are not additionally annotated so that they can remain in a loosely labeledsetting. Thus, only the self-collected consumer videos fromthe dataset used in Duan et al. (2012b) possess precise labels.The total numbers of consumer videos and YouTube videosare 195 and 906, respectively, and each video belongs toonly one event category. Following the settings in Duan et al.(2012b), six events, namely \u201cbirthday\u201d, \u201cpicnic\u201d, \u201cparade\u201d,\u201cshow\u201d, \u201csports\u201d and \u201cwedding\u201d are chosen for experiments.The target domain is constructed using both the consumervideos from the Kodak dataset and additional self-collectedconsumer videos in Duan et al. (2012b). On the other hand,the second part of the Kodak dataset and the loosely labeledYouTube videos used in Duan et al. (2012b) constitute thesource domain. In the target domain, three consumer videosfrom each event (18 videos in total) are randomly chosenas the labeled training videos and the remaining videos areFig. 11 Example images of the categories with high classification accuracy from the Caltech256 dataset123\f62.60 \u00b1 1.7661.92 \u00b1 2.8958.20 \u00b1 1.8735.34 \u00b1 1.5546.92 \u00b1 2.5324.95 \u00b1 1.2532.40 \u00b1 4.9953.78 \u00b1 2.9958.42 \u00b1 2.2557.18 \u00b1 0.8437.80 \u00b1 1.7737.24 \u00b1 1.5847.14 \u00b1 2.3447.19 \u00b1 2.5938.42 \u00b1 7.9331.07 \u00b1 2.60MKL (Duan etal. 2009)A-SVM (Yanget al. 2007)52.36 \u00b1 1.8839.11 \u00b1 2.7657used as the test data. In order to set up a fair comparisonin correspondence with the experimental results in Duanet al. (2012b), we use the same low-level features, whichare SIFT features and ST features. For each sampled frame,which is sampled at the sampling rate of 2 frames per second, the 128-dimensional SIFT features are extracted fromthe salient regions, which are detected by the Difference-ofGaussians (DoG) interest point detector (Lowe et al. 2004).The 162-dimensional local ST feature is the concatenationof the 72-dimensional HOG feature and the 90-dimensionalHOF feature. We also conduct experiments in the same threecases as in Duan et al. (2012b): (a) dictionaries and classifiers are learned based on SIFT features, (b) dictionaries andclassifiers are learned based on ST features and (c) dictionaries and classifiers are learned on both SIFT and ST features. Based on the same experimental settings as in Duan etal. (2012b), we compare our method WSCDDL with SVMAT, SVM-T, FR (Daum\u00e9 2007), A-SVM (Yang et al. 2007),MKL (Duan et al. 2009), DTSVM (Duan et al. 2009) andA-MKL (Duan et al. 2012b), where SVM-AT denotes thecase that labeled training samples are obtained from both thetarget domain and the source domain, and correspondinglySVM-T denotes the case that labeled training samples areonly obtained from the target domain. Table 6 demonstratesthe recognition results of the proposed WSCDDL methodand other cross-domain methods. We can observe that SVMT consistently outperforms SVM-AT in both scenarios of(b) and (c), which indicates that brutally including the STfeatures of source domain videos may degrade the recognition performance. The proposed WSCDDL method consistently outperforms other cross-domain methods in all threecases.36.23 \u00b1 3.3742.00 \u00b1 4.94(c)44.11 \u00b1 3.5724.73 \u00b1 2.2232.56 \u00b1 2.08(b)28.44 \u00b1 2.6153.93 \u00b1 5.5842.32 \u00b1 5.50(a)49.98 \u00b1 5.63SVM-ATFR (Daum\u00e92007)6 ConclusionSVM-TTable 6 Comparison with the state-of-the-art methods on the Kodak and YouTube datasetDTSVM (Duanet al. 2009)A-MKL (Duanet al. 2012b)WSCDDL-EuWSCDDL-MRInt J Comput Vis (2014) 109:42\u201359In this paper, we have presented a novel visual categorization framework using the weakly-supervised cross-domaindictionary learning algorithm. Auxiliary domain knowledgeis utilized to span the intra-class diversities, so that the overall performance of the original system can be improved. Theproposed framework only requires a small set of labeledsamples in the source domain. By means of a transformation matrix, dictionary learning is performed on both thesource domain data and the target domain data while nocorrespondence annotations between the two domains arerequired. Promising results are achieved on action recognition, image classification and event recognition tasks, whereknowledge from either the Web or a related dataset istransferred to standard benchmark datasets. The proposedframework leads to an interesting topic for future investigation when large scale source and target domain data areavailable.123\f58ReferencesAharon, M., Elad, M., & Bruckstein, A. (2006). K-SVD: An algorithmfor designing overcomplete dictionaries for sparse representation.IEEE Transaction on Signal Processing, 54(11), 4311\u20134322.Borgwardt, K. M., Gretton, A., Rasch, M. J., Kriegel, H. P., Sch\u00f6lkopf,B., & Smola, A. J. (2006). Integrating structured biological databy kernel maximum mean discrepancy. Bioinformatices, 22, e49\u2013e57.Boureau, Y., Bach, F., LeCun, Y., & Ponce, J. (2010). Learning midlevel features for recognition. CVPR.Cao, L., Liu, Z., & Huang, T. S. (2010). Cross-dataset action detection.CVPR.Cao, X., Wang, Z., Yan, P., & Li, X. (2013). Transfer learning for pedestrian detection. Neurocomputing, 100, 51\u201357.Chen, S. S., Donoho, L. D., & Saunders, A. M. (1993). Atomic decomposition by basis pursuit. IEEE Transaction on Signal Processing,41(12), 3397\u20133415.Dalal, N., & Triggs, B. (2005). Histograms of oriented gradients forhuman detection. CVPR.Dalal, N., Triggs, B., & Schmid, C. (2006). Human detection usingoriented histograms of flow and appearance. ECCV.Daum\u00e9 III, Hal, Frustratingly easy domain adaptation, Proceedings ofthe Annual Meeting Association for Computational Linguistics, pp.256\u2013263 (2007).Dikmen, M., Ning, H., Lin, D. J., Cao, L., Le, V., Tsai, S. F., et al.(2008). Surveillance event detection. TRECVID Video EvaluationWorkshop.Doll\u00e1r, P., Rabaud, V., Cottrell, G., & Belongie, S. (2005). Behaviorrecognition via sparse spatio-temporal features, IEEE InternationalWorkshop on Visual Surveillance and Performance Evaluation ofTracking and Surveillance, pp. 65\u201372 .Duan, L., Tsang, I. W., & Xu, D. (2012). Domain transfer multiplekernel learning. IEEE Transaction on Pattern Analysis and MachineIntelligence, 34, 465\u2013479.Duan, L., Tsang, I. W., Xu, D., & Maybank, J. S. (2009). Domaintransfer svm for video concept detection. CVPR.Duan, L., Xu, D., Tsang, I. W., & Luo, J. (2012). Visual event recognitionin videos by learning from web data. IEEE Transaction on PatternAnalysis and Machine Intelligence, 34, 1667\u20131680.Duchenne, O., Laptev, I., Sivic, J., Bach, F., & Ponce, J. (2009). Automatic annotation of human actions in video. ICCV.Fei-Fei, L. (2006). Knowledge transfer in learning to recognize visualobjects classes. ICDL.Fei-Fei, L., Fergus, R., & Perona, P. (2007). Learning generativevisual models from few training examples. An incremental bayesianapproach tested on 101 object categories. Computer Vision andImage Understanding, 106, 59\u201370.Gao, X., Wang, X., Li, X., & Tao, D. (2011). Transfer latent variablemodel based on divergence analysis. Pattern Recognition, 44, 2358\u20132366.Gilbert, A., Illingworth, J., & Bowden, R. (2011). Action recognitionusing mined hierarchical compound features. IEEE Transaction onPattern Analysis and Machine Intelligence, 33, 883\u2013897.Golub, G., Hansen, P., & O\u2019Leary, D. (1999). Tikhonov regularizationand total least squares. Journal on Matrix Analysis and Applications,21(1), 185\u2013194.Gregor, K., & LeCun, Y. (2010). ICML: Learning fast approximationsof sparse coding. New York: Saunders.Griffin, G., Holub, A., & Perona, P. (2007). Caltech-256 object categorydataset, CIT Technical Report 1694.Ikizler-Cinbis, N., Sclaroff, S. (2010). Object, scene and actions: Combining multiple features for human action recognition. ECCV.J\u00e9gou, H., Douze, M., & Schmid, C. (2010). Improving bag-of-featuresfor large scale image search. International Journal of ComputerVision, 87, 316\u2013336.123Int J Comput Vis (2014) 109:42\u201359Ji, S., Xu, W., Yang, M., & Yu, K. (2013). 3D convolutional neuralnetworks for human action recognition. IEEE Transaction on PatternAnalysis and Machine Intelligence, 35, 221\u2013231.Jiang, Z., Lin, Z., & Davis, L. S. (2011) Learning a discriminativedictionary for sparse coding via label consistent K-SVD. CVPR.Junejo, I. N., Dexter, E., Laptev, I., & P\u00e9rez, P. (2011). Viewindependent action recognition from temporal self-similarities. IEEETransaction on Pattern Analysis and Machine Intelligence, 33, 172\u2013185.Kuehne, H., Jhuang, H., Garrote, E., Poggio, & T., Serre, T. (2011).HMDB: A large video database for human motion recognition.ICCV.Kullback, S. (1987). The kullback-leibler distance. The American Statistician, 41, 340\u2013341.Laptev, I., Marszalek, M., Schmid, C., & Rozenfeld, B. (2008). Learningrealistic human actions from movies. CVPR.Laptev, I. (2005). On space-time interest points. Internation Journal ofComputer Vision, 64, 107\u2013123.Lazebnik, S., Schmid, C., & Ponce, J. (2006) Beyond bags of features:Spatial pyramid matching for recognizing natural scene categories.CVPR.Lee, H., Battle, A., Raina, R., & Andrew, Ng. (2007). Efficient sparsecoding algorithms. NIPS.Lee, H., Battle, A., Raina, R., & Ng, A. (2006). Efficient sparse codingalgorithms. NIPS.Li, R., & Zickler, T. (2012). Discriminative virtual views for cross-viewaction recognition. CVPR.Liu, J., Luo, J., & Shah, M. (2009). Recognizing realistic actions fromvideos \u201cin the wild\u201d. CVPR.Liu, J., Shah, M., Kuipers, B., & Savarese, S. (2011). Cross-view actionrecognition via view knowledge transfer. CVPR.Liu, L., Shao, L., & Rockett, P. (2012). Boosted key-frame selectionand correlated pyramidal motion-feature representation for humanaction recognition. Pattern Recognition. doi:10.1016/j.patcog.2012.10.004.Liwicki, S., Zafeiriou, S., Tzimiropoulos, G., & Pantic, M. (2012). Efficient online subspace learning with an indefinite kernel for visualtracking and recognition. IEEE Transaction on Neural Networks andLearning Systems, 23, 1624\u20131636.Loui, A., Luo, J., Chang, S., Ellis, D., Jiang, W., Kennedy, l., Lee, K.,& Yanagawa, K. (2007). Kodak\u2019s consumer video benchmark dataset: concept definition and annotation. IWMIR.Lowe, D. (2004). Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision, 60, 91\u2013110.Lowe, D. G., Luo, J., Chang, S. F., Ellis, D., Jiang, W., Kennedy, L., etal. (2004). Distinctive image features from scale-invariant keypoints.International Journal of Computer Vision, 60(2), 91\u2013110.Mairal, J., Bach, F., Ponce, J., Sapiro, G,. & Zisserman, A. (2008).Discriminative learned dictionaries for local image analysis. CVPR.Mairal, J., Bach, F., Ponce, J., Sapiro, G., & Zisserman, A. (2009).Supervised dictionary learning. NIPS.Mairal, J., Leordeanu, M., Bach, F., Hebert, M., & Ponce, J. (2008)Discriminative sparse image models for class-specific edge detectionand image interpretation. ECCV.Maji, S., Berg, A., & Malik, J. (2013). Efficient classification for additiveKernel SVMs. IEEE Transaction on Pattern Analysis and MachineIntelligence, 35, 66\u201377.Mallat, S. G., & Zhang, Z. (1993). Matching pursuits with timefrequency dictionaries. IEEE Transaction on Signal Processing,41(12), 3397\u20133415.Marszalek, M., Laptev, I., & Schmid, C. (2009). Actions in context.CVPR.Orrite, C., Rodr\u00edguez, M., & Monta\u00f1\u00e9s, M. (2011). One-sequence learning of human actions. Human Behavior Unterstanding, 7065, 40\u201351.Pan, S. J., & Yang, Q. (2010). A survey on transfer learning. IEEETransaction on Knowledge and Data Engineering, 22, 1345\u20131359.\fInt J Comput Vis (2014) 109:42\u201359Pati, Y., & Ramin, R. (1993). Orthogonal matching pursuit: Recursivefunction approximation with applications to wavelet decomposition.Asilomar Conference on Signals, Systems and Computers, 4, 40\u201344.Qiu, Q., Patel, V. M., Turaga, P., & Chellappa, R. (2012). Domain adaptive dictionary learning. ECCV.Raina, R., Battle, A., Lee, H., Packer, B., & Ng, A. Y. (2007). Self-taughtlearning: Transfer learning from unlabeled data. ICML.Schuldt, C., Laptev, I., & Caputo, B. (2004). Recognizing humanactions: A local svm approach. ICPR.Sidenblada, H., & Black, M. J. (2003). Learning the statistics of peoplein images and video. International Journal of Computer Vision, 54,183\u2013209.Sohn, K., Jung, D., Lee, H., & Hero, A. (2011) Efficient learning ofsparse, distributed, convolutional feature representations for objectrecognition. ICCV.Su, Y., & Jurie, F. (2012). Improving image classification using semanticattributes. International Journal of Computer Vision, 100, 1\u201319.Uemura, H., Ishikawa, S., Mikolajczyk, K. (2008). Feature tracking andmotion compensation for action recognition. BMVC.Wang, H., Klaser, A., Schmid, C., Liu, C. (2011). Action recognitionby dense trajectories. CVPR.Wang, H., Ullah, M., Klaser, A., Laptev, I., Schmid, C. (2009). Evaluation of local spatio-temporal features for action recognition. BMVC.Wang, J., Yang, J., Yu, K., Lv, F., huang, T., Gong, Y. (2010). Localityconstrained linear coding for image classification. CVPR.Wang, Y., & Mori, G. (2009). Max-margin hidden conditional randomfields for human action recognition. CVPR.Wang, Y., & Mori, G. (2011). Hidden part models for human actionrecognition: Probabilistic versus max margin. IEEE Transaction onPattern Analysis and Machine Intelligence, 33, 1310\u20131323.Wright, J., Yang, Y. A., Ganesh, A., Sastry, S. S., & Ma, Y. (2009).IEEE Transaction on Pattern Analysis and Machine Intelligence,31, 210\u2013227.Xiang, S., Nie, F., Meng, G., Pan, C., & Zhang, C. (2012). Discriminative least squares regression for multiclass classification and featureselection. IEEE Transaction on Neural Networks and Learning Systems, 23, 1738\u20131754.59Yang, L., Jin, R., Sukthankar, R., & Jurie, F. (2008). Unifying discriminative visual codebook generation with classifier training for objectcategory recognition. CVPR.Yang, J., Yan, R., & Hauptmann, A. G. (2007). Cross-domain videoconcept detection using adaptive SVMs. ACM MM.Yang, J., Yu, K., Gong, Y., Huang, T. (2009). Linear spatial pyramidmatching using sparse coding for image classification. CVPR.Yang, J., Yu, K., & Huang, T. (2010). Supervised translation-invariantsparse coding. CVPR.Yao, A., Gall, J., & Van, L. G. (2012). Coupled action recognitionand pose estimation from multiple views. International Journal ofComputer Vision, 100, 16\u201337.Zafeiriou, S., Tzimiropoulos, G., Petrou, M., & Stathaki, T. (2012) Regularized kernel discriminant analysis with a robust kernel for facerecognition and verification. NIPS.Zhang, H., Berg, C. A., Maire, M., & Malik, J. (2006) SVM-KNN:Discriminative nearest neighbor classification for visual categoryrecognition. CVPR.Zhang, Q., & Li, B. (2010). Discriminative K-SVD for dictionary learning in face recognition. CVPR.Zhang, W., Surve, A., Fern, X., & Dietterich, T. (2009). Learning nonredundant codebooks for classifying complex objects. ICML.Zheng, J., Jinag, Z., Phillips,P. J., & Chellappa, R. (2012) Cross-viewaction recognition via a transferable dictionary pair. BMVC.Zhou, D., Bousquet, O., Lal, T., Weston, J., Gretton, A., & Sch\u00f6lkopf,B. (2004). Learning with local and global consistency. NIPS.Zhou, M., Chen, H., Paisley, J., Ren, L., Sapiro, G., & Carin, L. (2009).Non-parametric bayesian dictionary learning for sparse image representations. NIPS.Zhou, D., Weston, J., Gretton, A., Bousquet, O., & Sch\u00f6lkopf, B. (2004).Ranking on data manifolds. NIPS.Zhu, F., & Shao, L. (2013). Enhancing action recognition by crossdomain dictionary learning. BMVC.123\f", "770IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 32, NO. 5,MAY 2010Domain Adaptation Problems:A DASVM Classification Techniqueand a Circular Validation StrategyLorenzo Bruzzone, Fellow, IEEE, and Mattia Marconcini, Member, IEEEABSTRACT\u2014This paper addresses pattern classification in the framework of domain adaptation by considering methods that solveproblems in which training data are assumed to be available only for a source domain different (even if related) from the target domainof (unlabeled) test data. Two main novel contributions are proposed: 1) a domain adaptation support vector machine (DASVM)technique which extends the formulation of support vector machines (SVMs) to the domain adaptation framework and 2) a circularindirect accuracy assessment strategy for validating the learning of domain adaptation classifiers when no true labels for thetarget-domain instances are available. Experimental results, obtained on a series of two-dimensional toy problems and on two realdata sets related to brain computer interface and remote sensing applications, confirmed the effectiveness and the reliability of both theDASVM technique and the proposed circular validation strategy.Index Terms\u2014Domain adaptation, transfer learning, semi-supervised learning, support vector machines, accuracy assessment,validation strategy.\u00c71INTRODUCTIONTHEcomplexity of pattern classification problems depends on both the investigated application and theavailable prior information. Two main families of learningmethods can be used for training a classifier: supervisedlearning methods (when labeled training samples are given)or unsupervised learning methods (when labeled trainingsamples are not available). Let us define a domain D as adistribution P \u00f0x; y\u00de, x 2 X~, y 2 \u0002, which governs theclassification problem under investigation, where X~ and\u0002 represent all possible instances and all possibleinformation classes for the considered problem, respectively. In the supervised learning setting, classificationalgorithms are designed under the hypothesis that thedistribution P^\u00f0x; y\u00de estimated from available labeledtraining data T \u00bc f\u00f0xi ; yi \u00degi , xi 2 X \u0002 X~, yi 2 \u0002 drawnfrom D well approximates P \u00f0x; y\u00de. Hence, it is possible toobtain high classification accuracies over unseen test datadrawn from the same domain. In the unsupervisedlearning setting, no training data are available. Thus, theproblem can be addressed only through clustering methods. However, in many operational applications, there arehybrid situations where, even if prior information isavailable, it is not sufficient to define a training setrepresentative of the distribution to which the trainedmodel should be applied. These kinds of problems can beaddressed according to transfer learning methods.. The authors are with the Department of Information Engineering andComputer Science, University of Trento, 38050, Povo, Trento, Italy.E-mail: lorenzo.bruzzone@ing.unitn.it, mattia.marconcini@gmail.com.Manuscript received 16 Jan. 2008; revised 19 Feb. 2009; accepted 2 Mar. 2009;published online 10 Mar. 2009.Recommended for acceptance by A. Smola.For information on obtaining reprints of this article, please send e-mail to:tpami@computer.org, and reference IEEECS Log NumberTPAMI-2008-01-0033.Digital Object Identifier no. 10.1109/TPAMI.2009.57.0162-8828/10/$26.00 \u00df 2010 IEEETransfer learning refers to the problem of retaining andapplying the knowledge available for one or more tasks,domains, or distributions to efficiently develop an effectivehypothesis for a new task, domain, or distribution. Insteadof involving generalization across problem instances,transfer learning emphasizes the transfer of knowledgeacross tasks, domains, and distributions that are similar butnot the same. When the objective is to transfer knowledgeacross different tasks, this results in the multitask learningsubproblem. Multitask learning methods aim at improvingthe generalization capability by exploiting the informationcontained in training data available for the considered tasks(where the set of considered information classes is allowedto vary). In particular, what is learned for each task is usedas a bias for other tasks in order to improve theclassification performances [1], [2], [3]. In the single-taskframework, the default assumption of supervised learningmethods is that training and test data are drawn from thesame distribution. When the two distributions do notmatch, two distinct transfer learning subproblems can bedefined depending on whether training and test data referto the same domain or not: 1) learning under sample selectionbias and 2) learning under domain adaptation.In the case of sample selection bias, unlabeled test data aredrawn from the same domain D of training data, but theestimated distribution P^\u00f0x; y\u00de \u00bc P^\u00f0x\u00deP^\u00f0y j x\u00de does notcorrectly model the true underlying distribution thatgoverns D since the number (or the quality) of availabletraining samples is not sufficient for an adequate learning ofthe classifier. The small amount of labeled data generallyleads to a poor estimation P^\u00f0x\u00de of the prior distributionP \u00f0x\u00de (i.e., P^\u00f0x\u00de 6\u00bc P \u00f0x\u00de). Moreover, if the few availabletraining data do not represent the general target populationand introduce a bias in the estimated class prior distribution(i.e., P^\u00f0y\u00de 6\u00bc P \u00f0y\u00de), this may cause a poor estimation of thePublished by the IEEE Computer Society\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...771TABLE 1Taxonomy of Learning Types and Problems(X~ and \u0002 Represent All Possible Instances and All Possible Information Classes, Respectively, for the Considered Problem)conditional distribution (i.e., P^\u00f0y j x\u00de 6\u00bc P \u00f0y j x\u00de). On onehand, if both P^\u00f0x\u00de 6\u00bc P \u00f0x\u00de and P^\u00f0y j x\u00de 6\u00bc P \u00f0y j x\u00de, theproblem is referred to as sample selection bias [4], [5], [6].On the other hand, the particular case where the true andestimated distributions are assumed to differ only viaP^\u00f0x\u00de 6\u00bc P \u00f0x\u00de, but P^\u00f0y j x\u00de \u0003 P \u00f0y j x\u00de is denoted by covariateshift [7], [8].In the case of domain adaptation, unlabeled test patternsX t \u00bc fxti gi , X t \u0002 X~, are drawn from a target domain Dtdifferent from the source domain Ds of training samplesT s \u00bc f\u00f0xsi ; ysi \u00degi , xsi 2 X s \u0002 X~, ysi 2 \u0002. This may happen whenthe available labeled data are out of date, whereas the test dataare obtained from fast evolving information sources, or whenseries of data acquired at different times should be classified,but training samples collected only at one time are available.In this context, let P s \u00f0x; y\u00de \u00bc P s \u00f0y j x\u00de \u0004 P s \u00f0x\u00de and P t \u00f0x; y\u00de \u00bcP t \u00f0y j x\u00de \u0004 P t \u00f0x\u00de be the true underlying distributions for thesource and target domains, respectively. The key idea is toinfer a good approximation of P t \u00f0x; y\u00de by exploitingP s \u00f0x; y\u00de. If P t \u00f0y j x\u00de deviates from P s \u00f0y j x\u00de to a givenextent, domain adaptation is necessary. In the framework ofdomain adaptation, most of the learning methods areinspired by the idea that, although different, the twoconsidered domains are correlated.1 In particular, it isintuitive to observe that considering the (unlabeled) data ofthe target domain in the training phase could improve theperformances with respect to ignore this informationsource.2 Table 1 summarizes the main characteristics of allthe aforementioned learning methods.In the last few years, transfer learning has beenrecognized as an important topic in the machine learningand pattern recognition community. However, the attentionhas been focused mainly on developing methodologies foraddressing multitask learning or learning under sampleselection bias, whereas less attention has been devoted to1. The correlation between probability distributions (which allowsestimating quantitatively how similar they are) can be empiricallyevaluated according to some similarity metrics. Hence, two domains areconsidered correlated if the distance between the corresponding underlyingdistributions is relatively small according to proper metrics (e.g., [9], [10],[11]).2. A simple toy example for domain adaptation problems is describedand investigated in Section 6, where source-domain samples are distributedaccording to two intertwining moons associated with two specificinformation classes, while target-domain samples are obtained by a freerotation of the original source-domain patterns (i.e., due to rotation, sourceand target-domain data exhibit different distributions: P s \u00f0x\u00de 6\u00bc P t \u00f0x\u00de andP s \u00f0y j x\u00de 6\u00bc P t \u00f0y j x\u00de).\f772IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,domain adaptation problems. This is due to two mainmotivations: 1) Domain adaptation is a more critical andchallenging problem with respect to the other transferlearning subproblems, as training data are assumed to beavailable only for a source domain different (even if related)from the target domain of the (unlabeled) test samples, and2) unlike other problems, in practice, there are no strategiesto assess the effectiveness of the classification results usingstandard statistical validation methods as no labeledsamples are assumed to be available for the target domain.Considering the complexity of the problem, the lack ofprocedures for the accuracy assessment is crucial, and atpresent, seems to be a major limitation for the developmentof operational domain adaptation learning methods.In this paper, we address domain adaptation problemsby introducing two main novel contributions: 1) a domainadaptation support vector machine (DASVM) techniquethat extends support vector machines (SVMs) to the domainadaptation framework by exploiting labeled source-domaindata and unlabeled target domain data in the training phaseof the algorithm and 2) a circular indirect accuracyassessment strategy for the domain adaptation learningthat permits to automatically identify reliable solutions forthe target-domain classification problem by only exploitingsource-domain labeled samples.The rationale for developing a domain adaptationtechnique in the framework of SVMs [12], [13] is due tothe effectiveness of this classification methodology thatattempts to separate samples belonging to different classesby defining maximum margin hyperplanes [14], [15], [16].The relevance of SVMs is mainly related to their desirableproperties that can be summarized as follows:Empirical effectiveness with respect to other traditional classifiers, which results in relatively highclassification accuracies and very good generalization capabilities.2. Convexity of the objective function used in thelearning of the classifier, which results in a uniquesolution (i.e., the system cannot fall into suboptimalsolutions associated with local minima).3. Possibility of representing the optimization problemin a dual formulation, where only nonzero Lagrangemultipliers are necessary for defining the separationhyperplane (sparsity of the solution).4. Capability of addressing classification problems inwhich no explicit parametric models on the distribution of information classes are assumed (distribution-free classifier).5. Possibility of defining nonlinear decision boundariesby implicitly mapping the available observationsinto a higher dimensional space (i.e., kernel trick).In the literature, semi-supervised [17], [18], [19] andtransductive [20], [21] techniques based on SVMs havebeen proposed for solving problems under sample selectionbias characterized by a large amount of unlabeled data but areduced number of labeled data.3 In particular, they try torecover information from the distribution of unlabeled data1.3. It is worth noting that the objective functions used in the learning ofsemi-supervised and transductive SVMs are often not convex.VOL. 32, NO. 5,MAY 2010in the input space in order to improve the final classificationperformances. Nevertheless, these techniques are designedfor handling problems where labeled and unlabeled datacome from the same domain; thus, they are ineffective ondomain adaptation problems, especially when the sourceand target-domain distributions are significantly different.In order to overcome such a drawback, the proposedDASVM technique exploits and extends to domain adaptation problems principles of both transductive SVMs(TSVMs) [20] and progressive transductive SVMs (PTSVMs)[21]. From a general perspective, available labeled datafrom the source domain Ds are used for determining aninitial unreliable solution for the target-domain problem;then, unlabeled samples of the target domain Dt areexploited for properly adjusting the decision function,while labeled samples of Ds are gradually erased. The finalclassification function is determined only on the basis ofsemilabeled samples, i.e., originally unlabeled target-domaininstances that obtain labels during the learning process.In order to estimate the correctness of the solutions fordomain adaptation problems (where no prior informationfor Dt is available), we propose a novel validation strategydeveloped under the assumption that there exists anintrinsic structure intimately relating Ds and Dt . Underthe hypothesis that data in the two domains do not followuncorrelated distributions, we assume that it is possible toobtain an indirect evaluation of the reliability of the solutionto the investigated target problem. The effectiveness of thesolution for the target-domain samples can be inferred atthe end of a circular procedure by exploiting availablelabeled samples (i.e., prior information) related to thesource domain Ds .Experimental results obtained on a series of simulateddomain adaptation toy problems and on two real domainadaptation problems defined in the framework of braincomputer interface and remote sensing point out theeffectiveness and the reliability of both the presentedDASVM and the proposed circular validation strategy. Itis worth noting that the circular validation strategy isgeneral and can be used with any classification techniqueapplied to domain adaptation problems.The paper is organized into seven sections. In Section 2, asurvey on domain adaptation methods is presented. Section 3introduces the notation and the assumptions considered inthis work. Section 4 presents the proposed DASVM technique. Section 5 describes the circular validation strategydevised for assessing the accuracy of domain adaptationlearning algorithms. In Section 6, experimental results arereported and discussed. Finally, Section 7 draws theconclusions of this paper.2RELATED WORKIn the last few years, the scientific community has devoted agrowing interest to the definition of classification techniques for addressing domain adaptation problems. It isworth mentioning that a series of preliminary algorithmshas been developed under the assumption that a smallamount of target-domain labeled samples are available inthe learning phase, thus violating one of the key hypothesesfor domain adaptation. However, the role of these studies\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...has been particularly important for later development ofdomain adaptation classifiers. In the following, we firstbriefly review some of the most relevant algorithmsdeveloped in the aforementioned framework; then, wefocus the attention on current state-of-the-art domainadaptation techniques.2.1Algorithms Assuming Labeled Data Availablefor the Target DomainMost of the techniques presented in this framework havebeen developed for solving text classification problems. Acommon approach is to treat source-domain data as priorknowledge and to estimate the target-domain model parameters under such prior distribution. Hwa [22] and Gildea[23] proved that simple techniques based on using adequatelyselected subsets of source-domain data and parameterpruning can improve the performance on unlabeled targetdata. In [24], Roark and Bacchiani used source-domain data toconstruct a Dirichlet prior for MAP estimation of the targetdomain. In [25], Li and Bilmes proposed an accuracyregularization objective function, which minimizes theempirical risk on target data while maximizing a Bayesiandivergence prior determined on the source-domain datadistribution. Another approach proposed in [26] by Chelbaand Acero is to use the parameters of the maximum entropymodel learned from the source domain as the means of aGaussian prior when training a new model on target data. Adifferent technique based on the Conditional ExpectationMaximization (CEM) algorithm developed in the maximumentropy framework has been presented by Daume\u0300 and Marcuin [27]. Unlike the aforementioned techniques that do notconsider unlabeled samples of the target domain in thelearning phase, in [28], a domain adaptation method that canexploit information intrinsic in unlabeled target-domain datahas been presented. Jiang and Zhai proposed a generalinstance weighting framework that implements severaladaptation heuristics: removing misleading training samplesin the source domain, assigning more weights to labeledtarget patterns than labeled source patterns, and augmentingtraining samples with target samples with predicted labels.Other techniques aim at bridging the gap between source andtarget distributions by changing data representation. As anexample, in [29], Florian et al. developed an algorithm thatbuilds a source-domain model and considers its predictionsas features for the target domain. In this context, anotherinteresting approach has been recently proposed in [30],where Daume\u0300 presented an algorithm based on the idea oftransforming domain adaptation problems into standardsupervised learning problems (to which any standardalgorithm may be applied) by augmenting the size of thefeature space of both source and target data.2.2 Domain Adaptation AlgorithmsAt present, several domain adaptation algorithms rely ondefining new features for capturing the correspondencebetween source and target domains [31], [32]. In this way,the two domains appear to have similar distributions, thusenabling effective domain adaptation. Moreover, as oftenfeatures are correlated, careful feature subsetting could leadto significant accuracy gains [33]. In [31], Blitzer et al.describe a heuristic method for domain adaptation, whichexploits unlabeled data from both domains to inducecorrespondences among features in the two domains. The773unlabeled target samples are exploited for inferring a goodfeature representation, which can be regarded as weightingthe features. In [32], rather than choosing a common featurerepresentation heuristically, Ben-David et al. try to directlylearn a new representation which minimizes a bound on thetarget generalization error. The bound is determined bothusing source-domain labeled samples and source andtarget-domain unlabeled samples, and it is stated in termsof a representation function designed to minimize domaindivergence, as well as classification error. The algorithmaims at jointly minimizing a trade-off between source-targetsimilarity and source-domain training error. In [33], Satpaland Sarawagi present a method for addressing domainadaptation problems that selects a subset of features forwhich the distance (evaluated in terms of a particulardistortion metric) between the source and target distributions is minimized, while maximizing the likelihood oflabeled training data.Other interesting approaches for domain adaptation havebeen presented by Dai et al. [34] and [35]. In [34], theyintroduced a naive Bayes algorithm for addressing domainadaptation in the context of text categorization, where the EMalgorithm is used to find a locally optimal posteriorhypothesis under the target distribution. An initial modelbased on the source training data is first estimated. Such amodel is treated as a poor estimation of the target distribution. The EM algorithm is applied to find a local optimal inthe hypothesis space, where the estimation should graduallyapproach the target distribution. In [35], a co-clusteringbased classification algorithm is presented, where co-clustering is used as a bridge to propagate the class structure andknowledge from the source domain to the target domain.Domain adaptation without labeled target-domain datahas also been previously analyzed by the authors in thecontext of remote sensing image classification [36], [37], [38],[39] for addressing automatic updating of land-cover maps.In [36], a domain adaptation approach is proposed that is ableto update the parameters of an already trained parametricmaximum-likelihood (ML) classifier on the basis of thedistribution of a new image for which no labeled samplesare available. In [37], in order to take into account thetemporal correlation between images acquired on the samearea at different times, the ML-based domain adaptationapproach is reformulated in the framework of the Bayesianrule for cascade classification (i.e., the classification process isperformed by jointly considering information contained inthe source and target domains). The basic idea in bothapproaches is modeling the observed spaces by a mixture ofdistributions whose components are estimated by the use ofunlabeled target data and according to a proper inferenceapplied to source samples of the reference image. This isachieved by using a specific version of the EM algorithm withfinite Gaussian Mixture Models [40]. In [38], domainadaptation approaches based on a multiple-classifier systemand a multiple-cascade-classifier system (MCCS) have beendefined, respectively. In particular, in [39], the proposedMCCS architecture is composed of an ensemble of classifiersdeveloped in the framework of cascade classification, whichis integrated in a multiple-classifier architecture. Both aparametric ML classification approach and a nonparametricradial basis function neural network (RBF-NN) classificationtechnique are used as basic classifiers. In addition, in order toincrease both the effectiveness and robustness of the\f774IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,ensemble, hybrid ML and RBF-NN cascade classifiers aredefined.3PROBLEM FORMULATION AND ASSUMPTIONSGiven an input space X~ and a set of informationclasses \u0002, a classifier is any function g\u00f0x\u00de : X~ ! \u0002 thatmaps instances x 2 X~ to information classes. In supervised learning problems, training samples T \u00bc f\u00f0xi ; yi \u00degi ,xi 2 X \u0002 X~, yi 2 \u0002, drawn from the probability distribution P \u00f0x; y\u00de \u00bc P \u00f0y j x\u00de \u0004 P \u00f0x\u00de are assumed to be available.Accordingly, the learning problem is to determine asupervised classifier g\u00f0x j T ; \u0002\u00de4 that permits to obtainhigh predictive accuracy for unlabeled test samplesdrawn from the same distribution P \u00f0x; y\u00de by exploitingthe available training set T . The discrimination capabilitydepends on the classifier model, which is described by avector of parameters \u0002 that is specific for each family ofclassifiers.In the framework of domain adaptation, the problem ismore complex as test patterns are drawn from a targetdomain distribution P t \u00f0x; y\u00de \u00bc P t \u00f0y j x\u00de \u0004 P t \u00f0x\u00de differentfrom the source-domain distribution of training samplesP s \u00f0x; y\u00de \u00bc P s \u00f0y j x\u00de \u0004 P s \u00f0x\u00de. Obtaining a good adaptationrequires an adequate modeling of the relationship betweensource and target domains Ds and Dt . There are twoextreme cases for domain adaptation problems: 1) IfP s \u00f0x; y\u00de \u0005 P t \u00f0x; y\u00de, adaptation is not necessary and standard supervised learning algorithms can be employed and2) if P s \u00f0x; y\u00de and P t \u00f0x; y\u00de are uncorrelated, then sourcedomain data are useless for building a model for Dt .Nevertheless, in real applications, Ds and Dt are generallyneither identical nor uncorrelated. In these situations, it isreasonable to assume the existence of an intrinsic relationship between the two domains that makes it possibleadaptation. We expect that the probability to succeed in theadaptation process is associated with the complexity of theproblem, which depends on the correlation betweenP s \u00f0x; y\u00de and P t \u00f0x; y\u00de.In this context, let us consider two sets X s \u00bc fxsl gNl\u00bc1 andX t \u00bc fxtu gMu\u00bc1 composed of N source-domain and M targetdomain patterns, respectively. Let xs and xt be thed-dimensional feature vectors related to Ds and Dt ,respectively (d represents the dimensionality of the inputspace). The proposed techniques are formulated under thefollowing assumptions:The same set of L classes \u0002 \u00bc f!i gLi\u00bc1 characterizesDs and Dt .. A set of true labels Y s \u00bc fysl gNl\u00bc1 for X s is available,thus, it is possible to define a training set T s \u00bcfX s ; Y s g \u00bc f\u00f0xsl ; ysl \u00degNl\u00bc1 for Ds .. A set of true labels Y t \u00bc fytu gMu\u00bc1 for X t is notavailable, thus, it is not possible to define a trainingset for Dt .Under such a hypothesis, our goals are:.1.to define a domain adaptation classifier g\u00f0x jT s ; X t ; \u00de based on SVMs which permits us to4. This notation has been adopted for pointing out all the input variables(data and learning parameters) that affect the output of a classifier.2.4VOL. 32, NO. 5,MAY 2010obtain an accurate classification for target-domainsamples by exploiting labeled training samples T sfrom Ds and unlabeled samples X t from Dt (as forsupervised classifiers, the model adopted for classification is described by a vector of parameters ,which is specific for each family of domain adaptation classifiers);to develop a strategy for validating the learning ofthe domain adaptation classifier without labeledtarget-domain data.PROPOSED DASVM TECHNIQUEIn this section, for simplicity, we describe the proposedDASVM technique in the case of a two-class problem.Unlike transductive and semi-supervised SVMs, theDASVM algorithm takes into account that unlabeledtarget-domain samples are drawn from a distributionP t \u00f0x; y\u00de different from the one of source-domain trainingpatterns P s \u00f0x; y\u00de. Therefore, source-domain samples areonly exploited for initializing the discriminant function forthe target-domain problem, while they are successivelygradually erased in order to obtain a final separationhyperplane defined only on the basis of target-domainsamples. This represents an important conceptual difference with respect to both transductive and semi-supervisedSVMs techniques, which recover information from unlabeled samples under the assumption that the labeled andunlabeled samples are drawn from the same domain. Thus,they cannot be used for solving domain adaptationproblems. On the contrary, the DASVM technique, byiteratively deleting source-domain samples and adaptingthe discriminant function step by step to the target-domaininstances, can recover useful information and properly seizethe target-domain classification problem.The proposed DASVM algorithm is made up of threemain phases: 1) initialization (only T s is used for initializingthe discriminant function), 2) iterative domain adaptation(T s and X t are used for gradually adapting the discriminantfunction to Dt ), and 3) convergence (only X t is used fordefining the final discriminant function). In the following,\u00f0i\u00dewe will denote by T \u00f0i\u00de and X t the training set and theunlabeled set (i.e., the set containing the target-domainsamples that have not been inserted into the training setT \u00f0i\u00de ) at the generic iteration i, respectively. These phases aredescribed in the following.4.1 Phase 1: InitializationIn the first phase, an initial separation hyperplane isdetermined on the basis of source-domain training dataalone. We have that T \u00f00\u00de \u00bc fX s ; Y s g \u00bc f\u00f0xsl ; ysl \u00degNl\u00bc1 and\u00f00\u00deX t \u00bc fxtu gM.AsforstandardsupervisedSVMs,theu\u00bc1bound cost function to minimize is the following:\u00028X \u00031\u00f00\u00de2>>min\u0003lsk w k \u00feC<w;b;\u00032l\u0004 \u00f00\u00de s\u0005s\u00f00\u00de\u0005\u0004>\u0006 1 \u0007 \u0003ls>: yl w \u0004 xl s\u00fe b8l \u00bc 1; . . . ; N; xsl ; ysl 2 T \u00f00\u00de ;\u0003l \u0006 0\u00f01\u00de\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...775Fig. 1. Separation hyperplane (solid line) and margin bounds (dashed lines) at different stages of the DASVM algorithm for a toy data set. Labeledsource-domain patterns are shown as white and black circles. Semilabeled target-domain patterns are shown as white and black squares,respectively. Unlabeled target-domain patterns are represented as gray squares. Feature space structure obtained: (a) at the first iteration (thedashed circles highlight the \u0004 semilabeled patterns selected from both sides of the margin; in the example \u0004 \u00bc 3); (b) at the second iteration and (c) atthe last iteration, respectively, in an ideal situation (the dashed gray lines represent both the separation hyperplane and the margin bounds at thebeginning of the learning process).where w\u00f00\u00de is a vector normal to the separation hyperplaneh\u00f00\u00de : w\u00f00\u00de \u0004 x \u00fe b\u00f00\u00de \u00bc 0, b is a constant such that b\u00f00\u00de =kw\u00f00\u00de k2represents the distance of the hyperplane from the origin, \u0003iare slack variables, and C is a penalization parameter (alsocalled regularization parameter).4.2 Phase 2: Iterative Domain AdaptationAt the generic iteration i, all the original unlabeled target\u00f00\u00dedomain samples xtu 2 X t are associated with an estimated\u00f0i\u00de tlabel y^t\u00f0i\u00deu \u00bc sgn\u00bdf \u00f0xu \u00de\b, determined according to thecurrent decision function f \u00f0i\u00de \u00f0xtu \u00de \u00bc w\u00f0i\u00de \u0004 xtu \u00fe b\u00f0i\u00de . Then, a\u00f0i\u00desubset of the (remaining) unlabeled samples X t isiteratively selected and moved (with the correspondingestimated labels) into the training set T \u00f0i\u00fe1\u00de . On one hand,the higher the distance from the separation hyperplaneh\u00f0i\u00de : w\u00f0i\u00de \u0004 x \u00fe b\u00f0i\u00de \u00bc 0, the higher the probability for anunlabeled sample to be correctly classified. On the otherhand, the current unlabeled samples falling into the marginband M\u00f0i\u00de \u00bc fx j \u00071 f \u00f0i\u00de \u00f0x\u00de 1g are those with the highest probability to be associated with nonzero Lagrangemultipliers (and thus, to affect the position of h\u00f0i\u00fe1\u00de ) onceinserted in T \u00f0i\u00fe1\u00de with their current estimated label(patterns falling outside the margin band are more likelyto be associated with null multipliers). According to thesetwo observations, at each iteration, we progressively takeinto account the unlabeled target-domain samples fallinginto M\u00f0i\u00de closest to the margin bounds. Let us define thefollowing two subsets:\u0004 \u0005\u0004\u0005\u0007\u0006\u0004 t t\u00f0i\u00de \u0005 t\u00f0i\u00deH\u00f0i\u00dexu ; y^u j xu 2 X t ; 1 \u0006 f \u00f0i\u00de xtu \u0006 f \u00f0i\u00de xtu\u00fe1 \u0006 0 ;up \u00bc\u0005 t\u0004 \u0005\u0004\u0005\u0007\u0006\u0004\u00f0i\u00de\u00f0i\u00deHlow \u00bc xtu ; y^t\u00f0i\u00dej xu 2 X t ; \u00071 f \u00f0i\u00de xtuf \u00f0i\u00de xtu\u00fe1 < 0 ;u\u00f02\u00de\u00f0i\u00deHlowwhere H\u00f0i\u00deare made up of the patterns of theup and\u00f0i\u00decurrent unlabeled set X t (considered with their corresponding estimated labels) lying in the upper and lower sides of\u00f0i\u00dethe margin band M\u00f0i\u00de , respectively. Samples of H\u00f0i\u00deup and Hloware sorted in ascending order with respect to their distancefrom the upper and lower bound of the margin, respectively.The DASVM approach exploits a strategy inspired by thePTSVM algorithm [21] in which, at each iteration of thelearning process, the unlabeled samples inside the marginband M\u00f0i\u00de with the maximum and minimum values of thedecision function are moved into the training set. As twopatterns may not be sufficiently representative for tuning theposition of the hyperplane, in the proposed DASVM, at eachiteration, the first \u0004 patterns (where the parameter \u0004 \u0006 1 is\u00f0i\u00dedefined a priori by the user) belonging to H\u00f0i\u00deup and to Hlow ,whose current estimated labels y^t\u00f0i\u00deare \u201c\u00fe1\u201d and \u201c\u00071,\u201durespectively, are selected and inserted into the trainingset T \u00f0i\u00de (see Figs. 1a and 1b). Such samples are defined as\u00f0i\u00desemilabeled patterns. As the cardinality of H\u00f0i\u00deup and Hlow maybe lower than \u0004, the subset of target-domain patternsselected at the generic iteration i becomes\u0005\u0007\u0006\u00042 H\u00f0i\u00deH\u00f0i\u00de \u00bc xtu ; y^t\u00f0i\u00deu \u0005\u00f0i\u00deuup j 1\u00f03\u00de\u0005\u0007\u0006\u0004\u00f0i\u00de2 Hlow j 1 u \u0006\u00f0i\u00de ;[ xtu ; y^t\u00f0i\u00deu\u00f0i\u00de\u00f0i\u00dewhere \u0005\u00f0i\u00de \u00bc min\u00f0\u0004; jH\u00f0i\u00de\u00bc min\u00f0\u0004; jHlow j\u00de. Patternsup j\u00de and \u0006\u00f0i\u00debelonging to H are then merged with T \u00f0i\u00de . A dynamicaladjustment is necessary for taking into account that theposition of the separation hyperplane h\u00f0i\u00de changes at eachiteration. Let\u0007\u0006^t\u00f0i\u00071\u00de\u00f04\u00deS \u00f0i\u00de \u00bc \u00f0xtu ; y^t\u00f0i\u00071\u00de\u00de 2 T \u00f0i\u00de j y^t\u00f0i\u00deuu 6\u00bc yurepresent the set of semilabeled samples belonging to T \u00f0i\u00dewhose labels at iteration i are different from those atiteration i \u0007 1. If the label of a semilabeled pattern atiteration i is different from the one at iteration i \u0007 1 (labelinconsistency), such a label is erased and the semilabeled\u00f0i\u00fe1\u00depattern is reset to the unlabeled state and moved to X t .In this way, it is possible to reconsider this pattern in thefollowing iterations of the learning procedure.\f776IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,Let J \u00f0i\u00de represent the set containing all the semilabeledpatterns at the ith iteration. J \u00f0i\u00de is partitioned into a finitenumber of subsets \u0007 2 IN0 ,\u00f0i\u00de\u00f0i\u00deJ \u00f0i\u00de \u00bc J 1 [ J 2 [ \u0004 \u0004 \u0004 [ J \u00f0i\u00de\u00078 \u00f0i\u00de\u00f0i\u00de>J \u00bcH>< 1\u00f0i\u00de\u00f0i\u00071\u00deJ k \u00bc J k\u00071 \u0007 S \u00f0i\u00de ; 8k \u00bc 2; . . . ; \u0007 \u0007 1>>\u0004: \u00f0i\u00de\u00f0i\u00071\u00de \u0005[ J \u0007\u00071 \u0007 S \u00f0i\u00de ;J \u0007 \u00bc J \u00f0i\u00071\u00de\u0007\u00f05\u00dewhere each kth subset includes all of the semilabeledsamples that do not change their label after the tuning of theseparation hyperplane at the ith iteration and that belongedto the subset with index k \u0007 1 at iteration i \u0007 1. As will bepointed out in the following, the DASVM algorithm aims atgradually increasing the regularization parameter for thesemilabeled patterns according to a time-dependent criterion; accordingly, \u0007 is defined as the maximum number ofiterations for which the user allows the regularizationparameter for semilabeled samples to increase.As the main purpose of the proposed technique is todefine and solve a bound minimization problem withrespect only to the target-domain samples, at each iterationa subset Q\u00f0i\u00de of the original source-domain training patternsis deleted. The higher the distance from the separationhyperplane h\u00f0i\u00de , the lower the influence in affecting itsposition. Accordingly, it is reasonable to erase from T \u00f0i\u00de thesource-domain samples lying farther from h\u00f0i\u00de (see Fig. 1a).Let us define the following two subsets:\u0004 \u0005\u0004\u0005\u0007\u0006\u0004 s s \u0005xl ; yl 2 T \u00f0i\u00de j f \u00f0i\u00de xsl \u0006 f \u00f0i\u00de xsl\u00fe1 \u0006 0 ;Q\u00f0i\u00deup \u00bc\u00f06\u00de\u0006\u0004\u0005\u0004 \u0005\u0004\u0005\u0007\u00f0i\u00deQlow \u00bc xsl ; ysl 2 T \u00f0i\u00de j f \u00f0i\u00de xslf \u00f0i\u00de xsl\u00fe1 < 0 ;\u00f0i\u00dewhere Q\u00f0i\u00deup and Qlow contain the unlabeled target-domainpatterns that lie above and under the separation hyperplane, respectively, sorted in descending order with respectto their distance from h\u00f0i\u00de . At the ith iteration, the number of\u00f0i\u00depatterns to erase from Q\u00f0i\u00deup and Qlow is set equal to thenumber of semilabeled patterns selected from the upperand lower sides of the margin band (i.e., \u0005\u00f0i\u00de and \u0006\u00f0i\u00de ),respectively. If none of the remaining unlabeled samplesfall into the margin band \u00f0H\u00f0i\u00de \u00bc \u0003\u00de, the number of patternsto delete is set to \u0004. As a consequence, we have:\u0005\u0007\u0006\u0004l \b \u00f0i\u00deQ\u00f0i\u00de \u00bc xsl ; ysl 2 Q\u00f0i\u00deup j 1\u00f07\u00de\u0005\u0007\u0006\u0004\u00f0i\u00de\u00f0i\u00de;[ xsl ; ysl 2 Qlow j1 lwhere\b\b\u0005\b if H\u00f0i\u00de 6\u00bc \u0003min \u0005\u00f0i\u00de ; \bQ\u00f0i\u00deup\u00bcand\u0004 \b \u00f0i\u00de \b\u0005if H\u00f0i\u00de \u00bc \u0003min \u0004; \bQup \b(\b \u00f0i\u00de \b\u0005\u0004min \u0006\u00f0i\u00de ; \bQlow \b if H\u00f0i\u00de 6\u00bc \u0003;\u00bc\u0004 \b \u00f0i\u00de \b\u0005if H\u00f0i\u00de \u00bc \u0003:min \u0004; \bQlow \b\b \u00f0i\u00de\u00f0i\u00de\u0004Let \u00f0i\u00de \u00bc jT \u00f0i\u00de j \u0007 jJ \u00f0i\u00071\u00de j and \u00f0i\u00de \u00bc jJ \u00f0i\u00071\u00de j represent thenumber of original source-domain and semilabeled samplesbelonging to the current training set T \u00f0i\u00de , respectively. Fori \u0006 1, the bound minimization problem can be written asMAY 2010\u00038PP2>>minw;b;\u0003\u0003s ;\u0003\u0003t 12 w\u00f0i\u00de \u00fe C \u00f0i\u00de l \u0003ls \u00fe u Cu \u0003ut>>>>\u0005\u0004 \u00f0i\u00de s>s\u00f0i\u00de>>\u0006 1 \u0007 \u0003ls< y l \u0004 w \u0004 xl \u00fe b\u0005\u00048l \u00bc 1; . . . ; \u00f0i\u00de ; xsl ; ysl 2 T \u00f0i\u00de\u0004\u0005>>>y^t\u00f0i\u00071\u00de\u0004 w\u00f0i\u00de \u0004 xtu \u00fe b\u00f0i\u00de \u0006 1 \u0007 \u0003ut>u>\u0005\u0004>>>2 T \u00f0i\u00de8u \u00bc 1; . . . ; \u00f0i\u00de ; xtu ; y^t\u00f0i\u00071\u00de>u:s t\u0003l ; \u0003u \u0006 0:\u00f08\u00deThe semilabeled samples \u00f0xtu ; y^t\u00f0i\u00071\u00de\u00de 2 T \u00f0i\u00de are associateduwith a regularization parameter Cu \u00bc Cu \u00f0k\u00de 2 IR\u00fe that\u00f0i\u00071\u00dedepends on the kth subset J kwhich they belong to atiteration i \u0007 1. The original source-domain patterns, instead, are associated with a regularization parameter C \u00f0i\u00dethat directly depends on the ith iteration. The purpose ofC \u00f0i\u00de and Cu is to control the number of misclassifiedsamples of the current training set T \u00f0i\u00de drawn from Ds andDt , respectively. On increasing their values, the penaltyassociated with errors increases. In other words, the largerthe regularization parameter, the higher the influence of theassociated samples on the selection of the separationhyperplane. As P t \u00f0x; y\u00de in general could be rather differentcompared to P s \u00f0x; y\u00de, unlabeled samples should be considered gradually in the learning process in order to avoidinstabilities. For this reason, the algorithm adopts aweighting strategy based on a temporal criterion. Theregularization parameter for the semilabeled patternsincreases in a quadratic way, depending on the number ofiterations k they had last inside the set containing thesemilabeled patterns J \u00f0i\u00de (see Fig. 2a):\b\b8u \u00bc 1; . . . ; \bJ \u00f0i\u00de \b;\u0005\u0004C max \u0007 C\u00f0i\u00de2 Jk ;Cu \u00bc\u00f0k \u0007 1\u00de2 \u00fe C , xtu ; y^t\u00f0i\u00de\u00f09\u00deu2\u00f0\u0007 \u0007 1\u00dek \u00bc 1; . . . ; \u0007;where C is the initial regularization value for semilabeledsamples (this is a user-defined parameter), and C max is themaximum cost value of semilabeled samples and is relatedto that of training patterns (i.e., C max \u00bc \u0004 C, 0 <1being a constant; a reasonable choice has proved to be\u00bc 0:5). The greater k is, the higher the reliability of asemilabeled sample is expected to be.Likewise, the algorithm makes the cost factor for theoriginal source-domain labeled samples C \u00f0i\u00de to decrease in aquadratic way (see Fig. 2b). At the beginning, the position ofthe separation hyperplane strongly depends on sourcedomain patterns \u00f0xsl ; ysl \u00de, but their influence always getslower as the number of iterations increases (until i \u00bc \u0007):C \u00f0i\u00de \u00bc max(VOL. 32, NO. 5,\u0002C \u0007C 2i \u00fe C; C\u00072:\u00f010\u00deThe second phase ends when the convergence criteriondescribed below is satisfied.4.3 Phase 3: ConvergenceFrom a theoretical viewpoint, it can be assumed thatconvergence is reached if none of the remaining targetdomain samples lies into the margin band, H\u00f0i\u00de \u00bc \u0003, afterall of the source-domain labeled samples have been erased,Q\u00f0i\u00de \u00bc \u0003 (see Fig. 1c). Nevertheless, such a choice mightresult in a high computational load. Moreover, it may\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...\u00f0i\u00de777\u00f0i\u00deFig. 2. (a) Behavior of Cu , regularization parameter for the semilabeled patterns belonging to J \u00f0i\u00de \u00bc J 1 [ J 2 [ . . . [ J \u00f0i\u00de\u0007 , versus k (index\u00f0i\u00decorresponding to the subset J k , which is related to the number of iterations in which a semilabeled pattern is associated with the samelabel). (b) Behavior of the regularization parameter for the original source-domain labeled patterns, C \u00f0i\u00de , versus the number of iterations i.happen that even if the margin band is empty, the numberof inconsistent patterns is not negligible. For these reasons,the following empirical stopping criterion has been defined:8< Q\u00f0i\u00de \u00bc \u0003;\u00f011\u00dejH\u00f0i\u00de j d \u0004 Me;: \u00f0i\u00ded \u0004 MejSwhere M is the number of target-domain samples and is aconstant fixed a priori that tunes the sensitivity of thelearning process. This means that convergence is reached ifboth the number of mislabeled and remaining unlabeledpatterns lying in the margin band at the current iteration islower than or equal to d \u0004 Me. The final minimizationproblem at the last iteration i\u0004 becomes8\u0002\u0003P>12>>kwk\u00feC\u0003minw;b;\u0003\u0003 2>u u u><\u0004\u0005\u0004t\u00f0i\u00071\u00det\u00f012\u00de\u0004 w \u0004 xu \u00fe b \u0006 1 \u0007 \u0003uy^\b \u00f0i\u00de\u0004 \b \u0004 t t\u00f0i\u00071\u00de> u\u0005\u0004\u0004>\u00f0i\u00de\b\b>^2T8u\u00bc1;...;T;y;x>u u>:\u0003u \u0006 0:At the end, all of the target-domain patterns xtu 2 X t arelabeled according to the resulting separation hyperplane,ytu \u00bc sgn\u00bdw \u0004 xtu \u00fe b\bgMi.e., Y^t \u00bc f^u\u00bc1 .The above-described algorithm is defined for two-classproblems. When a multiclass problem has to be investigated,a One-Against-All (OAA) strategy [41] can be employed.5PROPOSED CIRCULAR VALIDATION STRATEGYIn this section, we present a novel general empiricalstrategy for validating the solutions obtained with a domainadaptation classifier when no labeled data related to thetarget domain are available. This method can also be usedwith the DASVM presented in the previous section.5.1Background and Rationale of the ProposedStrategyThe proposed strategy is based on the two followingassumptions.1.Assumption 1: Under the assumption that P s \u00f0x; y\u00deand P t \u00f0x; y\u00de are neither uncorrelated nor identical, itis reasonable to assume the existence of an intrinsicrelationship between solutions that are satisfactoryfor the two domains. This relationship is associatedwith the intrinsic structure of the consideredproblem (which is related to the correlation betweenP s \u00f0x; y\u00de and P t \u00f0x; y\u00de). We expect that an adequatelytrained domain adaptation algorithm seizes thestructure of the problem and can move frommodeling the source-domain problem to modelingthe target-domain problem, and vice versa. On thecontrary, if the learning process fails, the considereddomain adaptation algorithm completely loses thestructure of the problem and results in an unpredictable behavior that involves a random solution.This solution has no relation to the consideredproblem. In this condition, it is no more possible torecover the intrinsic structure of the problem, andthus, moving from modeling the target-domainproblem to modeling the source-domain problem.2. Assumption 2: The only labeled samples available arethose related to the source domain Ds . Thus, forvalidating the learning for Dt , we should devise anindirect procedure based on the training set T s .On the basis of these observations, the proposed strategyrelies on the following rationale: Let us consider that,starting from a reliable estimated distribution P^ns \u00f0x; y\u00de forDs (and thus, from an acceptable classification accuracy onsource-domain patterns), the nth generic domain adaptation classifier results in an accurate estimate P^nt \u00f0x; y\u00de forP t \u00f0x; y\u00de (and hence, in a satisfactory classification accuracyfor the instances related to Dt ). In such a case, the domainadaptation classifier seizes the structure of the targetdomain problem. In this condition, we assume that, byagain applying the same learning algorithm in the reversesense (using the classification labels in place of the missingprior knowledge for target-domain patterns X t , keeping thesame learning parameters, and considering the problem ofclassifying source-domain patterns X s ), it is possible to inferan accurate estimate for P s \u00f0x; y\u00de (thus obtaining a gooddiscrimination capability also for the source-domain problem). On the contrary, if the domain adaptation algorithmdoes not identify an acceptable solution for Dt , this meansthat it does not capture the relationship between the twodomains but converges to a solution which is not related tothe investigated problem (i.e., the resulting P^nt \u00f0x; y\u00de does not\f778IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 32, NO. 5,MAY 2010than \u0005th for source and target-domain samples (nonconsistentsolutions), respectively. \u0005th represents the smallest value for\u0005 such that a solution can be considered acceptable for theproblem under investigation.Each classifier gn \u00f0x\u00de is associated with an estimate of thejoint probability distribution P^n \u00f0x; y\u00de \u00bc P^n \u00f0y j x\u00de \u0004 P^\u00f0x\u00de forthe considered domain. Indeed, while P^\u00f0x\u00de directly depends on the instances available for the considered domain,the estimated conditional posterior distribution P^n \u00f0y j x\u00de isrelated to the information class associated by the classifier tothe generic sample x, i.e., P^n \u00f0y j x\u00de \u00bc P^\u00f0gn \u00f0x\u00de j x\u00de. Accordingly, both the source and target-domain estimated jointdistributions can be written asFig. 3. Diagram of all the possible state transitions exploited from theproposed circular validation strategy.represent an adequate estimation of the real distributionP t \u00f0x; y\u00de). In this condition, by again applying the algorithmin the reverse sense (from target to source), it seemsimpossible to recover a reliable solution for the sourcedomain problem, but rather, it is reasonable to expect apoor estimate for P s \u00f0x; y\u00de. This reasoning has someanalogies with the definition of specific trajectories thatmodel transitions between different states in chaoticsystems. On the basis of these expected properties, we canuse the accuracy evaluated on the original training samplesfrom Ds for validating the solution obtained for targetdomain instances after a circular (forward and backward)application of the considered domain adaptation algorithm.5.2Formulation of the Proposed Circular ValidationStrategyGiven a classification accuracy measure \u0005\u00f0Y j ; Y^jn \u00de thatevaluates the similarity between a set of labels Y^jn (i.e., asolution) predicted by the generic classifier gn \u00f0x\u00de and thecorresponding set of true labels Y j , and given a threshold\u0005th for \u0005, let us define the following four sets of classifiers(see Fig. 3):A \u00bc fgn \u00f0x\u00de j \u0005\u00f0Y s ; Y^sn \u00de \u0006 \u0005th g;\u00f013\u00deB \u00bc fgn \u00f0x\u00de j \u0005\u00f0Y t ; Y^tn \u00de \u0006 \u0005th g;\u00f014\u00deC \u00bc fgn \u00f0x\u00de j \u0005\u00f0Y s ; Y^sn \u00de < \u0005th g;\u00f015\u00deD \u00bc fgn \u00f0x\u00de j \u0005\u00f0Y t ; Y^tn \u00de < \u0005th g;\u00f016\u00deysin \u00bc gn \u00f0xsi \u00deg and Y^tn \u00bc f^ytin \u00bc gn \u00f0xti \u00deg are thewhere Y^sn \u00bc f^labels predicted by gn \u00f0x\u00de for source and target-domainsamples, respectively. It is worth noting that the subscript npoints out a classification model obtained starting from thesame classification technique using different values ofparameters in the training phase (e.g., a DASVM classifierwith different values of learning parameters). On one hand,A and B contain all of the classifiers that permit to obtainsolutions whose accuracy is higher than or equal to \u0005th forsource and target-domain samples (consistent solutions),respectively. On the other hand, C and D contain all of theclassifiers that provide solutions whose accuracy is lowerP^ns \u00f0x; y\u00de \u00bc P^ns \u00f0y j x\u00de \u0004 P^s \u00f0x\u00de \u00bc P^s \u00f0gn \u00f0x\u00de j x\u00de \u0004 P^s \u00f0x\u00de;\u00f017\u00deP^nt \u00f0x; y\u00de \u00bc P^nt \u00f0y j x\u00de \u0004 P^t \u00f0x\u00de \u00bc P^t \u00f0gn \u00f0x\u00de j x\u00de \u0004 P^t \u00f0x\u00de:\u00f018\u00deTherefore, it is possible to relate the quality of theseestimated distributions with the four sets of classifiersdescribed above:If gn \u00f0x\u00de 2 A, we assume that P^ns \u00f0x; y\u00de is consistent\u0004with P s \u00f0x; y\u00de (the system is in state A).. If gn \u00f0x\u00de 2 B, we assume that P^nt \u00f0x; y\u00de is consistent\u0004with P t \u00f0x; y\u00de (the system is in state B).. If gn \u00f0x\u00de 2 C, we assume that P^ns \u00f0x; y\u00de is not consistent\u0004with P s \u00f0x; y\u00de (the system is in state C).t^. If gn \u00f0x\u00de 2 D, we assume that Pn \u00f0x; y\u00de is not consis\u0004tent with P t \u00f0x; y\u00de (the system is in state D).\u0004Starting from state A, with a proper choice of the learningparameters, a domain adaptation classifier is expected to\u0004 (thus belonging to B). On the contrary, if themove to state Bchoice of the parameters is not adequate (or P t \u00f0x; y\u00de is too\u0004 (thusdifferent from P s \u00f0x; y\u00de), the classifier moves to state Dbelonging to D). Let us now consider the solution obtainedfor the target-domain samples. We can address the reversedomain adaptation problem (from target to source) with thesame classifier keeping the same learning parameters andjointly exploiting the classification labels Y^tn (instead of thetraining set, thus defining T^t \u00bc fX t ; Y^tn g) and sourcedomain samples X s (considered without their labels Y s ).As the true labels fysi gNi\u00bc1 for source-domain instances areknown, we can compute the value for \u0005 associated with theresults obtained after the circular learning process. If\u0005 < \u0005th , the classification accuracy for the source-domainproblem is considered nonacceptable, then the backwardclassifier moves to state C\u0004 (thus belonging to C). On thecontrary, if \u0005 \u0006 \u0005th , the solution is consistent, thus thebackward classifier belongs to A and the system moves\u0004back to state A.Our assumption is that, when the domain adaptation\u0004 theclassifier starting from state C\u0004 is able to return into state A,classification accuracy for target-domain data is satisfactoryand P^nt \u00f0x; y\u00de is a good approximation of P t \u00f0x; y\u00de. This aspect iscrucial because it means that, in such situations, we are able toassess that target-domain data are classified with a properaccuracy even if no prior knowledge is available. The twomain hypotheses under which the proposed validationtechnique is effective are the following:.\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...\u0004 the system must never move back toStarting from state D\u0004 If the solution obtained in the forward sensestate A.(from source to target) for target-domain instances isnot satisfactory (i.e., P^nt \u00f0x; y\u00de is not consistent withP t \u00f0x; y\u00de), by applying the considered algorithm inthe backward sense (from target to source), it mustnever be possible to obtain an acceptable solution forsource-domain instances (i.e., the resulting P^ns \u00f0x; y\u00deis always not consistent with P s \u00f0x; y\u00de).\u0004 If\u0004 the system can return to state A.. Starting from state Bthere exists a set of satisfactory solutions obtained inthe forward sense (from source to target) for targetdomain instances (i.e., the related P^nt \u00f0x; y\u00de areconsistent with P t \u00f0x; y\u00de), by applying the domainadaptation classifier in the backward sense (fromtarget to source), it must be possible to obtain for atleast one of them an acceptable solution for sourcedomain samples (i.e., the related P^ns \u00f0x; y\u00de is consistent with P s \u00f0x; y\u00de).It is worth noting that, under the aforementioned assumptions, the system may reject some solutions that are actuallyconsistent with the target-domain problem as the learningparameters are not optimized for the backward process andwe cannot assume a perfect symmetry between the domainadaptation problems from source to target, and vice versa.Nevertheless, the very important aspect is that the systemnever accepts and validates solutions that are nonconsistent, which is definitely a more critical aspect of validationin operational problems..6EXPERIMENTAL RESULTSIn order to assess the effectiveness of both the proposedDASVM technique and the presented circular validationstrategy, we carried out several experiments on differentdata sets. We analyzed three different domain adaptationproblems: 1) a series of two-dimensional toy problemshaving different complexity, 2) a real problem in theframework of brain computer interface, and 3) a realproblem in the context of remote sensing. For all of thedata sets, true labels were available for both source andtarget-domain instances. However, prior information related to the target domain Dt was considered only for anobjective and quantitative assessment of the performancesof the proposed techniques. In the following, we willdescribe the common procedure adopted for analyzing theconsidered data sets; then, in the next sections, we willpresent in detail the results obtained for each of them.In all of the trials, we employed Gaussian kernelfunctions (ruled by the free parameter \u000e) as they provedeffective in addressing different kinds of problems. Wechose the percentage overall accuracy OA% (i.e., thepercentage of correctly labeled samples over the wholenumber of considered samples) as reference classificationaccuracy measure \u0005 and fixed \u0005th \u00bc OA%th \u00bc 85 in thevalidation strategy. This means that, both for the sourceand target-domain classification problems, we assumed thata solution was consistent if OA% \u0006 85.In order to estimate the complexity of the investigateddomain adaptation problems, we first analyzed the \u201cdistance\u201d between source and target-domain distributions. To779this aim, a common choice in the literature is to compute theKullback-Leibler (KL) [10] divergence, which is defined asXpnD\u00bdP \u00f0x\u00de k Q\u00f0x\u00de\b \u00bcpn log ;\u00f019\u00deqnnwhere pn and qn are point probabilities of the twoconsidered source and target distributions P and Q,respectively [11]. Note that D\u00bdP \u00f0x\u00dekQ\u00f0x\u00de\b 2 \u00bd0; 1\u00de. Even ifKL divergence is generally considered as a kind of distancebetween two distributions, it is not symmetric (i.e.,D\u00bdP \u00f0x\u00dekQ\u00f0x\u00de\b 6\u00bc D\u00bdQ\u00f0x\u00dekP \u00f0x\u00de\b). Therefore, in our experiments, we considered the Jensen-Shannon divergence(DJS ), which is a symmetrized and smoothed version ofthe KL divergence [11]. DJS is defined asDJS \u00bdP \u00f0x\u00de; Q\u00f0x\u00de\b \u00bc \u000f \u0004 D\u00bdP \u00f0x\u00de k M\u00f0x\u00de\b\u00fe\u0004 D\u00bdQ\u00f0x\u00de k M\u00f0x\u00de\b;\u00f020\u00dewhere M\u00f0x\u00de \u00bc \u000f \u0004 P \u00f0x\u00de \u00fe \u0004 Q\u00f0x\u00de. In particular, we considered the case where \u000f \u00bc \u00bc 0:5, (referred in theliterature as specific DJS ) for which it holds thatDJS \u00bdP \u00f0x\u00de; Q\u00f0x\u00de\b 2 \u00bd0; log 2\b. The existence of both a lowerand an upper bound for DJS is particularly important as itpermits us to understand how different the two considereddistributions are. If DJS \u00bdP \u00f0x\u00de; Q\u00f0x\u00de\b \u00bc 0, then P and Q areconsidered identical, whereas if DJS \u00bc log 2 \u2019 0:693, P andQ are considered uncorrelated. Besides the distanceDJS \u00bdP s \u00f0x\u00de; P t \u00f0x\u00de\b evaluated between general distributions,we also analyzed the distance DJS \u00bdP s \u00f0xj!i \u00de; P t \u00f0xj!i \u00de\bbetween class conditional distributions.In all experiments, we trained several supervised SVMson the labeled source-domain samples T s \u00bc fX s ; Y s g, inorder to identify the models (and thus, the values of thesupervised parameters \u000e and C) that resulted in accurate(consistent) solutions for source-domain samples. Successively, we trained a number of DASVMs using T s as labeledset and target-domain instances X t as unlabeled set. In thelearning phase, we assigned to \u000e and C pairs of valuesassociated with solutions consistent with Ds . On theremaining learning parameters (i.e., C , \u0004, and \u0007 ), weapplied a grid search. Note that, for the sake of comparison,we also evaluated the performances obtained by other twostate-of-the-art domain adaptation techniques: 1) the retraining technique for maximum likelihood classifierspresented in [36] (denoted by MLretrain ) and 2) themaximum likelihood cascade classifier proposed in [37](denoted by MLcascade ).For validating the potentialities of the proposed domainadaptation technique, we identified the DASVM thatprovided the highest overall accuracy on the basis of theavailable target-domain true labels (which were not takeninto account in the learning phase). This accuracy valuerepresents an upper bound for the performances of thepresented method. In order to assess the effectiveness of theempirical circular validation strategy introduced in Section 4,for all of the considered DASVMs, we applied the proposeddomain adaptation algorithm in the reverse sense. Startingfrom the corresponding set of target-domain predictedlabels, Y^tn , for the generic nth DASVM, we defined anestimated training set T^tn \u00bc fX t ; Y^tn g for Dt and trained thecorrespondent nth \u201cbackward\u201d DASVM using T^tn as labeled\f780IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 32, NO. 5,MAY 2010Fig. 4. Problem I: (a) original source-domain data; (b) decision regions obtained for the source-domain problem by a supervised SVM trainedaccording to a 10-fold CV strategy. Decision regions obtained for the target-domain problem by the proposed DASVM technique with optimalselection of learning parameters when (c) \u0010 \u00bc 10 , (d) \u0010 \u00bc 20 , (e) \u0010 \u00bc 30 , (f) \u0010 \u00bc 40 , and (g) \u0010 \u00bc 50 . (h) Superimposition of source data and targetdata for \u0010 \u00bc 50 (the dashed circles point out regions, where target data that belong to class !1 overlap source data that belong to class !2 , and viceversa) and decision regions obtained for the source-domain problem by a supervised SVM trained according to a 10-fold CV strategy.set and source-domain samples X s (considered without theirlabels) as unlabeled set (the same learning parametersemployed in the forward learning were used). By exploitingavailable prior information for Ds , we determined whetherthe final solution Y^sn was consistent or not and, accordingly,inferred the correctness of the related solution to the targetdomain problem Y^tn . By using the available target-domaintrue labels, we could compute the average percentage overallaccuracy of the solutions correctly identified as consistentwith Dt by the circular validation strategy. This value is veryimportant as it represents an average measure for the qualityof the solutions consistent with Dt identified by the proposedvalidation strategy without any prior information on X t .Note that, in order to obtain significant estimations, for all ofthe considered problems, we trained 350 backward DASVMsboth starting from consistent and nonconsistent solutionswith the target-domain problem. For the sake of comparison,we also evaluated the accuracies exhibited on target-domainsamples by a supervised SVM trained on source-domaindata according to a 10-fold cross validation (CV).In all experiments, we employed the Sequential MinimalOptimization algorithm [42] for training both the supervised SVMs and, with proper modifications, the proposedDASVMs. As pointed out in Section 4, we fixed \u00bc 0:5.Concerning the convergence criterion, a reasonable empirical choice has proven to be \u00bc 3\u000410\u00072 .6.1 Problem I: Synthetic Data SetThe first set of experiments was aimed at characterizing thebehavior of both the DASVM algorithm and the circularvalidation strategy when addressing a well-defined problem in a controlled environment at different levels ofcomplexity. This analysis is particularly important forempirically understanding the operational conditions forwhich we can expect to obtain satisfactory performanceswith the proposed methods. We considered as sourcedomain data a toy data set made up of 300 samplesgenerated according to a bidimensional pattern of twointertwining moons associated with two specific information classes (150 samples each), as shown in Fig. 4a. Targetdata were generated by rotating anticlockwise the originalsource data set 11 times by 10, 15, 20, 25, 30, 35, 40, 45, 50,55, and 60 degrees, respectively. Due to rotation, sourceand target-domain data exhibit different distributions (i.e.,P s \u00f0x\u00de 6\u00bc P t \u00f0x\u00de and P s \u00f0y j x\u00de 6\u00bc P t \u00f0y j x\u00de). In particular, thegreater the rotation angle (\u0010), the more complex theresulting domain adaptation problem, as confirmed bythe values for DJS reported in Table 2.The proposed DASVM algorithm proved to be particularly effective for solving this kind of problem and involvedvery high accuracies even in very critical conditions. FromTable 3, one can observe that, for an optimal selection oflearning parameters (DASVMbest ), we could obtain perfectseparation between information classes when \u0010 2 \u00bd10 ; 50 \b(see Figs. 4c, 4d, 4e, 4f, and 4g). The accuracies are alwayshigher than those exhibited by the supervised SVM trainedaccording to a 10-fold CV on source-domain data (the OA%grows almost quadratically with respect to the rotationangle, i.e., from \u00fe0:33 for \u0010 \u00bc 10 to \u00fe67:33 for \u0010 \u00bc 50 ).Only for greater values of \u0010 (i.e., 55 and 60 ) the DASVM\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...781TABLE 2Problem I: Jensen-Shannon Divergence Values for Different Rotation Angleswas not able to find a solution consistent with Dt . Nevertheless, this behavior seems reasonable due to the complexityof the corresponding domain adaptation problems. In thesecases, the initial separation hyperplane determined according to source-domain samples resulted in an average OA%on target-domain data smaller than 30. Accordingly, it wasnot possible to recover correct classification labels as morethan 70 percent of target-domain samples were misclassifiedat the first iteration of the DASVM algorithm. The complexityof this problem is also confirmed from the high values of DJS .It should be pointed out that, as soon as the rotationangle becomes greater than 35 , target-domain data thatactually belong to the class !1 overlap source-domain databelonging to the class !2 , and vice versa (see, for instance,Fig. 4h). Note that, due to rotation, there are target-domaininstances that coincide with source-domain instances butwith different true labels. This represents a strong limitationfor other state-of-the-art domain adaptation techniquesreported in Section 2. The proposed DASVM technique,due do to the fact that iteratively erases original trainingsamples in the iterative learning phase, does not suffer fromthis drawback and is able to obtain satisfactory performances also in such critical cases. It is worth noting thatDASVMs outperformed both MLretrain and MLcascade : thegreater the rotation angle \u0010 (and thus, the greater theproblem complexity), the higher the gap in terms ofclassification accuracy (see Table 3). In particular, for\u0010 \u00bc 50 , the increase in OA% is around 30, thus furtherconfirming the effectiveness of the proposed technique inaddressing also very critical situations.With regard to the presented circular validation strategy,we obtained very promising results. In particular, for all ofthe considered cases, the proposed strategy was alwaysable to correctly reject solutions that were not consistentwith Dt , thus satisfying the most critical assumption for theoperational employment of the proposed technique. Asexpected, when the DASVM started from a solution thatdid not adequately model the source-domain classificationproblem, the system could not recover a solution consistent\u0004 j D\u00de\u0004 \u00bc 0. Table 3 also reports thewith Ds , thus P \u00f0Aprobability of correct validation of solutions consistent\u0004 j B\u00de,\u0004 for the cases in which it was possible towith Dt , P \u00f0Aobtain at least one of them in the forward learning phase(i.e., \u0010 2 \u00bd10 ; 50 \b). It is possible to notice that, for smallvalues of \u0010, the proposed circular strategy identified morethan one half of correct solutions, while, by increasing \u0010values, the number of correct solutions properly recognizedgradually decreased. This is a reasonable behavior if weconsider that the distance between distributions sharplyincreases and learning parameters are not optimized for thebackward process.Fig. 5 shows some examples of the empirical estimatedprobability distribution P^\u00f0OA%\u00de of the OA% for thesolutions obtained for source-domain data at the end of thebackward learning process when the system starts from both\u0004 (black line) and state D\u0004 (gray line). If we consider asstate BTABLE 3Problem I: Percentage Overall Accuracy Exhibited on Target-Domain Instances for Different Rotation Angles(a) Percentage OA exhibited by: 1) A supervised SVM trained on source-domain samples according to a 10-fold CV strategy (SV M CV ); 2) theproposed DASVM technique with optimal selection of learning parameters (DASV M best ). The average accuracy associated with the consistentsolutions obtained by the proposed DASVM technique and correctly identified by the circular validation strategy (DASV M ave ) and the probability\u0004 j B\u00de\u0004 of identifying consistent solutions with the proposed circular validation strategy are also given. (b) Percentage OA exhibited by: 1) TheP \u00f0Aretraining technique for maximum likelihood classifier (MLretrain ); 2) the maximum likelihood cascade classifier (MLcascade ).\f782IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 32, NO. 5,MAY 2010Fig. 5. Problem I: Empirical estimated probability distribution P^\u00f0OA%\u00de of the percentage overall accuracy (OA%) for the solutions obtained on the\u0004 (black line) and state D\u0004 (gray line) for (a) \u0010 \u00bc 10 , (b) \u0010 \u00bc 20 , (c) \u0010 \u00bc 30 , (d) \u0010 \u00bc 40 , andsource domain when the system starts from both state B\u0004\u0004 if OA% \u0006 85, the system moves to state A.(e) \u0010 \u00bc 50 . If OA% < 85, the system moves to state C;an example Fig. 2b (which refers to the case \u0010 \u00bc 20 ), we cansee that q0:85 \u00f0OA%\u00de (i.e., the quantile corresponding toOA%th \u00bc 85) is equal to 0.48. Accordingly, as the systems\u0004 B\u00de\u0004 \u00bcmove to state C\u0004 if OA% < OA%th , we have that P \u00f0Cj\u0004\u0004\u0004\u0004q0:85 \u00f0OA%\u00de \u00bc 0:48; therefore, P \u00f0AjB\u00de \u00bc 1 \u0007 P \u00f0CjB\u00de, which\u0004 in themeans that the classifier can go back to state A52 percent of the cases. The very important conclusion of thisanalysis is that even in critical situations, the proposedcircular validation strategy was able to identify correctsolutions without considering any prior information on thelabels of target-domain data. Moreover, if we consider theaverage OA% of solutions correctly identified as consistentwith Dt , we can see that it is comparable with that obtainedwith optimal selection of leaning parameters, thus confirming the effectiveness of the proposed circular validationstrategy.6.2 Problem II: Brain Computer Interface Data SetThe second data set considered refers to a Brain ComputerInterface (BCI) problem. A BCI is an assistive communication system, which helps people with severe disabilities torealize the control of motor neuroprotheses. The data set weconsidered was made up of electrocorticogram (ECoG)signals recorded from the same subject performing thesame task in two different days (i.e., at times t1 and t2 ) withabout one week in between. In the considered case, thesubject had to perform imagined movements of either theleft small finger or the tongue (associated with the classes !1and !2 , respectively) for at least 3 seconds. For greaterdetails about this data set, the reader is referred to [43], [44].It is worth noting that the design of a classifier for a BCIsystem is very challenging when a classifier trained on dataacquired on a certain day should classify data recorded inother days without retraining. On one hand, the patientmight be in a different state concerning motivation, fatigue,etc. Therefore, his brain will show different electricalactivity. On the other hand, the recording system mighthave undergone slight changes concerning electrode positions and impedances.Fig. 6a presents the system designed for extracting thefeatures used in our experiments. Original ECoG signalswere first low-pass (0-3 Hz) and band-pass (8-30 Hz)filtered in order to acquire movement-related potentials(MRD) and event-related desynchronization (ERD) signals,respectively, which are electrical physiological phenomenaactivated by limb movements or imagined movements [45],[46]. Then, we used the common spatial subspace decomposition (CSSD) technique, which allows us to extract signalcomponents specific to one condition and eliminate background activities [47]. For both frequency intervals, weselected the two components that, according to the CSSDtechnique, are more related to the considered informationclasses. The final data set is obtained by merging togetherthese two pairs of features. For the source domain at time t1 ,the brain activity was monitored for 278 events (139associated with each information class), whereas, for thetarget domain at time t2 , 100 events were considered (50 foreach information class).The resulting domain adaptation problem proved to beparticularly challenging, as confirmed by the values for theDJS reported in Table 4. Source and target-domain overalldistributions were rather different (0.408), but the gap waseven more relevant for the conditional class distributions(0.625 for the class !1 and 0.616 for the class !2 ). Even in suchcritical conditions, the DASVM algorithm proved effective\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...783Fig. 6. Problem II: (a) Architecture of the system employed for extracting the features used in the experiments. (b) Empirical estimated probabilitydistribution P^\u00f0OA%\u00de of the percentage overall accuracy (OA%) for the solutions obtained on the source domain when the system starts from both\u0004\u0004 if OA% \u0006 85, the system moves to state A.\u0004 (black line) and state D\u0004 (gray line). If OA% < 85, the system moves to state C;state BTABLE 4Problem II: Jensen-Shannon Divergence ValuesTABLE 5Problem II: Percentage Overall Accuracy (OA%) Exhibited on Target-Domain Instances by:1) a Supervised SVM Trained on Source-Domain Instances According to a 10-Fold CV Strategy (SVMCV );2) the Proposed DASVM Technique with Optimal Selection of Learning Parameters (DASVMbest );3) the Maximum Likelihood Classifier (MLretrain ); and 4) the Maximum Likelihood Cascade Classifier (MLcascade )The average accuracy associated with the consistent solutions obtained by the proposed DASVM technique and correctly identified by the circularvalidation strategy (DASVMave ) is also given.(see Table 5). In particular, in the best case, we were able toobtain an OA% equal to 93.00, which corresponds to anincrease of \u00fe14:00 with respect to the OA% yielded with thestandard supervised SVM trained according to the 10-foldCV strategy at time t1 . Moreover, DASVMs provided alsohigher OA% than both MLretrain (\u00fe5) and MLcascade (\u00fe6). Theproposed technique exhibited a very good capability ofseizing the structure of the investigated domain adaptationproblem, as it is possible to infer from the behavior ofP^\u00f0OA%\u00de (see Fig. 6b). In particular, with the circularvalidation strategy, we were able to correctly identify66 percent of solutions consistent at time t2 (i.e.,q0:85 \u00f0OA%\u00de \u00bc 0:44) with an average OA% equal to 91.65(\u00fe11:65 with respect to the supervised SVM). This meansthat it was possible to recover a satisfactory accuracy forsource-domain data only starting from high accuracies fortarget-domain data, thus confirming that solutions arecorrectly validated as consistent only if the target-domainproblem is well modeled. Accordingly, also for this data set,\u0004 thus\u0004 to state A,the system never moved back from state Dexhibiting the crucial property to be always able to rejectwrong solutions.6.3 Problem III: Remote Sensing Data SetThe third set of experiments was carried out on a multiclassproblem in the context of a remote sensing application. Weinvestigated the task of automatic updating of land-covermaps by classification of remote sensing images acquiredover the same geographical area at two different times t1and t2 . We considered two coregistered multispectralimages acquired in September 1995 and July 1996 by theThematic Mapper (TM) sensor of the Landsat 5 Satellite (seeFigs. 7a and 7b). The selected test site was a section of about11:7 km 10:8 km (i.e., 412 382 pixels) of a scene including Lake Mulargia on the Island of Sardinia, Italy. The fiveinformation classes that characterized the investigated siteat both times were taken into account, i.e., forest, pasture,urban area, water body, and vineyard. For both source andtarget-domain problems, the same number of samples wasconsidered for each information class (see Table 6). It isworth noting that, due to many differences at the twoacquisition times (e.g., different acquisition system state,dissimilar illumination conditions, alterations in the phenologic state of vegetation, changes occurred on the ground,etc.), the distance between spectral distributions of the twoimages is considerable.Among the seven available spectral bands, as commonlydone in the literature, we did not take into account band 6,which corresponds to the low-resolution channel acquiredin the thermal infrared. In order to characterize the textureproperties of the considered classes and to exploit thedistribution-free nature of SVMs, we extracted five texturefeatures based on the gray-level co-occurrence matrix (i.e.,\f784IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,VOL. 32, NO. 5,MAY 2010Fig. 7. Problem III: Spectral channel 5 of the multispectral Landsat-5 Thematic Mapper images used in the experiments. (a) Image acquired inSeptember 1995. (b) Image acquired in July 1996. (c) Empirical estimated probability distribution P^\u00f0OA%\u00de of the percentage overall accuracy (OA%)\u0004 (black line) and state D\u0004 (gray line). If OA% < 85, thefor the solutions obtained on the source domain when the system starts from both state B\u0004\u0004 if OA% \u0006 85, the system moves to state A.system moves to state C;TABLE 6Problem III: Number of Both Source-Domain (September 1995 Image) and Target-Domain (July 1996 Image) Patternsand Jensen-Shannon Divergence ValuesTABLE 7Problem III: Percentage Overall Accuracy (OA%), Producer\u2019s Accuracies (PA%), and User\u2019s Accuracies (UA%) Exhibited onTarget-Domain Instances by: 1) a Supervised SVM Trained on Source-Domain InstancesAccording to a 10-Fold CV Strategy (SVMCV ); 2) the Proposed DASVM Technique with Optimal Selection of Learning Parameters(DASVMbest ); 3) the Retraining Technique for the Maximum Likelihood Classifier (MLretrain );and 4) the Maximum Likelihood Cascade Classifier (MLcascade )The average accuracies associated with the consistent solutions obtained by the proposed DASVM technique and correctly identified by the circularvalidation strategy (DASVMave ) are also given.correlation, sum average, sum variance, difference variance, and entropy) and added them to the six TMchannels. As the images were acquired in different periodsof the year, the resulting overall DJS distance betweensource-domain distribution at time t1 and target-domaindistribution at time t2 was considerable (i.e., 0.391). Thecomplexity of the investigated domain adaptation problemis stressed up by the distances between conditional classdistribution at the two dates, which assume high values, inparticular, for the classes pasture (i.e., 0.517) and vineyard(i.e., 0.567). As pointed out in Section 3, one of theconstraints imposed by the DASVM algorithm is the use ofthe OAA multiclass architecture; therefore, we adopted thesame multiclass strategy also when dealing with supervised SVMs used for comparisons.Table 7 shows the results obtained in terms of OA% andboth percentage producer\u2019s and user\u2019s accuracies5 (i.e.,PA% and UA%, respectively) for each information class.Taking into account the complexity of the problem underinvestigation, the obtained classification accuracies confirmed also in this case the good adaptation capabilities ofthe proposed DASVM technique, which was able tosharply increase the accuracy with respect to the supervised SVM trained according to a 10-fold CV on sourcedomain samples. In particular, in the best case, the OA%5. For each specific information class: 1) Producer\u2019s accuracy is definedas the ratio between the number of samples correctly classified as belongingto that class and the total number of reference samples available for thatclass; 2) user\u2019s accuracy is defined as the ratio between the number ofsamples correctly classified as belonging to that class and the total numberof samples classified as belonging to that class.\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...increased up to 94.78 (i.e., \u00fe19:05). Moreover, the improvement in the PA% is huge for pasture (i.e., \u00fe63:78)and remarkable for vineyard (\u00fe9:12), whereas the increasein the UA% is noteworthy for vineyard (i.e., \u00fe42:27), forest(\u00fe17:62), and pasture (\u00fe9:07).Also, in this case, DASVMs exhibited higher accuraciesthan MLretrain and MLcascade (\u00fe2:02 and \u00fe3:03 in terms ofOA% for optimal selection of learning parameters), thusconfirming their effectiveness also when addressing multiclass problems.Fig. 7c points out the effectiveness of the proposedcircular validation strategy also on this data set. Thisstrategy allowed us to correctly reject all of the solutionsthat were not consistent with Dt . In addition, when the\u0004 we had q0:85 \u00f0OA%\u00de \u00bc 0:51,system started from state B,which corresponds to almost one-half (i.e., 49 percent) ofconsistent solutions properly validated without any priorinformation for the image at time t2 . It is worth noting that,\u0004in most part of the cases, the system moved back to state Awhen the classification accuracy at t2 was particularly high.This is confirmed by the high average OA% obtained fortarget-domain instances for the solutions correctly identified as consistent by the validation strategy. The averageOA% is equal to 90.88 (\u00fe15:15 with respect to thesupervised SVM), whereas as concerns both PA% andUA%, the behavior is similar to that obtained for the bestcase described above. In particular, the increase in pasturePA% and vineyard UA% is considerable (i.e., \u00fe52:93 and\u00fe29:00, respectively).7DISCUSSION AND CONCLUSIONIn this paper, we have addressed domain adaptationproblems by introducing two main novel contributions: 1) adomain adaptation classifier based on SVMs (DASVM) and2) a circular strategy aimed at validating the results obtainedwith a domain adaptation classifier.The proposed DASVM technique extends the principlesof SVMs to the domain adaptation framework by taking intoaccount that unlabeled test samples are drawn from a targetdomain Dt different from the source domain Ds of trainingsamples. Labeled patterns drawn from Ds are used only forconstraining the learning phase of the classifier, but the finalsolution only models the structure of Dt . In particular,labeled source-domain data are employed for determiningan initial discriminant function for the target-domainproblem; then, unlabeled samples from Dt are exploited forproperly adjusting the decision function, while samples fromDs are gradually erased. The final classification function isdetermined only on the basis of semilabeled samples, i.e.,originally unlabeled target-domain instances that obtainlabels during the learning process. For better controlling thebehavior and stability of the classifier, an adaptive weightingstrategy for the regularization parameters based on atemporal criterion is adopted. This permits us to tune theinfluence of unlabeled patterns and, in general, prevents thesystem from converging to improper solutions.It is worth noting that the proposed DASVM is designedfor addressing a problem conceptually different from thosefaced by transductive and semi-supervised SVMs, whichhave been defined for handling problems where labeled785and unlabeled data are drawn from the same domain. Thus,they are ineffective in domain adaptation, where trainingdata are assumed to be available only for a source domaindifferent (even if related) from the target domain of the(unlabeled) test samples.As for transductive and semi-supervised SVMs, also forDASVMs it is not possible to guarantee for obtaining reliablesolutions to the classification problem. In fact, if the accuracyafter the initialization phase is particularly low (i.e., most ofthe unlabeled target-domain samples are incorrectly classified at the beginning of the learning process), it becomesdifficult to obtain satisfactory performances. The convergence of the algorithm to a consistent solution depends onthe intrinsic correlation between the two domains: Thefarther Dt is from Ds , the harder the resulting domainadaptation problem. This correlation can be measured bycomputing similarity metrics between Ds and Dt .In the framework of domain adaptation, due to theabsence of prior information for target-domain instances,standard statistical validation strategies proposed in theliterature cannot be used for assessing the effectiveness oflearning and the validity of the resulting classifier. In thiscontext, we proposed an indirect circular validationstrategy based on the idea that an intrinsic structure relatesthe solutions consistent with Ds and Dt . A solution for Dt(for which no prior information is available) is assumed tobe consistent if the solution obtained by applying the samedomain adaptation learning algorithm in the reverse sense(i.e., using the classification labels in place of missing priorknowledge for target-domain instances) to source-domaindata (considered as unlabeled in the reverse domainadaptation learning) is associated with an acceptableaccuracy (which can be evaluated due to the available truelabels for source-domain samples).From the analysis of experimental results obtained on aseries of two-dimensional toy problems and on two realproblems defined in the context of brain computer interfaceand remote sensing, we can conclude that the presentedDASVM resulted in high and satisfactory classificationaccuracy, outperforming other state-of-the-art domainadaptation techniques. Several trials also confirmed theeffectiveness of the proposed circular validation strategy,which always proved able to reject solutions that were notconsistent with the investigated classification task andidentified acceptable solutions for Dt even in very criticalconditions. In this framework, the joint use of both theproposed DASVM classification technique and the circularvalidation strategy seems particularly suitable to definesystems capable of solving real application problems.As a final remark, it is worth noting that, from acomputational viewpoint, each iteration of the DASVMsrequires a time equivalent to that taken from the learning ofa supervised SVM. In fact, as the number of target-domainsemilabeled patterns increases, the number of sourcedomain labeled patterns decreases; therefore, the cardinality of the training set does not increase with the number ofiterations. Accordingly, it is possible to state that thecomputational load grows linearly with the number ofiterations. In general, the computational time is comparableto the one of semi-supervised methods and higher than the\f786IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,one required by supervised SVMs (on average, a hundredof iterations for each binary DASVM are needed). Nevertheless, taking into account both the very promising resultsobtained and the complexity of the investigated problems,we can consider this cost reasonable.ACKNOWLEDGMENTSThe authors would like to thank the associate editor and theanonymous reviewers for their valuable comments.REFERENCES[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22]R. Caruana, \u201cMultitask Learning,\u201d Machine Learning J., vol. 28,no. 1, pp. 41-75, 1997.S. Thrun and L.Y. Pratt, Learning to Learn. Kluwer AcademicPublishers, 1998.S. Ben-David and R. Schuller, \u201cExploiting Task Relatedness forMultiple Task Learning,\u201d Proc. 16th Ann. Conf. Learning Theory,2003.B. Zadrozny, \u201cLearning and Evaluating Classifiers under SampleSelection Bias,\u201d Proc. 21st Int\u2019l Conf. Machine Learning, 2004.M. Dudik, R.E. Schapire, and J.S. Philips, \u201cCorrecting SampleSelection Bias in Maximum Entropy Density Estimation,\u201d Advancesin Neural Information Processing Systems 17, MIT Press, 2005.J. Huang, A. Smola, A. Gretton, K.M. Borgwardt, and B.Scho\u0308lkopf, \u201cCorrecting Sample Selection Bias by Unlabeled Data,\u201dAdvances in Neural Information Processing Systems 20, MIT Press,2007.H. Shimodaira, \u201cImproving Predictive Inference under CovariateShift by Weighting the Loglikelihood Function\u201d J. StatisticalPlanning and Inference, vol. 90, pp. 227-244, 2000.M. Sugiyama and K.R. Mu\u0308ller, \u201cInput-Dependent Estimation ofGeneralization Error under Covariate Shift,\u201d Statistics and Decisions, vol. 23, pp. 249-279, 2005.H. Jeffreys, \u201cAn Invariant Form for the Prior Probability inEstimation Problems,\u201d Proc. Royal Soc. London, vol. 186, pp. 453461, 1946.S. Kullback and R. Leibler, \u201cOn Information and Sufficiency,\u201dAnnals of Math. Statistics, vol. 22, pp. 79-86, 1951.J. Lin, \u201cDivergence Measures Based on the Shannon Entropy,\u201dIEEE Trans. Information Theory, vol. 37, pp. 145-151, 1991.V.N. Vapnik, Statistical Learning Theory. John Wiley & Sons, Inc.,1998.V.N. Vapnik, The Nature of Statistical Learning Theory, second ed.Springer-Verlag, 1995.M. Pontil and A. Verri, \u201cSupport Vector Machines for 3D ObjectRecognition,\u201d IEEE Trans. Pattern Analysis and Machine Intelligence,vol. 20, no. 6, pp. 637-646, June 1998.G. Ratsch, S. Mika, B. Scho\u0308lkopf, and K.R. Muller, \u201cConstructingBoosting Algorithms from SVMs: An Application to One-ClassClassification,\u201d IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 24, no. 9, pp. 1184-1199, Sept. 2002.K. In Kim, K. Jung, S.H. Park, and H.J. Kim, \u201cSupport VectorMachines for Texture Classification,\u201d IEEE Trans. PatternAnalysis and Machine Intelligence, vol. 24, no. 11, pp. 1542-1550,Nov. 2002.K.P. Bennett and A. Demiriz, \u201cSemi-Supervised Support VectorMachines,\u201d Advances in Neural Information Processing Systems,vol. 10, pp. 368-374, MIT Press, 1998.G. Fung and O.L. Mangasarian, \u201cSemi-Supervised Support VectorMachines for Unlabeled Data Classification,\u201d Optimization Methodsand Software, vol. 15, no. 1, 2001.X. Zhu, \u201cSemi-Supervised Learning Literature Survey,\u201d TR-1530,Computer Sciences, Univ. of Wisconsin-Madison, 2005.T. Joachims, \u201cTransductive Inference for Text Classification UsingSupport Vector Machines,\u201d Proc. 16th Int\u2019l Conf. Machine Learning,1999.Y. Chen, G. Wang, and S. Dong, \u201cLearning with ProgressiveTransductive Support Vector Machine,\u201d Pattern Recognition Letters,vol. 24, no. 12, pp. 1845-1855, 2003.R. Hwa, \u201cSupervised Grammar Induction Using Training Datawith Limited Constituent Information,\u201d Proc. 37th Ann. Meeting ofthe Assoc. for Computational Linguistics, 1999.VOL. 32, NO. 5,MAY 2010[23] D. Gildea, \u201cCorpus Variation and Parser Performance,\u201d Proc. 2001Conf. Empirical Methods in Natural Language Processing, 2001.[24] B. Roark and M. Bacchiani, \u201cSupervised and Unsupervised PCFGAdaptation to Novel Domains,\u201d Proc. 2003 Conf. North Am. Chapterof the Assoc. for Computational Linguistics and Human LanguageTechnology, 2003.[25] X. Li and J. Bilmes, \u201cA Bayesian Divergence Prior for ClassifierAdaptation,\u201d Proc. 11th Int\u2019l Conf. Artificial Intelligence andStatistics, 2007.[26] C. Chelba and A. Acero, \u201cAdaptation of Maximum EntropyCapitalizer: Little Data Can Help a Lot,\u201d Proc. 2004 Conf. EmpiricalMethods in Natural Language Processing, 2004.[27] H. Daume\u0300 III and D. Marcu, \u201cDomain Adaptation for StatisticalClassifiers,\u201d J. Artificial Intelligence Research, vol. 26, pp. 101-126,2006.[28] J. Jiang and C. Zhai, \u201cInstance Weighting for Domain Adaptationin NLP,\u201d Proc. 45th Ann. Meeting of the Assoc. for ComputationalLinguistics, 2007.[29] R. Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kambhatla, X.Luo, N. Nicolov, and S. Roukos, \u201cA Statistical Model forMultilingual Entity Detection and Tracking,\u201d Proc. 2004 Conf.North Am. Chapter of the Assoc. for Computational Linguistics andHuman Language Technology, 2004.[30] H. Daume\u0300 III, \u201cFrustratingly Easy Domain Adaptation,\u201d Proc. 45thAnn. Meeting of the Assoc. for Computational Linguistics, 2007.[31] J. Blitzer, R. McDonald, and F. Pereira, \u201cDomain Adaptation withStructural Correspondence Learning,\u201d Proc. 2006 Conf. EmpiricalMethods in Natural Language Processing, 2006.[32] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira, \u201cAnalysis ofRepresentation for Domain Adaptation,\u201d Advances in NeuralInformation Processing Systems 19, MIT Press, 2006.[33] S. Satpal and S. Sarawagi, \u201cDomain Adaptation of ConditionalProbability Models via Feature Subsetting,\u201d Proc. 11th EuropeanConf. Principles and Practice of Knowledge Discovery in Databases,2007.[34] W. Dai, G.R. Xue, Q. Yang, and Y. Yu, \u201cTransferring Na\u0131\u0308ve BayesClassifier for Text Classification,\u201d Proc. 22nd Nat\u2019l Conf. ArtificialIntelligence, 2007.[35] W. Dai, G.R. Xue, Q. Yang, and Y. Yu, \u201cCo-Clustering BasedClassification for Out-of-Domain Documents,\u201d Proc. ACMSIGKDD, 2007.[36] L. Bruzzone and D. Ferna\u0300ndez Prieto, \u201cUnsupervised Retrainingof a Maximum-Likelihood Classifier for the Analysis of Multitemporal Remote-Sensing Images,\u201d IEEE Trans. Geosciences andRemote Sensing, vol. 39, pp. 456-460, 2001.[37] L. Bruzzone and D. Ferna\u0300ndez Prieto, \u201cA Partially UnsupervisedApproach to the Automatic Classification of MultitemporalRemote-Sensing Images,\u201d Pattern Recognition Letters, vol. 33,no. 9, pp. 1063-1071, 2002.[38] L. Bruzzone and R. Cossu, \u201cA Multiple-Cascade-Classifier Systemfor a Robust and Partially Unsupervised Updating of Land-CoverMaps,\u201d IEEE Trans. Geosciences and Remote Sensing, vol. 40, no. 9,pp. 1984-1996, Sept. 2002.[39] L. Bruzzone, R. Cossu, and G. Vernazza, \u201cCombining Parametricand Non-Parametric Algorithms for a Partially UnsupervisedClassification of Multitemporal Remote-Sensing Images,\u201d Information Fusion, vol. 3, no. 4, pp. 289-297, 2002.[40] S. Tajudin and D. Landgrebe, \u201cRobust Parameter Estimation forMixture Model,\u201d IEEE Trans. Geoscience and Remote Sensing, vol. 38,pp. 439-445, 2000.[41] N. Cristianini and J. Shawe-Taylor, An Introduction to SupportVector Machines. Cambridge Univ. Press, 2000.[42] J. Platt, \u201cFast Training of Support Vector Machines UsingSequential Minimal Optimization,\u201d Advances in Kernel Methods:Support Vector Learning, B. Scho\u0308lkopf, C. Burges, and A. Smola,eds., pp. 185-208, MIT Press, 1998.[43] https://ida.first.fraunhofer.de/projects/bci/competition_iii/,2008.[44] T. Lal, T. Hinterberger, G. Widman, M. Schro\u0308der, J. Hill, W.Rosenstiel, C. Elger, B. Scho\u0308lkopf, and N. Birbaumer, \u201cMethodsTowards Invasive Human Brain Computer Interfaces,\u201d Advancesin Neural Information Processing Systems 17, MIT Press, 2004.[45] C. Toro, G. Deuschl, R. Thatcher, S. Sato, C. Kufta, and M. Hallett,\u201cEvent-Related Desynchronization and Movement-Related Cortical Potentials on the ECoG and EEG,\u201d Electroencephalography andClinical Neurophysiology, vol. 93, pp. 380-389, 1994.\fBRUZZONE AND MARCONCINI: DOMAIN ADAPTATION PROBLEMS: A DASVM CLASSIFICATION TECHNIQUE AND A CIRCULAR...[46] C. Babiloni, F. Carducci, F. Cincotti, P.M. Rossini, C. Neuper, G.Pfurtscheller, and F. Babiloni, \u201cHuman Movement-Related Potentials vs Desynchronization of EEG Alpha Rhythm: A HighResolution EEG Study,\u201d Neuroimage, vol. 10, pp. 658-665, 1999.[47] Y. Wang, P. Berg, and M. Scherg, \u201cCommon Spatial SubspaceDecomposition Applied to Analysis of Brain Responses UnderMultiple Task Conditions: A Simulation Study,\u201d Clinical Neurophysiology, vol. 110, pp. 604-614, 1999.Lorenzo Bruzzone received the laurea (MS)degree in electronic engineering (summa cumlaude) and the PhD degree in telecommunications from the University of Genoa, Italy, in 1993and 1998, respectively. He is currently a fullprofessor of telecommunications at the University of Trento, Italy, where he teaches remotesensing, pattern recognition, radar, and electrical communications. His current researchinterests are in the areas of remote sensing,signal processing, and pattern recognition (analysis of multitemporalimages, feature extraction and selection, classification, regression andestimation, data fusion, machine learning). He conducts and supervisesresearch on these topics within the frameworks of several national andinternational projects. He is the author (or coauthor) of 86 scientificpublications in refereed international journals (58 in IEEE journals), morethan 140 papers in conference proceedings, and 11 book chapters. Heis editor/coeditor of nine books/conference proceedings. He is a refereefor many international journals and has served on the scientificcommittees of several international conferences. He is a member ofthe managing committee of the Italian Interuniversity Consortium onTelecommunications and a member of the scientific committee of theIndia-Italy Center for Advanced Research. Since 2009, he has been amember of the administrative committee of the IEEE Geoscience andRemote Sensing Society. He ranked first place in the Student PrizePaper Competition of the 1998 IEEE International Geoscience andRemote Sensing Symposium (Seattle, July 1998). He was a recipient ofthe Recognition of the IEEE Transactions on Geoscience and RemoteSensing Best Reviewers in 1999 and was a guest coeditor of severalspecial issues of the IEEE Transactions on Geoscience and RemoteSensing. He was the general chair and cochair of the First and SecondIEEE International Workshops on the Analysis of Multitemporal RemoteSensing Images (MultiTemp), and is currently a member of thepermanent steering committee of this series of workshops. Since2003, he has been the chair of the SPIE Conference on Image andSignal Processing for Remote Sensing. From 2004 to 2006, he servedas an associate editor of the IEEE Geoscience and Remote SensingLetters and currently is an associate editor for the IEEE Transactions onGeoscience and Remote Sensing and the Canadian Journal of RemoteSensing. In 2008 he was appointed a member of the joint NASA/ESAScience Definition Team for Outer Planet Flagship Missions. He is also amember of the International Association for Pattern Recognition and theItalian Association for Remote Sensing (AIT). He is a fellow of the IEEE.787Mattia Marconcini received the \u201claurea\u201d (BS)and the \u201claurea specialistica\u201d (MS) degrees intelecommunication engineering (summa cumlaude) and the PhD degree in communicationand information technologies from the Universityof Trento, Italy, in 2002, 2004, and 2008,respectively. He is presently with the RemoteSensing Laboratory in the Department of Information Engineering and Computer Science,University of Trento. His current researchactivities are in the area of machine learning, pattern recognition, andremote sensing. In particular, his interests are related to transferlearning and domain adaptation classification and image segmentationproblems. He conducts research on these topics within the frameworksof several national and international projects. He was a finalist in theStudent Prize Paper Competition of the 2007 IEEE InternationalGeoscience and Remote Sensing Symposium (Barcelona, July 2007).He is a member of the IEEE.. For more information on this or any other computing topic,please visit our Digital Library at www.computer.org/publications/dlib.\f", "2015 IEEE International Conference on Computer VisionPoseNet: A Convolutional Network for Real-Time 6-DOF Camera RelocalizationAlex KendallMatthew GrimesUniversity of CambridgeRoberto Cipollaagk34, mkg30, rc10001 @cam.ac.ukKing\u2019s CollegeOld HospitalShop Fac\u0327adeSt Mary\u2019s ChurchFigure 1: PoseNet: Convolutional neural network monocular camera relocalization. Relocalization results for an inputimage (top), the predicted camera pose of a visual reconstruction (middle), shown again overlaid in red on the original image(bottom). Our system relocalizes to within approximately 2m and 3\u25e6 for large outdoor scenes spanning 50, 000m2 . For anonline demonstration, please see our project webpage: mi.eng.cam.ac.uk/projects/relocalisation/Abstract1. IntroductionInferring where you are, or localization, is crucial formobile robotics, navigation and augmented reality. This paper addresses the lost or kidnapped robot problem by introducing a novel relocalization algorithm. Our proposed system, PoseNet, takes a single 224x224 RGB image and regresses the camera\u2019s 6-DoF pose relative to a scene. Fig. 1demonstrates some examples. The algorithm is simple inthe fact that it consists of a convolutional neural network(convnet) trained end-to-end to regress the camera\u2019s orientation and position. It operates in real time, taking 5ms torun, and obtains approximately 2m and 3 degrees accuracyfor large scale outdoor scenes (covering a ground area of upto 50, 000m2 ).Our main contribution is the deep convolutional neuralnetwork camera pose regressor. We introduce two noveltechniques to achieve this. We leverage transfer learning from recognition to relocalization with very large scaleclassi\ufb01cation datasets. Additionally we use structure frommotion to automatically generate training labels (cameraposes) from a video of the scene. This reduces the humanlabor in creating labeled video datasets to just recording theWe present a robust and real-time monocular six degree of freedom relocalization system. Our system trainsa convolutional neural network to regress the 6-DOF camera pose from a single RGB image in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking 5ms per frame to compute. Itobtains approximately 2m and 3\u25e6 accuracy for large scaleoutdoor scenes and 0.5m and 5\u25e6 accuracy indoors. This isachieved using an ef\ufb01cient 23 layer deep convnet, demonstrating that convnets can be used to solve complicated outof image plane regression problems. This was made possible by leveraging transfer learning from large scale classi\ufb01cation data. We show that the PoseNet localizes from highlevel features and is robust to dif\ufb01cult lighting, motion blurand different camera intrinsics where point based SIFT registration fails. Furthermore we show how the pose featurethat is produced generalizes to other scenes allowing us toregress pose with only a few dozen training examples.1550-5499/15 $31.00 \u00a9 2015 IEEEDOI 10.1109/ICCV.2015.3362938\fers have been proposed such as [4] which uses SIFT features [15] in a bag of words approach to probabilisticallyrecognize previously viewed scenery. Convnets have alsobeen used to classify a scene into one of several locationlabels [23]. Our approach combines the strengths of theseapproaches: it does not need an initial pose estimate, andproduces a continuous pose. Note we do not build a map,rather we train a neural network, whose size, unlike a map,does not require memory linearly proportional to the size ofthe scene (see \ufb01g. 13).Our work most closely follows from the Scene Coordinate Regression Forests for relocalization proposed in [20].This algorithm uses depth images to create scene coordinate labels which map each pixel from camera coordinatesto global scene coordinates. This was then used to traina regression forest to regress these labels and localize thecamera. However, unlike our approach, this algorithm islimited to RGB-D images to generate the scene coordinatelabel, in practice constraining its use to indoor scenes.Previous research such as [27, 14, 9, 3] has also usedSIFT-like point based features to match and localize fromlandmarks. However these methods require a large databaseof features and ef\ufb01cient retrieval methods. A method whichuses these point features is structure from motion (SfM) [28,1, 22] which we use here as an of\ufb02ine tool to automaticallylabel video frames with camera pose. We use [8] to generatea dense visualisation of our relocalization results.Despite their ability in classifying spatio-temporal data,convolutional neural networks are only just beginning to beused for regression. They have advanced the state of theart in object detection [24] and human pose regression [25].However these have limited their regression targets to liein the 2-D image plane. Here we demonstrate regressingthe full 6-DOF camera pose transform including depth andout-of-plane rotation. Furthermore, we show we are able tolearn regression as opposed to being a very \ufb01ne resolutionclassi\ufb01er.It has been shown that convnet representations trained onclassi\ufb01cation problems generalize well to other tasks [18,17, 2, 6]. We show that you can apply these representationsof classi\ufb01cation to 6-DOF regression problems. Using thesepre-learned representations allows convnets to be used onsmaller datasets without over\ufb01tting.video.Our second main contribution is towards understandingthe representations that this convnet generates. We showthat the system learns to compute feature vectors which areeasily mapped to pose, and which also generalize to unseenscenes with a few additional training samples.Appearance-based relocalization has had success [4, 23]in coarsely locating the camera among a limited, discretizedset of place labels, leaving the pose estimation to a separatesystem. This paper presents a means of computing continuous pose directly from appearance. The scene may includemultiple objects and need not be viewed under consistentconditions. For example the scene may include dynamicobjects like people and cars or experience changing weatherconditions.Simultaneous localization and mapping (SLAM) is atraditional solution to this problem. We introduce a newframework for localization which removes several issuesfaced by typical SLAM pipelines, such as the need tostore densely spaced keyframes, the need to maintain separate mechanisms for appearance-based localization andlandmark-based pose estimation, and a need to establishframe-to-frame feature correspondence. We do this by mapping monocular images to a high-dimensional representation that is robust to nuisance variables. We empiricallyshow that this representation is a smoothly varying injective (one-to-one) function of pose, allowing us to regresspose directly from the image without need of tracking.Training convolutional networks is usually dependent onvery large labeled image datasets, which are costly to assemble. Examples include the ImageNet [5] and Places [29]datasets, with 14 million and 7 million hand-labeled images,respectively. We employ two techniques to overcome thislimitation:\u2022 an automated method of labeling data using structurefrom motion to generate large regression datasets ofcamera pose\u2022 transfer learning which trains a pose regressor, pretrained as a classi\ufb01er, on immense image recognitiondatasets. This converges to a lower error in less time,even with a very sparse training set, as compared totraining from scratch.2. Related work3. Model for deep regression of camera poseThere are generally two approaches to localization: metric and appearance-based. Metric SLAM localizes a mobilerobot by focusing on creating a sparse [13, 11] or dense[16, 7] map of the environment. Metric SLAM estimatesthe camera\u2019s continuous pose, given a good initial pose estimate. Appearance-based localization provides this coarseestimate by classifying the scene among a limited numberof discrete locations. Scalable appearance-based localiz-In this section we describe the convolutional neural network (convnet) we train to estimate camera pose directlyfrom a monocular image, I. Our network outputs a posevector p, given by a 3D camera position x and orientationrepresented by quaternion q:p = [x, q]2939(1)\fPose p is de\ufb01ned relative to an arbitrary global referenceframe. We chose quaternions as our orientation representation, because arbitrary 4-D values are easily mapped to legitimate rotations by normalizing them to unit length. Thisis a simpler process than the orthonormalization required ofrotation matrices.3.1. Simultaneously learning location andorientationTo regress pose, we train the convnet on Euclidean lossusing stochastic gradient descent with the following objective loss function:\u0002\u0002\u0002q \u0002\u0002\u0002loss(I) = \u0002x\u0302 \u2212 x\u00022 + \u03b2 \u0002q\u0302 \u2212(2)\u0002q\u0002 \u00022Figure 2: Relative performance of position and orientation regression on a single convnet with a range of scale factors for anindoor scene, Chess. This demonstrates that learning with the optimum scale factor leads to the convnet uncovering a more accuratepose function.Where \u03b2 is a scale factor chosen to keep the expected valueof position and orientation errors to be approximately equal.The set of rotations lives on the unit sphere in quaternionspace. However the Euclidean loss function makes no effortto keep q on the unit sphere. We \ufb01nd, however, that duringtraining, q becomes close enough to q\u0302 such that the distinction between spherical distance and Euclidean distancebecomes insigni\ufb01cant. For simplicity, and to avoid hampering the optimization with unnecessary constraints, we choseto omit the spherical constraint.We found that training individual networks to regressposition and orientation separately performed poorly compared to when they were trained with full 6-DOF pose labels (\ufb01g. 2). With just position, or just orientation information, the convnet was not as effectively able to determine thefunction representing camera pose. We also experimentedwith branching the network lower down into two separatecomponents to regress position and orientation. However,we found that it too was less effective, for similar reasons:separating into distinct position and orientation regressorsdenies each the information necessary to factor out orientation from position, or vice versa.In our loss function (2) a balance \u03b2 must be struck between the orientation and translation penalties (\ufb01g. 2). Theyare highly coupled as they are regressed from the samemodel weights. We observed that the optimal \u03b2 was givenby the ratio between expected error of position and orientation at the end of training, not the beginning. We found \u03b2to be greater for outdoor scenes as position errors tended tobe relatively greater. Following this intuition we \ufb01ne tuned\u03b2 using grid search. For the indoor scenes it was between120 to 750 and outdoor scenes between 250 to 2000.We found it was important to randomly initialize the \ufb01nal position regressor layer so that the norm of the weightscorresponding to each position dimension was proportionalto that dimension\u2019s spatial extent.Classi\ufb01cation problems have a training example for every category. This is not possible for regression as theoutput is continuous and in\ufb01nite. Furthermore, other convnets that have been used for regression operate off verylarge datasets [25, 19]. For localization regression to workoff limited data we leverage the powerful representationslearned off these large classi\ufb01cation datasets by pretrainingthe weights on these datasets.3.2. ArchitectureFor the experiments in this paper we use a state ofthe art deep neural network architecture for classi\ufb01cation,GoogLeNet [24], as a basis for developing our pose regression network. GoogLeNet is a 22 layer convolutional network with six \u2018inception modules\u2019 and two additional intermediate classi\ufb01ers which are discarded at test time. Ourmodel is a slightly modi\ufb01ed version of GoogLeNet with 23layers (counting only the layers with trainable parameters).We modi\ufb01ed GoogLeNet as follows:\u2022 Replace all three softmax classi\ufb01ers with af\ufb01ne regressors. The softmax layers were removed and each \ufb01nalfully connected layer was modi\ufb01ed to output a posevector of 7-dimensions representing position (3) andorientation (4).\u2022 Insert another fully connected layer before the \ufb01nal regressor of feature size 2048. This was to form a localization feature vector which may then be explored forgeneralisation.\u2022 At test time we also normalize the quaternion orientation vector to unit length.We rescaled the input image so that the smallest dimensionwas 256 pixels before cropping to the 224x224 pixel input to the GoogLeNet convnet. The convnet was trained onrandom crops (which do not affect the camera pose). Attest time we evaluate it with both a single center crop andalso densely with 128 uniformly spaced crops of the inputimage, averaging the resulting pose vectors. With parallel GPU processing, this results in a computational time increase from 5ms to 95ms per image.2940\ftails can be found in table 6. Signi\ufb01cant urban clutter suchas pedestrians and vehicles were present and data was collected from many different points in time representing different lighting and weather conditions. Train and test images are taken from distinct walking paths and not sampledfrom the same trajectory making the regression challenging(see \ufb01g. 3). We release this dataset for public use and hopeto add scenes to this dataset as this project progresses.The dataset was generated using structure from motiontechniques [28] which we use as ground truth measurementsfor this paper. A Google LG Nexus 5 smartphone was usedby a pedestrian to take high de\ufb01nition video around eachscene. This video was subsampled in time at 2Hz to generate images to input to the SfM pipeline. There is a spacingof about 1m between each camera position.To test on indoor scenes we use the publically available7 Scenes dataset [20], with scenes shown in \ufb01g. 5. Thisdataset contains signi\ufb01cant variation in camera height andwas designed for RGB-D relocalization. It is extremelychallenging for purely visual relocalization using SIFT-likefeatures, as it contains many ambiguous textureless features.Figure 3: Magni\ufb01ed view of a sequence of training (green) andtesting (blue) cameras for King\u2019s College. We show the predictedcamera pose in red for each testing frame. The images show thetest image (top), the predicted view from our convnet overlaid inred on the input image (middle) and the nearest neighbour trainingimage overlaid in red on the input image (bottom). This shows oursystem can interpolate camera pose effectively in space betweentraining frames.We experimented with rescaling the original image todifferent sizes before cropping for training and testing.Scaling up the input is equivalent to cropping the input before downsampling to 256 pixels on one side. This increasesthe spatial resolution of the input pixels. We found that thisdoes not increase the localization performance, indicatingthat context and \ufb01eld of view is more important than resolution for relocalization.The PoseNet model was implemented using the Caffelibrary [10]. It was trained using stochastic gradient descent with a base learning rate of 10\u2212 5, reduced by 90%every 80 epochs and with momentum of 0.9. Using onehalf of a dual-GPU card (NVidia Titan Black), training tookan hour using a batch size of 75. For reasons of time, wedid not explore multi-GPU training, although it is reasonable to expect better results from using double the throughput and memory. We subtracted a separate image mean foreach scene as we found this to improve experimental performance.5. ExperimentsWe show that PoseNet is able to effectively localizeacross both the indoor 7 Scenes dataset and outdoor Cambridge Landmarks dataset in table 6. To validate that theconvnet is regressing pose beyond that of the training examples we show the performance for \ufb01nding the nearestneighbour representation in the training data from the feature vector produced by the localization convnet. As ourperformance exceeds this we conclude that the convnet issuccessfully able to regress pose beyond training examples(see \ufb01g. 3). We also compare our algorithm to the RGB-DSCoRe Forest algorithm [20].Fig. 7 shows cumulative histograms of localization error for two indoor and two outdoor scenes. We note thatalthough the SCoRe forest is generally more accurate, itrequires depth information, and uses higher-resolution imagery. The indoor dataset contains many ambiguous andtextureless features which make relocalization without thisdepth modality extremely dif\ufb01cult. We note our methodoften localizes the most dif\ufb01cult testing frames, above the95th percentile, more accurately than SCoRe across all thescenes. We also observe that dense cropping only gives amodest improvement in performance. It is most importantin scenes with signi\ufb01cant clutter like pedestrians and cars,for example King\u2019s College, Shop Fac\u0327ade and St Mary\u2019sChurch.We explored the robustness of this method beyond whatwas tested in the dataset with additional images from dusk,rain, fog, night and with motion blur and different cameraswith unknown intrinsics. Fig. 8 shows the convnet gener-4. DatasetDeep learning performs extremely well on large datasets,however producing these datasets is often expensive or verylabour intensive. We overcome this by leveraging structure from motion to autonomously generate training labels(camera poses). This reduces the human labour to justrecording the video of each scene.For this paper we release an outdoor urban localizationdataset, Cambridge Landmarks1 , with 5 scenes. This noveldataset provides data to train and test pose regression algorithms in a large scale outdoor urban setting. A bird\u2019s eyeview of the camera poses is shown in \ufb01g. 4 and further de1 Todownload the dataset please see our project webpage:mi.eng.cam.ac.uk/projects/relocalisation/2941\fKing\u2019s CollegeStreetOld HospitalShop Fac\u0327adeSt Mary\u2019s ChurchFigure 4: Map of dataset showing training frames (green), testing frames (blue) and their predicted camera pose (red). The testingsequences are distinct trajectories from the training sequences and each scene covers a very large spatial extent.Figure 5: 7 Scenes dataset example images from left to right; Chess, Fire, Heads, Of\ufb01ce, Pumpkin, Red Kitchen and Stairs.SceneKing\u2019s CollegeStreetOld HospitalShop Fac\u0327adeSt Mary\u2019s ChurchChessFireHeadsOf\ufb01cePumpkinRed KitchenStairs# FramesTrain Test12203433015 292389518223110314875304000 20002000 20001000 10006000 40004000 20007000 50002000 1000SpatialExtent (m)140 x 40m500 x 100m50 x 40m35 x 25m80 x 60m3 x 2 x 1m2.5 x 1 x 1m2 x 0.5 x 1m2.5 x 2 x 1.5m2.5 x 2 x 1m4 x 3 x 1.5m2.5 x 2 x 1.5mSCoRe Forest(Uses RGB-D)N/AN/AN/AN/AN/A0.03m, 0.66\u25e60.05m, 1.50\u25e60.06m, 5.50\u25e60.04m, 0.78\u25e60.04m, 0.68\u25e60.04m, 0.76\u25e60.32m, 1.32\u25e6Dist. to Conv.Nearest Neighbour3.34m, 2.96\u25e61.95m, 4.51\u25e65.38m, 4.51\u25e62.10m, 5.20\u25e64.48m, 5.65\u25e60.41m, 5.60\u25e60.54m, 7.77\u25e60.28m, 7.00\u25e60.49m, 6.02\u25e60.58m, 6.08\u25e60.58m, 5.65\u25e60.56m, 7.71\u25e6PoseNet1.92m, 2.70\u25e63.67m, 3.25\u25e62.31m, 2.69\u25e61.46m, 4.04\u25e62.65m, 4.24\u25e60.32m, 4.06\u25e60.47m, 7.33\u25e60.29m, 6.00\u25e60.48m, 3.84\u25e60.47m, 4.21\u25e60.59m, 4.32\u25e60.47m, 6.93\u25e6Dense PoseNet1.66m, 2.43\u25e62.96m, 3.00\u25e62.62m, 2.45\u25e61.41m, 3.59\u25e62.45m, 3.98\u25e60.32m, 3.30\u25e60.47m, 7.02\u25e60.30m, 6.09\u25e60.48m, 3.62\u25e60.49m, 4.06\u25e60.58m, 4.17\u25e60.48m, 6.54\u25e6Figure 6: Dataset details and results. We show median performance for PoseNet on all scenes, evaluated on a single 224x224 center cropand 128 uniformly separated dense crops. For comparison we plot the results from SCoRe Forest [20] which uses depth, therefore fails onoutdoor scenes. This system regresses pixel-wise world coordinates of the input image at much larger resolution. This requires a densedepth map for training and an extra RANSAC step to determine the camera\u2019s pose. Additionally, we compare to matching the nearestneighbour feature vector representation from PoseNet. This demonstrates our regression PoseNet performs better than a classi\ufb01er.11110.80.80.80.80.60.60.60.60.40.40.40.40.20.20.20012345678005Positional error (m)1015010.80.80.80.60.60.600.4Nearest Neighbour CNNPoseNetDense PoseNet0123456Angular error (degrees)(a) King\u2019s College7800246810121.5000.514161801.50.80.6SCORE ForestPoseNetDense PoseNetNearest Neighbour CNN0.2201Positional error (m)10.4Nearest Neighbour CNNPoseNetDense PoseNet0.21Positional error (m)10.20.5Positional error (m)10.40.200Angular error (degrees)5101520Angular error (degrees)(b) St Mary\u2019s Church(c) Pumpkin25SCORE ForestPoseNetDense PoseNetNearest Neighbour CNN0.40.2300024681012141618Angular error (degrees)(d) StairsFigure 7: Localization performance. These \ufb01gures show our localization accuracy for both position and orientation as a cumulative histogram of errors for the entire testing set. The regression convnet outperforms the nearest neighbour feature matching which demonstrateswe regress \ufb01ner resolution results than given by training. Comparing to the RGB-D SCoRe Forest approach shows that our method iscompetitive, but outperformed by a more expensive depth approach. Our method does perform better on the hardest few frames, above the95th percentile, with our worst error lower than the worst error from the SCoRe approach.294220\f(a) Relocalization with increasing levels of motion blur. The system is able to recognize the pose as high level features such as the contouroutline still exist. Blurring the landmark increases apparent contour size and the system believes it is closer.(b) Relocalization under dif\ufb01cult dusk and night lighting conditions. In the dusk sequences, the landmark is silhouetted against the backdrophowever again the convnet seems to recognize the contours and estimate pose.(c) Relocalization with different weatherconditions. PoseNet is able to effectivelyestimate pose in fog and rain.(d) Relocalization with signi\ufb01cant people, vehicles and other dynamic objects.(e) Relocalization with unknown camera intrinsics: SLR with focal length45mm (left), and iPhone 4S with focal length 35mm (right) compared to thedataset\u2019s camera which had a focal lengthof 30mm.Figure 8: Robustness to challenging real life situations. Registration with point based techniques such as SIFT fails in examples (a-c),therefore ground truth measurements are not available. None of these types of challenges were seen during training. As convnets are ableto understand objects and contours they are still successful at estimating pose from the building\u2019s contour in the silhouetted examples (b)or even under extreme motion blur (a). Many of these quasi invariances were enhanced by pretraining from the scenes dataset.2943\fTest errorAlexNet pretrained on PlacesGoogLeNet with random initialisationGoogLeNet pretrained on ImageNetGoogLeNet pretrained on PlacesGoogLeNet pretrained on Places, then another indoor landmark020406080100Training epochsFigure 9: Robustness to a decreasing training baseline for theKing\u2019s College scene. Our system exhibits graceful decline in performance as fewer training samples are used.ally handles these challenges well. SfM with SIFT fails inall these cases so we were not able to generate a groundtruth camera pose, however we infer the accuracy by viewing the 3D reconstruction from the predicted camera pose,and overlaying this onto the input image.5.1. Robustness against training image spacingWe demonstrate in \ufb01g. 9 that, for an outdoor scale scene,we gain little by spacing the training images more closelythan 4m. The system is robust to very large spatial separation between training images, achieving reasonable performance even with only a few dozen training samples. Thepose accuracy deteriorates gracefully with increased training image spacing, whereas SIFT-based SfM sharply failsafter a certain threshold as it requires a small baseline [15].5.2. Importance of transfer learningIn general convnets require large amounts of trainingdata. We sidestep this problem by starting our pose training from a network pretrained on giant datasets such as ImageNet and Places. Similar to what has been demonstratedfor classi\ufb01cation tasks, \ufb01g. 10 shows how transfer learningcan be utilised effectively between classi\ufb01cation and complicated regression tasks. Such \u2018transfer learning\u2019 has beendemonstrated elsewhere for training classi\ufb01ers [18, 17, 2],but here we demonstrate transfer learning from classi\ufb01cation to the qualitatively different task of pose regression. Itis not immediately obvious that a network trained to output pose-invariant classi\ufb01cation labels would be suitable asa starting point for a pose regressor. We \ufb01nd, however, thatthis is not a problem in practice. A possible explanation isthat, in order for its output to be invariant to pose, the classi\ufb01er network must keep track of pose, to better factor itseffects away from identity cues. This would agree with ourown \ufb01ndings that a network trained to output position andorientation outperforms a network trained to output only po-Figure 10: Importance of transfer learning. Shows how pretraining on large datasets gives an increase in both performanceand training speed.sition. By preserving orientation information in the intermediate representations, it is better able to factor the effectsof orientation out of the \ufb01nal position estimation. Transfer learning gives not only a large improvement in trainingspeed, but also end performance.The relevance of data is also important. In \ufb01g. 10 thePlaces and ImageNet curves initially have the same performance. However, ultimately the Places pretraining performs better due to being a more relevant dataset to thislocalization task.5.3. Visualising features relevant to poseFig. 11 shows example saliency maps produced byPoseNet. The saliency map, as used in [21], is the magnitude of the gradient of the loss function with respect tothe pixel intensities. This uses the sensitivity of the posewith respect to the pixels as an indicator of how importantthe convnet considers different parts of the image.These results show that the strongest response is observed from higher-level features such as windows andspires. However a more surprising result is that PoseNet isalso very sensitive to large textureless patches such as road,grass and sky. These textureless patches may be more informative than the highest responding points because the effectof a group of pixels on the pose variable is the sum of thesaliency map values over that group of pixels. This evidencepoints to the net being able to localize off information fromthese textureless surfaces, something which interest-pointbased features such as SIFT or SURF fail to do.The last observation is that PoseNet has an attenuated response to people and other noisy objects, effectively masking them. These objects are dynamic, and the convnet hasidenti\ufb01ed them as not appropriate for localization.5.4. Viewing the internal representationt-SNE [26] is an algorithm for embedding highdimensional data in a low dimensional space, in a way thattries to preserve Euclidean distances. It is often used, aswe do here, to visualize high-dimensional feature vectors in2944\fFigure 11: Saliency maps. This \ufb01gure shows the saliency map superimposed on the input image. The saliency maps suggest that theconvnet exploits not only distinctive point features (a\u0300 la SIFT), but also large textureless patches, which can be as informative, if notmore so, to the pose. This, combined with a tendency to disregard dynamic objects such as pedestrians, enables it to perform well underchallenging circumstances. (Best viewed electronically.)12010(a)(b)(c)8Memory (GB)Time (seconds)100806040450MB5ms20040060080010001200Number of training samplesFigure 12: Feature vector visualisation. t-SNE visualisation ofthe feature vectors from a video sequence traversing an outdoorscene (King\u2019s College) in a straight line. Colour represents time.The feature representations are generated from the convnet withweights trained on Places (a), Places then another outdoor scene,St Mary\u2019s Church (b), Places then this outdoor scene, King\u2019s College (c). Despite (a,b) not being trained on this scene, these visualizations suggest that it is possible to compute the pose as a simple,if non-linear, function of these representations.622000SIFT Structure from MotionNearest Neighbour CNNPoseNet0020040060080010001200Number of training samplesFigure 13: Implementation ef\ufb01ciency. Experimental speed andmemory use of the convnet regression, nearest neighbour convnetfeature vector and SIFT relocalization methods.pute each pose, compared to the gigabytes and minutes formetric localization with SIFT. These values are independentof the number of training samples in the system while metric localization scales O(n2 ) with training data size [28].For comparison matching to the convnet nearest neighbouris also shown. This requires storing feature vectors for eachtraining frame, then perform a linear search to \ufb01nd the nearest neighbour for a given test frame.two dimensions. In \ufb01g. 12 we apply t-SNE to the featurevectors computed from a sequence of video frames takenby a pedestrian. As these \ufb01gures show, the feature vectorsare a function that smoothly varies with, and is largely oneto-one with, pose. This \u2018pose manifold\u2019 can be observednot only on networks trained on other scenes, but also networks trained on classi\ufb01cation image sets without pose labels. This further suggests that classi\ufb01cation convnets preserve pose information up to the \ufb01nal layer, regardless ofwhether it\u2019s expressed in the output. However, the mapping from feature vector to pose becomes more complicatedfor networks not trained on pose data. Furthermore, as thismanifold exists on scenes that the convnet was not trainedon, the convnet must learn some generic representation ofthe relationship between landmarks, geometry and cameramotion. This demonstrates that the feature vector that isproduced from regression is able to generalize to other tasksin the same way as classi\ufb01cation convnets.6. ConclusionsWe present, to our knowledge, the \ufb01rst application ofdeep convolutional neural networks to end-to-end 6-DOFcamera pose localization. We have demonstrated that onecan sidestep the need for millions of training images by useof transfer learning from networks trained as classi\ufb01ers. Weshowed that such networks preserve ample pose information in their feature vectors, despite being trained to producepose-invariant outputs. Our method tolerates large baselinesthat cause SIFT-based localizers to fail sharply.In future work, we aim to pursue further uses of multiview geometry as a source of training data for deep poseregressors, and explore probabilistic extensions to this algorithm [12]. It is obvious that a \ufb01nite neural network has anupper bound on the physical area that it can learn to localizewithin. We leave \ufb01nding this limit to future work.5.5. System ef\ufb01ciencyFig. 13 compares system performance of PoseNet on amodern desktop computer. Our network is very scalable, asit only takes 50 MB to store the weights, and 5ms to com2945\fReferences[1] S. Agarwal, Y. Furukawa, N. Snavely, I. Simon, B. Curless,S. M. Seitz, and R. Szeliski. Building rome in a day. Communications of the ACM, 54(10):105\u2013112, 2011.[2] Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. PatternAnalysis and Machine Intelligence, IEEE Transactions on,35(8):1798\u20131828, 2013.[3] A. Bergamo, S. N. Sinha, and L. Torresani. Leveraging structure from motion to learn discriminative codebooks for scalable landmark classi\ufb01cation. In Computer Vision and PatternRecognition (CVPR), 2013 IEEE Conference on, pages 763\u2013770. IEEE, 2013.[4] M. Cummins and P. Newman. FAB-MAP: Probabilistic localization and mapping in the space of appearance. TheInternational Journal of Robotics Research, 27(6):647\u2013665,2008.[5] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. FeiFei. Imagenet: A large-scale hierarchical image database.In Computer Vision and Pattern Recognition, 2009. CVPR2009. IEEE Conference on, pages 248\u2013255. IEEE, 2009.[6] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprintarXiv:1310.1531, 2013.[7] J. Engel, T. Scho\u0308ps, and D. Cremers. LSD-SLAM: Largescale direct monocular slam. In Computer Vision\u2013ECCV2014, pages 834\u2013849. Springer, 2014.[8] Y. Furukawa, B. Curless, S. M. Seitz, and R. Szeliski. Towards internet-scale multi-view stereo. In Computer Visionand Pattern Recognition (CVPR), 2010 IEEE Conference on,pages 1434\u20131441. IEEE, 2010.[9] Q. Hao, R. Cai, Z. Li, L. Zhang, Y. Pang, and F. Wu. 3dvisual phrases for landmark recognition. In Computer Visionand Pattern Recognition (CVPR), 2012 IEEE Conference on,pages 3594\u20133601. IEEE, 2012.[10] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprintarXiv:1408.5093, 2014.[11] M. Kaess, H. Johannsson, R. Roberts, V. Ila, J. J. Leonard,and F. Dellaert. iSAM2: Incremental smoothing and mapping using the bayes tree. The International Journal ofRobotics Research, page 0278364911430419, 2011.[12] A. Kendall and R. Cipolla. Modelling uncertainty indeep learning for camera relocalization. arXiv preprintarXiv:1509.05909, 2015.[13] G. Klein and D. Murray. Parallel tracking and mapping forsmall ar workspaces. In Mixed and Augmented Reality, 2007.ISMAR 2007. 6th IEEE and ACM International Symposiumon, pages 225\u2013234. IEEE, 2007.[14] Y. Li, N. Snavely, D. Huttenlocher, and P. Fua. Worldwidepose estimation using 3d point clouds. In Computer Vision\u2013ECCV 2012, pages 15\u201329. Springer, 2012.[15] D. G. Lowe.Distinctive image features from scaleinvariant keypoints. International journal of computer vision, 60(2):91\u2013110, 2004.[16] R. A. Newcombe, S. J. Lovegrove, and A. J. Davison.DTAM: Dense tracking and mapping in real-time. In Computer Vision (ICCV), 2011 IEEE International Conferenceon, pages 2320\u20132327. IEEE, 2011.[17] M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Learningand transferring mid-level image representations using convolutional neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages1717\u20131724. IEEE, 2014.[18] A. S. Razavian, H. Azizpour, J. Sullivan, and S. Carlsson.Cnn features off-the-shelf: an astounding baseline for recognition. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on, pages 512\u2013519.IEEE, 2014.[19] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,and Y. LeCun. Overfeat: Integrated recognition, localizationand detection using convolutional networks. arXiv preprintarXiv:1312.6229, 2013.[20] J. Shotton, B. Glocker, C. Zach, S. Izadi, A. Criminisi, andA. Fitzgibbon. Scene coordinate regression forests for camera relocalization in RGB-D images. In Computer Visionand Pattern Recognition (CVPR), 2013 IEEE Conference on,pages 2930\u20132937. IEEE, 2013.[21] K. Simonyan, A. Vedaldi, and A. Zisserman. Deep insideconvolutional networks: Visualising image classi\ufb01cationmodels and saliency maps. arXiv preprint arXiv:1312.6034,2013.[22] N. Snavely, S. M. Seitz, and R. Szeliski. Photo tourism:exploring photo collections in 3d. In ACM transactions ongraphics (TOG), volume 25, pages 835\u2013846. ACM, 2006.[23] N. Su\u0308nderhauf, F. Dayoub, S. Shirazi, B. Upcroft, andM. Milford. On the performance of convnet features forplace recognition. arXiv preprint arXiv:1501.04158, 2015.[24] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. arXiv preprintarXiv:1409.4842, 2014.[25] A. Toshev and C. Szegedy. Deeppose: Human pose estimation via deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages1653\u20131660. IEEE, 2014.[26] L. Van der Maaten and G. Hinton. Visualizing data usingt-SNE. Journal of Machine Learning Research, 9(25792605):85, 2008.[27] J. Wang, H. Zha, and R. Cipolla. Coarse-to-\ufb01ne vision-basedlocalization by indexing scale-invariant features. Systems,Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, 36(2):413\u2013422, 2006.[28] C. Wu. Towards linear-time incremental structure from motion. In 3D Vision-3DV 2013, 2013 International Conferenceon, pages 127\u2013134. IEEE, 2013.[29] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva.Learning deep features for scene recognition using placesdatabase. In Advances in Neural Information Processing Systems, pages 487\u2013495, 2014.2946\f", "1134IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014Learning with Augmented Features forSupervised and Semi-SupervisedHeterogeneous Domain AdaptationWen Li, Student Member, IEEE, Lixin Duan, Dong Xu, Senior Member, IEEE, and Ivor W. TsangAbstract\u2014In this paper, we study the heterogeneous domain adaptation (HDA) problem, in which the data from the source domainand the target domain are represented by heterogeneous features with different dimensions. By introducing two different projectionmatrices, we first transform the data from two domains into a common subspace such that the similarity between samples acrossdifferent domains can be measured. We then propose a new feature mapping function for each domain, which augments thetransformed samples with their original features and zeros. Existing supervised learning methods (e.g., SVM and SVR) can be readilyemployed by incorporating our newly proposed augmented feature representations for supervised HDA. As a showcase, we proposea novel method called Heterogeneous Feature Augmentation (HFA) based on SVM. We show that the proposed formulation can beequivalently derived as a standard Multiple Kernel Learning (MKL) problem, which is convex and thus the global solution can beguaranteed. To additionally utilize the unlabeled data in the target domain, we further propose the semi-supervised HFA (SHFA)which can simultaneously learn the target classifier as well as infer the labels of unlabeled target samples. Comprehensiveexperiments on three different applications clearly demonstrate that our SHFA and HFA outperform the existing HDA methods.Index Terms\u2014Heterogeneous domain adaptation, domain adaptation, transfer learning, augmented features1I NTRODUCTIONIN real-world applications, it is often expensive and timeconsuming to collect the labeled data. Domain adaptation, as a new machine learning strategy, has attractedgrowing attention because it can learn robust classifierswith very few or even no labeled data from the targetdomain by leveraging a large amount of labeled data fromother existing domains (a.k.a., source/auxiliary domains).Domain adaptation methods have been successfullyused for different research fields such as natural languageprocessing and computer vision [1]\u2013[7]. According to thesupervision information in the target domain, the domainadaptation methods can generally be divided into three categories: supervised domain adaptation by only using thelabeled data in the target domain, semi-supervised domainadaptation by using both the labeled and unlabeled datain the target domain, and unsupervised domain adaptation by only using unlabeled data in the target domain.\u2022 W. Li, and D. Xu are with the School of Computer Engineering, NanyangTechnological University, Singapore 639798.E-mail: wli1@e.ntu.edu.sg; dongxu@ntu.edu.sg.\u2022 L. Duan is with the Institute for Infocomm Research, Singapore 138632.E-mail: lxduan@gmail.com.\u2022 I. W. Tsang is with the Center for Quantum Computation & IntelligentSystems, University of Technology, Sydney, Australia.E-mail:ivor.tsang@gmail.com.Manuscript received 21 Jan. 2013; revised 15 June 2013; accepted 2 Aug.2013. Date of publication 28 Aug. 2013; date of current version 12 May2014.Recommended for acceptance by K. Borgwardt.For information on obtaining reprints of this article, please send e-mail to:reprints@ieee.org, and reference the Digital Object Identifier below.Digital Object Identifier 10.1109/TPAMI.2013.167However, most existing methods assume that the data fromdifferent domains are represented by the same type offeatures with the same dimension. Thus, they cannot dealwith the problem where the dimensions of data from thesource and target domains are different, which is known asheterogeneous domain adaptation (HDA) [8], [9].In the literature, a few approaches have been proposedfor the HDA problem. To discover the connection betweendifferent features, some work exploited an auxiliary datasetwhich encodes the correspondence between different typesof features. Dai et al. [8] proposed to learn a feature translator between two features from two domains, which ismodeled by the conditional probability of one feature giventhe other one. Such feature translator is learnt from anauxiliary dataset which contains the co-occurrence of thesetwo types of features. A similar assumption was also usedin [9], [10] for text-aid image clustering and classification.Others proposed to use an explicit feature correspondence,for example, the bilingual dictionary in cross-language textclassification task. Based on the structural correspondencelearning (SCL) [1], two methods [11], [12] were recently proposed to extract the so-called pivot features from the sourceand target domains, which are specifically designed for thecross-language text classification task. These pivot featuresare constructed by text words which have explicit semanticmeanings. They either directly translated the pivot featuresfrom one language to the other or modified the originalSCL to select pairs of pivot words from different languages.However, it is unclear how to build such correspondencefor more general HDA tasks such as the object recognitiontask where only the low-level visual features are provided.c 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.0162-8828 \u0002See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fLI ET AL.: LEARNING WITH AUGMENTED FEATURES1135Fig. 1. Samples from different domains are represented by different features, where red crosses, blue strips, orange triangles and green circles denote source positive samples, source negative samples, target positive samples and target negative samples, respectively. By using twoprojection matrices P and Q, we transform the heterogenous samples from two domains into an augmented feature space.For more general HDA tasks, Shi et al. [13] proposed amethod called Heterogeneous Spectral Mapping (HeMap)to discover a common feature subspace by learning two feature mapping matrices as well as the optimal projection ofthe data from both domains. Harel and Mannor [14] learntrotation matrices to match source data distributions to thatof the target domain. Wang and Mahadevan [15] used theclass labels of training data to learn the manifold alignmentby simultaneously maximizing the intra-domain similarity and the inter-domain dissimilarity. By kernelizing themethod in [16], Kulis et al. [17] proposed to learn an asymmetric kernel transformation to transfer feature knowledgebetween the data from the source and target domains.However, these existing HDA methods were designed forthe supervised learning scenario. For these methods, it isunclear how to learn the projection matrices or transformation metric by utilizing the abundant unlabeled datain the target domain which is usually available in manyapplications.In this work, we first propose a new method calledHeterogeneous Feature Augmentation (HFA) for supervised heterogeneous domain adaptation. As shown inFig. 1, considering the data from different domains are represented by features with different dimensions, we firsttransform the data from the source and target domainsinto a common subspace by using two different projection matrices P and Q. Then, we propose two new featuremapping functions to augment the transformed data withtheir original features and zeros. With the new augmentedfeature representations, we propose to learn the projection matrices P and Q by using the standard SVM withthe hinge loss function in a linear case. We also describeits kernelization in order to efficiently cope with the datawith very high dimension. To simplify the nontrivial optimization problem in HFA, we introduce an intermediatevariable H called as a transformation metric to combineP and Q. In our preliminary work [18], we proposed analternating optimization algorithm to iteratively learn anindividual transformation metric H and a classifier for eachclass. However, the global convergence remains unclear andthere may be pre-mature convergence. In this work, weequivalently reformulate it into a convex optimization problem by decomposing H into a linear combination of a setof rank-one positive semi-definite (PSD) matrices, whichshares a similar formulation with the well-known MultipleKernel Learning (MKL) problem [19]. Therefore, the globalsolution can be obtained easily by using the existing MKLsolvers.Moreover, we further extend our HFA to semisupervised HFA or SHFA in short by additionally utilizingthe unlabeled data in the target domain. While learning thetransformation metric H, we also infer the labels for theunlabeled target samples. Considering we need to solvea non-trivial mixed integer programming problem wheninferring the labels of unlabeled target training data, wefirst relax the objective of SHFA into a problem of findingthe optimal linear combination of all possible label candidates. Then we also use the linear combination of theserank-one PSD matrices to replace H as in HFA. Finally,we further rewrite the problem as a convex MKL problemwhich can be readily solved by existing MKL solvers.The remainder of this paper is organized as follows.The proposed HFA method and SHFA are introduced inSection 2 and Section 3, respectively. Extensive experimental results are presented in Section 4, followed byconclusions and future work in Section 5.2H ETEROGENEOUS F EATURE AUGMENTATIONIn the remainder of this paper, we use the superscript \u0003 todenote the transpose of a vector or a matrix. We define Inas the n \u00d7 n identity matrix and On\u00d7m as the n \u00d7 m matrixof all zeros. We also define 0n , 1n \u2208 Rn as the n \u00d7 1 columnvectors of all zeros and all ones, respectively. For simplicity,we also use I, O, 0 and 1 instead of In , On\u00d7m , 0n and 1nwhen the dimension is obvious. The \u0002p -norm of a vector\u00041\u0002\u0003p pna = [a1 , . . . , an ]\u0003 is defined as \u0005a\u0005p =a. We alsoi=1 iuse \u0005a\u0005 to denote the \u00022 -norm. The inequality a \u2264 b meansthat ai \u2264 bi for i = 1, . . . , n. Moreover, a \u25e6 b denotes theelement-wise product between the vectors a and b, i.e., a \u25e6b = [a1 b1 , . . . , an bn ]\u0003 . And H \b 0 means that H is a positivesemi-definite (PSD) matrix.In this work, we assume there are only one sourcedomain and one target domain. We are providedwith\u0005ns} from thea set of labeled training samples { (xsi , ysi )\u0005i=1source domain as\u0005nt well as a limited number of labeled} from the target domain, wheresamples { (xti , yti )\u0005i=1ysi and yti are the labels of the samples xsi and xti ,respectively, and ysi , yti \u2208 {1, \u22121}. The dimensions ofxsi and xti are ds and dt , respectively. Note that inthe HDA problem, ds = dt . We also define Xs =\f1136IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014[xs1 , . . . , xsns ] \u2208 Rds \u00d7ns and Xt = [xt1 , . . . , xtnt ] \u2208 Rdt \u00d7ntas the data matrices for the source and target domains,respectively.Formally, we present the formulation of our HFA methodas follows:min min2.1 Heterogeneous Feature AugmentationDaume III [3] proposed Feature Replication (FR) to augment the original feature space Rd into a larger spaceR3d by replicating the source and target data for homogeneous domain adaptation. Specifically, for any data pointx \u2208 Rd , the feature mapping functions \u03d5s and \u03d5t for thesource and target domains are defined as \u03d5s (x) = [x\u0003 , x\u0003 , 0\u0003d ]\u0003and \u03d5t (x) = [x\u0003 , 0\u0003d , x\u0003 ]\u0003 . Note that it is not meaningful todirectly use the method in [3] for the HDA task by simplypadding zeros to make the dimensions of the data from twodomains become the same, because there would be no correspondences between the heterogeneous features in thiscase.To effectively utilize the heterogeneous features fromtwo domains, we first introduce a common subspace forthe source and target data so that the heterogeneous features from two domains can be compared. We define thecommon subspace as Rdc , and any source sample xs andtarget sample xt can be projected onto it by using two projection matrices P \u2208 Rdc \u00d7ds and Q \u2208 Rdc \u00d7dt , respectively.Note that promising results have been shown by incorporating the original features into the augmented features [3]to enhance the similarities between data from the samedomain. Motivated by [3], we also incorporate the original features in this work and then augment any sourceand target domain samples xs \u2208 Rds and xt \u2208 Rdt byusing the augmented feature mapping functions \u03d5s and \u03d5tas follows:\u23a1 s\u23a4\u23a1 t\u23a4PxQx(1)\u03d5s (xs ) = \u23a3 xs \u23a6 and \u03d5t (xt ) = \u23a3 0ds \u23a6 .0d txtAfter introducing P and Q, the data from two domainscan be readily compared in the common subspace. It isworth mentioning that our newly proposed augmented features for the source and target samples in (1) can be readilyincorporated into different methods (e.g., SVM and SVR),making these methods applicable for the HDA problem.Specifically, we use the standard SVM formulationwith the hinge loss as a showcase for the supervisedheterogeneous domain adaptation, which is referred asHeterogeneous Feature Augmentation (HFA). To additionally utilize the unlabeled data in the target domain, we alsodevelop the semi-supervised HFA (SHFA) method based on\u03c1-SVM with the squared hinge loss for the semi-supervisedheterogeneous domain adaptation task. Details of the twomethods are introduced below.2.2 Proposed MethodWe define the feature weight vector w = [w\u0003c , w\u0003s , w\u0003t ]\u0003 \u2208Rdc +ds +dt for the augmented feature space, where wc \u2208Rdc , ws \u2208 Rds and wt \u2208 Rdt are also the weight vectorsdefined for the common subspace, the source domain andthe target domain, respectively. We then propose to learnthe projection matrices P and Q as well as the weight vector w by minimizing the structural risk functional of SVM.P,Q w,b,\u03be s ,\u03be ti is.t.1\u0005w\u00052 + C2nsnt\u03beis +\u03beit ,(2)i=1i=1ysi (w\u0003 \u03d5s (xsi ) + b) \u2265 1 \u2212 \u03beis , \u03beis \u2265 0;yti (w\u0003 \u03d5t (xti ) + b) \u2265 1 \u2212 \u03beit , \u03beit \u2265 0;\u0005P\u00052F \u2264 \u03bbp , \u0005Q\u00052F \u2264 \u03bbq ,(3)(4)where C > 0 is a tradeoff parameter which balances themodel complexity and the empirical losses on the trainingsamples from two domains, and \u03bbp , \u03bbq > 0 are predefined parameters to control the complexities of P and Q,respectively.To solve (2), we first derive the dual form of the inneroptimization problem in (2). Specifically, we introduce dualstvariables {\u03b1is |ni=1} and {\u03b1it |ni=1} for the constraints in (3)and (4), respectively. By setting the derivatives of theLagrangian of (2) with respect to w, b, \u03beis and \u03beit to zeros, weobtainKarush-Kuhn-Tucker (KKT) conditions as: w =\u0003ns sthes \u03d5 (xs ) + \u0003nt \u03b1 t yt \u03d5 (xt ), \u0003ns \u03b1 s ys + \u0003nt \u03b1 t yt = 0\u03b1ysi=1 i ii=1 i i t ii=1 i ii=1 i iiand 0 \u2264 \u03b1is , \u03b1it \u2264 C. With the KKT conditions, we arrive atthe dual problem as follows:1min max 1\u0003 \u03b1 \u2212 (\u03b1 \u25e6 y)\u0003 KP,Q (\u03b1 \u25e6 y),\u03b12P,Qs.t. y\u0003 \u03b1 = 0, 0 \u2264 \u03b1 \u2264 C1,(5)\u0005P\u00052F \u2264 \u03bbp , \u0005Q\u00052F \u2264 \u03bbq ,where \u03b1 = [\u03b11s , . . . , \u03b1ns s , \u03b11t , . . . , \u03b1nt t ]\u0003 \u2208 Rns +nt is a vectorof the dual variables, y = [y\u0003s , y\u0003t ]\u0003 \u2208 {+1, \u22121}ns +nt is thelabel vector of all training samples, ys = [ys1 , . . . , ysns ]\u0003 \u2208{+1, \u22121}ns is the label vector of samples from the sourcedomain, yt = [yt1 , . . . , ytnt ]\u0003 \u2208 {+1, \u22121}nt is the label vector of samples from the target\u000e domain, and KP,Q =X\u0003s (Ids + P\u0003 P)XsX\u0003s P\u0003 QXt\u2208 R(ns +nt )\u00d7(ns +nt ) is theX\u0003t Q\u0003 PXsX\u0003t (Idt + Q\u0003 Q)Xtderived kernel matrix for the samples from both domains.To solve the optimization problem in (5), the dimension of the common subspace (i.e., dc ) must be givenbeforehand. However, it is usually nontrivial to determinethe optimal dc . Observing that in the kernel matrix KP,Qin (5), the projection matrices P and Q always appearin the forms of P\u0003 P, P\u0003 Q, Q\u0003 P and Q\u0003 Q, we then replacethese multiplications by defining an intermediate variableH = [P, Q]\u0003 [P, Q] \u2208 R(ds +dt )\u00d7(ds +dt ) . Obviously, H is positivesemidefinite, i.e., H \b 0. With the introduction of H, we canthrow away the parameter dc . Moreover, the common subspace becomes latent, because we do not need to explicitlysolve for P and Q any more.With the definition of H, we reformulate the optimization problem in (5) as follows:1min max 1\u0003 \u03b1 \u2212 (\u03b1 \u25e6 y)\u0003 KH (\u03b1 \u25e6 y),\u03b1H\b02s.t. y\u0003 \u03b1 = 0, 0 \u2264 \u03b1 \u2264 C1,trace(H) \u2264 \u03bb,where KH=X\u0003 (H + I)X, XR(ds +dt )\u00d7(ns +nt ) and \u03bb = \u03bbp + \u03bbq .=Xs Ods \u00d7ntOdt \u00d7ns Xt(6)\u000e\u2208\fLI ET AL.: LEARNING WITH AUGMENTED FEATURESThus far, we have successfully converted our originalHDA problem, which learns two projection matrices P andQ, into a new problem of learning a transformation metric H.We emphasize that this new problem has two main advantages: i) it avoids determining the optimal dimension of thecommon subspace beforehand; and ii) as the common subspace becomes latent after the introduction of H, we onlyneed to optimize \u03b1 and H for our proposed method.However, there are still two major limitations for the current formulation of HFA in (6): i) The transformation metricH is linear, which may not be effective for some recognitiontasks. ii) The size of H grows with the dimensions of thesource and target data (i.e., ds and dt ). It is computationally expensive to learn the linear metric H in (6) for somereal-world applications (e.g., text categorization) with veryhigh dimensional data. In order to effectively deal with highdimensional data, inspired by [17], in the next subsectionwe will apply kernelization to the data from the source andtarget domains and show that (6) can be solved in a kernelspace by learning a nonlinear transformation metric withits size independent from the feature dimensions.2.3 Nonlinear Feature TransformationNote that the size of the linear transformation metric His related to the feature dimension, and thus it is computationally expensive for very high dimension data. In thissubsection, we will show that by applying kernelization,the transformation metric is independent from the featuredimension and grows only with respect to the number oftraining data from both domains.Let us denote the kernel on the source domain samplesas Ks = \b\u0003s \bs \u2208 Rns \u00d7ns where \bs = [\u03c6s (xs1 ), . . . , \u03c6s (xsns )]and \u03c6s (\u00b7) is the nonlinear feature mapping function inducedby Ks . Similarly, we denote the kernel on the targetdomain samples as Kt = \b\u0003t \bt \u2208 Rnt \u00d7nt where \bt =[\u03c6t (xt1 ), . . . , \u03c6t (xtnt )] and \u03c6t (\u00b7) is the nonlinear feature mapping function induced by Kt . As in the linear case, wecan correspondingly define the augmented features \u03d5s (xs )and \u03d5t (xt ) in (1) for the nonlinear features of two domainsby replacing xs and xt with \u03c6s (xs ) and \u03c6t (xt ), respectively. Denoting the dimensions of the nonlinear features\u03c6s (xs ) and \u03c6t (xt ) as d\u0303s and d\u0303t , we can also derive anoptimization problem as in (6) to solve a transformationmetric H \u2208 R(d\u0303s +d\u0303t )\u00d7(d\u0303s +d\u0303t ) which maps the different nonlinear features from two domains into a common featurespace. Correspondingly,\u000fthe kernel can\u0010 be written as KH =\bOsd\u0303s \u00d7nt \u2208 R(d\u0303s +d\u0303t )\u00d7(ns +nt ) .\b\u0003 (H + I)\b where \b =Od\u0303t \u00d7ns \btHowever, we usually do not know about the explicitforms of the nonlinear feature mapping functions \u03c6s (\u00b7) and\u03c6t (\u00b7) and hence the dimensions of H cannot be determined.Even in some special cases that the explicit forms of \u03c6s (\u00b7)and \u03c6t (\u00b7) can be derived, the dimensions of the nonlinearfeatures, i.e. d\u0303s and d\u0303t , are usually very high and hence it isvery computationally expensive to solve H.Inspired by [17], we define a nonlinear transformathat H =tion matrix H\u0303 \u2208 R(ns +nt )\u00d7(ns +nt ) which satisfies\u000eKs Ons \u00d7nt\u2212 12\u2212 12 \u0003(n+nst )\u00d7(ns +nt )\u2208R\bK H\u0303K \b where K =Ont \u00d7ns Kt1and K 2 is the symmetric square root of K. Now we show1137that the kernelization version of (6) can be derived as anoptimization problem on H\u0303 rather than H.It is easy to verify that trace(H\u0303) = trace(H) \u2264 \u03bb.Moreover, the kernel matrix can be written as KH =11\b\u0003 (H + I)\b = K 2 (H\u0303 + I)K 2 = KH\u0303 . Then we arrive at theformulation of our proposed HFA method after applyingkernelization as follows:1(7)min max 1\u0003 \u03b1 \u2212 (\u03b1 \u25e6 y)\u0003 KH\u0303 (\u03b1 \u25e6 y),\u03b12H\u0303\b0s.t. y\u0003 \u03b1 = 0, 0 \u2264 \u03b1 \u2264 C1,trace(H\u0303) \u2264 \u03bb.Hence, we optimize H\u0303 in (7) rather than directly solvingH. Note the size of H\u0303 is independent from the featuredimensions d\u0303s and d\u0303t .Intuitively, one can observe that the main differencesbetween the formulations of the nonlinear HFA in (7) and1the linear HFA in (6) are: i) we use K 2 in the nonlinear HFAto replace X in the linear case; ii) we also define a new nonlinear transformation metric H\u0303 which only depends on thenumbers of training samples ns and nt instead of using Hwhich depends on the feature dimensions ds and dt . Despitethe above differences, the two formulations share the sameform from the perspective of optimization. Therefore, wewill only discuss the nonlinear case in the remainder ofthis paper while the linear case can be similarly derived by1replacing K 2 \u2208 R(ns +nt )\u00d7(ns +nt ) and H\u0303 \u2208 R(ns +nt )\u00d7(ns +nt ) withX \u2208 R(ds +dt )\u00d7(ns +nt ) and H \u2208 R(ds +dt )\u00d7(ds +dt ) , respectively. Wealso use H instead of H\u0303 below for better presentation.2.4 A Convex FormulationTo solve the optimization problem in (7), in our preliminary work [18], we proposed an alternating optimizationapproach in which we iteratively solve an SVM problem with respect to \u03b1 and a semi-definite programming(SDP) problem with respect to H. However, the global convergence remains unclear and there may be pre-matureconvergence. In this subsection, we show that (7) can beequivalently reformulated as a convex MKL problem sothat the global solution can be guaranteed by using theexisting MKL solvers [19].As pointed in [19], the Ivanov regularization can bereplaced with some Tikhonov regularization and vice versewith the appropriate choice of regularization parameter,which means we can write the trace norm regularizationin (7) either as a constraint or as a regularizer term inthe objective function. Formally, let us denote \u03bc(H) =max\u03b1\u2208A 1\u0003 \u03b1 \u2212 12 (\u03b1 \u25e6 y)\u0003 KH (\u03b1 \u25e6 y) where A = {\u03b1|y\u0003 \u03b1 = 0, 0 \u2264\u03b1 \u2264 C1}, then the problem in (7) can also be reformulatedas:min \u03bc(H) + \u03b7 trace(H),H\b0(8)where \u03b7 is a tradeoff parameter. By properly setting \u03b7, theabove optimization problem yields the same solution as theoriginal problem in (7) [19].To avoid solving the non-trivial SDP problem as in [18],we propose to decompose H as a linear combination of a setof positive semi-definite (PSD) matrices. Inspired by [20],in this work, we use the set of rank-one normalized PSD\f1138IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014matrices which is defined as M = {Mr |\u221er=1 } where Mr =hr h\u0003r , hr \u2208 R(ns +nt ) and h\u0003r hr = 1. Then, any PSD matrix H in(8) can be represented as a linear combination\u0003 of the rankone PSD matrices in M, i.e., H = H\u03b8 = \u221er=1 \u03b8r Mr wherethe linear combination coefficient vector \u03b8 = [\u03b81 , . . . , \u03b8\u221e ]\u0003 ,\u03b8 \u2265 0. Although there are an infinite number of matrices inM (i.e., the index r goes from 1 to \u221e), only considering thelinear combination vector \u03b8 with a finite number of nonzero entries is sufficient to represent H as shown\u0003\u221e in [20].Notethatwehavetrace(H)=trace(r=1 \u03b8r Mr ) =\u0003\u221e\u0003r=1 \u03b8r trace(Mr ) = 1 \u03b8 . Instead of directly solving for theoptimal H in (8), we show in the following theorem that itis equivalent to solving for the optimal linear combinationcoefficient vector \u03b8 :Theorem 1. Given that \u03b8 \u2217 is the optimal solution to the following optimization problem,min \u03bc(H\u03b8 ) + \u03b7 1\u0003 \u03b8 ,\u03b8\u22650(9)H\u03b8 \u2217 is also the optimum to the optimization problem in (8).Proof. Let us denote the objective function in (8) as F(H) =\u03bc(H) + \u03b7 trace(H) and the objective function in (9) asG(\u03b8 ) = \u03bc(H\u03b8 )+\u03b7 1\u0003 \u03b8 , and denote the optimums to (8) and(9) as H\u2217 = arg minH\b0 F(H) and \u03b8 \u2217 = arg min\u03b8\u22650 G(\u03b8 ),respectively. To show H\u03b8 \u2217 is also the optimum of (8), weneed to prove F(H\u03b8 \u2217 ) = F(H\u2217 ).On one hand, we have F(H\u03b8 \u2217 ) \u2265 F(H\u2217 ), because H\u2217is the optimal solution to (8). On the other hand, wewill prove it as F(H\u2217 ) \u2265 G(\u03b8 \u2217 ) = F(H\u03b8 \u2217 ). Specifically, forany PSD\u0003 matrix H and a vector \u03b8 which satisfies H =H\u03b8 = \u221er=1 \u03b8r Mr , we have F(H) = \u03bc(H) + \u03b7 trace(H) =\u03bc(H\u03b8 ) + \u03b7 1\u0003 \u03b8 = G(\u03b8 ) \u2265 G(\u03b8 \u2217 ) in which G(\u03b8 ) \u2265 G(\u03b8 \u2217 )is due to the fact that \u03b8 \u2217 is the optimal solution to (9).Thus we have F(H\u2217 ) \u2265 G(\u03b8 \u2217 ). Moreover, since G(\u03b8 \u2217 ) =\u03bc(H\u03b8 \u2217 ) + \u03b7 1\u0003 \u03b8 \u2217 = \u03bc(H\u03b8 \u2217 ) + \u03b7 trace(H\u03b8 \u2217 ) = F(H\u03b8 \u2217 ), wehave F(H\u2217 ) \u2265 G(\u03b8 \u2217 ) = F(H\u03b8 \u2217 ).Finally, we conclude that F(H\u03b8 \u2217 ) = F(H\u2217 ), becausewe have proved F(H\u03b8 \u2217 ) \u2265 F(H\u2217 ) and F(H\u2217 ) \u2265 G(\u03b8 \u2217 ) =F(H\u03b8 \u2217 ). This completes the proof.By replacing the Tikhonov regularization (9) with thecorresponding Ivanov regularization (i.e. the regularizerterm 1\u0003 \u03b8 is rewritten as the constraint), we reformulate theoptimization problem of HFA as:111min max 1\u0003 \u03b1 \u2212 (\u03b1 \u25e6 y)\u0003 K 2 (H\u03b8 + I)K 2 (\u03b1 \u25e6 y),\u03b8 \u03b1\u2208A2(10)\u221es.t. H\u03b8 =\u03b8r M r ,Mr \u2208 M ,r=11\u0003 \u03b8 \u2264 \u03bb,\u03b8 \u2265 0.By setting \u03b8 \u2190 \u03bb1 \u03b8 , it can be further rewritten as:1min max 1\u0003 \u03b1 \u2212 (\u03b1 \u25e6 y)\u0003\u03b1\u2208A\u03b8 \u2208D\u03b8211\u221e\u03b8r Kr (\u03b1 \u25e6 y),(11)r=1where Kr = K 2 (\u03bbMr + I)K 2 and D\u03b8 = {\u03b8 |1\u0003 \u03b8 \u2264 1, \u03b8 \u2265 0}. Itis an Infinite Kernel Learning (IKL) problem with each basekernel as Kr , which can be readily solved with the existingMKL solver [19], [21].2.5 SolutionOne problem in (11) is that there are an infinite number ofbase kernels because the set M contains infinite rank-onematrices. However, a finite number of rank-one matrices aresufficient to represent the matrix H [20]. Inspired by [21],we solve (11) based on a small number of base kernelswhich are constructed by using the cutting-plane algorithm.Let us introduce a dual variable \u03c4 for \u03b8 in (11) and writethe dual form as:max 1\u0003 \u03b1 \u2212 \u03c4,(12)\u03c4,\u03b1\u2208A1(\u03b1 \u25e6 y)\u0003 Kr (\u03b1 \u25e6 y) \u2264 \u03c4, \u2200r,2which has an infinite number of constraints. With thecutting-plane algorithm, we can approximate (12) by iteratively adding a kernel for which the corresponding constraint is violated according to the current solution. Thekernel associated with this constraint is called an active kernel. To find the most active kernel, we need to maximizethe left-hand side of the constraint in (12), which is givenas:1(13)max(\u03b1 \u25e6 y)\u0003 KM (\u03b1 \u25e6 y),M\u2208M 2s.t.11where KM = K 2 (\u03bbM + I)K 2 . It has a closed form solutionas M = hh\u0003 \u2208 R(ns +nt )\u00d7(ns +nt ) with h =1K 2 (\u03b1\u25e6y)1\u0005K 2 (\u03b1\u25e6y)\u0005.We summarize the proposed algorithm in Algorithm 1.First, we initialize the set of rank-one PSD matrices M withM1 = h1 h\u00031 where h1 is a unit vector. Based on the currentM, we solve the MKL problem in (11) to obtain the optimal\u03b1 and \u03b8 . After that, we find the most active kernel which isdecided by a rank-one PSD matrix M as in (13). By using theclosed form solution of (13), we obtain a new rank-one PSDmatrix and add it into the current set M. Then we solvethe MKL problem again. The above steps are repeated untilconvergence. After obtaining the optimal solution \u03b1 and Hto (11), we can predict any test sample x from the targetdomain by using the following target decision function:\u000f\u0010Ons \u00d7nt\u0003 12(14)f (x) = (\u03b1 \u25e6 y) K (H + I)kt + b,\u22121Kt 2where kt = [k(xt1 , x), . . . , k(xtnt , x)]\u0003 and k(xi , xj ) =\u03c6t (xi )\u0003 \u03c6t (xj ) is a predefined kernel function for two datasamples xi and xj in the target domain.1Complexity Analysis: In our HFA, we first calculate K 2once at the beginning, which costs O(n3 ) time with n = ns +nt being the total number of training samples1 . After that,we perform the cutting-plane algorithm (i.e., Algorithm 1),in which we iteratively train an MKL classifier and findthe most violated rank-one matrix as in (13). As we havean efficient closed form solution for solving (13), the majortime cost of Algorithm 1 is from the training of MKL ateach iteration. However, the time complexity of MKL hasnot been theoretically analyzed. Usually, the MKL solverneeds to train an SVM classifier for a few iterations. Theempirical analysis shows that optimizing the QP problem11. More accurately, the time complexity for solving K 2 is O(n3s +n3t ),because the kernel matrix K is a block-diagonal matrix.\fLI ET AL.: LEARNING WITH AUGMENTED FEATURESAlgorithm 1 Heterogeneous Feature Augmentation\u0005nsInput: Labeled source samples { (xsi , ysi )\u0005i=1} and labeled\u0005nt}.target samples { (xti , yti )\u0005i=11: Set r = 1 and initialize M1 = {M1 } with M1=h1 h\u00031 andh1 = \u221an 1+n 1ns +nt .st2: repeat3:Solve \u03b8 and \u03b1 in (11) based on Mr by using theexisting MKL solver [19].4:Obtain a rank-one\u0011 PSD matrix Mr+1 by solving (13).5:Set Mr+1 = Mr {Mr+1 }, and r = r + 1.6: until The objective converges.\u0003Output: \u03b1 and H = \u03bb r \u03b8r Mr .in SVM is about O(n2.3 ) [22]. Therefore, the complexity ofMKL is O(Ln2.3 ) with L being the number of iterations inMKL. Thus, the total time complexity of our HFA is O(n3 +TLn2.3 ), where T is the number of iterations in Algorithm 1.In practice, both L and T are not very large.2.6 Convergence AnalysisLet us represent\u0003 the objective function in (11) as F(\u03b1, \u03b8 ) =1\u0003 \u03b1 \u2212 12 (\u03b1 \u25e6 y)\u0003 \u221er=1 \u03b8r Kr (\u03b1 \u25e6 y), and also denote the optimalsolution to (11) as (\u03b1 \u2217 , \u03b8 \u2217 ) = arg min\u03b8\u2208D\u03b8 max\u03b1\u2208A F(\u03b1, \u03b8 ).We denote the optimal solution of the MKL problem atthe r-th iteration as (\u03b1 r , \u03b8 r ). Because there are at most r nonzero elements in \u03b8 r , we assume these non-zero elements arethe first r entries in \u03b8 r for ease of presentation. Then, weshow in the following theorem that Algorithm 1 convergesto the global optimal solution:Theorem 2. With Algorithm 1, F(\u03b1 r , \u03b8 r ) monotonicallydecreases as r increases, and the following inequality holdsF(\u03b1 r , \u03b8 r ) \u2265 F(\u03b1 \u2217 , \u03b8 \u2217 ) \u2265 F(\u03b1 r , er+1 ),where er+1 \u2208 D\u03b8 is the vector with all zeros except the (r +1)-th entry being 1. We also have F(\u03b1 r , \u03b8 r ) = F(\u03b1 \u2217 , \u03b8 \u2217 ) =F(\u03b1 r , er+1 ) when Algorithm 1 converges at the r-th iteration.The theorem can be proved similarly as in [23]. We alsogive the proof in the Appendix, which is available inthe Computer Society Digital Library at https://doi.ieeecomputersociety.org/10.1109/TPAMI.2013.167. Moreover,as indicated in [24], the cutting-plane algorithm stops ina finite number of steps under some conditions. In ourexperiments, the algorithm usually takes less than 50iterations to obtain a sufficient accurate solution.2.7 DiscussionOur work is related to the existing heterogeneous domainadaptation methods. The pioneering works [8]\u2013[12] are limited to some specific HDA tasks, because they requiredadditional information to transfer the source knowledgeto the target domain. For instance, Dai et al. [8] andZhu et al. [10] proposed to use either labeled or unlabeled text corpora to aid image classification by assumingimages are associated with textual annotations. Such textual annotations can be additionally utilized to mine theword co-occurrence from textual annotations of images andwords in text documents, which is served as a bridge totransfer knowledge from the text documents to images.1139To handle more general HDA tasks, other methodshave been proposed to explicitly discover a common subspace [13], [15], [17] without using additional information,such that original data from the source and target domainscan be measured in the common subspace. Specifically,Shi et al. [13] proposed to learn feature mapping matrices based on a spectral transformation for domains withdifferent features. Wang et al. [15] proposed to learn the feature mapping by using the manifold alignment. However,such manifold assumption may not be satisfied in realworld applications with very diverse data. Recently, Kuliset al. [17] proposed a nonlinear metric learning method tolearn an asymmetric feature transformation for the sourceand target data with high dimensions. They assume thatif one source sample and one target sample are from thesame category, the learned similarity between this pair ofsamples should be large; otherwise, the similarity shouldbe small.In contrast to [13], [15], [17], in our proposed HFA,we simultaneously learn the common subspace and amax-margin classifier by solving a convex optimizationproblem, which shares a similar form with the MKLformulation. We also propose the heterogeneous augmented features by incorporating the original featuresfrom two domains, in order to learn a more robustclassifier (see Section 4.3 for experimental comparisons).Moreover, our work can also be extended to handle unlabeled samples from the target domain as shown in thenext section.3S EMI -S UPERVISED H ETEROGENEOUSF EATURE AUGMENTATIONThe unlabeled data has been demonstrated to be helpful for training a robust classifier in many applications [25]. For the traditional semi-supervised learning,readers can refer to [26] for a comprehensive survey.There are also many works on semi-supervised homogeneous domain adaptation, such as [27]\u2013[29]. However,most existing heterogeneous domain adaptation works [13],[15], [17] were designed for the supervised setting,and cannot utilize the abundant unlabeled data inthe target domain. Thus, we further propose semisupervised HFA to utilize the unlabeled data in the targetdomain.st} and {(xti , yti )|ni=1} to represent theWe still use {(xsi , ysi )|ni=1labeled data from the source domain and the target domain,respectively. Let us denote the unlabeled data in the taru} where xui \u2208 Rdt is an unlabeledget domain as {(xui , yui )|ni=1sample in the target domain, nu is the number of unlabeledsamples, and the label yui \u2208 {\u22121, +1} is unknown. We alsodenote yu = [yu1 , . . . , yunu ]\u0003 as the label vector of all the unlabeled data. Moreover, the total number of training samplesis denoted as n = ns + nt + nu .3.1 FormulationSince the labels of unlabeled data are unknown, we proposeto infer the optimal labeling yu for the unlabeled data in thetarget domain when learning the classifier. Based on the \u03c1SVM with the squared hinge loss, we propose the objective\f1140IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014for semi-supervised heterogeneous domain adaptation asfollows:\u00041\u0002\u0005w\u00052 + b2 \u2212 \u03c1minyu ,w,b,\u03c1,2P,Q,\u03beis ,\u03beit ,\u03beiu+C2nsnt(\u03beis )2+i=1(\u03beit )2 +i=1Cu2s.t. ysi (w\u0003 \u03d5s (xsi ) + b) \u2265 \u03c1 \u2212 \u03beis ,Proposition 1. The objective of (16) is lower-bounded by theoptimum of the following optimization problem:1max \u2212 \u03b1 \u00032min(15)i=1yti (w\u0003 \u03d5t (xti ) + b) \u2265 \u03c1 \u2212 \u03beit ,yui (w\u0003 \u03d5t (xui ) + b) \u2265 \u03c1 \u2212 \u03beiu ,1\u0003 yu = \u03b4, \u0005P\u00052F \u2264 \u03bbp , \u0005Q\u00052F \u2264 \u03bbq ,where \u03d5s (\u00b7) and \u03d5t (\u00b7) are defined in (1) for generating theaugmented features, and the constraint 1\u0003 yu = \u03b4 is usedas the prior information on the unlabeled data similarlyas in Transductive SVM (T-SVM) [25]. We refer to theabove method as Semi-supervised Heterogeneous FeatureAugmentation, or SHFA in short.Similarly as in HFA, we only discuss the nonlinear case for SHFA here, and the linear case can bederived analogously.\u000e Let us define a kernel matrix K =Ks Ons \u00d7(nt +nu )\u2208 Rn\u00d7n where Ks \u2208 Rns \u00d7ns is the kerO(nt +nu )\u00d7ns Ktnel of source domain samples and Kt \u2208 R(nt +nu )\u00d7(nt +nu ) isthe kernel of target domain samples. Then, by defining anonlinear transformation metric H \u2208 Rn\u00d7n , we can derivethe dual form of (15) as follows:1(16)min max \u2212 \u03b1 \u0003 (QH,y + D)\u03b12s.t. trace(H) \u2264 \u03bb,\u0004\u0002 11where QH,y = K 2 (H + I)K 2 + 11\u0003 \u25e6 (yy\u0003 ) \u2208 Rn\u00d7n , y =[y\u0003s , y\u0003t , y\u0003u ]\u0003 is the label vector in which ys and yt aregiven and yu is unknown, Y = {y \u2208 {\u22121, +1}n |y =[y\u0003s , y\u0003t , y\u0003u ]\u0003 , 1\u0003 yu = \u03b4} is the domain of y, \u03b1 =[\u03b11s , . . . , \u03b1ns s , \u03b11t , . . . , \u03b1nt t , \u03b11u , . . . , \u03b1nuu ]\u0003 \u2208 Rn with \u03b1is \u2019s, \u03b1it \u2019sand \u03b1iu \u2019s are the dual variables corresponding to theconstraints for source samples, labeled target samplesand unlabeled target samples, respectively, A = {\u03b1|\u03b1 \u22650, 1\u0003 \u03b1 = 1} is the domain of \u03b1 and D \u2208 Rn\u00d7n is a diagonal matrix with the diagonal elements as C1 for the labeleddata from both domains and C1u for the unlabeled targetdata.y\u2208Y ,H\b0 \u03b1\u2208A3.2 Convex RelaxationCompared with HFA, one major challenge in (16) isthat we need to infer the optimal label vector y, whichis a mixed integer programming (MIP) problem. It isan NP problem and is computationally expensive to besolved [30]\u2013[32] because there are possibly an exponential number of feasible labeling candidates y\u2019s. Inspiredby [30]\u2013[32], instead of directly finding the optimal labeling y, we seek for an optimal linear combination of thefeasible labeling candidates y\u2019s, which leads to a lowerbound of the original optimization problem as describedbelow.(17)ls.t. trace(H) \u2264 \u03bb,nu(\u03beiu )2\u03b3l QH,yl + D \u03b1\u03b3 \u2208D\u03b3 ,H\b0 \u03b1\u2208Awhere yl is the l-th feasible labeling candidate, \u03b3 =[\u03b31 , . . . , \u03b3|Y | ]\u0003 is the coefficient vector for the linear combination of all feasible labeling candidates and D\u03b3 = {\u03b3 |\u03b3 \u22650, 1\u0003 \u03b3 \u2264 1} is the domain of \u03b3 .Proof. The proof is provided in the Appendix, availableonline.Another challenge in (16) or (17) is to solve the positive semi-definite matrix H. We apply a similar strategyhere as used in HFA to solve the optimization problem in(17). Specifically, we decompose H into a linear combina\u0003tion of a set of rank-one PSD matrices, i.e., H = \u221er=1 \u03b8r Mrn\u00d7nwhere Mr \u2208 Ris a rank-one PSD matrix and \u03b8r is thecorresponding combination coefficient, which leads to thefollowing optimization problem:1min min max \u2212 \u03b1 \u00032\u03b3 \u2208D\u03b3 \u03b8 \u2208D\u03b8 \u03b1\u2208A\u03b8r \u03b3l QMr ,yl + D \u03b1r(18)l\u0004\u0002 11where QMr ,yl = K 2 (\u03bbMr + I)K 2 + 11\u0003 \u25e6 (yl yl \u0003 ) and D\u03b8 ={\u03b8 |\u03b8 \u2265 0, 1\u0003 \u03b8 \u2264 1}.However, there are three variables, \u03b8 , \u03b3 and \u03b1 in (18).To efficiently solve this problem, we propose a relaxationby combining \u03b8 and \u03b3 into one variable d. Specifically, letus denote dk = \u03b8r \u03b3l where dk is the k-th entry of d. Aftercombining the two indices r and l into one index k, we\u0003\u0003 \u0003have 1\u0003 d = k dk = r l \u03b8r \u03b3l = (1\u0003 \u03b8 )(1\u0003 \u03b3 ) \u2264 1. Then wereformulate the optimization problem in (18) as:1min max \u2212 \u03b1 \u00032d\u2208Dd \u03b1\u2208Adk QMk ,yk + D \u03b1(19)k\u0004\u0002 11where QMk ,yk = K 2 (\u03bbMk + I)K 2 + 11\u0003 \u25e6 (yk yk \u0003 ) and Dd ={d|1\u0003 d \u2264 1, d \u2265 0}.Hence, we obtain an MKL problem as in (19) where eachbase kernel is QMk ,yk , and the primal form of (19) is asfollows:mind,wk ,\u03c1,\u03bei12s.t.k\u0003\u0005wk \u00052+Cdkkw\u0003k \u03c8k (xi )1 d \u2264 1,n\u03bdi (\u03bei )2 \u2212 \u03c1(20)i=1\u2265 \u03c1 \u2212 \u03bei ,d \u2265 0,where d is the coefficient vector, \u03c8k (\u00b7) is the k-th feature\u0002 1 mapping function\u0004 induced by the kernel QMk ,yk =1\u000322K (\u03bbMk + I)K + 11 \u25e6(yk yk \u0003 ), and \u03bdi is the weight for thei-th sample which is 1 for labeled data from both domainsand Cu /C for unlabeled target data.\fLI ET AL.: LEARNING WITH AUGMENTED FEATURES11413.3 SolutionSimilar to HFA, there are also an infinite number of basekernels in (19). We therefore employ the cutting-plane algorithm to iteratively select a small set of active kernels. Wefirst write the dual form of (20) as follows:max \u2212\u03c4(21)\u03c4,\u03b1\u2208A1 \u0003\u03b1 (QMk ,yk + D)\u03b1 \u2264 \u03c4, \u2200k2where we have an infinite number of constraints. Thesubproblem for selecting the most active kernel is:s.t.1 \u0003\u03b1 QM,y \u03b1,(22)y\u2208Y ,M\u2208M 2\u0004\u0002 11where QM,y = K 2 (\u03bbM + I)K 2 + 11\u0003 \u25e6 (yy\u0003 ). Note that wedo not need to consider the constant term \u03b1 \u0003 D\u03b1 in the aboveformulation when selecting the most active kernel.Given any y, finding the violated M is as the same as inHFA. It can be obtained by solving (13) with the closed formmaxsolution M = hh\u0003 where h =M back into (22) and obtain1K 2 (\u03b1\u25e6y)1\u0005K 2 (\u03b1\u25e6y)\u0005. Then we substitute1 \u0003\u03b1 QM,y \u03b1,y\u2208Y ,M\u2208M 2\u0002 1\u000411= max(\u03b1 \u25e6 y)\u0003 K 2 (\u03bbM + I)K 2 + 11\u0003 (\u03b1 \u25e6 y),y\u2208Y ,M\u2208M 2(\u03b1 \u25e6 y)\u0003 K(\u03b1 \u25e6 y)(\u03b1 \u25e6 y)\u0003 K(\u03b1 \u25e6 y)= max \u03bby\u2208Y(\u03b1 \u25e6 y)\u0003 K(\u03b1 \u25e6 y)\u0003+(\u03b1 \u25e6 y) (K + 11\u0003 )(\u03b1 \u25e6 y)max= max (\u03b1 \u25e6 y)\u0003 ((\u03bb + 1)K + 11\u0003 )(\u03b1 \u25e6 y),(23)y\u2208Ywhich indicates that we only need to solve an optimizationproblem on y. However, it is another MIP problem, and isdifficult to be solved. Similar to [30], [32], we employ anapproximated solution to (23) for finding the most violatedy. Specifically, we first rewrite (23) as:\u0002\u0004max y\u0003 K\u0303 \u25e6 (\u03b1\u03b1 \u0003 ) y = max \u0005yi \u03b1i \u03c6\u0303(xi )\u00052(24)y\u2208Yy\u2208Yi11\u0003and \u03c6\u0303(\u00b7) is the feature mappingwhere K\u0303 = (\u03bb + 1)K +function induced by K\u0303. Following [30], [32], we use the \u0002\u221e norm to approximate the \u00022 -norm in (24), and the problembecomesmax \u0005y\u2208Yyi \u03b1i \u03c6\u0303(xi )\u0005\u221ei\u0012\u0013= max maxy\u2208Y j=1,...,d\u0303\u0012= maxj=1,...,d\u0303yi \u03b1i zij , \u2212iy\u2208Y\u0013yi \u03b1i zij , max \u2212maxiy\u2208Yyi \u03b1i zij1K 2 (\u03b1\u25e6y )k.Mk = hh\u0003 where h =1\u0005K 2 (\u03b1\u25e6y\u0011\u0011k )\u00058:Set M = M {Mk }, Y = Y {yk }.9: until The objective converges.Output: \u03b1, d, Y and M.the j-th dimension, we can respectively obtain two labelvectors by a simple sorting operation to solve the twoinner problems in (25). Specifically, we first sort the unlabeled samplesin descending order according to \u03b1i zij . For\u0003maxy\u2208Y i yi \u03b1i zij , the optimal label vector can be obtainedby setting the first (\u03b4 + nu )/2 unlabeled samples as positive and the remaining\u0003unlabeled samples as negative;similarly for maxy\u2208Y \u2212 i yi \u03b1i zij , the optimal label vector is obtained by setting the last (\u03b4 + nu )/2 unlabeledsamples as positive and remaining unlabeled samples asnegative. Finally, the most violated y is the label vectorwith the maximum objective value among these 2d\u0303 labelvectors.We summarize the algorithm for solving SHFA inAlgorithm 2. We first initialize the set of rank-one PSDmatrices M with M1 = h1 h\u00031 , and also initialize the labeling candidate set Y by using a feasible label vector y1 . Toobtain y\u0303u in y1 , we first sort the unlabeled training samples in descending order according to the prediction of theclassifier trained on the labeled target samples. Then y\u0303u isobtained by setting the first (\u03b4 +nu )/2 unlabeled samples aspositive and the remaining samples as negative. Next, wesolve the MKL problem in (19) based on Y and M. Afterthat, we find a violated y and calculate the correspondingM = hh\u0003 where h =yi \u03b1i zijiAlgorithm 2 Semi-supervised Heterogeneous FeatureAugmentation\u0005nsInput: Labeled source samples { (xsi , ysi )\u0005i=1}, labeled tar\u0005nttt\u0005get samples { (xi , yi ) i=1 }, and unlabeled target samples\u0005nu{ (xui , yui )\u0005i=1} with the unknown yui \u2019s.1: Train an SVM classifier f0 by only using the labeledtarget samples.2: Initialize the labeling candidate set Y = {y1 } where y1 =[y\u0003s , y\u0003t , y\u0303\u0003u ]\u0003 where y\u0303u is a feasible label vector obtainedby using the prediction from f0 .3: Initialize the rank-one matrices set M = {M1 } withM1 = h1 h\u00031 and h1 = \u221a1n 1n and set k = 1.4: repeat5:Set k = k + 1.6:Solve d and \u03b1 in (19) based on Y and M by usingthe existing MKL solver [19].7:Find the violated yk by solving (25) and obtain(25)iwhere zij is the j-th entry of the feature vector \u03c6\u0303(xi ) =[zi1 , . . . , zid\u0303 ]\u0003 with d\u0303 as the feature dimension.To find the optimal y, we first obtain \u03c6\u0303(x) by usingSVD decomposition on the kernel matrix K\u0303, which is alsoknown as the empirical kernel map [33]. Then we calculate \u03b1i zij for each feature dimension and each sample. For1K 2 (\u03b1\u25e6y)1\u0005K 2 (\u03b1\u25e6y)\u0005. We respectively add y and Minto Y and M and solve the MKL problem again. This process is repeated until convergence. The time complexity canbe analyzed similarly as in HFA, which is O(n3 + TLn2.3 )with n = ns + nt + nu being the total number of trainingsamples2 .2. The time complexity of the sorting operation for d\u0303 times in finding the optimal y is d\u0303nu log(nu ), which is less than n2 log(n). Whenthe number of training samples (i.e., n) is large as in our experiments,it can be ignored when compared with the time complexity O(Ln2.3 )for solving the MKL problem.\f1142IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014After obtaining the optimal solution \u03b1, d, Y and M , wecan predict any test sample x from the target domain byusing the following target decision function:\u0010\u000fOns\u00d7(nt +nu )\u0003 12kt +b, (26)f (x)= dk (\u03b1 \u25e6 yk ) K (\u03bbMk+I)\u22121Kt 2kTABLE 1Summarization of the Object DatasetIncluding 31 Categorieswhere kt =[k(xt1 , x), . . . , k(xtnt , x), k(xu1 , x), . . . , k(xunu , x)]\u0003 andk(xi , xj ) = \u03c6t (xi )\u0003 \u03c6t (xj ) is a predefined kernel function fortwo data samples xi and xj in the target domain.3.4 \u0005p -MKL ExtensionRecall that we have formulated our SHFA as an MKL problem in (20), in which the \u00021 -norm constraint on the kernelcoefficient vector d (i.e. \u0005d\u00051 \u2264 1) is adopted. However,the optimization problem in (20) can be extended to moregeneral \u0002p -MKL by using \u0002p -norm on d (i.e. \u0005d\u0005p \u2264 1) asfollows:mind,wk ,\u03c1,\u03bei12s.t.\u0005wk \u00052+Cdkkw\u0003k \u03c8k (xi )k\u0005d\u0005p \u2264 1,n\u03bdi (\u03bei )2 \u2212 \u03c1(27)i=1\u2265 \u03c1 \u2212 \u03bei ,d \u2265 0,where d, \u03c8k (xi ) and \u03bdi are as the same as defined in (20).Thus, the original SHFA is a special case of (27) whenp = 1. The \u0002p -MKL problem in (27) can also be solved byAlgorithm 2. The only difference is that we solve an \u0002p -MKLproblem instead of \u00021 -MKL in Step 6.4E XPERIMENTSIn this section, we evaluate our proposed HFA and SHFAmethods for object recognition, multilingual text categorization and cross-lingual sentiment classification. We focus onthe heterogeneous domain adaptation problem with onlyone source domain and one target domain. For the supervised heterogeneous domain adaptation setting, we onlyutilize a limited number of labeled training samples inthe target domain; for the semi-supervised heterogeneousdomain adaptation setting, we additionally employ a largenumber of unlabeled training samples in the target domain.4.1 SetupObject recognition: We employ a recently released Officedataset3 used in [16], [17] for this task. This dataset contains a total of 4106 images from 31 categories collectedfrom three sources: amazon (object images downloadedfrom Amazon), dslr (high-resolution images taken froma digital SLR camera) and webcam (low-resolution imagestaken from a web camera). We follow the same protocolsin the previous work [17]. Specifically, SURF features [34]are extracted for all the images. The images from amazonand webcam are clustered into 800 visual words by usingk-means. After vector quantization, each image is represented as a 800 dimensional histogram feature. Similarly,we represent each image from dslr as a 600-dimensionalhistogram feature.3. https://www.icsi.berkeley.edu/~saenko/projects.htmlIn the experiments, dslr is used as the target domain,while amazon and webcam are considered as two individual source domains. We strictly follow the settingin [16], [17] and randomly select 20 (resp., 8) training images per category for the source domain amazon(resp., webcam). For the target domain dslr , 3 trainingimages are randomly selected from each category, and theremaining dslr images are used for testing, which arealso used as the unlabeled training samples in the semisupervised setting. See Table 1 for a summarization of thisdataset.Text categorization: We use the Reuters multilingualdataset4 [35], which is collected by sampling parts of theReuters RCV1 and RCV2 collections. It contains about 11Knewswire articles from 6 classes (i.e., C15, CCAT, E21, ECAT,GCAT and M11) in 5 languages (i.e., English , French ,German , Italian and Spanish). While each documentwas also translated into the other four languages in thisdataset, we do not use the translated documents in thiswork. All documents are represented by using the TF-IDFfeature.We take Spanish as the target domain in the experimentand use each of the other four languages as an individualsource domain. For each class, we randomly sample 100training documents from the source domain and m training documents from the target domain, where m = 5, 10, 15and 20. And the remaining documents in the target domainare used as the test data, among which 3, 000 documentsare additionally sampled as the unlabeled training data inthe semi-supervised setting. Note that the method in [15]cannot handle the original high dimensional TF-IDF features. In order to fairly compare our HFA method [15],for documents written in each language, we perform PCAbased on the TF-IDF features with 60% energy preserved.We summarize this dataset in Table 2.Sentiment Classification: We use the Cross-LingualSentiment (CLS) dataset5 [36], which is an extended version of the Multi-Domain Sentiment Dataset [2] widelyused for domain adaptation. It is collected from Amazonand contains about 800,000 reviews of three product categories: Books, DVDs and Music, and written in fourlanguages: English, German, French, and Japanese. TheEnglish reviews were sampled from the Multi-DomainSentiment Dataset and reviews in other languages arecrawled from Amazon. For each category and each language, the dataset is officially partitioned into a trainingset, a test set and an unlabeled set, where the training set4. https://multilingreuters.iit.nrc.ca/ReutersMultiLingualMultiView.htm5. https://www.uni-weimar.de/cms/medien/webis/research/corpora/corpus-webis-cls-10.html\fLI ET AL.: LEARNING WITH AUGMENTED FEATURES1143TABLE 2Summarization of the Reuters Multilingual Dataset Including 6 Classesand test set consist of 2,000 reviews, and the numbers ofunlabeled reviews vary from 9,000 to 170,000.We take English as the source domain and each of theother three languages as an individual target domain inthe experiment. We randomly sample 500 reviews from thetraining set of the source domain and 100 reviews from thetraining set of the target domain as the labeled data. Thetest set is the official test set for each category and eachlanguage. We also sample 1, 000 reviews from the unlabeledset as the unlabeled target training data. Similarly as fortext categorization, we extracted the TF-IDF features andperform PCA with 60% energy preserved. The completeinformation of this dataset is summarized in Table 3.Baselines: To evaluate our proposed methods, HFA andSHFA, we compare them with a number of baselines undertwo settings. The first setting (i.e., the supervised HDA setting) is as the same as [18], in which there are sufficientlabeled source samples and a limited number of labeled target samples. As the source and target data have differentdimensions, they cannot be directly combined to train anyclassifiers for the target domain. So the baseline algorithmsin this setting are listed as follows:\u2022\u2022\u2022\u2022SVM_T: It utilizes the labeled samples only fromthe target domain to train a standard SVM classifier for each category/class. This is a naive approachwithout considering the information from the sourcedomain.HeMap [13]: It finds the projection matrices for acommon feature subspace as well as learns the optimally projected data from both domains. We alignthe samples from different domains according totheir labels. Since HeMap requires the same number of samples from the source and target domains,we randomly select min{ns , nt } samples from eachdomain for learning the subspace.DAMA [15]: It learns a common feature subspaceby utilizing the class labels of the source and targettraining data for manifold alignment.ARC-t [17]: It uses the labeled training data fromboth domains to learn an asymmetric transformationmetric between different feature spaces.TABLE 3Summarization of the Cross-Lingual Sentiment DatasetIncluding 3 Categories and 2 ClassesIn the second setting (i.e. the semi-supervised HDA setting), we addtionally employ the unlabeled samples in thetarget domain. To evaluate our SHFA, we report the resultsof one more baseline, transductive SVM (T-SVM) [25], whichutilizes both the labeled data and unlabeled data to trainthe classifier. Note that the labeled samples in the sourcedomain cannot be used in T-SVM because they have differentfeatures with the samples in the target domain. Moreover,all the above heterogenous domain adaptation methods [13],[15], [17] were designed for the supervised heterogeneousdomain adaptation scenario, so it is unclear how to utilizethe unlabeled target data to learn the projection matrices ortransformation metric for these methods.For HeMap and DAMA, after learning the projectionmatrices, we apply SVM to train the final classifiers byusing the projected training data from both domains fora given category/class. For ARC-t, we construct the kernel matrix based on the learned asymmetric transformationmetric, and then SVM is also applied to train its final classifier. The RBF kernel is used for all methods with thebandwidth parameter as the mean distance of all trainingsamples. As we only have a very limited number of labeledtraining samples in the target domain, the cross-validationtechnique cannot be effectively employed to determine theoptimal parameters. Therefore, we set the tradeoff parameter in SVM as the default value C = 1 for all methods.For our HFA and SHFA methods, we empirically fix theparameter \u03bb as 100 in the vision application (i.e. the objectrecognition) and 1 in the text applications ( i.e., documentclassification and sentiment classification). And we alsoempirically set the weight of unlabeled data Cu in SHFA as10\u22123 for all experiments. Moreover, we additionally reportthe results of our SHFA with the \u0002p -MKL extension (seeSection 3.4) where we empirically set p = 1.5 for all thedatasets which generally achieves better results.For other methods, we report their best results on thetest data by varying their parameters in a wide range oneach dataset. Specifically, we validate the parameters \u03b2 inHeMap (see Equation (1) in [13]), \u03bc in DAMA (see Theorem1 in [15]) and \u03bb in ARC-t (see Equation (1) in [17]) from{0.01, 0.1, 1, 10, 100}. For T-SVM, we validate the weight ofunlabeled data Cu from {0.001, 0.01, 0.1, 1} and the parameter s for the ramp loss from [ \u2212 0.9, 0] with the step size as0.1. For both T-SVM and our SHFA, we set the parameter \u03b4for the balance constraint on unlabeled samples using theprior information.Evaluation metric: Following [17], for each methodwe measure the classification accuracy over all categories/classes on three datasets. We randomly sample thetraining data for a fixed number of times (i.e., 20 for the\f1144IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014TABLE 4Means and Standard Deviations of Classification Accuracies(%) of All Methods on the Object Dataset by Using 3 LabeledTraining Samples Per Class from the Target Domain dslrResults in boldface are significantly better than the others, judged by the t-test witha significance level at 0.05.Office dataset as in [17], and 10 for the Reuters dataset andthe Cross-Lingual Sentiment dataset) and report the meanclassification accuracies of all methods over all rounds ofexperiments.4.2 Classification ResultsObject recognition: We report the means and standarddeviations of classification accuracies for all methods onthe Office dataset [16] in Table 4. From the results, we havethe following observations in terms of the mean classification accuracy. SVM_T outperforms HeMap by using only3 labeled training samples from the target domain. Theexplanation is that HeMap does not explicitly utilize thelabel information of the target training data to learn thefeature mapping matrices. As a result, the learned common subspace cannot well preserve a similar data structureas in the original feature spaces of the source and target data, which results in poor classification performances.DAMA performs only slightly better that SVM_T, possibly due to the lack of strong manifold structure on thisdataset. Both results of ARC-t implemented by ourselvesand reported in [17] are only comparable with those ofSVM_T, which shows that ARC-t is less effective for HDAon this dataset. Our HFA outperforms the other methodsfor both cases, which clearly demonstrate the effectiveness of our proposed method for HDA by learning withaugmented features. Moreover, we also observe that it isbeneficial to additionally use unlabeled data in the targetdomain to learn a more robust classifier. Specifically, whensetting the parameter p in the \u0002p -norm regularizer of \u0002p MKL as p = 1, our SHFA outperforms HFA on both caseswhen amazon and webcam are used as the source domain.When setting p = 1.5, the improvements of SHFA over HFAare 1.2% and 1.6%, respectively. SHFA also outperforms TSVM which demonstrates we can train a better classifier bylearning the transformation metric H to effectively exploitthe source data in SHFA.Text categorization: Table 5 shows the means and standarddeviations of classification accuracies for all methods onthe Reuters multilingual dataset [35] by using m = 10 andm = 20 labeled training samples per class from the targetdomain. We have the following observations in terms ofthe mean classification accuracy. SVM_T still outperformsHeMap. DAMA and ARC-t perform better than SVM_Tfor most cases. Our proposed HFA method is better thanother supervised HDA methods on this dataset. For thesemi-supervised setting, T-SVM is even worse than SVM_Talthough we have tuned all the parameters in a wide range.One possible explanation is that T-SVM cannot effectivelyutilize these target unlabeled data on this dataset. However,our SHFA can effectively handle the unlabeled data in thetarget domain and the performance improvements of SHFA(p = 1.5) over HFA are 3.5%, 3.2%, 3.1%, 3.1% and 1.1%,1.1%, 1.0%, 1.1% for these four different source domainswhen m = 10 and m = 20, respectively.We also plot the classification results of SVM_T, DAMA,ARC-t and our methods HFA and SHFA by using different numbers of target training samples per class (i.e.,m = 5, 10, 15 and 20) for each source domain in Fig. 2.We do not report the results of HeMap, as they are muchworse than the other methods. From the results, the performances of all methods increase when using a larger m.And the two HDA methods DAMA and ARC-t generallyachieve better mean classification accuracies than SVM_Texcept for the setting using English as the source domain.Our HFA method generally outperforms all other baselinemethods according to mean classification accuracy. Whenusing the unlabeled data in the target domain, our SHFA(p = 1) outperforms all existing HDA methods and the performance can be further improved when setting p = 1.5.We also observe that SHFA has large improvements overHFA when the number of labeled data in the target domainis very small (see m = 5 in Fig. 2). When the number oflabeled data in the target domain increases, the unlabeledTABLE 5Means and Standard Deviations of Classification Accuracies (%) of All Methods on the Reuters Multilingual Dataset byUsing 10 and 20 Labeled Training Samples Per Class from the Target Domain SpanishResults in boldface are significantly better than the others, judged by the t-test with a significance level at 0.05.\fLI ET AL.: LEARNING WITH AUGMENTED FEATURESTABLE 6Means and Standard Deviations of Classification Accuracies(%) of All Methods on the Cross-Lingual Sentiment Dataset byUsing 100 Labeled Training Samples from the Target DomainResults in boldface are significantly better than the others, judged by the t-test witha significance level at 0.05.data in the target domain is less helpful, but SHFA is stillbetter than HFA.Sentiment classification: Table 6 summarizes the meansand standard deviations of classification accuracies for allmethods on the Cross-Lingual Sentiment dataset by usingm = 100 labeled training samples in the target domain.As in each domain there are three categories (i.e., Books,DVDs, Music), each mean accuracy in Table 6 is the meanaccuracy over three categories and ten rounds. We havethe following observations in terms of the mean classification accuracy. We observe that HeMap is worse thanSVM_T which again indicates it cannot learn good featuremappings on this dataset. ARC-t is only comparable withSVM_T, and DAMA outperform SVM_T for all cases. OurHFA is better than other basline methods, except one exceptional case that HFA is worse than DAMA when usingJapanese as the target domain. A possible explanation isthe reviews in Japanese have good manifold correspondence with that in English . However, our HFA is stillcomparable with DAMA in this case. Moreover, we alsohave the similar observation as on the Office dataset andReuters dataset, our SHFA achieves better results than HFAby additionally exploiting the unlabeled data in the targetdomain. With setting p = 1, the performance improvementsof SHFA over HFA are 3.7%, 3.6% and 3.6% when usingGerman , French and Japanese as the target domain,respectively. With setting p = 1.5, the performance improvements of SHFA over HFA are further increased to 4.4%,4.7% and 4.4%, respectively.11454.3 Augmented Features v.s. Common FeaturesWe defined two augmented feature mapping functions\u0003\u03d5s (xs ) = [(Pxs )\u0003 , xs \u0003 , 0\u0003dt ]\u0003 and \u03d5t (xt ) = [(Qxt )\u0003 , 0\u0003ds , xt ]\u0003 in (1)by concatenating the feature representation in the learnt common subspace (referred to as common features here) with theoriginal features and zeros. However, our methods are alsoapplicable by only using the common feature representationsPxs and Qxt for the samples from source and target domainswithout using the original features and zeros. We take SHFAwhen setting p = 1.5 as an example to evaluate our work byonly using the feature representation in the common space,which is referred as SHFA_commFeat . The results on theReuters multilingual dataset are shown in Table 7, where weuse the same settings as described in Section 4.1. We observethat SHFA_commFeat still outperforms the existing HDAmethods HeMap, DAMA, ARC-t, and HFA on all settingsin terms of mean accuracy, which clearly demonstrates theeffectiveness of our proposed learning scheme. Moreover,SHFA using the augmented features are consistently better than SHFA_commFeat in terms of mean accuracy, whichdemonstrates it is beneficial to use our proposed new learningmethods with the augmented features for HDA.4.4Performance Variations Using DifferentParametersWe conduct experiments on the Reuters multilingualdataset to evaluate the performance variations of ourSHFA by using different parameters (i.e., \u03bb, p, and Cu ). Asdescribed in Section 4.1, we still use 100 labeled samplesper class from the source domain, as well as 20 labeledsamples per class and 3000 unlabeled samples from the target domain. The results of our SHFA (p = 1) and SHFA(p = 1.5) by using the default values \u03bb = 1 and Cu = 0.001have been reported in Table 5. To evaluate the performancevariations, at each time we vary one parameter and setthe other parameters as the default values (i.e., \u03bb = 1,Cu = 0.001, and p = 1.5). The means of classification accuracies by varying different parameters on the four settingsare plotted in Fig. 3.From Fig. 3, we observe that our SHFA is quite stable tothese parameters in certain ranges. Specifically, by changing \u03bb in the range of [0.01, 100], the performances of SHFA(p = 1.5) vary within 1% in terms of mean classificationaccuracy, which are still better than these baseline methodsreported in Table 5. Also, by changing the parameter p ofFig. 2. Classification accuracies of all methods with respect to different number of target training samples per class (i.e., m = 5, 10, 15 and 20)on the Reuters multilingual dataset. Spanish is considered as the target domain, and in each subfigure the results are obtained by using onelanguage as the source domain. (a) English. (b) French. (c) German. (d) Italian.\f1146IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014TABLE 7Means and Standard Deviations of Classification Accuracies (%) of Our SHFA (p = 1.5) andSHFA_commFeat (p = 1.5) on the Reuters Multilingual Datasetthe \u0002p -norm in the range of {1, 1.2, 1.5, 2}, we observe thatwith a larger p, SHFA can achieve better results. However,our initial experiments show that a larger p usually leadsto a slower convergence. We empirically set p = 1.5 as thedefault value in all our experiments for a good tradeoffbetween the effectiveness and efficiency. Moreover, we alsoevaluate our SHFA (p = 1.5) by varying Cu in the rangeof [10\u22125 , 10\u22121 ]. The parameter Cu controls the weights ofunlabeled samples. Intuitively, it should not be too largebecause the inferred labels for the unlabeled samples arenot accurate, which is also supported by our experiment asshown in Fig. 3(c). While we empirically set Cu = 10\u22123 inall our experiments, we observe that SHFA (p = 1.5) usinga larger value (i.e., Cu = 10\u22122 ) can achieve better results onthis dataset. However, the performances drop dramaticallywhen setting it to a much larger value (say, Cu = 10\u22121 ).Nevertheless, our SHFA is generally stable and better thanthese baseline methods reported in Table 5 when settingCu \u2208 [10\u22125 , 10\u22122 ]. For the domain adaptation problem, it isdifficult to perform cross-validation to choose the optimalparameters, because we usually only have a limited numberof labeled samples in the target domain. We would like tostudy how to automatically decide the optimal parametersin the future.4.5 Time AnalysisWe take the Cross-Lingual Sentiment dataset as an exampleto evaluate the running time of all methods. The experimental setting is as the same as described in Section 4.1.The average per class training times of all methods arereported in Table 8. All the experiments are performedon a workstation with Xeon 3.33 GHz CPU and 16 GB ofRAM. From Table 8, we observe that the supervised methods (i.e., SVM_T, HeMap, DAMA, ARC-t and HFA) aregenerally faster than the semi-supervised methods (i.e., TSVM and our SHFA), because additional unlabeled samplesare used in the semi-supervised methods. SVM_T is veryfast because it only utilizes the labeled training data fromthe target domain. HeMap is fast since it only needs tosolve the eigen-decomposition problem in a very small sizedue to the limited number of labeled samples in the target domain. The training time of HFA is comparable tothat of DAMA and ARC-t. For the semi-supervised methods, we observe that our SHFA (p = 1) is faster thanT-SVM, and SHFA (p = 1.5) is slower than SHFA (p = 1).Moreover, the warm start strategy can be used to further accelerate our SHFA , which will be studied in thefuture.5C ONCLUSION AND F UTURE W ORKWe have proposed a new method called HeterogeneousFeature Augmentation (HFA) for heterogeneous domainadaptation. In HFA, we augment the heterogeneous features from the source and target domains by using twonewly proposed feature mapping functions, respectively.With the augmented features, we propose to find the twoprojection matrices for the source and target data andsimultaneously learn the classifier by using the standardSVM with the hinge loss in both linear and nonlinear cases.Then we convert the learning problem into an MKL formulation which is convex and thus the global solutioncan be guaranteed. Moreover, to utilize the abundant unlabeled data in the target domain, we further extend ourHFA method to semi-supervised HFA (SHFA). Promisingresults have demonstrated the effectiveness of HFA andSHFA on three real-world datasets for object recognition,text classification and sentiment classification.In the future, we will investigate how to incorporateother kernel learning methods such as [37] into our heterogeneous feature augmentation framework. Another important direction is to analyze the generalization bound forheterogeneous domain adaptation.Fig. 3. Performances of our SHFA using different parameters on the Reuters multilingual dataset. (a) Performances w.r.t. \u03bb. (b) Performances w.r.t.p in lp -norm. (c) Performance w.r.t. Cu .\fLI ET AL.: LEARNING WITH AUGMENTED FEATURES1147TABLE 8Average Per Class Training Time (in Seconds) Comparisons of AllMethods on the Cross-Lingual Sentiment DatasetACKNOWLEDGMENTSThis work is supported by the Singapore MOE Tier 2 Grant(ARC42/13).R EFERENCES[1] J. Blitzer, R. McDonald, and F. Pereira, \u201cDomain adaptation withstructural correspondence learning,\u201d in Proc. EMNLP, Sydney,NSW, Australia, 2006.[2] J. Blitzer, M. Dredze, and F. Pereira, \u201cBiographies, bollywood,boom-boxes and blenders: Domain adaptation for sentimentclassification,\u201d in Proc. 45th ACL, Prague, Czech Republic, 2007.[3] H. Daum\u00e9, III, \u201cFrustratingly easy domain adaptation,\u201d in Proc.ACL, 2007.[4] L. Duan, D. Xu, I. W. Tsang, and J. Luo, \u201cVisual event recognitionin videos by learning from web data,\u201d IEEE Trans. Pattern Anal.Mach. Intell., vol. 34, no. 9, pp. 1667\u20131680, Sep. 2012.[5] L. Duan, I. W. Tsang, and D. Xu, \u201cDomain transfer multiple kernellearning,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 3,pp. 465\u2013479, Mar. 2012.[6] L. Duan, D. Xu, and S.-F. Chang, \u201cExploiting web images forevent recognition in consumer videos: A multiple source domainadaptation approach,\u201d in Proc. CVPR, Providence, RI, USA, 2012,pp. 1338\u20131345.[7] L. Chen, L. Duan, and D. Xu, \u201cEvent recognition in videosby learning from heterogeneous web sources,\u201d in Proc. CVPR,Portland, OR, USA, 2013, pp. 2666\u20132673.[8] W. Dai, Y. Chen, G.-R. Xue, Q. Yang, and Y. Yu, \u201cTranslated learning: Transfer learning across different feature spaces,\u201d in Proc.NIPS, 2009.[9] Q. Yang, Y. Chen, G.-R. Xue, W. Dai, and Y. Yu, \u201cHeterogeneoustransfer learning for image clustering via the social web,\u201d in Proc.ACL/IJCNLP, Singapore, 2009.[10] Y. Zhu et al., \u201cHeterogeneous transfer learning for image classification,\u201d in Proc. AAAI, 2011.[11] B. Wei and C. Pal, \u201cCross-lingual adaptation: An experiment onsentiment classifications,\u201d in Proc. ACL, 2010.[12] P. Prettenhofer and B. Stein, \u201cCross-language text classificationusing structural correspondence learning,\u201d in Proc. ACL, 2010.[13] X. Shi, Q. Liu, W. Fan, P. S. Yu, and R. Zhu, \u201cTransfer learning onheterogenous feature spaces via spectral transformation,\u201d in Proc.ICDM, Sydney, NSW, Australia, 2010.[14] M. Harel and S. Mannor, \u201cLearning from multiple outlooks,\u201d inProc. 28th ICML, Bellevue, WA, USA, 2011.[15] C. Wang and S. Mahadevan, \u201cHeterogeneous domain adaptationusing manifold alignment,\u201d in Proc. 22nd IJCAI, 2011.[16] K. Saenko, B. Kulis, M. Fritz, and T. Darrell, \u201cAdapting visual category models to new domains,\u201d in Proc. ECCV, Heraklion, Greece,2010.[17] B. Kulis, K. Saenko, and T. Darrell, \u201cWhat you saw is notwhat you get: Domain adaptation using asymmetric kernel transforms,\u201d in Proc. CVPR, Providence, RI, USA, 2011.[18] L. Duan, D. Xu, and I. W. Tsang, \u201cLearning with augmented features for heterogeneous domain adaptation,\u201d in Proc. 29th ICML,Edinburgh, Scotland, U.K., 2012, pp. 711\u2013718.[19] M. Kloft, U. Brefeld, S. Sonnenburg, and A. Zien, \u201c\u0002p -normmultiple kernel learning,\u201d JMLR, vol. 12, pp. 953\u2013997, Mar. 2011.[20] M. Dudik, Z. Harchaoui, and J. Malick, \u201cLifted coordinatedescent for learning with trace-norm regularization,\u201d in Proc. 15thAISTATS, La Palma, Spain, 2012.[21] P. V. Gehler and S. Nowozin, \u201cInfinite kernel learning,\u201d MaxPlanck Institute for Biological Cybernetics, Tech. Rep. 178, 2008.[22] J. C. Platt, \u201cFast training of support vector machines usingsequential minimal optimization,\u201d in Advances in Kernel Methods.Cambridge, MA, USA: MIT Press, 1999, pp. 185\u2013208.[23] M. Tan, L. Wang, and I. W. Tsang, \u201cLearning sparse SVM forfeature selection on very high dimensional datasets,\u201d in Proc. 27thICML, Haifa, Israel, 2010.[24] A. Mutapcic and S. Boyd, \u201cCutting-set methods for robust convex optimization with pessimizing oracles,\u201d Optim. Meth. Softw.,vol. 24, no. 3, pp. 381\u2013406, Jun. 2009.[25] R. Collobert, F. Sinz, J. Weston, and L. Bottou, \u201cLarge scaletransductive SVMs,\u201d JMLR, vol. 7, pp. 1687\u20131712, Dec. 2006.[26] X. Zhu, \u201cSemi-supervised learning literature survey,\u201d Universityof Wisconsion-Madison, Tech. Rep. 1530, 2005.[27] L. Duan, D. Xu, and I. W. Tsang, \u201cDomain adaptation from multiple sources: A domain-dependent regularization approach,\u201d IEEETrans. Neural Netw. Learn. Syst., vol. 23, no. 3, pp. 504\u2013518, Mar.2012.[28] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, \u201cDomain adaptation via transfer component analysis,\u201d IEEE Trans. Neural Netw.Learn. Syst., vol. 22, no. 2, pp. 199\u2013210, Feb. 2011.[29] H. Daum\u00e9, III, A. Kumar, and A. Saha, \u201cCo-regularization basedsemi-supervised domain adaptation,\u201d in Proc. NIPS, 2010.[30] Y.-F. Li, I. W. Tsang, J. T. Kwok, and Z.-H. Zhou, \u201cTighter and convex maximum margin clustering,\u201d in Proc. AISTATS, ClearwaterBeach, FL, USA, 2009.[31] W. Li, L. Duan, D. Xu, and I. W. Tsang, \u201cText-based imageretrieval using progressive multi-instance learning,\u201d in Proc.ICCV, Barcelona, Spain, 2011, pp. 2049\u20132055.[32] W. Li, L. Duan, I. W. Tsang, and D. Xu, \u201cBatch mode adaptivemultiple instance learning for computer vision tasks,\u201d in Proc.CVPR, Providence, RI, USA, 2012, pp. 2368\u20132375.[33] B. Sch\u00f6lkopf et al., \u201cInput space versus feature space in kernelbased methods,\u201d IEEE Trans. Neural Netw., vol. 10, no. 5,pp. 1000\u20131017, Sep. 1999.[34] H. Bay, T. Tuytelaars, and L. V. Gool, \u201cSURF: Speeded up robustfeatures,\u201d in Proc. ECCV, Graz, Austria, 2006.[35] M. Amini, N. Usunier, and C. Goutte, \u201cLearning from multiplepartially observed views \u2013 An application to multilingual textcategorization,\u201d in Proc. NIPS, 2009.[36] P. Prettenhofer and B. Stein, \u201cCross-language text classificationusing structural correspondence learning,\u201d in Proc. 48th ACL,Uppsala, Sweden, 2010.[37] B. Kulis, M. Sustik, and I. Dhillon, \u201cLow-rank kernel learningwith Bregman matrix divergences,\u201d JMLR, vol. 10, pp. 341\u2013376,Feb. 2009.Wen Li received the B.S. and M.Eng. degreesfrom the Beijing Normal University, Beijing,China, in 2007 and 2010, respectively. Currently,he is pursuing the Ph.D. degree with theSchool of Computer Engineering, NanyangTechnological University, Singapore. His currentresearch interests include ambiguous learning,domain adaptation, and multiple kernel learning.Lixin Duan received the B.E. degree fromthe University of Science and Technologyof China, Hefei, China, in 2008 and thePh.D. degree from the Nanyang TechnologicalUniversity, Singapore, in 2012. Currently, he is aresearch scientist with the Institute for InfocommResearch, Singapore. He was a recipient ofthe Microsoft Research Asia Fellowship in 2009and the Best Student Paper Award at the IEEEConference on Computer Vision and PatternRecognition 2010. His current research interests include transfer learning, multiple instance learning, and theirapplications in computer vision and data mining.\f1148IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 6, JUNE 2014Dong Xu (M\u201907\u2013SM\u201913) received the B.E. andPh.D. degrees from the University of Scienceand Technology of China, Hefei, China, in 2001and 2005, respectively. While pursuing the Ph.D.degree, he was with Microsoft Research Asia,Beijing, China, and the Chinese University ofHong Kong, Shatin, Hong Kong, for more thantwo years. He was a post-doctoral research scientist with Columbia University, New York, NY,USA, for one year. Currently, he is an associateprofessor with Nanyang Technological University,Singapore. His current research interests include computer vision,statistical learning, and multimedia content analysis. He was the coauthor of a paper that won the Best Student Paper Award in the IEEEInternational Conference on Computer Vision and Pattern Recognitionin 2010.Ivor W. Tsang is an Australian Future Fellowand Associate Professor with the Centre forQuantum Computation & Intelligent Systems(QCIS), at the University of Technology, Sydney(UTS). Before joining UTS, he was the DeputyDirector of the Centre for ComputationalIntelligence, Nanyang Technological University,Singapore. He received his PhD degree in computer science from the Hong Kong University ofScience and Technology in 2007. He has morethan 100 research papers published in refereedinternational journals and conference proceedings, including JMLR,TPAMI, TNN/TNNLS, NIPS, ICML, UAI, AISTATS, SIGKDD, IJCAI,AAAI, ACL, ICCV, CVPR, ICDM, etc. In 2009, Dr Tsang was conferredthe 2008 Natural Science Award (Class II) by Ministry of Education,China, which recognized his contributions to kernel methods. In 2013,Dr Tsang received his prestigious Australian Research Council FutureFellowship for his research regarding Machine Learning on Big Data.Besides this, he had received the prestigious IEEE Transactions onNeural Networks Outstanding 2004 Paper Award in 2006, and anumber of best paper awards and honors from reputable internationalconferences, including the Best Student Paper Award at CVPR 2010,the Best Paper Award at ICTAI 2011, the Best Poster Award HonorableMention at ACML 2012, the Best Student Paper Nomination at theIEEE CEC 2012, and the Best Paper Award from the IEEE Hong KongChapter of Signal Processing Postgraduate Forum in 2006. He wasalso awarded the Microsoft Fellowship 2005, and the ECCV 2012Outstanding Reviewer Award.\u0002 For more information on this or any other computing topic,please visit our Digital Library at www.computer.org/publications/dlib.\f", "Mach Learn (2010) 79: 151\u2013175DOI 10.1007/s10994-009-5152-4A theory of learning from different domainsShai Ben-David \u00b7 John Blitzer \u00b7 Koby Crammer \u00b7Alex Kulesza \u00b7 Fernando Pereira \u00b7Jennifer Wortman VaughanReceived: 28 February 2009 / Revised: 12 September 2009 / Accepted: 18 September 2009 /Published online: 23 October 2009\u00a9 The Author(s) 2009. This article is published with open access at Springerlink.comAbstract Discriminative learning methods for classification perform well when trainingand test data are drawn from the same distribution. Often, however, we have plentiful labeledtraining data from a source domain but wish to learn a classifier which performs well ona target domain with a different distribution and little or no labeled training data. In thiswork we investigate two questions. First, under what conditions can a classifier trained fromsource data be expected to perform well on target data? Second, given a small amount oflabeled target data, how should we combine it during training with the large amount oflabeled source data to achieve the lowest target error at test time?Editors: Nicolo Cesa-Bianchi, David R. Hardoon, and Gayle Leen.Preliminary versions of the work contained in this article appeared in Advances in Neural InformationProcessing Systems (Ben-David et al. 2006; Blitzer et al. 2007a).S. Ben-DavidDavid R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canadae-mail: shai@cs.uwaterloo.caJ. Blitzer (\u0002)Department of Computer Science, UC Berkeley, Berkeley, CA, USAe-mail: blitzer@cs.berkeley.eduK. CrammerDepartment of Electrical Engineering, The Technion, Haifa, Israele-mail: koby@ee.technion.ac.ilA. KuleszaDepartment of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USAe-mail: kulesza@cis.upenn.eduF. PereiraGoogle Research, Mountain View, CA, USAe-mail: pereira@google.comJ.W. VaughanSchool of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USAe-mail: jenn@seas.harvard.edu\f152Mach Learn (2010) 79: 151\u2013175We address the first question by bounding a classifier\u2019s target error in terms of its sourceerror and the divergence between the two domains. We give a classifier-induced divergencemeasure that can be estimated from finite, unlabeled samples from the domains. Under theassumption that there exists some hypothesis that performs well in both domains, we showthat this quantity together with the empirical source error characterize the target error of asource-trained classifier.We answer the second question by bounding the target error of a model which minimizesa convex combination of the empirical source and target errors. Previous theoretical workhas considered minimizing just the source error, just the target error, or weighting instancesfrom the two domains equally. We show how to choose the optimal combination of sourceand target error as a function of the divergence, the sample sizes of both domains, and thecomplexity of the hypothesis class. The resulting bound generalizes the previously studiedcases and is always at least as tight as a bound which considers minimizing only the targeterror or an equal weighting of source and target errors.Keywords Domain adaptation \u00b7 Transfer learning \u00b7 Learning theory \u00b7 Sample-selectionbias1 IntroductionMost research in machine learning, both theoretical and empirical, assumes that models aretrained and tested using data drawn from some fixed distribution. This single domain settinghas been well studied, and uniform convergence theory guarantees that a model\u2019s empiricaltraining error is close to its true error under such assumptions. In many practical cases,however, we wish to train a model in one or more source domains and then apply it to adifferent target domain. For example, we might have a spam filter trained from a large emailcollection received by a group of current users (the source domain) and wish to adapt it fora new user (the target domain). Intuitively this should improve filtering performance for thenew user, under the assumption that users generally agree on what is spam and what is not.The challenge is that each user receives a unique distribution of email.Many other examples arise in natural language processing. In general, labeled data fortasks like part-of-speech tagging (Ratnaparkhi 1996), parsing (Collins 1999), informationextraction (Bikel et al. 1997), and sentiment analysis (Pang et al. 2002) are drawn froma limited set of document types and genres in a given language due to availability, cost,and specific goals of the project. However, useful applications for the trained systems mayinvolve documents of different types or genres. We can hope to successfully adapt the systems in these cases since parts-of-speech, syntactic structure, entity mentions, and positiveor negative sentiment are to a large extent stable across different domains, as they dependon general properties of language.In this work we investigate the problem of domain adaptation. We analyze a settingin which we have plentiful labeled training data drawn from one or more source distributions but little or no labeled training data drawn from the target distribution of interest.This work answers two main questions. First, under what conditions on the source andtarget distributions can we expect to learn well? We give a bound on a classifier\u2019s targetdomain error in terms of its source domain error and a divergence measure between thetwo domains. In a distribution-free setting, we cannot obtain accurate estimates of common measures of divergence such as L1 or Kullback-Leibler from finite samples. Instead,we show that when learning a hypothesis from a class of finite complexity, it is sufficient to use a classifier-induced divergence we call the H\u0002H-divergence (Kifer et al. 2004;\fMach Learn (2010) 79: 151\u2013175153Ben-David et al. 2006). Finite sample estimates of the H\u0002H-divergence converge uniformlyto the true H\u0002H-divergence, allowing us to estimate the domain divergence from unlabeleddata in both domains. Our final bound on the target error is in terms of the empirical sourceerror, the empirical H\u0002H-divergence between unlabeled samples from the domains, and thecombined error of the best single hypothesis for both domains.A second important question is how to learn when the large quantity of labeled sourcedata is augmented with a small amount of labeled target data, for example, when our newemail user has begun to manually mark a few received messages as spam. Given a sourcedomain S and a target domain T , we consider hypotheses h which minimize a convex combination of empirical source and target error (\u0003\u02c6T (h) and \u0003\u02c6S (h), respectively), which we referto as the empirical \u03b1-error:\u03b1 \u0003\u02c6T (h) + (1 \u2212 \u03b1)\u02c6\u0003S (h).Setting \u03b1 involves trading off the ideal but small target dataset against the large (but lessrelevant) source dataset. Baseline choices for \u03b1 include \u03b1 = 0 (using only source data) (BenDavid et al. 2006), \u03b1 = 1 (using only target data), and the equal weighting of source andtarget instances (Crammer et al. 2008), setting \u03b1 to the fraction of the instances that are fromthe target domain. We give a bound on a classifier\u2019s target error in terms of its empirical \u03b1error. The \u03b1 that minimizes the bound depends on the divergence between the domains aswell as the size of the source and target training datasets. The optimal bound is always atleast as tight as the bounds using only source, only target, or equally-weighted source andtarget instances. We show that for a real-world problem of sentiment classification, nontrivial settings of \u03b1 perform better than the three baseline settings.In the next section, we give a brief overview of related work. We then specify preciselyour model of domain adaptation. Section 4 shows how to bound the target error of a hypothesis in terms of its source error and the source-target divergence. Section 5 gives our mainresult, a bound on the target error of a classifier which minimizes a convex combination ofempirical errors on the two domains, and in Sect. 6 we investigate the properties of the bestconvex combination of that bound. In Sect. 7, we illustrate experimentally the above boundson sentiment classification data. Section 8 describes how to extend the previous results tothe case of multiple data sources. Finally, we conclude with a brief discussion of futuredirections for research in Sect. 9.2 Related workCrammer et al. (2008) introduced a PAC-style model of learning from multiple sourcesin which the distribution over input points is assumed to be the same across sources buteach source may have its own deterministic labeling function. They derive bounds on thetarget error of the function that minimizes the empirical error on (uniformly weighted) datafrom any subset of the sources. As discussed in Sect. 8.2, the bounds that they derive areequivalent to ours in certain restricted settings, but their theory is significantly less general.Daum\u00e9 (2007) and Finkel (2009) suggest an empirically successful method for domainadaptation based on multi-task learning. The crucial difference between our domain adaptation setting and analyses of multi-task methods is that multi-task bounds require labeleddata from each task, and make no attempt to exploit unlabeled data. Although these boundshave a more limited scope than ours, they can sometimes yield useful results even when theoptimal predictors for each task (or domain in the case of Daum\u00e9 2007) are quite different (Baxter 2000; Ando and Zhang 2005).\f154Mach Learn (2010) 79: 151\u2013175Li and Bilmes (2007) give PAC-Bayesian learning bounds for adaptation using \u201cdivergence priors.\u201d In particular, they place a source-centered prior on the parameters of a modellearned in the target domain. Like our model, the divergence prior emphasizes the tradeoff between source hypotheses trained on large (but biased) data sets and target hypothesestrained from small (but unbiased) data sets. In our model, however, we measure the divergence (and consequently the bias) of the source domain from unlabeled data. This allows usto choose a tradeoff parameter for source and target labeled data before training begins.More recently, Mansour et al. (2009a, 2009b) introduced a theoretical model for the\u201cmultiple source adaptation problem.\u201d This model operates under assumptions very similarto our multiple source analysis (Sect. 8), and we address their work in more detail there.Finally, domain adaptation is closely related to the setting of sample selection bias (Heckman 1979). A well-studied variant of this is covariate shift, which has seen significant workin recent years (Huang et al. 2007; Sugiyama et al. 2008; Cortes et al. 2008). This line ofwork leads to algorithms based on instance weighting, which have also been explored empirically in the machine learning and natural language processing communities (Jiang andZhai 2007; Bickel et al. 2007). Our work differs from covariate shift primarily in two ways.First, we do not assume the labeling rule is identical for the source and target data (althoughthere must exist some good labeling rule for both in order to achieve low error). Second,our H\u0002H-divergence can be computed from finite samples of unlabeled data, allowing usto directly estimate the error of a source-trained classifier on the target domain.A point of general contrast is that we work in an agnostic setting in which we do notmake strong assumptions about the data generation model, such as a specific relationshipbetween the source and target data distributions, which would be needed to obtain absoluteerror bounds. Instead, we assume only that the samples from each of the two domains aregenerated i.i.d. according to the respective data distributions, and as a result our boundsmust be relative to the error of some benchmark predictor rather than absolute, specifically,relative to the combined error on both domains of an optimal joint predictor.3 A rigorous model of domain adaptationWe formalize the problem of domain adaptation for binary classification as follows. Wedefine a domain1 as a pair consisting of a distribution D on inputs X and a labeling functionf : X \u2192 [0, 1], which can have a fractional (expected) value when labeling occurs nondeterministically. Initially, we consider two domains, a source domain and a target domain.We denote by \u0003DS , fS \u0004 the source domain and \u0003DT , fT \u0004 the target domain.A hypothesis is a function h : X \u2192 {0, 1}. The probability according to the distributionDS that a hypothesis h disagrees with a labeling function f (which can also be a hypothesis)is defined as\u0002\u0003\u0003S (h, f ) = Ex\u223cDS |h(x) \u2212 f (x)| .When we want to refer to the source error (sometimes called risk) of a hypothesis, we usethe shorthand \u0003S (h) = \u0003S (h, fS ). We write the empirical source error as \u0003\u02c6S (h). We use theparallel notation \u0003T (h, f ), \u0003T (h), and \u0003\u02c6T (h) for the target domain.1 Note that this notion of domain is not the domain of a function. We always mean a specific distribution andfunction pair when we say \u201cdomain.\u201d\fMach Learn (2010) 79: 151\u20131751554 A bound relating the source and target errorWe now proceed to develop bounds on the target domain generalization performance of aclassifier trained in the source domain. We first show how to bound the target error in termsof the source error, the difference between labeling functions fS and fT , and the divergencebetween the distributions DS and DT . Since we expect the labeling function difference tobe small in practice, we focus here on measuring distribution divergence, and especially onhow to estimate it with finite samples of unlabeled data from DS and DT . That is the role ofthe H-divergence introduced in Sect. 4.1.A natural measure of divergence for distributions is the L1 or variation divergenced1 (D, D\u0006 ) = 2 sup |PrD [B] \u2212 PrD\u0006 [B]| ,B\u2208Bwhere B is the set of measurable subsets under D and D\u0006 . We make use of this measure tostate an initial bound on the target error of a classifier.Theorem 1 For a hypothesis h,\u0003T (h) \u2264 \u0003S (h) + d1 (DS , DT )\u0003\u0003\u0005\u0002\u0002\u0004+ min EDS |fS (x) \u2212 fT (x)| , EDT |fS (x) \u2212 fT (x)| .\u0002Proof See Appendix.In this bound, the first term is the source error, which a training algorithm might seekto minimize, and the third is the difference in labeling functions across the two domains,which we expect to be small. The problem is the remaining term. Bounding the error interms of the L1 divergence between distributions has two disadvantages. First, it cannot beaccurately estimated from finite samples of arbitrary distributions (Batu et al. 2000; Kiferet al. 2004) and therefore has limited usefulness in practice. Second, for our purposes the L1divergence is an overly strict measure that unnecessarily inflates the bound, since it involvesa supremum over all measurable subsets. We are only interested in the error of a hypothesisfrom some class of finite complexity, thus we can restrict our attentions to the subsets onwhich this type of hypothesis can commit errors. The divergence measure introduced in thenext section addresses both of these concerns.4.1 The H-divergenceDefinition 1 (Based on Kifer et al. 2004) Given a domain X with D and D\u0006 probabilitydistributions over X , let H be a hypothesis class on X and denote by I (h) the set for whichh \u2208 H is the characteristic function; that is, x \u2208 I (h) \u21d4 h(x) = 1. The H-divergence between D and D\u0006 isdH (D, D\u0006 ) = 2 sup |PrD [I (h)] \u2212 PrD\u0006 [I (h)] |.h\u2208HThe H-divergence resolves both problems associated with the L1 divergence. First, for hypothesis classes H of finite VC dimension, the H-divergence can be estimated from finitesamples (see Lemma 1 below). Second, the H-divergence for any class H is never largerthan the L1 divergence, and is in general smaller when H has finite VC dimension.Since it plays an important role in the rest of this work, we now state a slight modificationof Theorem 3.4 of Kifer et al. (2004) as a lemma.\f156Mach Learn (2010) 79: 151\u2013175Lemma 1 Let H be a hypothesis space on X with VC dimension d. If U and U \u0006 are samplesof size m from D and D\u0006 respectively and d\u0302H (U , U \u0006 ) is the empirical H-divergence betweensamples, then for any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4,\u0006\u0006\u0006dH (D, D ) \u2264 d\u0302H (U , U ) + 4d log(2m) + log( 2\u03b4 ).mLemma 1 shows that the empirical H-divergence between two samples from distributionsD and D\u0006 converges uniformly to the true H-divergence for hypothesis classes H of finiteVC dimension.The next lemma shows that we can compute the H-divergence by finding a classifierwhich attempts to separate one domain from the other. Our basic plan of attack will beas follows: Label each unlabeled source instance with 0 and unlabeled target instance as 1.Then train a classifier to discriminate between source and target instances. The H-divergenceis immediately computable from the error.Lemma 2 For a symmetric hypothesis class H (one where for every h \u2208 H, the inversehypothesis 1 \u2212 h is also in H) and samples U , U \u0006 of size m\u0007\b\u0002\u000311\u0006I [x \u2208 U ] +I x \u2208 U\u0006d\u0302H (U , U ) = 2 1 \u2212 min,h\u2208H mmx:h(x)=0x:h(x)=1where I [x \u2208 U ] is the binary indicator variable which is 1 when x \u2208 U .\u0002Proof See Appendix.This lemma leads directly to a procedure for computing the H-divergence. We first finda hypothesis in H which has minimum error for the binary classification problem of distinguishing source from target instances. The error of this hypothesis is related to the Hdivergence by Lemma 2. Of course, minimizing error for most reasonable hypothesis classesis a computationally intractable problem. Nonetheless, as we shall see in Sect. 7, the error ofhypotheses trained to minimize convex upper bounds on error are useful in approximatingthe H-divergence.4.2 Bounding the difference in error using the H-divergenceThe H-divergence allows us to estimate divergence from unlabeled data, but in order to useit in a bound we must have tools to represent error relative to other hypotheses in our class.We introduce two new definitions.Definition 2 The ideal joint hypothesis is the hypothesis which minimizes the combinederrorh\u2217 = argmin \u0003S (h) + \u0003T (h).h\u2208HWe denote the combined error of the ideal hypothesis by\u03bb = \u0003S (h\u2217 ) + \u0003T (h\u2217 ).\fMach Learn (2010) 79: 151\u2013175157The ideal joint hypothesis explicitly embodies our notion of adaptability. When this hypothesis performs poorly, we cannot expect to learn a good target classifier by minimizingsource error. On the other hand, we will show that if the ideal joint hypothesis performswell, we can measure adaptability of a source-trained classifier by using the H-divergencebetween the marginal distributions DS and DT .Next we define the symmetric difference hypothesis space H\u0002H for a hypothesisspace H, which will be very useful in reasoning about error.Definition 3 For a hypothesis space H, the symmetric difference hypothesis space H\u0002H isthe set of hypothesesg \u2208 H \u0002H\u21d0\u21d2g(x) = h(x) \u2295 h\u0006 (x)for some h, h\u0006 \u2208 H,where \u2295 is the XOR function. In words, every hypothesis g \u2208 H\u0002H is the set of disagreements between two hypotheses in H.The following simple lemma shows how we can make use of the H\u0002H-divergence inbounding the error of our hypothesis.Lemma 3 For any hypotheses h, h\u0006 \u2208 H,1|\u0003S (h, h\u0006 ) \u2212 \u0003T (h, h\u0006 )| \u2264 dH\u0002H (DS , DT ).2Proof By the definition of H\u0002H-distance,\u0003\u0003\u0002\u0002dH\u0002H (DS , DT ) = 2 sup Prx\u223cDS h(x) \u000e= h\u0006 (x) \u2212 Prx\u223cDT h(x) \u000e= h\u0006 (x)h,h\u0006 \u2208H= 2 sup |\u0003S (h, h\u0006 ) \u2212 \u0003T (h, h\u0006 )| \u2265 2|\u0003S (h, h\u0006 ) \u2212 \u0003T (h, h\u0006 )|.h,h\u0006 \u2208H\u0002We are now ready to give a bound on target error in terms of the new divergence measurewe have defined.Theorem 2 Let H be a hypothesis space of VC dimension d. If US , UT are unlabeled samples of size m\u0006 each, drawn from DS and DT respectively, then for any \u03b4 \u2208 (0, 1), withprobability at least 1 \u2212 \u03b4 (over the choice of the samples), for every h \u2208 H:\u00062d log(2m\u0006 ) + log( 2\u03b4 )1+ \u03bb.\u0003T (h) \u2264 \u0003S (h) + d\u0302H\u0002H (US , UT ) + 42m\u0006Proof This proof relies on Lemma 3 and the triangle inequality for classification error (BenDavid et al. 2006; Crammer et al. 2008), which implies that for any labeling functions f1 ,f2 , and f3 , we have \u0003(f1 , f2 ) \u2264 \u0003(f1 , f3 ) + \u0003(f2 , f3 ). Then\u0003T (h) \u2264 \u0003T (h\u2217 ) + \u0003T (h, h\u2217 )\u2264 \u0003T (h\u2217 ) + \u0003S (h, h\u2217 ) + \u0003T (h, h\u2217 ) \u2212 \u0003S (h, h\u2217 )1\u2264 \u0003T (h\u2217 ) + \u0003S (h, h\u2217 ) + dH\u0002H (DS , DT )2\f158Mach Learn (2010) 79: 151\u20131751\u2264 \u0003T (h\u2217 ) + \u0003S (h) + \u0003S (h\u2217 ) + dH\u0002H (DS , DT )21= \u0003S (h) + dH\u0002H (DS , DT ) + \u03bb2\u00062d log(2m\u0006 ) + log( 2\u03b4 )1\u2264 \u0003S (h) + d\u0302H\u0002H (US , UT ) + 4+ \u03bb.2m\u0006The last step is an application of Lemma 1, together with the observation that since we canrepresent every g \u2208 H\u0002H as a linear threshold network of depth 2 with 2 hidden units, theVC dimension of H\u0002H is at most twice the VC dimension of H (Anthony and Bartlett1999).\u0002The bound in Theorem 2 is relative to \u03bb, and we briefly comment that the form\u03bb = \u0003S (h\u2217 ) + \u0003T (h\u2217 ) comes from the use of the triangle inequality for classification error.Other losses result in other forms for this bound (Crammer et al. 2008). When the combinederror of the ideal joint hypothesis is large, then there is no classifier that performs well onboth the source and target domains, so we cannot hope to find a good target hypothesis bytraining only on the source domain. On the other hand, for small \u03bb (the most relevant casefor domain adaptation), the bound shows that source error and unlabeled H\u0002H-divergenceare important quantities in computing the target error.5 A learning bound combining source and target training dataTheorem 2 shows how to relate source and target error. We now proceed to give a learningbound for empirical risk minimization using combined source and target training data.At train time a learner receives a sample S = (ST , SS ) of m instances, where ST consistsof \u03b2m instances drawn independently from DT and SS consists of (1 \u2212 \u03b2)m instances drawnindependently from DS . The goal of a learner is to find a hypothesis that minimizes targeterror \u0003T (h). When \u03b2 is small, as in domain adaptation, minimizing empirical target errormay not be the best choice. We analyze learners that instead minimize a convex combinationof empirical source and target error,\u0003\u02c6\u03b1 (h) = \u03b1 \u0003\u02c6T (h) + (1 \u2212 \u03b1)\u02c6\u0003S (h),for some \u03b1 \u2208 [0, 1]. We denote as \u0003\u03b1 (h) the corresponding weighted combination of truesource and target errors, measured with respect to DS and DT .We bound the target error of a domain adaptation algorithm that minimizes \u0003\u02c6\u03b1 (h). Theproof of the bound has two main components, which we state as lemmas below. First webound the difference between the target error \u0003T (h) and weighted error \u0003\u03b1 (h). Then webound the difference between the true and empirical weighted errors \u0003\u03b1 (h) and \u0003\u02c6\u03b1 (h).Lemma 4 Let h be a hypothesis in class H. Then\u00071|\u0003\u03b1 (h) \u2212 \u0003T (h)| \u2264 (1 \u2212 \u03b1) dH\u0002H (DS , DT ) + \u03bb .2Proof See Appendix.\u0002\fMach Learn (2010) 79: 151\u2013175159The lemma shows that as \u03b1 approaches 1, we rely increasingly on the target data, andthe distance between domains matters less and less. The uniform convergence bound on the\u03b1-error is nearly identical to the standard uniform convergence bound for hypothesis classesof finite VC dimension (Vapnik 1998; Anthony and Bartlett 1999), only with target andsource errors weighted differently. The key part of the proof relies on a slight modificationof Hoeffding\u2019s inequality for our setup, which we state here:Lemma 5 For a fixed hypothesis h, if a random labeled sample of size m is generated bydrawing \u03b2m points from DT and (1 \u2212 \u03b2)m points from DS , and labeling them accordingto fS and fT respectively, then for any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4 (over thechoice of the samples),\u0002\u0003Pr |\u02c6\u0003\u03b1 (h) \u2212 \u0003\u03b1 (h)| \u2265 \u0003 \u2264 2 exp\u0007\u22122m\u0003 2\u03b12\u03b2+.(1\u2212\u03b1)21\u2212\u03b2Before giving the proof, we first restate Hoeffding\u2019s inequality for completeness.Proposition 1 (Hoeffding\u2019s inequality) If X1 , . . . , Xn are independent random variableswith ai \u2264 Xi \u2264 bi for all i, then for any \u0003 > 0,\u0002\u00032 2Pr |X\u0304 \u2212 E[X\u0304]| \u2265 \u0003 \u2264 2e\u22122n \u0003 /n (b \u2212a )2ii=1 i,where X\u0304 = (X1 + \u00b7 \u00b7 \u00b7 + Xn )/n.We are now ready to prove the lemma.Proof (Lemma 5) Let X1 , . . . , X\u03b2m be random variables that take on the values\u03b1|h(x) \u2212 fT (x)|\u03b2for the \u03b2m instances x \u2208 ST . Similarly, let X\u03b2m+1 , . . . , Xm be random variables that take onthe values1\u2212\u03b1|h(x) \u2212 fS (x)|1\u2212\u03b2for the (1 \u2212 \u03b2)m instances x \u2208 SS . Note that X1 , . . . , X\u03b2m \u2208 [0, \u03b1/\u03b2] and X\u03b2m+1 , . . . , Xm \u2208[0, (1 \u2212 \u03b1)/(1 \u2212 \u03b2)]. Then\u0003\u02c6\u03b1 (h) = \u03b1 \u0003\u02c6T (h) + (1 \u2212 \u03b1)\u02c6\u0003S (h)=\u03b1111|h(x) \u2212 fT (x)| + (1 \u2212 \u03b1)|h(x) \u2212 fS (x)| =\u03b2m x\u2208S(1 \u2212 \u03b2)m x\u2208SmTSFurthermore, by linearity of expectations\u000711\u2212\u03b1\u03b1\u0003S (h))E[\u02c6\u0003\u03b1 (h)] =\u03b2m \u0003T (h) + (1 \u2212 \u03b2)mm\u03b21\u2212\u03b2= \u03b1\u0003T (h) + (1 \u2212 \u03b1)\u0003S (h) = \u0003\u03b1 (h).mXi .i=1\f160Mach Learn (2010) 79: 151\u2013175So by Hoeffding\u2019s inequality the following holds for every h.\u0007\u0002\u0003\u22122m2 \u0003 2Pr |\u02c6\u0003\u03b1 (h) \u2212 \u0003\u03b1 (h)| \u2265 \u0003 \u2264 2 expm2i=1 range (Xi )\u0007\u22122m2 \u0003 2= 2 exp\u03b1 21\u2212\u03b1 2\u03b2m( \u03b2 ) + (1 \u2212 \u03b2)m( 1\u2212\u03b2)\u0007\u22122m\u0003 2= 2 exp 2.2\u03b1+ (1\u2212\u03b1)\u03b21\u2212\u03b2\u0002This lemma shows that as \u03b1 moves away from \u03b2 (where each instance is weightedequally), our finite sample approximation to \u0003\u03b1 (h) becomes less reliable. We can now moveon to the main theorem of this section.Theorem 3 Let H be a hypothesis space of VC dimension d. Let US and UT be unlabeledsamples of size m\u0006 each, drawn from DS and DT respectively. Let S be a labeled sample ofsize m generated by drawing \u03b2m points from DT and (1 \u2212 \u03b2)m points from DS and labelingthem according to fS and fT , respectively. If h\u0302 \u2208 H is the empirical minimizer of \u0003\u02c6\u03b1 (h)on S and h\u2217T = minh\u2208H \u0003T (h) is the target error minimizer, then for any \u03b4 \u2208 (0, 1), withprobability at least 1 \u2212 \u03b4 (over the choice of the samples),\u0006\u0006222d log(2(m + 1)) + 2 log( 8\u03b4 )(1\u2212\u03b1)\u03b1\u0003T (h\u0302) \u2264 \u0003T (h\u2217T ) + 4+\u03b21\u2212\u03b2m\u0006\u00072d log(2m\u0006 ) + log( 8\u03b4 )1+\u03bb .+ 2(1 \u2212 \u03b1) d\u0302H\u0002H (US , UT ) + 42m\u0006The proof follows the standard set of steps for proving learning bounds (Anthony andBartlett 1999), using Lemma 4 to bound the difference between target and weighted errorsand Lemma 5 for the uniform convergence of empirical and true weighted errors. The fullproof is in Appendix.When \u03b1 = 0 (that is, we ignore target data), the bound is identical to that of Theorem 2,but with an empirical estimate for the source error. Similarly when \u03b1 = 1 (that is, we useonly target data), the bound is the standard learning bound using only target data. At theoptimal \u03b1 (which minimizes the right hand side), the bound is always at least as tight aseither of these two settings. Finally note that by choosing different values of \u03b1, the boundallows us to effectively trade off the small amount of target data against the large amount ofless relevant source data.We remark that when it is known that \u03bb = 0, the dependence on m in Theorem 3 can beimproved; this corresponds to the restricted or realizable setting.6 Optimal mixing valueWe examine now the bound of Theorem 3 in more detail to illustrate some interesting properties. Writing the bound as a function of \u03b1 and omitting additive constants, we obtain\u0006\u0007\u03b1 2 (1 \u2212 \u03b1)2f (\u03b1) = 2B++ 2(1 \u2212 \u03b1)A,(1)\u03b21\u2212\u03b2\fMach Learn (2010) 79: 151\u2013175where\u0007A=161\u00062d log(2m\u0006 ) + log( 4\u03b4 )1d\u0302H\u0002H (US , UT ) + 4+\u03bb ,2m\u0006is the total divergence between source and target, and\u00062d log(2(m + 1)) + 2 log( 8\u03b4 )B =4m\u221ais the complexity term, which is approximately d/m. The optimal value \u03b1 \u2217 is a function ofthe number of target\u221a examples mT = \u03b2m, the number of source examples mS = (1 \u2212 \u03b2)m,and the ratio D = d/A:\u000e1mT \u2265 D 2(2)\u03b1 \u2217 (mT , mS ; D) =min{1, \u03bd} mT \u2264 D 2 ,where\u0007mTmS\u03bd=1+ \u000f.2mT + mSD (mS + mT ) \u2212 mS mTSeveral observations follow from this analysis. First, if mT = 0 (\u03b2 = 0) then \u03b1 \u2217 = 0 andif mS = 0 (\u03b2 = 1) then \u03b1 \u2217 = 1. That is, if we have only source or only target data, the bestcombination is to use exactly what we have. Second, if we are certain that the source andtarget are the same, that is if A = 0 (or D \u2192 \u221e), then \u03b1 \u2217 = \u03b2, that is, the optimal combination is to use the training data with uniform weighting of the examples across all examples,as in Crammer et al. (2008), who always enforce such a uniform weighing. Finally, twophase transitions occur in the value of \u03b1 \u2217 . First, if there are enough target data (specifically,if mT \u2265 D 2 = d/A2 ) then no source data are needed, and in fact using any source data willyield suboptimal performance. This is because the possible reduction in error due to additional source data is always less than the increase in error caused by the source data beingtoo far from the target data. Second, even if there are few target examples, it might be thecase that we do not have enough source data to justify using it, and this small amount ofsource data should be ignored. Once we have enough source data then we get a non-trivialvalue for \u03b1 \u2217 .These two phase transitions are illustrated in Fig. 1. The intensity of a point reflects thevalue \u03b1 \u2217 and ranges from 0 (white) to 1 (black). In this plot \u03b1 \u2217 is a function of mS (x axis)and mT (y axis), and we fix the complexity to d = 1,601 and the divergence between sourceand target to A = 0.715. We chose these values to correspond more closely to real data (seeSect. 7). Observe first that D 2 = 1,601/(0.715)2 \u2248 3,130. When mT \u2265 D 2 , the first case of(2) predicts that \u03b1 \u2217 = 1 for all values of mS , which is illustrated by the black region abovethe line mT = 3,130. Furthermore, fixing the value of mT \u2264 3,130, the second case of (2)predicts that \u03b1 \u2217 will be either one (1) if mS is small enough, or go smoothly to zero as mSincreases. This is illustrated by any horizontal line with mT \u2264 3,130. Each such line is blackfor small values of mS and then gradually becomes white as mS increases (left to right).7 Results on sentiment classificationIn this section we illustrate our theory on the natural language processing task of sentimentclassification (Pang et al. 2002). The point of these experiments is not to instantiate the\f162Mach Learn (2010) 79: 151\u2013175Fig. 1 An illustration of the phase transition in the balance between source and target training data. Thevalue of \u03b1 minimizing the bound is indicated by the intensity, where black means \u03b1 = 1. We fix d = 1,601and A = 0.715, approximating the empirical setup in Fig. 3. The x-axis shows the number of source instances (log-scale). The y-axis shows the number of target instances. A phase transition occurs at 3,130target instances. With more target instances than this, it is more effective to ignore even an infinite amount ofsource databound from Theorem 3 directly, since the amount of data we use here is much too smallfor the bound to yield meaningful numerical results. Instead, we show how the two mainprinciples of our theory from Sects. 4 and 5 can be applied on a real-world problem. First,we show that an approximation to the H-distance, obtained by training a linear model to discriminate between instances from different domains, correlates well with the loss incurredby training in one domain and testing in another. Second, we investigate minimizing the\u03b1-error as suggested by Theorem 3. We show that the optimal value of \u03b1 for a given amountof source and target data is closely related to our approximate H-distance.The next subsection describes the problem of sentiment classification, along with ourdataset, features, and learning algorithms. Then we show experimentally how our approximate H-distance is related to the adaptation performance and the optimal value of \u03b1.7.1 Sentiment classificationGiven a piece of text (usually a review or essay), automatic sentiment classification is thetask of determining whether the sentiment expressed by the text is positive or negative (Panget al. 2002; Turney 2002). While movie reviews are the most commonly studied domain,sentiment analysis has been extended to a number of new domains, ranging from stockmessage boards to congressional floor debates (Das and Chen 2001; Thomas et al. 2006).Research results have been deployed industrially in systems that gauge market reaction andsummarize opinion from Web pages, discussion boards, and blogs.We used the publicly available data set from (Blitzer et al. 2007b) to examine our theory.2The data set consists of reviews from the Amazon website for several different types ofproducts. We chose reviews from the domains apparel, books, DVDs, kitchen & housewares,and electronics. Each review consists of a rating (1\u20135 stars), a title, and review text. Wecreated a binary classification problem by binning reviews with 1\u20132 stars as \u201cnegative\u201d and4\u20135 stars as \u201cpositive\u201d. Reviews with 3 stars were discarded.Classifying product reviews as having either positive or negative sentiment fits well intoour theory of domain adaptation. We note that reviews for different products have widely2 Available at https://www.cs.jhu.edu/~mdredze/.\fMach Learn (2010) 79: 151\u2013175163Positive books reviewTitle: A great find during an annual summer shopping tripReview: I found this novel at a bookstore on the boardwalk I visit every summer....The narrative was brilliantly told,the dialogue completely believable and theplot totally heartwrenching. If I had madeit to the end without some tears, I wouldbelieve myself made of stone!Negative books reviewTitle: The Hard WayReview: I am not sure whatever possessed me to buy this book. Honestly,it was a complete waste of my time. Toquote a friend, it was not the best useof my entertainment dollar. If you area fan of pedestrian writing, lack-lusterplots and hackneyed character development, this is your book.Positive kitchen & housewares reviewTitle: no more doggy feuds with neighborReview: i absolutely love this product. myneighbor has four little yippers and myshepard/chow mix was antagonized by theyipping on our side of the fence. I hungthe device on my side of the fence and thenoise keeps the neighbors dog from picking \u201carguments\u201d with my dog. all barkingand fighting has ceased.Negative kitchen & housewares reviewTitle: cooks great, lid does not workwell. . .Review: I Love the way the Tefal deepfryer cooks, however, I am returning mysecond one due to a defective lid closure. The lid may close initially, but after a few uses it no longer stays closed.Since I have small children in my home,I will not be purchasing this one again.Fig. 2 Some sample product reviews for sentiment classification. The top row shows reviews from the booksdomain. The bottom row shows reviews from kitchen & housewaresdifferent vocabularies, so classifiers trained on one domain are likely to miss out on important lexical cues in a different domain. On the other hand, a single good universal sentimentclassifier is likely to exist\u2014namely the classifier that assigns high positive weight to all positive words and high negative weight to all negative words, regardless of product type. Weillustrate the type of text in this dataset in Fig. 2, which shows one positive and one negativereview each from the domains books and kitchen & housewares.For each domain, the data set contains 1,600 labeled documents and between 5,000 and6,000 unlabeled documents. We follow Pang et al. (2002) and represent each instance (review) by a sparse vector containing the counts of its unigrams and bigrams, and we normalize the vectors in L1 . Finally, we discard all but the most frequent 1,600 unigrams and bigrams from each data set. In all of the learning problems of the next section, including thosethat require us to estimate an approximate H-distance, we use signed linear classifiers. Toestimate the parameters of these classifiers, we minimize a Huber loss with stochastic gradient descent (Zhang 2004).7.2 ExperimentsWe explore Theorem 3 further by comparing its predictions to the predictions of an approximation that can be computed from finite labeled source and unlabeled source and targetsamples. As we shall see, our approximation is a finite-sample analog of (1). We first address \u03bb, the error of the ideal hypothesis. Unfortunately, in general we cannot assume anyrelationship between the labeling functions fS and fT . Thus in order to estimate \u03bb, we must\f164Mach Learn (2010) 79: 151\u2013175estimate \u0003T (h\u2217 ) independently of the source data. If we had enough target data to do thisaccurately, we would not need to adapt a source classifier in the first place. For our sentiment task, however, \u03bb is small enough to be a negligible term in the bound. Thus we ignoreit here.We approximate the divergence between two domains by training a linear classifier todiscriminate between unlabeled instances from the source and target domains. Then we apply Lemma 2 to get an estimate of d\u0302H that we denote by \u03b6 (US , UT ). \u03b6 (US , UT ) is a lowerbound on d\u0302H , which is in turn a lower bound on d\u0302H\u0002H . For Theorem 3 to be valid, weneed an upper bound on d\u0302H\u0002H . Unfortunately, this is computationally intractable for linearthreshold classifiers, since finding a minimum error classifier is hard in general (Ben-Davidet al. 2003). We chose our \u03b6 (US , UT ) estimate because it requires no new machinery beyondan algorithm for empirical risk minimization on H. Finally, we note that the unlabeled sample size m\u0006 is large, so we leave out the finite sample error term for the H\u0002H-divergence.We set C to be 1,601, the VC dimension of a 1,600-dimensional linear classifier and ignorethe log m term in the numerator of the bound. The complete approximation to the bound is\u0006 \u0007C \u03b1 2 (1 \u2212 \u03b1)2+(3)f (\u03b1) =+ (1 \u2212 \u03b1)\u03b6 (US , UT ).m \u03b21\u2212\u03b2\u0010Cin (3) corresponds to B from (1), and \u03b6 (US , UT ) is a finite sample approxiNote that mmation to A when \u03bb is negligible and we have large unlabeled samples from both the sourceand target domains.We compare (3) to experimental results for the sentiment classification task. All of ourexperiments use the apparel domain as the target. We obtain empirical curves for the errorFig. 3 Comparing the bound from Theorem 3 with test error for sentiment classification. Each column variesone component of the bound. For all plots, the y-axis shows the error and the x-axis shows \u03b1. Plots on the toprow show the value given by our approximation to the bound, and plots on the bottom row show the empiricaltest set error. Column (a) depicts different distances among domains. Column (b) depicts different numbersof target instances, and column (c) represents different numbers of source instances\fMach Learn (2010) 79: 151\u2013175165as a function of \u03b1 by training a classifier using a weighted hinge loss. Suppose the targetdomain has weight \u03b1 and there are \u03b2m target training instances. Then we scale the loss oftarget training instance by \u03b1/\u03b2 and the loss of a source training instance by (1 \u2212 \u03b1)/(1 \u2212 \u03b2).Figure 3 shows a series of plots of (3) (top row) coupled with corresponding plots of testerror (bottom row) as a function of \u03b1 for different amounts of source and target data anddifferent distances between domains. In each column, a single parameter (distance, numberof target instances mT , or number of source instances mS ) is varied while the other two areheld constant. Note that \u03b2 = mT /(mT +mS ). The plots on the top row of Fig. 3 are not meantto be numerical proxies for the true error. (For the source domains \u201cbooks\u201d and \u201cdvd\u201d, thedistance alone is well above 1/2.) However, they illustrate that the bound is similar in shapeto the true error curve and that important relationships are preserved.Note that in every pair of plots, the empirical error curves, like the bounds, have anessentially convex shape. Furthermore, the value of \u03b1 that minimizes the bound also yieldslow empirical error in each case. This suggests that choosing \u03b1 to minimize the bound ofTheorem 3 and subsequently training a classifier to minimize the empirical error \u0003\u02c6\u03b1 (h) canwork well in practice, provided we have a reasonable measure of complexity and \u03bb is small.Column (a) shows that more distant source domains result in higher target error. Column (b)illustrates that for more target data, we have not only lower error in general, but also a higherminimizing \u03b1. Finally, column (c) demonstrates the limitations of distant source data.When enough labeled target data exists, we always prefer to use only the target data,no matter how much source data is available. Intuitively this is because any biased sourcedomain cannot help to reduce error beyond some positive constant. When the target dataalone is sufficient to surpass this level of performance, the source data ceases to be useful.Thus column (c) illustrates empirically one phase transition we discuss in Sect. 6.8 Combining data from multiple sourcesWe now explore an extension of our theory to the case of multiple source domains. Inthis setting, the learner is presented with data from N distinct sources. Each source Sj isassociated with an unknown distribution Dj over input points and an unknown labelingfunction fj . The learner receives a total of m labeled samples, with mj = \u03b2j m from eachsource Sj , and the objective is to use these samples to train a model to perform well ona target domain \u0003DT , fT \u0004, which may or may not be one of the sources. This setting ismotivated by several domain adaptation algorithms (Huang et al. 2007; Bickel et al. 2007;Jiang and Zhai 2007; Dai et al. 2007) that weigh the loss from training instances depending on how \u201cfar\u201d they are from the target domain. That is, each training instance is its ownsource domain.As before, we examine algorithms that minimize convex combinations of training errorover the labeled examples from each source domain. Given a vector \u03b1 = (\u03b11 , . . . , \u03b1N ) ofdomain weights with Nj =1 \u03b1j = 1, we define the empirical \u03b1-weighted error of function hasN\u0003\u02c6\u03b1 (h) =N\u03b1j \u0003\u02c6j (h) =j =1j =1\u03b1jmj|h(x) \u2212 fj (x)|.x\u2208SjThe true \u03b1-weighted error \u0003\u03b1 (h) is defined analogously. We use D\u03b1 to denote the mixture ofthe N source distributions with mixing weights equal to the components of \u03b1.We present in turn two alternative generalizations of the bounds in Sect. 5. The firstbound considers the quality and quantity of data available from each source individually,\f166Mach Learn (2010) 79: 151\u2013175ignoring the relationships between sources. In contrast, the second bound depends directlyon the H\u0002H-distance between the target domain and the weighted combination of sourcedomains. This dependence allows us to achieve significantly tighter bounds when there exists a mixture of sources that approximates the target better than any single source. Bothresults require the derivation of uniform convergence bounds for the empirical \u03b1-error. Webegin with those.8.1 Uniform convergenceThe following lemma provides a uniform convergence bound for the empirical \u03b1-error.Lemma 6 For each j \u2208 {1, . . . , N }, let Sj be a labeled sample of size \u03b2j m generated bydrawing \u03b2j m points from Dj and labeling them according to fj . For any fixed weight vector\u03b1, let \u0003\u02c6\u03b1 (h) be the empirical \u03b1-weighted error of some fixed hypothesis h on this sample,and let \u0003\u03b1 (h) be the true \u03b1-weighted error. Then for any \u03b4 \u2208 (0, 1), with probability at least1 \u2212 \u03b4:\u0011\u0012\u0002\u0003\u22122m\u0003 2Pr |\u02c6\u0003\u03b1 (h) \u2212 \u0003\u03b1 (h)| \u2265 \u0003 \u2264 2 exp.2\u03b1jNj =1 \u03b2j\u0002Proof See Appendix.Note that this bound is minimized when \u03b1j = \u03b2j for all j . In other words, convergenceis fastest when all data instances are weighted equally.8.2 A bound using pairwise divergenceThe first bound we present considers the pairwise H\u0002H-distance between each source andthe target, and illustrates the trade-off that exists between minimizing the average divergenceof the training data from the target and weighting all points equally to encourage fasterconvergence. The term Nj =1 \u03b1j \u03bbj that appears in this bound plays a role corresponding to\u03bb in the previous section. Somewhat surprisingly, this term can be small even when there isnot a single hypothesis that works well for all heavily weighted sources.Theorem 4 Let H be a hypothesis space of VC dimension d. For each j \u2208 {1, . . . , N },let Sj be a labeled sample of size \u03b2j m generated by drawing \u03b2j m points from Dj andlabeling them according to fj . If h\u0302 \u2208 H is the empirical minimizer of \u0003\u02c6\u03b1 (h) for a fixedweight vector \u03b1 on these samples and h\u2217T = minh\u2208H \u0003T (h) is the target error minimizer, thenfor any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4,\u0013\u0011\u0014 N 2 \u0012\u0007\u0014\u03b1jd log(2m) \u2212 log(\u03b4)\u2217\u0003T (h\u0302) \u2264 \u0003T (hT ) + 2\u0015\u03b22mj =1 jN+\u0017\u0016\u03b1j 2\u03bbj + dH\u0002H (Dj , DT ) ,j =1where \u03bbj = minh\u2208H {\u0003T (h) + \u0003j (h)}.\fMach Learn (2010) 79: 151\u2013175167\u0002Proof See Appendix.In the special case where the H\u0002H-divergence between each source and the target is 0and all data instances are weighted equally, the bound in Theorem 4 becomes\u0006\u0003T (h\u0302) \u2264 \u0003T (h\u2217T ) + 2N2d log(2(m + 1)) + 2 log( 4\u03b4 )+2\u03b1j \u03bbj .mj =1This bound is nearly identical to the multiple source classification bound given in Theorem 6of Crammer et al. (2008). Aside from the constants in the complexity term, the only difference is that the quantity \u03bbi that appears here is replaced by an alternate measure of the labelerror between source Sj and the target. Furthermore, these measures are equivalent whenthe true target function is a member of H. However, the bound of Crammer et al. (2008)is less general. In particular, it does not handle positive H\u0002H-divergence or non-uniformweighting of the data.8.3 A bound using combined divergenceIn the previous bound, divergence between domains is measured only on pairs, so it is notnecessary to have a single hypothesis that is good for every source domain. However, thisbound does not give us the flexibility to take advantage of domain structure when calculating unlabeled divergence. The alternate bound given in Theorem 5 allows us to effectivelyalter the source distribution by changing \u03b1. This has two consequences. First, we must nowdemand that there exists a hypothesis h\u2217 which has low error on both the \u03b1-weighted convex combination of sources and the target domain. Second, we measure H\u0002H-divergencebetween the target and a mixture of sources, rather than between the target and each singlesource.Theorem 5 Let H be a hypothesis space of VC dimension d. For each j \u2208 {1, . . . , N },let Sj be a labeled sample of size \u03b2j m generated by drawing \u03b2j m points from Dj andlabeling them according to fj . If h\u0302 \u2208 H is the empirical minimizer of \u0003\u02c6\u03b1 (h) for a fixedweight vector \u03b1 on these samples and h\u2217T = minh\u2208H \u0003T (h) is the target error minimizer, thenfor any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4,\u0013\u0011\u0014\u0014\u2217\u0003T (h\u0302) \u2264 \u0003T (hT ) + 4\u0015Nj =1\u03b1j2\u0012\u0007\u03b2jd log(2m) \u2212 log(\u03b4)2m+ 2\u03b3\u03b1 + dH\u0002H (D\u03b1 , DT ),where \u03b3\u03b1 = minh {\u0003T (h) + \u0003\u03b1 (h)} = minh {\u0003T (h) +Proof See Appendix.Nj =1 \u03b1j \u0003j (h)}.\u0002Theorem 5 reduces to Theorem 3 when N = 2 and one of the two source domains is thetarget domain (that is, we have some small number of target instances).\f168Mach Learn (2010) 79: 151\u20131758.4 DiscussionOne might ask whether there exist settings where a non-uniform weighting can lead to asignificantly lower value of the bound than a uniform weighting. Indeed, this can happenif some non-uniform weighting of sources accurately approximates the target distribution.This is true, for example, in the setting studied by Mansour et al. (2009a, 2009b), who deriveresults for combining pre-computed hypotheses. In particular, they show that for arbitraryconvex losses, if the R\u00e9nyi divergence between the target and a mixture of sources is small,it is possible to combine low-error source hypotheses to create a low-error target hypothesis.They then show that if for each domain j there exists a hypothesis hj with error less than \u0003,it is possible to achieve an error less than \u0003 on the target by weighting the predictions ofh1 , . . . , hN appropriately.The R\u00e9nyi divergence is not directly comparable to the H\u0002H-divergence in general;however it is possible to exhibit source and target distributions which have low H\u0002Hdivergence and high (even infinite) R\u00e9nyi divergence. For example, the R\u00e9nyi divergenceis infinite when the source and target distributions do not share support, but the H\u0002Hdivergence is only large when these regions of differing support also coincide with classifierdisagreement regions. On the other hand, we require that a single hypothesis be trained onthe mixture of sources. Mansour et al. (2009a, 2009b) give algorithms which do not requirethe original training data at all, but only a single hypothesis from each source.9 ConclusionWe presented a theoretical investigation of the task of domain adaptation, a task in whichwe have a large amount of training data from a source domain, but we wish to apply amodel in a target domain with a much smaller amount of training data. Our main result is auniform convergence learning bound for algorithms which minimize convex combinationsof empirical source and target error. Our bound reflects the trade-off between the size of thesource data and the accuracy of the target data, and we give a simple approximation to it thatis computable from finite labeled and unlabeled samples. This approximation makes correctpredictions about model test error for a sentiment classification task. Our theory also extendsin a straightforward manner to a multi-source setting, which we believe helps to explain thesuccess of recent empirical work in domain adaptation.There are two interesting open problems that deserve future exploration. First, our boundson the divergence between source and target distribution are in terms of VC dimension. Wedo not yet know whether our divergence measure admits tighter data-dependent bounds(McAllester 2003; Bartlett and Mendelson 2002), or if there are other, more appropriatedivergence measures which do. Second, it would be interesting to investigate algorithmsthat choose a convex combination of multiple sources to minimize the bound in Theorem 5as possible approaches to adaptation from multiple sources.Acknowledgements This material is based upon work partially supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. NBCHD030010 (CALO), by the National ScienceFoundation under grants ITR 0428193 and RI 0803256, and by a gift from Google, Inc. to the University ofPennsylvania. Koby Crammer is a Horev fellow, supported by the Taub Foundations. Any opinions, findings,and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the DARPA, Department of Interior-National Business Center (DOI-NBC), NSF, theTaub Foundations, or Google, Inc.\fMach Learn (2010) 79: 151\u2013175169Open Access This article is distributed under the terms of the Creative Commons Attribution Noncommercial License which permits any noncommercial use, distribution, and reproduction in any medium, providedthe original author(s) and source are credited.Appendix: ProofsTheorem 1 For a hypothesis h,\u0003T (h) \u2264 \u0003S (h) + d1 (DS , DT )\u0003\u0003\u0005\u0004\u0002\u0002+ min EDS |fS (x) \u2212 fT (x)| , EDT |fS (x) \u2212 fT (x)| .Proof Recall that \u0003T (h) = \u0003T (h, fT ) and \u0003S (h) = \u0003S (h, fS ). Let \u03c6S and \u03c6T be the densityfunctions of DS and DT respectively.\u0003T (h) = \u0003T (h) + \u0003S (h) \u2212 \u0003S (h) + \u0003S (h, fT ) \u2212 \u0003S (h, fT )\u2264 \u0003S (h) + |\u0003S (h, fT ) \u2212 \u0003S (h, fS )| + |\u0003T (h, fT ) \u2212 \u0003S (h, fT )|\u0003\u0002\u2264 \u0003S (h) + EDS |fS (x) \u2212 fT (x)| + |\u0003T (h, fT ) \u2212 \u0003S (h, fT )|\u0018\u0003\u0002\u2264 \u0003S (h) + EDS |fS (x) \u2212 fT (x)| + |\u03c6S (x) \u2212 \u03c6T (x)||h(x) \u2212 fT (x)|dx\u0003\u0002\u2264 \u0003S (h) + EDS |fS (x) \u2212 fT (x)| + d1 (DS , DT ).In the first line, we could instead choose to add and subtract \u0003T (h, fS ) rather than \u0003S (h, fT ),which would result in the same bound only with the expectation taken with respect to DTinstead of DS . Choosing the smaller of the two gives us the bound.\u0002Lemma 2 For a symmetric hypothesis class H (one where for every h \u2208 H, the inversehypothesis 1 \u2212 h is also in H) and samples U , U \u0006 of size m, the empirical H-distance is\u0007\b11dH (U , U \u0006 ) = 2 1 \u2212 minI [x \u2208 U ] +I [x \u2208 U \u0006 ]h\u2208H mmx:h(x)=0x:h(x)=1where I [x \u2208 U ] is the binary indicator variable which is 1 when x \u2208 U .Proof We will show that for any hypothesis h and corresponding set I (h) of positivelylabeled instances,\b11I [x \u2208 U ] +I [x \u2208 U \u0006 ] = PrU [I (h)] \u2212 PrU \u0006 [I (h)] .1\u2212m x:h(x)=0m x:h(x)=1We have1\u22121m=\u0007\u0002\u0003I x \u2208 U\u0006I [x \u2208 U ] +x:h(x)=0x:h(x)=1\u0002\u0002\u0016\u0003\u0017\u0016\u0003\u001711I [x \u2208 U ] + I x \u2208 U \u0006 +I [x \u2208 U ] + I x \u2208 U \u00062m x:h(x)=02m x:h(x)=1\f170Mach Learn (2010) 79: 151\u2013175\u22121m\u0007\u0002\u0003I x \u2208 U\u0006I [x \u2208 U ] +x:h(x)=0x:h(x)=1=\u0017\u0002\u0016 \u0002\u0003\u0016\u0003\u001711I x \u2208 U \u0006 \u2212 I [x \u2208 U ] +I [x \u2208 U ] \u2212 I x \u2208 U \u00062m x:h(x)=02m x:h(x)=1=11(1 \u2212 PrU \u0006 [I (h)] \u2212 (1 \u2212 PrU [I (h)])) + (PrU [I (h)] \u2212 PrU \u0006 [I (h)])22= PrU [I (h)] \u2212 PrU \u0006 [I (h)] .(4)The absolute value in the statement of the lemma follows from the symmetry of H.\u0002Lemma 4 Let h be a hypothesis in class H. Then\u0007|\u0003\u03b1 (h) \u2212 \u0003T (h)| \u2264 (1 \u2212 \u03b1)1dH\u0002H (DS , DT ) + \u03bb .2Proof Similarly to the proof of Theorem 2, this proof relies heavily on the triangle inequalityfor classification error.|\u0003\u03b1 (h) \u2212 \u0003T (h)|= (1 \u2212 \u03b1)|\u0003S (h) \u2212 \u0003T (h)|\u0002\u0003\u2264 (1 \u2212 \u03b1) |\u0003S (h) \u2212 \u0003S (h, h\u2217 )| + |\u0003S (h, h\u2217 ) \u2212 \u0003T (h, h\u2217 )| + |\u0003T (h, h\u2217 ) \u2212 \u0003T (h)|\u0002\u0003\u2264 (1 \u2212 \u03b1) \u0003S (h\u2217 ) + |\u0003S (h, h\u2217 ) \u2212 \u0003T (h, h\u2217 )| + \u0003T (h\u2217 )\u00071\u2264 (1 \u2212 \u03b1)dH\u0002H (DS , DT ) + \u03bb .\u00022Theorem 3 Let H be a hypothesis space of VC dimension d. Let US and UT be unlabeledsamples of size m\u0006 each, drawn from DS and DT respectively. Let S be a labeled sample ofsize m generated by drawing \u03b2m points from DT and (1 \u2212 \u03b2)m points from DS , labelingthem according to fS and fT , respectively. If h\u0302 \u2208 H is the empirical minimizer of \u0003\u02c6\u03b1 (h)on S and h\u2217T = minh\u2208H \u0003T (h) is the target error minimizer, then for any \u03b4 \u2208 (0, 1), withprobability at least 1 \u2212 \u03b4 (over the choice of the samples),\u0006\u0003T (h\u0302) \u2264\u0006\u0016 \u00172d log (2(m + 1)) + 2 log 8\u03b4m\u0006\u00072d log(2m\u0006 ) + log( 4\u03b4 )1+\u03bb .+ 2(1 \u2212 \u03b1) d\u0302H\u0002H (US , UT ) + 42m\u0006\u0003T (h\u2217T ) + 4\u03b1 2 (1 \u2212 \u03b1)2+\u03b21\u2212\u03b2Proof The complete proof is mostly identical to the standard proof of uniform convergencefor empirical risk minimizers. We show here the steps that are different. Below we use L4,and Thm2 to indicate that a line of the proof follows by application of Lemma 4 or Theorem 2 respectively. L5 indicates that the proof follows by Lemma 5, but also relies onsample symmetrization and bounding the growth function by the VC dimension (Anthony\fMach Learn (2010) 79: 151\u2013175171and Bartlett 1999).\u00071dH\u0002H (DS , DT ) + \u03bb(L4)2\u0006\u0006\u03b1 2 (1 \u2212 \u03b1)2 2d log(2(m + 1)) + 2 log( 8\u03b4 )+\u2264 \u0003\u02c6\u03b1 (h\u0302) + 2\u03b21\u2212\u03b2m\u00071+ (1 \u2212 \u03b1) dH\u0002H (DS , DT ) + \u03bb(L5)2\u0006\u0006\u03b1 2 (1 \u2212 \u03b1)2 2d log(2(m + 1)) + 2 log( 8\u03b4 )\u2217+\u2264 \u0003\u02c6\u03b1 (hT ) + 2\u03b21\u2212\u03b2m\u0007\u0019\u001a1+ (1 \u2212 \u03b1) dH\u0002H (DS , DT ) + \u03bbh\u0302 = arg min \u0003\u02c6\u03b1 (h)h\u2208H2\u0006\u0006\u03b1 2 (1 \u2212 \u03b1)2 2d log(2(m + 1)) + 2 log( 8\u03b4 )\u2264 \u0003\u03b1 (h\u2217T ) + 4+\u03b21\u2212\u03b2m\u00071+ (1 \u2212 \u03b1) dH\u0002H (DS , DT ) + \u03bb(L5)2\u0006\u0006222d log(2(m + 1)) + 2 log( 8\u03b4 )(1\u2212\u03b1)\u03b1+\u2264 \u0003T (h\u2217T ) + 4\u03b21\u2212\u03b2m\u00071+ 2(1 \u2212 \u03b1) dH\u0002H (DS , DT ) + \u03bb(L4)2\u0006\u0006222d log(2(m + 1)) + 2 log( 8\u03b4 )(1\u2212\u03b1)\u03b1+\u2264 \u0003T (h\u2217T ) + 4\u03b21\u2212\u03b2m\u0006\u00072d log(2m\u0006 ) + log( 4\u03b4 )1+\u03bb+ 2(1 \u2212 \u03b1) d\u0302H\u0002H (US , UT ) + 42m\u0006\u0003T (h\u0302) \u2264 \u0003\u03b1 (h\u0302) + (1 \u2212 \u03b1)(Thm 2) \u0002Lemma 6 For each j \u2208 {1, . . . , N }, let Sj be a labeled sample of size \u03b2j m generated bydrawing \u03b2j m points from Dj and labeling them according to fj . For any fixed weight vector\u03b1, let \u0003\u02c6\u03b1 (h) be the empirical \u03b1-weighted error of some fixed hypothesis h on this sample,and let \u0003\u03b1 (h) be the true \u03b1-weighted error. Then for any \u03b4 \u2208 (0, 1), with probability at least1 \u2212 \u03b4:\u0007\u0003\u0002\u22122m\u0003 2Pr |\u02c6\u0003\u03b1 (h) \u2212 \u0003\u03b1 (h)| \u2265 \u0003 \u2264 2 exp.2\u03b1jNj =1 \u03b2jProof Due to its similarity to the proof of Lemma 5, we omit some details of this proof, andconcentrate only on the parts that differ.For each source j , let Xj,1 , . . . , Xj,\u03b2j m be random variables that take on the values(\u03b1j /\u03b2j )|h(x)\u2212fj (x)| for the \u03b2j m instances x \u2208 Sj . Note that Xj,1 , . . . , Xj,\u03b2j m \u2208 [0, \u03b1j /\u03b2j ].\f172Mach Learn (2010) 79: 151\u2013175ThenN\u0003\u02c6\u03b1 (h) =N\u03b1j \u0003\u02c6j (h) =j =1\u03b1jj =111|h(x) \u2212 fj (x)| =\u03b2j m x\u2208SmjN\u03b2j mXj,i .j =1 i=1By linearity of expectations, we have that E[\u02c6\u0003\u03b1 (h)] = \u0003\u03b1 (h), and so by Hoeffding\u2019s inequality, for every h \u2208 H,\u0002\u0003Pr |\u02c6\u0003\u03b1 (h) \u2212 \u0003\u03b1 (h)| \u2265 \u0003 \u2264 2 exp\u0007\u22122m2 \u0003 2\u03b2j m2i=1 range (Xj,i )Nj =1\u0007= 2 exp\u22122m\u0003 2\u03b1j2Nj =1 \u03b2j.\u0002Theorem 4 Let H be a hypothesis space of VC dimension d. For each j \u2208 {1, . . . , N },let Sj be a labeled sample of size \u03b2j m generated by drawing \u03b2j m points from Dj andlabeling them according to fj . If h\u0302 \u2208 H is the empirical minimizer of \u0003\u02c6\u03b1 (h) for a fixedweight vector \u03b1 on these samples and h\u2217T = minh\u2208H \u0003T (h) is the target error minimizer, thenfor any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4,\u0013\u0011\u0014\u0014\u2217\u0003T (h\u0302) \u2264 \u0003T (hT ) + 4\u0015Nj =1N+\u03b1j2\u0012\u0007\u03b2j2d log(2(m + 1)) + log( 4\u03b4 )m\u0017\u0016\u03b1j 2\u03bbj + dH\u0002H (Dj , DT ) ,j =1where \u03bbj = minh\u2208H {\u0003T (h) + \u0003j (h)}.Proof Let h\u2217j = argminh {\u0003T (h) + \u0003j (h)}. Then|\u0003\u03b1 (h) \u2212 \u0003T (h)|NN\u03b1j \u0003j (h) \u2212 \u0003T (h) \u2264=j =1N\u2264\u03b1j \u0003j (h) \u2212 \u0003T (h)j =1\u0016\u0017\u03b1j \u0003j (h) \u2212 \u0003j (h, h\u2217j ) + \u0003j (h, h\u2217j ) \u2212 \u0003T (h, h\u2217j ) + \u0003T (h, h\u2217j ) \u2212 \u0003T (h)j =1N\u2264\u0017\u0016\u03b1j \u0003j (h\u2217j ) + \u0003j (h, h\u2217j ) \u2212 \u0003T (h, h\u2217j ) + \u0003T (h\u2217j )j =1\u00071\u03b1j \u03bbj + dH\u0002H (Dj , DT ) .2j =1N\u2264The third line follows from the triangle inequality. The last line follows from the definitionof \u03bbj and Lemma 3. Putting this together with Lemma 6, we find that for any \u03b4 \u2208 (0, 1),\fMach Learn (2010) 79: 151\u2013175173with probability 1 \u2212 \u03b4,\u00071\u03b1j \u03bbj + dH\u0002H (Dj , DT )2j =1N\u0003T (h\u0302) \u2264 \u0003\u03b1 (h\u0302) +\u0013\u0011\u0014\u0014\u2264 \u0003\u02c6\u03b1 (h\u0302) + 2\u0015N\u03b1j2j =1\u0012\u0007\u03b2j2d log(2(m + 1)) + log( 4\u03b4 )m\u00071\u03b1j \u03bbj + dH\u0002H (Dj , DT )2j =1N+\u2264\u0013\u0011\u0014\u0014\u0003\u02c6\u03b1 (h\u2217T ) + 2\u0015Nj =1\u03b1j2\u0012\u0007\u03b2j2d log(2(m + 1)) + log( 4\u03b4 )m\u00071\u03b1j \u03bbj + dH\u0002H (Dj , DT )2j =1N+\u0013\u0011\u0014\u0014\u2264 \u0003\u03b1 (h\u2217 ) + 4\u0015NTj =1\u03b1j2\u0012\u0007\u03b2j2d log(2(m + 1)) + log( 4\u03b4 )m\u00071\u03b1j \u03bbj + dH\u0002H (Dj , DT )2j =1N+\u0013\u0011\u0014\u0014\u2217\u2264 \u0003T (h ) + 4\u0015NTj =1N+\u03b1j2\u03b2j\u0012\u00072d log(2(m + 1)) + log( 4\u03b4 )m\u0017\u0016\u03b1j 2\u03bbj + dH\u0002H (Dj , DT ) .j =1\u0002Theorem 5 Let H be a hypothesis space of VC dimension d. For each j \u2208 {1, . . . , N },let Sj be a labeled sample of size \u03b2j m generated by drawing \u03b2j m points from Dj andlabeling them according to fj . If h\u0302 \u2208 H is the empirical minimizer of \u0003\u02c6\u03b1 (h) for a fixedweight vector \u03b1 on these samples and h\u2217T = minh\u2208H \u0003T (h) is the target error minimizer, thenfor any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4,\u0013\u0011\u0014 N 2 \u0012\u0007\u0014\u03b1j2d log(2(m + 1)) + log( 4\u03b4 )\u2217\u0003T (h\u0302) \u2264 \u0003T (hT ) + 2\u0015\u03b2mj =1 j\u00071+ 2 \u03b3\u03b1 + dH\u0002H (D\u03b1 , DT ) ,2where \u03b3\u03b1 = minh {\u0003T (h) + \u0003\u03b1 (h)} = minh {\u0003T (h) +Nj =1 \u03b1j \u0003j (h)}.Proof The proof is almost identical to that of Theorem 4 with minor modifications to thederivation of the bound on |\u0003\u03b1 (h)\u2212\u0003T (h)|. Let h\u2217 = argminh {\u0003T (h)+\u0003\u03b1 (h)}. By the triangle\f174Mach Learn (2010) 79: 151\u2013175inequality and Lemma 3,|\u0003\u03b1 (h) \u2212 \u0003T (h)| \u2264 \u0003\u03b1 (h) \u2212 \u0003\u03b1 (h, h\u2217 ) + \u0003\u03b1 (h, h\u2217 ) \u2212 \u0003T (h, h\u2217 ) + \u0003T (h, h\u2217 ) \u2212 \u0003T (h)\u2264 \u0003\u03b1 (h\u2217 ) + \u0003\u03b1 (h, h\u2217 ) \u2212 \u0003T (h, h\u2217 ) + \u0003T (h\u2217 )1\u2264 \u03b3 + dH\u0002H (D\u03b1 , DT ).2The remainder of the proof is unchanged.\u0002ReferencesAndo, R., & Zhang, T. (2005). A framework for learning predictive structures from multiple tasks and unlabeled data. Journal of Machine Learning Research, 6, 1817\u20131853.Anthony, M., & Bartlett, P. (1999). Neural network learning: theoretical foundations. Cambridge: CambridgeUniversity Press.Bartlett, P., & Mendelson, S. (2002). Rademacher and Gaussian complexities: risk bounds and structuralresults. Journal of Machine Learning Research, 3, 463\u2013482.Batu, T., Fortnow, L., Rubinfeld, R., Smith, W., & White, P. (2000). Testing that distributions are close. In:IEEE symposium on foundations of computer science (Vol. 41, pp. 259\u2013269).Baxter, J. (2000). A model of inductive bias learning. Journal of Artificial Intelligence Research, 12, 149\u2013198.Ben-David, S., Eiron, N., & Long, P. (2003). On the difficulty of approximately maximizing agreements.Journal of Computer and System Sciences, 66, 496\u2013514.Ben-David, S., Blitzer, J., Crammer, K., & Pereira, F. (2006). Analysis of representations for domain adaptation. In: Advances in neural information processing systems.Bickel, S., Br\u00fcckner, M., & Scheffer, T. (2007). Discriminative learning for differing training and test distributions. In: Proceedings of the international conference on machine learning.Bikel, D., Miller, S., Schwartz, R., & Weischedel, R. (1997). Nymble: a high-performance learning namefinder. In: Conference on applied natural language processing.Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., & Wortman, J. (2007a). Learning bounds for domain adaptation. In: Advances in neural information processing systems.Blitzer, J., Dredze, M., & Pereira, F. (2007b) Biographies, Bollywood, boomboxes and blenders: domainadaptation for sentiment classification. In: ACL.Collins, M. (1999). Head-driven statistical models for natural language parsing. PhD thesis, University ofPennsylvania.Cortes, C., Mohri, M., Riley, M., & Rostamizadeh, A. (2008). Sample selection bias correction theory. In:Proceedings of the 19th annual conference on algorithmic learning theory.Crammer, K., Kearns, M., & Wortman, J. (2008). Learning from multiple sources. Journal of Machine Learning Research, 9, 1757\u20131774.Dai, W., Yang, Q., Xue, G., & Yu, Y. (2007). Boosting for transfer learning. In: Proceedings of the international conference on machine learning.Das, S., & Chen, M. (2001). Yahoo! for Amazon: extracting market sentiment from stock message boards.In: Proceedings of the Asia pacific finance association annual conference.Daum\u00e9, H. (2007). Frustratingly easy domain adaptation. In: Association for computational linguistics(ACL).Finkel, J. R. Manning, C. D. (2009). Hierarchical Bayesian domain adaptation. In: Proceedings of the northAmerican association for computational linguistics.Heckman, J. (1979). Sample selection bias as a specification error. Econometrica, 47, 153\u2013161.Huang, J., Smola, A., Gretton, A., Borgwardt, K., & Schoelkopf, B. (2007). Correcting sample selection biasby unlabeled data. In: Advances in neural information processing systems.Jiang, J., & Zhai, C. (2007). Instance weighting for domain adaptation. In: Proceedings of the association forcomputational linguistics.Kifer, D., Ben-David, S., & Gehrke, J. (2004). Detecting change in data streams. In: Ver large databases.Li, X., & Bilmes, J. (2007). A Bayesian divergence prior for classification adaptation. In: Proceedings of theinternational conference on artificial intelligence and statistics.Mansour, Y., Mohri, M., & Rostamizadeh, A. (2009a). Domain adaptation with multiple sources. In: Advances in neural information processing systems.\fMach Learn (2010) 79: 151\u2013175175Mansour, Y., Mohri, M., & Rostamizadeh, A. (2009b). Multiple source adaptation and the r\u00e9nyi divergence.In: Proceedings of the conference on uncertainty in artificial intelligence.McAllester, D. (2003). Simplified PAC-Bayesian margin bounds. In: Proceedings of the sixteenth annualconference on learning theory.Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classification using machine learningtechniques. In: Proceedings of empirical methods in natural language processing.Ratnaparkhi, A. (1996). A maximum entropy model for part-of-speech tagging. In: Proceedings of empiricalmethods in natural language processing.Sugiyama, M., Suzuki, T., Nakajima, S., Kashima, H., von B\u00fcnau, P., & Kawanabe, M. (2008). Direct importance estimation for covariate shift adaptation. Annals of the Institute of Statistical Mathematics, 60,699\u2013746.Thomas, M., Pang, B., & Lee, L. (2006). Get out the vote: determining support or opposition from congressional floor-debate transcripts. In: Proceedings of empirical methods in natural language processing.Turney, P. (2002). Thumbs up or thumbs down? Semantic orientation applied to unsupervised classificationof reviews. In: Proceedings of the association for computational linguistics.Vapnik, V. (1998). Statistical learning theory. New York: Wiley.Zhang, T. (2004). Solving large-scale linear prediction problems with stochastic gradient descent. In: Proceedings of the international conference on machine learning.\f", "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 20151019Transfer Learning for VisualCategorization: A SurveyLing Shao, Senior Member, IEEE, Fan Zhu, Student Member, IEEE, and Xuelong Li, Fellow, IEEEAbstract\u2014 Regular machine learning and data mining techniques study the training data for future inferences under amajor assumption that the future data are within the samefeature space or have the same distribution as the trainingdata. However, due to the limited availability of human labeledtraining data, training data that stay in the same feature spaceor have the same distribution as the future data cannot beguaranteed to be sufficient enough to avoid the over-fittingproblem. In real-world applications, apart from data in thetarget domain, related data in a different domain can also beincluded to expand the availability of our prior knowledge aboutthe target future data. Transfer learning addresses such crossdomain learning problems by extracting useful information fromdata in a related domain and transferring them for being usedin target tasks. In recent years, with transfer learning beingapplied to visual categorization, some typical problems, e.g., viewdivergence in action recognition tasks and concept drifting inimage classification tasks, can be efficiently solved. In this paper,we survey state-of-the-art transfer learning algorithms in visualcategorization applications, such as object recognition, imageclassification, and human action recognition.Index Terms\u2014 Action recognition, image classification,machine learning, object recognition, survey, transfer learning,visual categorization.I. I NTRODUCTIONIN THE past few years, the computer vision communityhas witnessed a significant amount of applications in videosearch and retrieval, surveillance, robotics, and so on. Regularmachine learning approaches [1]\u2013[7] have achieved promisingresults under the major assumption that the training andtesting data stay in the same feature space or share thesame distribution. However, in real-world applications, due tothe high price of human manual labeling and environmentalManuscript received December 29, 2012; revised October 17, 2013,January 30, 2014, and May 26, 2014; accepted June 3, 2014. Date ofpublication July 1, 2014; date of current version April 15, 2015. This workwas supported in part by the National Basic Research Program of China (973Program) under Grant 2012CB316400, in part by the University of Sheffield,Sheffield, U.K., and in part by the National Natural Science Foundation ofChina under Grants 61125106 and 61072093.L. Shao is with the College of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing210044, China, and also with the Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield S1 3JD, U.K. (e-mail:ling.shao@sheffield.ac.uk).F. Zhu is with the Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield S1 3JD, U.K. (e-mail: fan.zhu@sheffield.ac.uk).X. Li is with the Center for OPTical IMagery Analysis and Learning, StateKey Laboratory of Transient Optics and Photonics, Xi\u2019an Institute of Opticsand Precision Mechanics, Chinese Academy of Sciences, Xi\u2019an 710119, China(e-mail: xuelong_li@opt.ac.cn).Color versions of one or more of the figures in this paper are availableonline at https://ieeexplore.ieee.org.Digital Object Identifier 10.1109/TNNLS.2014.2330900restrictions, sufficient training data belonging to the samefeature space or the same distribution as the testing datamay not always be available. Typical examples are [8]\u2013[11],where only one action template is provided for each actionclass for training, and [12], where training samples arecaptured from a different viewpoint. In such situations, regularmachine learning techniques are very likely to fail. Thisreminds us of the capability of the human vision system.Given the gigantic geometric and intraclass variabilities ofobjects, humans are able to learn tens of thousands of visualcategories in their life, which leads to the hypothesis thathumans achieve such a capability by accumulated informationand knowledge [13]. It is estimated that there are about 10\u201330thousands object classes in the world [14] and children canlearn 4\u20135 object classes per day [13]. Due to the limitationof objects that a child can see within a day, learning newobject classes from large amounts of corresponding objectdata is not possible. Thus, it is believed that the existingknowledge gained from previous known objects assists the newlearning process through their connections with the new objectcategories. For example, assuming we did not know what awatermelon is, we would only need one training sample ofwatermelons together with our previous knowledge on melonscircular shapes, the green color, and so on, to remember thenew object category watermelon. Transfer learning mimics thehuman vision system by making use of sufficient amountsof prior knowledge in other related domains when executingnew tasks in the given domain. In transfer learning, both thetraining data and the testing data can contribute to two types ofdomains: 1) the target domain and 2) the source domain. Thetarget domain contains the testing instances, which are the taskof the categorization system, and the source domain containstraining instances, which are under a different distributionwith the target domain data. In most cases, there is only onetarget domain for a transfer learning task, while either singleor multiple source domains can exist. For example, in [15],action recognition is conducted across data sets from differentdomains, where the KTH data set [16], which has a cleanbackground and limited viewpoint and scale changes, is set asthe source data set, and the Microsoft research action data set1and the TRECVID surveillance data [17], which are capturedfrom realistic scenarios, are used as the target data set. In [18],the source and target data sets are chosen from different TVprogram channels for the task of video concept detection.Transfer learning can be considered as a speciallearning paradigm where partial/all training data used are1 https://research.microsoft.com/\u223czliu/ActionRecoRsrc2162-237X \u00a9 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\f1020IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015Fig. 1. Basic frameworks of traditional machine learning approaches and knowledge transfer approaches. For regular machine learning approaches, thelearning system can only handle the situation that testing samples and training samples are under the same distribution. On the other hand, transfer learningapproaches have to deal with the data distribution mismatch problem through specific knowledge transfer methods, e.g., mining the shared patterns from dataacross different domains.under a different distribution with the testing data. To understand the significance of knowledge transfer in terms of visuallearning problems, the literature, (see [19]\u2013[21]) has concludedthree general issues regarding the transfer process: 1) when totransfer; 2) what to transfer; and 3) how to transfer. First,when to transfer includes the issues whether transfer learningis necessary for specific learning tasks and whether the sourcedomain data are related to the target domain data. In thescenarios of [22]\u2013[24], where training samples are sufficientand impressive performance can be achieved, while beingconstrained in the target domains, including another domainas the source domain becomes superfluous. A variety ofdivergence levels exist across different pairs of source domainand target domain data, brute-forcing the knowledge from thesource domain into the target domain irrespective of theirdivergence would cause certain performance degeneration,or, in even worse cases, it would break the original dataconsistency in the target domain. Second, the answer to whatto transfer can be concluded in three aspects: 1) inductivetransfer learning, where all the source domain instances andtheir corresponding labels are used for knowledge transfer;2) instance transfer learning, where only the source domaininstances are used; and 3) parameter transfer learning, inaddition to the source domain instances and labels, someparameters of prelearned models from the source domainare utilized to help improve the performance in the targetdomain. Finally, how to transfer includes all the specifictransfer learning techniques, and it is also the most importantpart that has been studied in the transfer learning literature.Many transfer learning techniques have been proposed, e.g.,in [25]\u2013[27], where knowledge transfer is based on the nonnegative matrix trifactorization framework, and in [28], wherethe transfer learning phase is via dimensionality reduction.We illustrate the basic frameworks of traditional machinelearning approaches and knowledge transfer approaches inFig. 1. For traditional machine learning approaches, the idealchoice of the training set to predict a testing instance carshould contain cars. However, in the case of knowledgetransfer, the training set can just contain some relevant categories rather than cars, e.g., wheels, which are similar to thewheels of cars; bicycles, which share the knowledge of wheelswith the car wheels, or even some irrelevant objects, e.g.,laptops and birds, which seem to have no connections withcars, but actually share certain edges or geometrical layoutswith local parts of a car image.As the age of big data has come, transfer learning canprovide more benefits to solve the target problem with morerelevant data. Thus, it is believed that more applications ontransfer learning will emerge in future research. This surveyaims to give a comprehensive overview of transfer learningtechniques on visual categorization tasks, so that readerscould potentially use the analysis and discussions in thissurvey to understand how transfer learning can be appliedto visual categorization tasks or to solve their problem witha suitable transfer learning method. The visual categorizationtasks possess some unique characteristics due to certain visualproperties that can be potentially used in the training process,e.g., the appearance or shape of an object part, the localsymmetries of an object, and the structural. All these uniqueproperties can be employed when designing transfer learningalgorithms, which makes our work different from that of [19]and [29], where the former focuses on classification, regressionand clustering problems related to data mining tasks andthe latter focuses on reinforcement learning, which addressesproblems with only limited environmental feedback rather thancorrectly labeled examples.The remaining part of this survey is structured as follows.An overview is given in Section II. In Sections III and IV,two transfer learning categories, which execute knowledgetransfer through feature representations and classifiers, arediscussed in detail, respectively, answering the problems ofwhat to transfer and how to transfer. In Section V, the modelselection methods from multiple source domains, i.e., whento transfer, are discussed. Evaluation, analysis, and discussionson the stated transfer learning methods are given in Section VI.Finally, the conclusions are drawn in Section VII.\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATIONFig. 2.1021Different ways of differentiating existing knowledge transfer approaches.II. OVERVIEWA. Developing Interests on Transfer LearningDating from the raising of its notion in the last century, transfer learning (also known as, cross-domain learning,domain transfer, and domain adaptation) has a long historyof being studied as a particular machine learning technique.In recent years, with the information explosion on the Internet,(e.g., audio, images, and videos) and the growing demandsfor target tasks in terms of accuracies, data scales, and computational efficiencies, transfer learning approaches begin toattract increasing interests from all research areas in patternrecognition and machine learning. When regular machinelearning techniques reach their limits, transfer learning opensthe flow of a new stream that could fundamentally changethe way of how we used to learn things and how we used totreat classification or regression tasks. Along with the flow,some workshops and tutorial have been held (such as theNIPS 1995 postconference workshop2 in machine learningand data mining areas and another transfer learning surveyis given in [29] for reinforcement learning). In this survey,we focus on the applications of transfer learning techniquesto visual categorization, including action recognition, objectrecognition, and image classification.B. Notations and IssuesSome general notations are defined as follows for laterusage: let D T = DlT \u222a DuT denote the target domain data,where the partially labeled parts are denoted by DlT and theunlabeled parts are denoted by DuT . In addition to the targetdomain data, a set of auxiliary data is seen as the sourcedomain data, which is semilabeled or fully labeled and hasthe representation Ds = {(x i , yi )}ai=1 in a single source case,Nakin a multipleand D1s , D2s , . . . , DsM with Dks = {(x ik , yik )}i=1dsource case. Here, x i \u2208 R is the i th feature vector, where2 https://nips.cc/Conferences/2005/Workshops/d denotes the data dimension, and yi denotes the class labelof the i th sample.According to prior proposals, common issues regardingknowledge transfer are twofold. First, the auxiliary samplesare typically treated without accounting for their mutualdependency during adaptation, which may cause the adapteddata to be arbitrarily distributed and the structural informationbeyond single data samples of the auxiliary data may becomeundermined. Second, during adaptation, noises, and particularly possible outliers from the auxiliary domains are blindlyforced to the target domain [30].When transferring knowledge from the auxiliary domainsto the target domain, it is crucial to know the distributionsimilarities between the target domain data and each sourcedomain data. So far, the most common criterion to measurethe distribution similarity of two domains is a nonparametricdistances metric named maximum mean discrepancy (MMD).The MMD is proposed in [31], and it compares data distributions in the reproducing kernel Hilbert space\u00022\u0002nsnT\u00021 \u0003\u0004 s\u0005\u0004 T \u0005\u00021 \u0003\u0002\u0002sT\u03c6 xi \u2212\u03c6 xi \u0002(1)Distk (D , D ) = \u0002\u0002\u0002 nsnTi=1i=1where \u03c6(\u00b7) is the feature space mapping function.In the literature, transfer learning techniques are categorizedaccording to a variety of taxonomies. In [19], consideringtasks allocated to the target domain and auxiliary domainsand the availability of sample labels within the target domainand auxiliary domains, transfer learning techniques are firstgrouped as inductive transfer learning, transductive transferlearning, and unsupervised transfer learning, upon which theyare further categorized as instance-transfer, feature representation transfer, parameter transfer, and relational knowledgetransfer within each initial partition. Fig. 2 shows five waysof differentiating existing knowledge transfer approaches forvisual categorization. In this survey, inheriting the conceptsfrom the computer vision community, we simply categorizetransfer learning techniques into feature representation levelknowledge transfer and classifier level knowledge transfer.\f1022IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015III. F EATURE R EPRESENTATION T RANSFERFeature representation level knowledge transfer is a populartransfer learning category that maps the target domain to thesource domains exploiting a set of meticulously manufacturedfeatures. Through this type of feature representation levelknowledge transfer, data divergence between the target domainand the source domains can be significantly reduced so thatthe performance of the task in the target domain is improved.Most existing transductive features are designed for specificdomains and would not perform optimally across different datatypes. Thus, we review the feature level knowledge transfertechniques according to two data types: 1) cross-domainknowledge transfer and 2) cross-view knowledge transfer.A. Cross-Domain Knowledge TransferIn the cross-domain setting, the gap between the sourcedomain data and the target domain data varies from imagesto videos and from objects to edges. According to the degreeof data divergence, different approaches are proposed. In [15],knowledge transfer is made between the KTH data set [16],the TRECVID data set [17] and the Microsoft research actiondata set II (MSRII), where the KTH data set is seen asthe target domain and both the TRECVID data set and theMSRII data set are used as the source domains. The KTHdata set is limited to clean backgrounds and a single actorand each video sequence exhibits one individual action fromthe beginning to the end. On the other hand, the TRECVIDdata set and the MSRII data set are captured from realisticscenarios, with cluttered backgrounds and multiple actorsin each video sequence. To take advantage of the labeledtraining data from both the target domain and the sourcedomain, Daum\u00e9 [32] proposed the feature replication (FR)method using augmented feature for training. Inspired by [33],which applies the Gaussian mixture model (GMM) to modelthe visual similarities between images or videos, the workin [15] models the spatial temporal interests points (STIPs)with the GMM and introduces a prior distribution of theGMM parameters to generate probabilistic representations ofthe original STIPs. Such representations can accomplish theadaptation from the source domains to the target domain. Thebasic setting of [34] assumes that there are labeled trainingdata in the source domain, but no labeled training data in thetarget domain. Furthermore, the activities in the source domainand the target domain do not overlap, so that traditionalsupervised learning methods cannot be applied in this scenario.Utilizing the Web pages returned by search engines to minesimilarities across the domains, the labeled data in the sourcedomain are then interpreted by the label space of the targetdomain. In some extreme cases, the source domain data maynot be relevant to the target domain data.Sparseness has gained tremendous attention in various scientific fields, and computer vision is a dominant part of thistrend. Sparse models can find their applications in a wide rangeof computer vision techniques, e.g., dictionary learning (DL)[35]\u2013[37] and transfer learning. Raina et al. [38] apply sparsecoding to unlabeled data to break the tremendous amount ofdata in the source domain into basic patterns, (e.g., edges inthe task of image classification) so that knowledge can betransferred through the bottom level to form a higher levelrepresentation of the training samples in the target domain, inwhich case the source domain data do not necessarily needto be relevant to the target domain data. Since in the regulartransfer learning formalism, the source domain data have tobe relevant with the target domain data, such a knowledgetransfer method is named self-taught learning rather thantransfer learning. Zhu and Shao [39] present a discriminativecross-domain DL (DCDDL) framework that utilizes relevantdata from other visual domains as auxiliary knowledge forenhancing the learning system in the target domain. The objective function is designed to encourage similar visual patternsacross different domains to possess identical representationsafter being encoded by a learned dictionary pair. In the partof-speech (POS) tagging tasks, shared patterns from auxiliarycategorization tasks are extracted as pivot features, whichrepresent the frequent words emerged in the speech and arethemselves indicative of their corresponding categories [40].While the pivot features are sensitive to the POS tagging tasks,pivot visual words do not exist in typical local histogram-basedlow-level visual features, which indicates that no single featuredimension of the histogram bins is discriminative enough torepresent the difference of the visual categories [41].On the other hand, some works also target to identify a newlower-dimensional feature space such that the auxiliary domainand the target domain manifest some shared characteristics[42]\u2013[44], instead of transferring the entire knowledge acrossthe target domain and auxiliary domains making such anassumption that the smoothness property (i.e., those data pointsclose to each other are more likely to share the same label) issatisfied in low-dimension subspaces [41].B. Cross-View Knowledge TransferCross-view knowledge transfer can be seen as a special caseof cross-domain knowledge transfer, where the divergencesacross domains are caused by view-point changes. The taskis to recognize action classes in the target view using trainingsamples from one or more different views. Generating viewinvariant features to address the cross-view visual patternrecognition problems attracts significant attention in the computer vision field, especially for cross-view action recognition.The bottom of Fig. 3 shows the cross-view knowledge transferscenario on the multiview IXMAS [45] data set. The typicalsetting is to use samples captured in one view (the sourceview) as training data to predict the labels of samples capturedfrom a different view (the target view). The core methodologyof approaches that tackle visual categorization problems withchanges in the observer\u2019s viewpoint is to discover the sharedknowledge irrespective to such viewpoint changes. One common approach to attack the cross-view feature representationdiversity problem is to infer 3-D scene structure for cross-viewfeature adaptation, where the derived features can be adaptedfrom one view to another utilizing geometric reasoning[46]\u2013[49]. Another family of approaches is to explorevisual pattern properties, e.g., affine [50], projective [51],epipolar geometry [52]\u2013[54], to compute such cross-view\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATIONFig. 3. Top row: cross-domain knowledge transfer scenario. In the targetdomain, the walking action performed by a single player in clean backgroundscomes from the KTH data set, while in the target domain, the walking actioncaptured from much more complicated backgrounds with multiple playerscomes from the TRECVID data set. Bottom row: cross-view knowledgetransfer scenario, where the target view data and the source view data arethe same action captured from two different views of the IXMAS data set.feature representations. On the other hand, Junejo et al. [55]applied a self-similarity matrix to store distances betweendifferent pairs of actions for a view-invariant representation. Spatial-temporal features of a video sequence thatare insensitive to changes in view angle are studied in[12], [51], and [56]\u2013[58].In [12], a bipartite graph is built via unsupervisedco-clustering to measure the visual-word to visual-word relationship across the target view and the source view so thata high-level semantic feature that bridges the semantic gapbetween the two vocabularies can be generated. Beyondthe bag-of-visual-words representation, which have been successfully applied to natural language processing, informationretrieval, and computer vision, the proposed bag-of-bilingualwords representation discovers the shared set of commonaction concepts between two different views, even though thetwo view domains are highly independent. Similar to the workof [12], Li and Zickler [58] captured the conceptual ideaof virtual views construction to represent an action descriptor continuously from one observer\u2019s viewpoint to another.Another family of approaches is proposed in [59] and [60],where a pair of over-complete dictionaries are constructedutilizing correspondence samples across two view domains.Encouraged by the learned dictionary pair, the labeled sourceview data and unlabeled target view data are forced to thesame feature space that satisfies the smoothness assumption.We summarize the main characteristics of the feature representation level knowledge transfer approaches according totheir adaptation methods, the target domain label, the sourcedomain label, adaptation data types and applications, and listthem in Table I. Among these approaches, [38], [59], and [61]utilize the sparseness property to generate sparse representations for data adaptation.IV. C LASSIFIER -BASED K NOWLEDGE T RANSFERSimilar as the feature representation level knowledge transfer, classifier-based knowledge transfer is another significantpart of existing visual transfer learning techniques and it hasattracted much attention in recent years. However, unlike thefeature representation level knowledge transfer techniques,where only the training samples themselves in the source1023domain are adapted to the target learning framework, classifierbased knowledge transfer methods share the common traitthat the learned source domain models are utilized as priorknowledge in addition to the training samples when learningthe target model. Instead of minimizing the cross-domaindissimilarity by updating instances\u2019 representations, classifierbased knowledge transfer methods aim to learn a new modelthat minimizes the generalization error in the target domain viaprovided training instances from both domains and the learnedmodel. We structure this section according to the followingcategories of classifier-based knowledge transfer techniques.A. SVM-BasedSupport Vector Machine (SVM) is a supervised learningmethod for solving classification and regression problems, andthe majority of existing work on classifier-based knowledgetransfer are constructed from the original SVM classifier. As adirect application of SVM, adaptive-SVM (A-SVM) [18], andprojective model transfer SVM (PMT-SVM) [63] learn fromthe source model ws by regularizing the distance between thetarget model wt and the learned model ws . The A-SVM usesthe following objective function:L A = min \u0005wt \u2212 \u0003ws \u00052 + Cwt ,bN\u0003l(x i , yi ; wt , b)(2)iwhere yi \u2208 {\u22121, 1} indicates the corresponding labels,l(x i , yi ; wt , b) = max(0, 1 \u2212 yi (wt \u0006 x i + b)) is the hinge loss,C controls the weight of the loss function, and \u0003 controls theamount of transfer regularization. By regularizing the distancesbetween the two models, knowledge transfer for A-SVM islike a spring between \u0003ws and wt , which is equivalent toproviding samples from the source classes. By expanding theregularization term\u0005wt \u2212 \u0003ws \u00052 = \u0005wt \u00052 \u2212 2\u0003\u0005wt \u0005 cos \u03b8 + \u0003 2(3)where \u0005w\u00052 provides the margin maximization as in regularSVM and the second term \u22122\u0003\u0005w\u0005 cos \u03b8 induces the transferby maximizing cos \u03b8 , i.e., by minimizing the angle \u03b8 betweenwt and ws . Instead of maximizing the term cos \u03b8 , knowledge transfer can be induced by minimizing the projectionof wt onto the separating hyperplane orthogonal to ws forPMT-SVM using the following objective function:L PMT = min \u0005wt \u00052 + \u0003\u0005Pwt \u00052 + Cwt ,bs.t. : wt\u0006 ws \u2265 0N\u0003l(x i , yi ; wt , b)i(4)where P = I \u2212 (ws ws\u0006 )/(ws\u0006 ws ) is the projection matrix.Compared with A-SVM, PMT-SVM can increase the amountof transfer (\u0003) without penalizing margin maximization.Opposed to the rigid transfer methods A-SVM andPMT-SVM, the deformable adaptive SVM (DA-SVM) [63]provides more flexible transfer regularization through adeformable source template, where small local deformationscan be tolerated for the template fit of the source domain tothe target domain. Aytar and Zisserman [63] used a simpleexample to explain such visual deformation in knowledge\f1024IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015TABLE IM AIN C HARACTERISTICS OF L ISTED F EATURE R EPRESENTATION L EVEL K NOWLEDGE T RANSFER A PPROACHES .AVAILABILITY OF B OTH TARGET D OMAIN L ABELS , A DAPTATION T YPE , AND A PPLICATIONS OF A LLS TATED F EATURE R EPRESENTATION L EVEL K NOWLEDGE T RANSFER M ETHODS A RE L ISTEDtransfer that the wheel part of a motorbike template can beincreased in radius and reduced in thickness when fitting toa bicycle wheel template. The DA-SVM can also be seen asthe generalization form of the rigid A-SVM by replacing wsin (2) with \u03c4 (ws )L DA = min \u0005wt \u2212 \u0003\u03c4 (ws )\u00052 + Cf,wt ,b\u239b+\u03bb \u239dN\u0003iM,M\u0003i\b = jf i,2j di, j +M\u0003l(x i , yi ; wt , b)\u239e(1 \u2212 f ii )2 d \u23a0(5)iwhere \u03b8 is a scaling factor in the range of (0, 1) to control thedegree of transfer across the learned model ws and the targetmodel wt . When being extended to multimodel knowledgetransfer (multi-KT), the scaling factor \u03b8 is substituted withthe vector \u0007 = {\u03b81 , \u03b82 , . . . , \u03b8k }, where each \u03b8 j is the weightof a corresponding prior model. Thus, (6) can be rewritten as\u0002\u00022\u0002\u0002k\u0003\u0002\u0002\u0002L Multi-KT = min \u0002wt \u2212\u03b8 j ws j \u0002\u0002wt ,b \u0002\u0002j =1+lC\u0003\u03b6i (yi \u2212 wt \u00b7 \u03c6(x i ) \u2212 b)2 .2(7)i=1where di, j is the spatial distance between the i th and j th cell,d is the penalization for the additional flow from the i th sourcecell to the i th target cell, and \u03c4 (ws )i = Mj f ij ws j is the flowtransformation, where the parameter fi j denotes the amount oftransfer from the j th cell in the source template to the i th cellin the transformed template. The cells are extracted from localimage regions, on which local descriptors, (e.g., HOG [64] andSIFT [65]) are computed. Thus, different from other classifierbased knowledge transfer techniques, DA-SVM has such aconstraint that it has to be constructed using low-level visualfeatures that measure the geometrical information of localimage parts.Tommasi et al. [66] proposed a discriminative transferlearning method based on least squares support vector machine(LS-SVM) that learns the new category through adaptation.By replacing the regularization term in classical LS-SVM,the new learning objective function for knowledge transfer isformulated asl1C\u0003[yi \u2212 wt \u03c6(x i )\u2212b]2 (6)L KTLS = min \u0005wt \u2212 \u03b8 ws \u00052 +wt ,b 22i=1The \u03b6i in (7) is used for resampling the data so that trainingsamples are balanced. Taking the advantage of LS-SVM thatthe leave-one-out (LOO) error, which measures the properamount of knowledge to be transferred, can be written in aclosed form [67], the best values of \u03b8 j are those that minimizethe LOO error.Typically, the kernel functions need to be specified inadvance to learning and the associated kernel parameters,(e.g., the mean and variance in the Gaussian kernel) aredetermined during optimization. On top of the variouskernel learning methods [68]\u2013[71], the domain transfer SVM(DT-SVM) [72] unified the cross-domain learning frameworkby searching for the SVM decision function f (x) = w \u03c6(x)+bas well as the kernel function simultaneously instead of thetwo-step approaches [28], [73]. In general, DT-SVM achievescross-domain classification by reaching two objective criteria:1) DT-SVM minimizes the data distribution mismatch betweenthe target domain and source domains using the MMD criterion mentioned in Section II and 2) DT-SVM pursues betterclassification performance by minimizing the structural risk ofSVM. By meeting both criteria, an effective kernel function\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATIONcan be learned for better separation performance in linearspace over different domains, and thus samples from thesource domains are infused to the target domain to improvethe classification performance of the SVM classifier.B. TrAdaboostAdaptive boosting (AdaBoost) [74] is a popular boostingalgorithm, which has been used in conjunction with a widerange of other machine learning algorithms to enhance theirperformance. At every iteration, AdaBoost increases the accuracy of the selection of the next weak classifier by carefullyadjusting the weights on the training instances. Thus, moreimportance is given to misclassified instances since they arebelieved to be the most informative for the next selection.The transfer learning AdaBoost (TrAdaBoost) is introducedin [21] to extend AdaBoost for transfer learning by weightingless on the different-distribution data, which are consideredas dissimilar to the same-distribution data in each boostingiteration. The goal of TrAdaBoost is to reduce the weightedtraining error on the different-distribution data, and meanwhilepreserving the properties of AdaBoost. Since the qualityof different-distribution data is not certain, the performanceof TrAdaBoost cannot be always guaranteed to outperformAdaBoost.C. Generative ModelsThe learning to learn concept via rich generativemodels has emerged as one promising research area in bothcomputer vision and machine learning. Recently, researchershave begun developing new approaches to deal with transferlearning problems using generative models. One workshop inconjunction with NIPS 2010 was held specifically for thediscussion of transfer learning via rich generative models.In general, the generative knowledge transfer methods canlead to higher-impact transfer, including more information thanthose discriminative approaches and they can be more adaptiveto a single specific task.Fei-Fei et al. [75] proposed a Bayesian-based unsupervised one-shot learning object categorization framework thatlearns a new object category using a single example (orjust a few). Since Bayesian methods allow us to incorporate prior information about objects into a prior probabilitydensity function when observations become available, generalinformation coming from previously learnt unrelated categories is represented with a suitable prior probability density function on the parameters of the probabilistic models.Thus, priors can be formed from unrelated object categories.For example, when learning the category motorbikes, priorscan be obtained by averaging the learnt model parametersfrom other three categories spotted cats, faces, and airplanes,so that the hyperparameters of the priors are then estimated from the parameters of the existing category models.Yu and Aloimonos [76] applied the generative authortopic [77] model to learn the probabilistic distribution ofimage features-based object attributes. Since object attributescan represent common properties across different categories,they are used to transfer knowledge from source categories1025to target categories. Both the zero-shot learning problem andthe one-shot learning problem are addressed, where in the firstproblem, the attribute model learned from the source domaincategories is used to generate synthesized target trainingexamples through the generative process, and in the secondproblem, the learned attribute model is used to reduce theuncertainty of parameters of the Dirichelt priors.D. Fuzzy System-Based ModelsTransfer learning also finds its application in fuzzy systems.Deng et al. [78] and [79] proposed two knowledge-leveragebased fuzzy system models, respectively. The former is basedon the Takagi\u2013Sugeno\u2013Kang fuzzy system, and the latter isbased on the reduced set density estimator-based Mamdani\u2013Larsen-Type fuzzy system. In both works, the training set isdecomposed to training data of the current scene and modelparameters of reference scenes. The same knowledge leveragestrategy is adopted by both works, where model parametersobtained from the reference scenes are fed to the current scenefor parameter approximation. The knowledge leverage strategyis performed through a unified objective function, whichemphasizes on both learning from the data of the current sceneand transferring model parameters from reference scenes.1) Discussion: The stated SVM-based knowledge transfermethods can act as a plug in to the SVM training process.A common trait shared amid these methods according to theirobjective functions is that they all include a regularizationterm that measures the similarity between the learned modeland the target model. In A-SVM, PMT-SVM, and DA-SVM,\u0003 is the tradeoff parameter between margin maximizationand knowledge transfer, so it defines the amount of transfer regularization. The DA-SVM is specialized in dealingwith the transfer of visually deformable templates, whileA-SVM and PMT-SVM are more likely to be generalized.The advantage of PMT-SVM over A-SVM is that it canincrease the amount of transfer without penalizing marginmaximization, while A-SVM encourages \u0005w\u0005 to be largerwhen increasing \u0003. A large \u0005w\u0005 indicates small margins to thehyperplane, and thus the generalization error of the classifierfails to gain an optimal bound. In general, PMT-SVM isexpected to outperform A-SVM.Compared with SVM-based approaches, the boosting-basedmethod, TrAdaBoost, is simpler in terms of implementation,and it does not require the parameters from the prelearnedmodels. Like other boosting-based techniques, TrAdaBoosthas a fairly strong generalization ability. However, TrAdaBoostrelies heavily on the relevance of the source domain data to thetarget domain data, thus it is vulnerable to negative transfers.In addition, TrAdaBoost can easily overfit in the presenceof noise in either domain. The generative models are moreadaptive to a specific task, however, but computationally morecomplex.V. M ODEL S ELECTION IN K NOWLEDGE T RANSFERIn real-world applications, knowledge transfer techniqueshave to consider more complicated scenarios than adaptingthe samples or prelearned models from a single source domain\f1026IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015A. SVM-BasedIn the one-to-one adaptation scenario of A-SVM [18], thenew target classifier f T (x) is adapted from the existing sourceclassifier f s (x) using the formf T (x) = f s (x) +Fig. 4. Knowledge transfer from multiple auxiliary domains. (a) Auxiliarydomain 1. (b) Auxiliary domain 2. (c) Target domain. The two subfigures onthe left denote the two different auxiliary domain data and their correspondingdecision boundaries, where auxiliary domain 1 is partitioned by a horizontalline and auxiliary domain 2 is partitioned by a vertical line. By brutally combining the decision boundaries from the two auxiliary domains, ambiguouspredictions will be caused in the top-left region and the bottom-right regionof the target domain.to obtain the target learner. In the first case, more than onesource domains are available yet we have no idea whichsource domain contains more useful information that potentially improves the target learner or whether the knowledgein a specific domain is against the smoothness property inthe target domain. On the other hand, in visual categorizationtasks, the shared information across the two domains canbe hidden in different visual forms, e.g., appearance, localsymmetry, and layout, which can be captured by differentfeature descriptors. A fusion strategy is required to mine themost helpful knowledge from multiple features. The third caseis that some knowledge transfer techniques are constructedfrom prelearned models, e.g., a learned bicycle classifier or alearned bird classifier, and these models can lead to differentscales of contributions to the target model. In advance toknowledge transfer, the bad prelearned models need to befiltered out so that the good models can achieve more effectivetransfer. All the above three cases generalize the commonmany-to-one adaptation situations in knowledge transfer, andthey can all be deemed as the model selection problem. Fig. 4shows a typical example of multisource binary classification.A straightforward approach to reduce such prediction ambiguity is to measure the model similarity between each auxiliarydomain and the target domain, and apply the closest model forprediction in the target domain, i.e., if auxiliary domain 1 ismore similar with the target domain, the decision boundaryin Fig. 4(c) will inherit the decision boundary in Fig. 4(a).However, data in auxiliary domain 2, which also containuseful information for the prediction of target domain data,are abandoned.In general, extending the existing single-source knowledgetransfer techniques to the multiple-source scenario can evoketwo challenges: 1) how to leverage the distribution differencesamong multiple source-domains to promote the predictionperformance on the target domain task? and 2) how toextend the single-source knowledge transfer techniques to adistributed algorithm, while only sharing some statistical dataof all source domains instead of revealing the full contents?Since most existing multiple-source knowledge transfermethods are extended from their corresponding single-sourcealgorithms, we structure this section in a similar manner asSections III and IV.f (x)(8)where the perturbation function f (x) is learned using thelabeled data DlT from the target domain. Intuitively, whenencountering with multiple source domains D1s , D2s , . . . , DsM ,which are assumed to possess similar distributions to theprimary domain D t , the adapted classifier can be constructedusing the ensemble of all the source domain classifierssf 1s (x), f 2s (x), . . . , f M(x)f T (x) =M\u0003\u03b3k fks (x) +f (x)(9)k=1where \u03b3k \u2208 (0, 1) is the predefined weight of each sourcemclassifier f ks (x), which sums to one:k=1 \u03b3k = 1. TheMMD criterion can be applied for obtaining the value of \u03b3k .The perturbation function can be formulated asf (x) =nlT y T k(x T , x), where \u03b1 T is the coefficient of the i th\u03b1iii=1 i ilabeled pattern in the target domain and k(\u00b7, \u00b7) is a kernel function induced from the nonlinear feature mapping \u03c6(\u00b7). Whenapplying the same kernel function to the source classifiers,(9) can be expanded asf (x) =T\u0003s\u03b3snl\u0003\u03b1is yis k\u0004x iT , x\u0005+i=1nl\u0003\u0004\u0005\u03b1iT yiT k x iT , x , (10)i=1which is the sum of a set of weighted kernel evaluationsbetween the test pattern x and all labeled patterns x iT and x is ,respectively, from the target domain and all the sourcedomains. Obviously, the learning process is inefficient whenbeing applied to large-scale data sets, which is the first disadvantage of A-SVM on the many-to-one adaptation application.The second disadvantage of A-SVM is its failure on using theunlabeled target domain data DuT .Duan et al. [72] proposed the domain adaptationmachine (DAM) to overcome the two disadvantages ofA-SVM. To utilize the unlabeled target domain data DuT ,a data-dependent regularizer is defined for the targetclassifier f T( f uT ) =\u000521 \u0003 \u0003\u0004 T\u03b3sf i \u2212 fis2Sms=1i=1(11)where f uT = [ f nTl +1 , . . . , f nTT ] and f us = [ f nsl +1 , . . . , f nsT ] aredefined as the decision values from the target classifier and thesth source classifier, respectively. Based on the smoothnessassumption for domain adaptation, DAM minimizes the structural risk function of LS-SVM as well as the data-dependentregularizer simultaneously. DAM is formulated asl\u0004 T\u000521\u0003fi \u2212 yiT +2nminfT(fT) +\u0004Df uT\u0005(12)i=1where ( f T ) is a regularizer to control the complexity ofthe target classifier f T . Since the target classifier in DAM is\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATION1027learned in a sparse representation, the computation inefficiencyproblem of A-SVM is overcome.By arguing that it is more beneficial to transfer from afew relevant source domains rather than using all the sourcedomains as in A-SVM and DAM, Duan et al. [80] furtherdesign a new data-dependant regularizer in domain selectionmachine (DSM) for source domain selection\u000521 \u0003 \u0003\u0004 Tf i \u2212 f is .ds2S(f) =s=1m(13)i=1Similar as \u03b3s in (11), which is a predefined weight measuringthe relevance between the sth source domain and the targetdomain, ds \u2208 {0, 1} in (13) is a domain selection indicatorfor the sth source domain. When the objective function isoptimized, the value of ds is 1 if the sth source domainis relevant to the target domain, and the value of ds is 0otherwise. Another advantage of DSM over most existingtransfer learning methods is its ability to work when thesource domains and the target domain are represented bydifferent types of features, e.g., using static 2-D SIFT featuresto represent the source domain data and 3-D spatio-temporal(ST) features to represent the target domain data. The learningfunction of DSM can be formulated asS\u0003ds \u03b2s f s (x) + w \u03d5(x) + bf (x) = f 2 D(x) + f 3 D(x) =s=1(14)Ss=1 ds \u03b2sf s (x)where f 2 D(x) =is a weighted combinationof source classifiers based on SIFT features, \u03b2s is a real-valuedweight for the sth source domain, f 3D (x) = w \u03d5(x) + b isthe adaptation error function of space-time features, \u03d5(\u00b7) is afeature mapping function that maps x into \u03d5(x), w is a weightvector, and b is a bias term.B. Boosting-BasedAs discussed in Section IV-B, TrAdaBoost relies only onone source domain, which makes it intrinsically vulnerableto negative samples in the source domain. To avoid sucha problem, Yao and Doretto [81] proposed two boostingapproaches multisource-TrAdaBoost and task-TrAdaBoost forknowledge transfer with multiple source domains.Multisource-TrAdaBoost is an extension of TrAdaBoostto multiple source domains. Instead of searching for a weakclassifier by leveraging a single source domain, a mechanismis introduced to apply all the weak classifiers in the selectedsource domain that appears to be the most relevant to the targetdomain at the current iteration. Specifically, the training data ofeach source domain are combined with the training data in thetarget domain to generate a candidate weak classifier at eachiteration, while all the source domains are considered independent from each other. Thus, the multisource-TrAdaBoostapproach significantly reduces the effects of negative transfercaused by the imposition to knowledge transfer from a singlesource domain, which is potentially not relevant to the targetdomain.On the other hand, task-TrAdaBoost is a parameter-transferapproach, that tries to identify which parameters that comefrom various source domains can be used. Task-TrAdaBoostis constituted of two separate phases. In phase-I, traditionalAdaBoost is employed to extract suitable weak classifiersfrom each source domain, respectively, under the assumption that some parameters are shared between the sourcedomain and the target domain. Thus, the source domain isdescribed explicitly rather than implicitly with only the labeledsource domain data. Phase-II runs the AdaBoost loop againover the target training data using the collection of all thecandidate weak classifiers obtained from phase-I. At eachiteration, the weak classifier with the lowest classificationerror on the target training data is picked out to ensure theknowledge being transferred is more relevant to the targettask. In addition, the update of the weights on the targettraining data drives the search of the most helpful candidate classifiers in the next round for boosting the targetclassifier.C. Multikernel LearningThere are many types of hidden knowledge that can betransferred across different visual domains, for example, theappearance or shape of an object part, (e.g., the shape ofa wheel), local symmetries between parts, (e.g., the symmetry between front- and back-legs for quadrupeds), andthe partially shared layout, (e.g., the layout of torso andlimbs of a human). When employing knowledge transferbetween the visual domains, though the shared knowledgeexists among the target data and the source data, the exacttype of knowledge that needs to be transferred is uncertain.Alternately, since these different types of knowledge can berepresented by different features or different prior models,all types of knowledge can be considered by fusing thesefeatures or prior models when constructing the target model.Instead of using predefined weights for all the features orprior models, multikernel learning provides a more appropriatesolution by learning the linear combination of coefficients ofthe prelearned classifiers to assure the minimization of domainmismatches.Motivated by A-SVM, Duan et al. [82] proposed an adaptivemultiple kernel learning (A-MKL) method to cope with theconsiderable variation in feature distributions between videosfrom two domains. As described above, in A-SVM, the targetclassifier is adapted from an existing classifier trained with thesource domain data. When A-SVM employs multiple sourceclassifiers, those classifiers are fused with fixed weights.Different from A-SVM, A-MKL learns the optimal combination of coefficients corresponding to each prelearned classifierto minimize the mismatch between the data distributions oftwo domains under the MMD criterion.The multimodel knowledge transfer (multi-KT) [66] methodmodifies the l2 -norm regularizer in the LS-SVM objectivefunction and constrains the new hyperplane w to be closeto hyperplanes of F prior models. The regularization term isgiven as \u0005w \u2212 Fj=1 \u03b2 j \u03bc j \u0005, where \u03bc j is the hyperplane ofthe j th model, and \u03b2 j determines the amount of transfer fromeach model, while subjecting to the constraint that \u0005\u03b2\u00052 \u2264 1.\f1028IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015For a sample x, the decision function is given bys(x) = w \u00b7 \u03c6(x) +F\u0003\u03b2 j \u03bc j \u00b7 \u03c6(x).(15)j =1While the solution to multi-KT is through two separateoptimization problems, Jie et al. [83] proposed a multiplekernel transfer learning (MKTL) method that learns the besthyperplanes and corresponding weights assigned to each priormodel in a unified optimization process. The MKTL utilizesthe prior knowledge as experts evaluating the new queryinstances and addresses such a knowledge transfer problemwith a multikernel learning solver. In addition to the trainingsample x i , the prediction score s p (x i , z), z = 1, . . . , F (F isthe total number of classes), predicted by the prior models areconsidered when learning the new model. The intuition behindsuch an idea is that if prior knowledge of a bicycle gives a highprediction score to images of a motorbike, this informationmay also be useful for the new model of motorbikes, sincecertain visual parts, (e.g., the wheels) are shared between thetwo categories. Priors are built over multiple features insteadof only one, and meanwhile, different learning methods areconsidered.D. Cross-View Multiple Source AdaptationFor the cross-view action recognition problem, some sharedvisual patterns (either spatial or ST) can exist in actionscaptured from more than one view-points, thus transferringknowledge from multiple source views to the target viewis more beneficial rather than transferring from a singleview.Liu et al. [12] apply the locally weighted ensemble (LWE)approach introduced in [45] to fuse the multipleclassification models. Specifically, for a set of prelearnedmodels f 1 , f 2 , . . . , f k , the general Bayesian modelaveraging approach computes the posterior distributionkof y as P(y|x) =i=1 P(y|x, D, f i )P( f i |D), whereP(y|x, D, fi ) = P(y|x, f i ) is the prediction made by eachmodel and P( fi |D) is the posterior of model f i after observingthe training set D. Considering the data distribution mismatchacross the target domain and the source domains, the modelprior for P( fi |T ) is incorporated, where T is the test set. Byreplacing P( fi |D) with P( fi |T ), the difference between thetarget and the source domains are considered during learningP(y|x) =k\u0003w fi ,x P(y|x, f i )(16)i=1where w fi ,x = P( fi |x) is the true model weight that islocally adjusted for x representing the model\u2019s effectivenesson the target data.Li and Zickler [58] achieve multiview fusion by aggregatingthe response values from the w MKL-SVM [69] classifierson their corresponding cross-view features x\u0302, beyond which abinary decision is made. Similar as the idea in MKTL [83],MKL-SVM solves a standard SVM optimization problem,where the kernel is defined as a linear combination of multiplekernels.1) Discussion: The multiple source A-SVM is an intuitiveextension of A-SVM that it assembles all the source domainclassifiers by allocating a weight \u03b3k to each source classifier.The DAM and DSM are proposed to overcome the disadvantages of multiple source A-SVM in both inefficiency and thefailure of using unlabeled target domain data, where DSMprecedes over DAM by filtering out those less relevant sourcedomain data.By introducing multiple source domains rather thanone in both multisource-TrAdaBoost and task-TrAdaBoost,the first imperfection of TrAdaBoost has been compensated. The convergence properties of multisource-TrAdaBoostcan be inherited directly from TrAdaBoost [21], whereasfor task-TrAdaBoost they can be inherited directly fromAdaBoost [74]. It has been proved in [81] that since theconvergence rate of task-TrAdaBoost has a reduced upperbound compared with multisource-TrAdaBoost, it requiresfewer iterations to converge.Compared with A-SVM, the unlabeled data in the targetdomain are used in the MMD criterion of A-MKL, andthe weights in the target classifier are learned automaticallytogether with the optimal kernel combination. Calling thetheorem in [84], for the binary-class classification of multi-KT,multi-KT is equivalent to multiple source A-SVM based onthe Mahalanobis distance measure [85]. Since the relationshipbetween A-SVM and PMT-SVM is demonstrated in (2)\u2013(4),the connection between multi-KT and PMT-SVM can benaturally discovered.VI. E VALUATION , A NALYSIS , AND D ISCUSSIONIn general, there are three types of benefits that transferlearning can provide for performance improvements [66],[86], including: 1) higher start\u2014improved performance atthe initial points; 2) higher slope\u2014more rapid growth ofperformance; and 3) higher asymptote\u2014leading to improvedfinal performance. In the following, several simple experimentsare conducted with some selected representative knowledgetransfer techniques discussed above to make a comparisonbetween these methods and to see whether they can meet thestated criteria.A. Feature-Level Knowledge Transfer MethodsComparison between different feature representation crossview transfer learning methods is given in Tables II and III,where experiments are conducted on every possible pairwiseview combination of the IXMAS data set (i.e., twenty combinations in total) and columns demonstrate the results of targetviews, while rows demonstrate the results of auxiliary trainingviews. According to previous cross-view action recognitionworks, there are two different experimental settings, whichare the correspondence mode and the partially labeled mode.In the correspondence mode, the leave-one-action-class-outscheme is applied, where one action class is considered asthe orphan action in the target view, while all action videosof the selected class are excluded when establishing the correspondences. Approximately 30% of the nonorphan samplesare randomly selected to serve as the correspondences, and\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATIONTABLE IIC OMPARISON B ETWEEN D IFFERENT F EATURE R EPRESENTATIONC ROSS -V IEW T RANSFER L EARNING M ETHODS IN THEC ORRESPONDENCE M ODE . R ESULTS A RE R EPORTEDON E VERY P OSSIBLE PAIRWISE V IEW C OMBINATIONIXMAS D ATA S ET, W HERE C OLUMNSC ORRESPOND TO THE TARGET V IEWS ANDOF THEROWS C ORRESPOND TO S OURCE V IEWSTABLE IIIC OMPARISON B ETWEEN C ROSS -V IEW K NOWLEDGE T RANSFERM ETHODS IN THE PARTIALLY L ABELED M ODE . R ESULTSA RE R EPORTED ON E VERY P OSSIBLE PAIRWISE V IEWC OMBINATION OF THE IXMAS D ATA S ET, W HEREC OLUMNS C ORRESPOND TO THE TARGETV IEWS AND ROWS C ORRESPONDTO S OURCE V IEWSnone of these correspondences are labeled. On the other hand,there are a small set of samples labeled in the partially labeledmode. We list the performance comparison of the abovementioned methods of the correspondence mode in Table IIand of the partially labeled mode in Table III, respectively.1029Seven pairwise view scenarios are shown in Table II:1) without (WO) transfer learning techniques [12]; 2) usingthe method in [12] with bilingual-words (BW); 3) usingthe method in [62] with quantized aspect (QA); 4) using themethod in [55] with self-similarity metrics (SS); 5) using themethod in [87] with continuous model of aspect (CV); 6) usingthe method in [58] with discriminative virtual views (VV); and7) using the transferable dictionary pair in [59] constructedby DL. According to Table II, DL significantly outperformsthe other methods and its most significant improvement overWO is 87% when treating Camera 0 as the source viewand Camera 3 as the target view. Loosening the experimentalrestrictions by abandoning the correspondence instances fromboth views, while adding a small set of labeled traininginstances in the target view, comparisons between SVMSUT,AUGSVM, MIXSVM [88], VV, and DL are given in Table III,where DL still achieves the best results with the most significant improvement of 88.7% over WO when treating Camera 0as the source view and Camera 3 as the target view. In general,Camera 4 has relatively weak performance. The reason isthat Camera 4 is set above the actors, so that actions arecaptured in a totally different view. On the other hand, theperformance involving Camera 4 can effectively demonstratethe capability of a transfer learning system. The BW, VV,and DL significantly outperform QA, SS, and CV. However,one limitation for the former three lies in that they implicitlyassume that the target view is known for a query sequence.B. Classifier-Level Knowledge Transfer MethodsWe conduct experiments on both image classification andaction recognition tasks, where the PASCAL VOC 2007 dataset [89] is used for image classification and the UCF YouTubeand HMDB51 data set [90] are used for action recognition.The PASCAL VOC 2007 data set contains 20 object classes,including bird, bicycle, motorbike, and so on, among whichwe choose samples from the bicycle class and the motorbike class as positive samples of the target domain and thesource domain, respectively, and samples from the remainingclasses as negative testing samples in the target domain. Thehistogram of oriented gradients (HOG) features are extractedfrom each image by dividing each image into eight cells.The task is to learn a bicycle classifier to achieve a binarydecision over whether the test sample belongs to the bicyclecategory or a different category. The target classifier is learnedby transferring information from a motorbike classifier viathe guidance of a few bicycle samples. We compare themethods of nontransfer SVM, A-SVM, PMT-SVM, DA-SVM,and MKTL in Table IV with different numbers of trainingexamples that vary from 1 to 25 with the interval of 3. Amongthese methods, DA-SVM achieves the best performance interms of higher start and higher slope, while the PMT-SVMachieves the best final performance.The UCF YouTube action data set is a realistic data setthat contains camera shaking, cluttered background, variationsin actors\u2019 scale, variations in illumination, and view pointchanges. There are 11 actions contained in the UCF YouTubedata set, including biking, diving, golf swinging, and so on.\f1030IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015TABLE IVP ERFORMANCE C OMPARISON ON THE I MAGE C LASSIFICATION TASK B ETWEEN SVM, A-SVM, PMT-SVM, DA-SVM, AND MKTL. M ODELSA RE L EARNED W ITH D IFFERENT N UMBERS OF T RAINING E XAMPLES OF THE B ICYCLE C LASS AND THE M OTORBIKE C LASS AS THES OURCE D OMAIN . F IRST ROW I NDICATES THE N UMBER OF T RAINING S AMPLES U SED IN THE S OURCE D OMAINTABLE VP ERFORMANCE C OMPARISON ON THE A CTION R ECOGNITION TASK B ETWEEN SVM, A-SVM, PMT-SVM, AND MKTL M ODELS A RE L EARNEDW ITH D IFFERENT N UMBERS OF T RAINING E XAMPLES OF THE B IKING C LASS AND THE D IVING C LASS AS THE S OURCE D OMAIN ON THEUCF Y OU T UBE D ATA S ET. F IRST ROW I NDICATES THE N UMBER OF T RAINING S AMPLES U SED IN THE S OURCE D OMAINThe binary action recognition task aims at distinguishingactions between the biking class and the diving class withcorresponding source domain actions from the HMDB51 dataset, which is an even more challenging data set. Densetrajectories [91] are extracted from raw action video sequences\u221awith eight spatial scales spaced by a factor of 1/ 2, andfeature points are sampled on a grid spaced by five pixelsand tracked in each scale, separately. Each point at framet is tracked to the next frame t + 1 by median filteringin a dense optical flow field. To avoid the drifting problem, the length of a trajectory is limited to 15 frames. TheHOG-HOF [92] and MBH [93] are computed within a 32 \u00d732 \u00d7 15 volume along the dense trajectories, where eachvolume is subdivided into a ST grid of size 2 \u00d7 2 \u00d7 3 toimpose more structural information in the representation. TheLLC coding scheme [94] is applied to the low-level local densetrajectory features. We compare the methods of nontransferSVM, A-SVM, PMT-SVM, and MKTL in Table V. Obviously,the overall performance when transferring knowledge from themotorbike class to the bicycle class on the PASCAL VOC2007 data set significantly outperforms the performance fortransferring knowledge from the biking class to diving classon the UCF YouTube data set. This is due to that the relevancebetween motorbike and bicycle is much higher than therelevance between the actions biking and diving. In addition,the shared visual commons in video sequences are moredifficult to capture than those in images. Compared with theresults demonstrated in the image classification task, addingmore training samples in the action recognition task leads tomore significant improvements. As discussed in Section III,PMT-SVM is expected to outperform A-SVM in general.As shown in Tables IV and V, A-SVM outperforms PMT-SVMwhen a single or a few training instances are available, whilePMT-SVM outperforms A-SVM in most cases when sufficientTABLE VIR ECOGNITION R ESULTS ON THE UCF Y OU T UBE D ATA S ET W HENU SING THE HMDB51 D ATA S ET AS THE S OURCE D OMAINTABLE VIIM EAN AVERAGE P RECISIONS (MAPs) OF SVM, DASVM,DAM, DSM SIM , AND DSM M ETHODS ON K ODAK ,Y OU T UBE , AND CCV D ATA S ETStraining instances are available. This can be explained as thatPMT-SVM is relatively more sensitive to bad training samples.We additionally conduct experiments on the action recognition task to compare the performance between the featurelevel knowledge transfer techniques (FR and DCDDL),the classifier-level knowledge transfer technique (A-SVM)and nonknowledge transfer techniques (LLC and K-SVD).The experiments are conducted using the same setting asdescribed above on the UCF YouTube data set and theHMDB51 data set. The results are demonstrated in Table VI.\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATION1031TABLE VIIIM EANS AND S TANDARD D EVIATIONS OF MAPs OVER S IX E VENTS FOR M ETHODS IN T HREE C ASES : 1) C LASSIFIERS L EARNED BASED ON SIFTF EATURES ; 2) C LASSIFIERS L EARNED BASED ON ST F EATURES ; AND 3) C LASSIFIERS L EARNED BASED ON B OTH SIFT AND ST F EATURESBy comparing the results of nonknowledge transfer techniquesLLC and K-SVD by brutally using the source domain datato the same techniques without the source domain data, wecan conclude that brutal forcing the source domain data intothe target task could degrade the performance of originallearning systems. Among the listed techniques, the recentlyproposed cross-domain DL method DCDDL achieves the bestperformance.TABLE IXC ROSS -V IEW T RANSFER L EARNING A CTION R ECOGNITION W ITHM ULTIPLE AUXILIARY V IEWS U NDER B OTH C ORRESPONDENCEM ODE AND PARTIALLY L ABELED M ODEC. Knowledge Transfer From Multiple Source DomainsTo demonstrate the performance comparisons betweenmultisource knowledge transfer methods, we quote the experimental results in [80] and [82] for cross-domain multisourceknowledge transfer, and the results in [12] and [58] for crossview multisource knowledge transfer.Duan et al. [80] chose the two large-scale image datasets to construct multiple source domains, where the firstdata set is the NUS-WIDE data set [96], which consistsof 269, 648 images downloaded from the Flickr, and thesecond data set is collected from the photo forum calledphotosig.com, which contains about 1.3 million images. Threereal-world consumer video data sets, the Kodak data set [82],the YouTube data set [80], and the CCV data set [97],are used as the target domains for performance evaluation,where the former contains 195 videos from six event classes,(e.g., birthday, picnic, parade, show, sports, and wedding), themiddle is collected from YouTube using the same event classesas in the Kodak data set, and the latter contains 2726 videosfor the same event classes. In the source domain, one hundredthousand training images are randomly selected from the twoimage sources and SIFT features are extracted from eachimage. After that, five source domains are constructed byrandomly sampling 100 relevant images and 100 irrelevantimages for clustering. In the target domain, both static SIFTfeatures and space-time features are extracted from eachvideo sequence in all the three data sets, where space-timeinterest point (STIP) feature and the Mel-frequency cepstralcoefficients audio feature are extracted from the CCV dataset, and three types of space-time features, HOG, HOF, andMBH, are extracted from Kodak and YouTube data sets. Sincethe standard SVM and DASVM cannot handle the domainadaptation problem when the data from the source and thetarget domain are with different feature types, only static SIFTfeatures are used to learn classifiers in the target domain. TheMAPs of SVM, DASVM, DAM, DSMsim , and DSM methodson the three data sets are show in Table VII, where DSMsim ,as a simplified version of DSM, only considers the ST featuresin the target domain. Compared with the standard SVM,DASVM, and DAM achieve worse or equivalent performanceon all three data sets, which indicate that the source domaindata are not successfully used by these two methods. Basedon the observation that the DSMsim consistently outperformsthe related DAM method, it clearly demonstrates the benefitsof employing the selected relevant source domains rather thanusing all the source domains. The DSM method achieves thebest performance on all three data sets, which further demonstrates the effectiveness of integrating static SIFT features andST features. Experiments are also conducted in [82] usingthe Kodak data set and videos downloaded from YouTubeusing keywords-based search to evaluate the performance ofA-SVM, DTSVM, and A-MKL by transferring knowledgefrom the source image domains to the target video domain.Table VIII reports the means and the standard deviationsof MAPs over all six events for the standard SVM, MKL,DTSVM, and A-MKL methods in the three cases, which are:1) classifiers learned based on SIFT features; 2) classifierslearned based on ST features; and 3) classifiers learned basedon both SIFT and ST features. Two forms of the standardSVM method, SVM-AT and SVM-T, are evaluated, whereSVM-AT is learned based on samples from both the targetdomain and the source domain and SVM-T is learned basedon samples only from the target domain. SVM-T outperformsSVM-AT in both cases 2) and 3), which indicates that directly,including the source domain knowledge may degrade theevent recognition performances in the target domain. For allmethods, the MAPs based on SIFT features are better thanthose based on ST features. This is consistent with ourevaluation for classifier level knowledge transfer methods,\f1032IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015which indicates that the shared commons are more difficultto be captured in ST features than in static SIFT features.The effectiveness of fusing average classifiers and multiplebase kernels is proved in A-MKL by providing the bestperformances for all cases.The LWE fusing approach [12] and MKL-SVM approach[58] are compared with the SVMSUT, AUGSVM, MIXSVMmethods on both the correspondence mode and the partially labeled mode in Table IX for cross-view multisourceknowledge transfer. The overall results in the correspondencemode significantly outperforms the results in the partiallylabeled mode. In the correspondence mode, LWE andMKL-SVM achieve equivalent performance, while in thepartially labeled mode, MKL-SVM consistently leads to thebest performance.VII. C ONCLUSIONIn this survey, we have reviewed transfer learning techniqueson visual categorization tasks. There are three types of knowledge that are useful for knowledge transfer: 1) source domainfeatures; 2) source domain features and the correspondinglabels; and 3) parameters of the prelearned source domainmodels, which indicate instance-based transfer learning, inductive transfer learning and parameter-based transfer learning,respectively. Through the performance comparisons betweenknowledge transfer techniques and nonknowledge transfertechniques, we can conclude that brutal forcing the sourcedomain data for learning can degrade the performance ofthe original learning system, which demonstrates the significance of knowledge transfer. To transfer the source domainknowledge to the target domain, methods are designed fromeither the feature representation level or the classifier level.In general, the feature representation level knowledge transferaims to unify the mismatched data in different visual domainsto the same feature space and the classifier level knowledgetransfer aims to learn a target classifier based on the parametersof prelearned source domain models, while considering thedata smoothness in the target domain. Thus, the featurerepresentation level knowledge transfer techniques belong toeither instance-based transfer or inductive transfer, while mostclassifier level knowledge transfer techniques belong to theparameter-based transfer. To avoid transferring the negativeknowledge and deal with the many-to-one adaptation problem,many strategies are proposed to learn a set of weights for eachsource domain to achieve multiple source domain knowledgefusion.Transfer learning is a tool for improving the performance ofthe target domain model only in the case that the target domainlabeled data are not sufficient, otherwise the knowledge transfer is meaningless. So far, most research on transfer learningonly focuses on small scale data, which cannot well reflect thepotential advantage of transfer learning over regular machinelearning techniques. The future challenges of transfer learningshould lie in two aspects: 1) how to mine the informationthat would be helpful for the target domain from highly noisysource domain data and 2) how to extend the existing transferlearning methods to deal with large-scale source domaindata.R EFERENCES[1] L. Shao, L. Liu, and X. Li, \u201cFeature learning for image classification viamultiobjective genetic programming,\u201d IEEE Trans. Neural Netw. Learn.Syst., vol. 25, no. 7, pp. 1359\u20131371, Jul. 2014.[2] L. Liu, L. Shao, and P. Rockett, \u201cBoosted key-frame selectionand correlated pyramidal motion-feature representation for humanaction recognition,\u201d Pattern Recognit., vol. 46, no. 7, pp. 1810\u20131818,2013.[3] L. Shao, D. Wu, and X. Li, \u201cLearning deep and wide: A spectral methodfor learning deep networks,\u201d IEEE Trans. Neural Netw. Learn. Syst., doi:10.1109/TNNLS.2014.2308519.[4] L. Zhang, X. Zhen, and L. Shao, \u201cLearning object-to-class kernels forscene classification,\u201d IEEE Trans. Image Process., vol. 23, no. 8, pp.3241\u20133253, Aug. 2014.[5] L. Shao, X. Zhen, D. Tao, and X. Li, \u201cSpatio-temporal Laplacianpyramid coding for action recognition,\u201d IEEE Trans. Cybern., vol. 44,no. 6, pp. 817\u2013827, Jun. 2014.[6] L. Shao, S. Jones, and X. Li, \u201cEfficient search and localization of humanactions in video databases,\u201d IEEE Trans. Circuits Syst. Video Technol.,vol. 24, no. 3, pp. 504\u2013512, Mar. 2014.[7] F. Zhu, L. Shao, and M. Lin, \u201cMulti-view action recognition using localsimilarity random forests and sensor fusion,\u201d Pattern Recognit. Lett.,vol. 34, no. 1, pp. 20\u201324, 2013.[8] X. Cao, Z. Wang, P. Yan, and X. Li, \u201cTransfer learning for pedestriandetection,\u201d Neurocomputing, vol. 100, no. 1, pp. 51\u201357, 2013.[9] X. Gao, X. Wang, X. Li, and D. Tao, \u201cTransfer latent variable modelbased on divergence analysis,\u201d Pattern Recognit., vol. 44, nos. 10\u201311,pp. 2358\u20132366, 2011.[10] C. Orrite, M. Rodr\u00edguez, and M. Monta\u00f1\u00e9s, \u201cOne-sequence learning ofhuman actions,\u201d in Proc. 2nd Int. Workshop Human Behavior Unterstand., Amsterdam, The Netherlands, Nov. 2011, pp. 40\u201351.[11] D. Wu, F. Zhu, and L. Shao, \u201cOne shot learning gesture recognitionfrom RGBD images,\u201d in Proc. 25th IEEE Conf. Comput. Vis. PatternRecognit. Workshops, Providence, RI, USA, Jun. 2012, pp. 7\u201312.[12] J. Liu, M. Shah, B. Kuipers, and S. Savarese, \u201cCross-view actionrecognition via view knowledge transfer,\u201d in Proc. 24th IEEE Conf.Comput. Vis. Pattern Recognit., Colorado Springs, CO, USA, Jun. 2011,pp. 3209\u20133216.[13] L. Fei-Fei, \u201cKnowledge transfer in learning to recognize visual objectsclasses,\u201d in Proc. 5th Int. Conf. Develop. Learn., Bloomington, IN, USA,Jun. 2006.[14] I. Biederman, \u201cRecognition-by-components: A theory of human imageunderstanding,\u201d Psychol. Rev., vol. 94, no. 2, pp. 115\u2013147, 1987.[15] L. Cao, Z. Liu, and T. S. Huang, \u201cCross-dataset action detection,\u201d inProc. 23rd IEEE Conf. Comput. Vis. Pattern Recognit., San Francisco,CA, USA, Jun. 2010, pp. 1998\u20132005.[16] C. Schuldt, I. Laptev, and B. Caputo, \u201cRecognizing human actions:A local SVM approach,\u201d in Proc. 17th Int. Conf. Pattern Recognit.,Cambridge, U.K., Aug. 2004, pp. 32\u201336.[17] A. F. Smeaton, P. Over, and W. Kraaij, \u201cEvaluation campaigns andTRECVid,\u201d in Proc. 8th ACM Int. Workshop Multimedia Inform.Retrieval, Santa Barbara, CA, USA, Oct. 2006, pp. 321\u2013330.[18] J. Yang, R. Yan, and A. G. Hauptmann, \u201cCross-domain video conceptdetection using adaptive SVMs,\u201d in Proc. 15th ACM Int. Conf. Multimedia, Augsburg, Germany, Sep. 2007.[19] S. J. Pan and Q. Yang, \u201cA survey on transfer learning,\u201d IEEE Trans.Knowl. Data Eng., vol. 22, no. 10, pp. 1345\u20131359, Oct. 2010.[20] G.-J. Qi, C. Aggarwal, Y. Rui, Q. Tian, S. Chang, and T. Huang,\u201cTowards cross-category knowledge propagation for learning visualconcepts,\u201d in Proc. 24th IEEE Conf. Comput. Vis. Pattern Recognit.,Colorado Springs, CO, USA, Jun. 2011, pp. 897\u2013904.[21] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu, \u201cBoosting for transfer learning,\u201din Proc. 24th Int. Conf. Mach. Learn., Corvallis, OR, USA, Jun. 2007,pp. 193\u2013200.[22] Y. Wang and G. Mori, \u201cMax-margin hidden conditional random fieldsfor human action recognition,\u201d in Proc. 22nd IEEE Conf. Comput. Vis.Pattern Recognit., Miami, FL, USA, Jun. 2009, pp. 872\u2013879.[23] A. Yao, J. Gall, and L. Van Gool, \u201cA Hough transform-based voting framework for action recognition,\u201d in Proc. 23rd IEEE Conf.Comput. Vis. Pattern Recognit., San Francisco, CA, USA, Jun. 2010,pp. 2061\u20132068.[24] T. Xia, D. Tao, T. Mei, and Y. Zhang, \u201cMultiview spectral embedding,\u201d IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 40, no. 6,pp. 1438\u20131446, Dec. 2010.\fSHAO et al.: TRANSFER LEARNING FOR VISUAL CATEGORIZATION[25] H. Wang, F. Nie, H. Huang, and C. Ding, \u201cDyadic transfer learningfor cross-domain image classification,\u201d in Proc. 13th IEEE Int. Conf.Comput. Vis., Barcelona, Spain, Nov. 2011, pp. 551\u2013556.[26] T. Li and C. Ding, \u201cThe relationships among various nonnegative matrixfactorization methods for clustering,\u201d in Proc. 6th IEEE Int. Conf. DataMining, Hong Kong, Dec. 2006, pp. 362\u2013371.[27] C. Ding, T. Li, W. Peng, and H. Park, \u201cOrthogonal nonnegative matrixt-factorizations for clustering,\u201d in Proc. 12th ACM Int. Conf. Knowl. Discovery Data Mining, Philadelphia, PA, USA, Aug. 2006, pp. 126\u2013135.[28] S. J. Pan, J. T. Kwok, and Q. Yang, \u201cTransfer learning via dimensionalityreduction,\u201d in Proc. 23rd Nat. Conf. Artif. Intell. (AAAI), Chicago, IL,USA, Jul. 2008, pp. 677\u2013682.[29] M. E. Taylor and P. Stone, \u201cTransfer learning for reinforcement learningdomains: A survey,\u201d J. Mach. Learn. Res., vol. 10, no. 1, pp. 1633\u20131685,2009.[30] I. Jhuo, D. Liu, D. Lee, and S. Chang, \u201cRobust visual domain adaptationwith low-rank reconstruction,\u201d in Proc. 25th IEEE Conf. Comput. Vis.Pattern Recognit., Providence, RI, USA, Jun. 2012, pp. 2168\u20132175.[31] K. Borgwardt, A. Gretton, M. Rasch, H. Kriegel, B. Sch\u00f6lkopf, andA. Smola, \u201cIntegrating structured biological data by kernel maximummean discrepancy,\u201d Bioinformatics, vol. 22, no. 14, pp. e49\u2013e57, 2006.[32] H. Daum\u00e9, \u201cFrustratingly easy domain adaptation,\u201d in Proc. 45th Meeting Assoc. Comput. Linguist., Prague, Czech Republic, Jun. 2007.[33] X. Zhou, X. Zhuang, S. Yan, S.-F. Chang, M. Hasegawa-Johnson, andT. S. Huang, \u201cSIFT-bag kernel for video event analysis,\u201d in Proc.16th ACM Int. Conf. Multimedia, Vancouver, BC, Canada, Oct. 2008,pp. 229\u2013238.[34] V. W. Zheng, D. H. Hu, and Q. Yang, \u201cCross-domain activity recognition,\u201d in Proc. 11th Int. Conf. Ubiquitous Comput., Orlando, FL, USA,Jun. 2009, pp. 61\u201370.[35] R. Yan, L. Shao, and Y. Liu, \u201cNonlocal hierarchical dictionary learningusing wavelets for image denoising,\u201d IEEE Trans. Image Process.,vol. 22, no. 12, pp. 4689\u20134698, Dec. 2013.[36] L. Shao, R. Yan, X. Li, and Y. Liu, \u201cFrom heuristic optimizationto dictionary learning: A review and comprehensive comparison ofimage denoising algorithms,\u201d IEEE Trans. Cybern., vol. 44, no. 7,pp. 1001\u20131013, Jul. 2014.[37] J. Tang, L. Shao, and X. Li, \u201cEfficient dictionary learning for visualcategorization,\u201d Comput. Vis. Image Understand., vol. 124, no. 1,pp. 91\u201398, 2014.[38] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng, \u201cSelf-taughtlearning: Transfer learning from unlabeled data,\u201d in Proc. 24th Int. Conf.Mach. Learn., Corvallis, OR, USA, Jun. 2007, pp. 759\u2013766.[39] F. Zhu and L. Shao, \u201cWeakly-supervised cross-domain dictionary learning for visual recognition,\u201d Int. J. Comput. Vis., vol. 109, nos. 1\u20132,pp. 42\u201359, 2014.[40] J. Blitzer, R. McDonald, and F. Pereira, \u201cDomain adaptation withstructural correspondence learning,\u201d in Proc. Conf. Empirical MethodsNatural Lang. Process., Sydney, Australia, Jul. 2006, pp. 120\u2013128.[41] B. Gong, Y. Shi, F. Sha, and K. Grauman, \u201cGeodesic flow kernel forunsupervised domain adaptation,\u201d in Proc. 25th IEEE Conf. Comput.Vis. Pattern Recognit., Providence, RI, USA, Jun. 2012, pp. 2066\u20132073.[42] J. Yang, K. Yu, Y. Gong, and T. Huang, \u201cLinear spatial pyramidmatching using sparse coding for image classification,\u201d in Proc. 25thIEEE Conf. Comput. Vis. Pattern Recognit., Miami, FL, USA, Jun. 2009,pp. 1794\u20131801.[43] S. Wold, K. Esbensen, and P. Geladi, \u201cPrincipal component analysis,\u201dChemometrics Intell. Lab. Syst., vol. 2, no. 1, pp. 37\u201352, 1987.[44] P. O. Hoyer, \u201cNon-negative sparse coding,\u201d in Proc. 12th IEEE WorkshopNeural Netw. Signal Process., Miami, FL, USA, Jun. 2002, pp. 557\u2013565.[45] D. Weinland, R. Ronfard, and E. Boyer, \u201cFree viewpoint action recognition using motion history volumes,\u201d Comput. Vis. Image Understand.,vol. 104, nos. 2\u20133, pp. 249\u2013257, 2006.[46] T. J. Darrell, I. A. Essa, and A. P. Pentland, \u201cTask-specific gestureanalysis in real-time using interpolated views,\u201d IEEE Trans. PatternAnal. Mach. Intell., vol. 18, no. 12, pp. 1236\u20131242, Dec. 1996.[47] D. M. Gavrila and L. S. Davis, \u201c3-D model-based tracking of humansin action: A multi-view approach,\u201d in Proc. 9th IEEE Conf. Comput.Vis. Pattern Recognit., San Francisco, CA, USA, Jun. 1996, pp. 73\u201380.[48] F. Lv and R. Nevatia, \u201cSingle view human action recognition using keypose matching and Viterbi path searching,\u201d in Proc. 20th IEEE Conf.Comput. Vis. Pattern Recognit., Minneapolis, MN, USA, Jun. 2007,pp. 1\u20138.[49] D. Weinland, E. Boyer, and R. Ronfard, \u201cAction recognition fromarbitrary views using 3D exemplars,\u201d in Proc. 11th Int. Conf. Comput.Vis., Rio de Janeiro, Brazil, Oct. 2007, pp. 1\u20138.1033[50] C. Rao, A. Yilmaz, and M. Shah, \u201cView-invariant representation andrecognition of actions,\u201d Int. J. Comput. Vis., vol. 50, no. 2, pp. 203\u2013226,2002.[51] V. Parameswaran and R. Chellappa, \u201cView invariance for human actionrecognition,\u201d Int. J. Comput. Vis., vol. 66, no. 1, pp. 83\u2013101, 2006.[52] T. Syeda-Mahmood, A. Vasilescu, and S. Sethi, \u201cRecognizing actionevents from multiple viewpoints,\u201d in Proc. Workshop Detect. Recognit.Events Video, Vancouver, BC, Canada, May 2001, pp. 64\u201372.[53] A. Yilmaz and M. Shah, \u201cActions sketch: A novel action representation,\u201din Proc. 18th IEEE Conf. Comput. Vis. Pattern Recognit., San Diego,CA, USA, Jun. 2005, pp. 984\u2013989.[54] A. Gritai, Y. Sheikh, and M. Shah, \u201cOn the use of anthropometry in theinvariant analysis of human actions,\u201d in Proc. 17th Int. Conf. PatternRecognit., Cambridge, U.K., Aug. 2004, pp. 923\u2013926.[55] I. Junejo, E. Dexter, I. Laptev, and P. P\u00e9rez, \u201cCross-view action recognition from temporal self-similarities,\u201d in Proc. 10th Eur. Conf. Comput.Vis., Marseille, France, Oct. 2008, pp. 293\u2013306.[56] M. Blank, L. Gorelick, E. Shechtman, M. Irani, and R. Basri, \u201cActions asspace-time shapes,\u201d in Proc. 10th IEEE Int. Conf. Comput. Vis., Beijing,China, Oct. 2005, pp. 1395\u20131402.[57] S. Seitz and C. Dyer, \u201cView-invariant analysis of cyclic motion,\u201d Int. J.Comput. Vis., vol. 25, no. 3, pp. 231\u2013251, 1997.[58] R. Li and T. Zickler, \u201cDiscriminative virtual views for cross-view actionrecognition,\u201d in Proc. 25th IEEE Conf. Comput. Vis. Pattern Recognit.,Providence, RI, USA, Jun. 2012, pp. 2855\u20132862.[59] J. Zheng, Z. Jiang, P. Phillips, and R. Chellappa, \u201cCross-view actionrecognition via a transferable dictionary pair,\u201d in Proc. 23rd BritishMach. Vis. Conf., Surrey, U.K., Sep. 2012.[60] F. Zhu and L. Shao, \u201cCorrespondence-free dictionary learning for crossview action recognition,\u201d in Proc. 22nd Int. Conf. Pattern Recognit.,Stockholm, Sweden, Aug. 2014.[61] A. Quattoni, M. Collins, and T. Darrell, \u201cTransfer learning for imageclassification with sparse prototype representations,\u201d in Proc. 21st IEEEConf. Comput. Vis. Pattern Recognit., Anchorage, AK, USA, Jun. 2008,pp. 1\u20138.[62] A. Farhadi and M. Tabrizi, \u201cLearning to recognize activities from thewrong view point,\u201d in Proc. 10th Eur. Conf. Comput. Vis., Marseille,France, Oct. 2008, pp. 154\u2013166.[63] Y. Aytar and A. Zisserman, \u201cTabula rasa: Model transfer for object category detection,\u201d in Proc. 13th IEEE Int. Conf. Comput. Vis., Barcelona,Spain, Nov. 2011, pp. 2252\u20132259.[64] N. Dalal and B. Triggs, \u201cHistograms of oriented gradients for humandetection,\u201d in Proc. 21st IEEE Conf. Comput. Vis. Pattern Recognit.,San Diego, CA, USA, Jun. 2005, pp. 886\u2013893.[65] D. Lowe, \u201cDistinctive image features from scale-invariant keypoints,\u201dInt. J. Comput. Vis., vol. 60, no. 2, pp. 91\u2013110, 2004.[66] T. Tommasi, F. Orabona, and B. Caputo, \u201cSafety in numbers: Learningcategories from few examples with multi model knowledge transfer,\u201d inProc. 23rd IEEE Conf. Comput. Vis. Pattern Recognit., San Francisco,CA, USA, Jun. 2010, pp. 3081\u20133088.[67] C. Cawley, \u201cLeave-one-out cross-validation based model selection criteria for weighted LS-SVMs,\u201d in Proc. IEEE Int. Joint Conf. NeuralNetw., San Diego, CA, USA, Jul. 2006, pp. 1661\u20131668.[68] G. R. G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, andM. I. Jordan, \u201cLearning the kernel matrix with semidefinite programming,\u201d J. Mach. Learn. Res., vol. 5, pp. 27\u201372, Dec. 2004.[69] A. Rakotomamonjy, F. R. Bach, S. Canu, and Y. Grandvalet,\u201cSimpleMKL,\u201d J. Mach. Learn. Res., vol. 9, no. 11, pp. 2491\u20132521,2008.[70] S. Sonnenburg, G. R\u00e4tsch, C. Sch\u00e4fer, and B. Sch\u00f6lkopf, \u201cLargescale multiple kernel learning,\u201d J. Mach. Learn. Res., vol. 7, no. 6,pp. 1531\u20131565, 2006.[71] L. Duan, I. Tsang, and D. Xu, \u201cDomain transfer multiple kernellearning,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 3,pp. 465\u2013479, Mar. 2012.[72] L. Duan, I. Tsang, D. Xu, and S. Maybank, \u201cDomain transfer SVMfor video concept detection,\u201d in Proc. 22nd IEEE Conf. Comput. Vis.Pattern Recognit., Miami, FL, USA, Jun. 2009, pp. 1375\u20131381.[73] B. Sch\u00f6lkopf et al., \u201cCorrecting sample selection bias by unlabeleddata,\u201d in Proc. 20th Conf. Neural Inform. Process. Syst., Dec. 2006,pp. 601\u2013608.[74] Y. Freund and R. E. Schapire, \u201cA decision-theoretic generalization ofon-line learning and an application to boosting,\u201d J. Comput. Syst. Sci.,vol. 55, no. 1, pp. 119\u2013139, 1997.[75] L. Fei-Fei, R. Fergus, and P. Perona, \u201cOne-shot learning of objectcategories,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 28, no. 4,pp. 594\u2013611, Apr. 2006.\f1034IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 5, MAY 2015[76] X. Yu and Y. Aloimonos, \u201cAttribute-based transfer learning for objectcategorization with zero/one training example,\u201d in Proc. 11th Eur. Conf.Comput. Vis. (ECCV), Hersonissos, Greece, Sep. 2010, pp. 127\u2013140.[77] M. Rosen-Zvi, C. Chemudugunta, T. Griffiths, P. Smyth, andM. Steyvers, \u201cLearning author-topic models from text corpora,\u201d ACMTrans. Inform. Syst., vol. 28, no. 1, pp. 1\u201338, 2010.[78] Z. Deng, Y. Jiang, K.-S. Choi, F.-L. Chung, and S. Wang, \u201cKnowledgeleverage-based TSK fuzzy system modeling,\u201d IEEE Trans. Neural Netw.Learn. Syst., vol. 24, no. 8, pp. 1200\u20131212, Aug. 2013.[79] Z. Deng, Y. Jiang, F.-L. Chung, H. Ishibuchi, and S. Wang, \u201cKnowledgeleverage-based fuzzy system and its modeling,\u201d IEEE Trans. Fuzzy Syst.,vol. 21, no. 4, pp. 597\u2013609, Aug. 2013.[80] L. Duan, D. Xu, and S.-F. Chang, \u201cExploiting web images for eventrecognition in consumer videos: A multiple source domain adaptationapproach,\u201d in Proc. 25th IEEE Conf. Comput. Vis. Pattern Recognit.,Providence, RI, USA, Jun. 2012, pp. 1338\u20131345.[81] Y. Yao and G. Doretto, \u201cBoosting for transfer learning with multiplesources,\u201d in Proc. 23rd IEEE Conf. Comput. Vis. Pattern Recognit.,San Francisco, CA, USA, Jun. 2010, pp. 1855\u20131862.[82] L. Duan, D. Xu, I. Tsang, and J. Luo, \u201cVisual event recognition in videosby learning from web data,\u201d IEEE Trans. Pattern Anal. Mach. Intell.,vol. 34, no. 9, pp. 1667\u20131680, Sep. 2012.[83] L. Jie, T. Tommasi, and B. Caputo, \u201cMulticlass transfer learning fromunconstrained priors,\u201d in Proc. 13th IEEE Int. Conf. Comput. Vis.,Barcelona, Spain, Nov. 2011, pp. 1863\u20131870.[84] J. Ye and T. Xiong, \u201cSVM versus least squares SVM,\u201d in Proc. 7th Int.Conf. Artif. Intell. Stat., Scottsdale, AZ, USA, Apr. 2007, pp. 644\u2013651.[85] H. Trevor, T. Robert, and H. Friedman, The Elements of StatisticalLearning. New York, NY, USA: Springer-Verlag, 2001.[86] E. Olivas, M. Guerrero, M. B. M. Sober, and S. Lopez, Handbook ofResearch on Machine Learning Applications and Trends: Algorithms,Methods and Techniques, vol. 2. Hershey, PA, USA: Information ScienceIGI Publishing, 2009.[87] A. Farhadi, M. Tabrizi, I. Endres, and D. Forsyth, \u201cA latent modelof discriminative aspect,\u201d in Proc. IEEE 12th Int. Conf. Comput. Vis.,Kyoto, Japan, Sep. 2009, pp. 948\u2013955.[88] A. Bergamo and L. Torresani, \u201cExploiting weakly-labeled web imagesto improve object classification: A domain adaptation approach,\u201d inProc. 24th Conf. Neural Inform. Process. Syst., Trento, Italy, Apr. 2010,pp. 29\u201337.[89] (2007). The PASCAL Visual Object Classes Challenge 2007 (VOC2007)Results [Online]. Available: https://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html[90] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre, \u201cHMDB:A large video database for human motion recognition,\u201d in Proc.13th IEEE Int. Conf. Comput. Vis., Barcelona, Spain, Nov. 2011,pp. 2556\u20132563.[91] H. Wang, A. Klaser, C. Schmid, and C. L. Liu, \u201cAction recognitionby dense trajectories,\u201d in Proc. 24th IEEE Conf. Comput. Vis. PatternRecognit., Colorado Springs, CO, USA, Jun. 2011, pp. 3169\u20133176.[92] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld, \u201cLearningrealistic human actions from movies,\u201d in Proc. 21st IEEE Conf. Comput.Vis. Pattern Recognit., Anchorage, AK, USA, Jun. 2008, pp. 1\u20138.[93] N. Dalal, B. Triggs, and C. Schmid, \u201cHuman detection using orientedhistograms of flow and appearance,\u201d in Proc. 9th Eur. Conf. Comput.Vis., Graz, Austria, May 2006, pp. 428\u2013441.[94] J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong, \u201cLocalityconstrained linear coding for image classification,\u201d in Proc. 23rdIEEE Conf. Comput. Vis. Pattern Recognit., San Francisco, CA, USA,Jun. 2010, pp. 3360\u20133367.[95] M. Elad and M. Aharon, \u201cImage denoising via sparse and redundantrepresentations over learned dictionaries,\u201d IEEE Trans. Image Process.,vol. 15, no. 12, pp. 3736\u20133745, Dec. 2006.[96] T. Chua, J. Tang, R. Hong, H. Li, L. Zhiping, and Y. Zheng,\u201cNUS-WIDE: A real-world web image database from NationalUniversity of Singapore,\u201d in Proc. ACM Int. Conf. Image Video Retrieval,Santorini, Greece, Jul. 2009, pp. 48\u201356.[97] Y.-G. Jiang, G. Ye, S.-F. Chang, D. Ellis, and A. C. Loui, \u201cConsumervideo understanding: A benchmark database and an evaluation of humanand machine performance,\u201d in Proc. 1st ACM Int. Conf. MultimediaRetrieval, Trento, Italy, Apr. 2011, pp. 29\u201337.Ling Shao (M\u201909\u2013SM\u201910) received the B.Eng.degree from the University of Science and Technology of China, Hefei, China, and the M.Sc. and Ph.D.degrees from the University of Oxford, Oxford,U.K.He is a Senior Lecturer (Associate Professor)with the Department of Electronic and ElectricalEngineering, University of Sheffield, Sheffield, U.K.,and a Guest Professor with the College of Electronicand Information Engineering, Nanjing Universityof Information Science and Technology, Nanjing,China. He has authored and co-authored over 120 papers in well-knownjournals/conferences such as International Journal of Computer Vision, theIEEE T RANSACTIONS ON I MAGE P ROCESSING, the IEEE T RANSACTIONSON N EURAL N ETWORKS AND L EARNING S YSTEMS , the IEEE T RANSAC TIONS ON C IRCUITS AND S YSTEMS FOR V IDEO T ECHNOLOGY , the IEEET RANSACTIONS ON C YBERNETICS , Pattern Recognition, Computer Visionand Image Understanding, the IEEE Conference on Computer Vision and Pattern Recognition, the International Joint Conference on Artificial Intelligence,ACM Multimedia, and the British Machine Vision Conference, and holds morethan 10 European/U.S. patents. His current research interests include computervision, image/video processing, pattern recognition, and machine learning.Dr. Shao is an Associate Editor of the IEEE T RANSACTIONS ON C YBER NETICS , Information Sciences, and several other journals. He is a fellow ofthe British Computer Society.Fan Zhu (S\u201912) received the B.S. degree fromthe Wuhan Institute of Technology, Wuhan, China,in 2010, and the M.Sc. (Hons.) degree from theUniversity of Sheffield, Sheffield, U.K., in 2012,where he is currently pursuing the Ph.D. degreewith the Department of Electronic and ElectricalEngineering.His current research interests include submodularoptimization for computer vision, sparse coding, anddictionary learning and transfer learning.Xuelong Li (M\u201902\u2013SM\u201907\u2013F\u201912) is currently a Full Professor with theCenter for OPTical IMagery Analysis and Learning, State Key Laboratoryof Transient Optics and Photonics, Xi\u2019an Institute of Optics and PrecisionMechanics, Chinese Academy of Sciences, Xi\u2019an, China.\f", "2015 IEEE International Conference on Computer VisionCompression Artifacts Reduction by a Deep Convolutional NetworkChao Dong, Yubin Deng, Chen Change Loy, and Xiaoou TangDepartment of Information Engineering, The Chinese University of Hong Kong{dc012,dy015,ccloy,xtang}@ie.cuhk.edu.comAbstractLossy compression introduces complex compression artifacts, particularly the blocking artifacts, ringing effectsand blurring. Existing algorithms either focus on removingblocking artifacts and produce blurred output, or restoressharpened images that are accompanied with ringing effects. Inspired by the deep convolutional networks (DCN)on super-resolution [5], we formulate a compact and ef\ufb01cient network for seamless attenuation of different compression artifacts. We also demonstrate that a deeper model canbe effectively trained with the features learned in a shallow network. Following a similar \u201ceasy to hard\u201d idea, wesystematically investigate several practical transfer settingsand show the effectiveness of transfer learning in low-levelvision problems. Our method shows superior performancethan the state-of-the-arts both on the benchmark datasetsand the real-world use case (i.e. Twitter).(a) Left: the JPEG-compressed image, where we could see blocking artifacts, ringing effects and blurring on the eyes, abrupt intensity changes onthe face. Right: the restored image by the proposed deep model (AR-CNN),where we remove these compression artifacts and produce sharp details.1. Introduction(b) Left: the Twitter-compressed image, which is \ufb01rst re-scaled to a smallimage and then compressed on the server-side. Right: the restored image bythe proposed deep model (AR-CNN)Lossy compression (e.g. JPEG, WebP and HEVC-MSP)is one class of data encoding methods that uses inexactapproximations for representing the encoded content. Inthis age of information explosion, lossy compression isindispensable and inevitable for companies (e.g. Twitterand Facebook) to save bandwidth and storage space. However, compression in its nature will introduce undesiredcomplex artifacts, which will severely reduce the user experience (e.g. Figure 1). All these artifacts not only decrease perceptual visual quality, but also adversely affectvarious low-level image processing routines that take compressed images as input, e.g. contrast enhancement [16],super-resolution [30, 5], and edge detection [3]. However,under such a huge demand, effective compression artifactsreduction remains an open problem.We take JPEG compression as an example to explaincompression artifacts. JPEG compression scheme dividesan image into 8\u00d78 pixel blocks and applies block discretecosine transformation (DCT) on each block individually.Quantization is then applied on the DCT coef\ufb01cients to1550-5499/15 $31.00 \u00a9 2015 IEEEDOI 10.1109/ICCV.2015.73Figure 1. Example compressed images and our restoration resultson the JPEG compression scheme and the real use case \u2013 Twitter.save storage space. This step will cause a complex combination of different artifacts, as depicted in Figure 1(a).Blocking artifacts arise when each block is encoded without considering the correlation with the adjacent blocks, resulting in discontinuities at the 8\u00d78 borders. Ringing effects along the edges occur due to the coarse quantizationof the high-frequency components (also known as Gibbsphenomenon [9]). Blurring happens due to the loss ofhigh-frequency components. To cope with the various compression artifacts, different approaches have been proposed,some of which can only deal with certain types of artifacts.For instance, deblocking oriented approaches [18, 21, 26]perform \ufb01ltering along the block boundaries to reduce onlyblocking artifacts. Liew et al. [17] and Foi et al. [6]use thresholding by wavelet transform and Shape-AdaptiveDCT transform, respectively. These approaches are good at576\fremoving blocking and ringing artifacts, but tend to produceblurred output. Jung et al. [13] propose restoration methodbased on sparse representation. They produce sharpenedimages but accompanied with noisy edges and unnaturalsmooth regions.To date, deep learning has shown impressive results onboth high-level and low-level vision problems . In particular, the SRCNN proposed by Dong et al. [5] shows the greatpotential of an end-to-end DCN in image super-resolution.The study also points out that conventional sparse-codingbased image restoration model can be equally seen as a deepmodel. However, we \ufb01nd that the three-layer network is notwell suited in restoring the compressed images, especiallyin dealing with blocking artifacts and handling smooth regions. As various artifacts are coupled together, features extracted by the \ufb01rst layer is noisy, causing undesirable noisypatterns in reconstruction.To eliminate the undesired artifacts, we improve the SRCNN by embedding one or more \u201cfeature enhancement\u201dlayers after the \ufb01rst layer to clean the noisy features. Experiments show that the improved model, namely \u201cArtifacts Reduction Convolutional Neural Networks (AR-CNN)\u201d, is exceptionally effective in suppressing blocking artifacts whileretaining edge patterns and sharp details (see Figure 1).However, we are met with training dif\ufb01culties in traininga deeper DCN. \u201cDeeper is better\u201d is widely observed inhigh-level vision problems, but not in low-level vision tasks.Speci\ufb01cally, \u201cdeeper is not better\u201d has been pointed out insuper-resolution [4], where training a \ufb01ve-layer network becomes a bottleneck. The dif\ufb01culty of training is partiallydue to the sub-optimal initialization settings.The aforementioned dif\ufb01culty motivates us to investigatea better way to train a deeper model for low-level visionproblems. We \ufb01nd that this can be effectively solved bytransferring the features learned in a shallow network toa deeper one and \ufb01ne-tuning simultaneously1 . This strategy has also been proven successful in learning a deeperCNN for image classi\ufb01cation [24]. Following a similar general intuitive idea, easy to hard, we discover other interesting transfer settings in this low-level vision task: (1) Wetransfer the features learned in a high-quality compressionmodel (easier) to a low-quality one (harder), and \ufb01nd thatit converges faster than random initialization. (2) In thereal use case, companies tend to apply different compression strategies (including re-scaling) according to their purposes (e.g. Figure 1(b)). We transfer the features learnedin a standard compression model (easier) to a real use case(harder), and \ufb01nd that it performs better than learning fromscratch.The contributions of this study are two-fold: (1) Weformulate a new deep convolutional network for ef\ufb01cientreduction of various compression artifacts. Extensive experiments, including that on real use cases, demonstratethe effectiveness of our method over state-of-the-art methods [6, 12] both perceptually and quantitatively. (2) We verify that reusing the features in shallow networks is helpfulin learning a deeper model for compression artifact reduction. Under the same intuitive idea \u2013 easy to hard, we reveala number of interesting and practical transfer settings. Ourstudy is the \ufb01rst attempt to show the effectiveness of featuretransfer in a low-level vision problem.2. Related workExisting algorithms can be classi\ufb01ed into deblocking oriented and restoration oriented methods. The deblockingoriented methods focus on removing blocking and ringing artifacts. In the spatial domain, different kinds of \ufb01lters [18, 21, 26] have been proposed to adaptively deal withblocking artifacts in speci\ufb01c regions (e.g., edge, texture,and smooth regions). In the frequency domain, Liew etal. [17] utilize wavelet transform and derive thresholds atdifferent wavelet scales for denoising. The most successful deblocking oriented method is perhaps the PointwiseShape-Adaptive DCT (SA-DCT) [6], which is widely acknowledged as the state-of-the-art approach [12, 16]. However, as most deblocking oriented methods, SA-DCT couldnot reproduce sharp edges, and tend to overly smooth texture regions. The restoration oriented methods regard thecompression operation as distortion and propose restorationalgorithms. They include projection on convex sets basedmethod (POCS) [32], solving an MAP problem (FoE) [25],sparse-coding-based method [13] and the Regression TreeFields based method (RTF) [12], which is the new state-ofthe art method. The RTF takes the results of SA-DCT [6] asbases and produces globally consistent image reconstructions with a regression tree \ufb01eld model. It could also beoptimized for any differentiable loss functions (e.g. SSIM),but often at the cost of other evaluation metrics.Super-Resolution Convolutional Neural Network (SRCNN) [5] is closely related to our work. In the study, independent steps in the sparse-coding-based method are formulated as different convolutional layers and optimized ina uni\ufb01ed network. It shows the potential of deep model inlow-level vision problems like super-resolution. However,the model of compression is different from super-resolutionin that it consists of different kinds of artifacts. Designinga deep model for compression restoration requires a deepunderstanding into the different artifacts. We show that directly applying the SRCNN architecture for compressionrestoration will result in undesired noisy patterns in the reconstructed image.Transfer learning in deep neural networks becomes pop-1 Generally, the transfer learning method will train a base network \ufb01rst,and copy the learned parameters or features of several layers to the corresponding layers of a target network. These transferred layers can be leftfrozen or \ufb01ne-tuned to the target dataset. The remaining layers are randomly initialized and trained to the target task.577\f\u201cnoisy\u201d feature maps\u201ccleaner\u201d feature maps\u201crestored\u201d feature mapsCompressed image(Input)Reconstructed image(Output)Feature extractionFeature enhancementMappingReconstructionFigure 2. The framework of the Artifacts Reduction Convolutional Neural Network (AR-CNN). The network consists of four convolutionallayers, each of which is responsible for a speci\ufb01c operation. Then it optimizes the four operations (i.e., feature extraction, feature enhancement, mapping and reconstruction) jointly in an end-to-end framework. Example feature maps shown in each step could well illustrate thefunctionality of each operation. They are normalized for better visualization.ular since the success of deep learning in image classi\ufb01cation [15]. The features learned from the ImageNet showgood generalization ability [35] and become a powerfultool for several high-level vision problems, such as PascalVOC image classi\ufb01cation [20] and object detection [7, 22].Yosinski et al. [34] have also tried to quantify the degreeto which a particular layer is general or speci\ufb01c. Overall, transfer learning has been systematically investigatedin high-level vision problems, but not in low-level visiontasks. In this study, we explore several transfer settings oncompression artifacts reduction and show the effectivenessof transfer learning in low-level vision problems.the \ufb01nal output. The network can be expressed as:Fi (Y) = max (0, Wi \u2217 Y + Bi ) , i \u2208 {1, 2};F (Y) = W3 \u2217 F2 (Y) + B3 .(1)(2)where Wi and Bi represent the \ufb01lters and biases of the ithlayer respectively, Fi is the output feature maps and \u2019\u2217\u2019 denotes the convolution operation. The Wi contains ni \ufb01ltersof support ni\u22121 \u00d7 fi \u00d7 fi , where fi is the spatial support ofa \ufb01lter, ni is the number of \ufb01lters, and n0 is the number ofchannels in the input image. Note that there is no pooling orfull-connected layers in SRCNN, so the \ufb01nal output F (Y)is of the same size as the input image. Recti\ufb01ed Linear Unit(ReLU, max(0, x)) [19] is applied on the \ufb01lter responses.These three steps are analogous to the basic operationsin the sparse-coding-based super-resolution methods [31],and this close relationship lays theoretical foundation for itssuccessful application in super-resolution. Details can befound in the paper [5].3. MethodologyOur proposed approach is based on the current successful low-level vision model \u2013 SRCNN [5]. To have a betterunderstanding of our work, we \ufb01rst give a brief overview ofSRCNN. Then we explain the insights that lead to a deepernetwork and present our new model. Subsequently, we explore three types of transfer learning strategies that help intraining a deeper and better network.3.2. Convolutional Neural Network for Compression Artifacts ReductionInsights. In sparse-coding-based methods and SRCNN,the \ufb01rst step \u2013 feature extraction \u2013 determines what shouldbe emphasized and restored in the following stages. However, as various compression artifacts are coupled together,the extracted features are usually noisy and ambiguous foraccurate mapping. In the experiments of reducing JPEGcompression artifacts (see Section 4.1.2), we \ufb01nd that somequantization noises coupled with high frequency detailsare further enhanced, bringing unexpected noisy patternsaround sharp edges. Moreover, blocking artifacts in \ufb02atareas are misrecognized as normal edges, causing abruptintensity changes in smooth regions. Inspired by the feature enhancement step in super-resolution [29], we introduce a feature enhancement layer after the feature extraction layer in SRCNN to form a new and deeper network3.1. Review of SRCNNThe SRCNN aims at learning an end-to-end mapping,which takes the low-resolution image Y (after interpolation) as input and directly outputs the high-resolution oneF (Y). The network contains three convolutional layers,each of which is responsible for a speci\ufb01c task. Speci\ufb01cally, the \ufb01rst layer performs patch extraction and representation, which extracts overlapping patches from the input image and represents each patch as a high-dimensionalvector. Then the non-linear mapping layer maps eachhigh-dimensional vector of the \ufb01rst layer to another highdimensional vector, which is conceptually the representation of a high-resolution patch. At last, the reconstructionlayer aggregates the patch-wise representations to generate578\f\u2013 AR-CNN. This layer maps the \u201cnoisy\u201d features to a relatively \u201ccleaner\u201d feature space, which is equivalent to denoising the feature maps.Formulation. The overview of the new network ARCNN is shown in Figure 2. The three layers of SRCNNremain unchanged in the new model. We also use the sameannotations as in Section 3.1. To conduct feature enhancement, we extract new features from the n1 feature maps ofthe \ufb01rst layer, and combine them to form another set of feature maps. This operation F1\u0002 can also be formulated as aconvolutional layer:F1\u0002 (Y) = max (0, W1\u0002 \u2217 F1 (Y) + B1\u0002 ) ,\u0739\u0bba\u0b35\u11f2\u0739\u0bba\u0b36\u0739\u0bba\u0b37input\u0739\u0bba\u0b35\u0739\u0bba\u0b35\u11f2input\u0739\u0bba\u0b35outputinput\u0739\u0bba\u0b35outputoutputoutputtarget\u202b\u0724\u202c\u0b36data\u202b\u0723\u202c-\u202b\u0724\u074d\u202ctarget\u202b\u0724\u202c\u0b37T\u202b\u074e\u0741\u0750\u0750\u0745\u0753\u202c(3)Figure 3. Easy-hard transfer settings. First row: The baseline 4layer network trained with dataA-qA. Second row: The 5-layerAR-CNN targeted at dataA-qA. Third row: The AR-CNN targetedat dataA-qB. Fourth row: The AR-CNN targeted at Twitter data.Green boxes indicate the transferred features from the base network, and gray boxes represent random initialization. The ellipsoidal bars between weight vectors represent the activation functions.strategies (i.e. randomly drawn from Gaussian distributionswith \ufb01xed standard deviations [15]) are found not suitablefor training a very deep model, as reported in [10]. To address this issue, He et al. [10] derive a robust initializationmethod for recti\ufb01er nonlinearities, Simonyan et al. [24] propose to use the pre-trained features on a shallow network forinitialization.In low-level vision problems (e.g. super resolution), it isobserved that training a network beyond 4 layers would encounter the problem of convergence, even that a large number of training images (e.g. ImageNet) are provided [5]. Weare also met with this dif\ufb01culty during the training processof AR-CNN. To this end, we systematically investigate several transfer settings in training a low-level vision networkfollowing an intuitive idea of \u201ceasy-hard transfer\u201d. Speci\ufb01cally, we attempt to reuse the features learned in a relativelyeasier task to initialize a deeper or harder network. Interestingly, the concept \u201ceasy-hard transfer\u201d has already beenpointed out in neuro-computation study [8], where the priortraining on an easy discrimination can help learn a secondharder one.Formally, we de\ufb01ne the base (or source) task as A and thetarget tasks as Bi , i \u2208 {1, 2, 3}. As shown in Figure 3, thebase network baseA is a four-layer AR-CNN trained on alarge dataset dataA, of which images are compressed usinga standard compression scheme with the compression quality qA. All layers in baseA are randomly initialized from aGaussian distribution. We will transfer one or two layers ofbaseA to different target tasks (see Figure 3). Such transferscan be described as follows.Transfer shallow to deeper model. As indicated by [4],a \ufb01ve-layer network is sensitive to the initialization parameters and learning rate. Thus we transfer the \ufb01rst two layersof baseA to a \ufb01ve-layer network targetB1 . Then we ran-3.3. Model LearningGiven a set of ground truth images {Xi } and their corresponding compressed images {Yi }, we use Mean SquaredError (MSE) as the loss function:n1\u0002||F (Yi ; \u0398) \u2212 Xi ||2 ,n i=1\u0739\u0bba\u0b35target\u202b\u0724\u202c\u0b35data\u202b\u0723\u202c- \u202b\u0723\u074d\u202cwhere W1\u0002 corresponds to n1\u0002 \ufb01lters with size n1 \u00d7 f1\u0002 \u00d7f1\u0002 . B1\u0002 is an n1\u0002 -dimensional bias vector, and the outputF1\u0002 (Y) consists of n1\u0002 feature maps. Overall, the AR-CNNconsists of four layers, namely the feature extraction, feature enhancement, mapping and reconstruction layer.It is worth noticing that AR-CNN is not equal to a deeperSRCNN that contains more than one non-linear mappinglayers2 . A deeper SRCNN imposes more non-linearity inthe mapping stage, which equals to adopting a more robust regressor between the low-level features and the \ufb01naloutput. Similar ideas have been proposed in some sparsecoding-based methods [14, 2]. However, as the compression artifacts are complex, low-level features extracted by asingle layer are noisy. Thus the performance bottleneck lieson the features but not the regressor. AR-CNN improvesthe mapping accuracy by enhancing the extracted low-levelfeatures, and the \ufb01rst two layers together can be regarded asa better feature extractor. This leads to better performancethan a deeper SRCNN. Experimental results of AR-CNN,SRCNN and deeper SRCNN will be shown in Section 4.1.2.L(\u0398) =inputbase\u202b\u0723\u202cdata\u202b\u0723\u202c- \u202b\u0723\u074d\u202c(4)where \u0398 = {W1 , W1\u0002 , W2 , W3 , B1 , B1\u0002 , B2 , B3 }, n is thenumber of training samples. The loss is minimized usingstochastic gradient descent with the standard backpropagation. We adopt a batch-mode learning method with a batchsize of 128.3.4. Easy-Hard TransferTransfer learning in deep models provides an effectiveway of initialization. In fact, conventional initialization2 Adding non-linear mapping layers has been suggested as an extensionof SRCNN in [5].579\f4. ExperimentsWe use the BSDS500 database [1] as our base trainingset. Speci\ufb01cally, its disjoint training set (200 images) andtest set (200 images) are all used for training, and its validation set (100 images) is used for validation. As in othercompression artifacts reduction methods (e.g. RTF [12]),we apply the standard JPEG compression scheme, and usethe JPEG quality settings q = 40, 30, 20, 10 (from highquality to very low quality) in MATLAB JPEG encoder. Weonly focus on the restoration of the luminance channel (inYCrCb space) in this paper.The training image pairs {Y, X} are prepared as follows\u2013 Images in the training set are decomposed into 32 \u00d7 32sub-images4 X = {Xi }ni=1 . Then the compressed samples Y = {Yi }ni=1 are generated from the training sampleswith MATLAB JPEG encoder [12]. The sub-images are extracted from the ground truth images with a stride of 10.Thus the 400 training images could provide 537,600 training samples. To avoid the border effects caused by convolution, AR-CNN produces a 20 \u00d7 20 output given a 32 \u00d7 32input Yi . Hence, the loss (Eqn. (4)) was computed by comparing against the center 20 \u00d7 20 pixels of the ground truthsub-image Xi . In the training phase, we follow [11, 5] anduse a smaller learning rate (10\u22125 ) in the last layer and acomparably larger one (10\u22124 ) in the remaining layers.(a) High compression quality (quality 20 in Matlab encoder)(b) Low compression quality (quality 10 in Matlab encoder)Figure 4. First layer \ufb01lters of AR-CNN learned under differentJPEG compression qualities.domly initialize its remaining layers3 and train all layers toward the same dataset dataA. This is conceptually similar tothat applied in image classi\ufb01cation [24], but this approachhas never been validated in low-level vision problems.Transfer high to low quality. Images of low compression quality contain more complex artifacts. Here we usethe features learned from high compression quality imagesas a starting point to help learn more complicated features inthe DCN. Speci\ufb01cally, the \ufb01rst layer of targetB2 are copiedfrom baseA and trained on images that are compressed witha lower compression quality qB.Transfer standard to real use case. We then explorewhether the features learned under a standard compressionscheme can be generalized to other real use cases, whichoften contain more complex artifacts due to different levelsof re-scaling and compression. We transfer the \ufb01rst layer ofbaseA to the network targetB3 , and train all layers on thenew dataset.4.1. Comparison with the State-of-the-ArtsWe use the LIVE1 dataset [23] (29 images) as test set toevaluate both the quantitative and qualitative performance.The LIVE1 dataset contains images with diverse properties.It is widely used in image quality assessment [27] as wellas in super-resolution [30]. To have a comprehensive qualitative evaluation, we apply the PSNR, structural similarity(SSIM) [27]5 , and PSNR-B [33] for quality assessment. Wewant to emphasize the use of PSNR-B. It is designed specifically to assess blocky and deblocked images. The networksettings are f1 = 9, f1\u0002 = 7, f2 = 1, f3 = 5, n1 = 64,n1\u0002 = 32, n2 = 16 and n3 = 1, denoted as AR-CNN(9-7-1-5) or simply AR-CNN. A speci\ufb01c network is trainedfor each JPEG quality. Parameters are randomly initializedfrom a Gaussian distribution with a standard deviation of0.001.Discussion. Why the features learned from relativelyeasy tasks are helpful? First, the features from a welltrained network can provide a good starting point. Thenthe rest of a deeper model can be regarded as shallow one,which is easier to converge. Second, features learned in different tasks always have a lot in common. For instance,Figure 3.4 shows the features learned under different JPEGcompression qualities. Obviously, \ufb01lters a, b, c of high quality are very similar to \ufb01lters a\u0002 , b\u0002 , c\u0002 of low quality. Thiskind of features can be reused or improved during \ufb01netuning, making the convergence faster and more stable. Furthermore, a deep network for a hard problem can be seen asan insuf\ufb01ciently biased learner with overly large hypothesisspace to search, and therefore is prone to over\ufb01tting. Thesefew transfer settings we investigate introduce good bias toenable the learner to acquire a concept with greater generality. Experimental results in Section 4.2 validate the aboveanalysis.4.1.1Comparison with SA-DCTWe \ufb01rst compare AR-CNN with SA-DCT [6], which iswidely regarded as the state-of-the-art deblocking orientedmethod [12, 16]. The quantization results of PSNR, SSIM4 We use sub-images because we regard each sample as an image ratherthan a big patch.5 We use the unweighted structural similarity de\ufb01ned over \ufb01xed 8 \u00d7 8windows as in [28].3 Random initialization on remaining layers are also applied similarlyfor tasks B2 , and B3 .580\fTable 1. The average results of PSNR (dB), SSIM, PSNR-B (dB)on the LIVE1 dataset.PSNRSSIMPSNR-BQuality102030401020304010203040JPEG27.7730.0731.4132.350.79050.86830.90000.917325.3327.5728.9229.96SA-DCT28.6530.8132.0832.990.80930.87810.90780.924028.0129.8230.9231.79AR-CNN28.9831.2932.6933.630.82170.88710.91660.930628.7030.7632.1533.12Eval.MatPSNRSSIMPSNR-BAverage test PSNR (dB)Eval. MatTable 3. The average results of PSNR (dB), SSIM, PSNR-B (dB)on the LIVE1 dataset with q = 10 .Table 2. The average results of PSNR (dB), SSIM, PSNR-B (dB)on 5 classical test images [6].Eval. MatPSNRSSIMPSNR-BQuality102030401020304010203040JPEG27.8230.1231.4832.430.78000.85410.88440.901125.2127.5028.9429.92SA-DCT28.8830.9232.1433.000.80710.86630.89140.905528.1629.7530.8331.5927.770.790525.3328.910.817528.52DeeperSRCNN28.920.818928.46AR-CNN28.980.821728.7027.727.6AR\u0002CNNdeeper SRCNNSRCNN27.527.411.522.533.5Number of backprops44.558x 10Figure 5. Comparisons with SRCNN and Deeper SRCNN.AR-CNN29.0431.1632.5233.340.81110.86940.89670.910128.7530.6031.9932.80Table 4. The average results of PSNR (dB), SSIM, PSNR-B (dB)on the test set BSDS500 dataset.Eval.MatPSNRSSIMPSNR-BQualityJPEGRTF10201020102026.6228.800.79040.869023.5425.6227.6629.840.81770.886426.9328.80RTF+SA-DCT27.7129.870.81860.887126.9928.80AR-CNN27.7930.000.82280.889927.3229.15inal SRCNN (9-1-5) with f1 = 9, f3 = 5, n1 = 64 andn2 = 32. (ii) Deeper SRCNN (9-1-1-5) with an additionalnon-linear mapping layer (f2\u0002 = 1, n2\u0002 = 16). They all usethe BSDS500 dataset for training and validation as in Section 4. The compression quality is q = 10. The AR-CNN isthe same as in Section 4.1.1.Quantitative results tested on LIVE1 dataset are shownin Table 3. We could see that the two SRCNN networksare inferior on all evaluation metrics. From convergencecurves shown in Figure 5, it is clear that AR-CNN achieveshigher PSNR from the beginning of the learning stage. Furthermore, from their restored images7 in Figure 11, we \ufb01ndout that the two SRCNN networks all produce images withnoisy edges and unnatural smooth regions. These resultsdemonstrate our statements in Section 3.2. In short, thesuccess of training a deep model needs comprehensive understanding of the problem and careful design of the modelstructure.4.1.3Comparison with SRCNNComparison with RTFRTF [12] is the recent state-of-the-art restoration orientedmethod. Without their deblocking code, we can only compare with the released deblocking results. Their model istrained on the training set (200 images) of the BSDS500dataset, but all images are down-scaled by a factor of0.5 [12]. To have a fair comparison, we also train new ARCNN networks on the same half-sized 200 images. Test-As discussed in Section 3.2, SRCNN is not suitable forcompression artifacts reduction. For comparison, we traintwo SRCNN networks with different settings. (i) The orig6 The 5 test images in [6] are baboon, barbara, boats, lenna and peppers.7 MoreSRCNN27.80.5and PSNR-B are shown in Table 1. On the whole, our ARCNN outperforms the SA-DCT on all JPEG qualities andevaluation metrics by a large margin. Note that the gains onPSNR-B is much larger than that on PSNR. This indicatesthat AR-CNN could produce images with less blocking artifacts. We have also conducted evaluation on 5 classicaltest images used in [6]6 , and observed the same trend. Theresults are shown in Table 2.To compare the visual quality, we present some restoredimages7 with q = 10 in Figure 10. From Figure 10, wecould see that the result of AR-CNN could produce muchsharper edges with much less blocking and ringing artifacts compared with SA-DCT. The visual quality has beenlargely improved on all aspects compared with the state-ofthe-art method. Furthermore, AR-CNN is superior to SADCT on the implementation speed. For SA-DCT, it needs3.4 seconds to process a 256 \u00d7 256 image. While AR-CNNonly takes 0.5 second. They are all implemented using C++on a PC with Intel I3 CPU (3.1GHz) with 16GB RAM.4.1.2JPEGqualitative results are provided in the supplementary \ufb01le.581\fAverage test PSNR (dB)networkstructure9-7-1-59-7-1-59-7-1-59-7-3-1-59-7-3-1-59-7-1-59-7-1-59-7-1-59-7-1-59-7-1-59-7-1-5trainingdatasetBSDS-q10BSDS-q20BSDS-q10BSDS-q10BSDS-q10BSDS-q10BSDS-q10BSDS-q10TwitterTwitterTwitterinitializationstrategyGaussian (0, 0.001)Gaussian (0, 0.001)Gaussian (0, 0.001)1,2 layers of base-q10He et al. [10]Gaussian (0, 0.001)1 layer of base-q201,2 layer of base-q20Gaussian (0, 0.001)1 layer of base-q101 layer of base-q2027.727.6transfer 1 layertransfer 2 layersbase\u0002q1027.511.522.533.5Number of backprops44.558x 10Figure 7. Transfer high to low quality.27.825.22524.8transfer q10transfer q20base\u0002Twitter24.62468Number of backprops10127x 10Figure 8. Transfer standard to real use case.27.727.6transfer deeperHe [9]base\u0002q1027.50.511.522.533.5Number of backprops44.5transferred features from a four-layer network enable us totrain a \ufb01ve-layer network successfully. Note that directlytraining a \ufb01ve-layer network using conventional initialization ways is unreliable. Speci\ufb01cally, we have exhaustivelytried different groups of learning rates, but still have notobserved convergence. Furthermore, the \u201ctransfer deeper\u201dconverges faster and achieves better performance than using He et al.\u2019s method [10], which is also very effective intraining a deep model. We have also conducted comparativeexperiments with the structure \u201c9-7-1-1-5\u201d and observed thesame trend.58x 10Figure 6. Transfer shallow to deeper model.ing is performed on the test set of the BSDS500 dataset(images scaled by a factor of 0.5), which is also consistentwith [12]. We compare with two RTF variants. One is theplain RTF, which uses the \ufb01lter bank and is optimized forPSNR. The other is the RTF+SA-DCT, which includes theSA-DCT as a base method and is optimized for MAE. Thelater one achieves the highest PSNR value among all RTFvariants [12].As shown in Table 4, we obtain superior performancethan the plain RTF, and even better performance than thecombination of RTF and SA-DCT, especially under themore representative PSNR-B metric. Moreover, training onsuch a small dataset has largely restricted the ability of ARCNN. The performance of AR-CNN will further improvegiven more training images.4.2.2Transfer high to low qualityResults are shown in Figure 7. Obviously, the two networkswith transferred features converge faster than that trainingfrom scratch. For example, to reach an average PSNRof 27.77dB, the \u201ctransfer 1 layer\u201d takes only 1.54 \u00d7 108backprops, which are roughly a half of that for \u201cbase-q10\u201d.Moreover, the \u201ctransfer 1 layer\u201d also outperforms the \u2018baseq10\u201d by a slight margin throughout the training phase. Onereason for this is that only initializing the \ufb01rst layer provides the network with more \ufb02exibility in adapting to a newdataset. This also indicates that a good starting point couldhelp train a better network with higher convergence speed.4.2. Experiments on Easy-Hard TransferWe show the experimental results of different \u201ceasy-hardtransfer\u201d settings, of which the details are shown in Table 5.Take the base network as an example, the base-q10 is afour-layer AR-CNN (9-7-1-5) trained on the BSDS500 [1]dataset (400 images) under the compression quality q =10. Parameters are initialized by randomly drawing froma Gaussian distribution with zero mean and standard deviation 0.001. Figures 6 - 8 show the convergence curves onthe validation set.4.2.127.80.5Average test PSNR (dB)shortformbase-q10base-q20base-q10transfer deeperHe [10]base-q10transfer 1 layertransfer 2 layersbase-Twittertransfer q10transfer q20Average test PSNR (dB)Table 5. Experimental settings of \u201ceasy-hard transfer\u201d.transferstrategybasenetworkshallowtodeephightolowstandardtoreal4.2.3Transfer standard to real use case \u2013 TwitterOnline Social Media like Twitter are popular platforms formessage posting. However, Twitter will compress the uploaded images on the server-side. For instance, a typical8 mega-pixel (MP) image (3264 \u00d7 2448) will result in acompressed and re-scaled version with a \ufb01xed resolutionof 600 \u00d7 450. Such re-scaling and compression will introduce very complex artifacts, making restoration dif\ufb01cult forexisting deblocking algorithms (e.g. SA-DCT). However,AR-CNN can \ufb01t to the new data easily. Further, we wantTransfer shallow to deeper modelIn Table 5, we denote a deeper (\ufb01ve-layer) AR-CNN as \u201c97-3-1-5\u201d, which contains another feature enhancement layer(f1\u0002\u0002 = 3 and n1\u0002\u0002 = 16). Results in Figure 6 show that the582\fOriginalPSNR /SSIM /PSNR-BAR-CNNJPEGSA-DCT32.46 dB /0.8558 /29.64 dB 33.88 dB /0.9015 /33.02 dB 34.37 dB /0.9079 /34.10 dBFigure\u000110.\u0001Results\u0001on\u0001image\u0001\u201cparrots\u201d\u0001show\u0001that\u0001AR\u000eCNN\u0001is\u0001better\u0001than\u0001SA-DCT\u0001on\u0001removing\u0001blocking\u0001artifacts.JPEG30.12 dB /0.8817 /26.86 dBSRCNN32.58 dB /0.9298 /31.52 dBDeeper SRCNN32.60 dB /0.9301 /31.47 dBAR-CNN32.88 dB /0.9343 /32.22 dBFigure\u000111.\u0001Results\u0001on\u0001image\u0001\u201cmonarch\u201d\u0001show\u0001that\u0001AR\u000eCNN\u0001is\u0001better\u0001than\u0001SRCNN\u0001on\u0001removing\u0001ringing\u0001effects.Original / PSNRBase-Twitter / 27.75 dBTwitter / 26.55 dBTransfer q10 / 27.92 dBFigure\u000112.\u0001Restoration\u0001results\u0001of\u0001AR-CNN\u0001on\u0001Twitter\u0001compressed\u0001images.\u0001 The\u0001origina\u0001image\u0001(8MP\u0001version)\u0001is\u0001too\u0001large\u0001for\u0001display\u0001and\u0001only\u0001part\u0001of\u0001the\u0001image\u0001is\u0001shown\u0001for\u0001better\u0001visualization.improvements over the compressed version.to show that features learned under standard compressionschemes could also facilitate training on a completely different dataset. We use 40 photos of resolution 3264 \u00d7 2448taken by mobile phones (totally 335,209 training subimages) and their Twitter-compressed version8 to train threenetworks with initialization settings listed in Table 5.From Figure 8, we observe that the \u201ctransfer q10\u201dand \u201ctransfer q20\u201d networks converge much faster thanthe \u201cbase-Twitter\u201d trained from scratch. Speci\ufb01cally, the\u201ctransfer q10\u201d takes 6 \u00d7 107 backprops to achieve 25.1dB,while the \u201cbase-Twitter\u201d uses 10 \u00d7 107 backprops. Despiteof fast convergence, transferred features also lead to higherPSNR values compared with \u201cbase-Twitter\u201d. This observation suggests that features learned under standard compression schemes are also transferrable to tackle real use caseproblems. Some restoration results7 are shown in Figure 12.We could see that both networks achieve satisfactory quality8 We5. ConclusionApplying deep model on low-level vision problems requires deep understanding of the problem itself. In this paper, we carefully study the compression process and propose a four-layer convolutional network, AR-CNN, whichis extremely effective in dealing with various compression artifacts. We further systematically investigate severaleasy-to-hard transfer settings that could facilitate traininga deeper or better network, and verify the effectiveness oftransfer learning in low-level vision problems. As discussedin SRCNN [5], we \ufb01nd that larger \ufb01lter sizes also help improve the performance. We will leave them to further work.will share this dataset on our project page.583\fReferences[20] M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Learning andtransferring mid-level image representations using convolutional neural networks. In CVPR, pages 1717\u20131724. IEEE,2014.[21] H. C. Reeve III and J. S. Lim. Reduction of blocking effects in image coding. Optical Engineering, 23(1):230134\u2013230134, 1984.[22] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, andY. LeCun. Overfeat: Integrated recognition, localization anddetection using convolutional networks. arXiv:1312.6229,2013.[23] H. R. Sheikh, Z. Wang, L. Cormack, and A. C. Bovik. Liveimage quality assessment database release 2, 2005.[24] K. Simonyan and A. Zisserman.Very deep convolutional networks for large-scale image recognition.arXiv:1409.1556, 2014.[25] D. Sun and W.-K. Cham. Postprocessing of low bit-rateblock DCT coded images based on a \ufb01elds of experts prior.TIP, 16(11):2743\u20132751, 2007.[26] C. Wang, J. Zhou, and S. Liu. Adaptive non-local means\ufb01lter for image deblocking. Signal Processing: Image Communication, 28(5):522\u2013530, 2013.[27] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli.Image quality assessment: from error visibility to structuralsimilarity. TIP, 13(4):600\u2013612, 2004.[28] Z. Wang and E. P. Simoncelli. Maximum differentiation(MAD) competition: A methodology for comparing computational models of perceptual quantities. Journal of Vision,8(12):8, 2008.[29] Z. Xiong, X. Sun, and F. Wu. Image hallucination with feature enhancement. In CVPR, pages 2074\u20132081. IEEE, 2009.[30] C.-Y. Yang, C. Ma, and M.-H. Yang. Single-image superresolution: A benchmark. In ECCV, pages 372\u2013386. 2014.[31] J. Yang, J. Wright, T. S. Huang, and Y. Ma. Image superresolution via sparse representation. 19(11):2861\u20132873,2010.[32] Y. Yang, N. P. Galatsanos, and A. K. Katsaggelos.Projection-based spatially adaptive reconstruction of blocktransform compressed images. TIP, 4(7):896\u2013908, 1995.[33] C. Yim and A. C. Bovik. Quality assessment of deblockedimages. TIP, 20(1):88\u201398, 2011.[34] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural networks? In NIPS, pages3320\u20133328, 2014.[35] M. D. Zeiler and R. Fergus. Visualizing and understandingconvolutional networks. In ECCV, pages 818\u2013833. 2014.[1] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. TPAMI,33(5):898\u2013916, 2011.[2] M. Bevilacqua, A. Roumy, C. Guillemot, and M.-L. A.Morel. Low-complexity single-image super-resolution basedon nonnegative neighbor embedding. In BMVC, 2012.[3] P. Dolla\u0301r and C. L. Zitnick. Structured forests for fast edgedetection. In ICCV, pages 1841\u20131848. IEEE, 2013.[4] C. Dong, C. C. Loy, K. He, and X. Tang.Image super-resolution using deep convolutional networks.arXiv:1501.00092, 2014.[5] C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deepconvolutional network for image super-resolution. In ECCV,pages 184\u2013199. 2014.[6] A. Foi, V. Katkovnik, and K. Egiazarian. Pointwise shapeadaptive DCT for high-quality denoising and deblocking ofgrayscale and color images. TIP, 16(5):1395\u20131411, 2007.[7] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semanticsegmentation. In CVPR, pages 580\u2013587. IEEE, 2014.[8] M. A. Gluck and C. E. Myers. Hippocampal mediation ofstimulus representation: A computational theory. Hippocampus, 3(4):491\u2013516, 1993.[9] R. C. Gonzalez and R. E. Woods. Digital image processing,2002.[10] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep intorecti\ufb01ers: Surpassing human-level performance on imagenetclassi\ufb01cation. arXiv:1502.01852, 2015.[11] V. Jain and S. Seung. Natural image denoising with convolutional networks. In NIPS, pages 769\u2013776, 2009.[12] J. Jancsary, S. Nowozin, and C. Rother. Loss-speci\ufb01c training of non-parametric image restoration models: A new stateof the art. In ECCV, pages 112\u2013125. 2012.[13] C. Jung, L. Jiao, H. Qi, and T. Sun. Image deblocking viasparse representation. Signal Processing: Image Communication, 27(6):663\u2013677, 2012.[14] K. I. Kim and Y. Kwon. Single-image super-resolution usingsparse regression and natural image prior. 32(6):1127\u20131133,2010.[15] A. Krizhevsky, I. Sutskever, and G. Hinton. ImageNet classi\ufb01cation with deep convolutional neural networks. pages1097\u20131105, 2012.[16] Y. Li, F. Guo, R. T. Tan, and M. S. Brown. A contrast enhancement framework with jpeg artifacts suppression. InECCV, pages 174\u2013188. 2014.[17] A.-C. Liew and H. Yan. Blocking artifacts suppression inblock-coded images using overcomplete wavelet representation. TCSVT, 14(4):450\u2013461, 2004.[18] P. List, A. Joch, J. Lainema, G. Bjontegaard, and M. Karczewicz. Adaptive deblocking \ufb01lter. TCSVT, 13(7):614\u2013619,2003.[19] V. Nair and G. E. Hinton. Recti\ufb01ed linear units improverestricted Boltzmann machines. In ICML, pages 807\u2013814,2010.584\f", "This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX1Adaptation Regularization: A GeneralFramework for Transfer LearningMingsheng Long, Jianmin Wang, Guiguang Ding, Sinno Jialin Pan, and Philip S. Yu, Fellow, IEEEAbstract\u2014Domain transfer learning, which learns a target classi\ufb01er using labeled data from a different distribution, has shownpromising value in knowledge discovery yet still been a challenging problem. Most previous works designed adaptive classi\ufb01ersby exploring two learning strategies independently: distribution adaptation and label propagation. In this paper, we propose anovel transfer learning framework, referred to as Adaptation Regularization based Transfer Learning (ARTL), to model themin a uni\ufb01ed way based on the structural risk minimization principle and the regularization theory. Speci\ufb01cally, ARTL learns theadaptive classi\ufb01er by simultaneously optimizing the structural risk functional, the joint distribution matching between domains,and the manifold consistency underlying marginal distribution. Based on the framework, we propose two novel methods usingRegularized Least Squares (RLS) and Support Vector Machines (SVMs), respectively, and use the Representer theoremin reproducing kernel Hilbert space to derive corresponding solutions. Comprehensive experiments verify that ARTL cansigni\ufb01cantly outperform state-of-the-art learning methods on several public text and image datasets.Index Terms\u2014Transfer learning, adaptation regularization, distribution adaptation, manifold regularization, generalization error.!1I NTRODUCTIONIT is very dif\ufb01cult, if not impossible, to induce asupervised classi\ufb01er without any labeled data. Forthe emerging domains where labeled data are sparse,to save the manual labeling efforts, one may expect toleverage abundant labeled data available in a relatedsource domain for training an accurate classi\ufb01er to bereused in the target domain. Recently, the literaturehas witnessed an increasing interest in developingtransfer learning [1] methods for cross-domain knowledge transfer problems. Transfer learning has provento be promising in many real-world applications, e.g.,text categorization [2], [3], sentiment analysis [4], [5],image classi\ufb01cation [6] and retrieval [7], video summarization [8], and collaborative recommendation [9].Recall that the probability distributions in differentdomains may change tremendously and have very different statistical properties, e.g., mean and variance.Therefore, one major computational issue of transferlearning is how to reduce the difference in distributions between the source and target data. Recentworks aim to discover a good feature representationacross domains, which can simultaneously reduce thedistribution difference and preserve the importantproperties of the original data [10]. Under the new fea\u2022 Mingsheng Long, Jianmin Wang, and Guiguang Ding are with theSchool of Software, Tsinghua University. Mingsheng Long is also withthe Department of Computer Science, Tsinghua University, Beijing,China. E-mail: longmingsheng@gmail.com, jimwang@tsinghua.edu.cn,dinggg@tsinghua.edu.cn. Corresponding author: Jianmin Wang.\u2022 Sinno Jialin Pan is with the Institute of Infocomm Research, Singapore138632. E-mail: jspan@i2r.a-star.edu.sg.\u2022 Philip S. Yu is with the Department of Computer Science, Universityof Illinois at Chicago, IL 60607, USA. E-mail: psyu@uic.edu.Manuscript received August 15, 2012; revised June 15, 2013.Digital Object Indentifier 10.1109/TKDE.2013.111ture representation, standard supervised learning algorithms can be trained on source domain and reusedon target domain [11], [12]. Pan et al. [11] proposedMaximum Mean Discrepancy Embedding (MMDE), inwhich the MMD [13] distance measure for comparingdifferent distributions is explicitly minimized. Si et al.[12] proposed a general Transfer Subspace Learning(TSL) framework, in which the Bregman divergence isimposed as a regularization to a variety of subspacelearning methods, e.g., PCA and LDA. Another line ofworks aims to directly construct an adaptive classi\ufb01erby imposing the distance measure as a regularizationto supervised learning methods, e.g., SVMs [14], [15],[16], [17]. However, these methods only utilized thesource domain labeled data to train a classi\ufb01er. Weshow that such labeled data can be further exploredto reduce the difference in the conditional distributionsacross domains. Also, these methods only utilized thetarget domain unlabeled data to reduce the differencein the marginal distributions across domains. We showthat these unlabeled data can be further explored toboost classi\ufb01cation performance.It is noteworthy that, in some real-world scenarios,only minimizing difference in marginal distributionsbetween domains is not good enough for knowledgetransfer, since the discriminative directions of thesource and target domains may still be different [10],[18]. Therefore, another major computational issue oftransfer learning is how to further explore marginaldistributions to potentially match the discriminativedirections between domains. In this direction, the unlabeled data may often reveal the underlying truth ofthe target domain [19], [20], [21]. Bruzzone et al. [19]proposed Domain Adaptation Support Vector Machine (DASVM), which extended Transductive SVM1041-4347/13/$31.00 \u00a9 2013 IEEE\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXDtDsDsMDAfDtDs(a)DsDtCDADs(b)DtMRffDtDsDtDtDs(c)fDtDs(d)Fig. 1. Motivation of ARTL. f : hyperplane; Ds : sourcedomain; Dt : target domain; \u25e6: domain/class centroid;MDA: marginal distribution adaptation; CDA: conditional distribution adaptation; MR: manifold regularization.(TSVM) to progressively classify the unlabeled targetdata and simultaneously remove some labeled sourcedata. Bahadori et al. [20] proposed Latent Transductive Transfer Learning (LATTL) to combine subspacelearning and transductive classi\ufb01cation (TSVM) in auni\ufb01ed framework. However, all these methods adoptTSVM as building block, which is dif\ufb01cult to solveand is not natural for out-of-sample data [22]. In addition, these methods do not minimize the differencebetween the conditional distributions across domains.Based on the aforementioned discussions, we summarize the computational issues of transfer learning inFigure 1 and highlight our motivation. Given a labeledsource domain Ds and an unlabeled target domain Dtas in subplot (a), we can see that hyperplane f trainedon Ds cannot discriminate Dt correctly due to substantial distribution difference. Similar to most previousworks, we minimize the distance between the marginaldistributions in subplot (b), i.e., the sample means ofthe two domains are drawn closer. Then hyperplanef can classify Dt more correctly. Noteworthily, it isindispensable to minimize the distance between theconditional distributions as in subplot (c), which canmake the intra-class centroids close and the inter-classcentroids more separable. Finally, as shown in subplot(d), it is important to maximize the manifold consistency underlying the marginal distributions, whichcan \u201crotate\u201d hyperplane f to respect the groundtruthof the target data. This motivates us to design a general framework to integrate all these learning objectives.In this paper, we propose a general transfer learningframework, referred to as Adaptation Regularizationbased Transfer Learning (ARTL), to model the jointdistribution adaptation and manifold regularizationin a uni\ufb01ed way underpinned by the structural riskminimization principle and the regularization theory.More speci\ufb01cally, ARTL learns an adaptive classi\ufb01er by simultaneously optimizing the structural riskfunctional, the joint distribution matching betweenboth marginal and conditional distributions, and themanifold consistency of the marginal distribution. Thecontributions of this paper are summarized as follows.\u2022To cope with the considerable change betweendata distributions from different domains, ARTLaims to minimize the structural risk functional,joint adaptation of both marginal and conditional2distributions, and the manifold regularization. Tothe best of our knowledge, ARTL is the \ufb01rst semisupervised domain transfer learning frameworkwhich can explore all these learning criteria simultaneously. In particular, ARTL remains simpleby introducing only one additional term (parameter) compared with the state-of-the-art graphbased semi-supervised learning framework [22].\u2022 Many standard supervised methods, e.g., RLSand SVMs, can be incorporated into the ARTLframework to tackle domain transfer learning. Arevised Representer theorem in the ReproducingKernel Hilbert Space (RKHS) is presented to facilitate easy handling of optimization problems.\u2022 Under the ARTL framework, we further proposetwo novel methods, i.e., ARRLS and ARSVM, respectively. Both of them are convex optimizationproblems enjoying the global optimal solutions.\u2022 Comprehensive experiments on text (Reuters21578 and 20-Newsgroups) and image (PIE, USPS, and MNIST) datasets verify the effectiveness ofthe ARTL framework in real-world applications.The remainder of the paper is organized as follows.We start by reviewing related works in Section 2. InSection 3, we present the ARTL framework, the twomethods ARRLS and ARSVM, and the analysis oftime complexity. In Sections 4 and 5, we theoreticallyanalyze the generalization error bound of ARTL, andconduct empirical studies on real-world datasets, respectively. Finally, we conclude the paper in Section 6.2R ELATED W ORKIn this section, we discuss previous works on transferlearning that are most related to our work, and highlight their differences. According to literature survey[1], most previous methods can be roughly organizedinto two categories: instance reweighting [23], [24] andfeature extraction. Our work belongs to the featureextraction category, which includes two subcategories:transfer subspace learning and transfer classi\ufb01er induction.2.1 Transfer Subspace LearningThese methods aim to extract a shared subspace inwhich the distributions of the source and target dataare drawn close. Typical learning strategies includes:1) Correspondence Learning, which \ufb01rst identi\ufb01es thecorrespondence among features and then explores thiscorrespondence for transfer subspace learning [4], [5];2) Property Preservation, which extracts shared latentfactors between domains by preserving the importantproperties of the original data, e.g., statistical property[25], [2], geometric structure [26], [27], [28], or both [3];3) Distribution Adaptation, which learns a sharedsubspace where the distribution difference is explicitlyreduced by minimizing prede\ufb01ned distance measures,e.g., MMD or Bregman divergence [11], [12], [10], [29].\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX2.2Transfer Classi\ufb01er InductionThese methods aim to directly design an adaptiveclassi\ufb01er by incorporating the adaptation of differentdistributions through model regularization. For easydiscussion, the learning strategies of these methodsare summarized as below. Our ARTL framework belongs to this subcategory, with substantial extensions.1) Subspace Learning + Classi\ufb01er Induction: Thesemethods simultaneously extract a shared subspaceand train a supervised [30] or semi-supervised classi\ufb01er [20] in this subspace. The advantage is that thesubspace and classi\ufb01er can establish mutual reinforcement. Different from these methods, ARTL does notinvolve subspace learning and thus is more generic.2) Distribution Adaptation + Classi\ufb01er Induction:These methods directly integrate the minimization ofdistribution difference as a regularization term to thestandard supervised classi\ufb01er [15], [19], [16], [17]. Butall these methods only minimize the distance betweenthe marginal distributions. Different from these methods, ARTL minimizes the distance between both themarginal and conditional distributions. Our work alsoexplores manifold structure to improve performance.3) Feature Replication + Co-Regularization: In thesemethods, the distribution difference is \ufb01rstly reducedthrough feature replication, then both the source andtarget classi\ufb01ers are required to agree on the unlabeledtarget data [31]. These methods require some labeleddata in target domain, which is not required by ARTL.4) Parameter Sharing + Manifold Regularization: Thisstrategy is explored by semi-supervised multi-tasklearning methods [32], [33], which aim to improve theperformance of multiple related tasks by exploring thecommon structure through a common prior. However,these methods ignore the distribution adaptation between multiple tasks, which is different from ARTL.5) Kernel Matching + Manifold Regularization: Thesemethods simultaneously perform classi\ufb01er induction,kernel matching, and manifold preservation [21]. Thedifferences between these methods and ARTL are that:1) these methods do not reduce the distance betweenconditional distributions; 2) kernel matching is usuallyformulated as an integer program, which is dif\ufb01cult tosolve; and 3) it is dif\ufb01cult to encode kernel matchingas a regularization to standard classi\ufb01ers, as a resulta Representer theorem is missing for these methods.3 A DAPTATION R EGULARIZATION BASEDT RANSFER L EARNING F RAMEWORKIn this section, we \ufb01rst de\ufb01ne the problem setting andlearning goal for domain transfer learning. After that,we present the proposed general framework, ARTL.Based on the framework, we propose two methodsusing RLS and SVMs, and derive learning algorithmsusing the Representer theorem in RKHS. Finally, weanalyze the computational complexity of algorithms.3TABLE 1Notations and descriptions used in this paper.NotationDescriptionNotationDescriptionDs , Dt source/target domainXdata matrixn, m#examples in Ds /DtYlabel matrixKkernel matrixd, C #shared features/classes#nearest neighborsw, \u03b1classi\ufb01er parametersp\u03c3shrinkage regularizationElabel indicator matrixMMD regularizationMMMD matrix\u03bb\u03b3manifold regularizationLgraph Laplacian matrix3.1 Problem De\ufb01nitionNotations, which are frequently used in this paper,are summarized in Table 1.De\ufb01nition 1 (Domain). [1] A domain D is composed ofa d-dimensional feature space X and a marginal probabilitydistribution P (x), i.e., D = {X , P (x)}, where x \u2208 X .In general, if two domains Ds and Dt are different, then they may have different feature spaces ormarginal distributions, i.e., Xs =\u0004 Xt \u2228 Ps (xs ) \u0004= Pt (xt ).De\ufb01nition 2 (Task). [1] Given domain D, a task T iscomposed of a label space Y and a prediction function f (x),i.e., T = {Y, f (x)}, where y \u2208 Y, and f (x) = Q(y|x) canbe interpreted as the conditional probability distribution.In general, if two tasks Ts and Tt are different, thenthey may have different label spaces or conditionaldistributions, i.e., Ys \u0004= Yt \u2228 Qs (ys |xs ) \u0004= Qt (yt |xt ).De\ufb01nition 3 (Domain Transfer Learning). Given labeled source domain Ds = {(x1 , y1 ), . . . , (xn , yn )} andunlabeled target domain Dt = {xn+1 , . . . , xn+m }, the goalof domain transfer learning is to learn a target predictionfunction ft : xt \u0006\u2192 yt with low expected error on Dt , underthe assumptions Xs = Xt , Ys = Yt , Ps (xs ) \u0004= Pt (xt ), andQs (ys |xs ) \u0004= Qt (yt |xt ).To address domain transfer learning problems directly by estimating the distribution densities is challenging. Although the marginal distribution Pt (xt )can be estimated using kernel density estimate (KDE)[18], it is impossible for the conditional distributionQt (yt |xt ) since there are no labeled data in the targetdomain. Most previous works thus assume that thereexists a proper feature transformation F such thatPs (F (xs )) = Pt (F (xt )), Qs (ys |F (xs )) \u2248 Qt (yt |F (xt )).The transformation F can be inferred by minimizingthe distribution distance between marginal distributions, and preserving properties of original data [10].In this paper, we put forward several justi\ufb01cations.\u2022 It is insuf\ufb01cient to minimize only the distributiondistance between the marginal distributions. Thedistribution distance between the conditional distributions should also be explicitly minimized.\u2022 It is useful to further explore the marginal distributions. Noteworthily, preserving manifold consistency underlying the marginal distribution canbene\ufb01t us from semi-supervised learning [22].\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXIt may be more generic to explore the data distributions in original feature space or kernel space,instead of various dimension-reduced subspaces.Based on these justi\ufb01cations, we propose our generalARTL framework in the following section.\u20223.2General FrameworkWe design the general ARTL framework underpinnedby the structural risk minimization principle and theregularization theory. Speci\ufb01cally, we aim to optimizethree complementary objective functions as follows:1) Minimizing the structural risk functional on thesource domain labeled data Ds ;2) Minimizing the distribution difference betweenthe joint probability distributions Js and Jt ;3) Maximizing the manifold consistency underlying the marginal distributions Ps and Pt .Suppose the prediction function (i.e., classi\ufb01er) be f =wT \u03c6(x), where w is the classi\ufb01er parameters, and \u03c6 :X \u0006\u2192 H is the feature mapping function that projectsthe original feature vector to a Hilbert space H. Thelearning framework of ARTL is formulated asf = arg minf \u2208HKn\u0002\u0003 (f (xi ) , yi ) + \u03c3 fi=12K(1)where K is the kernel function induced by \u03c6 suchthat \u03c6 (xi ) , \u03c6 (xj ) = K (xi , xj ), and \u03c3, \u03bb, and \u03b3 arepositive regularization parameters. We interpret eachterm of Framework (1) in the following subsections.3.2.1 Structural Risk MinimizationOur ultimate goal is to learn an adaptive classi\ufb01er forthe target domain Dt . To begin with, we can induce astandard classi\ufb01er f on the labeled source domain Ds .We adopt the structural risk minimization principle[34], and minimize the structural risk functional asf \u2208HKn\u0002i=1\u0003 (f (xi ) , yi ) + \u03c3 f2Kdistance between the joint probability distributions Jsand Jt . By probability theory, J = P \u00b7 Q, thus we seekto minimize the distribution distance 1) between themarginal distributions Ps and Pt , and 2) between theconditional distributions Qs and Qt , simultaneously.Marginal Distribution Adaptation: We minimizeDf,K (Ps , Pt ), the distance between marginal distributions Ps and Pt . Since directly estimating probabilitydensities is nontrivial, we resort to explore nonparametric statistics. We adopt empirical Maximum MeanDiscrepancy (MMD) [13], [11] as the distance measure,which compares different distributions based on thedistance between the sample means of two domains ina reproducing kernel Hilbert space (RKHS) H, namely\u0003\u00032\u0003 n\u0003n+m\u0002\u0002\u0003\u000311\u0003MMD2H (Ds , Dt ) = \u0003\u03c6(x)\u2212\u03c6(x)ij \u0003\u0003nm j=n+1\u0003 i=1\u0003Hwhere \u03c6 : X \u0006\u2192 H is the feature mapping. To makeMMD a proper regularization for the classi\ufb01er f , weadopt the projected MMD [15], which is computed as\u0003\u00032\u0003 \u0002\u0003n+m\u0002\u00031 n\u00031\u0003 (3)Df,K (Ps , Pt ) = \u0003f(x)\u2212f(x)ij \u0003\u0003nm j=n+1\u0003 i=1\u0003H+ \u03bbDf,K (Js , Jt ) + \u03b3Mf,K (Ps , Pt )f = arg min4(2)where HK is a set of classi\ufb01ers in the kernel space,f 2K is the squared norm of f in HK , \u03c3 is the shrinkage regularization parameter, and \u0003 is the loss functionthat measures the \ufb01tness of f for predicting the labelson training samples. Two widely-used loss functionsare the hinge loss for SVMs \u0003 = max (0, 1 \u2212 yi f (xi )),2and the squared loss for RLS \u0003 = (yi \u2212 f (xi )) .3.2.2 Joint Distribution AdaptationUnfortunately, the standard classi\ufb01er f inferred by (2)may not generalize well to the target domain Dt , sincethe structural risk minimization principle requires thetraining and test data to be sampled from identicalprobability distribution [34]. Thus the \ufb01rst major computational issue is how to minimize the distributionTwhere f (x) = w \u03c6(x), and K is the kernel functioninduced by \u03c6 such that \u03c6 (xi ) , \u03c6 (xj ) = K (xi , xj ).Conditional Distribution Adaptation: We minimize Df,K (Qs , Qt ), the distance between conditionaldistributions Qs and Qt . Since calculating the nonparametric statistics of Qs (ys |xs ) and Qt (yt |xt ) is dif\ufb01cult, we resort to explore the nonparametric statisticsof Qs (xs |ys ) and Qt (xt |yt ) instead, which can well approximate Qs (ys |xs ) and Qt (yt |xt ) when sample sizesare large. Unfortunately, it is impossible to calculatethe sample means of Qt (xt |yt ) w.r.t. each class (classcentroids), since there are no labels in the target domain data. In this paper, we propose to use the pseudotarget labels predicted by some supervised classi\ufb01ers(e.g., SVMs) trained on the source domain labeleddata. Though many of the pseudo target labels maybe incorrect due to substantial distribution difference,we assume that the pseudo class centroids calculatedby them may reside not far apart from the true classcentroids. Therefore, we can use both true and pseudolabels to compute the projected MMD w.r.t. each classc \u2208 {1, . . . , C} and make the intra-class centroids oftwo distributions Qs (xs |ys ) and Qt (xt |yt ) closer in H\u0002\u0002\u0002\u0002 1(c)Df,K (Qs ,Qt )=\u0002 (c)\u0002n\u0002(c)\u0003\u0003f (xi )\u2212 1(c)m(c)(c)xi \u2208Dsxj \u2208Dt\u00022\u0002\u0002\u0002f (xj )\u0002\u0002\u0002(4)Hwhere Ds = {xi : xi \u2208 Ds \u2227 y (xi ) = c} is the set ofexamples belonging to class c in the source data, y (xi )(c)is the true label of xi , and n(c) = |Ds |. Correspond(c)ingly, Dt = {xj : xj \u2208 Dt \u2227 y\u0302 (xj ) = c} is the set ofexamples belonging to class c in the target data, y\u0302 (xj )(c)is the pseudo (predicted) label of xj , and m(c) = |Dt |.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXIntegrating (3) and (4) leads to the regularizationfor joint distribution adaptation, computed as followsDf,K (Js , Jt ) = Df,K (Ps , Pt ) +C\u0002c=1(c)Df,K (Qs , Qt ) (5)By regularizing (2) with (5), both the sample means ofthe marginal and conditional distributions are drawncloser in H. It is noteworthy that, if we use an adaptive classi\ufb01er to obtain the pseudo labels, then we canusually obtain a more accurate labeling for the targetdata, which can further boost classi\ufb01cation accuracy.ARTL can readily integrate any base classi\ufb01ers by (5).3.2.3 Manifold RegularizationIn domain transfer learning, there are both labeledand unlabeled data. Since by using (5) we can onlymatch the sample means between different distributions, but we expect that knowledge of the marginaldistributions Ps and Pt can be further exploited forbetter function learning. In other words, the unlabeleddata may often reveal the underlying truth of the target domain, e.g., the sample variances. By the manifoldassumption [22], if two points xs , xt \u2208 X are close inthe intrinsic geometry of the marginal distributionsPs (xs ) and Pt (xt ), then the conditional distributionsQs (ys |xs ) and Qt (yt |xt ) are similar. Under geodesicsmoothness, the manifold regularization is computed asMf,K (Ps ,Pt )=n+m\u0003i,j=1(f (xi )\u2212f (xj ))2 Wij =n+m\u0003i,j=1f (xi )Lij f (xj )(6)where W is the graph af\ufb01nity matrix, and L is thenormalized graph Laplacian matrix. W is de\ufb01ned as\u0004cos (xi , xj ) , if xi \u2208 Np (xj ) \u2228 xj \u2208 Np (xi )Wij =0,otherwise(7)where Np (xi ) is the set of p-nearest neighbors of pointxi . L is computed as L = I\u2212D\u22121/2 WD\u22121/2\u0005, where Dnis a diagonal matrix with each item Dii = j=1 Wij .By regularizing (2) with (6), the marginal distributions can be fully exploited to maximize the consistency between the predictive structure of f and theintrinsic manifold structure of the data. This can substantially match the sample variances between domains.3.3Learning AlgorithmsWe extend standard algorithms (RLS and SVMs) under the ARTL framework with different choices of lossfunctions \u0003. The major dif\ufb01culty lies in that the kernelmapping \u03c6 : X \u0006\u2192 H may have in\ufb01nite dimensions.To solve (1) effectively, we need to reformulate it byusing the following revised Representer theorem.Theorem 1 (Representer Theorem). [35], [22] Theminimizer of optimization problem (1) admits an expansionf (x) =n+m\u0002i=1\u03b1i K (xi , x)andw=n+m\u0002i=1\u03b1i \u03c6 (xi ) (8)5in terms of the cross-domain labeled and unlabeled examples, where K is a kernel induced by \u03c6, \u03b1i is a coef\ufb01cient.We focus on reformulating the regularization. Byincorporating Equation (8) into Equation (5), we haveC\u0006\u0007 \u0002\u0006\u0007Df,K (Js , Jt ) = tr \u03b1T KM0 K\u03b1 +tr \u03b1T KMc K\u03b1c=1\u0007\u0006= tr \u03b1T KMK\u03b1with M =C\u0002Mcc=0(9)where K \u2208 R(n+m)\u00d7(n+m) is kernel matrix with Kij =K(xi , xj ), \u03b1 = (\u03b11 , . . . , \u03b1n+m ) is classi\ufb01er parameters.Mc , c \u2208 {0, 1, . . . , C} are MMD matrices computed as\u23a7(c)1\u23aa, x i , xj \u2208 Ds\u23aan(c) n(c)\u23aa\u23aa(c)1\u23aa\u23aa\u23a8 m(c) m(c) , x\u0004i , xj \u2208 Dt(c)(c)(Mc )ij =(10)x i \u2208 Ds , x j \u2208 D t\u22121\u23aa,\u23aa(c)(c)n(c) m(c)\u23aa\u23aax j \u2208 D s , xi \u2208 D t\u23aa\u23aa\u23a90,otherwise(c)(c)where n(c) , m(c) , Ds , Dt , c \u2208 {1, . . . , C} are de\ufb01nedas (4). For clarity, we can also compute M0 with (10) if(0)(0)substituting n(0) = n, m(0) = m, Ds = Ds , Dt = Dt .Similarly, by incorporating (8) into (6), we obtain\u0006\u0007Mf,K (Ps , Pt ) = tr \u03b1T KLK\u03b1(11)With (9) and (11), we can readily implement newalgorithms under ARTL by extending RLS and SVMs.3.3.1 ARRLS: ARTL Using Squared Loss2Using squared loss \u0003 (f (xi ), yi ) = (yi \u2212 f (xi )) , thestructural risk functional can be formulated as followsn\u0003i=1n+m\u0003\u0002(f (xi ),yi )+\u03c3\u0003f \u00032K =i=1Eii (yi \u2212f (xi ))2 +\u03c3\u0003f \u00032K(12)where E is a diagonal label indicator matrix with eachelement Eii = 1 if xi \u2208 Ds , and Eii = 0 otherwise.By substituting Representer theorem (8) into (12), weobtainn\u0003i=1\u0002(f (xi ),yi )+\u03c3\u0003f \u00032K =(Y\u2212\u03b1T K)E2F+\u03c3tr(\u03b1T K\u03b1)(13)where Y = [y1 , . . . , yn+m ] is the label matrix. It is nomatter that the target labels are unknown, since theyare \ufb01ltered out by the label indicator matrix E. Integrating Equations (13), (9), and (11) into Framework(1), we obtain the objective for ARRLS based on RLS:\u03b1= arg min\u03b1\u2208Rn+m(Y\u2212\u03b1T K)E2F+tr(\u03c3\u03b1T K\u03b1+\u03b1T K(\u03bbM+\u03b3L)K\u03b1)(14)Setting derivative of objective function as 0 leads to\u03b1 = ((E + \u03bbM + \u03b3L) K + \u03c3I)\u22121EYT(15)Note that when \u03bb = \u03b3 = 0, (15) gives zero coef\ufb01cientsover the joint distribution adaptation and manifoldregularization and thus degenerates to standard RLS.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXMulti-Class Extension: Denote y \u2208 RC a label vector such that yc = 1 if y(x) = c, and yc = 0 otherwise.The label matrix is Y = [y1 , . . . , yn+m ] \u2208 RC\u00d7(n+m) ,and the parameter matrix is \u03b1 \u2208 R(n+m)\u00d7C . In thisway, ARRLS can be extended to multi-class problems.3.3.2 ARSVM: ARTL Using Hinge LossUsing hinge loss \u0003 (f (xi ), yi ) = max (0, 1 \u2212 yi f (xi )),the structural risk functional can be formulated asn\u0003i=1\u0002(f (xi ),yi )+\u03c3\u0003f \u00032K =n\u0003i=1max(0,1\u2212yi f (xi ))+\u03c3\u0003f \u00032K(16)By substituting the Representer theorem (8) into (16),and integrating Equations (16), (9), and (11) into (1),we obtain the objective for ARSVM based on SVMs:\u03b1\u2208Rn\u0002minn+m,\u03be\u2208Rn\u239b\u03bei + \u03c3\u03b1T K\u03b1 + \u03b1T K (\u03bbM + \u03b3L) K\u03b1i=1n+m\u0002s.t. yi \u239d\u239e(17)To solve Equation (17) effectively, we follow [22] andreformulate (17) using Lagrange dual, which leads to\u03b2 = arg max\u03b2\u2208Rni=1Denote s the average number of non-zero features perexample, s \u2264 d, p \u0010 min(n + m, d). The computationalcomplexity of the framework consists of three parts.1) Solving the linear systems (15) or (18) using LUdecomposition requires O((n + m)3 ), which may begreatly reduced using the conjugate gradient method.For ARSVM, solving the SVM optimization (18) witha widely-used SVM solver [36] requires O((n + m)2.3 ).2) For constructingthe \u0007graph Laplacian matrix L,\u0006ARTL needs O s(n + m)2 , which is performed once.3) For constructing the kernel matrix K\u0007\u0006 and aggregate MMD matrix M, ARTL requires O C(n + m)2 .In summary,of Algo\u0007\u0006 the computational complexityrithm 1 is O (n + m)3 + (s + C) (n + m)2 using exactcomputations, which is adopted in this paper. It is notdif\ufb01cult to speed up the algorithms using conjugategradient methods, and this is left for our future work.3.5 Connections to Existing Works\u03bei \u2265 0, i = 1, . . . , ns.t.3.4 Computational Complexity\u03b1j K (xi , xj ) + b\u23a0 \u2265 1 \u2212 \u03bei , i = 1, . . . , nj=1n\u00026n\u00021\u03b2i \u2212 \u03b2 T Q\u03b22i=1\u03b2i yi = 0, 0 \u2264 \u03b2i \u22641, i = 1, . . . , nnwith Q = Y\u0303E\u0303K(2\u03c3I + 2 (\u03bbM + \u03b3L) K)\u22121(18)E\u0303T Y\u0303where Y\u0303 = diag(y1 , . . . , yn ), E\u0303 = [In , 0] \u2208 Rn\u00d7(n+m) .ARSVM can be easily implemented by using a standard SVM solver with the quadratic form induced bythe Q matrix, and then using \u03b2 to obtain the classi\ufb01er\u22121parameters by \u03b1 = (2\u03c3I + 2 (\u03bbM + \u03b3L) K) E\u0303T Y\u0303\u03b2.The learning algorithms are summarized in Algorithm 1. To make parameters \u03bb and \u03b3 easily tuned, wenormalize graph Laplacian matrix and MMD matrix.Algorithm 1: ARTL: Adaptation RegularizationTransfer Learning Algorithms ARRLS and ARSVMInput: Data X, Y; parameters p, \u03c3, \u03bb, \u03b3.Output: Adaptive classi\ufb01er f : X \u0006\u2192 Y.1 begin2Construct MMD matrix M by Equations (9),(10), graph Laplacian L by Equation (7).3Choose a kernel function K(xi , xj ) andcompute kernel matrix K by Kij = K(xi , xj ).M4Normalize M \u2190 \u0003M\u0003, L \u2190 D\u22121/2 LD\u22121/2 .F5Compute \u03b1 for ARRLS by Equation (15), forARSVM by Equation (18) with SVM solver.6Return adaptive classi\ufb01er f by Equation (8).As discussed in Section 2, our work is substantiallydifferent from a variety of prior cross-domain learningmethods such as [4], [25], [5], [6], [37], which do notexplicitly consider distribution matching or manifoldregularization. In this subsection, we will speci\ufb01callydistinguish our work from an insightful perspective.Distribution Adaptation: These methods explicitly reduce distribution difference by minimizing prede\ufb01neddistance measures, e.g., MMD or Bregman divergence[14], [11], [15], [12], [19], [16], [17]. However, they onlyreduce the distance between marginal distributions,while the distance between conditional distributionsis not minimized. Several works considered to matchboth the marginal and conditional distributions [18],[29], however, they require some labeled data in thetarget domain, which are not required by our method.Also, the manifold structure underlying the marginaldistributions is not considered in all these methods.Manifold Regularization: These methods explicitlymaximize the consistency of the induced embeddings(subspace learning) [26], [27], [28], [3] or classi\ufb01ers(supervised learning) [22], [33] with respect to theintrinsic manifold structure. However, these methodshave not explicitly reduced the distribution differencebetween domains and may over\ufb01t target domain data.To our knowledge, the works most closely relatedto our ARTL are Graph co-regularized Transfer Learning (GTL) [3], Semi-Supervised Transfer ComponentAnalysis (SSTCA) [10], Discriminative Feature Extraction (DFE) [30], Latent Transductive Transfer Learning(LATTL) [20], and Semi-Supervised Kernel Matching(SSKM) [21]. All these methods can be categorized as\u201csemi-supervised transfer learning\u201d, since they haveexplored the combination of semi-supervised learningand transfer learning. For clear comparison, the difference between these methods is illustrated in Table 2.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXTABLE 2Comparison between Most Closely Related Works.Comparison PerspectiveGTL SSTCA DFE LATTL SSKM ARTL\u221a\u221a\u221aData Reconstruction\u221a\u221a\u221a\u221aStructural Risk Minimization\u221a\u221a\u221aMarginal Adaptation\u2220\u221aConditional Adaptation\u221a\u221a\u221a\u221aManifold Regularization\u0003\u2220\u221aConvex Optimization\u221a\u221a\u221a\u221a General Frameworkuni\ufb01ed optimization; \u0003 two-step approach; \u2220 alternative approach.GTL and SSTCA are dimensionality reductionmethods where label information and manifoldstructure are explored only for subspace learning.Our ARTL is a framework for adaptive classi\ufb01ers.\u2022 DFE is a joint learning method for distributionadaptation and classi\ufb01er training. It explores themanifold structure in a separated second step, also it does not match the conditional distributions.\u2022 LATTL is a combination of subspace learning andtransductive classi\ufb01cation. By using TransductiveSVM (TSVM) to explore both the labeled and unlabeled data, LATTL can naturally achieve a better generalization capability to the target domain.It has two weaknesses: 1) it does not explicitlyreduce distribution distance; 2) its TSVM learningframework is not natural for out-of-sample data.\u2022 SSKM is the most similar work to ours. It simultaneously considers structural risk minimization,kernel matching, and manifold preservation. Thedifferences between SSKM and ARTL are that: 1)SSKM does not reduce the distance between conditional distributions; 2) the kernel matching is aninteger programming problem and is dif\ufb01cult tosolve; and 3) the kernel matching is not directlyimposed as a regularization to the classi\ufb01er, thusit does not exhibit a generic Representer theorem.In summary, our proposed ARTL can simultaneouslyexplore 1) structural risk minimization, 2) distributionadaptation of both the marginal and conditional distributions, and 3) manifold consistency maximization.ARTL is underpinned by the regularization theory inRKHS, and can exhibit a revised Representer theorem.Thus ARTL is a general framework in which a varietyof supervised algorithms can be readily incorporated.Furthermore, ARTL is a convex optimization problemenjoying global optima. We will compare ARTL withTCA and SSKM empirically to validate its advantage.\u20224G ENERALIZATION B OUND A NALYSISWe analyze the generalization error bound of ARTLon the target domain based on the structural risk onthe source domain, following the approaches in [38],[30]. First, we denotethe\u0006\u0007 induced prediction functionas f (x) = sgn wT \u03c6 (x) , and the true labeling function as h(x) : X \u0006\u2192 {1, \u22121}. Let \u0003(x) be a continuousloss function \u0003 (x) = |h (x) \u2212 f (x)|, then 0 \u2264 \u0003 (x) \u2264 2.7First of all, the expected error of f in Dt is de\ufb01ned ast(f ) = Ex\u223cPt [|h (x) \u2212 f (x)|] = Ex\u223cPt [\u0003 (x)]Similarly, the expected error of f in Ds is de\ufb01ned ass(f ) = Ex\u223cPs [|h (x) \u2212 f (x)|] = Ex\u223cPs [\u0003 (x)]Now we present the target error bound in terms of thesource risk in the following theorem, which is essentially a restatement of [38] with a slight modi\ufb01cation.Theorem 2. Suppose the hypothesis space containing f isof VC-dimension d, then the expected error of f in Dt isbounded with probability at least 1 \u2212 \u03b4 by\u0002\u0005t (f ) \u2264 \u0005\u02c6s (f ) +4n\u0003d log2en4+ logd\u03b4\u0004+ Df,K (Js , Jt ) + \u03a9(19)where e is the base of natural logarithm, \u02c6s (f ) is the empirical error of f in Ds , and \u03a9 = inf f \u2208HK [ s (f ) + t (f )].From Theorem 2, the expected error in Dt , i.e., t (f ),is bounded if we can simultaneously minimize 1) theempirical error of labeled data in Ds , i.e., \u02c6s (f ), 2) thedistribution distance between Ds and Dt in RKHS H,i.e., Df,K (Js , Jt ), and 3) the adaptability of the truefunction h in terms of hypothesis space HK , i.e., \u03a9.In ARTL framework, i.e., Equation (1), \u02c6s (f ) is explicitly minimized by structural risk minimization inEquation (2); Df,K (Js , Jt ) is explicitly minimized bydistribution adaptation in Equation (5); \u03a9 is implicitlyminimized by manifold regularization in Equation (6).Non-rigorously, we interpret why manifold regularization in Equation (6) can implicitly minimize \u03a9,the adaptability of the true function h in terms of thehypothesis space HK . First, we introduce the following theorem, which states the error bound of semisupervised learning based on manifold regularization.Theorem 3. [39] Consider collection (xi , yi ) for i \u2208Zn+m = {1, . . . , n+m}. Assume that we randomly pick ndistinct integers j1 , . . . , jn from Zn+m uniformly (withoutreplacement), and denote it by Zn . Let h be the truepredictor and f\u0302 (Zn ) be the semi-supervised learner trainedusing labeled data in Zn and unlabeled data in Zn+m \\Zn\u0010\u00111 \u0002T\u0003 (fi , yi ) + \u03b3f Lff\u0302 (Zn ) = arg inff \u2208Rn+m ni\u2208Zn\u2202\u0003 (h, y)| \u2264 \u03c4 , and \u0003(h, y) is convex with respect to h,if | \u2202hthen we have the generalization error bound on Zn+m \\Zn\u0013\u0012\u00021E Zn\u0003 f\u02c6i (Zn ) , yimi\u2208Zn+m \\Zn\u0010\u0006\u0007 \u0011n+m\u0002\u03c4 2 tr L\u221211T\u0003 (fi , yi ) + \u03b3f Lf +\u2264 inf2\u03b3n (n + m)f \u2208Rn+m n + mi=1In ARTL, manifold regularization (6) is performedin RKHS H where the distribution distance has beenminimized by Equation (5). Thus, Theorem 3 states\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXthat, the classi\ufb01er f\u02c6 trained in a semi-supervised wayon Ds \u222a Dt in RKHS H can be guaranteed by an errorbound in Dt . In other words, the manifold regularization (6) can implicitly minimize \u03a9, the adaptability oftrue function h in terms of the hypothesis space HK .TABLE 3Top categories and subcategories in 20-Newsgroups.Top Categorycomp5 E XPERIMENTSIn this section, we perform extensive experimentson two real-world applications (i.e., text classi\ufb01cationand image recognition) to evaluate ARTL. Datasetsand codes will be available online upon publication.5.1 Data Preparation5.1.1 Text DatasetsThe 219 cross-domain text datasets are generated from20-Newsgroups and Reuters-21578, which are twobenchmark text corpora widely used for evaluatingtransfer learning algorithms [25], [26], [10], [2], [17].20-Newsgroups1 has approximately 20,000 documents distributed evenly in 20 different subcategories.The corpus contains four top categories comp, rec, sciand talk. Each top category has four subcategories,which are listed in Table 3. In the experiments, wecan construct 6 dataset groups for binary classi\ufb01cationby randomly selecting two top categories (one forpositive and the other one for negative) from the fourtop categories. The 6 dataset groups are comp vs rec,comp vs sci, comp vs talk, rec vs sci, rec vs talk, and scivs talk. Similar to the approach in [25], we set up onedataset (including source domain and target domain)for cross-domain classi\ufb01cation as follows. For eachpair of top categories P and Q (e.g., P for positive andQ for negative), their four sub-categories are denotedby P1 , P2 , P3 , P4 and Q1 , Q2 , Q3 , Q4 , respectively. Werandomly select (without replacement) two subcategories from P (e.g., P1 and P2 ) and two subcategoriesfrom Q (e.g., Q1 and Q2 ) to form a source domain,then the remaining subcategories in P and Q (i.e., P3 ,P4 and Q3 , Q4 ) are selected to form a target domain.This dataset construction strategy ensures that thedomains of labeled and unlabeled data are related,since they are under the same top categories. Besides,the domains are also ensured to be different, sincethey are drawn from different subcategories. In thisway, for each dataset group P vs Q, we can generateC42 \u00b7 C42 = 36 datasets. Clearly, for each example in thegenerated dataset group, its class label is either P or Q.In total, we can generate 6 dataset groups consistingof 6 \u00b7 36 = 216 datasets. For fair comparison, the 216datasets are constructed using a preprocessed versionof 20-Newsgroups [2], which contains 25,804 featuresand 15,033 documents, with each document weightedby term frequency-inverse document frequency (TF-IDF).Reuters-215782 has three top categories orgs, people,and place. Using the same strategy, we can construct 31. https://people.csail.mit.edu/jrennie/20newsgroups2. https://www.daviddlewis.com/resources/testcollections/reuters215788recscitalkSubcategorycomp.graphicscomp.os.ms-windows.misccomp.sys.ibm.pc.hardwarecomp.sys.mac.hardwarerec.autosrec.motorcyclesrec.sport.baseballrec.sport.hokeysci.cryptsci.electronicssci.medsci.spacetalk.politics.gunstalk.politics.mideasttalk.politics.misctalk.religion.misc#Examples970963979958987993991997989984987985909940774627#Features25804cross-domain text datasets orgs vs people, orgs vs placeand people vs place. For fair comparison, we use thepreprocessed version of Reuters-21578 studied in [40].5.1.2 Image DatasetsUSPS, MNIST and PIE (refer to Figure 2 and Table 4)are three handwritten digits/face datasets broadlyadopted in compute vision and pattern recognition.USPS3 dataset composes of 7,291 training imagesand 2,007 test images of size 16 \u00d7 16.MNIST4 dataset has a training set of 60,000 examples and a test set of 10,000 examples of size 28 \u00d7 28.From Figure 2, we see that USPS and MNIST followdifferent distributions. They share 10 semantic classes,with each corresponding to one digit. We constructone dataset USPS vs MNIST by randomly sampling1,800 images in USPS to form the source domain, andsampling 2,000 images in MNIST to form the targetdomain. Then we switch the source/target pair to getanother dataset MNIST vs USPS. We uniformly rescaleall images to size 16 \u00d7 16, and represent each imageby a 256-dimensional vector encoding the gray-scalevalues of all pixels. In this way, the source and targetdomain are ensured to share the same feature space.PIE5 , standing for \u201cPose, Illumination, Expression\u201d,is a benchmark face database. It has 68 individualswith 41,368 face images sized 32\u00d732. The images werecaptured by 13 synchronized cameras and 21 \ufb02ashes,under varying poses, illuminations, and expressions.In our experiments, we simply adopt the preprocessed versions of PIE6 , i.e., PIE1 [41] and PIE2 [42],which are generated by randomly sampling the faceimages from the near-frontal poses (C27) under different lighting and illumination conditions. We constructone dataset PIE1 vs PIE2 by selecting all 2,856 imagesin PIE1 to form the source domain, and all 3,329images in PIE2 to form the target domain. We switchsource/target pair to get another dataset PIE2 vs PIE1.3.4.5.6.https://www-i6.informatik.rwth-aachen.de/\u223ckeysers/usps.htmlhttps://yann.lecun.com/exdb/mnisthttps://vasc.ri.cmu.edu/idb/html/facehttps://www.cad.zju.edu.cn/home/dengcai/Data/FaceData.html\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XXFig. 2. Benchmark image datasets PIE, USPS, MNIST.TABLE 4Statistics of the 4 benchmark image datasets.DatasetUSPSMNISTPIE1PIE2TypeDigitDigitFaceFace#Examples1,8002,0002,8563,329#Features2562561,0241,024#Classes10106868Thus the source and target domains are guaranteedto follow different distributions in the same featurespace, due to variations in lighting and illumination.5.2Experimental Setup5.2.1 Baseline MethodsWe compare ARTL approaches, i.e., ARSVM and ARRLS, with eight state-of-the-art supervised and transfer learning methods for text and image classi\ufb01cation:\u2022 Logistic Regression (LR)\u2022 Support Vector Machine (SVM)\u2022 Laplacian SVM (LapSVM) [22]\u2022 Cross-Domain Spectral Classi\ufb01cation (CDSC) [26]\u2022 Spectral Feature Alignment (SFA) [5]\u2022 Transfer Component Analysis (TCA) [10]\u2022 Large Margin Transductive TL (LMTTL) [15]\u2022 Semi-Supervised Kernel Matching (SSKM) [21]Speci\ufb01cally, LMTTL is a special case of ARTL with \u03b3 =0, C = 0, while SSKM can be viewed as a special caseof ARTL with C = 0. SSKM adopts a kernel matchingstrategy which needs an additional mapping matrix tomatch different kernels. Different from SSKM, ARTLseamlessly integrates the distribution adaptation terminto the classi\ufb01er based on the regularization theory.Note that we do not compare with [30] because theirwork cannot cope with thousands of training samples.5.2.2 Implementation DetailsFollowing [1], [10], [21], LR and SVM are trained onthe labeled source data, and tested on the unlabeledtarget data; CDSC, SFA, and TCA are run on all dataas dimensionality reduction step, then an LR classi\ufb01eris trained on the labeled source data to classify the unlabeled target data; LapSVM, LMTTL, SSKM, ARSVM,and ARRLS are trained on all data in a transductiveway to directly induce domain-adaptive classi\ufb01ers.Under our experimental setup, it is impossible toautomatically tune the optimal parameters for thetarget classi\ufb01er using cross validation, since we haveno labeled data in the target domain. Therefore, weevaluate the eight baseline methods on our datasets9by empirically searching the parameter space for theoptimal parameter settings, and report the best resultsof each method. For LR7 and SVM8 , we set the tradeoff parameter C (i.e., 1/2\u03c3 in ARTL) by searching C \u2208{0.1, 0.5, 1, 5, 10, 50, 100}. For LapSVM9 , we set regularization parameters \u03b3A and \u03b3I (i.e., \u03c3 and \u03b3 in ARTL)by searching \u03b3A , \u03b3I \u2208 {0.01, 0.05, 0.1, 0.5, 1, 5, 10}. Fortransfer subspace learning methods CDSC, SFA, andTCA, we set the optimal subspace dimension k bysearching k \u2208 {4, 8, 16, 32, 64, 128}. For transfer classi\ufb01er induction methods LMTTL and SSKM, we setthe trade-off parameter \u03bb between the structural riskfunctional and the distribution adaptation term bysearching \u03bb \u2208 {0.01, 0.1, 1, 10, 100}. We use linear kernel, i.e., K(xi , xj ) = xi , xj , for all kernel methods.ARTL approaches involve four tunable parameters:shrinkage/MMD/manifold regularization parameters\u03c3, \u03bb, \u03b3, and #nearest neighbors p. Sensitivity analysisvalidates that ARTL can achieve stable performanceunder a wide range of parameter values, especially for\u03c3, \u03bb, and p. In the comparative study, we \ufb01x \u03c3 = 0.1,\u03bb = 10, p = 10, and set 1) \u03b3 = 10 for the text datasets,and 2) \u03b3 = 1 for the image datasets. In practice, wecan simplify model selection by sequentially choosingoptimal parameter values from the most stable ones tothe most sensitive ones. Firstly, since the adaptationregularization can largely control model complexity,ARTL is very robust to \u03c3, and we can simply choose small \u03c3 such that ARTL does not degenerate. Secondly,since distribution adaptation is inevitable for transferlearning, we choose \u03bb such that ARTL can suf\ufb01cientlymatch both the marginal and conditional distributionsacross domains. Finally, we can choose \u03b3 by followingthe graph-based semi-supervised learning framework[22], where p is often predetermined as KNN methods.We use the classi\ufb01cation Accuracy on the test data(unlabeled target data) as the evaluation metric, sinceit is widely adopted in the literature [30], [5], [10], [17]Accuracy =|x : x \u2208 Dt \u2227 f (x) = y (x)||x : x \u2208 Dt |where y(x) is the groundtruth label of x while f (x)is the label predicted by the classi\ufb01cation algorithm.5.3 Experimental ResultsIn this section, we compare our ARTL with the eightbaseline methods in terms of classi\ufb01cation accuracy.5.3.1 Results of Text Classi\ufb01cationAs 20-Newsgroups and Reuters-21578 are different inhierarchical structure, we report the results separately.20-Newsgroups: The average classi\ufb01cation accuracyof ARTL approaches, including ARSVM and ARRLS,and the eight baseline methods on the 6 cross-domain7. https://www.csie.ntu.edu.tw/\u223ccjlin/liblinear8. https://www.csie.ntu.edu.tw/\u223ccjlin/libsvm9. https://vikas.sindhwani.org/manifoldregularization.html\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX10TABLE 5Average classi\ufb01cation accuracy (%) on the 6 cross-domain text dataset groups comprising of 216 datasets.DatasetGroupcomp vs reccomp vs scicomp vs talkrec vs scirec vs talksci vs talkAverageLR88.3777.8796.3175.2882.2876.9982.85Standard LearningSVMLapSVM87.5181.9375.3868.9695.4495.4073.8274.2183.2787.4476.8580.2282.0581.36LRCDSCSFATCALMTTLSSKMARRLS7060510152025Dataset Index309580LRCDSCSFATCALMTTLSSKMARRLS706050355(a) comp vs rec101520Dataset Index2530Accuracy (%)Accuracy (%)Accuracy (%)8085803590LRCDSCSFATCALMTTLSSKMARRLS70601520Dataset Index(d) rec vs sci25303580LRCDSCSFATCALMTTLSSKMARRLS7060505101520Dataset Index(e) rec vs talk253035Accuracy (%)90Accuracy (%)9080101520Dataset Index253035(c) comp vs talk100105(b) comp vs sci1005LRCDSCSFATCALMTTLSSKMARRLS9010050Transfer Classi\ufb01er InductionSSKMARSVMARRLS96.0695.1096.6484.1584.5386.7197.4097.5398.0385.7187.1991.0290.1595.9996.8274.7489.0391.1188.0391.5693.401009090Accuracy (%)LMTTL92.1577.5894.9378.2484.5574.8083.7110010050Transfer Subspace LearningCDSCSFATCA87.9589.7395.1275.7278.0777.3297.3395.8597.2077.5379.2582.3182.1486.9886.5880.9779.2779.3083.6284.8686.3180LRCDSCSFATCALMTTLSSKMARRLS7060505101520Dataset Index253035(f) sci vs talkFig. 3. Classi\ufb01cation accuracy of LR, CDSC, SFA, TCA, LMTTL, SSKM, and ARRLS on the 216 text datasets.dataset groups (216 datasets) are illustrated in Table 5.All the detailed results of the 6 dataset groups arelisted in Figures 3(a)\u223c3(f). Each of these six \ufb01gurescontains the results on the 36 datasets in the corresponding group. The 36 datasets are sorted by an increasing order of the classi\ufb01cation accuracy obtainedby Logistic Regression (LR). Therefore, the x-axis ineach \ufb01gure can essentially indicate the degree ofdif\ufb01culty in cross-domain knowledge transfer. Fromthese \ufb01gures, we can make the following observations.ARTL approaches achieve much better performancethan the eight baseline methods with statistical signi\ufb01cance. The average classi\ufb01cation accuracy of ARRLS on the 216 datasets is 93.40%. The performanceimprovement is 5.37% compared to the best baselinemethod SSKM, which means a very signi\ufb01cant errorreduction of 44.86%. Since these results are obtainedfrom a large number of datasets, it can convincinglyverify that ARTL can build robust adaptive classi\ufb01ersfor classifying cross-domain documents accurately.Secondly, we observe that all the transfer learningmethods can achieve better classi\ufb01cation accuracythan the standard learning methods. A major limitation of existing standard learning methods is that theytreat the data from different domains as if they weredrawn from a homogenous distribution. In reality, theidentical-distribution assumption does not hold in thecross-domain learning problems, and thus results intheir unsatisfactory performance. It is important tonotice that, the state-of-the-art semi-supervised learning method LapSVM cannot perform better than LRand SVM. Although LapSVM can explore the targetdata in a transductive way, it does not minimize thedistribution difference between domains. Therefore, itmay over\ufb01t the target data when the discriminativedirections are signi\ufb01cantly different between domains.Thirdly, we notice that ARTL signi\ufb01cantly outperforms CDSC, SFA, and TCA, which are state-of-the-arttransfer subspace learning methods based on featuretransformation. A major limitation of existing transfersubspace learning methods is that they are prone toover\ufb01tting, due to their incapability to simultaneouslyreduce the difference in both marginal and conditionaldistributions between domains. Although SFA worksparticularly well for sentiment classi\ufb01cation, it worksfairly for text classi\ufb01cation, and the reason is that SFAonly explores feature co-occurrence for feature alignment without considering feature frequency, whichis effective for low-frequency sentiment data but noteffective for high-frequency text data. ARTL addressesthese limitations and can achieve much better results.Fourthly, we observe that ARTL achieves much bet-\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX90100LRLapSVMCDSCSFATCALMTTLSSKMARSVMARRLS8070605011orgs vs peopleorgs vs placeDatasetpeople vs place(a) Reuters-21578LRSVMCDSCTCALMTTLSSKMARRLSARRLS+80604020USPS vs MNISTMNIST vs USPSPIE1 vs PIE2PIE2 vs PIE1Dataset(b) Image DatasetsFig. 4. Classi\ufb01cation accuracy of LR, SVM, LapSVM, CDSC, TCA, LMTTL, SSKM, ARSVM, ARRLS, ARRLS+.ter performance than LMTTL and SSKM. Notice that,LMTTL and SSKM are typical transfer classi\ufb01er induction methods, which can induce a supervised/semisupervised classi\ufb01er and meanwhile minimize the distribution difference between domains. However, sincethe difference between the conditional distributions isnot minimized, while the regularization terms are notimposed to the classi\ufb01er, it is likely that these methodscannot fully reduce the distribution difference andmay get stuck in poor local optima. ARTL achievessuperior performance by alleviating these limitations.Lastly, ARTL approaches often perform more robustly on dif\ufb01cult-to-classify datasets than all baselinemethods. This can be observed from Figures 3(a)\u223c3(f),where the improvements of ARTL over the baselinemethods are more remarkable on datasets in which LRperforms with extremely low accuracy (below 70%).Reuters-21578: The classi\ufb01cation accuracy of ARTLand the baseline methods on the 3 datasets generatedfrom Reuters-21578 are illustrated in Figure 4(a). Weobserve that ARTL has outperformed, or achievedcomparable performance than the baseline methods.We notice that, Reuters-21578 is more challengingthan 20-Newsgroups, since each of its top categoriesconsists of many subcategories, i.e., clusters or subclasses. Therefore, it is more dif\ufb01cult to minimize thedistribution difference by only matching the samplemeans between domains. This reason can explain theunsatisfactory performance obtained by distributionadaptation methods, i.e., TCA, LMTTL, and SSKM.By minimizing the distribution difference betweenboth marginal and conditional distributions, ARTLcan naturally match more statistical properties, i.e.,both domain centroids and class centroids. Also, bymaximizing the manifold consistency, ARTL can fullyexplore the marginal distributions, which can implicitly \u201crotate\u201d the decision hyperplane to better respectthe target data. In this way, ARTL can perform betteron dif\ufb01cult datasets with many classes or subclasses.5.3.2 Results of Image RecognitionThe average classi\ufb01cation accuracy of ARTL and thesix baseline methods on the four image datasets isillustrated in Figure 4(b). SFA is not compared since itcannot handle non-sparse image data, while LapSVMand ARSVM are not compared since their original implementations cannot deal with multi-class problems.We notice that, the transfer subspace learning methods, e.g., CDSC, generally outperform standard LRand SVM. This is an expected result, since subspacelearning methods, e.g., PCA, are very effective for image representation. Unfortunately, TCA has generallyunderperformed CDSC at this time. The main reasonsare two-folds: 1) the MMD distance measure is notvery suitable for image data, as exempli\ufb01ed by [12];2) the distribution difference is signi\ufb01cantly large inthe image datasets, resulting in the over\ufb01tting issues.We also notice that, the transfer classi\ufb01er inductionmethods, i.e., LMTTL and SSKM, outperform CDSCin the face datasets but underperform CDSC in thehandwritten digits datasets. We conjecture the reasonsas follows: 1) for the face datasets, there are 68 classes,thus transfer classi\ufb01er induction methods which directly inject the labeled information into the learningprocedure, are more effective; 2) for the handwrittendigits datasets, data reconstruction may be a more important process to reduce the distribution difference.In conclusion, ARTL generally outperforms all baseline methods. Therefore, we can often harvest a robust adaptive classi\ufb01er, by minimizing the differencebetween both marginal and conditional distributions,and meanwhile preserving the manifold consistency.5.4 Effectiveness Veri\ufb01cationWe verify effectiveness of ARTL by inspecting the impacts of base classi\ufb01er and adaptation regularization.5.4.1 Base Classi\ufb01er IntegrationARTL utilizes some base classi\ufb01er, e.g., SVM, to obtainthe pseudo labels for the target data, through whichthe difference between the conditional distributions isminimized. Unsurprisingly, if we use some adaptiveclassi\ufb01er, e.g., ARRLS, to obtain more accurate pseudolabels for the target data, then we can match the conditional distributions more accurately and further boostthe classi\ufb01cation accuracy. It is very interesting thatARTL can accept its outputs as inputs to iterativelyimprove itself. We denote this alternatingly enhancedversion of ARRLS as ARRLS+. We run ARRLS+ on theimage datasets, and show its classi\ufb01cation accuracy inFigure 4(b). Similar results on other datasets are omitted due to space limitation. We note that ARRLS+ hassigni\ufb01cantly outperformed ARRLS by 10.60%, whichveri\ufb01es ARTL can naturally integrate base classi\ufb01ers.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX\u03b1K\u03b11.51.5\u03b1K\u03b11.51.5\u03b1K\u03b11.5121.51.5111111110.50.50.50.50.50.50.50.500000000\u22120.5\u22120.5\u22120.5\u22120.5\u22120.5\u22120.5\u22120.5\u22120.5\u22121\u22121\u22121\u22121\u22121\u22121\u22121\u22121\u22121.5\u22121.5\u22121.5\u22121.5\u22121.5\u22121.5\u22121.5\u22121.502000 4000 6000 800002040(a) C = 002000 4000 6000 80000204002000 4000 6000 8000(b) \u03bb = 0020\u03b1K\u03b11.540(c) \u03b3 = 002000 4000 6000 800002040(d) optimal parametersFig. 5. Classi\ufb01cation predictions K\u03b1 and classi\ufb01er parameters \u03b1 output by ARRLS on the rec vs sci 1 dataset.5.4.2 Adaptation RegularizationTo inspect the effectiveness of each criterion, we runARRLS on a randomly selected dataset, e.g., rec vs sci1, by removing one term from its objective function.First, we remove the conditional distribution adaptation term by setting C = 0 as in Figure 5(a). In thiscase, we cannot even \ufb01nd a clear decision hyperplanefor the target data, i.e., the target data are not wellseparated at all. This veri\ufb01es the crucial role that theconditional distribution adaptation has played. Similar results can be observed from Figure 5(b), in whichwe remove the whole distribution adaptation term bysetting \u03bb = 0. The similar results between C = 0 and\u03bb = 0 implies that minimizing the difference betweenthe conditional distributions is much more importantthan that of the marginal distributions. With conditional distribution adaptation, we can make the intraclass centroids close and the inter-class centroids moreseparable, as can be clearly observed from Figure 5(d).Secondly, we remove the manifold regularizationterm by setting \u03b3 = 0 as in Figure 5(c). In this case,the predictions are scattering in a wider range than thegroundtruth [\u22121, 1]. In other words, the manifold consistency underlying the target data is violated, regardless that the target data are better separated due tothe distribution adaptation of both the marginal andconditional distributions. Therefore, to induce a goodadaptive classi\ufb01er using the ARTL framework, it isvery important to preserve the manifold consistency.The importance of the manifold regularization can beobserved by comparing Figure 5(c) with Figure 5(d).TABLE 6Time complexity of ARTL and the baseline methods.MethodLRLapSVMSFALMTTLARSVMRunning Time (s)0.0544.2020.82604.69730.09MethodSVMCDSCTCASSKMARRLSRunning Time (s)6.7925.371794.90191.3248.94different values of p in Figure 6(a), which indicatesa wide range p \u2208 [4, 64] for optimal parameter values.Shrinkage Regularization \u03c3: We run ARTL withvarying values of \u03c3. Theoretically, \u03c3 controls modelcomplexity of the adaptive classi\ufb01er. When \u03c3 \u2192 0,the classi\ufb01er degenerates and over\ufb01tting occurs. Onthe contrary, when \u03c3 \u2192 \u221e, ARTL is dominated bythe shrinkage regularization without \ufb01tting the inputdata. We plot the classi\ufb01cation accuracy w.r.t. differentvalues of \u03c3 in Figure 6(b), and choose \u03c3 \u2208 [0.001, 1].MMD Regularization \u03bb: We run ARTL with varying values of \u03bb. Theoretically, larger values of \u03bb makedistribution adaptation more effective. When \u03bb \u2192 0,distribution difference is not reduced and over\ufb01ttingoccurs. We plot classi\ufb01cation accuracy w.r.t. differentvalues of \u03bb in Figure 6(c), and can choose \u03bb \u2208 [5, 1000].Manifold Regularization \u03b3: We run ARTL withvarying values of \u03b3. Theoretically, larger values of \u03b3make manifold consistency more important in ARTL.When \u03b3 \u2192 \u221e, only manifold consistency is preservedwhile labeled information is discarded, which is unsupervised. We plot classi\ufb01cation accuracy w.r.t. different values of \u03b3 in Figure 6(d), and choose \u03b3 \u2208 [0.1, 10].5.5 Parameter SensitivityWe conduct empirical parameter sensitivity analysis,which validates that ARTL can achieve optimal performance under wide range of parameter values. Dueto space limitation, we randomly select one generateddataset from 20-Newsgroups, Reuters-21578, USPS &MNIST, and PIE respectively, and discuss the results.#Nearest Neighbors p: We run ARTL with varyingvalues of p. Theoretically, p should be neither toolarge nor too small, since an extremely dense graph(p \u2192 \u221e) will connect two examples which are notsimilar at all, while an extremely sparse graph (p \u2192 0)will capture limited similarity information betweenexamples. We plot the classi\ufb01cation accuracy w.r.t.5.6 Time ComplexityWe empirically check the time complexity of all algorithms by running them on the comp vs rec 1 datasetwith 25,800 features and 8,000 documents, and showthe results in Table 6. We see that ARRLS can achievecomparable time complexity as the baseline methods.6C ONCLUSIONIn this paper, we proposed a general framework, referred to as Adaptation Regularization based TransferLearning (ARTL), to address cross-domain learningproblems. ARTL aims to simultaneously optimize the\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.13100100909090808080807060503024816p326050rec vs sci 1org vs placeMNIST vs USPSPIE2 vs PIE140704064inf(a) #nearest neighbors p300.001 0.005 0.01 0.050.51706050rec vs sci 1org vs placeMNIST vs USPSPIE2 vs PIE10.1\u03c3Accuracy (%)10090Accuracy (%)100Accuracy (%)Accuracy (%)IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX510(b) shrinkage regularization \u03c3300.10.51510\u03bb501006050rec vs sci 1org vs placeMNIST vs USPSPIE2 vs PIE14070rec vs sci 1org vs placeMNIST vs USPSPIE2 vs PIE140500 1000(c) MMD regularization \u03bb300.01 0.050.10.51\u03b351050100(d) manifold regularization \u03b3Fig. 6. Parameter sensitivity study for ARTL on selected datasets (dashed lines show the best baseline results).structural risk functional, joint distribution adaptationof both the marginal and conditional distributions,and the manifold consistency. An important advantage of ARTL is that it can explore as many necessarylearning objectives as possible, yet still remain simpleto implement practically. Furthermore, many existingsupervised learning algorithms, e.g., RLS and SVM,can be readily incorporated into the ARTL framework.ARTL is robust to the distribution difference betweendomains, and can signi\ufb01cantly improve cross-domaintext/image classi\ufb01cation problems. Extensive experiments on 219 text datasets and 4 image datasets validate that the proposed approach can achieve superiorperformance than state-of-the-art adaptation methods.ACKNOWLEDGMENTSThis work is supported by National HGJ Key Project(2010ZX01042-002-002), National High-Tech Development Program (2012AA040911), National Basic Research Program (2009CB320700), and National Natural Science Foundation of China (61073005, 61271394).Philip S. Yu is supported in part by US NSF throughgrants OISE-1129076, CNS-1115234, DBI-0960443, andUS Department of Army through grant W911NF-121-0066.R EFERENCES[1][2][3][4][5][6]S. J. Pan and Q. Yang, \u201cA survey on transfer learning,\u201d IEEETransactions on Knowledge and Data Engineering, vol. 22, pp.1345\u20131359, 2010.F. Zhuang, P. Luo, Z. Shen, Q. He, Y. Xiong, Z. Shi, and H. Xiong, \u201cMining distinction and commonality across multipledomains using generative model for text classi\ufb01cation,\u201d IEEETransactions on Knowledge and Data Engineering, vol. 24, no. 11,2011.M. Long, J. Wang, G. Ding, D. Shen, and Q. Yang, \u201cTransferlearning with graph co-regularization,\u201d in Proceedings of the26th AAAI Conference on Arti\ufb01cial Intelligence, ser. AAAI, 2012.J. Blitzer, R. McDonald, and F. Pereira, \u201cDomain adaptationwith structural correspondence learning,\u201d in Proceedings ofthe 2006 Conference on Empirical Methods in Natural LanguageProcessing, ser. EMNLP, 2006.S. J. Pan, X. Ni, J.-T. Sun, Q. Yang, and Z. Chen, \u201cCross-domainsentiment classi\ufb01cation via spectral feature alignment,\u201d inProceedings of the 19th International Conference on World WideWeb, ser. WWW, 2010.Y. Zhu, Y. Chen, Z. Lu, S. J. Pan, G.-R. Xue, Y. Yu, and Q. Yang,\u201cHeterogeneous transfer learning for image classi\ufb01cation,\u201d inProceedings of the 25th AAAI Conference on Arti\ufb01cial Intelligence,ser. AAAI, 2011.[7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22][23][24]M. Rohrbach, M. Stark, G. Szarvas, I. Gurevych, and B. Schiele,\u201cWhat helps where \u2013 and why? semantic relatedness forknowledge transfer,\u201d in Proceedings of the 23rd IEEE Conferenceon Computer Vision and Pattern Recognition, ser. CVPR, 2010.L. Li, K. Zhou, G.-R. Xue, H. Zha, and Y. Yu, \u201cVideo summarization via transferrable structured learning,\u201d in Proceedingsof International Conference on World Wide Web, ser. WWW, 2011.B. Li, Q. Yang, and X. Xue, \u201cTransfer learning for collaborative\ufb01ltering via a rating-matrix generative model,\u201d in Proceedingsof the 26th International Conference on Machine Learning, ser.ICML, 2009.S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, \u201cDomainadaptation via transfer component analysis,\u201d IEEE Transactionson Neural Networks, vol. 22, no. 2, pp. 199\u2013210, 2011.S. J. Pan, J. T. Kwok, and Q. Yang, \u201cTransfer learning viadimensionality reduction,\u201d in Proceedings of the 22nd AAAIConference on Arti\ufb01cial Intelligence, ser. AAAI, 2008.S. Si, D. Tao, and B. Geng, \u201cBregman divergence-based regularization for transfer subspace learning,\u201d IEEE Transactions onKnowledge and Data Engineering, vol. 22, no. 7, 2010.A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Scholkopf, andA. J. Smola, \u201cA kernel method for the two-sample problem,\u201din Neural Information Processing Systems, ser. NIPS, 2006.J. Yang, R. Yan, and A. G. Hauptmann, \u201cCross-domain videoconcept detection using adaptive svms,\u201d in Proceedings of the15th international conference on Multimedia, ser. ACM MM, 2007.B. Quanz and J. Huan, \u201cLarge margin transductive transferlearning,\u201d in Proceedings of the 18th ACM conference on Information and knowledge management, ser. CIKM, 2009.J. Tao, F.-L. Chung, and S. Wang, \u201cOn minimum distributiondiscrepancy support vector machine for domain adaptation,\u201dPattern Recognition, vol. 45, no. 11, 2012.L. Duan, I. W. Tsang, and D. Xu, \u201cDomain transfer multiplekernel learning,\u201d IEEE Transactions on Pattern Analysis andMachine Intelligence, vol. 34, no. 3, pp. 465\u2013479, 2012.E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga,and O. Verscheure, \u201cCross domain distribution adaptation viakernel mapping,\u201d in Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,ser. KDD, 2009.L. Bruzzone and M. Marconcini, \u201cDomain adaptation problems: A dasvm classi\ufb01cation technique and a circular validation strategy,\u201d IEEE Transactions on Pattern Analysis andMachine Intelligence, vol. 32, no. 5, 2010.M. T. Bahadori, Y. Liu, and D. Zhang, \u201cLearning with minimum supervision: A general framework for transductivetransfer learning,\u201d in Proceedings of the 11th IEEE InternationalConference on Data Mining, ser. ICDM, 2011.M. Xiao and Y. Guo, \u201cSemi-supervised kernel matching fordomain adaptation,\u201d in Proceedings of the 26th AAAI Conferenceon Arti\ufb01cial Intelligence, ser. AAAI, 2012.M. Belkin, P. Niyogi, and V. Sindhwani, \u201cManifold regularization: A geometric framework for learning from labeledand unlabeled examples,\u201d Journal of Machine Learning Research,vol. 7, pp. 2399\u20132434, 2006.W. Dai, Q. Yang, G.-R. Xue, and Y. Yu, \u201cBoosting for transferlearning,\u201d in Proceedings of the 24th International Conference onMachine Learning, ser. ICML, 2007.J. Jiang and C. Zhai, \u201cInstance weighting for domain adap-\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 99, NO. PREPRINTS, 20XX[25][26][27][28][29][30][31][32][33][34][35][36][37][38][39][40][41][42]tation in nlp,\u201d in Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, ser. ACL, 2007.W. Dai, G.-R. Xue, Q. Yang, and Y. Yu, \u201cCo-clustering basedclassi\ufb01cation for out-of-domain documents,\u201d in Proceedings ofthe 13th ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining, ser. KDD, 2007.X. Ling, W. Dai, G.-R. Xue, Q. Yang, and Y. Yu, \u201cSpectraldomain-transfer learning,\u201d in Proceedings of the 14th ACMSIGKDD International Conference on Knowledge Discovery andData Mining, ser. KDD, 2008.C. Wang and S. Mahadevan, \u201cHeterogeneous domain adaptation using manifold alignment,\u201d in Proceedings of the 25th AAAIConference on Arti\ufb01cial Intelligence, ser. AAAI, 2011.X. Shi, Q. Liu, W. Fan, and P. S. Yu, \u201cTransfer across completely different feature spaces via spectral embedding,\u201d IEEETransactions on Knowledge and Data Engineering, vol. 25, no. 4,2012.B. Quanz, J. Huan, and M. Mishra, \u201cKnowledge transfer withlow-quality data: A feature extraction issue,\u201d IEEE Transactionson Knowledge and Data Engineering, vol. 24, no. 10, 2012.B. Chen, W. Lam, I. Tsang, and T.-L. Wong, \u201cExtracting discriminative concepts for domain adaptation in text mining,\u201din Proceedings of the 15th ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining, ser. KDD, 2009.H. Daume\u0301 III, A. Kumar, and A. Saha, \u201cCo-regularizationbased semi-supervised domain adaptation,\u201d in Advances inNeural Information Processing Systems, ser. NIPS, 2010.A. Argyriou and T. Evgeniou, \u201cMulti-task feature learning,\u201din Neural Information Processing Systems, ser. NIPS, 2006.Q. Liu, X. Liao, and L. Carin, \u201cSemi-supervised multitasklearning,\u201d in Advances in Neural Information Processing Systems,ser. NIPS, 2007.V. Vapnik, Statistical Learning Theory. John Wiley, 1998.B. Scho\u0308lkopf, R. Herbrich, and A. J. Smola, \u201cA generalized representer theorem,\u201d in Proceedings of the 14th Annual Conferenceon Computational Learning Theory, ser. COLT, 2001.C.-C. Chang and C.-J. Lin, \u201cLIBSVM: A library for supportvector machines,\u201d ACM Transactions on Intelligent Systems andTechnology, vol. 2, 2011, software available at https://www.csie.ntu.edu.tw/\u223ccjlin/libsvm.M. Long, J. Wang, G. Ding, W. Cheng, X. Zhang, and W. Wang,\u201cDual transfer learning,\u201d in Proceedings of the 12th SIAM International Conference on Data Mining, ser. SDM, 2012.S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira, \u201cAnalysisof representations for domain adaptation,\u201d in Advances inNeural Information Processing Systems, ser. NIPS, 2006.R. Johnson and T. Zhang, \u201cGraph-based semi-supervisedlearning and spectral kernel design,\u201d IEEE Transactions onInformation Theory, 2008.J. Gao, W. Fan, J. Jiang, and J. Han, \u201cKnowledge transfervia multiple model local structure mapping,\u201d in Proceedingsof the 14th ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining, ser. KDD, 2008.D. Cai, X. He, J. Han, and T. S. Huang, \u201cGraph regularized nonnegative matrix factorization for data representation,\u201dIEEE Transactions on Pattern Analysis and Machine Intelligence,vol. 33, no. 8, 2011.D. Cai, X. He, and J. Han, \u201cSpectral regression: A uni\ufb01edapproach for sparse subspace learning,\u201d in Proceedings of theIEEE International Conference on Data Mining, ser. ICDM, 2007.Mingsheng Long received the BS degree in2008, from the Department of Electrical Engineering, Tsinghua University, China. He isa PhD candidate in the Department of Computer Science and Technology, Tsinghua University. His research interests are transferlearning, feature learning, large-scale datamining, and unstructured data management.14Jianmin Wang graduated from Peking University, China, in 1990, and received his M.E.and Ph.D. in computer software from Tsinghua University, China, in 1992 and 1995,respectively. He is now a professor at theSchool of Software, Tsinghua University. Hisresearch interests include unstructured datamanagement, work\ufb02ow and BPM technology,benchmark for database system, softwarewatermarking, and mobile digital right management. He has published over 100 DBLPindexed papers in major journals (TKDE, DMKD, DKE, WWWJ, etc)and conferences (SIGMOD, VLDB, ICDE, CVPR, AAAI, etc). He ledto develop a product data/lifecycle management system, which hasbeen implemented in hundreds of enterprizes in China. He leads todevelop an unstructured data management system named LaUDMS.Guiguang Ding received his Ph.D degreein electronic engineering from the Universityof Xidian. He is an associate professor atthe School of Software, Tsinghua University.His current research centers on the area ofmultimedia information retrieval and mining,with speci\ufb01c focus on visual object recognition, automatic semantic annotation, imagecoding and representation, and social mediarecommendation. He has published about 40research papers in international conferencesand journals and applied for 18 Patent Rights in China.Sinno Jialin Pan received the Ph.D. degree in computer science from the HongKong University of Science and Technology(HKUST). He is currently a head (acting) ofthe text analytics lab of the Data Analytics Department at the Institute for InfocommResearch (I2 R), Singapore. He also holds anadjunct position of assistant professor of theDepartment of Computer Science at National University of Singapore (NUS). His mainresearch interests include transfer learning,active learning, semi-supervised learning and theirs applications intext mining, pervasive computing, medical engineering, and softwareengineering.Philip S. Yu received his Ph.D. degree inE.E. from Stanford University. He is a Distinguished Professor in Computer Science atthe University of Illinois at Chicago and holdsthe Wexler Chair in Information Technology.Dr. Yu is a Fellow of the ACM and the IEEE.He is the Editor-in-Chief of ACM Transactions on Knowledge Discovery from Data. Hewas the Editor-in-Chief of IEEE Transactionson Knowledge and Data Engineering (20012004). He received a Research ContributionsAward from IEEE International Conference on Data Mining (2003).\f", "IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 20161177LSDT: Latent Sparse Domain Transfer Learningfor Visual AdaptationLei Zhang, Member, IEEE, Wangmeng Zuo, Senior Member, IEEE, and David Zhang, Fellow, IEEEAbstract\u2014 We propose a novel reconstruction-based transferlearning method called latent sparse domain transfer (LSDT)for domain adaptation and visual categorization of heterogeneous data. For handling cross-domain distribution mismatch,we advocate reconstructing the target domain data with thecombined source and target domain data points based on\u00021 -norm sparse coding. Furthermore, we propose a joint learningmodel for simultaneous optimization of the sparse coding andthe optimal subspace representation. In addition, we generalizethe proposed LSDT model into a kernel-based linear/nonlinearbasis transformation learning framework for tackling nonlinear subspace shifts in reproduced kernel Hilbert space. Theproposed methods have three advantages: 1) the latent spaceand the reconstruction are jointly learned for pursuit of anoptimal subspace transfer; 2) with the theory of sparse subspaceclustering, a few valuable source and target data points areformulated to reconstruct the target data with noise (outliers)from source domain removed during domain adaptation, suchthat the robustness is guaranteed; and 3) a nonlinear projectionof some latent space with kernel is easily generalized for dealingwith highly nonlinear domain shift (e.g., face poses). Extensiveexperiments on several benchmark vision data sets demonstratethat the proposed approaches outperform other state-of-the-artrepresentation-based domain adaptation methods.Index Terms\u2014 Transfer learning, domain adaptation, visualcategorization, heterogeneous data.I. I NTRODUCTIONVISUAL big data bring many challenges to machinelearning and computer vision, e.g. the dilemma of insufficient labeled data. One interesting topic is to enrich thelimited labeled data with relevant data from web or othersources and exploit the unlabeled data by semi-supervisedlearning (SSL) [31], [32]. However, the enriched data fromtarget domain is violated from the training data in sourceManuscript received August 14, 2015; revised December 9, 2015; acceptedJanuary 4, 2016. Date of publication January 12, 2016; date of current versionJanuary 26, 2016. This work was supported in part by the National NaturalScience Foundation of China under Grant 61401048, Grant 61271093, andGrant 61401125, and in part by the Fundamental Research Fund Researchfund for the Central Universities. The associate editor coordinating the reviewof this manuscript and approving it for publication was Prof. Xiaochun Cao.L. Zhang is with the College of Communication Engineering, ChongqingUniversity, Chongqing 400044, China, and also with the Department ofComputing, The Hong Kong Polytechnic University, Hong Kong (e-mail:leizhang@cqu.edu.cn).W. Zuo is with the School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China (e-mail:cswmzuo@gmail.com).D. Zhang is with the Department of Computing, The Hong KongPolytechnic University, Hong Kong (e-mail: csdzhang@comp.polyu.edu.hk).Color versions of one or more of the figures in this paper are availableonline at https://ieeexplore.ieee.org.Digital Object Identifier 10.1109/TIP.2016.2516952domain [33], which leads to significant performance degradation in classification [7]. Domain adaptation, that has thesame goal as transfer learning, aims at transferring knowledge across different but related domains, i.e. P (X S |Y S ) \u0002=P (XT |YT ) [34], [35], where (X S , Y S ) denote the sourcedata matrix and the corresponding label matrix, (XT , YT )represent the target data matrix and label matrix. Physically,such subspace mismatch or domain shift/bias is common invision problems. It often results from a variety of visualcues or abrupt feature changes, such as camera viewpoint,resolution, illumination, color, poses, and background, etc.To this end, various domain adaptation methods have beendeveloped to adapt a model from source to target domain,including representation-based and classifier-based ones. Theformer tends to achieve domain alignment by learning a transformation [8], [14], [15], [19]. The latter advocates learning arobust classifier with X S and XT by introducing some ad-hocregularization [11], [16], [17], [40]. The common practice isto train a classifier on source data and find an optimal decisionboundary on both domains.In this paper, we focus on reconstruction based domainadaptation via latent subspace learning and sparse representation. Recently, a low-rank representation (LRR) based domainadaptation framework has been proposed for knowledge transfer, i.e. RDALR [2] and LTSL [1]. The basic idea of RDALRis illustrated in Fig. 1(a). A rotation W is used to transformthe source data X S , then do alignment by reconstructingthe rotated source data via LRR. However, finding such analignment between WX S and XT may not transfer knowledgedirectly and it is unclear if a test sample is from the sourcedomain or the target. Fig. 1(b) illustrates the basic ideaof LTSL, where the subspace projection W is pre-learnedby using PCA, LDA, etc. Then, the projected source dataWX S is used to reconstruct the projected target data WXTvia LRR. Both methods are inadequate in knowledge transferand subspace alignment, with three reasons as follows.First, in LTSL the subspace is pre-learned and is independent with the reconstruction process, which limits thedomain adaptation performance. Therefore, we propose a jointlearning method for the pursuit of the latent subspace P andreconstruction Z. The joint learning of P and Z makes ourmethod distinctly different with RDALR [2] and LTSL [1] inboth model and algorithm. Experiments on face and objectdatasets show that joint learning improves the recognitionaccuracy by 3% and 17%, respectively.Second, in both RDALR and LTSL, the data in targetdomain are reconstructed with the data in source domain only1057-7149 \u00a9 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.\f1178IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016Fig. 1. Overview of the existing reconstruction guided knowledge transfer methods and our method. (a) Idea of RDALR. (b) Idea of LTSL. (c) Idea ofour method.by using LRR [4]. Two noteworthy things include: (i) LRRwas suggested to get the block diagonal solution for subspacesegmentation. However, trivial solution will be obtained whenhandling the disjoint subspace and insufficient data. Moreover,LRR based domain adaptation is with a strong independentsubspace assumption. Different from LRR, sparse subspaceclustering (SSC) [3], [21], [37] is for data points that lie in aunion of low-dimensional subspaces, where a sparse matrix Zis learned by minimizing \u0003X \u2212 XZ\u0003F . Compared with LRR,SSC can be scalable [43] and multi-view [45], and wellsupported by both theoretical analysis [37] and experimentalresults [3] in handling the data points near the intersections ofsubspaces. Therefore, in light of the multi-source data lyingin different space, we are inspired to reconstruct the targetdata XT with the source data X S by learning a sparse Z.With face and object datasets, an increment of 2% and 6.4%recognition accuracy is achieved by using SSC-based reconstruction. (ii) For RDALR and LTSL, the target data XT arereconstructed by solely using the source data X S . When onlyvery few source data is available, better reconstructioncan\u0003\u0002be obtained by grouping the target data i.e. X = X S,XTas \u201cdictionary\u201d. Fortunately, with the SSC theory [37], wecan use both X S and XT for reconstructing the target dataand avoid the trivial solution. The experiments on face andobject datasets demonstrate that 4.7% and 9.7% increments ofrecognition accuracy are achieved by comparing with that ofusing source data only.Third, the existing methods work as a linear framework,and cannot tackle the nonlinear shifts in real-world visionproblems. Therefore, it is valuable to develop a nonlinearreconstruction guided subspace transfer framework. In thiswork, we generalize our model to tackle nonlinear shiftsin Reproduced Kernel Hilbert Space. The experiments onface and object datasets demonstrate that our method is7.7% and 6.3% higher than linear ones in recognition accuracy,respectively.In this paper, following the subspace reconstruction guideddomain adaptation framework, we propose a sparse reconstruction method in the learned latent space between the sourcedata X S and the target data XT . It tries to account for noisein data corruption and removes outliers, with their intrinsicrelatedness preserved. More formally, we name the proposedmethod as latent sparse domain transfer (LSDT), which aimsto learn a sparse reconstruction coefficient matrix betweendomains in some latent space for domain adaptation. Thebasic idea of LSDT is illustrated in Fig. 1(c). Compared withRDALR and LTSL, our LSDT can jointly learn the latent spaceP and the SSC-based reconstruction Z, and the target dataXT is reconstructed with the group data of X S and XT , suchthat the source and target data lie in a shared latent space withdomain shift/bias removed.In summary, the key contributions of this work are threefold.- The latent space projection P and the sparse reconstruction coefficient matrix Z are simultaneously learnt via ajoint learning mechanism, which can achieve an optimalsubspace representation. The sparse property implies thatonly a few data points from source domain are selectedfor subspace transfer and overcomes the overfittingproblem.- The sparse subspace clustering (SSC) is introduced forreconstruction guided domain adaptation. The combinedsource and target data are used to reconstruct the targetdomain, which can better span the entire feature spacethan the under-complete source data only. In particular,the trivial solution can be avoided by using SSC insteadof LRR.- Induced by Mercer kernel theorem, the proposed methodis generalized as a nonlinear method, in which the domainadaptation is employed in a reproduced kernel Hilbertspace (RKHS) for handling nonlinear domain shift.A. Paper OrganizationThis paper is organized as follows. In Section 2, we givea brief overview of the related work in domain adaptation.The proposed latent sparse domain transfer method isillustrated in Section 3. The proposed nonlinear LSDT ispresented in Section 4. The experimental results for severaldomain adaptation based vision tasks are shown in Section 5.\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION1179The in-depth discussion of the proposed methods is illustratedin Section 6. Section 7 concludes the paper.II. R ELATED W ORKSDomain adaptation can be performed in either representation level or classifier level [9], [10], [12], [14]\u2013[17], [36].In classifier based adaptation, Yang et al. [12] proposed anadaptive SVM (ASVM) where the source classifier f S (x)was adapted to the target classifier f T (x) by learning aperturbation \u0002 f (x), such that f T (x) = f S (x) + \u0002 f (x).Similarly, Duan et al. [16] proposed an adaptive multiplekernel learning (AMKL) for consumer video event recognitionfrom annotated web videos. Zhang and Zhang [36] proposeda DA framework with two error terms based on \u00032 -normregularization. However, for classifier-based methods, the labelinformation of source and target domains should be used forlearning a target classifier.To learn a better data representation for adaptation withoutlabels used, Gong et al. [10] proposed an unsupervised domainadaptation method (GFK), in which geodesic flow kernel isused to model the domain shift by integrating an infinitenumber of subspaces where the changes in geometric andstatistical properties are characterized. Gopalan et al. [8] alsoproposed an unsupervised method (SGF) for low dimensionalsubspace transfer. The idea behind SGF is that it samples agroup of subspaces along the geodesic between source andtarget data, and project the source data into the subspaces fordiscriminative classifier learning. Shekhar et al. [6] proposeda shared domain dictionary learning (SDDL), which assumesthat the knowledge of two domains can be integrated into onedictionary D. However, the label information of source andtarget data is still required, while the proposed method doesnot need the label information during cross-domain learning.In [44], Lin et al. proposed a dynamic spatio-temporal subspace i.e. STDM, for background subtraction, where incremental subspace learning and analytical linear reconstructionare used to maintain the dynamic space.In reconstruction based adaptation, RDALR and LTSL thatare most structurally relevant with this paper were proposedby Jhuo et al. [2] and Shao et al. [1], respectively, in whichlow rank representation (LRR) is used for subspace transfer.A brief overview of RDALR and LTSL is introduced asfollows.A. Robust Domain Adaptation via Low Rank (RDALR) [2]RDALR shown in Fig. 1(a) addresses the domain adaptationproblem by minimizing the following objective functionmin r ank (Z) + \u03b1 \u0003E\u00032,1W,Z,Es.t. WX S = XT Z + E, WWT = I(1)where rank(\u00b7) represents the rank of a matrix, \u0003E\u00032,1 denotes\u00032,1 -norm, and \u03b1 is the regularization coefficient. The constraint WWT = I is introduced to learn an orthogonaltransformation matrix. The term \u0003E\u00032,1 is used to encouragethe error columns of E to be 0, such that noise or outliers in source domain can be removed during adaptation.While minimization of rank(Z) tends to find a reconstructioncoefficient matrix with the lowest rank structure. In optimization, due to the discrete nature of rank function, nuclear normor trace norm (i.e. the sum of singular values of the matrix)is generally adopted as a proper surrogate of the rank. Then,inexact Augmented Lagrange Multiplier (ALM) [22] can beused for solving problem (1).B. Low-Rank Transfer Subspace Learning (LTSL) [1]Similarly but different in nature from RADLR, LTSL shownin Fig. 1(b) addresses the subspace transfer problem byminimizing the following objective functionmin F (W, X S ) + \u03bb1r ank (Z) + \u03bb2 \u0003E\u00032,1W,Z,Es.t. WT XT = WT X S Z + E, WT U2 W = I(2)where F (W, X S ) is a generalizedsubspacelearning function\u0005\u0004which can be written as T r WT U1 W , U1 and U2 are selectedbased on the conventional subspace learning model, such asPCA, LDA, etc. Given fixed W, inexact ALM under convexsurrogate of rank function can be used to solve problem (2),which is similar to (1). There are three main differencesbetween LTSL and RDALR:\u2022 RDALR tends to reconstruct the rotated source data X Sby using target data XT . While LTSL attempts to reconstruct the target data using the source data in the learnedsubspace.\u2022 RDALR first use W to rotate the source data, and performthe data alignment in the original space of target data.While LTSL aims to find a subspace alignment betweenX S and XT .\u2022 A subspace learning function is embedded into LTSL forlearning a transformation W with discriminative property.In summary, both RDALR and LTSL perform the domainadaptation using LRR. The former presents to data alignmentby leveraging LRR and provides some valuable insight fordomain adaptation. LTSL performs adaptation in some prelearned subspace, and presents a more complete theoretical andsubspace analysis for knowledge adaptation. As mentioned,Liu et al. [4] and Elhamifar and Vidal [21] proved that LRRperforms well when the subspaces are independent and thedata sampling is sufficient.However, this assumption is difficult to hold in crossdomain vision problems (i.e. data distribution mismatch).Following the representation based adaptation, our proposedmethod attempts to use SSC based sparse reconstructionfor subspace transfer while avoiding such strong low-rankassumption. More advantageously, the proposed method cansimultaneously learn a linear/nonlinear basis transformationfor subspace projection and a sparse reconstruction matrixwith stronger robustness. It can prohibit the noise or outliersin source domain from transferring to target domain and alsoavoid overfiting in reconstruction, especially when the numberof source data and target data is not sufficient. The proposedmethod is different from LTSL in three aspects. (i) The jointlearning of subspace and reconstruction. (ii) Sparse reconstruction based on SSC using combined source and target data.\f1180IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016Fig. 2.Flowchart of the training and testing phase of the proposed LSDT method for visual categorization.(iii) Kernel based nonlinear domain adaptation. Fig. 2 illustrates the flowchart of the proposed method for heterogeneousimage classification.By combining (3) and (4) together, the final formulation ofthe proposed LSDT method is represented as followsmin \u0003Z\u00031 + \u03bb1 \u0003PXT \u2212 P [X S , XT ] Z\u00032FZ,P\u00062\u0006\u0006\u0006+ \u03bb2 \u0006[X S , XT ] \u2212 PT P [X S , XT ]\u0006III. L ATENT S PARSE D OMAIN T RANSFER L EARNINGFA. NotationsIn this paper, the source and target domain are definedby subscript \u201cS\u201d and \u201cT ,\u201d respectively. The training dataof source and target domain is denoted as X S \u2208 R D\u00d7N Sand XT \u2208 R D\u00d7NT , respectively, where D is the number ofdimensions, N S and NT are the number of training samplesin both domains. XT l \u2208 R D\u00d7NT l and XT u \u2208 R D\u00d7NT u denotethe few labeled and most unlabeled data of target domain.Let P \u2208 Rd\u00d7D represents a basis transformation. The sparsereconstruction matrix between X S and XT is denoted as Z.1n denotes a full-one column vector with length ofn and I denotes an identity matrix. \u0003\u00b7\u00030 counts the numberof nonzero elements of a vector, \u0003\u00b7\u0003 p ( p = 0, 1 or 2)denotes \u0003 p -norm, and \u0003\u00b7\u0003F denote Frobenius norm of a matrix.[X]i denotes the i -th column of X. Note that matrix and vectoris in capital and lower bold face, and variable is in italics.B. Problem FormulationAs illustrated in Fig. 1, we aim to learn a reconstructioncoefficient matrix Z for representing target data XT by usingitself and source data X S together in some latent spaceprojected by a pre-defined basis transformation P. Therefore,the optimization problem can be formulated asmin \u0003PXT \u2212 P [X S , XT ] Z\u00032F ,Zs.t. \u0003Z\u00030 \u2264 T0(3)where Z \u2208 \u0006(N S +NT )\u00d7NT , T0 is the sparsity level. Due tothat \u00030 -norm based optimization is non-convex, in this paper,\u00031 -norm is used in the proposed model.For learning such a basis transformation P which can ensurethat the projection does not distort the data and can remain toomuch available information, the following term is integrated,\u00062\u0006\u0006\u0006min \u0006[X S , XT ] \u2212 PT P [X S , XT ]\u0006(4)PFs.t. PPT = I, 1TN S +NT Z = 1TNT , Z N S +i,i = 0,\u2200i = 1, \u00b7 \u00b7 \u00b7 , NT(5)where the rows of P are required to be orthogonal andnormalized to unit norm for preventing the solution degenerateinto zero by enforcing PPT = I. Additionally, we also impose1TN S +NT Z = 1TNT for addressing the problem that source andtarget data lie in a union of affine subspaces instead of linearsubspaces. \u03bb1 and \u03bb2 denote the tradeoff parameters.For simplification, we let X = [X S , XT ] \u2208 \u0006 D\u00d7N then theobjective function of problem (5) can be written asJ1 (P, Z, XT , X) = \u0003Z\u00031 + \u03bb1 \u0003PXT \u2212 PXZ\u00032F\u00062\u0006\u0006\u0006+ \u03bb2 \u0006X \u2212 PT PX\u0006F(6)One proposition on the basis transformation P is as follows.Proposition 1: There exists an optimal solution P\u2217 that canbe intuitively represented as a linear combination of raw sourceand target data X for some \u0003 \u2208 R N\u00d7d in the following formP \u2217 = \u0003T X T(7)Note that Proposition 1 has also been used in subspace clustering and dictionary learning [6], [13]. With Proposition 1,by substituting (7) into (6), the objective function is written as\u00062\u0006\u0006\u0006J2 (\u0003, Z, XT , X) = \u0003Z\u00031 + \u03bb1 \u0006\u0003T XT XT \u2212 \u0003T XT XZ\u0006F\u00062\u0006\u0006T T \u0006+ \u03bb2 \u0006X \u2212 X\u0003\u0003 X X\u0006(8)FLet KT = XT XT , K = XT X, then the proposed method (5)can be illustrated as follows\u0006\u0006\u00062\u00062\u0006\u0006\u0006\u0006min \u0003Z\u00031 + \u03bb1 \u0006\u0003T KT \u2212 \u0003T KZ\u0006 + \u03bb2 \u0006X \u2212 X\u0003\u0003T K\u0006Z,\u0003s.t. \u0003 K\u0003 = I,T1TN S +NT Z=FT1 NT ,Z N S +i,i = 0 \u2200i = 1, \u00b7 \u00b7 \u00b7 , NTF(9)\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION1181Algorithm 1 Solving Problem (10) by ADMMAlgorithm 2 Solving Problem (11) by Proposition 22) Update \u03a6: For solving \u0003, the minimization problem (9)after fixing Z can be written as\u00062\u00062\u0006\u0006\u0006\u0006\u0006\u0006min \u03bb1 \u0006\u0003T KT \u2212 \u0003T KZ\u0006 + \u03bb2 \u0006X \u2212 X\u0003\u0003T K\u0006\u0003Fs.t. \u0003 K\u0003 = ITF(11)We have the following proposition for solving \u0003 in (11).Proposition 2: When Z is fixed, the optimal solution of (11)is computed as\u0003\u2217 = VS\u2212 2 \u0004\u22171where V and S are from the eigen-decomposition ofK = VSVT , and \u0004\u2217 is the optimal solution of the followingproblem\u0004\u0005\u0004\u2217 = arg min T r \u0004T \u0005\u0004 , s.t. \u0004T \u0004 = I\u0004From (9), it is observed that a nonlinear framework of LSDTcan be deducted by using a nonlinear mapping function \u03d5. Thedetails can be referred as Section IV.For our LSDT model in Eq. (5), when fixed P, the subproblem on Z shares similar formulation with SSC [3] andRSC [37]. Based on the theoretical results in [37], our LSDTmodel is also feasible in recovering the underlying subspacestructures. However, the model in Eq. (5) is non-convex,making it difficult to extend the theoretical results [37] to thefull LSDT model.C. OptimizationIt can be seen from problem (9) that two variables areinvolved. To solve this minimization, alternative optimizationstrategy that solve one variable while fixing the other one isconsidered. Therefore, two main steps are included.1) Update Z: For solving Z, one can fix \u0003, then theminimization problem (9) with respect to Z becomes\u00062\u0006\u0006\u0006min \u0003Z\u00031 + \u03bb1 \u0006\u0003T KT \u2212 \u0003T KZ\u0006ZFs.t. 1TN S +NT Z = 1TNT , Z N S +i,i = 0, \u2200i = 1, \u00b7 \u00b7 \u00b7 , NT(10)This is a typical sparse Lasso optimization problem withlinear equality constraints, and can be efficiently solved byusing alternative direction multiplier method (ADMM) in [3].A full description of ADMM can be referred as [26] forinterested readers. The solving process of problem (10) byusing ADMM is outlined in Algorithm 1. The deduction forsolving Z can be found in Appendix A.The optimization of problem (11) is outlined in Algorithm 2.The deduction of the proposition 2 can be foundin Appendix B.In summary, with the two updating steps for Z and \u0003 basedon Algorithm 1 and Algorithm 2, the complete optimizationof the proposed LSDT method is illustrated in Algorithm 3.D. Remarks on the ConvergenceFrom the viewpoint of optimization, the proposed LSDT isnon-convex w.r.t. Z and \u0003, but the global solution of eachwhen fixing the other can be solved. The local optimum ofthe model can be guaranteed using the proposed optimizationmethod. The convergence is shown in the Discussion part(please see Fig. 8c). After 5 iterations, a local optimum canbe achieved for two datasets, as an example.From the level of approach, by comparing to LTSL [1], itpre-learns a transformation P using PCA or LDA, then solvesthe Z by using low-rank constraint, such that the performancemust be sub-optimal with the pre-learned P as a warm startwithout update. To overcome the flaw of such a suboptimal P,The proposed method aims at learning P and Z simultaneouslyby using an alternating optimization strategy, such that betterperformance can be expected.E. Computational ComplexityAlgorithm 3 includes two steps: update Z (Algorithm 1)and update \u0003 (Algorithm 2). For Algorithm 1 (i.e. ADMM),suppose that the number of iterations is T1 , the complexityof computing L is O(T1 N 3 ) and the complexity of computing Z is O(T1 N 2 ). Therefore, the computational complexity\f1182IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016Algorithm 3 The Proposed LSDTAlgorithm 4 The Proposed NLSDTof Algorithm 1 is O(T1 N 3 ) + O(T1 N 2 ). For Algorithm 2, theeigen-decomposition and matrix multiplication are involved,with the computational complexity of O(N 3 ). Suppose thatthe number of iterations in Algorithm 3 is T , then thetotal computational complexity of LSDT can be expressedas O(TT 1 N 3 ) + O(TT 1 N 2 ) + O(TN 3 ).NLSDT can be written as\u00062\u0006\u0006\u0006min \u0003Z\u00031 + \u03bb1 \u0006\u0003T KT \u2212 \u0003T KZ\u0006FZ,\u0003\u0007\b\bT+ \u03bb2 T r I \u2212 \u0003\u0003T K K I \u2212 \u0003\u0003T KIV. N ONLINEAR D OMAIN T RANSFER L EARNINGA. Formulation of NLSDTs.t. \u0003T K\u0003 = I, 1TN S +NT Z = 1TNT ,Z N S +i,i = 0 \u2200i = 1, \u00b7 \u00b7 \u00b7 , NT .(14)B. Optimization AlgorithmIn LSDT, a linear transformation P is exploited for latentsubspace learning. Naturally, NLSDT is a nonlinear extensionof LSDT by mapping the data from original space R Dto the reproducing kernel Hilbert space (RKHS) H, thatis defined as \u03d5 : R D \u2192 H, induced by Mercer kernel.In RKHS, a nonlinear transformation P is learned to handlenonlinear domain bias, such as rotation of poses in facerecognition.For introducing the framework of NLSDT, we first definethe kernel gram matrix,\u0004 whichis denoted \u0004as \u0005the matrixK,\u0005\u0004\u0005and [K]i, j = \u03d5 (xi ), \u03d5 x j H = \u03d5 (xi )T \u03d5 x j = \u03ba xi , x j ,where \u03ba is a kernel function. Similar to LSDT, the objectivefunction of NLSDT can be formulated asJ (P, Z, XT , X) = \u0003Z\u00031 + \u03bb1 \u0003P\u03d5 (XT ) \u2212 P\u03d5 (X) Z\u00032F\u00062\u0006\u0006\u0006+ \u03bb2 \u0006\u03d5 (X) \u2212 PT P\u03d5 (X)\u0006(12)FBased on Proposition 1, the optimal mapping P\u2217 can berepresented as P\u2217 = \u0003T \u03d5 (X)T . The objection (12) becomesThe optimization algorithm of NLSDT is similar withLSDT shown in Algorithm 1, in terms of Proposition 1 andProposition 2. From the models (9) and (14), we can observethat LSDT is in fact a special case of NLSDT when a linearkernel function is used to compute KT and K. In NLSDT,Gaussian RBF function, sigmoid function, etc. can be used askernel function. The NLSDT is illustrated in Algorithm 4.C. ClassificationWith the case of NLSDT, the classification scheme in thispaper consists of the following steps:\u2022 Compute the latent subspace embedding M S of sourcedata X S using the projection P\u2217 , as M S = P\u2217 \u03d5 (X S ).\u2022 Compute the latent subspace embedding MT l of thelabeled target training data XT l using the learnedprojection P\u2217 and sparse reconstruction Z, asMT l = P\u2217 \u03d5 (X) Z.\u2022 Compute the latent subspace embedding MT u of theseunlabeled target test data XT u as MT u = P\u2217 \u03d5 (XT u ).\u2022 Train a classifier W using \u00032 -norm regularized leastsquare method on the\u0002 labeled\u0003 training data [M S , MT l ]Tand label matrix Y = YTS , YTT l , where [Y]i, j = 1 if theclass j is assigned to the i -th sample, and \u22121 otherwise.\u2022 The decision labels of unlabeled target test data areobtained by computing MTT u W.J (P, Z, XT , X)\u00062\u0006\u0006\u0006= \u0003Z\u00031 + \u03bb1 \u0006\u0003T \u03d5 (X)T \u03d5 (XT ) \u2212 \u0003T \u03d5 (X)T \u03d5 (X) Z\u0006F\u00062\u0006\u0006\u0006+ \u03bb2 \u0006\u03d5 (X) \u2212 \u03d5 (X) \u0003\u0003T \u03d5 (X)T \u03d5 (X)\u0006F\u00062\u0006\u0006\u0006 TT= \u0003Z\u00031 + \u03bb1 \u0006\u0003 KT \u2212 \u0003 KZ\u0006F\u0006\u00062\u0006T \u0006+ \u03bb2 \u0006\u03d5 (X) \u2212 \u03d5 (X) \u0003\u0003 K\u0006(13)A. Synthetic Datawhere KT = \u03d5 (X)T \u03d5 (XT ) and K = \u03d5 (X)T \u03d5 (X) denote thekernel Gram matrix. Therefore, the minimization problem ofIn this section, we use the generated toy data for latentsubspace alignment by our method. The 3-dimensional source,few labeled target data and unlabeled target data with twoFV. E XPERIMENTS\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION1183TABLE I3DA AND 4DA B ENCHMARK D ATASETS FOR V ISUALD OMAIN A DAPTATION IN E XPERIMENTSFig. 3. The 3D illustration of synthetic data (left) and 2D illustration aftersubspace alignment (right).classes generated by Gaussian distributions of different meansand covariance matrices are shown in Fig. 3 (left). Each classin source domain contains 50 samples and it is easy to finda decision boundary of the two classes in source domain.In target domain, there are 5 labeled samples and 50 unlabeledsamples for each class. From the figure, it is clearly observedthat: 1) the data points of the same class between source andtarget domain have very different distribution; 2) the classification hyper-plane of source domain does not fit the decisionboundary of target domain. Therefore, how to determine onerobust decision boundary becomes very challenging.The proposed LSDT aims to find a latent space with domainadaptation, such that both domains can have similar distribution and better separable ability in the latent space. By usingthe proposed LSDT method, the source data and target datain the 2D subspace after projection and reconstruction canbe seen in Fig. 3 (right). We can observe that the subspacemismatch between source data and target data is reduced afterLSDT, and the decision boundary between the two classesis clear and easily to find with a general classifier. The toydata primarily demonstrates the effectiveness of our method inlatent subspace alignment for representation based adaptation.B. Object RecognitionIn this section, cross-domain object recognition is discussed.1) Experimental Setup: In experiments, we test our methodsin two visual benchmark datasets: 3DA and 4DA of objects,which are widely used for domain adaptation. Besides, thedeep features of 4DA datasets based on convolutional neuralnetwork (CNN) [38] are also exploited for object recognition.Specifically, the 3DA, 4DA and 4DA-CNN datasets andfeatures are illustrated as follows.a) 3DA (Amazon, DSLR and Webcam domain adaptation [9]): In the 3DA dataset, each domain contains 31 objectclasses, such as back-pack, keyboard, earphone, etc. By following the setting in [9], if Amazon is experimented as sourcedomain, 20 samples per class are selected for training, and8 samples are selected if DSLR or Webcam is source domain.For target domain, 3 training samples per class are selectedand the rest data in the target domain is used for testing. Thedetail of 3DA dataset is summarized in Table I.b) 4DA (Amazon, DSLR, Webcam and Caltech 256 [10]):For 4DA dataset, four domains are included, where eachdomain contains 10 common object classes rather than31 selected from 3DA dataset and an extra Caltech 256dataset [11]. In experiments, we follow the configurationin [10] where 20 samples per class are selected from Amazon,and 8 samples per class are randomly selected from DSLR,Webcam and Caltech if they are source domains, while3 samples per category are selected if they are target domains,and the rest data in target domain is used for testing. Thedetail of 4DA dataset is also summarized in Table I. Notethat, the 800-bin SURF features provided in [9] and [10] foreach domain are used.c) 4DA-CNN (Amazon, DSLR, Webcam and Caltech 256domain adaptation [10], [39]): For the 4DA-CNN setting,8 layers with 5 convolutional layers and 3 fully connectedlayers of CNN were trained on ImageNet in [38]. The welltrained CNN structure and parameters are used by taking the4DA dataset as input of CNN [39]. The outputs of the 6th and7th layer (i.e. DeCAF) are used. The feature dimension afterCNN is 4096. More details of the architecture and trainingprotocol can be referred to [38] and [39].d) Parameter setting: For LSDT method, the tradeoff coefficients \u03bb1 and \u03bb2 are fixed to be 1\u0004 in exper\u0005iments.the Gaussian function \u03ba xi , x j =\b \u0006For NLSDT,\u00062exp \u2212 \u0006xi \u2212 x j \u0006 /2\u03c3 2 is used, and the kernel parameter \u03c3is tuned for the best result. The \u00032 -norm regularized leastsquare method is used for classifier training.2) 3DA Experiment: We strictly follow the experimentalconfiguration by Saenko et al. [9]. 20 random splits oftraining data in source and target domain are implementedand the mean accuracies over 31 categories are reported.The experiments are employed in single source domain andmultiple source domains adaptation, respectively. In this experiment, we compare with five methods including ASVM [12],GFK [10], SGF [8], SA [41], RDALR [2], LTSL-PCA [1] andLTSL-LDA [1]. The experimental results of single sourcedomain and multiple source domains adaptation are shownin Table II.From the results, we can observe that LSDT with nonlinearkernel function performs much better results than other methods for single source domain adaptation. For multiple sourcedomain adaptation, both LSDT and NLSDT outperform othermethods. However, NLSDT is a little weak compared to thelinear method. Note that partial results of other methods arequoted from [1] and [2].Additionally, in Table II, the LTSL-PCA is better thanLTSL-LDA a. Note that LTSL outperforms RDALR methodwith a large margin which shows that the subspace learning\f1184IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016TABLE IIR ECOGNITION A CCURACY (%) OF S INGLE -S OURCE AND M ULTI -S OURCE D OMAIN A DAPTATION IN 3DA S ETTINGTABLE IIIR ECOGNITION A CCURACY (%) OF D IFFERENT D OMAIN A DAPTATION OVER 10 O BJECT C ATEGORIES IN 4DA S ETTINGis beneficial to domain transfer. Therefore, in the subsequentexperiments, LTSL as low-rank based subspace adaptation iscompared, instead of RDALR.3) 4DA Experiment: In this experiment, we strictly followthe experimental setting by Gong et al. [10]. There are fourdomains, and therefore 12 combinations of each two domainsare discussed. 20 random splits of training data in sourceand target domain are used for all methods, and the meanclassification accuracies over 10 object categories are reportedin Table III. Note that A: Amazon, D: DSLR, W: Webcam,C: Caltech 256. We have compared to existing methodsincluding Na\u00efveComb, ARC-t [15], sampling geodesicflow (SGF) [8], geodesic flow kernel (GFK) [10], domainadaptation machine (DAM) [18], max-margin domain transforms (MMDT) [14], Symm [19], SA [41], DIP [42] andLTSL [1]. From the results, we can observe that NLSDTperforms much better than state-of-the-art LTSL results andis also superior to other methods. Particularly, the average performance over 12 different tasks of our NLSDT isabout 5% improvement compared to LTSL. We can also seethat for LTSL, LDA is better than PCA for subspace learning.Additionally, the results also demonstrate that nonlinearmethod is effective for domain adaptation, since nonlinear shiftmay occur in data acquisition.4) 4DA-CNN Experiment: The experimental setting is thesame as 4DA setting, but with CNN features. The comparison results with state-of-the-art representation based domainadaptation methods such as SGF [8], GFK [10], SA [41],LTSL-PCA [1] and LTSL-LDA [1], are reported in Table IV.Note that SourceOnly denotes the results trained by SVMon the source data, Na\u00efveComb denotes the baseline methodlearned by SVM on the combined source and target trainingdata. From Table IV, we observe that: 1) the total classificationperformance is well improved by using deep feature representation, for example, the classification accuracy increases from83.5% to 98.7% for \u201cD\u2192W\u201d setting by using our NLSDTmethod, which show that the deep feature representation caneffectively remove the domain shift or bias; 2) LSDT andNLSDT have similar performance on deep features, whichimplies the linearly separable ability of the high-level deeprepresentation; 3) the proposed methods still outperform othermethods; 4) the output features of the 6th and 7th layer havecomparative performance in object recognition.C. Consumer & YouTube Video Event RecognitionIn this experiment, the dataset used for video event recognition is the YouTube videos & Consumer videos developedin [16], in which part of consumer videos were from KodakConsumer video benchmark dataset [27] and part from realusers. Considering that in real applications the labeled samples of consumer videos are usually fewer than the labeledweb videos, the web videos of low-resolution from YouTubewebsite are used as source data, while the consumer videos ofhigh-resolution are used as target data in experiments.By following [16], six visual events including \u201cbirthday,\u201d\u201cpicnic,\u201d \u201cparade,\u201d \u201cshow,\u201d \u201csports,\u201d and \u201cwedding\u201d areincluded. The total number of YouTube videos and Consumervideos is 906 and 195, respectively. For source domain, all906 YouTube web videos are used as labeled source data. Fortarget domain, we randomly selected m (m = 1, 3, 5, 7, 10)consumer videos per event as the labeled target training data,\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION1185TABLE IVR ECOGNITION A CCURACY (%) OVER 10 O BJECT C ATEGORIES IN 4DA-CNN S ETTING W ITH D EEP F EATURE R EPRESENTATIONTABLE VC LASSIFICATION A CCURACY (%) OVER 6 V ISUAL E VENTS W ITH D IFFERENT N UMBER OF L ABELED TARGET V IDEOS PER E VENTand the remaining consumer videos are used as unlabeled datafor evaluation. We sample the labeled target training videos5 times, the means and standard deviations of classificationaccuracies are reported.As described in [16], two types of features, ST feature [28]and SIFT feature [29] are used. For ST feature, 72D HOGand 90D HOF features are concatenated as a 162D vector.For each frame (65 frames per video), 128D SIFT featuresare extracted from salient regions detected by DoG interest point detector [30]. Finally, the visual vocabularies viak-means are built for feature clustering. The features can beobtained from [16].In experiment, we have compared our proposed methodwith two classifier based transfer learning methods such asA-MKL [16] and DTSVM (DTMKL) [17] which report thestate-of-the-art results on this dataset, and three representationbased domain adaptation methods such as GFK [10],SGF [8] and LTSL [1] coupled with PCA and LDA. Thebasic idea of A-MKL method is to learn the target classifierPSf T (x) with the optimal combinationp=1 \u03b2 p f p (x)of P source classifiers plus a learned perturbationM\u0002 f (x) =m=1 dm wm \u03d5m (x) + b based on multiplekernels. The basic idea of DTSVM (DTMKL) tends to learnMtarget decision function f T (x) =m=1 dm wm \u03d5m (x) + bwithout considering the optimal combination of pre-learnedsource classifiers involved in A-MKL. We also compared thebaseline method (i.e. Na\u00efveComb) trained by SVM.We have studied the recognition performance by leveragingdifferent number m (m = 1, 3, 5, 7, 10) of labeled videos perevent from consumer videos (target domain). The recognitionaccuracies over 6 visual events based on three types of lowlevel features are reported in Table V. From the results, wecan find that the proposed LSDT method with nonlinearGaussian kernel outperforms other methods. Fig. 4 describesthe recognition accuracy of all methods with the increasingnumber m of labeled videos per event. From the plots withdifferent features, we can observe that the proposed LSDTand NLSDT methods still perform the best results.D. CMU Multi-PIE DataThe CMU Multi-PIE face dataset [23] is a comprehensiveface dataset of 337 subjects, in which the images are captured across 15 poses, 20 illuminations, 6 expressions and4 different sessions. For our purpose, we select the first\f1186IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016Fig. 4. Recognition accuracy with different number of labeled videos per-event selected from target domain. (a) SIFT feature. (b) ST feature. (c) SIFT+STfeatures.Fig. 5. Example images of one subject. Session 1 (the 1st row with neutralexpression) and Session 2 (the 2nd row with smile expression).Fig. 7. Examples of the learned basis transformation P by NLSDT underSession 2. Each subplot represents a row of P.Fig. 6.Pose alignment of Session 2 by the proposed NLSDT method.60 subjects from session 1 and session 2 in experiments.Session 1 contains 7 images per subject with 7 poses underneutral expression, while session 2 was prepared with the sameposes as session 1 but under smile expression. The exampleimages of one subject in session 1 and session 2 are illustratedin Fig. 5. In this experiment, four experimental configurationsare as follows.- Session 1: one frontal face in red Rectangle and one60\u00b0 posed face in blue per subject are used as source andtarget training data, respectively. The remaining faces areprobe faces.- Session 2: the same configuration as session 1 isconducted.- Session 1 + 2: Two frontal faces and two faces withextreme 60\u00b0 pose from both sessions are used as trainingdata. The remaining faces are used as probe faces.- Cross Session: The faces per subject in session 1 withneural expression are taken as source domain, while thefaces per subject in session 2 with smile expression aretaken as target domain. This is to adapt the change ofexpression.Pose alignment is challenging due to the highly non-linearchanges induced by 3D rotation of a face. Fig. 6 illustrates thepose alignment process under Session 2 with smile expressionby the proposed NLSDT, where the frontal faces per subjectin red Rectangle are used as source data, and the faces with60\u00b0 poses in the blue Rectangle are used as target data foreach session. From Fig. 6, we can observe that the target faceunder pose is well aligned with residual (noise) removed.The best face recognition rates under the four experimental configurations by using different methods are shownin Table VI. From the results, we can see that the proposed NLSDT significantly outperforms other state-of-the-artmethods. This demonstrates that linear subspace transfer maynot work for nonlinear rotation. Fig. 7 shows the learnedbasis P on Session 2. Each subplot corresponds to a row of P.The first 60 subplots denote the frontal source faces and thelast 60 subplots show the target faces with 60\u00b0 pose, fromwhich we can observe that the target faces across poses canbe aligned.E. Handwritten Digits DataIn this section, three handwritten digits datasets including MNIST [24], USPS [25] and SEMEION [25] are usedfor cross-domain learning experiments, and the classificationaccuracies over 10 classes from digit 0 to digit 9 are reportedfor different tasks. The MNIST handwritten digits datasethas 70,000 instances with each image size of 28 \u00d7 28, theUSPS dataset contains 9298 examples with each image sizeof 16 \u00d7 16, and 2593 images of size 16 \u00d7 16 are includedin SEMEION dataset. For dimension consistency, the size ofMNIST digit images is manually resized into 16 \u00d7 16.In experiment, cross-domain tests are explored. Specifically,each dataset will be recognized to be source and target domainalternatively. Therefore, 6 combinations of cross-domain taskare experimented. For the purpose of our experiments, werandomly select 100 samples per class from source domainfor training and 10 samples per class from target domain fortesting. 5 random splits are used and the mean accuraciesvia nearest neighbor classifier with the best parameter tuningare reported in Table VII, in which A-SVM [12], SGF [8],GFK [10], SA [41] and LTSL [1] are compared with ourproposed NLSDT method with Gaussian kernel functionused.\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION1187TABLE VIC OMPARISON W ITH O THER M ETHODS FOR FACE R ECOGNITION A CROSS P OSESTABLE VIIH ANDWRITTEN D IGITS R ECOGNITION P ERFORMANCE A CROSS D OMAINSconverge to one minimum value after 3 iterations, whichdemonstrates the efficiency of optimization.B. Parameter Sensitivity Analysis of LSDTFig. 8. Performance with subspace dimension d (a), kernel parameter \u03c3 (b),and objective function with iteration t (c) on CMU Multi-PIE (a1 , b1 and c1 )and Handwritten digits (a2 , b2 and c2 ). The stair curve in each subplotcorresponds to the green curve.From the results, we can see that the proposed methodoutperforms other methods. The average improvement in accuracy is about 10% and 5% compared to the two methods,respectively. This demonstrates that the proposed NLSDTsucceeds in dealing with highly nonlinear domain shift/bias.VI. D ISCUSSIONA. Subspace Dimension, Kernel Parameter, and ConvergenceThis paper aims to learn a latent low dimensional subspacefor representation based adaptation. For showing the performance with subspace dimension variation, we conduct theexperiments on multi-PIE face data with Session 1 as sourceand Session 2 as target and handwritten digit data with USPSdigits as source and SEMEION digits as target. Fig. 8 illustrates the performance of our method with increasing numberof subspace dimension d, kernel parameter \u03c3 and iterationnumber t. From Fig. 8, it is clear that the proposed method caneffectively learn a low-dimensional latent space and reduce thecomputational demand of sparse coding. Additionally, fromthe convergence curves of objective function, the model canIn the proposed LSDT model, there are two trade-offparameters \u03bb1 and \u03bb2 involved for model tuning. For insight oftheir sensitivity to the performance, we tune the two parameters from {1, 10, 100, 1000, 10000}, respectively, and reportthe accuracy on several datasets. Fig. 9 denotes the results w.r.t.different parameter values of \u03bb1 and \u03bb2 . We see that the twoparameters show relatively stable performance, except that for3DA (a) and 4DA (b), the performance has a large variationwhen a large \u03bb1 is given. It is easy to obtain a relatively goodperformance by slightly tuning the model parameters.C. Parameter Settings of Baseline MethodsThroughout the paper, we have compared 13 methodsincluding 4 adaptive classifier based methods such as ASVM,DAM, AMKL and DTSVM, 5 feature transformation basedmethods such as DIP, MMDT, Symm, ARC-t, and RDALR\u201eand 4 closely related methods such as GFK, SGF, SA andLTSL. We present the parameter discussion from three aspects:\u2022 In the classifier based methods, SVM is an importanttool in the models, such as ASVM and DAM. Therefore,the kernel parameter and penalty coefficient are themain parameters. For AMKL and DTSVM (also calledDTMKL), multiple kernels are integrated for improvingthe domain transfer performance by minimizing the structural risk and the maximum mean discrepancy (MMD)between source and target domains. Therefore, thenumber of base kernels and kernel parameters playa key role in the optimal kernel function learning.In YouTube&Consumer video experiments, we have usedthe default parameters in the released codes and theirreported results for comparisons.\f1188IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016Fig. 9. Parameter sensitivity analysis on the considered datasets. (a) 3DA data (Dslr->Webcam). (b) 4DA data (D->W). (c) YouTube&Consumer Videos data.(d) Handwritten digit data (Semeion->USPS). (e) CMU PIE data (session 1).TABLE VIIIC OMPARISON TO PCA A ND LDA\u2022\u2022In the feature transformation based methods, DIP,MMDT, Symm and ARC-t tend to learn a transformationsuch that some similarity metric can be achieved with themaximized similarity or the minimized distance betweenthe distribution of the transformed source and targetdata. RDALR tends to reconstruct the target data withsource data by learning a low-rank matrix. Therefore, inthese methods, one or two regularization parameters arereferred during learning the transformation matrix. In theexperiments, we have copied the accuracy result reportedin their publications for comparisons.In the closely related methods, GFK, SGF, SA and LTSLmethods have a common characteristic that the unsupervised subspace transfer is explored. Specifically, principalcomponent analysis (PCA) is used for pre-learning thelow-dimensional subspace, where the domain adaptationis implemented with different strategies. Therefore, thesubspace dimension d is one key parameter for tuningin these subspace alignment based domain learningmethods. Additionally, SGF associates with the numberof PLS factors and LTSL refers to the trade-off parameter\u03bb2 /\u03bb1 in (2). In this paper, the subspace dimension andtrade-off parameters in these methods have been tuned,and the best results are reported for comparisons.D. Pre-Learn P Using PCA and LDA in LSDTFollowing the pre-learning of subspace in LTSL, in thissection, we discuss the joint learning of P and reconstruction Z, by comparing to PCA and LDA. The comparison results on multi-PIE and 3DA datasets are reportedin Table VIII. The increments of recognition accuracy demonstrate the contribution of learning P simultaneously with Zin LSDT.E. Low-Rank Constraint on Z in LSDTIn LTSL, low-rank representation based reconstruction isused for subspace transfer. For demonstrating the effectivenessTABLE IXR ECONSTRUCT THE TARGET D ATA W ITH S OURCE D ATA O NLY (S)AND C OMBINED S OURCE AND TARGET D ATA (ST)of LSDT based on SSC theory, we discuss the performanceof LRR in LSDT in Table IX (LSDT-LRR vs. LSDT). Theresults demonstrate that LSDT based on SSC is significantlybetter than that of LRR-based.F. Reconstruct XT Using X S Only in LSDTWe have also discussed the performance comparison byreconstructing XT using X=[X S ,XT ] (ST) and X S (S), respectively. The results in Table IX denote that the performancecan be well improved by reconstructing the target data usingboth source and target data in domain transfer. Generally,in reconstruction based domain adaptation, when only a fewnumber of source data is available, the target data can beleveraged for robust subspace transfer. It is worth noting thatsparse coding requires sufficient data for obtaining an overcomplete dictionary (i.e. X S ). For domain adaptation, when thesource data are insufficient, the assumption on over-completedictionary may not hold. In this work, we adopt two strategiesto avoid this issue. First, we consider the [X S ,XT ] as thedictionary for reconstruction to enlarge the dictionary size.Second, by introducing the low-dimensional projection P, weconsider the reconstruction of PXT by using the dictionaryP[X S ,XT ]. Therefore, even the dictionary X S is not overcomplete for coding XT , the dictionary P[X S ,XT ] will be overcomplete for coding PXT .G. Justification of MotivationsThe proposed LSDT is motivated by SSC theory, and aimsat realizing unsupervised domain adaptation by exploitingsparse reconstruction between different domains in the latentsubspace. The in-depth approach motivation of LSDT is asfollows.1) In general, the data from different domains lie in a unionof multiple subspaces. For knowledge \u201ctransfer\u201d but notna\u00efve \u201ctransformation,\u201d the low-dimensional latent space\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION2)3)4)5)of data should be found. Then, the \u201ctransfer\u201d task canbe effectively explored without overfitting. For findingsuch a latent space, we propose to learn a subspaceprojection P. In LTSL [1], the PCA or LDA is usedto compute the P for subspace pursuit.After obtaining the latent space via the P, the knowledge \u201ctransfer\u201d is then implemented. In this paper, the\u201ctransfer\u201d is realized via a reconstruction Z. In general, agood reconstruction is very important for robust domainadaptation. First, the outliers (noise) from source domainwould be removed in transferring to the target domain;Second, fewer data from source domain should be usedfor reconstruction. For this reason, we propose to imposea sparse constraint on Z. The superiority is shownin Table IX.From the above motivation 1) and 2), the reason whywe learn P and Z is clear. Although the P can bepre-computed by existing subspace learning methods,it is sub-optimal and leads to the local optimum of Z.Therefore, we propose to learn the P and Z simultaneously by using an alternative strategy, such that a muchbetter solution with stronger domain adaptability can beachieved. The performance comparison is demonstratedin Table VIII.We aim to reconstruct the target data PXT by usingP[X S ,XT ]. The X S part is used for knowledge adaptationand the XT part is exploited for self-representation andoutlier removing from the target data. When only afew source data is available, the the robustness can beimproved by leveraging the target data in reconstruction.Note that the trivial solution of Z is avoided based onthe SSC theory instead of LRR. The performance canbe observed in Table IX.The proposed NLSDT is an extension of LSDT, which ismotivated by the highly nonlinear domain shift. By simply introducing kernel function into LSDT, the performance is greatly improved throughout the experiments.VII. C ONCLUSIONThis paper proposes a new reconstruction based domainadaptation method for robust visual knowledge transfer. Themethod tends to reconstruct the target data with a few sourcedata points by using a sparse coefficient matrix in somelow-dimensional latent space. The method learns the sparsereconstruction coefficient matrix and the low-dimensionallatent space projection simultaneously, such that an optimal subspace transfer solution can be obtained. Additionally,a kernel framework is generalized into this method, whichaims at learning a nonlinear basis transformation and sparsereconstruction in the reproduced kernel Hilbert space inducedby Mercer theorem, to deal with highly nonlinear domainshifts such as 3D rotation of faces that cannot be tackledby linear techniques. Extensive experiments on synthetic data,two benchmark object datasets, Consumer & YouTube Videosdatasets, CMU multi-PIE face dataset, and three handwrittendigit datasets demonstrate the effectiveness of the proposedmethods in different cross domain transfer tasks.1189A PPENDIX AO PTIMIZATION OF (10)With an auxiliary variable L and U, the problem (10) canbe reformulated as\u00062\u0006\u0006\u0006min \u0003Z\u00031 + \u03bb1 \u0006\u0003T KT \u2212 \u0003T KL\u0006FZ,Ls.t. L = Z, 1TN S +NT L = 1TNT , Z N S +i,i = Ui , Ui = 0 (15)The augmented Lagrange function of (15) can be represented as\u00062\u03bc1 \u0006\u0006 T\u0006J3 (Z, L, U) = \u0003Z\u00031 +\u0006\u0003 KT \u2212 \u0003T KL\u0006 + Y A , L \u2212 ZF2+ Y B , 1TN S +NT L \u2212 1TNT\u000e\u0004\u0005+YCi Z N S +i,i \u2212 Ui + Y D , Ui\u03bc2+2\u000f\u0006\u00062\u0006\u0006\u0003L \u2212 Z\u00032F + \u00061TN S +NT L \u2212 1TNT \u00062+\u000e\u0004Z N S +i,i \u2212 Ui\u00052\u0010+ \u0003U\u000322i(16)where Y A , Y B , YC and Y D denote the Lag-multipliers,\u03bb1 = \u03bc1 /2.(1) Updating L: By fixing Z and U, one can set the partialderivative\u2202 J3 (Z,L,U)\u2202L= 0 of (16) as 0, and obtain L as\b\u22121L = \u03bc1 KT \u0003\u0003T K + \u03bc2 I + \u03bc2 1 N S +NT 1TN S +NT\b\u00d7 \u03bc1 KT \u0003\u0003T KT \u2212 Y A \u2212 1 N S +NT Y B + \u03bc2 Z+ \u03bc2 1 N S +NT 1TNT(2) Updating U: By fixing L and Z, lethaveUi =(17)\u2202 J3 (Z,L,U)\u2202Ui= 0, we\u03bc2 Z N S +i,i + YCi \u2212 Y Di2\u03bc2(18)(3) Updating Z: BY fixing L and U, Z can be solved asfollowsi) for Z N S +i,i , \u2200i = 1, . . . , NT , we have\u0011\u0011 \u03bc2 \u0004\u00052min \u0011 Z N S +i,i \u0011 +Z N S +i,i \u2212 L N S +i,i2N S +i,i\u2212 YA\u00b7 Z N S +i,i\u00052\u03bc2 \u0004+Z N S +i,i \u2212 Ui + YCi \u00b7 Z N S +i,i2\u0011\u0011\u21d4 min \u0011 Z N S +i,i \u0011\u000f\u000fL N S +i,i + Ui+ \u03bc2 Z N S +i,i \u22122\u0010\u0010Y AN S +i,i + YCi+2\u03bc2(19)\f1190IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 25, NO. 3, MARCH 2016ii) for Z other than Z N S +i,i , \u2200i = 1, . . . , NT , we have\u03bc2\u0003L \u2212 Z\u00032F + Y A , L \u2212 Zmin \u0003Z\u00031 +Z2\u00062\u0006\u0007\u0006\u03bc2 \u0006\u0006Z \u2212 L + Y A \u0006 . (20)\u21d4 min \u0003Z\u00031 +\u0006Z2\u03bc \u00062FA PPENDIX BP ROOF OF P ROPOSITION 2The objective function of (11) can be expanded as follows\u0006\u0006 \b\u00062\u00062\b\u0006\u0006\u0006\u0006\u03bb1 \u0006\u0003T K K\u22121 KT \u2212 Z \u0006 + \u03bb2 \u0006X I \u2212 \u0003\u0003T K \u0006FF\u0007 \b\bT\u22121\u22121T T= T r \u03bb1 K KT \u2212 Z K KT \u2212 Z K Q K\b \b+ T r \u03bb2 K \u2212 2KT QT K + KT QT KQK(21)where Q = \u0003\u0003T \u2208 R N\u00d7N .By following (21), with \u0003T K\u0003 = I, there is \u0003\u0003T K\u0003\u0003T =QKQT = \u0003\u0003T = Q, then the objective (21) can besimplified as\u0007\u0007 \b\bTT r \u03bb1 K\u22121 KT \u2212 Z K\u22121 KT \u2212 Z \u2212 \u03bb2 I KT QT K(22)According to the Eigenvalue decomposition of K = VSV [5],1T S 12 VT , where \u0004 = S 12 VT \u0003.we obtain KT QT K = VS 2Then the objective function (22) can be rewritten as\u0007\u0007 \b\bT1T r \u0004T S 2 VT \u03bb1 K\u22121 KT \u2212 Z K\u22121 KT \u2212 Z \u2212 \u03bb2 IT\b1\u00d7 VS 2 \u0004 = T r \u0004T \u0005\u0004(23)\b \u0004\u0005\u0004\u0005T1where \u0005 = S 2 VT \u03bb1 K\u22121 KT \u2212 Z K\u22121 KT \u2212 Z \u2212 \u03bb2 I1VS 2 and \u0004T \u0004 = \u0003T VSVT \u0003 = \u0003T K\u0003 = I.Finally, the original optimization problem (11) becomes\b\u0004\u2217 = arg min T r \u0004T \u0005\u0004 , s.t. \u0004T \u0004 = I(24)\u0004\u2217The optimal \u0004 is obtained by l eigenvectors with respectto the first l smallest Eigenvalues of \u0005. Once \u0004\u2217 is solved by1\u0004 = S 2 VT \u0003 and VVT = I, the optimal \u0003\u2217 can be solved as1\u0003\u2217 = VS\u2212 2 \u0004\u2217 .(25)ACKNOWLEDGMENTThe authors are grateful to the AE and anonymous reviewersfor their valuable comments on our work.R EFERENCES[1] M. Shao, D. Kit, and Y. Fu, \u201cGeneralized transfer subspace learningthrough low-rank constraint,\u201d Int. J. Comput. Vis., vol. 109, no. 1,pp. 74\u201393, 2014.[2] I. H. Jhuo, D. Liu, D. T. Lee, and S.-F. Chang, \u201cRobust visual domainadaptation with low-rank reconstruction,\u201d in Proc. IEEE Conf. CVPR,Jun. 2012, pp. 2168\u20132175.[3] E. Elhamifar and R. Vidal, \u201cSparse subspace clustering: Algorithm,theory, and applications,\u201d IEEE Trans. Pattern Anal. Mach. Intell.,vol. 35, no. 11, pp. 2765\u20132781, Nov. 2013.[4] G. Liu, Z. Lin, and Y. Yu, \u201cRobust subspace segmentation by low-rankrepresentation,\u201d in Proc. ICML, 2010, pp. 663\u2013670.[5] A. H. Sameh and J. A. Wisniewski, \u201cA trace minimization algorithmfor the generalized eigenvalue problem,\u201d SIAM J. Numer. Anal., vol. 19,no. 6, pp. 1243\u20131259, 1982.[6] S. Shekhar, V. M. Patel, H. V. Nguyen, and R. Chellappa, \u201cGeneralizeddomain-adaptive dictionaries,\u201d in Proc. IEEE Conf. CVPR, Jun. 2013,pp. 361\u2013368.[7] H. Daum\u00e9, III, A. Kumar, and A. Saha, \u201cFrustratinglyeasy semi-supervised domain adaptation,\u201d in Proc. Workshop Domain Adaptation Natural Language Process., 2010,pp. 53\u201359.[8] R. Gopalan, R. Li, and R. Chellappa, \u201cDomain adaptation forobject recognition: An unsupervised approach,\u201d in Proc. IEEE ICCV,Nov. 2011, pp. 999\u20131006.[9] K. Saenko, B. Kulis, M. Fritz, and T. Darrell, \u201cAdapting visual categorymodels to new domains,\u201d in Proc. ECCV, 2010, pp. 213\u2013226.[10] B. Gong, Y. Shi, F. Sha, and K. Grauman, \u201cGeodesic flow kernel forunsupervised domain adaptation,\u201d in Proc. IEEE Conf. CVPR, Jun. 2012,pp. 2066\u20132073.[11] G. Griffin, A. Holub, and P. Perona, \u201cCaltech-256 object category dataset,\u201d California Inst. Technol., Pasadena, CA, USA,Tech. Rep. CNS-TR-2007-001, 2007.[12] J. Yang, R. Yan, and A. G. Hauptmann, \u201cCross-domain video conceptdetection using adaptive SVMs,\u201d in Proc. 15th ACM Int. Conf. MM,2007, pp. 188\u2013197.[13] V. M. Patel, H. Van Nguyen, and R. Vidal, \u201cLatent space sparse subspaceclustering,\u201d in Proc. IEEE ICCV, Dec. 2013, pp. 225\u2013232.[14] J. Hoffman, E. Rodner, J. Donahue, K. Saenko, and T. Darrell, \u201cEfficientlearning of domain invariant image representations,\u201d in Proc. ICLR,2013, pp. 1\u201342.[15] B. Kulis, K. Saenko, and T. Darrell, \u201cWhat you saw is not what you get:Domain adaptation using asymmetric kernel transforms,\u201d in Proc. IEEEInt. Conf. Comput. Vis. Pattern Recognit., Jun. 2011, pp. 1785\u20131792.[16] L. Duan, D. Xu, I. W.-H. Tsang, and J. Luo, \u201cVisual event recognitionin videos by learning from Web data,\u201d IEEE Trans. Pattern Anal. Mach.Intell., vol. 34, no. 9, pp. 1667\u20131680, Sep. 2012.[17] L. Duan, I. W. Tsang, and D. Xu, \u201cDomain transfer multiple kernellearning,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 3,pp. 465\u2013479, Mar. 2012.[18] L. Duan, D. Xu, and I. W. Tsang, \u201cDomain adaptation from multiplesources: A domain-dependent regularization approach,\u201d IEEE Trans.Neural Netw. Learn. Syst., vol. 23, no. 3, pp. 504\u2013518, Mar. 2012.[19] J. Hoffman, E. Rodner, J. Donahue, B. Kulis, and K. Saenko, \u201cAsymmetric and category invariant feature transformations for domain adaptation,\u201d Int. J. Comput. Vis., vol. 109, no. 1, pp. 28\u201341, 2014.[20] G. Liu, Z. Lin, S. Yan, J. Sun, Y. Yu, and Y. Ma, \u201cRobust recoveryof subspace structures by low-rank representation,\u201d IEEE Trans. PatternAnal. Mach. Intell., vol. 35, no. 1, pp. 171\u2013184, Jan. 2013.[21] E. Elhamifar and R. Vidal, \u201cSparse subspace clustering,\u201d in Proc. IEEEConf. CVPR, Jun. 2009, pp. 2790\u20132797.[22] Z. Lin, M. Chen, L. Wu, and Y. Ma, \u201cThe augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices,\u201d Univ.Illinois Urbana-Champaign, Champaign, IL, USA, Tech. Rep. UILUENG-09-2215, 2009.[23] R. Gross, I. Matthews, J. Cohn, T. Kanade, and S. Baker, \u201cMulti-PIE,\u201dImage Vis. Comput., vol. 28, no. 5, pp. 807\u2013813, 2010.[24] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \u201cGradient-basedlearning applied to document recognition,\u201d Proc. IEEE, vol. 86, no. 11,pp. 2278\u20132324, Nov. 1998.[25] A. Frank and A. Asuncion. (2010). UCI Machine Learning Repository.[Online]. Available: https://archive.ics.uci.edu/ml[26] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, \u201cDistributedoptimization and statistical learning via the alternating direction methodof multipliers,\u201d Found. Trends Mach. Learn., vol. 3, no. 1, pp. 1\u2013122,2010.[27] A. Loui et al., \u201cKodak\u2019s consumer video benchmark data set: Conceptdefinition and annotation,\u201d in Proc. Int. Workshop Multimedia Inf. Retr.,2007, pp. 245\u2013254.[28] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld, \u201cLearningrealistic human actions from movies,\u201d in Proc. IEEE Conf. CVPR,Jun. 2008, pp. 1\u20138.[29] D. G. Lowe, \u201cObject recognition from local scale-invariant features,\u201d inProc. 7th IEEE ICCV, 1999, pp. 1150\u20131157.[30] D. G. Lowe, \u201cDistinctive image features from scale-invariant keypoints,\u201dInt. J. Comput. Vis., vol. 60, no. 2, pp. 91\u2013110, 2004.\fZHANG et al.: LSDT LEARNING FOR VISUAL ADAPTATION[31] M. Belkin and P. Niyogi, \u201cSemi-supervised learning on manifolds,\u201d inProc. NIPS, 2002, pp. 1\u201323.[32] A. Blum and S. Chawla, \u201cLearning from labeled and unlabeled datausing graph mincuts,\u201d in Proc. ICML, 2001, pp. 19\u201326.[33] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, \u201cDomain adaptationvia transfer component analysis,\u201d IEEE Trans. Neural Netw., vol. 22,no. 2, pp. 199\u2013210, Feb. 2011.[34] S. J. Pan and Q. Yang, \u201cA survey on transfer learning,\u201d IEEE Trans.Knowl. Data Eng., vol. 22, no. 10, pp. 1345\u20131359, Oct. 2010.[35] J. Ghosn and Y. Bengio, \u201cBias learning, knowledge sharing,\u201d IEEETrans. Neural Netw., vol. 14, no. 4, pp. 748\u2013765, Jul. 2003.[36] L. Zhang and D. Zhang, \u201cDomain adaptation extreme learning machinesfor drift compensation in E-nose systems,\u201d IEEE Trans. Instrum. Meas.,vol. 64, no. 7, pp. 1790\u20131801, Jul. 2015.[37] M. Soltanolkotabi, E. Elhamifar, and E. J. Cand\u00e8s, \u201cRobust subspaceclustering,\u201d Ann. Statist., vol. 42, no. 2, pp. 669\u2013699, 2014.[38] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u201cImageNet classification with deep convolutional neural networks,\u201d in Proc. NIPS, 2012,pp. 1097\u20131105.[39] J. Donahue et al., \u201cDeCAF: A deep convolutional activation feature forgeneric visual recognition,\u201d in Proc. ICML, 2014, pp. 1\u201317.[40] L. Zhang and D. Zhang. (2015). \u201cRobust visual knowledge transfer viaEDA.\u201d [Online]. Available: https://arxiv.org/abs/1505.04382[41] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars, \u201cUnsupervisedvisual domain adaptation using subspace alignment,\u201d in Proc. IEEEICCV, Dec. 2013, pp. 2960\u20132967.[42] M. Baktashmotlagh, M. T. Harandi, B. C. Lovell, and M. Salzmann,\u201cUnsupervised domain adaptation by domain invariant projection,\u201d inProc. IEEE ICCV, Dec. 2013, pp. 769\u2013776.[43] X. Peng, L. Zhang, and Z. Yi, \u201cScalable sparse subspace clustering,\u201d inProc. IEEE Conf. CVPR, Jun. 2013, pp. 430\u2013437.[44] L. Lin, Y. Xu, X. Liang, and J. Lai, \u201cComplex background subtraction bypursuing dynamic spatio-temporal models,\u201d IEEE Trans. Image Process.,vol. 23, no. 7, pp. 3191\u20133202, Jul. 2014.[45] X. Cao, C. Zhang, H. Fu, S. Liu, and H. Zhang, \u201cDiversity-inducedmulti-view subspace clustering,\u201d in Proc. IEEE Conf. CVPR, Jun. 2015,pp. 586\u2013594.Lei Zhang (M\u201914) received the Ph.D. degree in circuits and systems from the College of Communication Engineering, Chongqing University, Chongqing,China, in 2013. He was selected as a Hong KongScholar of China in 2013. From 2013 to 2015, hewas a Post-Doctoral Fellow with The Hong KongPolytechnic University, Hong Kong. He is currentlya Distinguished Research Fellow with ChongqingUniversity. He has authored over 40 scientific papersin machine olfaction, pattern recognition, machinelearning, and computer vision. His current researchinterests include machine learning, pattern recognition, and computer vision.He was a recipient of the Outstanding Doctoral Dissertation Award inChongqing, in 2015, the Hong Kong Scholar Award in 2014, the AcademyAward for Youth Innovation of Chongqing University in 2013, and theNew Academic Researcher Award for Doctoral Candidates from the Ministryof Education, China, in 2012.1191Wangmeng Zuo (M\u201909\u2013SM\u201914) received the Ph.D.degree in computer application technology fromthe Harbin Institute of Technology, Harbin, China,in 2007. In 2004, from 2005 to 2006, andfrom 2007 to 2008, he was a Research Assistant with the Department of Computing, TheHong Kong Polytechnic University, Hong Kong.From 2009 to 2010, he was a Visiting Professor with Microsoft Research Asia. He is currently an Associate Professor with the Schoolof Computer Science and Technology, HarbinInstitute of Technology. He has authored over 60 papers in toptier academic journals and conferences. His current research interestsinclude image modeling and blind restoration, discriminative learning,biometrics, and 3-D vision. He is an Associate Editor of the IET Biometrics.David Zhang (M\u201990\u2013SM\u201995\u2013F\u201909) received thedegree from Peking University, in 1974, and theM.Sc. and Ph.D. degrees from the Harbin Institute of Technology (HIT), in 1982 and 1985,respectively, all in computer science, and thePh.D. degree in electrical and computer engineering from the University of Waterloo, ON, Canada,in 1994. From 1986 to 1988, he was a PostDoctoral Fellow with Tsinghua University andthen an Associate Professor with Academia Sinica,Beijing. He has been a Chair Professor with TheHong Kong Polytechnic University since 2005, where he is the Founding Director of the Biometrics Research Centre (UGC/CRC) supportedby the Hong Kong SAR Government in 1998. He serves as a VisitingChair Professor with Tsinghua University, and an Adjunct Professor withPeking University, Shanghai Jiao Tong University, HIT, and the University of Waterloo. He is the Founder and Editor-in-Chief of the International Journal of Image and Graphics, a Book Editor of InternationalSeries on Biometrics (Springer), an Organizer of the International Conference on Biometrics Authentication, and an Associate Editor of morethan ten international journals, including the IEEE T RANSACTIONS. He hasauthored over ten books, over 300 international journal papers, and holds30 patents from USA/Japan/HK/China. He is a Croucher Senior ResearchFellow, a Distinguished Speaker of the IEEE Computer Society, and a fellowof IAPR.\f", "2013 IEEE International Conference on Computer VisionTransfer Feature Learning with Joint Distribution AdaptationMingsheng Long\u2020\u2021 , Jianmin Wang\u2020 , Guiguang Ding\u2020 , Jiaguang Sun\u2020 , and Philip S. Yu\u00a7\u2020School of Software, TNLIST, Tsinghua University, Beijing, China\u2021Department of Computer Science, Tsinghua University, Beijing, China\u00a7Department of Computer Science, University of Illinois at Chicago, IL, USAlongmingsheng@gmail.com, {jimwang,dinggg,sunjg}@tsinghua.edu.cn, psyu@uic.eduSource DomainAbstractTransfer learning is established as an effective technology in computer vision for leveraging rich labeled data in thesource domain to build an accurate classi\ufb01er for the targetdomain. However, most prior methods have not simultaneously reduced the difference in both the marginal distribution and conditional distribution between domains. In thispaper, we put forward a novel transfer learning approach,referred to as Joint Distribution Adaptation (JDA). Speci\ufb01cally, JDA aims to jointly adapt both the marginal distribution and conditional distribution in a principled dimensionality reduction procedure, and construct new feature representation that is effective and robust for substantial distribution difference. Extensive experiments verify that JDA cansigni\ufb01cantly outperform several state-of-the-art methods onfour types of cross-domain image classi\ufb01cation problems.10550051000510Figure 1. In our problem, labeled source and unlabeled target domains are different in both marginal and conditional distributions.[21, 15, 18], or re-weight source data in order to minimizethe distribution difference and then learn a classi\ufb01er on there-weighted source data [3, 4]. Most of existing methodsmeasure the distribution difference based on either marginaldistribution or conditional distribution. However, Figure 1demonstrates the importance of matching both marginal andconditional distributions for robust transfer learning. Somevery recent works started to match both the marginal andconditional distributions using sample selection [26], kernel density estimation [18], or two-stage re-weighting [23],but they may require either some labeled data in the targetdomain, or multiple source domains for consensus learning.1. IntroductionIn this paper, we address a challenging scenario in whichthe source and target domains are different in both marginaland conditional distributions, and the target domain has nolabeled data. We put forward a novel transfer learning solution, referred to as Joint Distribution Adaptation (JDA),to jointly adapt both the marginal and conditional distributions in a principled dimensionality reduction procedure.Speci\ufb01cally, we extend the nonparametric Maximum MeanDiscrepancy (MMD) [8] to measure the difference in bothmarginal and conditional distributions, and integrate it withPrincipal Component Analysis (PCA) to construct featurerepresentation that is effective and robust for substantial distribution difference. We present the underlying assumptionand learning algorithm for the JDA optimization problem.In computer vision, labeled information is crucial for avariety of recognition problems. For highly-evolving visualdomains where labeled data are very sparse, one may expectto leverage abundant labeled data readily available in somerelated source domains for training accurate classi\ufb01ers to bereused in the target domain. Recently, the literature has witnessed an increasing interest in developing transfer learning [16] algorithms for cross-domain knowledge adaptationproblems. Transfer learning has proven to be promising inimage classi\ufb01cation [24, 12] and tagging [19, 25], objectrecognition [14, 2, 7, 10], and feature learning [13, 11, 17].In cross-domain problems, the source and target dataare usually sampled from different probability distributions.Therefore, a major computational issue of transfer learningis to reduce the distribution difference between domains.Recent works aim to discover a shared feature representation which can reduce the distribution difference and preserve the important properties of input data simultaneously1550-5499/13 $31.00 \u00a9 2013 IEEEDOI 10.1109/ICCV.2013.274Target Domain10We perform comprehensive experiments on four types ofreal-world datasets: digit (USPS, MNIST), face (PIE), andobject (COIL20, Of\ufb01ce+Caltech [20]). From these datasets,we construct 36 cross-domain image datasets, each under a2200\fdifferent dif\ufb01culty in knowledge adaptation. Our empiricalresults demonstrate a signi\ufb01cant improvement of 7.57% interms of classi\ufb01cation accuracy, obtained by the proposedJDA approach over several state-of-the-art transfer learningmethods. Our results reveal substantial effects of matchingboth marginal and conditional distributions across domains.Table 1. Notations and descriptions used in this paper.NotationDescriptionNotationDescriptionDs , Dtsource/target domainXinput data matrixAadaptation matrixns , nt #source/target examples#shared features/classesZembedding matrixm, C#subspace basesHcentering matrixkregularization parameterMcMMD matrices, c \u2208 {0, . . . , C}\u03bbwhich the distribution differences between 1) Ps (xs ) andPt (xt ), 2) Qs (ys |xs ) and Qt (yt |xt ) are explicitly reduced.2. Related WorkIn this section, we discuss prior works on transfer learning that are related to ours, and highlight their differences.According to the literature survey [16], existing transferlearning methods can be roughly organized into two categories: instance reweighting [3, 4] and feature extraction.Our work belongs to the feature extraction category, whichcan be further reorganized into two rough subcategories.1) Property preservation, which shares latent factorsacross domains by preserving important properties of data,e.g. statistical property [17, 11], geometric structure [19, 6].2) Distribution adaptation, which explicitly minimizesprede\ufb01ned distance measures to reduce the difference in themarginal distribution [22, 15], conditional distribution [21],or both [26, 23, 18]. However, to match conditional distributions, these methods require either some labeled targetdata, or multiple source domains for consensus learning.To our knowledge, our work is among the \ufb01rst attemptsto jointly adapt both marginal and conditional distributionsbetween domains, and no labeled data are required in thetarget domain. Our work is a principled dimensionality reduction procedure with MMD-based distribution matching,which is different from feature re-weighting methods [1, 5].3.2. Proposed ApproachIn this paper, we propose to adapt the joint distributionsby a feature transformation T so that the joint expectationsof the features x and labels y are matched between domains:\u0002\u00022min \u0002EP (x ,y ) [T (xs ) , ys ] \u2212 EP (x ,y ) [T (xt ) , yt ]\u0002Tsstt\u0002\u00022\u2248 \u0002EPs (xs ) [T (xs )] \u2212 EPt (xt ) [T (xt )]\u0002\u0002\u00022+ \u0002EQs (ys |xs ) [ys |T (xs )] \u2212 EQt (yt |xt ) [yt |T (xt )]\u0002(1)The problem is nontrivial, since there are no labeled data inthe target domain, and Qt (yt |xt ) cannot be estimated exactly. The best approximation is to assume that Qt (yt |xt ) \u2248Qs (yt |xt ) [1]. This can be executed by applying a classi\ufb01erf trained on the labeled source data to the unlabeled targetdata. In order to achieve a more accurate approximation forQt (yt |xt ), we propose an iterative pseudo label re\ufb01nementstrategy to iteratively re\ufb01ne the transformation T and classi\ufb01er f . The proposed approach is technically detailed later.3.2.1 Feature Transformation3. Joint Distribution AdaptationDimensionality reduction methods can learn a transformedfeature representation by minimizing the reconstruction error of the input data. For simplicity and generality, we willchoose Principal Component Analysis (PCA) for data reconstruction. Denote X = [x1 , . . . , xn ] \u2208 Rm\u00d7n the inputdata matrix, and H = I \u2212 n1 1 the centering matrix, wheren = ns + nt and 1 the n \u00d7 n matrix of ones, then the covariance matrix can be computed as XHXT . The learninggoal of PCA is to \ufb01nd an orthogonal transformation matrixA \u2208 Rm\u00d7k such that embedded data variance is maximized\u0003\u0004max tr AT XHXT A(2)In this section, we present in detail the Joint DistributionAdaptation (JDA) approach for effective transfer learning.3.1. Problem De\ufb01nitionWe begin with the de\ufb01nitions of terminologies. For clarity, the frequently used notations are summarized in Table 1.De\ufb01nition 1 (Domain) A domain D is composed of an mdimensional feature space X and a marginal probabilitydistribution P (x), i.e., D = {X , P (x)}, where x \u2208 X .AT A=IDe\ufb01nition 2 (Task) Given domain D, a task T is composed of a C-cardinality label set Y and a classi\ufb01er f (x),i.e., T = {Y, f (x)}, where y \u2208 Y, and f (x) = Q(y|x) canbe interpreted as the conditional probability distribution.where tr(\u00b7) denotes the trace of a matrix. This optimizationproblem can be ef\ufb01ciently solved by eigendecompositionXHXT A = A\u03a6, where \u03a6 = diag(\u03c61 , . . . , \u03c6k ) \u2208 Rk\u00d7kare the k largest eigenvalues. Then we \ufb01nd the optimal kdimensional representation by Z = [z1 , . . . , zn ] = AT X.Problem 1 (Joint Distribution Adaptation) Givenlabeled source domain Ds = {(x1 , y1 ), . . . , (xns , yns )} andunlabeled target domain Dt = {xns +1 , . . . , xns +nt } underthe assumptions that Xs = Xt , Ys = Yt , Ps (xs ) \u0003= Pt (xt ),Qs (ys |xs ) \u0003= Qt (yt |xt ), learn a feature representation in3.2.2 Marginal Distribution AdaptationHowever, even through the PCA-induced k-dimensionalrepresentation, the distribution difference between domains2201\fw.r.t. each class c \u2208 {1, . . . , C} in the label set Y. Here wemodify MMD to measure the distance between the classconditional distributions Qs (xs |ys = c) and Qt (xt |yt = c)will still be signi\ufb01cantly large. Thus a major computational issue is to reduce the distribution difference by explicitlyminimizing proper distance measures. Since parametricallyestimating the probability density for a distribution is oftena nontrivial problem, we resort to explore the suf\ufb01cient statistics instead. To reduce the difference between marginaldistributions Ps (xs ) and Pt (xt ), we follow [8, 15, 23] andadopt the empirical Maximum Mean Discrepancy (MMD)as the distance measure to compare different distributions,which computes the distance between the sample means ofthe source and target data in the k-dimensional embeddings:\u0002ns\u00021\u0002 1 \u0003 TA xi \u2212\u0002\u0002 nsnti=1n\u0003s +ntj=ns +1\u0002\u0002\u0002\u0002 1\u0002 (c)\u0002 ns\u0002\u0003(c)xi \u2208DsAT xi \u22121(c)nt\u00022\u0002\u0002\u0002AT xj \u0002 =tr(AT XMc XT A)\u0002(c)\u0002xj \u2208Dt\u0003(5)(c)where Ds = {xi : xi \u2208 Ds \u2227 y (xi ) = c} is the set of examples belonging to class c in the source data, y (xi ) is(c)(c)the true label of xi , and ns = |Ds |. Correspondingly,(c)Dt = {xj : xj \u2208 Dt \u2227 y (xj ) = c} is the set of examplesbelonging to class c in the target data, y (xj ) is the pseudo(c)(c)(predicted) label of xj , and nt = |Dt |. Thus the MMDmatrices Mc involving class labels are computed as follows\u23a7(c)1\u23aaxi , xj \u2208 Ds(c) (c) ,\u23aa\u23aannss\u23aa\u23aa(c)1\u23aaxi , xj \u2208 Dt\u23aa(c) ,\u23a8 n(c)t nt(c)(c)(Mc )ij =(6)xi \u2208 Ds , xj \u2208 Dt\u22121\u23aa\u23aa,(c) (c)\u23aa(c)(c)\u23aa ns ntxj \u2208 Ds , xi \u2208 Dt\u23aa\u23aa\u23aa\u23a90,otherwise\u00022\u0002\u0004\u0005\u0002A xj \u0002 = tr AT XM0 XT A\u0002T(3)where M0 is the MMD matrix and is computed as follows\u23a71\u23aa\u23a8 ns ns , xi , xj \u2208 Ds(4)(M0 )ij = nt1nt , xi , xj \u2208 Dt\u23aa\u23a9 \u22121ns nt , otherwiseBy minimizing Equation (3) such that Equation (2) is maximized, the marginal distributions between domains aredrawn close under the new representation Z = AT X. Notethat we have just developed JDA to be similar to TCA [15].By minimizing Equation (5) such that Equation (2) is maximized, the conditional distributions between domains aredrawn close under the new representation Z = AT X. Withthis important improvement, JDA can be robust for crossdomain problems with changes in conditional distributions.It is important to note that, although many of the pseudotarget labels are incorrect due to the differences in both themarginal and conditional distributions, we can still leveragethem to match the conditional distributions with the revisedMMD measure de\ufb01ned in Equation (5). The justi\ufb01cation isthat we match the distributions by exploring the suf\ufb01cient statistics instead of the density estimates. In this way, we canleverage the source classi\ufb01er to improve the target classi\ufb01er.We will verify this argument thoroughly in the experiments.3.2.3 Conditional Distribution AdaptationHowever, reducing the difference in the marginal distributions does not guarantee that the conditional distributionsbetween domains can also be drawn close. Indeed, minimizing the difference between the conditional distributionsQs (ys |xs ) and Qt (yt |xt ) is crucial for robust distributionadaptation [23]. Unfortunately, it is nontrivial to match theconditional distributions, even by exploring suf\ufb01cient statistics of the distributions, since there are no labeled data inthe target domain, i.e., Qt (yt |xt ) cannot be modeled directly. Some very recent works started to match the conditionaldistributions via sample selection in a kernel mapping space[26], circular validation [3], co-training [4], and kernel density estimation [18]. But they all require some labeled datain the target domain, and thus cannot address our problem.In this paper, we propose to explore the pseudo labels ofthe target data, which can be easily predicted by applyingsome base classi\ufb01ers trained on the labeled source data tothe unlabeled target data. The base classi\ufb01er can be eitherstandard learners, e.g., Support Vector Machine (SVM), ortransfer learners, e.g., Transfer Component Analysis (TCA) [15]. Since the posterior probabilities Qs (ys |xs ) andQt (yt |xt ) are quite involved, we resort to explore the suf\ufb01cient statistics of class-conditional distributions Qs (xs |ys )and Qt (xt |yt ) instead. Now with the true source labels andpseudo target labels, we can essentially match the classconditional distributions Qs (xs |ys = c) and Qt (xt |yt = c)3.2.4 Optimization ProblemIn JDA, to achieve effective and robust transfer learning, weaim to simultaneously minimize the differences in both themarginal distributions and conditional distributions acrossdomains. Thus, we incorporate Equations (3) and (5) intoEquation (2), which leads to the JDA optimization problem:minAT XHXT A=ICc=0\u0003\u00042tr AT XMc XT A + \u03bb \u0006A\u0006F (7)where \u03bb is the regularization parameter to guarantee the optimization problem to be well-de\ufb01ned. Based on the generalized Rayleigh quotient, minimizing Equations (3) and (5)such that Equation (2) is maximized is equivalent to minimizing Equations (3) and (5) such that Equation (2) is \ufb01xed.2202\fIt is obvious that TCA can be viewed as a special case ofJDA with C = 0. With JDA, we can simultaneously adaptboth the marginal distributions and conditional distributionsbetween domains to facilitate joint distribution adaptation.A fascinating property of JDA is its capability to effectivelyexplore the conditional distributions only using principledunsupervised dimensionality reduction and base classi\ufb01er.Thus JDA can be easy to implement and deploy practically.Kernelization: For nonlinear problems, consider kernelmapping \u03c8 : x \u0007\u2192 \u03c8(x), or \u03c8(X) = [\u03c8(x1 ), . . . , \u03c8(xn )],and kernel matrix K = \u03c8(X)T \u03c8(X) \u2208 Rn\u00d7n . We utilizethe Representer theorem to formulate Kernel-JDA as\u0003\u0004C2mintr AT KMc KT A + \u03bb \u0006A\u0006F (8)AT KHKT A=IAlgorithm 1: JDA: Joint Distribution Adaptation12345678c=0In this section, we conduct extensive experiments for image classi\ufb01cation problems to evaluate the JDA approach.Datasets and codes will be available online on publication.3.2.5 Iterative Re\ufb01nementIt is worth noting that, with JDA, we can usually obtain amore accurate labeling for the target data. Thus, if we usethis labeling as the pseudo target labels and run JDA iteratively, then we can alternatingly improve the labeling quality until convergence. This EM-like pseudo label re\ufb01nementprocedure is empirically effective as shown in experiments.4.1. Data PreparationUSPS+MNIST, COIL20, PIE, and Of\ufb01ce+Caltech (referto Figure 2 and Table 2) are six benchmark datasets widelyadopted to evaluate visual domain adaptation algorithms.USPS dataset consists of 7,291 training images and2,007 test images of size 16 \u00d7 16.MNIST dataset has a training set of 60,000 examplesand a test set of 10,000 examples of size 28 \u00d7 28.From Figure 2, we see that USPS and MNIST followvery different distributions. They share 10 classes of digits.To speed up experiments, we construct one dataset USPSvs MNIST by randomly sampling 1,800 images in USPS toform the source data, and randomly sampling 2,000 imagesin MNIST to form the target data. We switch source/targetpair to get another dataset MNIST vs USPS. We uniformlyrescale all images to size 16 \u00d7 16, and represent each one bya feature vector encoding the gray-scale pixel values. Thusthe source and target data can share the same feature space.COIL20 contains 20 objects with 1,440 images. Theimages of each object were taken 5 degrees apart as the object is rotated on a turntable and each object has 72 images.Each image is 32 \u00d7 32 pixels with 256 gray levels per pixel.In experiments, we partition the dataset into two subsetsCOIL1 and COIL2: COIL1 contains all images taken inthe directions of [0\u25e6 , 85\u25e6 ] \u222a [180\u25e6 , 265\u25e6] (quadrants 1 and3); COIL2 contains all images taken in the directions of[90\u25e6 , 175\u25e6 ] \u222a [270\u25e6 , 355\u25e6] (quadrants 2 and 4). In this way,subsets COIL1 and COIL2 will follow relatively differentdistributions. We construct one dataset COIL1 vs COIL2 byselecting all 720 images in COIL1 to form the source data,and all 720 images in COIL2 to form the target data. Weswitch source/target to get another dataset COIL2 vs COIL1.PIE, which stands for \u201cPose, Illumination, Expression\u201d,3.3. Learning AlgorithmAccording to the constrained optimization theory, we denote \u03a6 = diag(\u03c61 , . . . , \u03c6k ) \u2208 Rk\u00d7k as the Lagrange multiplier, and derive the Lagrange function for problem (7) asCSetting\u2202L\u2202AX(9)= 0, we obtain generalized eigendecompositionCc=0Mc XT + \u03bbI A = XHXT A\u03a6Construct MMD matrices {Mc }Cc=1 by Equation (6).until ConvergencesReturn an adaptive classi\ufb01er f trained on {Axi , yi }ni=1 .4. Experimentswhere A \u2208 Rn\u00d7k is the adaptation matrix for Kernel-JDA.L = tr AT XMc XT + \u03bbI Ac=0\u0004 \u0004\u0003\u0003+ tr I \u2212 AT XHXT A \u03a6Input: Data X, ys ; #subspace bases k, regularization parameter \u03bb.Output: Adaptation matrix A, embedding Z, adaptive classi\ufb01er f .beginConstruct MMD matrix M0 by Eq. (4), set {Mc := 0}Cc=1 .repeatSolve the generalized eigendecomposition problem inEquation (10) and select the k smallest eigenvectors toconstruct the adaptation matrix A, and Z := AT X.\u0002\u0003nsTrain a standard classi\ufb01er f on (AT xi , yi ) i=1tos +ntupdate pseudo target labels {\u0004yj := f (AT xj )}nj=ns +1 .(10)Finally, \ufb01nding the optimal adaptation matrix A is reducedto solving Equation (10) for the k smallest eigenvectors. Acomplete procedure of JDA is summarized in Algorithm 1.3.4. Computational ComplexityWe analyze the computational complexity of Algorithm 1 using the big O notation. We denote T the number ofiterations, then typical values of k are not greater than 500,T not greater than 50, so kmin(m, n), Tmin(m,n).\u0004\u0003The computational cost is detailed as follows: O T km2for solving the generalized eigendecompositionproblem\u0004\u0003with dense matrices, i.e., Line 4; O T Cn2 for constructing the MMD matrices, i.e., Lines 2 and 6; O (T mn) forall other steps. In summary, \u0003the overall computational com\u0004plexity of Algorithm 1 is O T km2 + T Cn2 + T mn) .2203\fTable 2. Statistics of the six benchmark digit/face/object datasets.DatasetUSPSMNISTCOIL20PIEOf\ufb01ceCaltech\u2022\u2022\u2022\u2022\u2022Figure 2. USPS, MNIST, COIL20, PIE, Of\ufb01ce, and Caltech-256.TypeDigitDigitObjectFaceObjectObject#Examples1,8002,0001,44011,5541,4101,123#Features2562561,0241,024800800#Classes101020681010SubsetsUSPSMNISTCOIL1, COIL2PIE1, . . . , PIE5A, W, DC1-Nearest Neighbor Classi\ufb01er (NN)Principal Component Analysis (PCA) + NNGeodesic Flow Kernel (GFK) [6] + NNTransfer Component Analysis (TCA) [15] + NNTransfer Subspace Learning (TSL) [22] + NNis a benchmark face database. The database has 68 individuals with 41,368 face images of size 32\u00d732. The face imageswere captured by 13 synchronized cameras (different poses)and 21 \ufb02ashes (different illuminations and/or expressions).In these experiments, to thoroughly evaluate that our approach can perform robustly across different distributions,we adopt \ufb01ve subsets of PIE, each corresponding to a different pose. Speci\ufb01cally, we choose PIE1 (C05, left pose),PIE2 (C07, upward pose), PIE3 (C09, downward pose),PIE4 (C27, frontal pose), PIE5 (C29, right pose). In eachsubset (pose), all the face images are taken under differentlighting, illumination, and expression conditions. By randomly selecting two different subsets (poses) as the sourcedomain and target domain respectively, we can construct5 \u00d7 4 = 20 cross-domain face datasets, e.g., PIE1 vs PIE2,PIE1 vs PIE3, PIE1 vs PIE4, PIE1 vs PIE5, . . . , PIE5 vsPIE4. In this way, the source and target data are constructedusing face images from different poses, and thus will followsigni\ufb01cantly different distributions. Moreover, the distribution differences in these datasets may vary a lot, since forexample, the difference between the left and right poses islarger than the difference between the left and frontal poses.Of\ufb01ce [20, 6] is an increasingly popular benchmark forvisual domain adaptation. The database contains three realworld object domains, Amazon (images downloaded fromonline merchants), Webcam (low-resolution images by aweb camera), and DSLR (high-resolution images by a digital SLR camera). It has 4,652 images and 31 categories.Caltech-256 [9] is a standard database for object recognition. The database has 30,607 images and 256 categories.In these expriments, we adopt the public Of\ufb01ce+Caltechdatasets released by Gong et al. [6]. SURF features are extracted and quantized into an 800-bin histogram with codebooks computed with Kmeans on a subset of images fromAmazon. Then the histograms are standardized by z-score.Speci\ufb01cally, we have four domains, C (Caltech-256), A (Amazon), W (Webcam), and D (DSLR). By randomly selecting two different domains as the source domain and targetdomain respectively, we construct 4 \u00d7 3 = 12 cross-domainobject datasets, e.g., C \u2192 A, C \u2192 W, C \u2192 D, . . . , D \u2192 W.where Dt is the set of test data, y(x) is the truth label of x,y(x) is the label predicted by the classi\ufb01cation algorithm.4.2. Baseline Methods4.4. Experimental ResultsWe compare our JDA approach with \ufb01ve state-of-the-art(related) baseline methods for image classi\ufb01cation problem.The classi\ufb01cation accuracies of JDA and the \ufb01ve baseline methods on the 36 cross-domain image (digit, face, andSpeci\ufb01cally, TCA and TSL can both be viewed as a specialcase of JDA with C = 0. TSL adopts Bregman divergenceinstead of MMD as the distance for comparing distributions.As suggested by [6], NN is chosen as the base classi\ufb01ersince it does not require tuning cross-validation parameters.4.3. Implementation DetailsFollowing [6, 15], NN is trained on the labeled sourcedata, and tested on the unlabeled target data; PCA, TSL,TCA, and JDA are performed on all data as a dimensionalityreduction procedure, then an NN classi\ufb01er is trained on thelabeled source data for classifying the unlabeled target data.Under our experimental setup, it is impossible to tunethe optimal parameters using cross validation, since labeledand unlabeled data are sampled from different distributions.Thus we evaluate all methods by empirically searching theparameter space for the optimal parameter settings, and report the best results of each method. For subspace learningmethods, we set #bases by searching k \u2208 [10, 20, . . . , 200].For transfer learning methods, we set adaptation regularization parameter \u03bb by searching \u03bb \u2208 {0.01, 0.1, 1, 10, 100}.The JDA approach involves only two model parameters:#subspace bases k and regularization parameter \u03bb. In thecoming sections, we provide empirical analysis on parameter sensitivity, which veri\ufb01es that JDA can achieve stableperformance under a wide range of parameter values. In thecomparative study, we set k = 100 and 1) \u03bb = 0.1 for thedigit/face datasets, 2) \u03bb = 1.0 for the object datasets. Thenumber of iterations for JDA to converge is T = 10. We donot run JDA repeatedly since it has no random initialization.We use classi\ufb01cation Accuracy on test data as the evaluation metric, which is widely used in literature [22, 15, 6]Accuracy =2204|x : x \u2208 Dt \u2227 y (x) = y (x)||x : x \u2208 Dt |(11)\f100100NNPCAGFKTCATSLNNPCAGFKTCATSLJDANN80807060PCAGFKTCATSLJDA80Accuracy (%)Accuracy (%)Accuracy (%)100JDA9060406040504020USPS vs MNIST MNIST vs USPS COIL1 vs COIL2 COIL2 vs COIL1Dataset2468101214Dataset Index (PIE)16182020123456789Dataset Index (Office+Caltech)101112Figure 3. Accuracy (%) on the 4 types of 36 cross-domain image datasets, each under different dif\ufb01culty in knowledge adaptation.Table 3. Accuracy (%) on 4 types of cross-domain image datasets.DatasetUSPS vs MNISTMNIST vs USPSCOIL1 vs COIL2COIL2 vs COIL1PIE1 vs PIE2 (1)PIE1 vs PIE3 (2)PIE1 vs PIE4 (3)PIE1 vs PIE5 (4)PIE2 vs PIE1 (5)PIE2 vs PIE3 (6)PIE2 vs PIE4 (7)PIE2 vs PIE5 (8)PIE3 vs PIE1 (9)PIE3 vs PIE2 (10)PIE3 vs PIE4 (11)PIE3 vs PIE5 (12)PIE4 vs PIE1 (13)PIE4 vs PIE2 (14)PIE4 vs PIE3 (15)PIE4 vs PIE5 (16)PIE5 vs PIE1 (17)PIE5 vs PIE2 (18)PIE5 vs PIE3 (19)PIE5 vs PIE4 (20)C\u2192A (1)C\u2192W (2)C\u2192D (3)A\u2192C (4)A\u2192W (5)A\u2192D (6)W\u2192C (7)W\u2192A (8)W\u2192D (9)D\u2192C (10)D\u2192A (11)D\u2192W (12)AverageStandard LearningNNPCA44.744.9565.9466.2283.6184.7282.7884.0326.0924.8026.5925.1830.6729.2616.6716.3024.4924.2246.6345.5354.0753.3526.5325.4321.3720.9541.0140.4546.5346.1426.2325.3132.9531.9662.6860.9673.2272.1837.1935.1118.4918.8524.1923.3928.3127.2131.2430.3423.7036.9525.7632.5425.4838.2226.0034.7329.8335.5925.4827.3919.8626.3622.9631.0059.2477.0726.2729.6528.5032.0563.3975.9337.4639.84GFK46.4567.2272.5074.1726.1527.2731.1517.5925.2447.3754.2527.0821.8243.1646.4126.7834.2462.9273.3537.3820.3524.6228.4931.3341.0240.6838.8540.2538.9836.3130.7229.7580.8930.2832.0575.5941.19Transfer LearningTCATSL51.0553.7556.2866.0688.4788.0685.8387.9240.7644.0841.7947.4959.6362.7829.3536.1541.8146.2851.4757.6064.7371.4333.7035.6634.6936.9447.7047.0256.2359.4533.1536.3455.6463.6667.8372.6875.8683.5240.2644.7926.9833.2829.9034.1329.9036.5833.6438.7538.2044.4738.6434.2441.4043.3137.7637.5837.6333.9033.1226.1129.3029.8330.0630.2787.2687.2631.7028.5032.1527.5686.1085.4247.2249.80datasets, but poorly on the other datasets. In GFK, the subspace dimension should be small enough to ensure differentsubspaces transit smoothly along the geodesic \ufb02ow, which,however, may not represent input data accurately. JDA performs much better by learning an accurate shared subspace.Thirdly, JDA signi\ufb01cantly outperforms TCA, which isa state-of-the-art transfer learning method based on featureextraction. A major limitation of TCA is that the differencein the conditional distributions is not explicitly reduced. JDA avoids this limitation and achieves much better results.Lastly, JDA achieves much better performance than TSL, which depends on the kernel density estimation (KDE)to match the marginal distributions. Theoretically, TSL canadapt the marginal distributions better than TCA, which isvalidated by the empirical results. However, TSL also doesnot explicitly reduce the difference in the conditional distributions. One possible dif\ufb01culty for TSL to adapt the conditional distributions is that TSL relies on the distributiondensity, which is hard to manipulate with partially incorrectpseudo labels. JDA succeeds in matching the conditionaldistributions through exploring only the suf\ufb01cient statistics.JDA59.6567.2889.3188.4758.8154.2384.5049.7557.6262.9375.8239.8950.9657.9568.4539.9580.5882.6387.2554.6646.4642.0553.3157.0144.7841.6945.2239.3637.9739.4931.1732.7889.1731.5233.0989.4957.374.5. Effectiveness Veri\ufb01cationWe further verify the effectiveness of JDA by inspectingthe distribution distance and the similarity of embeddings.Distribution Distance: We run NN, PCA, TCA, andJDA on dataset PIE1 vs PIE2 using their optimal parameter settings. Then we compute the aggregate MMD distance of each method on their induced embeddings by Equation (7). Note that, in order to compute the true distancein both the marginal and conditional distributions betweendomains, we have to use the groundtruth labels instead ofthe pseudo labels. However, the groundtruth target labelsare only used for veri\ufb01cation, not for learning procedure.Figure 4(a) shows the distribution distance computed foreach method, and \ufb01gure 4(b) shows the classi\ufb01cation accuracy. We can have these observations. 1) Without learninga feature representation, the distribution distance of NN inthe original feature space is the largest. 2) PCA can learna new representation in which the distribution distance is slightly reduced, but not much, thus it cannot help much forcross-domain problems. 3) TCA can substantially reducethe distribution distance by explicitly reducing the differ-object) datasets are illustrated in Table 3. The results arevisualized in Figure 3 for better interpretation. We observethat JDA achieves much better performance than the \ufb01vebaseline methods with statistical signi\ufb01cance. The averageclassi\ufb01cation accuracy of JDA on the 36 datasets is 57.37%and the performance improvement is 7.57% compared tothe best baseline method TSL, i.e., a signi\ufb01cant error reduction of 15.07%. Note that, the adaptation dif\ufb01culty in the36 datasets varies a lot, since the standard NN classi\ufb01er canonly achieve an average classi\ufb01cation accuracy of 37.46%,and may perform very poorly on many of the datasets. Thisveri\ufb01es that JDA can construct more effective and robustrepresentation for cross-domain image classi\ufb01cation tasks.Secondly, GFK performs pretty well on Of\ufb01ce+Caltech2205\f70NNPCATCAJDA1050NNPCATCAJDA50403051015#iterations20(a) MMD distance w.r.t. #iterations205050100100Example15Example60Accuracy (%)MMD Distance201502001015#iterations25030030035010020(b) Accuracy (%) w.r.t. #iterations2002503505150200Example300(c) Similarity of TCA embedding100200Example300(d) Similarity of JDA embeddingFigure 4. Effectiveness veri\ufb01cation: MMD distance, classi\ufb01cation accuracy, and similarity of embeddings on the PIE1 vs PIE2 dataset.ence in the marginal distributions, so it can achieve betterclassi\ufb01cation accuracy. 4) JDA can reduce the difference inboth the marginal and conditional distributions, thus it canextract a most effective and robust representation for crossdomain problems. By iteratively re\ufb01ning the pseudo labels,JDA can reduce the difference in conditional distributionsin each iteration to improve the classi\ufb01cation performance.Similarity of Embeddings: We run TCA and JDA ondataset PIE1 vs PIE2 using their optimal parameter settings.Then we compute the 20-nearest neighbor similarity matrixon the embedding Z = AT X obtained by TCA and JDArespectively. For better illustration, we only use the 365face images corresponding to the \ufb01rst 5 classes, in whichthe \ufb01rst 245 images are from the source data, the last 120images are from the target data. Correspondingly, in thesimilarity matrix, the top-left and bottom-right submatricesindicate within-domain similarity, the top-right and bottomleft submatrices indicate between-domain similarity. Also,the diagonal blocks of the similarity matrix indicate withinclass similarity in the same domain, the diagonal blocks ofthe top-right and bottom-left submatrices indicate withinclass similarity across domains, while all other blocks ofthe similarity matrix indicate between-class similarity.Figures 4(c) and 4(d) illustrate the similarity matrix ofTCA embedding and JDA embedding respectively. To bean effective and robust embedding for cross-domain classi\ufb01cation problems, 1) the between-domain similarity shouldbe high enough to establish knowledge transfer, and 2) thebetween-class similarity should be low to facilitate categorydiscrimination. In this sense, we see that TCA cannot extract a good embedding on which the between-domain similarity is high while the between-class similarity is low. Thisproves that only adapting the marginal distributions is notenough for transfer learning. It is interesting to observe thatJDA can indeed learn the ideal embedding, which can leadto better generalization capability across different domains.Table 4. Time complexity of JDA and all the baseline methods.MethodNNTCARuntime (s)4.853.80MethodPCATSLRuntime (s)2.631789MethodGFKJDARuntime (s)4.5846.32eter values. We only report the results on USPS vs MNIST,PIE1 vs PIE2, and A \u2192 D datasets, while similar trends onall other datasets are not shown due to space limitation.We run JDA with varying values of k. It can be chosensuch that the low-dimensional representation is accurate fordata reconstruction. We plot classi\ufb01cation accuracy w.r.t. different values of k in Figure 5(a), and choose k \u2208 [60, 200].We run JDA with varying values of \u03bb. Theoretically,larger values of \u03bb can make shrinkage regularization moreimportant in JDA. When \u03bb \u2192 0, the optimization problemis ill-de\ufb01ned. When \u03bb \u2192 \u221e, distribution adaptation is notperformed, and JDA cannot construct robust representationfor cross-domain classi\ufb01cation. We plot classi\ufb01cation accuracy w.r.t. different values of \u03bb in Figure 5(b), which indicates that \u03bb \u2208 [0.001, 1.0] can be optimal parameter values,where JDA generally does much better than the baselines.4.7. Convergence and Time ComplexityWe also empirically check the convergence property ofJDA. Figures 5(c) and 5(d) show that classi\ufb01cation accuracy (distribution distance) increases (decreases) steadily withmore iterations and converges within only 10 iterations.We check the time complexity by running all algorithmson the PIE1 vs PIE2 dataset with 1,024 features and 4,961images, and show the results in Table 4. We observe thatJDA is T -times worse than TCA but much better than TSL.5. Conclusion and Future WorkIn this paper, we propose a Joint Distribution Adaptation(JDA) approach for robust transfer learning. JDA aims tosimultaneously adapt both marginal and conditional distributions in a principled dimensionality reduction procedure.Extensive experiments show that JDA is effective and robust for a variety of cross-domain problems, and can significantly outperform several state-of-the-art adaptation methods even if the distribution difference is substantially large.4.6. Parameter SensitivityWe conduct sensitivity analysis to validate that JDA canachieve optimal performance under a wide range of param-2206\f50403020USPS vs MNISTPIE1 vs PIE2A\u2192D1020 40 60 80 100120140160180200k(a) #subspace bases k50403020USPS vs MNISTPIE1 vs PIE2A\u2192D100.0001 0.001 0.01\u03bb0.114504030USPS vs MNISTPIE1 vs PIE2A\u2192D201010(b) regularization parameter \u03bbUSPS vs MNISTPIE1 vs PIE2A\u2192Dx60MMD Distance (e )7060Accuracy (%)7060Accuracy (%)Accuracy (%)7051015#iterations(c) accuracy w.r.t. #iterations20321051015#iterations20(d) distance w.r.t. #iterationsFigure 5. Parameter sensitivity and convergence study for JDA on three types of datasets (dashed lines show the best baseline results).In the future, we plan to extend our distance measure toother representation learning methods, e.g., Sparse Coding.6. AcknowledgmentsThis work is supported by the National HGJ Key Project(2010ZX01042-002-002-01), the National High-Tech R&DProgram (863 Program) (2012AA040911), the National Basic Research Program (973 Program) (2009CB320700), andthe National Natural Science Foundation of China (NSFC)(61073005, 61271394). Philip S. Yu is supported in part byUS NSF through grants IIS-0905215, CNS-1115234, IIS0914934, DBI-0960443, OISE-1129076, and US Department of Army through grant W911NF-12-1-0066.References[1] A. Arnold, R. Nallapati, and W. W. Cohen. A comparativestudy of methods for transductive transfer learning. In Proceedings of ICDMW, 2007.[2] Y. Aytar and A. Zisserman. Tabula rasa: Model transfer forobject category detection. In Proceedings of ICCV, 2011.[3] L. Bruzzone and M. Marconcini. Domain adaptation problems: A dasvm classi\ufb01cation technique and a circular validation strategy. IEEE TPAMI, 32(5), 2010.[4] M. Chen, K. Q. Weinberger, and J. C. Blitzer. Co-trainingfor domain adaptation. In Proceedings of NIPS, 2011.[5] N. FarajiDavar, T. de Campos, J. Kittler, and F. Yan. Transductive transfer learning for action recognition in tennisgames. In Proceedings of ICCVW, 2011.[6] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic \ufb02owkernel for unsupervised domain adaptation. In Proceedingsof CVPR, 2012.[7] R. Gopalan, R. Li, and R. Chellappa. Domain adaptation forobject recognition: An unsupervised approach. In Proceedings of ICCV, 2011.[8] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Scholkopf, andA. J. Smola. A kernel method for the two-sample problem.In Proceedings of NIPS, 2006.[9] G. Grif\ufb01n, A. Holub, and P. Perona. Caltech-256 object category dataset. Technical report, Caltech, 2007.[10] M. Guillaumin and V. Ferrari. Large-scale knowledge transfer for object localization in imagenet. In Proceedings ofCVPR, 2012.[11] I.-H. Jhuo, D. Liu, D.-T. Lee, and S.-F. Chang. Robust visual domain adaptation with low-rank reconstruction. In Proceedings of CVPR, 2012.[12] L. Jie, T. Tommasi, and B. Caputo. Multiclass transfer learning from unconstrained priors. In Proc. of ICCV, 2011.[13] C. H. Lampert and O. Kro\u0308mer. Weakly-paired maximumcovariance analysis for multimodal dimensionality reductionand transfer learning. In Proceedings of ECCV, 2010.[14] C. H. Lampert, H. Nickisch, and S. Harmeling. Learning todetect unseen object classes by between-class attribute transfer. In Proceedings of CVPR, 2009.[15] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. IEEE TNN,22(2):199\u2013210, 2011.[16] S. J. Pan and Q. Yang. A survey on transfer learning. IEEETKDE, 22:1345\u20131359, 2010.[17] Q. Qiu, V. M. Patel, P. Turaga, and R. Chellappa. Domainadaptive dictionary learning. In Proceedings of ECCV, 2012.[18] B. Quanz, J. Huan, and M. Mishra. Knowledge transfer withlow-quality data: A feature extraction issue. IEEE TKDE,24(10), 2012.[19] S. D. Roy, T. Mei, W. Zeng, and S. Li. Socialtransfer: Crossdomain transfer learning from social streams for media applications. In Proceedings of ACM MM, 2012.[20] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In Proceedings ofECCV, 2010.[21] S. Satpal and S. Sarawagi. Domain adaptation of conditionalprobability models via feature subsetting. In Proceedings ofPKDD, 2007.[22] S. Si, D. Tao, and B. Geng. Bregman divergence-based regularization for transfer subspace learning. IEEE TKDE, 2010.[23] Q. Sun, R. Chattopadhyay, S. Panchanathan, and J. Ye.A two-stage weighting framework for multi-source domainadaptation. In Proceedings of NIPS, 2011.[24] H. Wang, F. Nie, H. Huang, and C. Ding. Dyadic transferlearning for cross-domain image classi\ufb01cation. In Proceedings of ICCV, 2011.[25] S. Wang, S. Jiang, Q. Huang, and Q. Tian. Multi-feature metric learning with knowledge transfer among semantics andsocial tagging. In Proceedings of CVPR, 2012.[26] E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga,and O. Verscheure. Cross domain distribution adaptation viakernel mapping. In Proceedings of KDD, 2009.2207\f", "This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence1Transductive Multi-view Zero-Shot LearningYanwei Fu, Timothy M. Hospedales, Tao Xiang and Shaogang GongAbstract\u2014Most existing zero-shot learning approaches exploit transfer learning via an intermediate semantic representation sharedbetween an annotated auxiliary dataset and a target dataset with different classes and no annotation. A projection from a low-levelfeature space to the semantic representation space is learned from the auxiliary dataset and applied without adaptation to thetarget dataset. In this paper we identify two inherent limitations with these approaches. First, due to having disjoint and potentiallyunrelated classes, the projection functions learned from the auxiliary dataset/domain are biased when applied directly to the targetdataset/domain. We call this problem the projection domain shift problem and propose a novel framework, transductive multi-viewembedding, to solve it. The second limitation is the prototype sparsity problem which refers to the fact that for each target class, only asingle prototype is available for zero-shot learning given a semantic representation. To overcome this problem, a novel heterogeneousmulti-view hypergraph label propagation method is formulated for zero-shot learning in the transductive embedding space. It effectivelyexploits the complementary information offered by different semantic representations and takes advantage of the manifold structures ofmultiple representation spaces in a coherent manner. We demonstrate through extensive experiments that the proposed approach(1) rectifies the projection shift between the auxiliary and target domains, (2) exploits the complementarity of multiple semanticrepresentations, (3) significantly outperforms existing methods for both zero-shot and N-shot recognition on three image and videobenchmark datasets, and (4) enables novel cross-view annotation tasks.Index Terms\u2014Transducitve learning, multi-view Learning, transfer Learning, zero-shot Learning, heterogeneous hypergraph.F1I NTRODUCTIONHumans can distinguish 30,000 basic object classes [3]and many more subordinate ones (e.g. breeds of dogs).They can also create new categories dynamically fromfew examples or solely based on high-level description.In contrast, most existing computer vision techniquesrequire hundreds of labelled samples for each objectclass in order to learn a recognition model. Inspiredby humans\u2019 ability to recognise without seeing samples,and motivated by the prohibitive cost of training samplecollection and annotation, the research area of learning tolearn or lifelong learning [35], [6] has received increasinginterests. These studies aim to intelligently apply previously learned knowledge to help future recognitiontasks. In particular, a major and topical challenge in thisarea is to build recognition models capable of recognising novel visual categories without labelled trainingsamples, i.e. zero-shot learning (ZSL).The key idea underpinning ZSL approaches is toexploit knowledge transfer via an intermediate-levelsemantic representation. Common semantic representations include binary vectors of visual attributes [27], [31],[15] (e.g. \u2019hasTail\u2019 in Fig. 1) and continuous word vectors[32], [11], [44] encoding linguistic context. In ZSL, twodatasets with disjoint classes are considered: a labelledauxiliary set where a semantic representation is given foreach data point, and a target dataset to be classified without any labelled samples. The semantic representation isassumed to be shared between the auxiliary/source and\u2022 The authors are with the School of Electronic Engineering and ComputerScience, Queen Mary University of London, E1 4NS, UK.Email: {y.fu,t.hospedales,t.xiang,s.gong}@qmul.ac.uktarget/test dataset. It can thus be re-used for knowledgetransfer between the source and target sets: a projectionfunction mapping low-level features to the semanticrepresentation is learned from the auxiliary data byclassifier or regressor. This projection is then applied tomap each unlabelled target class instance into the samesemantic space. In this space, a \u2018prototype\u2019 of each targetclass is specified, and each projected target instance isclassified by measuring similarity to the class prototypes.Depending on the semantic space, the class prototypecould be a binary attribute vector listing class properties(e.g., \u2019hasTail\u2019) [27] or a word vector describing thelinguistic context of the textual class name [11].Two inherent problems exist in this conventional zeroshot learning approach. The first problem is the projection domain shift problem. Since the two datasetshave different and potentially unrelated classes, theunderlying data distributions of the classes differ, sodo the \u2018ideal\u2019 projection functions between the lowlevel feature space and the semantic spaces. Therefore,using the projection functions learned from the auxiliary dataset/domain without any adaptation to thetarget dataset/domain causes an unknown shift/bias.We call it the projection domain shift problem. This isillustrated in Fig. 1, which shows two object classesfrom the Animals with Attributes (AwA) dataset [28]:Zebra is one of the 40 auxiliary classes while Pig isone of 10 target classes. Both of them share the same\u2018hasTail\u2019 semantic attribute, but the visual appearanceof their tails differs greatly (Fig. 1(a)). Similarly, manyother attributes of Pig are visually different from thecorresponding attributes in the auxiliary classes. Figure 1(b) illustrates the projection domain shift problemby plotting (in 2D using t-SNE [47]) an 85D attribute0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence2ZebraPrototypeThe same \u2018hasTail\u2019 attributedifferent visual appearancePigPrototypePigPrototype(a) visual space(b) attribute space(c) multi-view embedding spaceFigure 1. An illustration of the projection domain shiftproblem. Zero-shot prototypes are shown as red starsand predicted semantic attribute projections (defined inSec. 3.2) shown in blue.space representation of the image feature projections andclass prototypes (85D binary attribute vectors). A largediscrepancy can be seen between the Pig prototype inthe semantic attribute space and the projections of itsclass member instances, but not for the auxiliary Zebraclass. This discrepancy is caused when the projectionslearned from the 40 auxiliary classes are applied directlyto project the Pig instances \u2013 what \u2018hasTail\u2019 (as wellas the other 84 attributes) visually means is differentnow. Such a discrepancy will inherently degrade theeffectiveness of zero-shot recognition of the Pig classbecause the target class instances are classified accordingto their similarities/distances to those prototypes. To ourknowledge, this problem has neither been identified noraddressed in the zero-shot learning literature.The second problem is the prototype sparsity problem: for each target class, we only have a single prototype which is insufficient to fully represent what thatclass looks like. As shown in Figs. 6(b) and (c), thereoften exist large intra-class variations and inter-classsimilarities. Consequently, even if the single prototypeis centred among its class instances in the semantic representation space, existing zero-shot classifiers will stillstruggle to assign correct class labels \u2013 one prototype perclass is not enough to represent the intra-class variabilityor help disambiguate class overlap [39].In addition to these two problems, conventional approaches to zero-shot learning are also limited in exploiting multiple intermediate semantic representations.Each representation (or semantic \u2018view\u2019) may containcomplementary information \u2013 useful for distinguishingdifferent classes in different ways. While both visualattributes [27], [9], [31], [15] and linguistic semanticrepresentations such as word vectors [32], [11], [44] havebeen independently exploited successfully, it remainsunattempted and non-trivial to synergistically exploitmultiple semantic views. This is because they are oftenof very different dimensions and types and each suffersfrom different domain shift effects discussed above.In this paper, we propose to solve the projectiondomain shift problem using transductive multi-viewembedding. The transductive setting means using theunlabelled test data to improve generalisation accuracy.In our framework, each unlabelled target class instance isrepresented by multiple views: its low-level feature viewand its (biased) projections in multiple semantic spaces(visual attribute space and word space in this work).To rectify the projection domain shift between auxiliaryand target datasets, we introduce a multi-view semanticspace alignment process to correlate different semanticviews and the low-level feature view by projecting themonto a common latent embedding space learned usingmulti-view Canonical Correlation Analysis (CCA) [17].The intuition is that when the biased target data projections (semantic representations) are correlated/alignedwith their (unbiased) low-level feature representations,the bias/projection domain shift is alleviated. The effectsof this process on projection domain shift are illustratedby Fig. 1(c), where after alignment, the target Pig classprototype is much closer to its member points in thisembedding space. Furthermore, after exploiting the complementarity of different low-level feature and semanticviews synergistically in the common embedding space,different target classes become more compact and moreseparable (see Fig. 6(d) for an example), making thesubsequent zero-shot recognition a much easier task.Even with the proposed transductive multi-view embedding framework, the prototype sparsity problem remains \u2013 instead of one prototype per class, a handfulare now available depending on how many views areembedded, which are still sparse. Our solution is to posethis as a semi-supervised learning [57] problem: prototypes in each view are treated as labelled \u2018instances\u2019,and we exploit the manifold structure of the unlabelleddata distribution in each view in the embedding spacevia label propagation on a graph. To this end, we introduce a novel transductive multi-view hypergraph labelpropagation (TMV-HLP) algorithm for recognition. Thecore in our TMV-HLP algorithm is a new distributedrepresentation of graph structure termed heterogeneoushypergraph which allows us to exploit the complementarity of different semantic and low-level feature views,as well as the manifold structure of the target data tocompensate for the impoverished supervision availablefrom the sparse prototypes. Zero-shot learning is thenperformed by semi-supervised label propagation fromthe prototypes to the target data points within and acrossthe graphs. The whole framework is illustrated in Fig. 2.By combining our transductive embedding frameworkand the TMV-HLP zero-shot recognition algorithm, ourapproach generalises seamlessly when none (zero-shot),or few (N-shot) samples of the target classes are available. Uniquely it can also synergistically exploit zero+ N-shot (i.e., both prototypes and labelled samples)learning. Furthermore, the proposed method enables anumber of novel cross-view annotation tasks includingzero-shot class description and zero prototype learning.Our contributions Our contributions are as follows: (1)To our knowledge, this is the first attempt to investi-0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence3gate and provide a solution to the projection domainshift problem in zero-shot learning. (2) We propose atransductive multi-view embedding space that not onlyrectifies the projection shift, but also exploits the complementarity of multiple semantic representations of visualdata. (3) A novel transductive multi-view heterogeneoushypergraph label propagation algorithm is developed toimprove both zero-shot and N-shot learning tasks in theembedding space and overcome the prototype sparsityproblem. (4) The learned embedding space enables anumber of novel cross-view annotation tasks. Extensiveexperiments are carried out and the results show that ourapproach significantly outperforms existing methods forboth zero-shot and N-shot recognition on three imageand video benchmark datasets.2R ELATED W ORKSemantic spaces for zero-shot learning To addresszero-shot learning, attribute-based semantic representations have been explored for images [27], [9] and to alesser extent videos [31], [15]. Most existing studies [27],[24], [33], [34], [41], [54], [1] assume that an exhaustiveontology of attributes has been manually specified ateither the class or instance level. However, annotatingattributes scales poorly as ontologies tend to be domainspecific. This is despite efforts exploring augmenteddata-driven/latent attributes at the expense of nameability [9], [31], [15]. To address this, semantic representations using existing ontologies and incidental datahave been proposed [38], [37]. Recently, word vector approaches based on distributed language representationshave gained popularity. In this case a word space is extracted from linguistic knowledge bases e.g., Wikipediaby natural language processing models such as [4],[32]. The language model is then used to project eachclass\u2019 textual name into this space. These projections canbe used as prototypes for zero-shot learning [11], [44].Importantly, regardless of the semantic spaces used, existing methods focus on either designing better semanticspaces or how to best learn the projections. The formeris orthogonal to our work \u2013 any semantic spaces can beused in our framework and better ones would benefitour model. For the latter, no existing work has identifiedor addressed the projection domain shift problem.Transductive zero-shot learning was considered by Fuet al. [13], [15] who introduced a generative model to foruser-defined and latent attributes. A simple transductivezero-shot learning algorithm is proposed: averaging theprototype\u2019s k-nearest neighbours to exploit the test dataattribute distribution. Rohrbach et al. [36] proposed amore elaborate transductive strategy, using graph-basedlabel propagation to exploit the manifold structure ofthe test data. These studies effectively transform theZSL task into a transductive semi-supervised learningtask [57] with prototypes providing the few labelledinstances. Nevertheless, these studies and this paper (aswith most previous work [28], [27], [37]) only considerrecognition among the novel classes: unifying zero-shotwith supervised learning remains an open challenge [44].Domain adaptation Domain adaptation methods attempt to address the domain shift problems that occur when the assumption that the source and targetinstances are drawn from the same distribution is violated. Methods have been derived for both classification[10], [8] and regression [45], and both with [8] andwithout [10] requiring label information in the targettask. Our zero-shot learning problem means that most ofsupervised domain adaptation methods are inapplicable.Our projection domain shift problem differs from theconventional domain shift problems in that (i) it isindirectly observed in terms of the projection shift ratherthan the feature distribution shift, and (ii) the sourcedomain classes and target domain classes are completelydifferent and could even be unrelated. Consequentlyour domain adaptation method differs significantly fromthe existing unsupervised ones such as [10] in that ourmethod relies on correlating different representations ofthe unlabelled target data in a multi-view embeddingspace.Learning multi-view embedding spaces Relating lowlevel feature and semantic views of data has been exploited in visual recognition and cross-modal retrieval.Most existing work [43], [17], [23], [51] focuses onmodelling images/videos with associated text (e.g. tagson Flickr/YouTube). Multi-view CCA is often exploitedto provide unsupervised fusion of different modalities.However, there are two fundamental differences between previous multi-view embedding work and ours:(1) Our embedding space is transductive, that is, learnedfrom unlabelled target data from which all semanticviews are estimated by projection rather than being theoriginal views. These projected views thus have theprojection domain shift problem that the previous workdoes not have. (2) The objectives are different: we aimto rectify the projection domain shift problem via theembedding in order to perform better recognition andannotation while previous studies target primarily crossmodal retrieval. Note that although in this work, thepopular CCA model is adopted for multi-view embedding, other models [40], [49] could also be considered.Graph-based label propagation In most previous zeroshot learning studies (e.g., direct attribute prediction(DAP) [28]), the available knowledge (a single prototypeper target class) is very limited. There has therefore beenrecent interest in additionally exploiting the unlabelledtarget data distribution by transductive learning [36],[15]. However, both [36] and [15] suffer from the projection domain shift problem, and are unable to effectivelyexploit multiple semantic representations/views. In contrast, after embedding, our framework synergisticallyintegrates the low-level feature and semantic representations by transductive multi-view hypergraph label propagation (TMV-HLP). Moreover, TMV-HLP generalisesbeyond zero-shot to N-shot learning if labelled instancesare available for the target classes.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence4In a broader context, graph-based label propagation[55] in general, and classification on multi-view graphs(C-MG) in particular are well-studied in semi-supervisedlearning. Most C-MG solutions are based on the seminal work of Zhou et al [56] which generalises spectralclustering from a single graph to multiple graphs bydefining a mixture of random walks on multiple graphs.In the embedding space, instead of constructing local neighbourhood graphs for each view independently(e.g. TMV-BLP [14]), this paper proposes a distributedrepresentation of pairwise similarity using heterogeneoushypergraphs. Such a distributed heterogeneous hypergraph representation can better explore the higher-orderrelations between any two nodes of different complementary views, and thus give rise to a more robustpairwise similarity graph and lead to better classificationperformance than previous multi-view graph methods[56], [14]. Hypergraphs have been used as an effectivetool to align multiple data/feature modalities in datamining [29], multimedia [12] and computer vision [30],[19] applications. A hypergraph is the generalisation ofa 2-graph with edges connecting many nodes/vertices,versus connecting two nodes in conventional 2-graphs.This makes it cope better with noisy nodes and thusachieve better performance than conventional graphs[21], [22], [12]. The only existing work considering hypergraphs for multi-view data modelling is [19]. Differentfrom the multi-view hypergraphs proposed in [19] whichare homogeneous, that is, constructed in each viewindependently, we construct a multi-view heterogeneoushypergraph: using the nodes from one view as querynodes to compute hyperedges in another view. Thisnovel graph structure better exploits the complementarity of different views in the common embedding space.3 L EARNING A T RANSDUCTIVE M ULTI -V IEWE MBEDDING S PACEA schematic overview of our framework is given inFig. 2. We next introduce some notation and assumptions, followed by the details of how to map imagefeatures into each semantic space, and how to mapmultiple spaces into a common embedding space.3.1Problem setupWe have cS source/auxiliary classes with \bnS instancesS = {XS , YSi , zS } and cT target classes T = XT , YTi , zTwith nT instances. XS \u2208 Rns \u00d7t and XT \u2208 RnT \u00d7t denotethe t\u2212dimensional low-level feature vectors of auxiliaryand target instances respectively. zS and zT are theauxiliary and target class label vectors. We assume theauxiliary and target classes are disjoint: zS \u2229 zT = \u2205. Wehave I different types of semantic representations; YSiand YTi represent the i-th type of mi -dimensional semantic representation for the auxiliary and target datasetsrespectively; so YSi \u2208 RnS \u00d7mi and YTi \u2208 RnT \u00d7mi . Notethat for the auxiliary dataset, YSi is given as each datapoint is labelled. But for the target dataset, YTi is missing,and its prediction Y\u0302Ti from XT is used instead. As weshall see, this is obtained using a projection functionlearned from the auxiliary dataset. The problem of zeroshot learning is to estimate zT given XT and Y\u0302Ti .Without any labelled data for the target classes, external knowledge is needed to represent what each targetclass looks like, in the form of class prototypes. Specifically, each target class c has a pre-defined class-levelsemantic prototype yci in each semantic view i. In thispaper, we consider two types of intermediate semanticrepresentation (i.e. I = 2) \u2013 attributes and word vectors, which represent two distinct and complementarysources of information. We use X , A and V to denotethe low-level feature, attribute and word vector spacesrespectively. The attribute space A is typically manuallydefined using a standard ontology. For the word vectorspace V, we employ the state-of-the-art skip-gram neuralnetwork model [32] trained on all English Wikipediaarticles1 . Using this learned model, we can project thetextual name of any class into the V space to get its wordvector representation. Unlike semantic attributes, it is a\u2018free\u2019 semantic representation in that this process doesnot need any human annotation. We next address howto project low-level features into these two spaces.3.2Learning the projections of semantic spacesMapping images and videos into semantic space i requires a projection function f i : X \u2192 Y i . This is typically realised by classifier [27] or regressor [44]. In thispaper, using the auxiliary set S, we train support vectorclassifiers f A (\u00b7) and support vector regressors f V (\u00b7) foreach dimension2 of the auxiliary class attribute and wordvectors respectively. Then the target class instances XThave the semantic projections: Y\u0302TA = f A (XT ) and Y\u0302TV =f V (XT ). However, these predicted intermediate semantics have the projection domain shift problem illustratedin Fig. 1. To address this, we learn a transductive multiview semantic embedding space to align the semanticprojections with the low-level features of target data.3.3Transductive multi-view embeddingWe introduce a multi-view semantic alignment (i.e.transductive multi-view embedding) process to correlatetarget instances in different (biased) semantic view projections with their low-level feature view. This processalleviates the projection domain shift problem, as wellas providing a common space in which heterogeneousviews can be directly compared, and their complementarity exploited (Sec. 4). To this end, we employmulti-view Canonical Correlation Analysis (CCA) fornV views, with the target data representation in viewi denoted \u03a6i , a nT \u00d7 mi matrix. Specifically, we project1. To 13 Feb. 2014, it includes 2.9 billion words from a 4.33 millionwords vocabulary (single and bi/tri-gram words).2. Note that methods for learning projection functions for all dimensions jointly exist (e.g. [11]) and can be adopted in our framework.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence5Target data:XTPig vs. Giant panda\u03a8{X,A,V}\u03c8c{X,A,V}Low-level feature spaceA X T)f(Vf (XT)CCA(XT, Y\u0302TV, Y\u0302TA )Classification by label propagationHypergraph in multi-view embedding spaceiontatenPrototypes of PigSemanticY\u02c6 VTPrototypes of Giant Pandaword spacriAttetebuRresep\u02c6TYAFigure 2. The pipeline of our framework illustrated on the task of classifying unlabelled target data into two classes.three views of each target class instance f A (XT ), f V (XT )and XT (i.e. nV = I + 1 = 3) into a shared embeddingspace. The three projection functions W i are learned byPnVminnT race(W i \u03a3ij W j )i,j=1V{Wi }i=1=PnVi,j=1\u0002 \u0003Ts.t. W i \u03a3ii W i = Ii 6= j, k 6= li, j = 1, \u00b7 \u00b7 \u00b7 , nVk \u03a6i W i \u2212 \u03a6j W j k2F\u0002 i \u0003Twk \u03a3ij wlj = 0k, l = 1, \u00b7 \u00b7 \u00b7 , nT(1)ding space, \u03bb is a power weight of Di and empiricallyset to 4 [17], and \u03a8i is the final representation of thetarget data from view i in \u0393. We index the nV = 3 viewsas i \u2208 {X , V, A} for notational convenience. The sameformulation can be used if more views are available.Similarity in the embedding space The choice ofsimilarity metric is important for high-dimensional embedding spaces. For the subsequent recognition andannotation tasks, we compute cosine distance in \u0393 by l2normalisation: normalising any vector \u03c8ki (the k-th rowof \u03a8i ) to unit length (i.e. k \u03c8ki k2 = 1). Cosine similarityis given by the inner product of any two vectors in \u0393.where W i is the projection matrix which maps the view\u03a6i (\u2208 RnT \u00d7mi ) into the embedding space and wki isthe kth column of W i . \u03a3ij is the covariance matrixbetween \u03a6i and \u03a6j . The optimisation problem above ismulti-convex as long as \u03a3ii are non-singular. The localoptimum can be easily found by iteratively maximisingover each W i given the current values of the othercoefficients as detailed in [18].The dimensionality me of the embedding spacePnVis thesum of the input view dimensions, i.e. me = i=1mi ,so W i \u2208 Rmi \u00d7me . Compared to the classic approach toCCA [18] which projects to a lower dimension space, thisretains all the input information including uncorrelateddimensions which may be valuable and complementary.Side-stepping the task of explicitly selecting a subspacedimension, we use a more stable and effective softweighting strategy to implicitly emphasise significantdimensions in the embedding space. This can be seenas a generalisation of standard dimension reducingapproaches to CCA, which implicitly define a binaryweight vector that activates a subset of dimensions anddeactivates others. Since the importance of each dimension is reflected by its corresponding eigenvalue [18],[17], we use the eigenvalues to weight the dimensionsand define a weighted embedding space \u0393:\u0002 \u0003\u03bb\u03a8i = \u03a6i W i Di = \u03a6i W i D\u0303i ,(2)For zero-shot recognition, each target class c to berecognised has a semantic prototype yci in each viewi. Similarly, we have three views of each unlabelledinstance f A (XT ), f V (XT ) and XT . The class prototypesare expected to be the mean of the distribution of theirclass in semantic space, since the projection functionf i is trained to map instances to their class prototypein each semantic view. To exploit the learned space \u0393to improve recognition, we project both the unlabelledinstances and the prototypes into the embedding space3 .The prototypes yci for views i \u2208 {A, V} are projectedas \u03c8ci = yci W i D\u0303i . So we have \u03c8cA and \u03c8cV for theattribute and word vector prototypes of each target classc in \u0393. In the absence of a prototype for the (nonsemantic) low-level feature view X , we synthesise it as\u03c8cX = (\u03c8cA + \u03c8cV )/2. If labelled data is available (i.e., Nshot case), these are also projected into the space. Recognition could now be achieved using NN classificationwith the embedded prototypes/N-shots as labelled data.However, this does not effectively exploit the multi-viewwhere Di is a diagonal matrix with its diagonal elementsset to the eigenvalues of each dimension in the embed-3. Before being projected into \u0393, the prototypes are updated by semilatent zero shot learning algorithm in [15].4R ECOGNITION BY M ULTI - VIEWGRAPH L ABEL P ROPAGATION0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.H YPER -\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence6complementarity, and suffers from labelled data (prototype) sparsity. To solve this problem, we next introduce aunified framework to fuse the views and transductivelyexploit the manifold structure of the unlabelled targetdata to perform zero-shot and N-shot learning.Most or all of the target instances are unlabelled, soclassification based on the sparse prototypes is effectively a semi-supervised learning problem [57]. We leverage graph-based semi-supervised learning to exploit themanifold structure of the unlabelled data transductivelyfor classification. This differs from the conventional approaches such as direct attribute prediction (DAP) [28]or NN, which too simplistically assume that the datadistribution for each target class is Gaussian or multinomial. However, since our embedding space containsmultiple projections of the target data and prototypes,it is hard to define a single graph that synergisticallyexploits the manifold structure of all views. We thereforeconstruct multiple graphs within and across views in atransductive multi-view hypergraph label propagation(TMV-HLP) model. Specifically, we construct the heterogeneous hypergraphs across views to combine/alignthe different manifold structures so as to enhance therobustness and exploit the complementarity of differentviews. Semi-supervised learning is then performed bypropagating the labels from the sparse prototypes (zeroshot) and/or the few labelled target instances (N-shot)to the unlabelled data using random walk on the graphs.4.1Constructing heterogeneous hypergraphsPairwise node similarity The key idea behind a hypergraph based method is to group similar data points, represented as vertices/nodes on a graph, into hyperedges,so that the subsequent computation is less sensitive to individual noisy nodes. With the hyperedges, the pairwisesimilarity between two data points are measured as thesimilarity between the two hyperedges that they belongto, instead of that between the two nodes only. Forboth forming hyperedges and computing the similaritybetween two hyperedges, pairwise similarity betweentwo graph nodes needs to be defined. In our embeddingspace \u0393, each data point in each view defines a node,and the similarity between any pair of nodes is:\u03c9(\u03c8ki , \u03c8lj ) = exp(<\u03c8ki , \u03c8lj$2>)(3)where < \u03c8ki , \u03c8lj >2 is the square of inner productbetween the ith and jth projections of nodes k and l witha bandwidth parameter $4 . Note that Eq (3) defines thepairwise similarity between any two nodes within thesame view (i = j) or across different views (i 6= j).4. Most previous work [36], [56] sets $ by cross-validation. Inspiredby [26], a simpler strategy for setting $ is adopted: $ \u2248 median <k,l=1,\u00b7\u00b7\u00b7 ,n\u03c8ki , \u03c8lj >2 in order to have roughly the same number of similar anddissimilar sample pairs. This makes the edge weights from differentpairs of nodes more comparable.Heterogeneous hyperedges Given the multi-view projections of the target data, we aim to construct a set ofacross-view heterogeneous hypergraphs\bG c = G ij | i, j \u2208 {X , V, A} , i 6= j(4)\b i ij ijwhere G ij =\u03a8 ,E ,\u2126denotes the cross-viewheterogeneous hypergraph from view i to j (in thatorder) and \u03a8i is the node set in view i; E ij is thehyperedge set and \u2126ij is the pairwise node similarityset for the hyperedges.n Specifically, we have theoijhyperedge set E= eij|i=6j,k=1,\u00b7\u00b7\u00b7n+ciTT\u03c8kincludes the nodes5where each hyperedge eiji\u03c8kin view j that are the most similar to nodeij\u03c8ki in nview=o\u0010 i and\u0011o the similarity set \u2126njjijiji| i 6= j, \u03c8l \u2208 e\u03c8i k = 1, \u00b7 \u00b7 \u00b7 nT + cT\u2206\u03c8 i = \u03c9 \u03c8 k , \u03c8 lkk\u0010\u0011jwhere \u03c9 \u03c8ki , \u03c8l is computed using Eq (3).We call \u03c8ki the query node for hyperedge eij, since the\u03c8ikhyperedge eiji intrinsically groups all nodes in view j\u03c8kthat are most similar to node \u03c8ki in view i. Similarly, G jican be constructed by using nodes from view j to querynodes in view i. Therefore given three views, we have sixacross view/heterogeneous hypergraphs. Figure 3 illustrates two heterogeneous hypergrahs constructed fromtwo views. Interestingly, our way of defining hyperedgesnaturally corresponds to the star expansion [46] wherethe query node (i.e. \u03c8ki ) is introduced to connect eachnode in the hyperedge eiji.\u03c8kSimilarity strength of hyperedge For each hyperedgeeij, we measure its similarity strength by using its query\u03c8ikijnodes \u03c8ki . Specifically, we use the weight \u03b4\u03c8i to indicatekthe similarity strength of nodes connected within theijhyperedge eij. Thus, we define \u03b4\u03c8i based on the mean\u03c8ikksimilarity of the set \u2206ijfor the hyperedge\u03c8ikij\u03b4\u03c8i =k1X| eij|\u03c8iki ,\u03c8 j\u03c8kl\u03c9(\u0010\u0011\u03c9 \u03c8ki , \u03c8lj ,(5)\u2208\u2206iji ,\u03c8lj \u2208eiji\u03c8\u03c8kk)where | eij| is the cardinality of hyperedge eij.\u03c8i\u03c8ikkIn the embedding space \u0393, similarity sets \u2206ijand\u03c8ik\u2206ijcan be compared. Nevertheless, these sets come\u03c8lifrom heterogeneous views and have varying scales. Thussome normalisation steps are necessary to make thetwo similarity sets more comparable and the subsequentcomputation more robust. Specifically, we extend zeroscore normalisation to the similarity sets: (a) We assume\u2200\u2206ij\u2208 \u2126ij and \u2206ijshould follow Gaussian distribu\u03c8i\u03c8ikktion. Thus, we enforce zero-score normalisation to \u2206iji.\u03c8k(b) We further assume that the retrieved similarity set\u2126ij between all the queried nodes \u03c8ki (l = 1, \u00b7 \u00b7 \u00b7 nT ) fromview i and \u03c8lj should also follow Gaussian distributions.5. Both the unlabelled samples and the prototypes are nodes.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence7GGe DijAAAijeView j in \u0393ijeEDCBFFCCBjiBeGHeterogenous hyperedgeeFjiEEjieCFGCorrelated-nodes in \u0393eEjiDeijGijeCDjieAFCAAAEeFijEBBeDjiView i in \u0393DijBjieGjiGGFigure 3. An example of constructing heterogeneous hypergraphs. Suppose in the embedding space, we have 14nodes belonging to 7 data points A, B, C, D, E, F and G of two views \u2013 view i (rectangle) and view j (circle). Datapoints A,B,C and D,E,F ,G belong to two different classes \u2013 red and green respectively. The multi-view semanticembedding maximises the correlations (connected by black dash lines) between the two views of the same node. Twohypergraphs are shown (G ij at the left and G ji at the right) with the heterogeneous hyperedges drawn with red/greendash ovals for the nodes of red/green classes. Each hyperedge consists of two most similar nodes to the query node.So we again enforce Gaussian distribution to the pairwise similarities between \u03c8lj and all query nodes fromview i by zero-score normalisation. (c) We select the first\u00af ijK highest values from \u2206iji as new similarity set \u2206\u03c8 i for\u03c8kk\u00af iji is then used in Eq (5) in place ofhyperedge eiji . \u2206\u03c8k\u2206iji.\u03c8k\u03c8kThese normalisation steps aim to compute a morerobust similarity between each pair of hyperedges.Computing similarity between hyperedgesWiththe hypergraph, the similarity between two nodes iscomputed using their hyperedges eiji . Specifically, for\u03c8keach hyperedgethereisanassociatedincidence matrix\u0010 \u0010\u0011\u0011j ijijH = h \u03c8l , e\u03c8iwhereijkh\u0010\u03c8lj , eiji\u03c8k(nT +cT )\u00d7|E |\u0011(=1if \u03c8lj \u2208 eij\u03c8i0otherwise(6)kTo take into consideration the similarity strength between hyperedge and query node, we extend the binaryijvalued hyperedge incidenceH \u0011\u0011to soft-assigned\u0010 matrix\u0010jijijincidence matrix SH = sh \u03c8l , e\u03c8iaskfollows(nT +cT )\u00d7|E ij |\u0010\u0011\u0010\u0011 \u0010\u0011ijjj ijish \u03c8lj , eij=\u03b4\u00b7\u03c9\u03c8,\u03c8\u00b7h\u03c8,eiiikll\u03c8\u03c8\u03c8kk(7)kThis soft-assigned incidence matrix is the product ofthree components: (1) the weight \u03b4\u03c8ki for hyperedgeeiji ; (2) the pairwise similarity computed using queried\u03c8knode \u03c8ki ; (3) the\u0010 binary \u0011valued hyperedge incidencematrix element h \u03c8lj , eij. To make the values of SH iji\u03c8kcomparable among the different heterogeneous views,we apply l2 normalisation to the soft-assigned incidencematrix values for all node incident to each hyperedge.Now for each heterogeneous hypergraph, we can finally define the pairwise similarity between any twonodes or hyperedges. Specifically for G ij , the similaritybetween the o-th and l-th nodes is\u0010\u0011\u0010\u0011\u0010\u0011X\u03c9cij \u03c8oj , \u03c8lj =sh \u03c8oj , eij\u00b7 sh \u03c8lj , eij. (8)\u03c8i\u03c8ieiji \u2208E ijkk\u03c8kWith this pairwise hyperedge similarity, the hypergraph definition is now complete. Empirically, given anode, other nodes on the graph that have very lowsimilarities will have very limited effects on its label.Thus, to reduce computational cost, we only use the Knearest-neighbour (KNN)6 nodes of each node [57] forthe subsequent label propagation step.The advantages of heterogeneous hypergraphs Weargue that the pairwise similarity of heterogeneous hypergraphs is a distributed representation [2]. To explainit, we can use star extension [46] to extend a hypergraphinto a 2-graph. For each hyperedge eij, the query node\u03c8ik\u03c8ki is used to compute the pairwise similarity \u2206iji of all\u03c8kthe nodes in view j. Each hyperedge can thus define ahyper-plane by categorising the nodes in view j into twogroups: strong and weak similarity group regarding toquery node \u03c8ki . In other words, the hyperedge set E ijis multi-clustering with linearly separated regions (byeach hyperplane) per classes. Since the final pairwisesimilarity in Eq (8) can be represented by a set ofsimilarity weights computed by hyperedge, and suchweights are not mutually exclusive and are statisticallyindependent, we consider the heterogeneous hypergrapha distributed representation. The advantage of havinga distributed representation has been studied by Wattsand Strogatz [52], [53] which shows that such a representation gives rise to better convergence rates andbetter clustering abilities. In contrast, the homogeneoushypergraphs adopted by previous work [22], [12], [19]does not have this property which makes them lessrobust against noise. In addition, fusing different viewsin the early stage of graph construction potentially can6. K = 30. It can be varied from 10 \u223c 50 with little effect in ourexperiments.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence8lead to better exploitation of the complementarity ofdifferent views. However, it is worth pointing out that(1) The reason we can query nodes across views toconstruct heterogeneous hypergraph is because we haveprojected all views in the same embedding space in thefirst place. (2) Hypergraphs typically gain robustness atthe cost of losing discriminative power \u2013 it essentiallyblurs the boundary of different clusters/classes by takingaverage over hyperedges. A typical solution is to fusehypergraphs with 2-graphs [12], [19], [29], which weadopt here as well.The stationary probabilities for node k in G i and G ijareP i i il \u03c9p (\u03c8k , \u03c8l )i(13)\u03c0(k|G ) = P Piiiol \u03c9p (\u03c8k , \u03c8o )P ij j jl \u03c9c (\u03c8k , \u03c8l )(14)\u03c0(k|G ij ) = P Pijjjko \u03c9c (\u03c8k , \u03c8o )Finally, the stationary probability across the multiview hypergraph is computed as:X\u03c0(k) =\u03c0(k|G i ) \u00b7 p(G i )+(15)i\u2208{X ,V,A}4.2XLabel propagation by random walkNow we have twohy\b types of graphs: heterogeneous\bpergraphs G c = G ij and 2-graphs7 G p = G i . Giventhree views (nV = 3), we thus have nine graphs in total(six hypergraphs and three 2-graphs). To classify the unlabelled nodes, we need to propagate label informationfrom the prototype nodes across the graph. Such semisupervised label propagation [56], [57] has a closed-formsolution and is explained as a random walk. A randomwalk requires pairwise transition probability for nodesk and l. We obtain this by aggregating the informationfrom all graphs G = {G p ; G c },X\u0001\u0001p (k \u2192 l) =p k \u2192 l | G i \u00b7 p G i | k + (9)i\u2208{X ,V,A}X\u0001\u0001p k \u2192 l | G ij \u00b7 p G ij | ki,j\u2208{X ,V,A},i6=jwhereand\u0001\u03c9pi (\u03c8 i , \u03c8 i )p k \u2192 l | Gi = P i k i l i ,o \u03c9p (\u03c8k , \u03c8o )(10)\u0001\u03c9 ij (\u03c8 j , \u03c8 j )p k \u2192 l | G ij = P c ij k j l jo \u03c9c (\u03c8k , \u03c8o )and then the posterior probability to choose graph G i atprojection/node \u03c8ki will be:\u03c0(k|G i )p(G i )Piiijiji \u03c0(k|G )p(G ) +ij \u03c0(k|G )p(G )(11)\u03c0(k|G ij )p(G ij )P+ ij \u03c0(k|G ij )p(G ij )(12)p(G i |k) = Pp(G ij |k) = Pi\u03c0(k|G i )p(G i )where p(G i ) and p(G ij ) are the prior probability ofgraphs G i and G ij in the random walk. This probabilityexpresses prior expectation about the informativeness ofeach graph. The same Bayesian model averaging [14] canbe used here to estimate these prior probabilities. However, the computational cost is combinatorially increasedwith the number of views; and it turns out the prior isnot critical to the results of our framework. Therefore,uniform prior is used in our experiments.7. That is the K-nearest-neighbour graph of each view in \u0393 [14].\u03c0(k|G ij ) \u00b7 p(G ij )(16)i,j\u2208{X ,V,A},i6=jGiven the defined graphs and random walk process, wecan derive our label propagation algorithm (TMV-HLP).Let P denote the transition probability matrix defined byEq (9) and \u03a0 the diagonal matrix with the elements \u03c0(k)computed by Eq (15). The Laplacian matrix L combinesinformation of different views and is defined as: L =T\u03a0. The label matrix Z for labelled N-shot data\u03a0\u2212 \u03a0P +P2or zero-shot prototypes is defined as:\uf8f1\uf8f4qk \u2208 class c\uf8f2 1(17)Z(qk , c) =\u22121qk \u2208/ class c\uf8f4\uf8f30unknownGiven the label matrix Z and Laplacian L, label propagation on multiple graphs has the closed-form solution[56]: Z\u0302 = \u03b7(\u03b7\u03a0 + L)\u22121 \u03a0Z where \u03b7 is a regularisationparameter8 . Note that in our framework, both labelledtarget class instances and prototypes are modelled asgraph nodes. Thus the difference between zero-shot andN-shot learning lies only on the initial labelled instances:Zero-shot learning has the prototypes as labelled nodes;N-shot has instances as labelled nodes; and a new condition exploiting both prototypes and N-shot togetheris possible. This unified recognition framework thusapplies when either or both of prototypes and labelledinstances are available. The computational costof our\u0001TMV-HLP is O (cT + nT )2 \u00b7 n2V + (cT + nT )3 , where Kis the number of nearest neighbours in the KNN graphs,and nV is the number of views. It costs O((cT +nT )2 \u00b7n2V )to construct the heterogeneous graph, while the inversematrix of Laplacian matrix L in label propagation stepwill take O((cT + nT )3 ) computational time, which however can be further reduced to O(cT nT t) using the recentwork of Fujiwara et al. [16], where t is an iterationparameter in their paper and t \u001c nT .5A NNOTATIONANDB EYONDOur multi-view embedding space \u0393 bridges the semanticgap between low-level features X and semantic representations A and V. Leveraging this cross-view mapping,8. It can be varied from 1 \u2212 10 with little effects in our experiments.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence9annotation [20], [51], [17] can be improved and appliedin novel ways. We consider three annotation tasks here:Instance level annotation Given a new instance u, wecan describe/annotate it by predicting its attributes. Theconventional solution is directly applying y\u0302uA = f A (xu )for test data xu [9], [17]. However, as analysed before,this suffers from the projection domain shift problem.To alleviate this, our multi-view embedding space alignsthe semantic attribute projections with the low-levelfeatures of each unlabelled instance in the target domain.This alignment can be used for image annotation inthe target domain. Thus, with our framework, we cannow infer attributes for any test instance via the learnedhi\u22121.embedding space \u0393 as y\u0302uA = xu W X D\u0303X W A D\u0303AZero-shot class description From a broader machineintelligence perspective, one might be interested to askwhat are the attributes of an unseen class, based solelyon the class name. Given our multi-view embeddingspace, we can infer the semantic attribute description ofa novel class. This zero-shot class description task couldbe useful, for example, to hypothesise the zero-shotattribute prototype of a class instead of defining it by experts [27] or ontology [15]. Our transductive embeddingenables this task by connecting semantic word space(i.e. naming) and discriminative attribute space (i.e. describing). Given the prototype ycV from the name of ai\u22121hnovel class c, we compute y\u0302cA = ycV W V D\u0303V W A D\u0303Ato generate the class-level attribute description.Zero prototype learning This task is the inverse of theprevious task \u2013 to infer the name of class given a setof attributes. It could be useful, for example, to validateor assess a proposed zero-shot attribute prototype, orto provide an automated semantic-property based indexinto a dictionary or database. To our knowledge, this isthe first attempt to evaluate the quality of a class attribute prototype because no previous work has directlyand systematically linked linguistic knowledge spacewith visual attribute space. Specifically given an attributehi\u22121prototype ycA , we can use y\u0302cV = y\u0302cA W A D\u0303A W V D\u0303Vto name the corresponding class and perform retrievalon dictionary words in V using y\u0302cV .66.1E XPERIMENTSDatasets and settingsWe evaluate our framework on three widely used image/video datasets: Animals with Attributes (AwA),Unstructured Social Activity Attribute (USAA), andCaltech-UCSD-Birds (CUB). AwA [27] consists of 50classes of animals (30, 475 images) and 85 associatedclass-level attributes. It has a standard source/targetsplit for zero-shot learning with 10 classes and 6, 180images held out as the target dataset. We use thesame \u2018hand-crafted\u2019 low-level features (RGB colour histograms, SIFT, rgSIFT, PHOG, SURF and local selfsimilarity histograms) released with the dataset (denotedas H); and the same multi-kernel learning (MKL) attribute classifier from [27]. USAA is a video dataset[15] with 69 instance-level attributes for 8 classes ofcomplex (unstructured) social group activity videos fromYouTube. Each class has around 100 training and testvideos respectively. USAA provides the instance-level attributes since there are significant intra-class variations.We use the thresholded mean of instances from eachclass to define a binary attribute prototype as in [15].The same setting in [15] is adopted: 4 classes as sourceand 4 classes as target data. We use exactly the sameSIFT, MFCC and STIP low-level features for USAA asin [15]. CUB-200-2011 [48] contains 11, 788 images of200 bird classes. This is more challenging than AwA\u2013 it is designed for fine-grained recognition and hasmore classes but fewer images. Each class is annotatedwith 312 binary attributes derived from a bird speciesontology. We use 150 classes as auxiliary data, holdingout 50 as test data. We extract 128 dimensional SIFTand colour histogram descriptors from regular grid ofmulti-scale and aggregate them into image-level featureFisher Vectors (F) by using 256 Gaussians, as in [1].Colour histogram and PHOG features are also used toextract global color and texture cues from each image.Due to the recent progress on deep learning basedrepresentations, we also extract OverFeat (O) [42]9 fromAwA and CUB as an alternative to H and F respectively.In addition, DeCAF (D) [7] is also considered for AwA.We report absolute classification accuracy on USAAand mean accuracy for AwA and CUB for direct comparison to published results. The word vector space istrained by the model in [32] with 1, 000 dimensions.6.26.2.1Recognition by zero-shot learningComparisons with state-of-the-artWe compare our method (TMV-HLP) with the recentstate-of-the-art models that report results or can be reimplemented by us on the three datasets in Table 1.They cover a wide range of approaches on utilisingsemantic intermediate representation for zero-shot learning. They can be roughly categorised according to thesemantic representation(s) used: DAP and IAP ([27],[28]), M2LATM [15], ALE [1], [36] and [50] use attributesonly; HLE/AHLE [1] and Mo/Ma/O/D [38] use bothattributes and linguistic knowledge bases (same as us);[54] uses attribute and some additional human manualannotation. Note that our linguistic knowledge baserepresentation is in the form of word vectors, which doesnot incur additional manual annotation. Our methodalso does not exploit data-driven attributes such asM2LATM [15] and Mo/Ma/O/D [38].Consider first the results on the most widely usedAwA. Apart from the standard hand-crafted feature(H), we consider the more powerful OverFeat deepfeature (O), and a combination of OverFeat and DeCAF9. We use the trained model of OverFeat in [42].0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence10ApproachDAPIAPM2LATM [15] ***ALE/HLE/AHLE [1]Mo/Ma/O/D [38]PST [36] ***[54]TMV-BLP [14]***TMV-HLP ***AwA (H [27])40.5([27]) / 41.4([28]) / 38.4*27.8([27]) / 42.2([28])41.337.4/39.0/43.527.0 / 23.6 / 33.0 / 35.742.748.3**47.749.0AwA (O)51.0*\u2013\u2013\u2013\u201354.1*\u201369.973.5AwA (O, D)57.1*\u2013\u2013\u2013\u201362.9*\u201377.880.5USAA33.2([15]) / 35.2*\u201341.9\u2013\u201336.2*\u201348.250.4CUB (O)26.2*\u2013\u2013\u2013\u201338.3*\u201345.247.9CUB (F )9.1*\u2013\u201318.0*\u201313.2*\u201316.319.5Table 1Comparison with the state-of-the-art on zero-shot learning on AwA, USAA and CUB. Features H, O, D and Frepresent hand-crafted, OverFeat, DeCAF, and Fisher Vector respectively. Mo, Ma, O and D represent the highestresults by the mined object class-attribute associations, mined attributes, objectness as attributes and direct similaritymethods used in [38] respectively. \u2018\u2013\u2019: no result reported. *: our implementation. **: requires additional humanannotations.***: requires unlabelled data, i.e. a transductive setting.10. With these two low-level feature views, there are six views intotal in the embedding space.Soft Vs. Hard dimension weighting for CCAContributions of CCA and LP0.550hard weightingsoft weighting (\u03bb=1)soft weighting (\u03bb=2)soft weighting( \u03bb=3)soft weighting( \u03bb=4)soft weighting (\u03bb=5)0.470.464644Accuracy (% )0.480.45424038360.440.43 110Nearest Neighbour (NN)Label Propagation (LP)480.49Accuracy(%)(O, D)10 . Table 1 shows that (1) with the same experimental settings and the same feature (H), our TMVHLP (49.0%) outperforms the best result reported so far(48.3%) in [54] which, unlike ours, requires additionalhuman annotation to relabel the similarities betweenauxiliary and target classes. (2) With the more powerfulOverFeat feature, our method achieves 73.5% zero-shotrecognition accuracy. Even more remarkably, when boththe OverFeat and DeCAF features are used in our framework, the result (see the AwA (O, D) column) is 80.5%.Even with only 10 target classes, this is an extremelygood result given that we do not have any labelledsamples from the target classes. Note that this goodresult is not solely due to the feature strength, as themargin between the conventional DAP and our TMVHLP is much bigger indicating that our TMV-HLP playsa critical role in achieving this result. (3) Our methodis also superior to the AHLE method in [1] which alsouses two semantic spaces: attribute and WordNet hierarchy. Different from our embedding framework, AHLEsimply concatenates the two spaces. (4) Our methodalso outperforms the other alternatives of either miningother semantic knowledge bases (Mo/Ma/O/D [38])or exploring data-driven attributes (M2LATM [15]). (5)Among all compared methods, PST [36] is the onlyone except ours that performs label propagation basedtransductive learning. It yields better results than DAPin all the experiments which essentially does nearestneighbour in the semantic space. TMV-HLP consistentlybeats PST in all the results shown in Table 1 thanks toour multi-view embedding. (6) Compared to our TMVBLP model [14], the superior results of TMV-HLP showsthat the proposed heterogeneous hypergraph is moreeffective than the homogeneous 2-graphs used in TMVBLP for zero-shot learning.Table 1 also shows that on two very different datasets:USAA video activity, and CUB fine-grained, our TMVHLP significantly outperforms the state-of-the-art alternatives. In particular, on the more challenging CUB,3432102103104Log(Dimensions) of Multi\u2212view embedding CCA space30A(a)V\u03a8A\u03a8V(b)Figure 4. (a) Comparing soft and hard dimension weighting of CCA for AwA. (b) Contributions of CCA and labelpropagation on AwA. \u03a8A and \u03a8V indicate the subspacesof target data from view A and V in \u0393 respectively. Handcrafted features are used in both experiments.47.9% accuracy is achieved on 50 classes (chance level2%) using the OverFeat feature. Considering the finegrained nature and the number of classes, this is evenmore impressive than the 80.5% result on AwA.6.2.2Further evaluationsEffectiveness of soft weighting for CCA embeddingIn this experiment, we compare the soft-weighting (Eq(2)) of CCA embedding space \u0393 (a strategy adopted inthis work) with the conventional hard-weighting strategy of selecting the number of dimensions for CCA projection. Fig. 4(a) shows that the performance of the hardweighting CCA depends on the number of projectiondimensions selected (blue curve). In contrast, our softweighting strategy uses all dimensions weighted by theCCA eigenvalues, so that the important dimensions areautomatically weighted more highly. The result showsthat this strategy is clearly better and it is not verysensitive to the weighting parameter \u03bb, with choices of\u03bb > 2 all working well.Contributions of individual components There aretwo major components in our ZSL framework: CCAembedding and label propagation. In this experimentwe investigate whether both of them contribute to the0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence11strong performance. To this end, we compare the ZSLresults on AwA with label propagation and without(nearest neighbour) before and after CCA embedding. InFig. 4(b), we can see that: (i) Label propagation alwayshelps regardless whether the views have been embeddedusing CCA, although its effects are more pronouncedafter embedding. (ii) Even without label propagation,i.e. using nearest neighbour for classification, the performance is improved by the CCA embedding. However,the improvement is bigger with label propagation. Thisresult thus suggests that both CCA embedding and labelpropagation are useful, and our ZSL framework worksthe best when both are used.Transductive multi-view embedding To further validate the contribution of our transductive multi-viewembedding space, we split up different views with andwithout embedding and the results are shown in Fig. 5.In Figs. 5(a) and (c), the hand-crafted feature H and SIFT,MFCC and STIP low-level features are used for AwA andUSAA respectively, and we compare V vs. \u0393(X + V),A vs. \u0393(X + A) and [V, A] vs. \u0393(X + V + A) (see thecaption of Fig. 5 for definitions). We use DAP for Aand nearest neighbour for V and [V, A], because theprototypes of V are not binary vectors so DAP cannot beapplied. We use TMV-HLP for \u0393(X + V) and \u0393(X + A)respectively. We highlight the following observations: (1)After transductive embedding, \u0393(X + V + A), \u0393(X + V)and \u0393(X + A) outperform [V, A], V and A respectively.This means that the transductive embedding is helpfulwhichever semantic space is used in rectifying the projection domain shift problem by aligning the semanticviews with low-level features. (2) The results of [V, A] arehigher than those of A and V individually, showing thatthe two semantic views are indeed complementary evenwith simple feature level fusion. Similarly, our TMVHLP on all views \u0393(X + V + A) improves individualembeddings \u0393(X + V) and \u0393(X + A).Embedding deep learning feature views also helpsIn Fig. 5(b) three different low-level features are considered for AwA: hand-crafted (H), OverFeat (O) andDeCAF features (D). The zero-shot learning results ofeach individual space are indicated as VH , AH , VO ,AO , VD , AD in Fig. 5(b) and we observe that VO >VD > VH and AO > AD > AH . That is OverFeat >DeCAF > hand-crafted features. It is widely reportedthat deep features have better performance than \u2018handcrafted\u2019 features on many computer vision benchmarkdatasets [5], [42]. What is interesting to see here isthat OverFeat > DeCAF since both are based on thesame Convolutional Neural Network (CNN) model of[25]. Apart from implementation details, one significantdifference is that DeCAF is pre-trained by ILSVRC2012while OverFeat by ILSVRC2013 which contains moreanimal classes meaning better (more relevant) featurescan be learned. It is also worth pointing out that: (1)With both OverFeat and DeCAF features, the numberof views to learn an embedding space increases from 3to 9; and our results suggest that the more views, thebetter chance to solve the domain shift problem and thedata become more separable as different views containcomplementary information. (2) Figure 5(b) shows thatwhen all 9 available views (XH , VH , AH , XD , VD , AD ,XO , VO and AO ) are used for embedding, the resultis significantly better than those from each individualview. Nevertheless, it is lower than that obtained byembedding views (XD , VD , AD , XO , VO and AO ). Thissuggests that view selection may be required when alarge number of views are available for learning theembedding space.Embedding makes target classes more separable Weemploy t-SNE [47] to visualise the space XO , VO , AOand \u0393(X + A + V)O,D in Fig. 6. It shows that evenin the powerful OverFeat view, the 10 target classesare heavily overlapped (Fig. 6(a)). It gets better in thesemantic views (Figs. 6(b) and (c)). However, when all6 views are embedded, all classes are clearly separable(Fig. 6(d)).Running time In practice, for the AwA dataset withhand-crafted features, our pipeline takes less than 30minutes to complete the zero-shot classification task(over 6, 180 images) using a six core 2.66GHz CPUplatform. This includes the time for multi-view CCA embedding and label propagation using our heterogeneoushypergraphs.6.3Annotation and beyondIn this section we evaluate our multi-view embeddingspace for the conventional and novel annotation tasksintroduced in Sec. 5.Instance annotation by attributes To quantify the annotation performance, we predict attributes/annotationsfor each target class instance for USAA, which hasthe largest instance level attribute variations among thethree datasets. We employ two standard measures: meanaverage precision (mAP) and F-measure (FM) betweenthe estimated and true annotation list. Using our multiview embedding space, our method (FM: 0.341, mAP:0.355) outperforms significantly the baseline of directlyestimating yuA = f A (xu ) (FM: 0.299, mAP: 0.267).Zero-shot description In this task, we explicitly inferthe attributes corresponding to a specified novel class,given only the textual name of that class without seeingany visual samples. Table 2 illustrates this for AwA.Clearly most of the top/bottom 5 attributes predicted foreach of the 10 target classes are meaningful (in the idealcase, all top 5 should be true positives and all bottom 5true negatives). Predicting the top-5 attributes for eachclass gives an F-measure of 0.236. In comparison, if wedirectly select the 5 nearest attribute name projection tothe class name projection (prototype) in the word space,the F-measure is 0.063, demonstrating the importance oflearning the multi-view embedding space. In additionto providing a method to automatically \u2013 rather thanmanually \u2013 generate an attribute ontology, this task isinteresting because even a human could find it very0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence12ZSL of AwA (hand\u2212crafted features)5085ZSL of AwA(hand\u2212crafted and deep features)Zero\u2212shot learning of USAA50488046754446444038Accuracy (% )6542Accuracy (% )Accuracy (% )4870605542405038453634403432353630V\u0393(X+V)A(a)[V,A ] \u0393(X+V+A)\u0393(X+A)3032VHAHVOAOVD(b)AD\u0393(X+V+A)\u0393(X+V+A) O,DH,O, D30V\u0393(X+V)A\u0393(X+A)(c)[V,A ]\u0393(X+V+A)Figure 5. Effectiveness of transductive multi-view embedding. (a) zero-shot learning on AwA using only hand-craftedfeatures; (b) zero-shot learning on AwA using hand-crafted and deep features together; (c) zero-shot learning onUSAA. [V, A] indicates the concatenation of semantic word and attribute space vectors. \u0393(X + V) and \u0393(X + A)mean using low-level+semantic word spaces and low-level+attribute spaces respectively to learn the embedding.\u0393(X + V + A) indicates using all 3 views to learn the embedding.(a) Overfeat view4030150persian cathippopotamusleopardhumpback whalesealchimpanzeeratgiant pandapigraccoon20100100\u221210\u221220\u22123050\u221240\u221260\u221240\u221220020406080(b) Attribute view100050050\u0e0050\u0e00100100\u0e00150\u0e00150\u0e00100\u0e0050050100(c) Word vector view10015015050-10050050100150(d) Multi-view embedding space0\u0e0050\u0e00100\u0e00150\u0e00100\u0e0080\u0e0060\u0e0040\u0e0020020406080100OtherRepresentationsFigure 6. t-SNE Visualisation of (a) OverFeat view (XO ), (b) attribute view (AO ), (c) word vector view (VO ), and (d)transition probability of pairwise nodes computed by Eq (9) of TMV-HLP in (\u0393(X + A + V)O,D ). The unlabelled targetclasses are much more separable in (d).challenging (effectively a human has to list the attributesof a class which he has never seen or been explicitlytaught about, but has only seen mentioned in text).Zero prototype learning In this task we attempt thereverse of the previous experiment: inferring a classname given a list of attributes. Table 3 illustrates thisfor USAA. Table 3(a) shows queries by the groundtruthattribute definitions of some USAA classes and the top4 ranked list of classes returned. The estimated classnames of each attribute vector are reasonable \u2013 the top-4words are either the class name or related to the classname. A baseline is to use the textual names of theattributes projected in the word space (summing theirword vectors) to search for the nearest classes in wordspace, instead of the embedding space. Table 3(a) showsthat the predicted classes in this case are reasonable,but significantly worse than querying via the embeddingspace. To quantify this we evaluate the average rankof the true name for each USAA class when queriedby its attributes. For querying by embedding space, theaverage rank is an impressive 2.13 (out of 4.33M wordswith a chance-level rank of 2.17M), compared with theaverage rank of 110.24 by directly querying word space[32] with textual descriptions of the attributes. Table3(b) shows an example of \u201cincremental\u201d query usingthe ontology definition of birthday party [15]. We firstquery the \u2018wrapped presents\u2019 attribute only, followed byadding \u2018small balloon\u2019 and all other attributes (\u2018birthdaysongs and \u2018birthday caps\u2019). The changing list of topranked retrieved words intuitively reflects the expecta-0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence13(a) Query by GT attributes ofQuery via embedding spaceQuery attribute words in word spacegraduation partyparty, graduation, audience, caucuscheering, proudly, dressed, wearingmusic_performancemusic, performance, musical, heavy metalsing, singer, sang, dancingwedding_ceremonywedding_ceremony, wedding, glosses, stagnun, christening, bridegroom, wedding_ceremony(b) Attribute queryTop ranked wordswrapped presentsmusic; performance; solo_performances; performing+small balloonwedding; wedding_reception; birthday_celebration; birthday+birthday song +birthday capsbirthday_party; prom; wedding receptionTable 3Zero prototype learning on USAA. (a) Querying classes by groundtruth (GT) attribute definitions of the specifiedclasses. (b) An incrementally constructed attribute query for the birthday_party class. Bold indicates true positive.AwApchplphwsealcpratgppigrcT-5B-5T-5B-5T-5B-5T-5B-5T-5B-5T-5B-5T-5B-5T-5B-5T-5B-5T-5B-5Attributesactive, furry, tail, paws, ground.swims, hooves, long neck, horns, arcticold world, strong, quadrupedal, fast, walksred, plankton, skimmers, stripes, tunnelsold world, active, fast, quadrupedal, muscleplankton, arctic, insects, hops, tunnelsfish, smart, fast, group, flippershops, grazer, tunnels, fields, plainsold world, smart, fast, chew teeth, strongfly, insects, tree, hops, tunnelsfast, smart, chew teeth, active, browntunnels, hops, skimmers, fields, long neckactive, fast, furry, new world, pawsarctic, plankton, hooves, horns, long neckquadrupedal, active, old world, walks, furrytunnels, skimmers, long neck, blue, hopsquadrupedal, old world, ground, furry, chew teethdesert, long neck, orange, blue, skimmersfast, active, furry, quadrupedal, forestlong neck, desert, tusks, skimmers, blueTable 2Zero-shot description of 10 AwA target classes. \u0393 islearned using 6 views (XD , VD , AD , XO , VO and AO ).The true positives are highlighted in bold. pc, hp, lp, hw,cp, gp, and rc are short for Persian cat, hippopotamus,leopard, humpback whale, chimpanzee, giant panda,and raccoon respectively. T-5/B-5 are the top/bottom 5attributes predicted for each target class.A number of directions have been identified for futurework. First, we employ CCA for learning the embedding space. Although it works well, other embeddingframeworks can be considered (e.g. [49]). In the current pipeline, low-level features are first projected ontodifferent semantic views before embedding. It shouldbe possible to develop a unified embedding frameworkto combine these two steps. Second, under a realisticlifelong learning setting [6], an unlabelled data pointcould either belong to a seen/auxiliary category or anunseen class. An ideal framework should be able toclassify both seen and unseen classes [44]. Finally, ourresults suggest that more views, either manually defined(attributes), extracted from a linguistic corpus (wordspace), or learned from visual data (deep features), canpotentially give rise to better embedding space. Moreinvestigation is needed on how to systematically designand select semantic views for embedding.R EFERENCES[1][2][3][4]tion of the combinatorial meaning of the attributes.[5]7C ONCLUSIONSWe identified the challenge of projection domain shift inzero-shot learning and presented a new framework tosolve it by rectifying the biased projections in a multiview embedding space. We also proposed a novel labelpropagation algorithm TMV-HLP based on heterogeneous across-view hypergraphs. TMV-HLP synergistically exploits multiple intermediate semantic representations, as well as the manifold structure of unlabelledtarget data to improve recognition in a unified way forzero shot, N-shot and zero+N shot learning tasks. As aresult we achieved state-of-the-art performance on thechallenging AwA, CUB and USAA datasets. Finally, wedemonstrated that our framework enables novel tasks ofrelating textual class names and their semantic attributes.[6][7][8][9][10][11][12][13]Z. Akata, F. Perronnin, Z. Harchaoui, and C. Schmid. Labelembedding for attribute-based classification. In CVPR, 2013.Y. Bengio. Learning deep architectures for AI. Found. Trends Mach.Learn., pages 1\u2013127, 2009.I. Biederman. Recognition by components - a theory of humanimage understanding. Psychological Review, 1987.P. F. Brown, V. J. Pietra, P. V.deSouza, J. C.Lai, and R. L.Mercer.Class-based n-gram models of natural language. Journal Computational Linguistics, 1992.K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Returnof the devil in the details: Delving deep into convolutional nets.ArXiv e-prints, 2014.X. Chen, A. Shrivastava, and A. Gupta. NEIL: Extracting VisualKnowledge from Web Data. In ICCV, 2013.J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng,and T. Darrell. Decaf: A deep convolutional activation feature forgeneric visual recognition. CoRR, abs/1310.1531, 2013.L. Duan, I. W. Tsang, D. Xu, and S. J. Maybank. Domain transfersvm for video concept detection. In CVPR, 2009.A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describingobjects by their attributes. In CVPR, 2009.B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. InICCV, 2013.A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato,and T. Mikolov. Devise: A deep visual-semantic embeddingmodel andrea. In NIPS, 2013.Y. Fu, Y. Guo, Y. Zhu, F. Liu, C. Song, and Z.-H. Zhou. Multi-viewvideo summarization. IEEE Trans. on MM, 12(7):717\u2013729, 2010.Y. Fu, T. Hospedales, T. Xiang, and S. Gong. Attribute learningfor understanding unstructured social activity. In ECCV, 2012.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\fThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/TPAMI.2015.2408354, IEEE Transactions on Pattern Analysis and Machine Intelligence14[14] Y. Fu, T. M. Hospedales, T. Xiang, Z. Fu, and S. Gong. Transductive multi-view embedding for zero-shot recognition andannotation. In ECCV, 2014.[15] Y. Fu, T. M. Hospedales, T. Xiang, and S. Gong. Learning multimodal latent attributes. TPAMI, 2013.[16] Y. Fujiwara and G. Irie. Efficient label propagation. In ICML,2014.[17] Y. Gong, Q. Ke, M. Isard, and S. Lazebnik. A multi-viewembedding space for modeling internet images, tags, and theirsemantics. IJCV, 2013.[18] D. R. Hardoon, S. Szedmak, and J. Shawe-Taylor. Canonicalcorrelation analysis; an overview with application to learningmethods. In Neural Computation, 2004.[19] C. Hong, J. Yu, J. Li, and X. Chen. Multi-view hypergraph learningby patch alignment framework. Neurocomputing, 2013.[20] T. Hospedales, S. Gong, and T. Xiang. Learning tags fromunsegmented videos of multiple human actions. In ICDM, 2011.[21] Y. Huang, Q. Liu, and D. Metaxas. Video object segmentation byhypergraph cut. In CVPR, 2009.[22] Y. Huang, Q. Liu, S. Zhang, and D. N. Metaxas. Image retrievalvia probabilistic hypergraph ranking. In CVPR, 2010.[23] S. J. Hwang and K. Grauman. Learning the relative importance ofobjects from tagged images for retrieval and cross-modal search.IJCV, 2011.[24] S. J. Hwang, F. Sha, and K. Grauman. Sharing features betweenobjects and their attributes. In CVPR, 2011.[25] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.[26] C. H. Lampert. Kernel methods in computer vision. Foundationsand Trends in Computer Graphics and Vision, 2009.[27] C. H. Lampert, H. Nickisch, and S. Harmeling. Learning to detectunseen object classes by between-class attribute transfer. In CVPR,2009.[28] C. H. Lampert, H. Nickisch, and S. Harmeling. Attribute-basedclassification for zero-shot visual object categorization. IEEETPAMI, 2013.[29] X. Li, W. Hu, C. Shen, A. Dick, and Z. Zhang. Context-awarehypergraph construction for robust spectral clustering. IEEETransactions on Knowledge and Data Engineering, 2013.[30] X. Li, Y. Li, C. Shen, A. R. Dick, and A. van den Hengel.Contextual hypergraph modelling for salient object detection.ICCV, 2013.[31] J. Liu, B. Kuipers, and S. Savarese. Recognizing human actionsby attributes. In CVPR, 2011.[32] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimationof word representation in vector space. In Proceedings of Workshopat ICLR, 2013.[33] M. Palatucci, G. Hinton, D. Pomerleau, and T. M. Mitchell. Zeroshot learning with semantic output codes. In NIPS, 2009.[34] D. Parikh and K. Grauman. Relative attributes. In ICCV, 2011.[35] A. Pentina and C. H. Lampert. A pac-bayesian bound for lifelonglearning anastasia. In ICML, 2014.[36] M. Rohrbach, S. Ebert, and B. Schiele. Transfer learning in atransductive setting. In NIPS, 2013.[37] M. Rohrbach, M. Stark, and B. Schiele. Evaluating knowledgetransfer and zero-shot learning in a large-scale setting. In CVPR,2012.[38] M. Rohrbach, M. Stark, G. Szarvas, I. Gurevych, and B. Schiele.What helps where\u2013and why semantic relatedness for knowledgetransfer. In CVPR, 2010.[39] E. Rosch. Classification of real-world objects: Origins and representations in cognition. Thinking: Readings in Cognitive Science,1977.[40] R. Rosipal and N. Kramer. Overview and recent advances inpartial least squares. In C. Saunders, M. Grobelnik, S. Gunn,and J. Shawe-Taylor, editors, Subspace, Latent Structure and FeatureSelection, pages 34\u201351. Springer Berlin Heidelberg, 2006.[41] W. J. Scheirer, N. Kumar, P. N. Belhumeur, and T. E. Boult. Multiattribute spaces: Calibration for attribute fusion and similaritysearch. In CVPR, 2012.[42] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, andY. LeCun. Overfeat: Integrated recognition, localization anddetection using convolutional networks. In ICLR, 2014.[43] R. Socher and L. Fei-Fei. Connecting modalities: Semi-supervisedsegmentation and annotation of images using unaligned textcorpora. In CVPR, 2010.[44] R. Socher, M. Ganjoo, H. Sridhar, O. Bastani, C. D. Manning, andA. Y. Ng. Zero-shot learning through cross-modal transfer. InNIPS, 2013.[45] A. J. Storkey and M. Sugiyama. Mixture regression for covariateshift. In NIPS, 2007.[46] L. Sun, S. Ji, and J. Ye. Hypergraph spectral learning for multilabel classification. In ACM KDD, 2008.[47] L. van der Maaten and G. Hinton. Visualizing high-dimensionaldata using t-sne. JMLR, 2008.[48] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. TheCaltech-UCSD Birds-200-2011 Dataset. Technical Report CNS-TR2011-001, California Institute of Technology, 2011.[49] K. Wang, R. He, W. Wang, L. Wang, and T. Tan. Learning coupledfeature spaces for cross-modal matching. In ICCV, 2013.[50] X. Wang and Q. Ji. A unified probabilistic approach modelingrelationships between attributes and objects. ICCV, 2013.[51] Y. Wang and S. Gong. Translating topics to words for imageannotation. In ACM CIKM, 2007.[52] D. Watts and S. Strogatz. Collective dynamics of \u2019small-world\u2019networks. Nature, 1998.[53] D. J. Watts. Small Worlds: The Dynamics of Networks Between Orderand Randomness. University Presses of California, 8 edition, 2004.[54] F. X. Yu, L. Cao, R. S. Feris, J. R. Smith, and S.-F. Chang. Designingcategory-level attributes for discriminative visual recognition.CVPR, 2013.[55] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Sch\u00f6lkopf.Learning with local and global consistency. In NIPS, 2004.[56] D. Zhou and C. J. C. Burges. Spectral clustering and transductivelearning with multiple views. ICML 07, 2007.[57] X. Zhu. Semi-supervised learning literature survey. TechnicalReport 1530, University of Wisconsin-Madison Department ofComputer Science, 2007.Yanwei Fu received the PhD degree fromQueen Mary University of London in 2014, andthe MEng degree in the Department of Computer Science & Technology at Nanjing University in 2011, China. He is currently a Post-docof Disney Research, Pittsburgh. His researchinterest is image and video understanding.Timothy M. Hospedales received the PhD degree in neuroinformatics from the University ofEdinburgh in 2008. He is currently a lecturer (assistant professor) of computer science at QueenMary University of London. His research interests include probabilistic modelling and machinelearning applied variously to problems in computer vision, data mining, interactive learning,and neuroscience. He has published more than20 papers in major international journals andconferences. He is a member of the IEEE.Tao Xiang received the PhD degree in electrical and computer engineering from the NationalUniversity of Singapore in 2002. He is currentlya reader (associate professor) in the School ofElectronic Engineering and Computer Science,Queen Mary University of London. His researchinterests include computer vision and machinelearning. He has published over 100 papers ininternational journals and conferences and coauthored a book, Visual Analysis of Behaviour:From Pixels to Semantics.Shaogang Gong is Professor of Visual Computation at Queen Mary University of London, aFellow of the Institution of Electrical Engineersand a Fellow of the British Computer Society.He received his D.Phil in computer vision fromKeble College, Oxford University in 1989. Hisresearch interests include computer vision, machine learning and video analysis.0162-8828 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttps://www.ieee.org/publications_standards/publications/rights/index.html for more information.\f"], "extra": [{"Pan (2010)": 0}, {"Shelhamer (2017)": 1}, {"Girshick (2016)": 2}, {"Pan (2011)": 3}, {"Duan (2012)": 4}, {"Gao (2014)": 5}, {"Donahue (2017)": 6}, {"Lu (2015)": 7}, {"Taylor (2009)": 8}, {"Zhu (2014)": 9}, {"Bruzzone (2010)": 10}, {"Kendall (2015)": 11}, {"Li (2014)": 12}, {"Ben-David (2010)": 13}, {"Shao (2015)": 14}, {"Dong (2015)": 15}, {"Long (2014)": 16}, {"Zhang (2016)": 17}, {"Long (2013)": 18}, {"Fu (2015)": 19}], "meta": ["Pan (2010)", "Shelhamer (2017)", "Girshick (2016)", "Pan (2011)", "Duan (2012)", "Gao (2014)", "Donahue (2017)", "Lu (2015)", "Taylor (2009)", "Zhu (2014)", "Bruzzone (2010)", "Kendall (2015)", "Li (2014)", "Ben-David (2010)", "Shao (2015)", "Dong (2015)", "Long (2014)", "Zhang (2016)", "Long (2013)", "Fu (2015)"]}}; }
plotInterface = buildViz(500,500,null,null,false,true,false,false,true,true,false,false,true,0.1,false,"","",getDataAndInfo(),false,false,(function(d) {
     return  d.term + "<br/>Dim 0: " + Math.round(d.ox*1000)/1000 + "<br/>Dim 1: " + Math.round(d.oy*1000)/1000 
    }),null,null,null,false,false,true,false,null,null,10,null,0,0,false,true,true,undefined,null);
</script>
