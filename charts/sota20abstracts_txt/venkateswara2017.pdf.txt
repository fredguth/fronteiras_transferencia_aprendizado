Deep Hashing Network for Unsupervised Domain Adaptation

In recent years, deep neural networks have emerged as a
dominant machine learning tool for a wide variety of application domains. However, training a deep neural network
requires a large amount of labeled data, which is an expensive process in terms of time, labor and human expertise.
Domain adaptation or transfer learning algorithms address
this challenge by leveraging labeled data in a different, but
related source domain, to develop a model for the target
domain. Further, the explosive growth of digital data has
posed a fundamental challenge concerning its storage and
retrieval. Due to its storage and retrieval efficiency, recent
years have witnessed a wide application of hashing in a
variety of computer vision applications. In this paper, we
first introduce a new dataset, Office-Home, to evaluate domain adaptation algorithms. The dataset contains images
of a variety of everyday objects from multiple domains. We
then propose a novel deep learning framework that can exploit labeled source data and unlabeled target data to learn
informative hash codes, to accurately classify unseen target data. To the best of our knowledge, this is the first
research effort to exploit the feature learning capabilities
of deep neural networks to learn representative hash codes
to address the domain adaptation problem. Our extensive
empirical studies on multiple transfer tasks corroborate the
usefulness of the framework in learning efficient hash codes
which outperform existing competitive baselines for unsupervised domain adaptation.

The explosive growth of digital data in the modern era
has posed fundamental challenges regarding their storage,
retrieval and computational requirements. Against this
backdrop, hashing has emerged as one of the most popular and effective techniques due to its fast query speed and
low memory cost [48]. Hashing techniques transform high
dimensional data into compact binary codes and generate
similar binary codes for similar data items. Motivated by
this fact, we propose to train a deep neural network to output binary hash codes (instead of probability values), which
can be used for classification. We see two advantages to estimating a hash value instead of a standard probability vector in the final layer of the network: (i) the hash values are
used to develop a unique loss function for target data in the
absence of labels and (ii) during prediction, the hash value
of a test sample can be compared against the hash values
of the training samples to arrive at a more robust category
prediction.

