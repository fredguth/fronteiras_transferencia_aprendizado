{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import scattertext as st\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"../TEMAC/top-20-papers/\"\n",
    "files = os.listdir(pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./txt/\"):\n",
    "    print('creating ', \"./txt/\")\n",
    "    os.makedirs(\"./txt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have = set(os.listdir(\"./txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(files): \n",
    "    txt_basename = f + '.txt'\n",
    "    if txt_basename in have:\n",
    "        print('%d/%d skipping %s, already exists.' % (i, len(files), txt_basename, ))\n",
    "        continue\n",
    "    pdf_path = os.path.join(pdf_dir, f)\n",
    "    txt_path = os.path.join(\"./txt/\", txt_basename)\n",
    "    cmd = \"pdftotext %s %s\" % (pdf_path, txt_path)\n",
    "    os.system(cmd)\n",
    "    print('%d/%d %s' % (i, len(files), cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Arquivo</th>\n",
       "      <th>Ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pan (2010)</td>\n",
       "      <td>10_1109--TKDE_2009_191.pdf.txt</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shelhamer (2017)</td>\n",
       "      <td>10_1109--TPAMI_2016_2572683.pdf.txt</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Girshick (2016)</td>\n",
       "      <td>10_1109--TPAMI_2015_2437384.pdf.txt</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Nome                              Arquivo   Ano\n",
       "0        Pan (2010)       10_1109--TKDE_2009_191.pdf.txt  2010\n",
       "1  Shelhamer (2017)  10_1109--TPAMI_2016_2572683.pdf.txt  2017\n",
       "2   Girshick (2016)  10_1109--TPAMI_2015_2437384.pdf.txt  2016"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('documents.csv', sep=\";\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Texto']=data[\"Arquivo\"].apply(lambda fname: open(\"./top20abstracts_txt/\"+fname, \"r\").read().replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Parsed']= data['Texto'].apply(st.whitespace_nlp_with_sentences)\n",
    "data['Categoria']= np.where(data['Ano']> 2016, 'FRONTIER', 'NORMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Arquivo</th>\n",
       "      <th>Ano</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Parsed</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zhang (2016)</td>\n",
       "      <td>10_1109--TIP_2016_2516952.pdf.txt</td>\n",
       "      <td>2016</td>\n",
       "      <td>LSDT: Latent Sparse Domain Transfer Learningfo...</td>\n",
       "      <td>LSDT: Latent Sparse Domain Transfer Learningfo...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Long (2013)</td>\n",
       "      <td>10_1109--ICCV_2013_274.pdf.txt</td>\n",
       "      <td>2013</td>\n",
       "      <td>Transfer Feature Learning with Joint Distribut...</td>\n",
       "      <td>Transfer Feature Learning with Joint Distribut...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fu (2015)</td>\n",
       "      <td>10_1109--TPAMI_2015_2408354.pdf.txt</td>\n",
       "      <td>2015</td>\n",
       "      <td>Transductive Multi-view Zero-Shot LearningMost...</td>\n",
       "      <td>Transductive Multi-view Zero-Shot LearningMost...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Nome                              Arquivo   Ano  \\\n",
       "17  Zhang (2016)    10_1109--TIP_2016_2516952.pdf.txt  2016   \n",
       "18   Long (2013)       10_1109--ICCV_2013_274.pdf.txt  2013   \n",
       "19     Fu (2015)  10_1109--TPAMI_2015_2408354.pdf.txt  2015   \n",
       "\n",
       "                                                Texto  \\\n",
       "17  LSDT: Latent Sparse Domain Transfer Learningfo...   \n",
       "18  Transfer Feature Learning with Joint Distribut...   \n",
       "19  Transductive Multi-view Zero-Shot LearningMost...   \n",
       "\n",
       "                                               Parsed Categoria  \n",
       "17  LSDT: Latent Sparse Domain Transfer Learningfo...    NORMAL  \n",
       "18  Transfer Feature Learning with Joint Distribut...    NORMAL  \n",
       "19  Transductive Multi-view Zero-Shot LearningMost...    NORMAL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (st.CorpusFromParsedDocuments(data.sample(frac=1), category_col='Categoria', parsed_col='Parsed').build().get_stoplisted_unigram_corpus())\n",
    "corpus = corpus.add_doc_names_as_metadata(corpus.get_df()['Nome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x1047 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1718 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = TfidfTransformer().fit_transform(corpus.get_term_doc_mat())\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = svds(embeddings, k=3, maxiter=20000, which='LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolutional</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methods</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptation</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfer</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corpus\n",
       "term                 \n",
       "distribution       19\n",
       "convolutional      20\n",
       "methods            20\n",
       "different          21\n",
       "adaptation         25\n",
       "target             28\n",
       "data               53\n",
       "transfer           55\n",
       "domain             59\n",
       "learning           85"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_term_count_df().sort_values(by=['corpus']).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.3473816 , -0.14022942,  0.42432806,  0.26518075,  0.01838124,\n",
       "        -0.10537036, -0.01787369, -0.17523474,  0.37128464, -0.18892453,\n",
       "        -0.11021823, -0.27273756,  0.10467141, -0.10246393, -0.24263888,\n",
       "        -0.07520039,  0.12405308, -0.06952901, -0.21671091,  0.39187982]),\n",
       " array([ 0.08952413, -0.39590432, -0.07686658, -0.05711692, -0.31135918,\n",
       "        -0.54383051, -0.32990408, -0.07459006, -0.0350106 ,  0.15352596,\n",
       "        -0.46751766,  0.14085436,  0.07903418, -0.04940756, -0.00272074,\n",
       "         0.02183445,  0.08674152,  0.0922206 ,  0.17468877,  0.00725442]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.T[0], u.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Li (2014)</th>\n",
       "      <td>-0.347382</td>\n",
       "      <td>0.089524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Girshick (2016)</th>\n",
       "      <td>-0.140229</td>\n",
       "      <td>-0.395904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taylor (2009)</th>\n",
       "      <td>0.424328</td>\n",
       "      <td>-0.076867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shao (2015)</th>\n",
       "      <td>0.265181</td>\n",
       "      <td>-0.057117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dong (2015)</th>\n",
       "      <td>0.018381</td>\n",
       "      <td>-0.311359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shelhamer (2017)</th>\n",
       "      <td>-0.105370</td>\n",
       "      <td>-0.543831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendall (2015)</th>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.329904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gao (2014)</th>\n",
       "      <td>-0.175235</td>\n",
       "      <td>-0.074590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lu (2015)</th>\n",
       "      <td>0.371285</td>\n",
       "      <td>-0.035011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bruzzone (2010)</th>\n",
       "      <td>-0.188925</td>\n",
       "      <td>0.153526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donahue (2017)</th>\n",
       "      <td>-0.110218</td>\n",
       "      <td>-0.467518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhang (2016)</th>\n",
       "      <td>-0.272738</td>\n",
       "      <td>0.140854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long (2013)</th>\n",
       "      <td>0.104671</td>\n",
       "      <td>0.079034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fu (2015)</th>\n",
       "      <td>-0.102464</td>\n",
       "      <td>-0.049408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhu (2014)</th>\n",
       "      <td>-0.242639</td>\n",
       "      <td>-0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben-David (2010)</th>\n",
       "      <td>-0.075200</td>\n",
       "      <td>0.021834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long (2014)</th>\n",
       "      <td>0.124053</td>\n",
       "      <td>0.086742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pan (2011)</th>\n",
       "      <td>-0.069529</td>\n",
       "      <td>0.092221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duan (2012)</th>\n",
       "      <td>-0.216711</td>\n",
       "      <td>0.174689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pan (2010)</th>\n",
       "      <td>0.391880</td>\n",
       "      <td>0.007254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x         y\n",
       "term                                \n",
       "Li (2014)        -0.347382  0.089524\n",
       "Girshick (2016)  -0.140229 -0.395904\n",
       "Taylor (2009)     0.424328 -0.076867\n",
       "Shao (2015)       0.265181 -0.057117\n",
       "Dong (2015)       0.018381 -0.311359\n",
       "Shelhamer (2017) -0.105370 -0.543831\n",
       "Kendall (2015)   -0.017874 -0.329904\n",
       "Gao (2014)       -0.175235 -0.074590\n",
       "Lu (2015)         0.371285 -0.035011\n",
       "Bruzzone (2010)  -0.188925  0.153526\n",
       "Donahue (2017)   -0.110218 -0.467518\n",
       "Zhang (2016)     -0.272738  0.140854\n",
       "Long (2013)       0.104671  0.079034\n",
       "Fu (2015)        -0.102464 -0.049408\n",
       "Zhu (2014)       -0.242639 -0.002721\n",
       "Ben-David (2010) -0.075200  0.021834\n",
       "Long (2014)       0.124053  0.086742\n",
       "Pan (2011)       -0.069529  0.092221\n",
       "Duan (2012)      -0.216711  0.174689\n",
       "Pan (2010)        0.391880  0.007254"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection = pd.DataFrame({'term': corpus.get_metadata(), 'x': u.T[0], 'y': u.T[1]}).set_index('term')\n",
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = 'NORMAL'\n",
    "scores = (corpus.get_category_ids() == corpus.get_categories().index(category)).astype(int)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_pca_explorer(corpus,\n",
    "                               category,\n",
    "                               category_name='2009~2016',\n",
    "                               not_category_name='2017~2019',\n",
    "                               metadata=data['Nome'],\n",
    "                               width_in_pixels=300,\n",
    "                               show_axes=False,\n",
    "                               use_non_text_features=True,\n",
    "                               use_full_doc=True,\n",
    "                               projection=projection,\n",
    "                               scores=scores,\n",
    "                               show_top_terms=False,\n",
    "                               save_svg_button=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351127"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Documents4.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
