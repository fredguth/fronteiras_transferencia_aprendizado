{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import scattertext as st\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author - Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pan, SJ  (2010)</td>\n",
       "      <td>Pan, SJ</td>\n",
       "      <td>A Survey on Transfer Learning</td>\n",
       "      <td>2010</td>\n",
       "      <td>Transfer learning; survey; machine learning; d...</td>\n",
       "      <td>A major assumption in many machine learning an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shelhamer, E  (2017)</td>\n",
       "      <td>Shelhamer, E</td>\n",
       "      <td>Fully Convolutional Networks for Semantic Segm...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Semantic Segmentation; Convolutional Networks;...</td>\n",
       "      <td>Convolutional networks are powerful visual mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Girshick, R  (2016)</td>\n",
       "      <td>Girshick, R</td>\n",
       "      <td>Region-Based Convolutional Networks for Accura...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Object recognition; detection; semantic segmen...</td>\n",
       "      <td>Object detection performance, as measured on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Author - Year        Author  \\\n",
       "0       Pan, SJ  (2010)       Pan, SJ   \n",
       "1  Shelhamer, E  (2017)  Shelhamer, E   \n",
       "2   Girshick, R  (2016)   Girshick, R   \n",
       "\n",
       "                                               Title  Year  \\\n",
       "0                      A Survey on Transfer Learning  2010   \n",
       "1  Fully Convolutional Networks for Semantic Segm...  2017   \n",
       "2  Region-Based Convolutional Networks for Accura...  2016   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  Transfer learning; survey; machine learning; d...   \n",
       "1  Semantic Segmentation; Convolutional Networks;...   \n",
       "2  Object recognition; detection; semantic segmen...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  A major assumption in many machine learning an...  \n",
       "1  Convolutional networks are powerful visual mod...  \n",
       "2  Object detection performance, as measured on t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('top20_withAbstracts.csv', sep=\";\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Texto']= data[\"Title\"].map(str) + \" \"+ data[\"Keywords\"].map(str) +\" \"+data[\"Abstract\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Parsed']= data['Texto'].apply(st.whitespace_nlp_with_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Categoria']= np.where(data['Year']> 2016, 'FRONTIER', 'NORMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author - Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Parsed</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Long, MS  (2014)</td>\n",
       "      <td>Long, MS</td>\n",
       "      <td>Adaptation Regularization: A General Framework...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Transfer learning; adaptation regularization; ...</td>\n",
       "      <td>Domain transfer learning, which learns a targe...</td>\n",
       "      <td>Adaptation Regularization: A General Framework...</td>\n",
       "      <td>Adaptation Regularization: A General Framework...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zhang, L  (2016)</td>\n",
       "      <td>Zhang, L</td>\n",
       "      <td>LSDT: Latent Sparse Domain Transfer Learning f...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Transfer learning; domain adaptation; visualca...</td>\n",
       "      <td>We propose a novel reconstruction-based transf...</td>\n",
       "      <td>LSDT: Latent Sparse Domain Transfer Learning f...</td>\n",
       "      <td>LSDT: Latent Sparse Domain Transfer Learning f...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fu, YW  (2015)</td>\n",
       "      <td>Fu, YW</td>\n",
       "      <td>Transductive Multi-View Zero-Shot Learning</td>\n",
       "      <td>2015</td>\n",
       "      <td>Transducitve learning; multi-view Learning; tr...</td>\n",
       "      <td>Most existing zero-shot learning approaches ex...</td>\n",
       "      <td>Transductive Multi-View Zero-Shot Learning Tra...</td>\n",
       "      <td>Transductive Multi-View Zero-Shot Learning Tra...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Author - Year    Author  \\\n",
       "17  Long, MS  (2014)  Long, MS   \n",
       "18  Zhang, L  (2016)  Zhang, L   \n",
       "19    Fu, YW  (2015)    Fu, YW   \n",
       "\n",
       "                                                Title  Year  \\\n",
       "17  Adaptation Regularization: A General Framework...  2014   \n",
       "18  LSDT: Latent Sparse Domain Transfer Learning f...  2016   \n",
       "19         Transductive Multi-View Zero-Shot Learning  2015   \n",
       "\n",
       "                                             Keywords  \\\n",
       "17  Transfer learning; adaptation regularization; ...   \n",
       "18  Transfer learning; domain adaptation; visualca...   \n",
       "19  Transducitve learning; multi-view Learning; tr...   \n",
       "\n",
       "                                             Abstract  \\\n",
       "17  Domain transfer learning, which learns a targe...   \n",
       "18  We propose a novel reconstruction-based transf...   \n",
       "19  Most existing zero-shot learning approaches ex...   \n",
       "\n",
       "                                                Texto  \\\n",
       "17  Adaptation Regularization: A General Framework...   \n",
       "18  LSDT: Latent Sparse Domain Transfer Learning f...   \n",
       "19  Transductive Multi-View Zero-Shot Learning Tra...   \n",
       "\n",
       "                                               Parsed Categoria  \n",
       "17  Adaptation Regularization: A General Framework...    NORMAL  \n",
       "18  LSDT: Latent Sparse Domain Transfer Learning f...    NORMAL  \n",
       "19  Transductive Multi-View Zero-Shot Learning Tra...    NORMAL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (st.CorpusFromParsedDocuments(data.sample(frac=1), category_col='Categoria', parsed_col='Parsed').build().get_stoplisted_unigram_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.add_doc_names_as_metadata(corpus.get_df()['Author - Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x889 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1662 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = TfidfTransformer().fit_transform(corpus.get_term_doc_mat())\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = svds(embeddings, k=3, maxiter=20000, which='LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methods</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolutional</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptation</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfer</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corpus\n",
       "term                 \n",
       "different          22\n",
       "methods            22\n",
       "source             23\n",
       "convolutional      23\n",
       "adaptation         32\n",
       "target             42\n",
       "data               57\n",
       "transfer           68\n",
       "domain             76\n",
       "learning          112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_term_count_df().sort_values(by=['corpus']).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.T[0], u.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ben-David, S  (2010)</th>\n",
       "      <td>0.091006</td>\n",
       "      <td>-0.075597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lu, J  (2015)</th>\n",
       "      <td>-0.340530</td>\n",
       "      <td>0.066492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Girshick, R  (2016)</th>\n",
       "      <td>0.173054</td>\n",
       "      <td>0.437989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duan, LX  (2012)</th>\n",
       "      <td>0.172170</td>\n",
       "      <td>-0.178303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fu, YW  (2015)</th>\n",
       "      <td>0.095830</td>\n",
       "      <td>0.040449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taylor, ME  (2009)</th>\n",
       "      <td>-0.462783</td>\n",
       "      <td>0.094160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pan, SJ  (2010)</th>\n",
       "      <td>-0.467088</td>\n",
       "      <td>0.029676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donahue, J  (2017)</th>\n",
       "      <td>0.143670</td>\n",
       "      <td>0.435661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bruzzone, L  (2010)</th>\n",
       "      <td>0.138631</td>\n",
       "      <td>-0.146922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dong, C  (2015)</th>\n",
       "      <td>0.066674</td>\n",
       "      <td>0.301108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li, W  (2014)</th>\n",
       "      <td>0.303360</td>\n",
       "      <td>-0.149746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhu, F  (2014)</th>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhang, L  (2016)</th>\n",
       "      <td>0.214494</td>\n",
       "      <td>-0.144183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long, MS  (2013)</th>\n",
       "      <td>0.061330</td>\n",
       "      <td>-0.096565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gao, J  (2014)</th>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.034770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shelhamer, E  (2017)</th>\n",
       "      <td>0.184947</td>\n",
       "      <td>0.546704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendall, A  (2015)</th>\n",
       "      <td>0.030070</td>\n",
       "      <td>0.238349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long, MS  (2014)</th>\n",
       "      <td>0.047416</td>\n",
       "      <td>-0.129711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shao, L  (2015)</th>\n",
       "      <td>-0.313831</td>\n",
       "      <td>0.095732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pan, SJ  (2011)</th>\n",
       "      <td>0.159015</td>\n",
       "      <td>-0.127751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             x         y\n",
       "term                                    \n",
       "Ben-David, S  (2010)  0.091006 -0.075597\n",
       "Lu, J  (2015)        -0.340530  0.066492\n",
       "Girshick, R  (2016)   0.173054  0.437989\n",
       "Duan, LX  (2012)      0.172170 -0.178303\n",
       "Fu, YW  (2015)        0.095830  0.040449\n",
       "Taylor, ME  (2009)   -0.462783  0.094160\n",
       "Pan, SJ  (2010)      -0.467088  0.029676\n",
       "Donahue, J  (2017)    0.143670  0.435661\n",
       "Bruzzone, L  (2010)   0.138631 -0.146922\n",
       "Dong, C  (2015)       0.066674  0.301108\n",
       "Li, W  (2014)         0.303360 -0.149746\n",
       "Zhu, F  (2014)        0.014070  0.032399\n",
       "Zhang, L  (2016)      0.214494 -0.144183\n",
       "Long, MS  (2013)      0.061330 -0.096565\n",
       "Gao, J  (2014)        0.164957  0.034770\n",
       "Shelhamer, E  (2017)  0.184947  0.546704\n",
       "Kendall, A  (2015)    0.030070  0.238349\n",
       "Long, MS  (2014)      0.047416 -0.129711\n",
       "Shao, L  (2015)      -0.313831  0.095732\n",
       "Pan, SJ  (2011)       0.159015 -0.127751"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection = pd.DataFrame({'term': corpus.get_metadata(), 'x': u.T[0], 'y': u.T[1]}).set_index('term')\n",
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = 'NORMAL'\n",
    "scores = (corpus.get_category_ids() == corpus.get_categories().index(category)).astype(int)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_pca_explorer(corpus,\n",
    "                               category,\n",
    "                               category_name='2009~2016',\n",
    "                               not_category_name='2017~2019',\n",
    "                               metadata=data['Author - Year'],\n",
    "                               width_in_pixels=600,\n",
    "                               show_axes=False,\n",
    "                               use_non_text_features=True,\n",
    "                               use_full_doc=True,\n",
    "                               projection=projection,\n",
    "                               scores=scores,\n",
    "                               show_top_terms=False,\n",
    "                               save_svg_button=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352070"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Documents5.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
