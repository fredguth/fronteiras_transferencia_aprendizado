%%%% Proceedings format for most of ACM conferences (with the exceptions listed below) and all ICPS volumes.
\documentclass[sigconf]{acmart}
\usepackage{graphicx, wrapfig}
\graphicspath{{imgs/}}
\usepackage[para]{footmisc} %  footnotes na mesma linha
\usepackage{lipsum}
% \usepackage[inline]{enumitem}
\usepackage{stfloats}
\usepackage{enumerate}
\usepackage[most]{tcolorbox}
\usepackage[english,ngerman,brazilian]{babel}


\newtcolorbox[blend into=figures]{card}[2][]{enhanced,
  float=tbp,title={#2},
  colframe=gray!75!black,olback=yellow!5!white,#1
}


\settopmatter{printacmref=false}
\setcopyright{none}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}
\captionsetup{justification   = raggedright,
              singlelinecheck = false}
\newcommand{\source}[2]{\raggedleft{}\vspace*{-7mm}\caption*{ \textmd{\scriptsize{Dados: {#1}.\hfill Ferramenta:{#2}}}}}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% end of the preamble, start of the body of the document source.
\begin{document}

%
% The "title" command has an optional parameter, allowing the author to define a "short title" to be used in page headers.
\title[Fronteiras da Transferência de Aprendizado: uma revisão sistemática com enfoque meta-analítico]{Fronteiras da Transferência de Aprendizado: \\
uma revisão sistemática com enfoque meta-analítico}
%

\author{Fred Guth}
\email{fredguth@fredguth.com}
\affiliation{%
  \institution{Departamento de Ciência de Computação, Universidade de Brasília}
  \postcode{70.910-900}
  \city{Brasília}
  \state{DF}
  \country{Brazil}
}

\renewcommand{\shortauthors}{Guth, F.}

\begin{abstract}
  Humanos e animais conseguem aprender com poucas amostras e apresentam extraordinária capacidade de generalização que os algoritmos de aprendizagem de máquina ainda estão longe de alcançar~\cite{goodfellow}. Os modelos mais bem sucedidos da atualidade exigem uma enormidade de dados bem rotulados que são caros e difíceis de obter, tornando-se hoje um dos maiores empecilhos para aplicações práticas. Tais fatos apontam para o grande potencial da área de Transferência de Aprendizado, que tem por objetivo aproveitar o conhecimento obtido em uma atividade para aprender mais eficientemente outras, que guardem alguma relação com a primeira. O presente estudo visa apresentar uma revisão sistemática da literatura e identificar, com embasamento quantitativo, as principais contribuições para a área. Além disso, usamos medidas de acoplamento bibliográfico para identificar trabalhos na fronteira do conhecimento e fizemos uma análise textual, em resumos e palavras-chave, comparando estes com os "clássicos" da área de forma a mapear para que direção a pesquisa avança.  
\end{abstract}


\begin{CCSXML}
<ccs2012>
 <concept>
 <concept_id>10010147.10010257.10010258.10010262.10010277</concept_id>
 <concept_desc>Computing methodologies~Transfer learning</concept_desc>
 <concept_significance>500</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[500]{Computing methodologies~Transfer learning}

\keywords{transferência de aprendizado, revisão sistemática, enfoque meta-analítico}


\maketitle


\section{Introdução} 
  Recentes avanços em Aprendizagem de Máquina tornam possíveis aplicações que são capazes de reconhecer pessoas, lugares e objetos com acurácia super-humana\cite{fei}, diagnosticar câncer de pele tão bem quanto dermatologistas\cite{skin_cancer},  ver através de paredes usando sinais de rádio\cite{wifi}, entre tantas outras. Apesar de tanto sucesso, os modelos mais bem sucedidos da atualidade exigem uma enormidade de dados bem rotulados que são caros e difíceis de obter, pois, em geral, o jeito padrão de se treinar modelos é sempre começar \emph{tabula rasa}, ou seja, com uma inicialização aleatória dos parâmetros~\cite{Ruder2019Neural}. 
  
  Aprender assim, a partir do nada, é contrário à forma como os humanos o fazem. Em nosso dia a dia, transferimos conhecimento a todo momento. Saber tocar piano, facilita aprender tocar órgão. Saber português ajuda a aprender espanhol. Pessoas conseguem inteligentemente aplicar conhecimento prévio para resolver novos problemas com maior eficácia e eficiência\cite{PanYang}. Algoritmos de aprendizagem de máquina ainda estão longe de alcançar essa extraordinária capacidade de generalização\cite{goodfellow}. Estudos recentes~\cite{DBLP:journals/corr/JiaL17}, mostram que os algoritmos atuais não generalizam bem além de dados vistos durante o treinamento. 
  \begin{figure}[h]
    \includegraphics[width=\columnwidth]{citacoes_por_ano}
    \source{Web of Science (março/2019)}{Excel}
    \caption{Evolução do número de citações aos artigos em Tranferência de Aprendizado nos últimos 10 anos. Até 2020, o número de citações aos artigos na área deverá dobrar.}
    \label{fig:citacoes_por_ano}
  \end{figure}

  Tais fatos apontam  o grande potencial ainda inalcançado da área de Transferência de Aprendizado (TL\footnote{Do inglês, \emph{Transfer Learning}.}), que tem por objetivo aproveitar o conhecimento obtido em uma atividade para aprender mais eficientemente outras, que guardem alguma relação com a primeira.
  
  Na prática, entretanto, TL ainda é tratada de uma forma \textit{ad hoc}, sendo os métodos de transferências meras extensões dos algoritmos de aprendizado utilizados \cite{torrey}. Essa dicotomia entre a importância do problema e a inexistência de práticas e teorias consolidadas, tornam TL um campo promissor e interessante para pesquisa. 
  
  \begin{quote} "Transferência de Aprendizado será o próximo motor do sucesso comercial com Aprendizado de Máquinas." \hfill ---Andrew Ng, Tutorial NIPS 2016 \cite{ANg}
  \end{quote}

  Portanto, não é de se estranhar o crescente interesse pelo assunto (vide figura \ref{fig:citacoes_por_ano} e \S\ref{sec:panorama}).  

  \subsection{Objetivo}\label{objetivos}
   Esta pesquisa quer responder duas perguntas:
    \begin{enumerate}
      \item{Quais são as fronteiras do conhecimento em Transferência de Aprendizado?}
      \item {É possível embasar essa avaliação em dados bibliométricos?}
    \end{enumerate}
    Para responder estas perguntas é preciso, antes, analisar a literatura do tema, revelar as principais contribuições na área e como se relacionam.
  
  \subsection{Contribuições}

    \begin{enumerate}[C1.]
      \item Apresentamos uma revisão sistemática atualizada da literatura em Transferência de Aprendizagem, usando a abordagem TEMAC (\S \ref{TEMAC}). Esse método nos permite focar nas contribuições de alto impacto. 
      \item Estendemos o TEMAC com uma análise textual de resumos (\S \ref{detalha}\ref{analiseTextual}), utilizando o \emph{ScatterText}~\cite{kessler2017scattertext}, o que até onde sabemos, é uma aplicação original desta ferramenta de visualização.
      \item Apontamos com embasamento quantitativo as direções das frentes de pesquisa da área e apontamos lacunas e problemas em aberto.
    \end{enumerate}
  
  \subsection{Visão Geral e Organização do Artigo}
  Ainda nesta breve introdução apresentaremos os \emph{Trabalhos Relacionados} (\S\ref{related}). Na próxima seção (\S\ref{TEMAC}), apresentaremos o método de pesquisa que dá embasamento quantitativo que queremos para atingirmos nossos objetivos (\S\ref{objetivos}). Na seção \S\ref{literatura}, apresentamos os resultados, que neste trabalho é a própria  \emph{Revisão da Literatura}. \emph{Problemas em Aberto} são discutidos na seção \S\ref{emAberto}. Por fim, concluímos o trabalho (\S\ref{conclusao}) apresentando as respostas às perguntas de \S\ref{objetivos}.
  

  \subsection{Trabalhos Relacionados}\label{related}
  Pan, S. (2009)\cite{PanYang} é a mais citada revisão sobre \emph{Transferência de Aprendizado}. Hohman, F. (2018) faz uma revisão sistemática da literatura sobre análises visuais em \emph{deep learning} e utiliza um método bastante interessante baseado nos cinco W's e um H (Why, Who, What, How, When, and Where). Ruder, S. (2019) \cite{Ruder2019Neural} apresenta um capítulo com uma revisão bibliográfica e taxonomia para o contexto de NLP. Park, I. (2018) utiliza uma abordagem meta-analítica para identificar a fronteira de pesquisa em \emph{Pattern Recognition}.
\section{Método: Revisão com Enfoque Meta-Analítico Consolidado}\label{TEMAC}
Na presente pequisa utilizamos o método de revisão sistemática da Teoria do Enfoque Meta-Analítico (TEMAC) ~\cite{Mariano}, que visa oferecer um embasamento quantitativo para a escolha da literatura. Apesar do nome, TEMAC não deve ser confundida com Meta-Análise, pois o foco desta é gerar conhecimento por meio de dados empíricos secundários, enquanto o daquela é oferecer uma sistematização da escolha bibliográfica.

A abordagem TEMAC é dividida em 3 etapas: 
\begin{enumerate}[a)]
  \item preparação da pesquisa;
  \item apresentação e inter-relação dos dados;
  \item detalhamento, modelo integrador e validação por evidências.
\end{enumerate}

\subsection{Preparação da Pesquisa}
Foi realizada uma busca na base de dados \emph{Clarivate Analyticis Web of Science (WoS)}, conforme especificado na figura \ref{card:wos}, no dia 31 de março de 2019, que resultou em 1.289 artigos encontrados. Nota-se que o tema é de crescente interesse (figura \ref{fig:artigos_por_ano}) e projeta-se que em 3 anos o número de artigos irá praticamente dobrar (crescimento exponencial com $R^2=0,9789$). 
\begin{figure}[htp]

\begin{tcolorbox}[colback=yellow!5!white,colframe=gray!75!black,title={Results: 1,289 (from Web of Science Core Collection)}]
  \footnotesize{
    \begin{verbatim}
    You searched for: 
    TOPIC: ("transfer learning")
    Refined by: 
    WEB OF SCIENCE CATEGORIES: 
      ( COMPUTER SCIENCE ARTIFICIAL INTELLIGENCE )
    AND LANGUAGES: ( ENGLISH ) 
    AND RESEARCH AREAS: ( COMPUTER SCIENCE )
    Timespan: 2009-2019. 
    Indexes: SCI-EXPANDED, CPCI-S, ESCI.
    \end{verbatim}
  }

\end{tcolorbox}
\caption{"Busca10anos": Parâmetros de busca na base \emph{Web of Science}.}
\label{card:wos}
\end{figure}

Também fizemos uma busca mais restrita aos trabalhos mais recentes (figura \ref{card:sota}) para a análise da \emph{Fronteira de Pesquisa} (\S \ref{fronteira}).
\begin{figure}[htp]
  \begin{tcolorbox}[colback=yellow!5!white,colframe=gray!75!black,title={Results: 384 (from Web of Science Core Collection)}]
    \footnotesize{
  \begin{verbatim}
  You searched for: 
  TOPIC: ("transfer learning")
  Refined by: 
  WEB OF SCIENCE CATEGORIES: 
    ( COMPUTER SCIENCE ARTIFICIAL INTELLIGENCE )
  AND LANGUAGES: ( ENGLISH ) 
  AND RESEARCH AREAS: ( COMPUTER SCIENCE )
  AND PUBLICATION YEARS: ( 2019 OR 2018 OR 2017 )
  AND DOCUMENT TYPES: ( PROCEEDINGS PAPER )
  Timespan: 2009-2019. 
  Indexes: SCI-EXPANDED, CPCI-S, ESCI.
  \end{verbatim}
    }
  
  \end{tcolorbox}
  \caption{"Busca2anos"Parâmetros de busca para análise de Fronteira.}
  \label{card:sota}
\end{figure}

\subsection{Apresentação e Inter-relação dos Dados}\label{inter}
Nessa etapa apresentamos (vide \S\ref{sec:panorama}):
\begin{enumerate}
  \item artigos mais citados e com melhor média de citações por ano;
  \item evolução ano a ano do número de artigos;
  \item evolução ano a ano do número de citações;
  \item autores com mais artigos e com mais citações;
  \item conferência com mais artigos e citações;
  \item instituições com mais artigos e citações;
  \item países que mais produzem artigos científicos na área;
  \item frequencia de palavras-chave (figuras \ref{fig:clouds} e \ref{fig:scatterText}).
\end{enumerate}
\subsection{Detalhamento}\label{detalha}

\begin{enumerate}[a)]
  \item{\textbf{Análise de Co-citações}: Co-citação é definida como a frequência em que dois documentos são citados em uma mesma lista de referências. Assume-se que são "peças"~que compõem uma mesma "estrutura de conhecimento".  A análise de co-citações, portanto, é útil para mapear a herança intelectual de um determinado campo de estudos sob a ótica das publicações de alto-impacto, mas tende a negligenciar a dinâmica na fronteira de pesquisa\cite{Vogel2012}, justamente porque os trabalhos na fronteira não tiveram tempo para serem citados e pontuar nas métricas de impacto.\\Para a análise de co-citações, utilizamos o software livre \emph{VosViewer 1.6.10}~\cite{VOSviewer}, que \emph{clusterizou} citações das listas de referências dos artigos da "Busca10anos" (o que abrange artigos que não fazem parte do resultado da busca). Foram identificados 3 núcleos de conhecimento (figura \ref{fig:classicos}).
  }

  \item{\textbf{Análise de Acoplamento Bibliográfico}: Acoplamento bibliográfico ocorre quando dois documentos tem pelo menos um documento em comum, ou seja, documentos acoplam se suas bibliografias se sobrepõem. Como existe uma ordem cronológica entre o documento que cita e o que é citado, o acoplamento bibliográfico permite traçar gerações de pesquisas e com isso identificar as que estão na fronteira do conhecimento.  É importante ressaltar que, neste contexto, estar na fronteira não é necessariamente ser promissor. Essa é uma limitação da abordagem quantitativa, por isso é preciso complementá-la com uma análise qualitativa para propor, ainda que com certo grau de subjetividade, os trabalhos promissores a se tornar os "clássicos de amanhã". \\Pelo TEMAC, a análise de acoplamento bibliográfico deve ser feita para o período um período não superior aos últimos 3 anos. Em nossa análise, usamos uma busca mais restrita (figura \ref{card:sota}) com período entre 2017 e março de 2019 e nos restringimos também aos artigos de conferência, assumindo que publicação em revista têm uma maior tempo de revisão, portanto, artigos em conferências são publicados mais proximamente ao momento de sua confecção. 
  }
  \item{\textbf{Análise Textual (\emph{bag-of-words}  com tf-idf)}: nesta análise, tratamos os artigos como \emph{bag-of-words} e usamos o conceito de \textbf{tf-idf} para definir as palavras (termos) que melhor identificam determinados artigos (documentos). Por exemplo, quais palavras melhor explicam trabalhos de fronteira vis à vis o todos os documentos resultantes da busca na base \emph{Web of Science} (vide figura \ref{fig:scatterText}). A métrica \textbf{tf-idf} pode ser definida como:
  \begin{equation}
    \mathrm{tfidf}(t,d,D) = \mathrm{tf}(t,d) \cdot \mathrm{idf}(t, D)
  \end{equation}
  onde $\mathrm{tf}(t,d)$ é a frequência em que um termo $t$ aparece em um documento $d$ e $\mathrm{idf}(t, D)$ é o inverso da frequência do termo $t$ no conjunto de documentos $D$ (o \emph{corpus}). 
  \begin{equation}
    \mathrm{tf}(t,d) = 0.5 + 0.5 \cdot  \frac{f_{t, d}}{\max\{f_{t', d}:t' \in d\}}
  \end{equation}
  \begin{equation}
    \mathrm{idf}(t, D) =  \log \frac{N}{|\{d \in D: t \in d\}|}
  \end{equation}
  onde:
  \begin{description}
    \item $N$: número de documentos do corpus $N = {|D|}$
   \item$ |\{d \in D: t \in d\}| $ : número de documentos onde o termo  $ t $ aparece (i.e., $ \mathrm{tf}(t,d) \neq 0$). Para evitar uma divisão por zero caso o termo não esteja no corpus, é como fazer um ajuste no denominador para: $1 + |\{d \in D: t \in d\}|$.
  \end{description}
  
  A métrica \textbf{tf-idf} é a base da ferramenta visual \emph{ScatterText}~\cite{kessler2017scattertext} que foi utilizada para gerar as figuras \ref{fig:scatterText_documentbased} e \ref{fig:scatterText}.

  }\label{analiseTextual}
\end{enumerate}



\section{Revisão da Literatura}\label{literatura}
  \subsection{Um breve histórico}
  Pesquisa em transferência de aprendizado tem atraído mais e mais atenção desde 1995, quando foi tema de  um workshop na NIPS-95 que discutiu a necessidade de métodos de aprendizado de máquina que retém e reusam conhecimento previamente obtido~\cite{PanYang}. 
  
  Desde então, ainda que com diferentes nomes (\emph{learning to learn, life-long learning, knowledge transfer} entre outros), a área vem recebendo cada vez mais atenção (figuras \ref{fig:artigos_por_ano} e \ref{fig:citacoes_por_ano}). Em 2005 um anúncio de um projeto da DARPA foi talvez a primeira menção que ao termo \emph{transfer learning}, definindo-o como o objetivo de extrair conhecimento de um ou mais \emph{tarefas fonte} e aplicá-lo a \emph{tarefas alvo}~\cite{PanYang}. Se removermos a restrição de data de início da "Busca10Anos"(figure \ref{card:wos}), confirmamos que os primeiros artigos com o termo "transfer learning" são de 2005.

  \begin{figure}[h]
    \includegraphics[width=\columnwidth]{artigos_por_ano}
    \source{Web of Science (março/2019)}{Excel}
    \caption{Evolução do número de artigos em Tranferência de Aprendizado nos últimos 10 anos. Até 2021, o número de artigos na área deverá dobrar.}
    \label{fig:artigos_por_ano}
  \end{figure}

  Em 2012, a rede neural profunda\footnote{deep neural network} submetida pelo time de Alex Krizhevsky et. al. para o desafio Imagenet (ILSVRC) performou 41\% melhor que o segundo melhor colocado, dando início ao crescimento explosivo de \emph{deep learning} na pesquisa de Aprendizado de Máquinas. Tal sucesso ressaltou a importância dos dados para o avanço de inteligência artificial, mas também permitiu uma igual quebra de paradigma em transferência de aprendizado: percebeu-se que modelos treinados na ImageNet podiam facilmente ser usados para inicializar outros modelos e reduzir em muito a necessidade de amostras~\cite{Ruder2019Neural}.   Essa abordagem de "sintonia fina"\footnote{\emph{fine-tuning}} permitiu resultados bons em diversas tarefas com ordens de magnitude a menos de dados. 

  Atualmente, \emph{transferência de aprendizado} é um tópico comum em prestigiadas conferências como CVPR, ICCV, ICPR e NeurIPS (vide figura \ref{fig:toptop}, \emph{Top 10 encontros}).
  \subsection{Notações e definições}
  \begin{figure}[h]
    \fbox{\includegraphics[width=\columnwidth]{taxonomy.pdf}}
    \caption{Visão geral dos diversos tipos de transferência. Taxonomia de \emph{A Survey on Transfer Learning}\protect{~\cite{PanYang}} }
    \label{fig:taxonomia}
  \end{figure}
    Transferência de Aprendizado envolve os conceitos de \emph{domínio} e \emph{tarefa}. Seguindo a notação de \cite{PanYang}, um domínio $\mathcal{D}$ é composto de um espaço de características $\mathcal{X}\subset R^d$ e uma distribuição marginal $P(\mathrm{X})$, onde $\mathrm{S}=\{x_1, \dots, x_n\}\in\mathcal{X} $. Para um problema de classificação de imagens, por exemplo, $\mathcal{X}$ é o espaço de todas possíveis representações de imagens, com suas dimensões e canais, $x_i$ é uma imagem e $\mathrm{S}$ é o \textit{dataset} de treinamento. 

    Dado um domínio $\mathcal{D}=\{\mathcal{X}, P(X)\}$, uma tarefa $\mathcal{T}$ é definida pelo espaço de rótulos $\mathcal{Y}$ com distribuição condicional $P(\mathrm{Y}|\mathrm{X})$, ou seja, $\mathcal{T}=\{\mathcal{Y}, f(\cdot)\}$, onde $f(\cdot)$ é uma função objetivo que dado um $x_i \in \mathcal{D}$, prediz seu correspondente $y_i \in \mathcal{Y}$. 

    Dado um domínio fonte $\mathcal{D_S}$ e uma tarefa $\mathcal{T_S}$, um domínio destino $\mathcal{D_T}$ e uma tarefa $\mathcal{T_T}$, \textbf{transferência de aprendizado} objetiva auxiliar o aprendizado da função de predição $f_T(\cdot)$ em  $\mathcal{D_T}$ usando conhecimento de $\mathcal{D_S}$ e $\mathcal{T_S}$, onde $\mathcal{D_S}\neq\mathcal{D_T}$ ou $\mathcal{T_S}\neq\mathcal{T_T}$.

    No presente artigo, usaremos a taxonomia dos tipos de transferência apresentada na figura \ref{fig:taxonomia}. 
    \subsection{O panorama da produção científica na área}\label{sec:panorama}
  Na figura \ref{fig:toptop}, é possível notar que o autor com mais citações é Pan, S., com 2706 citações. Tal impacto deve-se, sobretudo ao artigo \emph{A Survey on Transfer Learning}, que é o artigo mais citado da área com 2240 citações. O mérito deste trabalho é apresentar notações e uma taxonomia para TL. Saiu na revista \emph{IEEE Transactions on Knowledge an Data Engineering}, de 2,775 de fator de impacto, e ocupa a 33\textordfeminine ~posição no ranking de publicações InCite JCR para a categoria \emph{Computer Science, Artificial Intelligence}, ou seja, uma publicação cujo foco não é o tipo de pesquisa que menciona \emph{transferência de aprendizado}. 

  A China é o país com o maior número de artigos publicados, seguido pelos Estados Unidos. O Brazil está na 11\textordfeminine colocação, junto com a Índia, mas a frente de países como Espanha, Coreia do Sul e Israel.

  A maior parte dos artigos são publicados em \emph{proceeding} de conferências, 63\%. A conferência com mais artigos sobre TL é a CVPR\footnote{Conference on Computer Vision and Pattern Recognition}, mas apesar de ser somente a 4\textordfeminine em artigos a ECCV\footnote{European Conference on Computer Vision} é a conferência com o maior número agregado de citações. É digno de nota que as conferências de visão computacional tem sido o espaço onde artigos de TL mais são divulgados. Ao mesmo tempo, estranha a falta de alguma conferência com maior foco em NLP. Também não há entre os 20 artigos mais citados, nenhum que seja especializado em linguagem.
  \subsection{Os Clássicos}\label{classicos}
  \begin{figure}[h!]
    \fbox{\includegraphics[width=\columnwidth]{completo_21.pdf}}
    \source{Web of Science (março/2019)}{VosViewer\protect{~\cite{VOSviewer}}}
    \caption{Núcleos de conhecimento obtidos pela análise de co-citações. Os diferentes grupos representam autores que normalmente são co-citados nos 1268 artigos resultantes da busca realizada.}
    \label{fig:classicos}
  \end{figure}
  \begin{figure*}[htp]
    \centering
    \fbox{\includegraphics[width=\textwidth]{listas.pdf}}
    \source{Web of Science (março/2019)}{Excel}
    \caption{Panorama da produção científica sobre Transferência de Aprendizado.} \label{fig:toptop}
  \end{figure*}
A análise de co-citação usando o \emph{VosViewer} apontou para existência de 3 núcleos\footnote{\emph{clusters}} de conhecimento. Esses núcleos têm um forte componente temporal, podendo ser vistos como ondas, a primeira concentrando obras anteriores a 2011 (a moda é 2006),  está em amarelo na figura \ref{fig:classicos}, a segunda entre 2011 e 2014 (a moda é 2012) está em vermelho, e a terceira e última onda, em verde na figura, são obras de 2012 até hoje (moda 2014).

\subsubsection{Primeira onda}
Uma das características mais fortes desta onda é sua componente teórica. Nesse núcleo estão obras que apresentam algumas classes de transferência de aprendizado: Thurn, S. (1996) \cite{thrun1996learning} e Caruana, R. (1997) \cite{Caruana1997} introduzem \emph{Multi-Task Learning} e a ideia de que tarefas adicionais (ou auxiliares) introduzem um viés indutivo que facilita a convergência do aprendizado; Chapelle, O. (2006) \cite{Chapelle:2010:SL:1841234} com seu livro sobre \emph{Semi-Supervised Learning}; Raina, R. (2007) e \emph{Self-taught learning}; Vapnik, V. (1998) \cite{Vapnik1998} e os fundamentos da teoria de aprendizagem estatística.

Uma outra componente da primeira onda são artigos de Adaptação de Domínio, com certo foco em abordagens que buscam aprender características latentes, de menor dimensionalidade, com o pressuposto que em um espaço latente os domínios são mais similares: Ando, R. K.(2005) \cite{ando2005framework}, Blitzer, J. (2006) \cite{Blitzer:2006:DAS:1610075.1610094} e Daume, H.. (2006) \cite{DaumeIII2006}, por exemplo. 

Por fim, algumas das obras mais citadas desta onda são \emph{surveys}: Pan, S. (2010) \cite{PanYang}, Taylor, M. E. (2009) \cite{Taylor:2009:TLR:1577069.1755839}; que não por coincidência aparecem já mais para o final da primeira onda, organizando a pesquisa até aquele ponto. 

\subsubsection{Segunda onda}
A segunda onda é dominada por artigos sobre Adaptação de Domínio.  Alguns continuam com o foco em características latente como Pan, S. (2011) \cite{Pan2011}, mas a maioria usa abordagens que tentam selecionar amostras do domínio fonte que sejam similares ao domínio alvo: Ben-David, S. (2010) \cite{BenDavid2009} aborda similaridade da distribuição de domínios, Si, S. (2010) \cite{SiSi2010} busca minimizar a divergência; Nesta abordagem também é comum utilizar classificadores, em geral \emph{Support Vector Machines} (SVMs): Yang, J. (2007) \cite{Yang2007}, Bruzzone, L. (2010) \cite{Bruzzone2010}, Duan, L. (2012)\cite{LixinDuan2012}, entre outros.

Há também trabalhos de Adaptação Não Supervisionada de Domínio: Gong, B. (2012) \cite{BoqingGong2012}, Fernando, B. (2013) \cite{Fernando2013}.
Notou-se com estranheza que não apareceu em nossa análise nenhuma \emph{survey} "fechando" essa onda, apesar de sabermos da existência do capítulo \emph{A Comprehensive Survey on Domain Adaptation for Visual Applications}, Csurka, G. (2017) \cite{Csurka2017}. Foi constatado, entretanto, que esta obra não foi indexada pela base \emph{WoS} e portanto não fez parte dos resultados de nossas buscas. 

\subsubsection{Terceira onda}
A terceira onda é o núcleo de conhecimento de transferência de aprendizado no contexto de \emph{deep learning}. 

Encontramos obras clássicas como: Hinton, G. (2006) \cite{Hinton2006}, talvez o artigo seminal de \emph{Deep Learning}; Bengio, Y. (2009) \cite{Bengio2009} apresenta o conceito de \emph{representation learning} e a ideia de curriculum, uma sequencia de tarefas a serem aprendidas em sequencia, por terem representações em diferentes níveis de complexidade; LeCun, Bengio e Hinton (2015)\cite{LeCun2015} fazem uma revisão da área de \emph{Deep Learning}. Também aqui se encontra o artigo de Krizhevsky, A. (2012) \cite{alexnet}, sobre \emph{AlexNet}, o modelo que ao ganhar o desafio ImageNet (ILSVRC) de 2012 com uma margem de mais de 40\% melhor que o segundo colocado, tornou \emph{Deep Learning} conhecido do público geral e deu início a uma verdadeira "corrida do ouro" na pesquisa de aprendizado de máquina. 

Alguns artigos são sobre \emph{large datasets}, um importante componente de \emph{deep learning}:  Deng, J. (2009) \cite{Deng2009} apresenta a ImageNet e sugere que modelos treinados nela poderão ser usados para aprender novos domínios mais facilmente; Everingham, M. (2009) \cite{Everingham2009} traz o desafio Pascal VOC; Russakovsky, O. (2015) \cite{Russakovsky2015} analisa o impacto da ImageNet em diversos problemas de visão computacional, e, consequentemente, o papel da transferência de aprendizado. 

Há também artigos que apresentam arquiteturas para resolução de tarefas específicas, utilizando modelos pre-treinados na ImageNet como extração de características: Girshick, R. (2014) \cite{Girshick2014}, modelo R-CNN, He, K. (2016) \cite{He2016}, Resnet, e Simonyan, K.\cite{simonyan2014very}, em detecção de objetos;  Fan, J. \cite{JialueFan2010} em rastreamento de humanos; Long e Shelhamer (2015) \cite{Long2015} em segmentação semântica; entre outros.

Transferência de aprendizado passou a ser tão onipresente em \emph{Deep Learning} que Mahajan (2018) \cite{mahajan2018exploring} argumenta que \emph{não} pré-treinar modelos na ImageNet em problemas de visão computacional é um descuido.  

Por essa razão, é difícil apontar trabalhos desta onda cujo foco é a Transferência de Aprendizado. Nessa vertente, alguns artigos dignos de nota são: Glorot, X. (2011) \cite{glorot2011domain} é o primeiro a propor aplicar \emph{deep neural networks} par aprender representações comuns para Adaptação de Domínio; Donahue, J. (2014)\cite{donahue2014decaf} e Oquab, M. (2014)\cite{Oquab:2014:LTM:2679600.2680210} mostram que parametros aprendidos em tarefas fonte servem como representações que permitem aprender com poucos exemplos a tarefa alvo.

  \begin{figure}
    \fbox{\includegraphics[width=\columnwidth]{top20_abstracts.pdf}}
    \caption{} \label{fig:scatterText_documentbased}
  \end{figure}
  \begin{figure}
    \fbox{\includegraphics[width=\columnwidth]{keyword_clouds}}
    \caption{} \label{fig:clouds}
  \end{figure}
  \subsection{A Fronteira}\label{fronteira}
  \lipsum[2]
  \begin{figure}
    \includegraphics[width=\columnwidth]{frontier3.pdf}
    \caption{} \label{fig:scatterText}
  \end{figure}
  \begin{figure}
    \fbox{\includegraphics[width=\columnwidth]{frontier_heat}}
    \caption{} \label{fig:bicoupling}
  \end{figure}

\section{Problemas em Aberto}\label{emAberto}
\begin{enumerate}
  \item inexistência de métricas específicas para medir transferência.
  \item não há uma categorização que dê a devida importância a métodos mais novos (GANs, autoencoders)...???
  \item NLP
  \item Teoria
  \item categorização específica deep transfer learning
  \item 
\end{enumerate}
\lipsum[3]
\section{Conclusão}\label{conclusao}
\lipsum[3]
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}
\end{document}
