FN Clarivate Analytics Web of Science
VR 1.0
PT S
AU Isin, A
   Sharif, T
AF Isin, Ali
   Sharif, Tazeen
BE Aliev, RA
   Kacprzyk, J
   Pedrycz, W
   Jamshidi, M
   Sadikoglu, FM
TI Deep Learning for Lung Lesion Detection
SO 13TH INTERNATIONAL CONFERENCE ON THEORY AND APPLICATION OF FUZZY SYSTEMS
   AND SOFT COMPUTING - ICAFS-2018
SE Advances in Intelligent Systems and Computing
CT 13th International Conference on Application of Fuzzy Systems and Soft
   Computing (ICAFS)
CY AUG 27-28, 2018
CL Warsaw, POLAND
DE Deep learning; Lung lesion detection; Biomedical image processing;
   Transfer learning
AB As the most fatal cancer type, early diagnosis of the lung cancer plays an important role for the survival of the patients. Diagnosis of the lung cancer involves screening the patients initially by Computed Tomography (CT) for the presence of lung lesions. This procedure requires expert radiologists which need to go over very large numbers of image slices manually in order to detect and diagnose lung lesions. Unfortunately this is a very time consuming process and its performance is very dependent on the performing radiologist. Thus assisting the radiologists by developing an automated computer aided detection (CAD) system is an interesting research goal. In this regard, as the aim of this paper a pre-trained AlexNet (deep learning) framework is transferred to develop and implement a robust CAD system for the classification of lung images depending on whether they bear a lung lesion or not. High performances of 98.72% sensitivity, 98.35% specificity and 98.48% accuracy are reported as a result.
CR DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Isin A, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/03/C03089
   Isin A, 2017, PROCEDIA COMPUT SCI, V120, P268, DOI 10.1016/j.procs.2017.11.238
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Krizhevsky A., 2016, P ADV NEUR INF PROC, P1097
   Reeves AP, 2009, IEEE ENG MED BIO, P3715, DOI 10.1109/IEMBS.2009.5334807
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Wang G, 2016, IEEE ACCESS, V4, P8914, DOI 10.1109/ACCESS.2016.2624938
NR 8
TC 0
Z9 0
SN 2194-5357
EI 2194-5365
BN 978-3-030-04164-9
PY 2019
VL 896
BP 799
EP 806
DI 10.1007/978-3-030-04164-9_105
UT WOS:000461058100105
ER

PT S
AU Hussain, M
   Bird, JJ
   Faria, DR
AF Hussain, Mahbub
   Bird, Jordan J.
   Faria, Diego R.
BE Lotfi, A
   Bouchachia, H
   Gegov, A
   Langensiepen, C
   McGinnity, M
TI A Study on CNN Transfer Learning for Image Classification
SO ADVANCES IN COMPUTATIONAL INTELLIGENCE SYSTEMS (UKCI)
SE Advances in Intelligent Systems and Computing
CT 18th UK Workshop on Computational Intelligence (UKCI)
CY SEP 05-07, 2018
CL Nottingham Trent Univ, Nottingham, ENGLAND
HO Nottingham Trent Univ
AB Many image classification models have been introduced to help tackle the foremost issue of recognition accuracy. Image classification is one of the core problems in Computer Vision field with a large variety of practical applications. Examples include: object recognition for robotic manipulation, pedestrian or obstacle detection for autonomous vehicles, among others. A lot of attention has been associated with Machine Learning, specifically neural networks such as the Convolutional Neural Network (CNN) winning image classification competitions. This work proposes the study and investigation of such a CNN architecture model (i.e. Inception-v3) to establish whether it would work best in terms of accuracy and efficiency with new image datasets via Transfer Learning. The retrained model is evaluated, and the results are compared to some state-of-the-art approaches.
OI Bird, Jordan/0000-0002-9858-1231
CR Arun PV, 2013, GEOD CARTOGR, V62, P33, DOI 10.2478/geocart-2013-0005
   Gao Y., 2018, COMPUT AIDED CIV INF
   Larsen-Freeman D, 2013, LANG LEARN, V63, P107, DOI 10.1111/j.1467-9922.2012.00740.x
   Lin M., 2013, NETWORK NETWOR UNPUB
   Mathworks.com, 2018, MATHWORKS
   Nguyen N., 2016, COMPUTATIONAL COLLEC
   Rohrer B, 2016, CONVOLUTIONAL NEURAL
   Szegedy C., 2016, IEEE CVPR 2016 COMPU
   Szegedy C, 2015, GOING DEEPER CONVOLU
   TensorFlow, 2018, IM REC
   Vision Caltech, 2018, COMP VIS
   Wu J., 2015, CNN FOR DUMMIES
NR 12
TC 0
Z9 0
SN 2194-5357
EI 2194-5365
BN 978-3-319-97982-3; 978-3-319-97981-6
PY 2019
VL 840
BP 191
EP 202
DI 10.1007/978-3-319-97982-3_16
UT WOS:000456013900016
ER

PT S
AU Quinonez, Y
   Zatarain, O
   Lizarraga, C
   Peraza, J
AF Quinonez, Yadira
   Zatarain, Oscar
   Lizarraga, Carmen
   Peraza, Juan
BE Mejia, J
   Munoz, M
   Rocha, A
   Pena, A
   PerezCisneros, M
TI Using Convolutional Neural Networks to Recognition of Dolphin Images
SO TRENDS AND APPLICATIONS IN SOFTWARE ENGINEERING (CIMPS 2018)
SE Advances in Intelligent Systems and Computing
CT 7th International Conference on Software Process Improvement (CIMPS)
CY OCT 17-19, 2018
CL CUCEI, Guadalajara, MEXICO
HO CUCEI
DE Convolutional neural networks; Machine learning; Deep learning;
   TensorFlow; Inception V3; Inception ResNet V2
AB Classification of specific objects through Convolutional Neural Networks (CNN) has become an interesting research line in the area from information processing and machine learning, main idea is training a image dataset to perform the classifying a given pattern. In this work, a new dataset with 2504 images was introduced, the method used to train the networks was transfer learning to recognition of dolphin images. For this purpose, two models were used: Inception V3 and Inception ResNet V2 to train on TensorFlow platform with different images, corresponding to the four main classes: dolphin, dolphin_pod, open_sea, and seabirds. The paper ends with a critical discussion of the experimental results.
CR Alshahrani S, 2016, LECT NOTES COMPUT SC, V9612, P343, DOI 10.1007/978-3-319-41754-7_33
   [Anonymous], 2011, 1 ERKAM GURESEN 2 GU, V3, P426
   Atallah RR, 2018, IEEE ACCESS, V6, P28290, DOI 10.1109/ACCESS.2018.2836924
   Awad M., 2015, EFFICIENT LEARNING M, P167
   Bradbury Gwyneth, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P209, DOI 10.1007/978-3-642-40246-3_26
   Chen Q, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P204, DOI 10.1109/SITIS.2016.40
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Choi WG, 2014, LECT NOTES COMPUT SC, V8692, P417, DOI 10.1007/978-3-319-10593-2_28
   Goswami Tilottama, 2018, Microelectronics, Electromagnetics and Telecommunications. Proceedings of ICMEET 2017. LNEE 471, P475, DOI 10.1007/978-981-10-7329-8_48
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Habibi A. H., 2017, GUIDE CONVOLUTIONAL, P85
   He K, 2015, ARXIV151203385
   He X., 2018, DEEP LEARNING NATURA, P289
   Heck L, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P597, DOI 10.1109/GlobalSIP.2014.7032187
   Huang FL, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P704, DOI 10.1109/CompComm.2016.7924793
   Larasati R, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON SMART CITIES, AUTOMATION & INTELLIGENT COMPUTING SYSTEMS (ICON-SONICS 2017), P99, DOI 10.1109/ICON-SONICS.2017.8267829
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lu WS, 2017, IEEE PAC RIM CONF CO
   Miyajima R, 2017, IEEE MULTIMEDIA, V24, P91
   Moriya Shun, 2018, 2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC). Proceedings, P153, DOI 10.1109/COMPSAC.2018.10220
   Ouarda W, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P89, DOI 10.1109/SOCPAR.2014.7007987
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sustika R, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P17, DOI 10.1109/ICITISEE.2017.8285488
   Szegedy C., 2015, ARXIV151200567
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu Q, 2017, 2017 CHINESE AUTOMATION CONGRESS (CAC), P6522, DOI 10.1109/CAC.2017.8243952
   Yamashita R., 2018, INSIGHTS IMAGING, P1
NR 28
TC 0
Z9 0
SN 2194-5357
EI 2194-5365
BN 978-3-030-01171-0; 978-3-030-01170-3
PY 2019
VL 865
BP 236
EP 245
DI 10.1007/978-3-030-01171-0_22
UT WOS:000455365000022
ER

PT S
AU Comert, Z
   Kocamaz, AF
AF Comert, Zafer
   Kocamaz, Adnan Fatih
BE Silhavy, R
TI Fetal Hypoxia Detection Based on Deep Convolutional Neural Network with
   Transfer Learning Approach
SO SOFTWARE ENGINEERING AND ALGORITHMS IN INTELLIGENT SYSTEMS
SE Advances in Intelligent Systems and Computing
CT 7th Computer Science On-Line Conference (CSOC)
CY APR, 2018
CL ELECTR NETWORK
DE Biomedical signal processing; Fetal monitoring; Deep convolutional
   neural network; Classification
ID HEART-RATE CLASSIFICATION; SUPPORT VECTOR MACHINE; RATE-VARIABILITY;
   CARDIOTOCOGRAPHY
AB Electronic fetal monitoring (EFM) device which is used to record Fetal Heart Rate (FHR) and Uterine Contraction (UC) signals simultaneously is one of the significant tools in terms of the present obstetric clinical applications. In clinical practice, EFM traces are routinely evaluated with visual inspection by observers. For this reason, such a subjective interpretation has been caused various conflicts among observers to arise. Although the existing of international guidelines for ensuring more consistent assessment, the automated FHR analysis has been adopted as the most promising solution. In this study, an innovative approach based on deep convolutional neural network (DCNN) is proposed to classify FHR signals as normal and abnormal. The proposed method composes of three stages. FHR signals are passed through a set of preprocessing procedures in order to ensure more meaningful input images, firstly. Then, a visual representation of time-frequency information, spectrograms are obtained with the help of the Short Time Fourier Transform (STFT). Finally, DCNN method is utilized to classify FHR signals. To this end, the colored spectrograms images are used to train the network. In order to evaluate the proposed model, we conducted extensive experiments on the open CTU-UHB database considering the area under the receiver operating characteristic curve and other several performance metrics derived from the confusion matrix. Consequently, we achieved encouraging results.
OI Comert, Zafer/0000-0001-5256-7648
CR Ayres-De-Campos D, 2015, INT J GYNECOL OBSTET, V131, P13, DOI 10.1016/j.ijgo.2015.06.020
   Bernardes J, 1998, INT J GYNECOL OBSTET, V62, P141, DOI 10.1016/S0020-7292(98)00079-4
   Brown R, 2014, MED HYPOTHESES, V83, P410, DOI 10.1016/j.mehy.2014.07.009
   Bursa M, 2017, LECT NOTES COMPUT SC, V10443, P100, DOI 10.1007/978-3-319-64265-9_9
   Cesarelli M, 2007, COMPUT BIOL MED, V37, P663, DOI 10.1016/j.compbiomed.2006.06.003
   Chudacek V, 2014, BMC PREGNANCY CHILDB, V14, DOI 10.1186/1471-2393-14-16
   Comert Z, 2017, ACTA PHYS POL A, V132, P451, DOI 10.12693/APhysPolA.132.451
   Comert Z., 2016, INT J COMPUT APPL, V156, P26, DOI DOI 10.5120/IJCA2016912417.
   Comert Z., 2017, INT C ARTIF INTEL DA, P1, DOI [10.1109/IDAP.2017.8090210, DOI 10.1109/IDAP.2017.8090210]
   Comert Z., 2017, J SCI TECHNOL, V7, P93
   Comert Z., 2017, 25 SIGN PROC COMM AP, P1, DOI [10.1109/SIU.2017, DOI 10.1109/SIU.2017.7960397]
   Comert Z., 2016, 24 SIGN PROC COMM AP
   Comert Z., 2016, INT ART INT DAT PROC, P569, DOI [10.13140.CRG.2.2.23901.00489, DOI 10.13140/RG.2.2.23901.00489]
   Czabanski R, 2012, EXPERT SYST APPL, V39, P11846, DOI 10.1016/j.eswa.2012.01.196
   Garabedian C, 2017, J GYNECOL OBSTET HUM, V46, P131, DOI 10.1016/j.jogoh.2016.11.002
   GROOME LJ, 1994, EARLY HUM DEV, V38, P1, DOI 10.1016/0378-3782(94)90045-0
   Kahaner D., 1989, NUMERICAL METHODS SO
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Magenes G, 2004, P ANN INT IEEE EMBS, V26, P462
   Monteiro-Santos J, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19120688
   Murray H, 2017, BEST PRACT RES CL OB, V38, P2, DOI 10.1016/j.bpobgyn.2016.10.008
   NAWAB SH, 1983, IEEE T ACOUST SPEECH, V31, P986, DOI 10.1109/TASSP.1983.1164162
   Palomaki O, 2006, J PERINAT MED, V34, P298, DOI 10.1515/JPM.2006.057
   Romano M., 2014, 13 MED C MED BIOL EN, P651, DOI [10.1007/978-3-319-00846-2_161, DOI 10.1007/978-3-319-00846-2_161]
   Romano M, 2016, COMPUT MATH METHOD M, DOI 10.1155/2016/9585431
   Sahin H, 2015, APPL SOFT COMPUT, V33, P231, DOI 10.1016/j.asoc.2015.04.038
   Spilka Jiri, 2013, Information Technology in Bio- and Medical Informatics. 4th International Conference (ITBAM 2013). Proceedings: LNCS 8060, P47, DOI 10.1007/978-3-642-40093-3_4
   Spilka J, 2017, IEEE J BIOMED HEALTH, V21, P664, DOI 10.1109/JBHI.2016.2546312
   Subha V., 2015, J COMMUN TECHNOL EL, V2, P13
   Tongsong T, 2005, J OBSTET GYNAECOL RE, V31, P68, DOI 10.1111/j.1447-0756.2005.00243.x
   vanGeijn HP, 1996, BAILLIERE CLIN OB GY, V10, P185, DOI 10.1016/S0950-3552(96)80033-2
   Warrick P, 2005, IEEE IJCNN, P2400
   Yu YH, 2017, INFORMATION, V8, DOI 10.3390/info8030091
NR 34
TC 1
Z9 1
SN 2194-5357
EI 2194-5365
BN 978-3-319-91186-1; 978-3-319-91185-4
PY 2019
VL 763
BP 239
EP 248
DI 10.1007/978-3-319-91186-1_25
UT WOS:000445094400025
ER

PT J
AU Crosswhite, N
   Byrne, J
   Stauffer, C
   Parkhi, O
   Cao, Q
   Zisserman, A
AF Crosswhite, Nate
   Byrne, Jeffrey
   Stauffer, Chris
   Parkhi, Omkar
   Cao, Qiong
   Zisserman, Andrew
TI Template adaptation for face verification and identification
SO IMAGE AND VISION COMPUTING
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
DE Face recognition; Biometrics; Face verification
AB Face recognition performance evaluation has traditionally focused on one-to-one verification, popularized by the Labeled Faces in the Wild data set [1] for imagery and the YouTubeFaces data set [2] for videos. In contrast, the newly released IJB-A face recognition data set [3] unifies evaluation of one-to-many face identification with one-to-one face verification over templates, or sets of imagery and videos for a subject. In this paper, we study the problem of template adaptation, a form of transfer learning to the set of media in a template. Extensive performance evaluations on IJB-A show a surprising result, that perhaps the simplest method of template adaptation, combining deep convolutional network features with template specific linear SVMs, outperforms the state-of-the-art by a wide margin. We study the effects of template size, negative set construction and classifier fusion on performance, then compare template adaptation to convolutional networks with metric learning, 2D and 3D alignment. Our unexpected conclusion is that these other methods, when combined with template adaptation, all achieve nearly the same top performance on IJB-A for template-based face verification and identification. (C) 2018 Elsevier B.V. All rights reserved.
CR AbdAlmageed W., 2016, WACV
   Chatfield K., 2015, INT J MULTIMED INF R
   Chen D., 2012, ECCV
   Chen J., 2015, ICCV WORKSH CHALEARN
   Chen V. PJ., 2016, WACV
   Crosswhite N, 2016, TEMPLATE ADAPTATION
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Grother P., 2014, 8009 NIST
   Hayat M., 2017, CVPR
   Hu G., 2015, ICCV WORKSH CHALEARN
   Huang G. B., 2007, 0749 U MASS
   Kazemi V., 2014, CVPR
   Klare B. F., 2015, CVPR
   Kobayashi T., 2015, CVPR
   Learned-Miller E., 2015, ADV FACE DETECTION F
   Lu C., 2015, AAAI
   Malisiewicz T., 2011, ICCV
   Maze B., 2018, 11 IAPR INT C BIOM
   Parkhi O. M., 2014, CVPR
   Parkhi O.M., 2015, BMVC
   Phillips J., 2015, BTAS
   Ranjan  R., 2017, L2 CONSTRAINED SOFTM
   RoyChowdry A., 2016, WACV
   Sankaranarayanan S., 2016, TRIPLET SIMILARITY E
   Schroff F., 2015, CVPR
   Simonyan K., 2015, ICLR
   Sun Y, 2015, CVPR
   Sun Y., 2014, DEEPID3 FACE RECOGNI
   Szegedy C., 2015, CVPR
   Taigman Y., 2014, CVPR
   Taigman Y., 2015, CVPR
   Wan L., 2013, ICML
   Whitelam C., 2017, CVPR WORKSH BIOM
   Wolf L., 2011, CVPR
   Wolf L, 2011, PAMI, V33
   Wolf L, 2009, ICCV
   Xiong  L., 2017, GOOD PRACTICE TOP PE
   Yi D, 2014, LEARNING FACE REPRES
   Zinkevich M., 2011, NIPS
NR 39
TC 0
Z9 0
SN 0262-8856
EI 1872-8138
PD NOV
PY 2018
VL 79
BP 35
EP 48
DI 10.1016/j.imavis.2018.09.002
UT WOS:000449893800004
ER

PT J
AU Singaravel, S
   Suykens, J
   Geyer, P
AF Singaravel, Sundaravelpandian
   Suykens, Johan
   Geyer, Philipp
TI Deep-learning neural-network architectures and methods: Using component
   based models in building-design energy prediction
SO ADVANCED ENGINEERING INFORMATICS
CT 24th EG-ICE International Workshop on Intelligent Computing in
   Engineering (EG-ICE)
CY JUL 10-12, 2017
CL Nottingham, ENGLAND
DE Performance gap; Sustainability; Building performance simulation;
   Transfer learning; Multi-task learning; LSTM
ID COOLING-LOAD PREDICTION; RESIDENTIAL BUILDINGS; CONSUMPTION;
   PERFORMANCE; OPTIMIZATION; REGRESSION; FRAMEWORK; VS.
AB Increasing sustainability requirements make evaluating different design options for identifying energy-efficient design ever more important. These requirements demand simulation models that are not only accurate but also fast. Machine Learning (ML) enables effective mimicry of Building Performance Simulation (BPS) while generating results much faster than BPS. Component-Based Machine Learning (CBML) enhances the capabilities of the monolithic ML model. Extending monolithic ML approach, the paper presents deep-learning architectures, component development methods and evaluates their suitability for space exploration in building design. Results indicate that deep learning increases the performance of models over simple artificial neural network models. Methods such as transfer learning and Multi-Task Learning make the component development process more efficient. Testing the deep-learning model on 201 new design cases indicates that its cooling energy prediction (R-2: 0.983) is similar to BPS, while errors for heating energy predictions (R-2: 0.848) are higher than BPS. Higher heating energy prediction error can be resolved by collecting heating data using better design space sampling methods that cover the heating demand distribution effectively. Given that the accuracy of the deep-learning model for heating predictions can be increased, the major advantage of deep-learning models over BPS is their high computation speed. BPS required 1145 s to simulate 201 design cases. Using the deep-learning model, similar results can be obtained in 0.9 s. High computation speed makes deep-learning models suitable for design space exploration.
OI Geyer, Philipp/0000-0002-0935-4361
CR Amasyali K, 2018, RENEW SUST ENERG REV, V81, P1192, DOI 10.1016/j.rser.2017.04.095
   Ascione F, 2017, ENERG BUILDINGS, V146, P200, DOI 10.1016/j.enbuild.2017.04.069
   Augenbroe G, 2002, BUILD ENVIRON, V37, P891, DOI 10.1016/S0360-1323(02)00041-0
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chary Aarthi, 2017, Expert Rev Clin Pharmacol, P1, DOI 10.1080/17512433.2017.1377610
   Cheng MY, 2014, APPL SOFT COMPUT, V22, P178, DOI 10.1016/j.asoc.2014.05.015
   Chollet  F., 2015, KERAS
   Cohen N., 2015, EXPRESSIVE POWER DEE
   de Souza CB, 2012, AUTOMAT CONSTR, V22, P112, DOI 10.1016/j.autcon.2011.09.008
   de Wilde P, 2014, AUTOMAT CONSTR, V41, P40, DOI 10.1016/j.autcon.2014.02.009
   Dong B, 2005, ENERG BUILDINGS, V37, P545, DOI 10.1016/j.enbuild.2004.09.009
   Edwards RE, 2012, ENERG BUILDINGS, V49, P591, DOI 10.1016/j.enbuild.2012.03.010
   Eisenhower B, 2012, ENERG BUILDINGS, V47, P292, DOI 10.1016/j.enbuild.2011.12.001
   Fan C, 2017, APPL ENERG, V195, P222, DOI 10.1016/j.apenergy.2017.03.064
   Geyer P., COMPONENT BASE UNPUB
   Goodfellow I., 2016, DEEP LEARN
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1, DOI 10.1162/neco.1997.9.1.1
   Horsey H., 2016, ACEEE SUMMER STUDY E
   Hou ZJ, 2006, APPL ENERG, V83, P1033, DOI 10.1016/j.apenergy.2005.08.006
   Kiros R., 2014, P 31 INT C MACH LEAR, P595
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Magalhaes SMC, 2017, ENERG BUILDINGS, V151, P332, DOI 10.1016/j.enbuild.2017.06.076
   Magnier L, 2010, BUILD ENVIRON, V45, P739, DOI 10.1016/j.buildenv.2009.08.016
   Menezes AC, 2012, APPL ENERG, V97, P355, DOI 10.1016/j.apenergy.2011.11.075
   Ngiam J, 2011, IEEE INT C MACH LEAR, V28, P689
   Paudel S, 2017, ENERG BUILDINGS, V138, P240, DOI 10.1016/j.enbuild.2016.11.009
   Ruder S., 2017, OVERVIEW MULTITASK L
   Sak H, 2014, INTERSPEECH, P338
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Singaravel S., 2016, INT WORKSH EUR GROUP, P23
   Singaravel S., 2017, EG ICE, P260
   Singaravel S., 2017, P 15 IBPSA C, P2617
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever  I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.1007/S10107-014-0839-0
   Tsanas A, 2012, ENERG BUILDINGS, V49, P560, DOI 10.1016/j.enbuild.2012.03.003
   U. of W. -M. S. E. Laboratory, 1975, TRNSYS TRANS SIM PRO
   van Dronkelaar C., 2016, FRONTIERS MECH ENG, V1, P1, DOI DOI 10.3389/FMECH.2015.00017
   Van Gelder L, 2014, SIMUL MODEL PRACT TH, V49, P245, DOI 10.1016/j.simpat.2014.10.004
   Yu Z, 2010, ENERG BUILDINGS, V42, P1637, DOI 10.1016/j.enbuild.2010.04.006
   Zapata-Lancaster G, 2016, ARCHIT ENG DES MANAG, V12, P279, DOI 10.1080/17452007.2016.1178627
   Zhang F, 2016, ENERG BUILDINGS, V126, P94, DOI 10.1016/j.enbuild.2016.05.028
NR 43
TC 3
Z9 3
SN 1474-0346
EI 1873-5320
PD OCT
PY 2018
VL 38
BP 81
EP 90
DI 10.1016/j.aei.2018.06.004
UT WOS:000454378700007
ER

PT J
AU Dodge, S
   Mounsef, J
   Karam, L
AF Dodge, Samuel
   Mounsef, Jinane
   Karam, Lina
TI Unconstrained ear recognition using deep neural networks
SO IET BIOMETRICS
CT Conference on Unconstrained Ear Recognition Challenge (UERC) held in
   conjunction with the International Joint Conference on Biometrics (IJCB)
CY OCT 01-04, 2017
CL Denver, CO
DE neural nets; ear; feature extraction; learning (artificial
   intelligence); image classification; shallow classifier; deep
   learning-based averaging ensemble; DNNs; feature extractor; transfer
   learning; deep neural networks; combined AWE plus CVLE dataset;
   unconstrained ear recognition datasets; feature-extraction models;
   training dataset
ID DISCRIMINANT-ANALYSIS; FEATURES; SHAPE
AB The authors perform unconstrained ear recognition using transfer learning with deep neural networks (DNNs). First, they show how existing DNNs can be used as a feature extractor. The extracted features are used by a shallow classifier to perform ear recognition. Performance can be improved by augmenting the training dataset with small image transformations. Next, they compare the performance of the feature-extraction models with fine-tuned networks. However, because the datasets are limited in size, a fine-tuned network tends to over-fit. They propose a deep learning-based averaging ensemble to reduce the effect of over-fitting. Performance results are provided on unconstrained ear recognition datasets, the AWE and CVLE datasets as well as a combined AWE + CVLE dataset. They show that their ensemble results in the best recognition performance on these datasets as compared to DNN feature-extraction based models and single fine-tuned models.
CR Ahmad A., 2017, INT JOINT C BIOM OCT
   Anwar AS, 2015, PROCEDIA COMPUT SCI, V65, P529, DOI 10.1016/j.procs.2015.09.126
   Benzaoui A., 2016, INT C ADV ASP SOFTW, P1
   Burge M., 1996, BIOMETRICS, P273
   Burge M., 1997, WORKSH AUSTR ASS PAT, P275
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Chatfield K., 2014, BRIT MACH VIS C
   Choras M., 2005, ELECT LETT COMPUTER, V5, P51
   Choras M, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P451
   Emersic Z., 2017, INT JOINT C BIOM OCT
   Emersic Z, 2017, IEEE INT CONF AUTOMA, P987, DOI 10.1109/FG.2017.123
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Erhan D., 2009, 1341 U MONTR
   Fabate A., 2006, INT C PATTERN RECOGN, V4, P437
   Forrest N, 2016, ARXIV160207360
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46
   Hurley DJ, 2005, COMPUT VIS IMAGE UND, V98, P491, DOI 10.1016/j.cviu.2004.11.001
   Jacob L, 2014, ADV INTELL SYST, V264, P1, DOI 10.1007/978-3-319-04960-1_1
   Kisku DR, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS, P380, DOI 10.1109/ACTEA.2009.5227958
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kumar A., 2007, SPIE DEF SEC S
   Kumar A, 2013, PATTERN RECOGN, V46, P73, DOI 10.1016/j.patcog.2012.06.020
   lannarelli A., 1989, EAR IDENTIFICATION
   Galdamez PL, 2017, J APPL LOGIC, V24, P62, DOI 10.1016/j.jal.2016.11.014
   Mamta, 2013, EXPERT SYST APPL, V40, P6478, DOI 10.1016/j.eswa.2013.05.020
   Moreno B., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P469, DOI 10.1109/CCST.1999.797956
   Mu Z., 2009, USTB EAR IMAGE DATAB
   Mu ZC, 2004, LECT NOTES COMPUT SC, V3338, P663
   Murukesh C, 2012, PROCEDIA ENGINEER, V38, P771, DOI 10.1016/j.proeng.2012.06.097
   Omara I, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P341
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sana A, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P46
   Sforza C, 2009, FORENSIC SCI INT, V187, DOI 10.1016/j.forsciint.2009.02.019
   Simonyan K., 2014, INT C LEARN REPR
   Tariq A., 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P50, DOI 10.1109/ICCSNT.2011.6181906
   Tian L, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P437, DOI 10.1109/CISP-BMEI.2016.7852751
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yu W., 2008, IEEE INT S PAR DISTR, P1
   Zhang H.J., 2005, IEEE INT C MACHINE L, P4511
   Zhao HL, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P228, DOI 10.1109/ICCSIT.2009.5234392
NR 44
TC 1
Z9 1
SN 2047-4938
EI 2047-4946
PD MAY
PY 2018
VL 7
IS 3
SI SI
BP 207
EP 214
DI 10.1049/iet-bmt.2017.0208
UT WOS:000430322000005
ER

PT B
AU Han, XY
   Peng, QK
   Zhu, ZB
AF Han, Xuyue
   Peng, Qinke
   Zhu, Zhibo
GP IEEE
TI Popularity Prediction of News Event Based on ELM and Transfer Learning
SO 2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA)
CT 13th World Congress on Intelligent Control and Automation (WCICA)
CY JUL 04-08, 2018
CL Changsha, PEOPLES R CHINA
ID ELECTION
AB With the popularization of the Internet, the impact of news events on the society is growing. Research on the evolution of news event popularity could help netizens to grasp the overall development of news events. At present, the timeliness of the popularity prediction method for news event is prevalently weak and the data set is insufficient. This paper captures the real-time data from Baidu news search engine, and builds the predictive model of news event popularity based on ELM (Extreme Learning Machine). According to the similarity between news events and the prediction error of news event popularity, we propose the ELM-based prediction method by introducing the transfer learning strategy which considers the normalization of peak values of the popularity series. Our method is beneficial for establishing the prediction model under the non-independent distribution with missing data in the modeling process. The experimental results show that our method can predict the popularity of news event timely and effectively.
CR Dai W, 2008, NIPS
   Grigorievskiy A, 2014, NEURAL NETWORKS, V51, P50, DOI 10.1016/j.neunet.2013.12.002
   Hong Jiaming, 2011, COMPUTER RES DEV, V48, P1823
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Hyun KD, 2015, INFORM COMMUN SOC, V18, P766, DOI 10.1080/1369118X.2014.994543
   Kaleel SB, 2015, J COMPUT SCI-NETH, V6, P47, DOI 10.1016/j.jocs.2014.11.004
   Le Zhang, 2013, COMPUTER DIGITAL ENG, V41, P772
   Lee FLF, 2010, INT J PRESS/POLIT, V15, P462, DOI 10.1177/1940161210375463
   Li Q, 2014, INFORM SCIENCES, V278, P826, DOI 10.1016/j.ins.2014.03.096
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Liu JQ, 2014, LECT NOTES COMPUT SC, V8597, P3, DOI 10.1007/978-3-319-11538-2_1
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   [梅灿华 Mei Canhua], 2011, [计算机研究与发展, Journal of Computer Research and Development], V48, P1722
   Nardis Y, 2015, INT J PRESS/POLIT, V20, P45, DOI 10.1177/1940161214556710
   Nassirtoussi AK, 2015, EXPERT SYST APPL, V42, P306, DOI 10.1016/j.eswa.2014.08.004
   Nuij W, 2014, IEEE T KNOWL DATA EN, V26, P823, DOI 10.1109/TKDE.2013.133
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pereira EN, 2016, INDEP J MANAG PROD, V7, P252, DOI 10.14807/ijmp.v7i1.400
   Rojas I, 2016, CONTRIBUTIONS STAT
   Schemer C, 2012, J COMMUN, V62, P739, DOI 10.1111/j.1460-2466.2012.01672.x
   Singh R, 2007, PROC WRLD ACAD SCI E, V26, P361
   Tatar A, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0174-8
   Wu B, 2015, INT J INFORM MANAGE, V35, P702, DOI 10.1016/j.ijinfomgt.2015.07.003
   Xu Min, 2014, Control and Decision, V29, P141
   Yang Deqing, 2010, J COMPUTER RES DEV, V47
   Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083
   Zhang P, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1427
   Zhang XM, 2015, NEUROCOMPUTING, V149, P1469, DOI 10.1016/j.neucom.2014.08.045
   Zhang XM, 2014, LECT NOTES COMPUT SC, V8485, P484, DOI 10.1007/978-3-319-08010-9_53
NR 29
TC 0
Z9 0
BN 978-1-5386-7345-4
PY 2018
BP 329
EP 334
UT WOS:000461361000055
ER

PT S
AU Alsabahi, YAL
   Fan, L
   Feng, XY
AF Alsabahi, Y. A. L.
   Fan, Lei
   Feng, Xiaoyi
GP IEEE
TI Image Classification Method in DR Image Based on Transfer Learning
SO 2018 EIGHTH INTERNATIONAL CONFERENCE ON IMAGE PROCESSING THEORY, TOOLS
   AND APPLICATIONS (IPTA)
SE International Conference on Image Processing Theory Tools and
   Applications
CT 8th International Conference on Image Processing Theory, Tools and
   Applications (IPTA)
CY NOV 07-10, 2018
CL Xian, PEOPLES R CHINA
DE Transfer Learning; DR images; medical image; CAD
ID TUBERCULOSIS
AB Until now many cancer cases have been discovered in their early stages based on Computer Aided Diagnosis (CAD) system. There are many methods in the medical image processing field have been proposed to address this issue, and the result of these methods was deficient. Further, the application of AI in DR images is not widespread in hospitals. The classification process in the DR image is more difficult than other types of images. In this paper, we use transfer learning which is based on Inception V3 model to classify the DR images. We used the weight of Inception V3 model which was trained in the ImageNet dataset, and fine-tuning in our own dataset. Comparing to other proposed methods, our result had a higher accuracy.
CR Abadi Martin, 2016, P 12 USENIX S OP SYS, P265, DOI DOI 10.1038/NN.3331
   Becker AS, 2017, INVEST RADIOL, V52, P434, DOI 10.1097/RLI.0000000000000358
   Chauhan R. P, 2016, INT J ADV TECHNOLOGY, V3, P217
   Dai W, 2009, P 26 ANN INT C MACH, P193, DOI DOI 10.1145/1553374.1553399
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   DeSantis CE, 2017, CA-CANCER J CLIN, V67, P439, DOI 10.3322/caac.21412
   Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822
   Fan L, 2017, 2017 INTERNATIONAL CONFERENCE ON THE FRONTIERS AND ADVANCES IN DATA SCIENCE (FADS), P7, DOI 10.1109/FADS.2017.8253184
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Jaeger S, 2013, QUANT IMAGING MED SU, V3, P89, DOI 10.3978/j.issn.2223-4292.2013.04.03
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu JC, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293125
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thomas MA, 2004, J DIGIT IMAGING, V17, P189, DOI 10.1007/s10278-004-1000-z
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wu J., 2018, J ELECTRON IMAGING, V27, P1
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
NR 20
TC 0
Z9 0
SN 2154-512X
BN 978-1-5386-6428-5
PY 2018
BP 195
EP 198
UT WOS:000461275700035
ER

PT B
AU Suharjito
   Gunawan, H
   Thiracitta, N
   Nugroho, A
AF Suharjito
   Gunawan, Herman
   Thiracitta, Narada
   Nugroho, Ariadi
GP IEEE
TI Sign Language Recognition Using Modified Convolutional Neural Network
   Model
SO 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL
   CONFERENCE (INAPR)
CT 1st International Conference of the
   Indonesian-Association-for-Pattern-Recognition (INAPR)
CY SEP 07-08, 2018
CL Bina Nusantara Univ, Jakarta, INDONESIA
HO Bina Nusantara Univ
DE deep learning; convolutional neural network; recognition; comparation;
   sign language
AB Sign Language is an interesting topic and similar to Action Recognition. Especially along with the great development of Deep Learning. Video-based Sign Language Recognition is our concern because we want to recognize a sign not only by the shape but also by the action the signer does. The problem is sign language is very complex and vary. The variation of sign language is making the system harder to recognize all the words accurately. Many researchers have been researching Sign Language Recognition for a long time. So many methods had been used to find out which one is the best method. Because of similarity between Sign Language Recognition and Action Recognition, we are trying to implement one of the top-tier models in Action Recognition which is i3d inception this model is also a new Action Recognition model with very high accuracy. So we can know is it possible to adopt Action Recognition behavior into Sign Language Recognition. The goal of this paper is to implement the i3d inception model to Sign Language Recognition with transfer learning method. From the test we've been done, we got 100% accuracy on training with 10 words and 10 signers with 100 classes but the validation accuracy is pretty low. This model is too overfit.
CR Christoph Feichtenhofer R.P.W., 2016, ADV NEURAL INFORM PR, P3468
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escalera S., 2014, P EUR C COMP VIS WOR, P459
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Jaoa Carriera A. Z., 2018, COMP VIS PATT REC CV, P4724
   Kay W., 2017, COMPUTER VISION PATT, P1
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Pigou L., 2014, WORKSH EUR C COMP VI, p[572, 572]
   Ronchetti F., 2016, 22 C ARG CIENC COMP, P794
   Soomro K., 2012, CORR, P1
   Suharjito, 2017, 2 INT C COMP SCI COM
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
NR 14
TC 0
Z9 0
BN 978-1-5386-9422-0
PY 2018
BP 1
EP 5
UT WOS:000461327500001
ER

PT B
AU Liawatimena, S
   Heryadi, Y
   Lukas
   Trisetyarso, A
   Wibowo, A
   Abbas, BS
   Barlian, E
AF Liawatimena, Suryadiputra
   Heryadi, Yaya
   Lukas
   Trisetyarso, Agung
   Wibowo, Antoni
   Abbas, Bahtiar Saleh
   Barlian, Erland
GP IEEE
TI A Fish Classification on Images using Transfer Learning and Matlab
SO 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL
   CONFERENCE (INAPR)
CT 1st International Conference of the
   Indonesian-Association-for-Pattern-Recognition (INAPR)
CY SEP 07-08, 2018
CL Bina Nusantara Univ, Jakarta, INDONESIA
HO Bina Nusantara Univ
DE Image classification; Machine learning; Marine animals
AB The Ministry of Marine Affairs and Fisheries (MMAF) carry out the responsibilities and features associated with the policy of marine and fisheries. MMAF carry out the responsibilities and features associated with marine and fisheries policy. One of their duties and functions are organized marine and fishery statistics, in accordance to Law of The Republic of Indonesia Number sixteen of 1997 regarding Statistics. The main problem is the number of enumerators at each Basis Landing Of Fish. This paper proposed a fish classification on fish images using transfer learning and Matlab as the first stage of tackling the problem. FishNet is a modification from AlexNet to classify Katsuwonus Pelamis (Skipjack tuna or Cakalang), Euthynnus Affinis (Tongkol) and Coryphaena Hippurus (Mahi-mahi) that caught by fishermen. There are 15.120 images of 3 type of fishes, 5.040 for each fish. Data is split into 70: 30 for training and validation set. The training process is done using Matlab 2018a on Windows 7 operating system in a notebook with single CPU i7 with 8 GB RAM for 124 minutes. The validation accuracy is 99.63%.
CR Al-Smadi M., 2013, AFRICAN J COMPUTING, V3, P199, DOI DOI 10.1146/ANNUREV.ANTHR0.34.081804.120613
   [Anonymous], 2018, MACHINE LEARNING ARM
   Brownlee  J., 2018, GENTLE INTRO TRANSFE
   Canziani  A., 2016, ANAL DEEP NEURAL NET
   Dettmers  T., 2018, FULL HARDWARE GUIDE
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hof  R., 2018, DEEP LEARNING MIT TE
   Hu J, 2012, COMPUT ELECTRON AGR, V88, P133, DOI 10.1016/j.compag.2012.07.008
   John Lu Z., 2010, JR STAT SOC A, V173, P693, DOI [10. 1111/j. 1467-985X. 2010. 00646_6. x, DOI 10.1111/J.1467-985X.2010.00646_6.X, 10.1111/j.1467-985X.2010.00646_6.x]
   Jung  A., 2017, IMGAUG IMGAUG 0 2 6
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lee  A., 2016, COMP DEEP NEURAL NET
   R. A. P. Publication, 2009, FISHING FLEET ACEH P
   Rathi  D., 2018, ARXIV180510106V1CSCV
   Wayongkere, MELAUT 40 MIL DAPAT
   Widodo A. A., 2016, INDONES FISH RES J, V22, P43
   Yang  Y., 2018, PRIOR NOTIFICATION I, P158
   Yin  D., 2018, GRADIENT DIVERSITY K
   Yuniarta S, 2017, FISH RES, V193, P173, DOI 10.1016/j.fishres.2017.04.009
NR 19
TC 0
Z9 0
BN 978-1-5386-9422-0
PY 2018
BP 108
EP 112
UT WOS:000461327500022
ER

PT S
AU Norouzifard, M
   Nemati, A
   GholamHosseini, H
   Klette, R
   Nouri-Mahdavi, K
   Yousefi, S
AF Norouzifard, Mohammad
   Nemati, Ali
   GholamHosseini, Hamid
   Klette, Reinhard
   Nouri-Mahdavi, Kouros
   Yousefi, Siamak
GP IEEE
TI Automated Glaucoma Diagnosis Using Deep and Transfer Learning: Proposal
   of a System for Clinical Testing
SO 2018 INTERNATIONAL CONFERENCE ON IMAGE AND VISION COMPUTING NEW ZEALAND
   (IVCNZ)
SE International Conference on Image and Vision Computing New Zealand
CT International Conference on Image and Vision Computing New Zealand
   (IVCNZ)
CY NOV 19-21, 2018
CL Auckland, NEW ZEALAND
DE Glaucoma diagnosis; Deep learning; Image classification; Transfer
   learning; VGG19; InceptionResNet-V2
ID PERIMETRY; SAP
AB We developed a deep learning algorithm for identifying glaucoma on optic nerve head (ONH) photographs. We applied transfer learning to overcome overfitting on the small training sample size that we employed. The transfer learning framework that was previously trained on large datasets such as ImageNet, uses the initial parameters and makes the approach applicable to small sample sizes. We then classified the input ONH photographs as "normal" or "glaucoma".
   The proposed approach achieved a validation accuracy of 92.3% on a dataset of 277 ONH photographs from normal eyes and 170 ONH photographs from eyes with glaucoma. In order to re-test the accuracy and generalizability of the proposed approach, we re-tested the algorithm using an independent dataset of 30 ONH photographs. The re-test accuracy was 80.0% on average.
CR Al-Bander B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040087
   Al-Bander B, 2017, INT MULTICONF SYST, P207, DOI 10.1109/SSD.2017.8166974
   [Anonymous], 2015, LATEST STATS GLANCE
   [Anonymous], 2017, INCEPTIONRESNET V2 N
   [Anonymous], 2017, VGG19 NETWORK
   Bowd C, 2000, Semin Ophthalmol, V15, P194, DOI 10.3109/08820530009037871
   Budai  A., 2013, INT J BIOMEDICAL IMA, V20
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Chen XY, 2015, LECT NOTES COMPUT SC, V9351, P669, DOI 10.1007/978-3-319-24574-4_80
   Choi JY, 2017, PLOS ONE, V12, DOI [10.1371/journal.pone.0187338, 10.1371/journal.pone.0187336]
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Johnson  C., 2014, CLIN GLAUCOMA CARE, P117
   Johnson CA, 2002, AM J OPHTHALMOL, V134, P177, DOI 10.1016/S0002-9394(02)01577-5
   Jonas JB, 1996, SURV OPHTHALMOL, V40, P369, DOI 10.1016/S0039-6257(96)80065-8
   Kingman S, 2004, B WORLD HEALTH ORGAN, V82, P887
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li F, 2018, BMC MED IMAGING, V18, DOI 10.1186/s12880-018-0273-5
   Lim G, 2015, PROC INT C TOOLS ART, P162, DOI 10.1109/ICTAI.2015.36
   Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z
   Nomoto H, 2009, J GLAUCOMA, V18, P165, DOI 10.1097/IJG.0b013e318179f7ca
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C., 2017, AAAI, P4278
   Thakur N, 2018, BIOMED SIGNAL PROCES, V42, P162, DOI 10.1016/j.bspc.2018.01.014
   Tham YC, 2014, OPHTHALMOLOGY, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Wahab  H., 2014, IM PROC THEOR TOOLS, P1
   Westcott MC, 1997, BRIT J OPHTHALMOL, V81, P452, DOI 10.1136/bjo.81.6.452
NR 27
TC 0
Z9 0
SN 2151-2191
BN 978-1-7281-0125-5
PY 2018
UT WOS:000461058900009
ER

PT S
AU Singh, S
   Ho-Shon, K
   Karimi, S
   Hamey, L
AF Singh, Sonit
   Ho-Shon, Kevin
   Karimi, Sarvnaz
   Hamey, Len
GP IEEE
TI Modality Classification and Concept Detection in Medical Images using
   Deep Transfer Learning
SO 2018 INTERNATIONAL CONFERENCE ON IMAGE AND VISION COMPUTING NEW ZEALAND
   (IVCNZ)
SE International Conference on Image and Vision Computing New Zealand
CT International Conference on Image and Vision Computing New Zealand
   (IVCNZ)
CY NOV 19-21, 2018
CL Auckland, NEW ZEALAND
DE Medical Image Analysis; Modality Classification; Medical Image
   Classification; Concept Detection; Multi-Label learning; Convolutional
   Neural Networks; Deep Learning
ID RADIOLOGY; FEATURES
AB Medical image classification and concept detection are two important tasks for efficient and robust medical retrieval systems and also help with downstream tasks such as knowledge discovery, medical report generation, medical question answering, and clinical decision making. We investigate the effectiveness of transfer learning on the modality classification task using state-of-the-art deep convolutional neural networks pretrained on generic images. We also compare the performance of the traditional pipeline of handcrafted features with multi-label learning algorithms with end-to-end deep learning features for the concept detection task. Experimental results on the modality classification task show that transfer learning can leverage the patterns learned from large training data to the medical domain where little labeled data is available. Moreover, results on the concept detection task show that the deep learning approach provides better and more powerful feature representations compared to handcrafted feature extraction methods. The results on both tasks suggest that deep transfer learning methods are effective in the medical domain where data is scarce.
CR Arias J, 2016, COMPUT VIS IMAGE UND, V151, P61, DOI 10.1016/j.cviu.2016.04.002
   Benites F, 2015, 2015 IEEE International Conference on Data Mining Workshop (ICDMW), P847, DOI 10.1109/ICDMW.2015.14
   Chollet  F., 2015, KERAS
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Demner-Fushman  D., 2012, J COMPUTING SCI ENG, V6, P166
   Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080
   Dimitrovski I, 2015, COMPUT MED IMAG GRAP, V39, P14, DOI 10.1016/j.compmedimag.2014.06.005
   Duda R., 1973, PATTERN CLASSIFICATI
   Erickson BJ, 2018, J AM COLL RADIOL, V15, P521, DOI 10.1016/j.jacr.2017.12.027
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Garcia Seco de Herrera  A., 2015, WORKING NOTES CLEF 2
   Gibaja  E., WILEY INTERDISCIPLIN, V4, P411
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hosmer Jr. D. W., 2005, APPL LOGISTIC REGRES
   Howard A. G., 2017, ABS170404861 CORR
   Junghwan  C., 2015, 151106348V2 CORR
   Kim HJ, 2017, INT C CONTROL DECISI, P1, DOI 10.1109/CoDIT.2017.8102557
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Meier C, 2013, AM J PREV MED, V44, pS5, DOI 10.1016/j.amepre.2012.09.018
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rajpurkar  P., 2017, ABS171105225 CORR
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Read J, 2009, LECT NOTES ARTIF INT, V5782, P254
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy  C., 2017, INCEPTION V4 INCEPTI
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang JS, 2014, INT J AUTOM COMPUT, V11, P72, DOI 10.1007/s11633-014-0767-8
   Wang LM, 2017, SCI REP-UK, V7, DOI 10.1038/srep41545
   Webb G. I., 2010, NAIVE BAYES, P713
   Yu  Y., 2017, INFORMATION, V8
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
NR 42
TC 0
Z9 0
SN 2151-2191
BN 978-1-7281-0125-5
PY 2018
UT WOS:000461058900067
ER

PT B
AU Sumon, SA
   Chowdhury, J
   Debnath, S
   Mohammed, N
   Momen, S
AF Sumon, Shakil Ahmed
   Chowdhury, Joydip
   Debnath, Sujit
   Mohammed, Nabeel
   Momen, Sifat
GP IEEE
TI Bangla Short Speech Commands Recognition Using Convolutional Neural
   Networks
SO 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING
   (ICBSLP)
CT International Conference on Bangla Speech and Language Processing
   (ICBSLP)
CY SEP 21-22, 2018
CL Sylhet, BANGLADESH
DE Automatic Speech Recognition; Bangla Speech Recognition; Short Speech
   Commands; MFCC; Transfer learning; Convolutional neural network
AB Despite being one of the most widely spoken languages of the world, no significant efforts have been made in Bangla speech recognition. Speech recognition is a difficult task, particularly if the demand is to do so in noisy real-life conditions. In this study, Bangla short speech commands data set has been reported, where all the samples are taken in the real-life setting. Three different convolutional neural network (CNN) architectures have been designed to recognize those short speech commands. Mel-frequency cepstral coefficients (MFCC) features have been extracted from the audio files in one approach whereas only the raw audio files have been used in another CNN architecture. Lastly, a pre-trained model which is trained on a large English short speech commands data set has been fine-tuned by retraining on Bangla data set. Experimental results reveal that the MFCC model shows better accuracy in recognizing Bangla short speech commands where, surprisingly, the model predicting on raw audio data is very competitive. The models have shown proficiency in identifying single syllable words but encounter difficulties in recognizing multi-syllable commands.
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Ali M. A., 2013, AUTOMATIC SPEECH REC
   Deng L, 2014, INT CONF ACOUST SPEE
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315
   Hossain M. A., 2013, IMPLEMENTATION BACK
   Jaitly  N., 2012, P INTERSPEECH 2012
   Juangand B. H., 2005, AUTOMATIC SPEECH REC
   Muhammad Ghulam, 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P379, DOI 10.1109/ICCIT.2009.5407267
   Paul AK, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P171, DOI 10.1109/ICAPR.2009.80
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
NR 11
TC 0
Z9 0
BN 978-1-5386-8207-4
PY 2018
UT WOS:000460564300003
ER

PT B
AU Zunair, H
   Mohammed, N
   Momen, S
AF Zunair, Hasib
   Mohammed, Nabeel
   Momen, Sifat
GP IEEE
TI Unconventional Wisdom: A New Transfer Learning Approach Applied to
   Bengali Numeral Classification
SO 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING
   (ICBSLP)
CT International Conference on Bangla Speech and Language Processing
   (ICBSLP)
CY SEP 21-22, 2018
CL Sylhet, BANGLADESH
DE bengali digit classification; deep learning; convolution neural
   networks; transfer learning; data augmentation; keras; Numtadb
AB In this modern age, natural language processing (NLP) is evolving due to advances in the field of deep learning and its access to huge amount of data and computation power. Recently a lot of attention has been given to OCR for Bangla, the 5th most widely spoken language in the world. This paper reports on certain rather unconventional transfer learning approaches used to attain 6th place in the Kaggle Numta competition, where the challenge was to classify images of isolated Bangla numerals. The best result reported in this paper is an accuracy of 97.09% on the NumtaDB Bengali handwritten digit datasets test set, which was obtained by freezing intermediate layers. The unconventional approach used in this paper produces better results than conventional transfer learning while taking less epochs and having almost half the number of trainable parameters.
CR Alam S., 2018, NUMTADB ASSEMBLED BE, DOI [10.13140/RG.2.2.33418.36800, DOI 10.13140/RG.2.2.33418.36800]
   Alex K., 2012, IMAGENET CLASSIFICAT
   Bengio Y., 2012, J MACHINE LEARNING R, P17
   Christian S., 2012, JMLR WORKSHOP C P, V27, P17
   Geoffrey H., 2015, DISTILLING KNOWLEDGE
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI [10.1016/j.conbuildmat.2017.09.110, 10.1016/j.conbuildmat2017.09.110]
   Jason Y., 2012, TRANSFERABLE ARE FEA
   Karen S., 2015, VERY DEEP CONVOLUTIO
   Mithun B., 2017, DATA IN BRIEF
   Saha Sourajit, 2018, Procedia Computer Science, V132, P1760, DOI 10.1016/j.procs.2018.05.151
   Sharif SMA, 2016, INT C COMP ELEC ENG, P463, DOI 10.1109/ICECE.2016.7853957
   Sharif S. M. A., 2018, P INT C COMP COMM SY, P403
   Shopon Md, 2016, 2016 International Workshop on Computational Intelligence (IWCI), P64, DOI 10.1109/IWCI.2016.7860340
   Shopon M., 2017, IM VIS PATT REC ICIV, P1
NR 14
TC 0
Z9 0
BN 978-1-5386-8207-4
PY 2018
UT WOS:000460564300005
ER

PT S
AU Liu, SH
   Shang, Y
   Han, JZ
   Wang, X
   Gao, HC
   Liu, DQ
AF Liu, Shaohua
   Shang, Yan
   Han, Jizhong
   Wang, Xi
   Gao, Hongchao
   Liu, Dongqin
BE Zeng, B
   Huang, Q
   ElSaddik, A
   Li, H
   Jiang, S
   Fan, X
TI Multi-lingual Scene Text Detection Based on Fully Convolutional Networks
SO ADVANCES IN MULTIMEDIA INFORMATION PROCESSING - PCM 2017, PT I
SE Lecture Notes in Computer Science
CT 18th Pacific-Rim Conference on Multimedia (PCM)
CY SEP 28-29, 2017
CL Harbin, PEOPLES R CHINA
DE Sence text detection; Multi-language; Transfer learning; Fully
   convolution networks
ID LOCALIZATION; IMAGES
AB In the paper, we propose a method based on transfer learning to detect multi-lingual text in natural scenes. First, a semantic segmentation map of the input image is obtained through a fully convolution network (FCN). In this map, each pixel is classified to text or none-text. And then, the candidate boxes of text regions are computed based on the map. In this procedure, VGG network is trained to obtain a basic character classifier of single language. Based on this VGG model, FCN has the ability to classify each pixel to text or none-text for multi-lingual with doing transfer learning. Finally, the bounding boxes of text are carry out by filtering the unsatisfied candidates with some rules. The experimental results show that our method achieves good performance on the task of multi-lingual text detection. And compared with other advanced method, the time cost of our method is shortest.
CR Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Do C., 2005, P ADV NEUR INF PROC, P299
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Liao M., 2016, ARXIV161106779
   Liu CM, 2005, EIGHTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, PROCEEDINGS, P610
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yi CC, 2012, IEEE T IMAGE PROCESS, V21, P4256, DOI 10.1109/TIP.2012.2199327
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
NR 21
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-77380-3; 978-3-319-77379-7
PY 2018
VL 10735
BP 423
EP 432
DI 10.1007/978-3-319-77380-3_40
PN I
UT WOS:000460422000040
ER

PT S
AU Oliveira, H
   dos Santos, JA
AF Oliveira, Hugo
   dos Santos, Jefersson A.
GP IEEE
TI Deep Transfer Learning for Segmentation of Anatomical Structures in
   Chest Radiographs
SO PROCEEDINGS 2018 31ST SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND
   IMAGES (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 31st Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 29-NOV 01, 2018
CL Foz do Iguacu, BRAZIL
AB Segmentation of anatomical structures in Chest Posterior-Anterior Radiographs is a classical task on biomedical image analysis. Deep Learning has been widely used for detection and diagnosis of illnesses in several medical image modalities over the last years, but the portability of deep methods is still limited, hampering the reusability of pre-trained models in new data. We address this problem by proposing a novel method for Cross-Dataset Transfer Learning in Chest X-Ray images based on Unsupervised Image Translation architectures. Our Transfer Learning approach achieved Jaccard values of 88.20% on lung field segmentation in the Montgomery Set by using a pre-trained model on the JSRT dataset and no labeled data from the target dataset. Several experiments in unsupervised and semi-supervised transfer were performed and our method consistently outperformed simple fine-tuning when a limited amount of labels is used. Qualitative analysis on the tasks of clavicle and heart segmentation are also performed on Montgomery samples and pre-trained models from JSRT dataset. Our secondary contributions encompass several experiments in anatomical structure segmentation on JSRT, achieving state-of-the-art results in lung field (96.02%), heart (89.64%) and clavicle segmentation (87.30%).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Buades A, 2005, PROC CVPR IEEE, P60
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Chen HC, 2015, MED TEACH, V37, P1090, DOI 10.3109/0142159X.2015.1009431
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Dai W., 2018, SCAN STRUCTURE CORRE
   Efros AA, 2001, COMP GRAPH, P341
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hogeweg L, 2012, MED IMAGE ANAL, V16, P1490, DOI 10.1016/j.media.2012.06.009
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2018, ARXIV180404732
   Isola Phillip, 2016, ARXIV161107004
   Jaeger S, 2014, QUANT IMAGING MED SU, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Liu  M., 2017, ADV NEURAL INFORM PR, P700
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Novikov A, 2018, IEEE T MED IMAGING
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ronneberger O., 2015, INT C MED IM COMP CO, V2015, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Zhang J., 2017, TRANSFER LEARNING CR
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu J.-Y., 2017, ARXIV170310593
NR 30
TC 0
Z9 0
SN 1530-1834
BN 978-1-5386-9264-6
PY 2018
BP 204
EP 211
DI 10.1109/SIBGRAPI.2018.00033
UT WOS:000459886600027
ER

PT S
AU Zanlorensi, LA
   Luz, E
   Laroca, R
   Britto, AS
   Oliveira, LS
   Menotti, D
AF Zanlorensi, Luiz A.
   Luz, Eduardo
   Laroca, Rayson
   Britto, Alceu S., Jr.
   Oliveira, Luiz S.
   Menotti, David
GP IEEE
TI The Impact of Preprocessing on Deep Representations for Iris Recognition
   on Unconstrained Environments
SO PROCEEDINGS 2018 31ST SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND
   IMAGES (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 31st Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 29-NOV 01, 2018
CL Foz do Iguacu, BRAZIL
AB The use of iris as a biometric trait is widely used because of its high level of distinction and uniqueness. Nowadays, one of the major research challenges relies on the recognition of iris images obtained in visible spectrum under unconstrained environments. In this scenario, the acquired iris are affected by capture distance, rotation, blur, motion blur, low contrast and specular reflection, creating noises that disturb the iris recognition systems. Besides delineating the iris region, usually preprocessing techniques such as normalization and segmentation of noisy iris images are employed to minimize these problems. But these techniques inevitably run into some errors. In this context, we propose the use of deep representations, more specifically, architectures based on VGG and ResNet-50 networks, for dealing with the images using (and not) iris segmentation and normalization. We use transfer learning from the face domain and also propose a specific data augmentation technique for iris images. Our results show that the approach using non-normalized and only circle-delimited iris images reaches a new state of the art in the official protocol of the NICE.II competition, a subset of the UBIRIS database, one of the most challenging databases on unconstrained environments, reporting an average Equal Error Rate (EER) of 13.98% which represents an absolute reduction of about 5%.
CR Ahmed NU, 2017, PATTERN RECOGN LETT, V91, P11, DOI 10.1016/j.patrec.2017.03.003
   Ahmed NU, 2016, INT C PATT RECOG, P176, DOI 10.1109/ICPR.2016.7899629
   Al-Waisy A. S., 2017, PATTERN ANAL APPL
   Andersen-Hoppe E., 2017, INT WORKSH BIOM FOR, P1
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Bowyer KW, 2012, PATTERN RECOGN LETT, V33, P965, DOI 10.1016/j.patrec.2011.11.024
   Cao Q., 2017, CORR
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   De Marsico M, 2017, PATTERN RECOGN LETT, V91, P3, DOI 10.1016/j.patrec.2016.12.013
   De Marsico M, 2016, PATTERN RECOGN LETT, V82, P106, DOI 10.1016/j.patrec.2016.02.001
   De Marsico M, 2012, PATTERN RECOGN LETT, V33, P1006, DOI 10.1016/j.patrec.2011.09.010
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Du Y., 2016, P IEEE S VLSI CIRC J, P1
   Enright A. J., 2012, CORR
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Lei Z, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4563043
   Li PH, 2012, PATTERN RECOGN LETT, V33, P1012, DOI 10.1016/j.patrec.2011.06.017
   Li PH, 2012, PATTERN RECOGN LETT, V33, P1000, DOI 10.1016/j.patrec.2011.06.018
   Liu NAF, 2016, PATTERN RECOGN LETT, V82, P154, DOI 10.1016/j.patrec.2015.09.016
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucio D. R., 2018, CORR
   Luz E., 2017, PATTERN RECOGNITION
   Marra F., 2017, PATTERN RECOGNITION
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Parkhi O. M., 2015, P BRIT MACHINE VISIO, P1, DOI DOI 10.5244/C.29.41
   Phillips P. J., 2008, BIOM THEOR APPL SYST, P1
   Proenca H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proenca H, 2017, PROC CVPR IEEE, P6747, DOI 10.1109/CVPR.2017.714
   Proenca H, 2012, IEEE T INF FOREN SEC, V7, P798, DOI 10.1109/TIFS.2011.2177659
   Proenca H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Santos G, 2012, PATTERN RECOGN LETT, V33, P984, DOI 10.1016/j.patrec.2011.08.017
   Severo E., 2018, CORR
   Sher A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON FUNCTIONAL-STRUCTURAL PLANT GROWTH MODELING, SIMULATION, VISUALIZATION AND APPLICATIONS (FSPMA), P189, DOI 10.1109/FSPMA.2016.7818306
   Shin KY, 2012, PATTERN RECOGN LETT, V33, P991, DOI 10.1016/j.patrec.2011.08.016
   Simard PY, 2003, SEVENTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P958
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szewczyk R, 2012, PATTERN RECOGN LETT, V33, P1019, DOI 10.1016/j.patrec.2011.08.018
   Tan TN, 2012, PATTERN RECOGN LETT, V33, P970, DOI 10.1016/j.patrec.2011.08.009
   Tan TN, 2010, IMAGE VISION COMPUT, V28, P223, DOI 10.1016/j.imavis.2009.05.008
   Tapia J, 2017, ADV COMPUT VIS PATT, P219, DOI 10.1007/978-3-319-61657-5_9
   Wang Q, 2012, PATTERN RECOGN LETT, V33, P978, DOI 10.1016/j.patrec.2011.08.014
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 48
TC 0
Z9 0
SN 1530-1834
BN 978-1-5386-9264-6
PY 2018
BP 289
EP 296
DI 10.1109/SIBGRAPI.2018.00044
UT WOS:000459886600038
ER

PT S
AU Nazare, TS
   da Costa, GBP
   de Mello, RF
   Ponti, MA
AF Nazare, Tiago S.
   Paranhos da Costa, Gabriel B.
   de Mello, Rodrigo F.
   Ponti, Moacir A.
GP IEEE
TI Color quantization in transfer learning and noisy scenarios: an
   empirical analysis using convolutional networks
SO PROCEEDINGS 2018 31ST SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND
   IMAGES (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 31st Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 29-NOV 01, 2018
CL Foz do Iguacu, BRAZIL
AB Transfer learning is seen as one of the most promising areas of machine learning. Lately, features from pre-trained models have been used to achieve state-of-the-art results in several machine vision problems. Those models are usually employed when the problem of interest does not have enough supervised examples to support the network training from scratch. Most applications use networks pre-trained on noise-free RGB image datasets, what is observed even when the target domain counts on grayscale images or when data is degraded by noise. In this paper, we evaluate the use of Convolutional Neural Networks (CNNs) on such transfer learning scenarios and the impact of using RGB trained networks on grayscale image tasks. Our results confirm that the use of networks trained using colored images on grayscale tasks hinders the overall performance when compared to a similar network trained on a quantized version of the original dataset. Results also show that higher quantization levels (resulting in less colors) increase the robustness of CNN features in the presence of noise.
CR Ahn J., 2018, PLOS ONE, V13
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   da Costa G. B. Paranhos, 2016, 12 WORKSH VIS COMP W
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Deng J., 2009, CVPR09
   Dodge Samuel F., 2016, 8 INT C QUAL MULT EX, V2016, P1, DOI DOI 10.1109/QOMEX.2016.7498955
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Krizhevsky A., 2009, THESIS
   Kylberg G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-17
   Nazare Tiago S., 2018, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 22nd Iberoamerican Congress, CIARP 2017. Proceedings: LNCS 10657, P416, DOI 10.1007/978-3-319-75193-1_50
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Ponti M, 2016, NEUROCOMPUTING, V173, P385, DOI 10.1016/j.neucom.2015.04.114
   Ponti MA, 2017, SIBGRAPI, P17, DOI 10.1109/SIBGRAPI-T.2017.12
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Springenberg J. T., 2014, 14126806 ARXIV
   Szegedy  C., 2015, COMPUTER VISION PATT
   Xiao H., 2017, FASHION MNIST NOVEL
NR 21
TC 0
Z9 0
SN 1530-1834
BN 978-1-5386-9264-6
PY 2018
BP 377
EP 383
DI 10.1109/SIBGRAPI.2018.00055
UT WOS:000459886600049
ER

PT S
AU Peixinho, AZ
   Benato, BC
   Nonato, LG
   Falcao, AX
AF Peixinho, Alan Z.
   Benato, Barbara C.
   Nonato, Luis G.
   Falcao, Alexandre X.
GP IEEE
TI Delaunay Triangulation Data Augmentation guided by Visual Analytics for
   Deep Learning
SO PROCEEDINGS 2018 31ST SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND
   IMAGES (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 31st Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 29-NOV 01, 2018
CL Foz do Iguacu, BRAZIL
AB It is well known that image classification problems can be effectively solved by Convolutional Neural Networks (CNNs). However, the number of supervised training examples from all categories must be high enough to avoid model over-fitting. In this case, two key alternatives are usually presented (a) the generation of artificial examples, known as data augmentation, and (b) reusing a CNN previously trained over a large supervised training set from another image classification problem - a strategy known as transfer learning. Deep learning approaches have rarely exploited the superior ability of humans for cognitive tasks during the machine learning loop. We advocate that the expert intervention through visual analytics can improve machine learning. In this work, we demonstrate this claim by proposing a data augmentation framework based on Encoder-Decoder Neural Networks (EDNNs) and visual analytics for the design of more effective CNN-based image classifiers. An EDNN is initially trained such that its encoder extracts a feature vector from each training image. These samples are projected from the encoder feature space on to a 2D coordinate space. The expert includes points to the projection space and the feature vectors of the new samples are obtained on the original feature space by interpolation. The decoder generates artificial images from the feature vectors of the new samples and the augmented training set is used to improve the CNN-based classifier. We evaluate methods for the proposed framework and demonstrate its advantages using data from a real problem as case study - the diagnosis of helminth eggs in humans. We also show that transfer learning and data augmentation by affine transformations can further improve the results.
CR Bargal SA, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433, DOI 10.1145/2993148.2997627
   Caruana R., 1994, ADV NEURAL INFORM SY, V7, P657
   Cashman  D., 2017, VADL2017 WORKSH VIS
   Ciresan  D.C., 2012, ABS12022745 CORR
   Ciresan  D.C., 2011, ABS11020183 CORR
   Cox D, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Goodfellow I. J., 2014, ADV NEURAL INFORM PR, V3, P2672
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He  K., 2015, DEEP RESIDUAL LEARNI
   Hoferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Huang G, 2016, ARXIV160806993
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767, DOI 10.1111/j.1467-8659.2009.01475.x
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kingma  D., 2013, AUTOENCODING VARIATI
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Peixinho  A.Z., 2017, THESIS
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Rauber P., 2016, EUROVIS 16, P73
   Rauber P., 2017, INFORM VISUALIZATION
   Rauber  P.E., 2017, IEEE T VIS COMP GRAP, V23
   Salakhutdinov R., 2009, ARTIF INTELL, V5, P1967, DOI DOI 10.1109/CVPRW.2009.5206577
   Simard P. Y., 2003, BEST PRACTICES CONVO
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suzuki CTN, 2013, I S BIOMED IMAGING, P460
   Suzuki CTN, 2013, IEEE T BIO-MED ENG, V60, P803, DOI 10.1109/TBME.2012.2187204
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taylor  L., 2017, ABS170806020 CORR
   Torrey  L., 2009, TRANSFER LEARNING
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan L., 2013, P 30 INT C MACH LEAR, P1058
   Wang D., 2016, ARXIV160605718
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Wong  S., 2016, ABS160908764 CORR
   Wright  G.B., 2003, RADIAL BASIS FUNCTIO
   Xia  Y., 2015, FINE TUNING IMAGE ST
   Zhang  X., 2015, ABS150303163 CORR
NR 46
TC 0
Z9 0
SN 1530-1834
BN 978-1-5386-9264-6
PY 2018
BP 384
EP 391
DI 10.1109/SIBGRAPI.2018.00056
UT WOS:000459886600050
ER

PT S
AU Jader, G
   Fontinele, J
   Ruiz, M
   Abdalla, K
   Pithon, M
   Oliveira, L
AF Jader, Gil
   Fontinele, Jefferson
   Ruiz, Marco
   Abdalla, Kalyf
   Pithon, Matheus
   Oliveira, Luciano
GP IEEE
TI Deep instance segmentation of teeth in panoramic X-ray images
SO PROCEEDINGS 2018 31ST SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND
   IMAGES (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 31st Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 29-NOV 01, 2018
CL Foz do Iguacu, BRAZIL
ID DENTAL PERIAPICAL RADIOGRAPHS; BONE-MINERAL DENSITY; ALGORITHM;
   FRAMEWORK; FILTER; SET
AB In dentistry, radiological examinations help specialists by showing structure of the tooth bones with the goal of screening embedded teeth, bone abnormalities, cysts, tumors, infections, fractures, problems in the temporomandibular regions, just to cite a few. Sometimes, relying solely in the specialist's opinion can bring differences in the diagnoses, which can ultimately hinder the treatment. Although tools for complete automatic diagnosis are no yet expected, image pattern recognition has evolved towards decision support, mainly starting with the detection of teeth and their components in X-ray images. Tooth detection has been object of research during at least the last two decades, mainly relying in threshold and region-based methods. Following a different direction, this paper proposes to explore a deep learning method for instance segmentation of the teeth. To the best of our knowledge, it is the first system that detects and segment each tooth in panoramic X-ray images. It is noteworthy that this image type is the most challenging one to isolate teeth, since it shows other parts of patient's body (e.g., chin, spine and jaws). We propose a segmentation system based on mask regionbased convolutional neural network to accomplish an instance segmentation. Performance was thoroughly assessed from a 1500 challenging image data set, with high variation and containing 10 categories of different types of buccal image. By training the proposed system with only 193 images of mouth containing 32 teeth in average, using transfer learning strategies, we achieved 98% of accuracy, 88% of Fl-score, 94% of precision, 84% of recall and 99% of specificity over 1224 unseen images, results very superior than other 10 unsupervised methods.
CR Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   Ajaz A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P717, DOI 10.1109/iccsp.2013.6577149
   Ali R. B., 2015, INT C INT SYST DES A, V1, P505
   Alsmadi M. K., 2015, AIN SHAMS ENG J
   Amer YY, 2015, PROCEDIA COMPUT SCI, V65, P718, DOI 10.1016/j.procs.2015.09.016
   Bruellmann D, 2016, COMPUT BIOL MED, V72, P212, DOI 10.1016/j.compbiomed.2016.03.019
   Cameriere R, 2015, J FORENSIC RADIOL IM, V3, P61, DOI 10.1016/j.jofri.2014.10.001
   Dai W., 2017, SCAN STRUCTURE CORRE
   Dighe S., 2012, INT J SCI APPL INF T, V1, P52
   Economopotilos T, 2008, DENTOMAXILLOFAC RAD, V37, P185, DOI 10.1259/dmfr/26553364
   Geraets WGM, 2007, BONE, V40, P1217, DOI 10.1016/j.bone.2007.01.009
   Grafova L, 2013, DENTOMAXILLOFAC RAD, V42, DOI 10.1259/dmfr.20120391
   Hasan M. M., 2016, WAC, V1, P1
   He K., 2017, CORR
   Huang CH, 2008, ORAL SURG ORAL MED O, V105, P649, DOI 10.1016/j.tripleo.2007.08.019
   Indraswari R, 2015, INT CONF INFORM COMM, P49, DOI 10.1109/ICTS.2015.7379870
   Jain AK, 2004, PATTERN RECOGN, V37, P1519, DOI 10.1016/j.patcog.2003.12.016
   Kaur J., 2016, INT J ADV RES COMPUT, V6, P158
   Keshtkar F., 2007, CAN C EL COMP ENG, P328, DOI DOI 10.1109/CCECE.2006.277656
   Kingma D. P, 2014, P 3 INT C LEARN REPR
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Li H, 2012, INT CONF SIGN PROCES, P877, DOI 10.1109/ICoSP.2012.6491720
   Li S, 2006, COMPUT MED IMAG GRAP, V30, P65, DOI 10.1016/j.compmedimag.2005.10.007
   Li S, 2007, PATTERN RECOGN, V40, P2861, DOI 10.1016/j.patcog.2007.01.012
   Lin PL, 2015, COMPUT METH PROG BIO, V121, P117, DOI 10.1016/j.cmpb.2015.05.004
   Lin PL, 2013, INT CONF SYST SCI EN, P407, DOI 10.1109/ICSSE.2013.6614700
   Lin PL, 2014, COMPUT METH PROG BIO, V113, P433, DOI 10.1016/j.cmpb.2013.10.015
   Lin PL, 2010, PATTERN RECOGN, V43, P1380, DOI 10.1016/j.patcog.2009.10.005
   Lin PL, 2012, PATTERN RECOGN, V45, P934, DOI 10.1016/j.patcog.2011.08.027
   Lin T., 2014, CORR
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lurie A, 2012, OR SURG OR MED OR PA, V113, P549, DOI 10.1016/j.oooo.2011.10.002
   Modi CK, 2011, CAN CON EL COMP EN, P504, DOI 10.1109/CCECE.2011.6030501
   Niroshika AA, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P396
   Nomir O, 2008, IEEE T INF FOREN SEC, V3, P223, DOI 10.1109/TIFS.2008.919343
   Nomir O, 2008, PATTERN RECOGN, V41, P130, DOI 10.1016/j.patcog.2007.05.015
   Phen-Lan Lin, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P1821, DOI 10.1109/ICMLC.2012.6359652
   Rad Abdolvahab Ehsani, 2013, TELKOMNIKA, V11, P3109, DOI DOI 10.11591/ITELKOMNIKA.V11I6.2655
   Razali M. R. M., 2015, INT C COMP ASS SYST, P62
   Razali MRM, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS, AND CONTROL TECHNOLOGY (I4CT), P353, DOI 10.1109/I4CT.2014.6914204
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O., 2015, U NET CONVOLUTIONAL, P1, DOI DOI 10.1007/978-3-319-24574-428
   Said EH, 2006, IEEE T INF FOREN SEC, V1, P178, DOI 10.1109/TIFS.2006.873606
   Senthilkumaran N., 2012, INT J ADV RES COMPUT, V1, P5236
   Senthilkumaran N., 2012, INT J COMPUTER SCI I, V3, P5236
   Silva G, 2018, EXPERT SYST APPL, V107, P15, DOI 10.1016/j.eswa.2018.04.001
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Subramanyam RB, 2014, INT J ENG RES APPL, V4, P173
   Tikhe SV, 2016, INT CONF ADV COMPU, P225, DOI 10.1109/IACC.2016.50
   Trivedi D. N., 2015, INT J ADV COMPUTER R, V4, P985
   Wang CW, 2016, MED IMAGE ANAL, V31, P63, DOI 10.1016/j.media.2016.02.004
NR 51
TC 0
Z9 0
SN 1530-1834
BN 978-1-5386-9264-6
PY 2018
BP 400
EP 407
DI 10.1109/SIBGRAPI.2018.00058
UT WOS:000459886600052
ER

PT S
AU Masi, I
   Wu, Y
   Hassner, T
   Natarajan, P
AF Masi, Iacopo
   Wu, Yue
   Hassner, Tal
   Natarajan, Prem
GP IEEE
TI Deep Face Recognition: a Survey
SO PROCEEDINGS 2018 31ST SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND
   IMAGES (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 31st Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 29-NOV 01, 2018
CL Foz do Iguacu, BRAZIL
AB Face recognition made tremendous leaps in the last five years with a myriad of systems proposing novel techniques substantially backed by deep convolutional neural networks (DCNN). Although face recognition performance sky-rocketed using deep-learning in classic datasets like LFW, leading to the belief that this technique reached human performance, it still remains an open problem in unconstrained environments as demonstrated by the newly released IJB datasets.
   This survey aims to summarize the main advances in deep face recognition and, more in general, in learning face representations for verification and identification. The survey provides a clear, structured presentation of the principal, state-of-the-art (SOTA) face recognition techniques appearing within the past five years in top computer vision venues.
   The survey is broken down into multiple parts that follow a standard face recognition pipeline: (a) how SOTA systems are trained and which public data sets have they used; (b) face preprocessing part (detection, alignment, etc.); (c) architecture and loss functions used for transfer learning (d) face recognition for verification and identification. The survey concludes with an overview of the SOTA results at a glance along with some open issues currently overlooked by the community.
CR Bansal A., 2017, IJCB
   Bansal A., 2017, ICCV WORKSH
   Bledsoe W., 1966, MAN MACHINE FACIAL R
   Bledsoe W. W., 1966, PANORAMIC RES INC PA, V15, P2
   Borghi G., 2017, CVPR
   Bulat A., 2017, ICCV
   Cao C. L. X. T. Kaidi, 2018, CVPR
   Cao Q., 2018, AFGR
   Chang F., 2017, ICCV WORKSH
   Chatfield K., 2014, BMVC
   Chen J. -C., 2016, WACV
   Chen J. -C., 2015, CVPR WORKSH
   Crispell D. E., 2016, AIPR
   Crosswhite N., 2017, AFGR
   de Bittencourt Zavan F. H., 2017, SIBGRAPI
   Ferrari C., 2015, 3DV
   Ferrari C., 2018, TIP
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Fukushima K., 1982, COMPETITION COOPERAT, P267, DOI DOI 10.1007/978-3-642-46466-9_18
   Goodfellow I., 2014, NIPS
   Guo Y., 2016, ECCV
   Hadsell R., 2006, CVPR
   Hassner T., 2016, CVPR WORKSH JUN
   Hassner T., 2015, CVPR
   He K., 2016, CVPR
   Huang G. B., 2007, 0749 UMASS
   Jaderberg M., 2015, NIPS
   Kemelmacher-Shlizerman I., 2016, CVPR
   Kim K., 2018, WACV
   Klare B. F., 2015, CVPR
   Klontz J., 2013, BTAS
   Krizhevsky  A., 2012, NIPS
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lin J., 2017, ACM ICMR
   Liu W., 2016, ICML
   Liu W., 2017, CVPR, V1
   Liu Y., 2018, CVPR
   Masi I., 2014, ICPR
   Masi I., 2017, AFGR
   Masi I., 2016, ECCV
   Masi I., 2018, TPAMI
   Masi I., 2016, CVPR
   Maze B., 2018, IJCB
   Mnih A., 2009, NIPS
   Nech A., 2017, CVPR
   Parkhi O.M., 2015, BMVC
   Peng X., 2017, ICCV
   Phillips P. J., 2011, HDB FACE RECOGNITION, P551
   Ranjan R., 2017, AFGR
   Ranjan R., 2017, ARXIV170309507
   Russakovsky Olga, 2015, INT J COMPUT VISION, V115, P3, DOI [DOI 10.1007/S11263-015-0816-Y, 10.1007/s11263-015-0816-y]
   Sankaranarayanan S., 2016, BTAS
   Sankaranarayanan S, 2016, ARXIV160203418
   Schroff F., 2015, CVPR
   Song H. Oh, 2016, CVPR
   Springenberg J. T., 2016, ICLR
   Sun Y., 2014, CVPR
   Sun Y., 2015, ARXIV150200873
   Taigman Y., 2014, CVPR
   Tran A. T., 2017, CVPR
   Tran L., 2017, CVPR
   Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166
   Wang F., 2018, ECCV
   Wen Y., 2016, ECCV
   Whitelam C., 2017, CVPR WORKSH JUL
   Wolf L., 2011, CVPR
   Wolf L., 2009, CVPR
   Wu C. -Y., 2017, ICCV
   Wu Y., 2018, TPAMI
   Wu Y., 2017, IEEE T CONTR SYST T, VPP, P1
   Yang J., 2017, CVPR
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yi D., 2014, LEARNING FACE REPRES, V1411, P7923
   Yucel M. K., 2018, ARXIV180507566
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhao J., 2018, TPAMI
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zheng Y., 2018, CVPR
   Zhou E., 2015, ARXIV150104690
   Zhu X., 2016, CVPR
NR 81
TC 0
Z9 0
SN 1530-1834
BN 978-1-5386-9264-6
PY 2018
BP 471
EP 478
DI 10.1109/SIBGRAPI.2018.00067
UT WOS:000459886600061
ER

PT S
AU Liu, LJ
   Lu, JW
   Zhou, J
AF Liu, Lijie
   Lu, Jiwen
   Zhou, Jie
BA Kosecka, J
BF Kosecka, J
BE Maciejewski, AA
   Okamura, A
   Bicchi, A
   Stachniss, C
   Song, DZ
   Lee, DH
   Chaumette, F
   Ding, H
   Li, JS
   Wen, J
   Roberts, J
   Masamune, K
   Chong, NY
   Amato, N
   Tsagwarakis, N
   Rocco, P
   Asfour, T
   Chung, WK
   Yasuyoshi, Y
   Sun, Y
   Maciekeski, T
   Althoefer, K
   AndradeCetto, J
   Chung, WK
   Demircan, E
   Dias, J
   Fraisse, P
   Gross, R
   Harada, H
   Hasegawa, Y
   Hayashibe, M
   Kiguchi, K
   Kim, K
   Kroeger, T
   Li, Y
   Ma, S
   Mochiyama, H
   Monje, CA
   Rekleitis, I
   Roberts, R
   Stulp, F
   Tsai, CHD
   Zollo, L
TI Adversarial Transfer Networks for Visual Tracking
SO 2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT 25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY OCT 01-05, 2018
CL Madrid, SPAIN
AB Visual tracking plays an important role in unmanned systems. In many cases, the system needs to keep track of targets it has never seen before, and the only training sample available is the specified object in the initial frame. In this paper, we propose a deep architecture called adversarial transfer networks (ATNet), which aims to make well use of offline video training data and solve the problem of lacking training samples in visual tracking. Different from most existing trackers which neglect significant differences between videos and gulp the training data all together, our method utilizes the special nature of tracking problem and concentrates on transferring domain-specific information across similar tracking tasks. We first propose an efficient way to select a training video that is most similar to online tracking task and regard it as source domain. With the labeled data in the selected source domain, we apply adversarial transfer learning to make the feature distribution of source-domain samples and target-domain samples as similar as possible. Therefore, the transferred sourcedomain samples can provide various possible appearance of tracked target for training and boost the tracking performance. Experimental results on three OTB tracking benchmarks show that our method outperforms the state-of-the-art trackers in both accuracy and robustness.
CR Bolme D. S., 2010, CVPR
   Bousmalis  K., 2017, CVPR
   Chatfield K., 2014, BMVC
   Danelljan  M., 2015, ICCVW
   Danelljan  M., 2017, CVPR
   Danelljan  M., 2016, ECCV
   Fu Y, 2008, IEEE T INF FOREN SEC, V3, P91, DOI 10.1109/TIFS.2007.916280
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I., 2014, NIPS
   Hu  J., 2015, CVPR
   Hu JL, 2016, IEEE T CIRC SYST VID, V26, P2056, DOI 10.1109/TCSVT.2015.2477936
   Kim T., 2017, ARXIV170305192
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Li  J., 2017, CVPR
   Ma  C., 2015, ICCV
   Ma  L., 2015, ICCV
   Nam  H., 2016, CVPR
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qi  Y., 2016, CVPR
   Ren  L., 2018, ECCV
   Song  Y., 2017, ICCV
   Tao  R., 2016, CVPR
   Tzeng  E., 2017, CVPR
   Tzeng E., 2015, ICCV
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang  N., 2013, NIPS
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wulfmeier  M., 2018, ICRA
   Yun  S., 2017, CVPR
NR 29
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-8094-0
PY 2018
BP 75
EP 81
UT WOS:000458872700006
ER

PT S
AU Iuzzolino, ML
   Walker, ME
   Szafir, D
AF Iuzzolino, Michael L.
   Walker, Michael E.
   Szafir, Daniel
BA Kosecka, J
BF Kosecka, J
BE Maciejewski, AA
   Okamura, A
   Bicchi, A
   Stachniss, C
   Song, DZ
   Lee, DH
   Chaumette, F
   Ding, H
   Li, JS
   Wen, J
   Roberts, J
   Masamune, K
   Chong, NY
   Amato, N
   Tsagwarakis, N
   Rocco, P
   Asfour, T
   Chung, WK
   Yasuyoshi, Y
   Sun, Y
   Maciekeski, T
   Althoefer, K
   AndradeCetto, J
   Chung, WK
   Demircan, E
   Dias, J
   Fraisse, P
   Gross, R
   Harada, H
   Hasegawa, Y
   Hayashibe, M
   Kiguchi, K
   Kim, K
   Kroeger, T
   Li, Y
   Ma, S
   Mochiyama, H
   Monje, CA
   Rekleitis, I
   Roberts, R
   Stulp, F
   Tsai, CHD
   Zollo, L
TI Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails
SO 2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT 25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY OCT 01-05, 2018
CL Madrid, SPAIN
ID AERIAL
AB Robots hold promise in many scenarios involving outdoor use, such as search-and-rescue, wildlife management, and collecting data to improve environment, climate, and weather forecasting. However, autonomous navigation of outdoor trails remains a challenging problem. Recent work has sought to address this issue using deep learning. Although this approach has achieved state-of-the-art results, the deep learning paradigm may be limited due to a reliance on large amounts of annotated training data. Collecting and curating training datasets may not be feasible or practical in many situations, especially as trail conditions may change due to seasonal weather variations, storms, and natural erosion. In this paper, we explore an approach to address this issue through virtual-to-real-world transfer learning using a variety of deep learning models trained to classify the direction of a trail in an image. Our approach utilizes synthetic data gathered from virtual environments for model training, bypassing the need to collect a large amount of real images of the outdoors. We validate our approach in three main ways. First, we demonstrate that our models achieve classification accuracies upwards of 95% on our synthetic data set. Next, we utilize our classification models in the control system of a simulated robot to demonstrate feasibility. Finally, we evaluate our models on real-world trail data and demonstrate the potential of virtual-to-real-world transfer learning.
CR Chung J., 2014, CORR
   Giusti A, 2016, IEEE ROBOT AUTOM LET, V1, P661, DOI 10.1109/LRA.2015.2509024
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hsieh MA, 2007, J FIELD ROBOT, V24, P991, DOI 10.1002/rob.20222
   Jozefowicz R, 2015, P 32 INT C MACH LEAR, P2342, DOI DOI 10.1109/CVPR.2015.72987
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Peschel JM, 2013, IEEE T HUM-MACH SYST, V43, P53, DOI 10.1109/TSMCC.2012.2220133
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santana P, 2013, J FIELD ROBOT, V30, P64, DOI 10.1002/rob.21423
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szafir D, 2017, INT J ROBOT RES, V36, P514, DOI 10.1177/0278364916688256
   Tai L, 2017, IEEE INT C INT ROBOT, P31, DOI 10.1109/IROS.2017.8202134
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 13
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-8094-0
PY 2018
BP 576
EP 582
UT WOS:000458872700064
ER

PT S
AU Shen, MC
   Habibi, G
   How, JP
AF Shen, Macheng
   Habibi, Golnaz
   How, Jonathan P.
BA Kosecka, J
BF Kosecka, J
BE Maciejewski, AA
   Okamura, A
   Bicchi, A
   Stachniss, C
   Song, DZ
   Lee, DH
   Chaumette, F
   Ding, H
   Li, JS
   Wen, J
   Roberts, J
   Masamune, K
   Chong, NY
   Amato, N
   Tsagwarakis, N
   Rocco, P
   Asfour, T
   Chung, WK
   Yasuyoshi, Y
   Sun, Y
   Maciekeski, T
   Althoefer, K
   AndradeCetto, J
   Chung, WK
   Demircan, E
   Dias, J
   Fraisse, P
   Gross, R
   Harada, H
   Hasegawa, Y
   Hayashibe, M
   Kiguchi, K
   Kim, K
   Kroeger, T
   Li, Y
   Ma, S
   Mochiyama, H
   Monje, CA
   Rekleitis, I
   Roberts, R
   Stulp, F
   Tsai, CHD
   Zollo, L
TI Transferable Pedestrian Motion Prediction Models at Intersections
SO 2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT 25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY OCT 01-05, 2018
CL Madrid, SPAIN
AB One desirable capability of autonomous cars is to accurately predict the pedestrian motion near intersections for safe and efficient trajectory planning. We are interested in developing transfer learning algorithms that can be trained on the pedestrian trajectories collected at one intersection and yet still provide accurate predictions of the trajectories at another, previously unseen intersection. We first discussed the feature selection for transferable pedestrian motion models in general. Following this discussion, we developed one transferable pedestrian motion prediction algorithm based on Inverse Reinforcement Learning (IRL) that infers pedestrian intentions and predicts future trajectories based on observed trajectory. We evaluated our algorithm at three intersections. We used the accuracy of augmented semi- nonnegative sparse coding (ASNSC), trained and tested at the same intersection as a baseline. The result shows that the proposed algorithm improves the baseline accuracy by a statistically significant percentage in both non- transfer task and transfer task.
CR Abbeel Pieter, 2011, ENCY MACHINE LEARNIN, P554
   Ballan L, 2016, LECT NOTES COMPUT SC, V9905, P697, DOI 10.1007/978-3-319-46448-0_42
   Bruce A., 2004, P INT C ROB AUT ICRA
   Chen YF, 2016, IEEE INT CONF ROBOT, P2527, DOI 10.1109/ICRA.2016.7487407
   Deisenroth MP, 2009, NEUROCOMPUTING, V72, P1508, DOI 10.1016/j.neucom.2008.12.019
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Fouhey D. F., 2014, P IEEE C COMP VIS PA, P2019
   Joseph J, 2011, AUTON ROBOT, V31, P383, DOI 10.1007/s10514-011-9248-x
   Karasev V, 2016, IEEE INT CONF ROBOT, P2543, DOI 10.1109/ICRA.2016.7487409
   Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15
   Makris D., 2002, BMVC, P1
   Ramachandran D., 2007, URBANA, V51, P61801
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   Vasquez D, 2009, IEEE T INTELL TRANSP, V10, P403, DOI 10.1109/TITS.2009.2020208
   Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147
NR 15
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-8094-0
PY 2018
BP 4547
EP 4553
UT WOS:000458872704028
ER

PT S
AU Mueller, C
   Venicx, J
   Hayes, B
AF Mueller, Carl
   Venicx, Jeff
   Hayes, Bradley
BA Kosecka, J
BF Kosecka, J
BE Maciejewski, AA
   Okamura, A
   Bicchi, A
   Stachniss, C
   Song, DZ
   Lee, DH
   Chaumette, F
   Ding, H
   Li, JS
   Wen, J
   Roberts, J
   Masamune, K
   Chong, NY
   Amato, N
   Tsagwarakis, N
   Rocco, P
   Asfour, T
   Chung, WK
   Yasuyoshi, Y
   Sun, Y
   Maciekeski, T
   Althoefer, K
   AndradeCetto, J
   Chung, WK
   Demircan, E
   Dias, J
   Fraisse, P
   Gross, R
   Harada, H
   Hasegawa, Y
   Hayashibe, M
   Kiguchi, K
   Kim, K
   Kroeger, T
   Li, Y
   Ma, S
   Mochiyama, H
   Monje, CA
   Rekleitis, I
   Roberts, R
   Stulp, F
   Tsai, CHD
   Zollo, L
TI Robust Robot Learning from Demonstration and Skill Repair Using
   Conceptual Constraints
SO 2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT 25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY OCT 01-05, 2018
CL Madrid, SPAIN
AB Learning from demonstration (LfD) has enabled robots to rapidly gain new skills and capabilities by lever-aging examples provided by novice human operators. While effective, this training mechanism presents the potential for sub-optimal demonstrations to negatively impact performance due to unintentional operator error. In this work we introduce Concept Constrained Learning from Demonstration (CC-LfD), a novel algorithm for robust skill learning and skill repair that incorporates annotations of conceptually-grounded constraints (in the form of planning predicates) during live demonstrations into the LfD process. Through our evaluation, we show that CC-LfD can be used to quickly repair skills with as little as a single annotated demonstration without the need to identify and remove low-quality demonstrations. We also provide evidence for potential applications to transfer learning, whereby constraints can be used to adapt demonstrations from a related task to achieve proficiency with few new demonstrations required.
CR Abbeel Pieter, 2004, P 21 INT C MACH LEAR, P1, DOI DOI 10.1145/1015330.1015430
   Akgun B, 2016, AUTON ROBOT, V40, P211, DOI 10.1007/s10514-015-9448-x
   Akgun B, 2012, INT J SOC ROBOT, V4, P343, DOI 10.1007/s12369-012-0160-0
   Akgun B, 2012, ACMIEEE INT CONF HUM, P391
   Alexandrova  S., 2014, ROBOTICS SCI SYSTEMS
   Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Bakker P., 1996, WORKSH LEARN ROB AN, P3
   Basu  C., 2018, 13 ACM IEEE INT C HU
   Billard A, 2008, SPRINGER HDB ROBOTIC, P1371, DOI DOI 10.1007/978-3-540-30301-5_60
   Cakmak M, 2012, ACMIEEE INT CONF HUM, P17
   Calinon S., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P255
   Chao C., 2011, IEEE INT C DEV LEARN, V2, P1
   Chernova Sonia, 2014, SYNTHESIS LECT ARTIF, V8, P1
   Chitta S, 2012, IEEE ROBOT AUTOM MAG, V19, P18, DOI 10.1109/MRA.2011.2181749
   Coates A., 2008, P 25 INT C MACH LEAR, P144, DOI DOI 10.1145/1390156.1390175
   Duda Richard O., 1973, PATTERN CLASSIFICATI, V2
   Ekvall S, 2008, INT J ADV ROBOT SYST, V5, P223, DOI 10.5772/5611
   Grollman Daniel H., 2011, 2011 IEEE International Conference on Robotics and Automation, P3804
   Hayes Bradley, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6586, DOI 10.1109/ICRA.2017.7989778
   Hayes  B., AUTONOMOUSLY CONSTRU
   Hayes B, 2014, IEEE INT C INT ROBOT, P4442, DOI 10.1109/IROS.2014.6943191
   Hayes G. M., 1994, ROBOT CONTROLLER USI
   Jain  A., 2013, P ADV NEUR INF PROC, P575
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Kurenkov A, 2015, IEEE INT C INT ROBOT, P3608, DOI 10.1109/IROS.2015.7353881
   Nehaniv CL, 2007, IMITATION AND SOCIAL LEARNING IN ROBOTS, HUMANS AND ANIMALS: BEHAVIOURAL, SOCIAL AND COMMUNICATIVE DIMENSIONS, P1, DOI 10.1017/CBO9780511489808
   Ng A. Y., 2000, P 17 INT C MACH LEAR, P663, DOI DOI 10.2460/AJVR.67.2.323
   Pignat E, 2017, ROBOT AUTON SYST, V93, P61, DOI 10.1016/j.robot.2017.03.017
   Quigley M, 2009, ICRA WORKSH OP SOURC, V3, P2
   Russell SJ, 2003, ARTIFICIAL INTELLIGE, V2
   Stenmark Maj, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P463, DOI 10.1145/2909824.3020227
   Vakanski A, 2012, IEEE T SYST MAN CY B, V42, P1039, DOI 10.1109/TSMCB.2012.2185694
   Vukovic N, 2015, ENG APPL ARTIF INTEL, V45, P388, DOI 10.1016/j.engappai.2015.07.002
NR 33
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-8094-0
PY 2018
BP 6029
EP 6036
UT WOS:000458872705078
ER

PT S
AU Yan, Z
   Sun, L
   Ducketi, T
   Bellotto, N
AF Yan, Zhi
   Sun, Li
   Ducketi, Tom
   Bellotto, Nicola
BA Kosecka, J
BF Kosecka, J
BE Maciejewski, AA
   Okamura, A
   Bicchi, A
   Stachniss, C
   Song, DZ
   Lee, DH
   Chaumette, F
   Ding, H
   Li, JS
   Wen, J
   Roberts, J
   Masamune, K
   Chong, NY
   Amato, N
   Tsagwarakis, N
   Rocco, P
   Asfour, T
   Chung, WK
   Yasuyoshi, Y
   Sun, Y
   Maciekeski, T
   Althoefer, K
   AndradeCetto, J
   Chung, WK
   Demircan, E
   Dias, J
   Fraisse, P
   Gross, R
   Harada, H
   Hasegawa, Y
   Hayashibe, M
   Kiguchi, K
   Kim, K
   Kroeger, T
   Li, Y
   Ma, S
   Mochiyama, H
   Monje, CA
   Rekleitis, I
   Roberts, R
   Stulp, F
   Tsai, CHD
   Zollo, L
TI Multisensor Online Transfer Learning for 3D LiDAR-based Human Detection
   with a Mobile Robot
SO 2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT 25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY OCT 01-05, 2018
CL Madrid, SPAIN
ID PEOPLE TRACKING; RGB
AB Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new "trajectory probability". Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.
CR Arras KO, 2007, IEEE INT CONF ROBOT, P3402, DOI 10.1109/ROBOT.2007.363998
   Bar-Shalom Y, 1995, MULTITARGET MULTISEN
   Bellotto N, 2010, AUTON ROBOT, V28, P425, DOI 10.1007/s10514-009-9167-2
   Bellotto N, 2009, IEEE T SYST MAN CY B, V39, P167, DOI 10.1109/TSMCB.2008.2004050
   Burgard W., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P476, DOI 10.1109/ROBOT.2000.844100
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dondrup C., 2015, ICRA WORKSH MACH LEA
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gonzalez A, 2015, IEEE INT VEH SYM, P356, DOI 10.1109/IVS.2015.7225711
   Held D, 2013, IEEE INT CONF ROBOT, P1138, DOI 10.1109/ICRA.2013.6630715
   Jafari OH, 2014, IEEE INT CONF ROBOT, P5636, DOI 10.1109/ICRA.2014.6907688
   Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855
   Kobilarov M, 2006, IEEE INT CONF ROBOT, P557, DOI 10.1109/ROBOT.2006.1641769
   Koide K, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4187, DOI 10.1109/IROS.2016.7759616
   Linder T, 2016, IEEE INT CONF ROBOT, P5512, DOI 10.1109/ICRA.2016.7487766
   Misu K., 2012, P IAS, P705
   MORAVEC HP, 1988, AI MAG, V9, P61
   Munaro M, 2014, AUTON ROBOT, V37, P227, DOI 10.1007/s10514-014-9385-0
   Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141
   Quigley Morgan, 2009, ICRA WORKSH OP SOURC
   Read Jesse, 2012, Advances in Intelligent Data Analysis XI. Proceedings 11th International Symposium, IDA 2012, P313, DOI 10.1007/978-3-642-34156-4_29
   Schulz D, 2003, INT J ROBOT RES, V22, P99, DOI 10.1177/0278364903022002002
   Spinello L, 2010, INT J ROBOT RES, V29, P1498, DOI 10.1177/0278364910377533
   Sun L., 2018, P ICRA BRISB AUSTR M
   Sun L., 2018, IEEE ROBOTICS AUTOMA
   Teichman A, 2012, INT J ROBOT RES, V31, P804, DOI 10.1177/0278364912442751
   Yan Z, 2017, IEEE INT C INT ROBOT, P864, DOI 10.1109/IROS.2017.8202247
   Yan Z, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/57313
   Zhu X., 2009, INTRO SEMISUPERVISED
NR 30
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-8094-0
PY 2018
BP 7635
EP 7640
UT WOS:000458872706136
ER

PT B
AU Thazhackal, SS
   Devi, VS
AF Thazhackal, Sharun S.
   Devi, V. Susheela
BE Sundaram, S
TI A Hybrid Deep Learning Model to Predict Business Closure from Reviews
   and User Attributes Using Sentiment Aligned Topic Model
SO 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
CT 8th IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 18-21, 2018
CL Bengaluru, INDIA
DE business closure prediction; sentiment aligned topic model; NLP; lexicon
   generation; apsect-wise ratings; yelp; review analysis; deep learning;
   hybrid neural network; CNN
AB Business closure is a very good indicator for success or failure of a business. This will help investors and banks as to whether to invest or lend to a particular business for future growth and benefits. Traditional machine learning techniques require extensive manual feature engineering and still do not perform satisfactorily due to significant class imbalance problem and little difference in the attributes for open and closed businesses. We have used historical data besides taking care of the class imbalance problem. Transfer learning also has been used to tackle the issue of having small categorical dalasets. A hybrid deep learning model has been proposed to predict whether a business would be shut down within a specific period of time. Sentiment Aligned Topic Model (SATM) is used to extract aspect-wise sentiment scores from user reviews. Our results show a marked improvement over traditional machine learning techniques. It also shows how the aspect-wise sentiment scores corresponding to each business, computed using SATM, help to give better results.
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blunsom P., 2014, P 52 ANN M ASS COMP
   Demiroz Gulsen, DAT MIN WORKSH ICDMW
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189
   Kingma D., 2015, 3 INT C LEARN REPR S
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Martineau J., 2009, ICWSM
   Mejia J., 2015, ACAD MANAGEMENT P
   Nair V., 2010, P 27 INT C MACH LEAR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Wang Hao, 2014, C EMP METH NAT LANG, P1192
   Zhao Kui, 2017, ARXIV170807946CSLG
NR 14
TC 0
Z9 0
BN 978-1-5386-9276-9
PY 2018
BP 397
EP 404
UT WOS:000459238800054
ER

PT B
AU Xie, YQ
   Chen, KX
   Murphey, YL
AF Xie, Yongquan
   Chen, Kexun
   Murphey, Yi Lu
BE Sundaram, S
TI Real-time and Robust Driver Yawning Detection with Deep Neural Networks
SO 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
CT 8th IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 18-21, 2018
CL Bengaluru, INDIA
AB Yawning is an important indicator of drivers' drowsiness or fatigue. Techniques for automatic detection of driver's yawning have been developed for use as a component of driver fatigue monitoring system. However, detecting driver's yawning event accurately in real-time is still a challenging task, in particular in applications such as driver fatigue detection, illumination conditions vary in a broad range, driver facial features vary in size, shape, texture and degrees of distortion. In this paper, we present a deep neural network model built using transfer learning and sequential learning from yawning video clips as well as augmented images for yawning detection. As a result, unlike many other methods that follow a sequence of processes such as face ROI detection, eye/nose/mouth positioning and mouth open/dose determination, the proposed yawning detection system detect yawning events directly from video images without requiring any facial part positions. The system is robust to variations in object scales, positions and subject view angles. The system has been evaluated on publicly available yawning data sets, YawDD and NTHU-DDD, as well as a data set containing challenging yawning videos. The experimental results show that the proposed yawning detection system has the capability of detecting yawning events in high precision even when face turns away from camera up to 70 degrees, while exhibiting capability of being scale- and spatial-invariant. In addition, the model demonstrates the capability of discriminating yawning events very well from the actions involving mouth opening-closing motions such as talking and laughing.
CR Abtahi S., 2014, P 5 ACM MULT SYST C, P24
   Abtahi S., 2011, 2011 IEEE INT INSTR, P1, DOI DOI 10.1109/IMTC.2011.5944101
   Ali SI, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P15, DOI 10.1109/ICISCON.2014.6965210
   Andreu-Cabedo Y, 2015, IEEE INT CON MULTI
   Dehkordi M. T., 2018, INT RES J ENG TECHNO, V5, P646
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Ioffe S., 2015, ARXIV150203167
   Jabbar Rateb, 2018, Procedia Computer Science, V130, P400, DOI 10.1016/j.procs.2018.04.060
   Ji YY, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051205
   Kang HB, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P616, DOI 10.1109/ICCVW.2013.85
   Kaplan S, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2462084
   Klauer S. G, 2006, IMPACT DRIVER INATTE
   Kumar N, 2014, IJCSNS, V5, P7821
   Lin M., 2013, ARXIV13124400
   Lyu J., 2018, ARXIV180102325
   Motorist S., SMART MOTORIST
   Neubeck A, 2006, INT C PATT RECOG, P850
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Reddy B, 2017, IEEE COMPUT SOC CONF, P438, DOI 10.1109/CVPRW.2017.59
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C., 2015, CVPR
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Yen IL, 2017, 2017 11TH IEEE SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE), P1, DOI 10.1109/SOSE.2017.26
   Yuanyuan Liu, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P515, DOI 10.1109/CIS.2009.70
   Zhang W, 2015, EVID-BASED COMPL ALT, V2015, P1
NR 27
TC 0
Z9 0
BN 978-1-5386-9276-9
PY 2018
BP 532
EP 538
UT WOS:000459238800073
ER

PT B
AU Carvalho, M
   Pratama, M
AF Carvalho, Marcus
   Pratama, Mahardhika
BE Sundaram, S
TI Improving shallow neural network by compressing deep neural network
SO 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
CT 8th IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 18-21, 2018
CL Bengaluru, INDIA
DE Dark Knowledge; Deep Learning; Model Compression; Neural Network;
   Transfer Learning
AB This paper focuses on a simple technique to extract the dark knowledge of a Deep Multi-Column Deep Learning Network, and its compression into a shallow neural network, causing not only the improvement of the train and test performance of the latter but a cheap way to approximate the former results but with fewer parameters. First, we built a Multi-Column Deep Learning Network, i.e., a Committee Machine, using simple techniques to improve its training accuracy. Finally, we transfer its knowledge to a shallow neural network, compressing its learned information and demonstrating that dark knowledge techniques still have a huge impact on Deep Multi-Layer Perceptron's studies. This paper validates the performance of the proposed model in the MNIST database, comparing it with popular neural nets used before, where we were able to achieve better scores.
CR Bengio, 2010, P 13 INT C ART INT S
   Caruana, 2006, MODEL COMPRESSION
   Ciresan, 2012, NEURAL NETWORKS
   Couprie, 2013, INDOOR SEMANTIC SEGM
   Dahl G. E., 2010, ADV NEURAL INFORM PR, V24, P469
   Deng, 2012, IEE T AUDIO SPEECH L
   Farabet, 2013, CAUSAL GRAPH BASED V
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315
   Hinton, 2012, IEEE SIGNAL PROCESSI
   Hinton Geoffrey, 2014, BAYLEARN 2, V2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Seide, 2011, INTERSPEECH
   Sermanet, 2014, INT C LEARN REPR ICL
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
NR 14
TC 0
Z9 0
BN 978-1-5386-9276-9
PY 2018
BP 1382
EP 1387
UT WOS:000459238800189
ER

PT B
AU Ravi, A
   Venugopal, H
   Paul, S
   Tizhoosh, HR
AF Ravi, Aravind
   Venugopal, Harshwin
   Paul, Sruthy
   Tizhoosh, Hamid R.
BE Sundaram, S
TI A Dataset and Preliminary Results for Umpire Pose Detection Using SVM
   Classification of Deep Features
SO 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
CT 8th IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 18-21, 2018
CL Bengaluru, INDIA
DE video summarization; transfer learning; cricket; deep convolutional
   networks; image classification; inceptionv3; vgg19
AB In recent years, there has been increased interest in video summarization and automatic sports highlights generation. In this work, we introduce a new dataset, called SNOW, for umpire pose detection in the game of cricket. The proposed dataset is evaluated as a preliminary aid for developing systems to automatically generate cricket highlights. In cricket, the umpire has the authority to make important decisions about events on the field. The umpire signals important events using unique hand signals and gestures. We identify four such events for classification namely SIX, NO BALL, OFT and WIDE based on detecting the pose of the umpire from the frames of a cricket video. Pre-trained convolutional neural networks such as Inception V3 and VGG19 networks arc selected as primary candidates for feature extraction. The results are obtained using a linear SVM classifier. The highest classification performance was achieved for the SVM trained on features extracted from the VGG19 network. The preliminary results suggest that the proposed system is an effective solution for the application of cricket highlights generation.
CR Chambers GS, 2004, LECT NOTES COMPUT SC, V3138, P859
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Hari R., 2014, IEEE INT C COMP INT, P1
   Harikrishna N., 2011, COMM NCC 2011 NAT C, P1
   Huang YP, 2009, EXPERT SYST APPL, V36, P9907, DOI 10.1016/j.eswa.2009.01.078
   Kieffer B., 2017, ARXIV171005726
   Kolekar MH, 2011, MULTIMED TOOLS APPL, V54, P27, DOI 10.1007/s11042-010-0544-9
   Kolekar MH, 2010, MULTIMED TOOLS APPL, V47, P545, DOI 10.1007/s11042-009-0337-1
   Kumar M. D., 2017, ARXIV171001249
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Naphade M. R., 2004, P 12 ANN ACM INT C M, P660
   Narasimhan H, 2010, GECCO-2010 COMPANION PUBLICATION: PROCEEDINGS OF THE 12TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P2051
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Razavian A. S., 2014, COMP VIS PATT REC WO
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shvachko K, 2010, IEEE S MASS STOR SYS
   Simonyan K., 2014, ARXIV14091556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang A., 2012, P SIGCHI C HUM FACT, P1569
   Tizhoosh HR, 2018, IEEE T BIO-MED ENG, V65, P2267, DOI 10.1109/TBME.2018.2791567
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Zaharia  M., 2010, HOTCLOUD, P95
   Zhou W., 2000, P ACM MULT 2000 WORK, P213
NR 27
TC 0
Z9 0
BN 978-1-5386-9276-9
PY 2018
BP 1396
EP 1402
UT WOS:000459238800191
ER

PT B
AU Zhou, ZJ
   Xu, H
AF Zhou, Zejian
   Xu, Hao
BE Sundaram, S
TI Switching Deep Reinforcement Learning based Intelligent Online Decision
   Making for Autonomous Systems under Uncertain Environment
SO 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
CT 8th IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 18-21, 2018
CL Bengaluru, INDIA
DE switching reinforcement learning; decision making; autonomous system;
   uncertain environment
AB In this paper, finite horizon intelligent decision making problem has been investigated for autonomous systems especially under uncertain environment. According to latest studies, the uncertainty of environment will seriously affect the effectiveness of decision making especially for autonomous systems. To handle this issues, transfer learning and deep reinforcement learning has been presented recently. However, those existing Learning algorithms commonly needs a large set of state space which cause the algorithm to be time consuming and not suitable for real-lime application. Therefore, in this paper, a library of polices trained using Deep Q-Learning under similar environments are built firstly. Then, a neural network is designed to estimate the environment. Using the learned environment, a novel of switching policy will be developed and integrated with the designed deep reinforcement learning which can efficiently stop learning according to the practical error tolerance. Meanwhile, through the novel policy evaluation method based on the environment estimator, the autonomous agent will select the best policy to follow in an online manner. Eventually, simulation results are provided to demonstrate the effectiveness of the designed algorithm.
CR Csaji BC, 2008, J MACH LEARN RES, V9, P1679
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Doya K, 2002, NEURAL COMPUT, V14, P1347, DOI 10.1162/089976602753712972
   Fernandez F, 2010, ROBOT AUTON SYST, V58, P866, DOI 10.1016/j.robot.2010.03.007
   Fernndez Fernando, 2006, P 5 INT JOINT C AUT
   Hadoux Emmanuel, 2014, INT C SCAL UNC MAN
   Hernandez-Leal Pablo, 2016, IDENTIFYING TRACKING
   Mnih V., 2013, ARXIV13125602
   Nagabandi A., 2017, ARXIV170802596
   Rosman B, 2016, MACH LEARN, V104, P99, DOI 10.1007/s10994-016-5547-y
   Shorten R, 2007, SIAM REV, V49, P545, DOI 10.1137/05063516X
   Silva Da, 2006, P 23 INT C MACH LEAR
   Sutton R. S., 1998, INTRO REINFORCEMENT, V135
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Szita Istvn, 2002, J MACHINE LEARNING R, V3, P145
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Zuazua E, 2011, J EUR MATH SOC, V13, P85, DOI 10.4171/JEMS/245
NR 17
TC 0
Z9 0
BN 978-1-5386-9276-9
PY 2018
BP 1453
EP 1460
UT WOS:000459238800199
ER

PT B
AU Prasad, M
   Rajora, S
   Gupta, D
   Daraghmi, YA
   Daraghmi, E
   Yadav, P
   Tiwari, P
   Saxena, A
AF Prasad, Mukesh
   Rajora, Shantanu
   Gupta, Deepak
   Daraghmi, Yousef-Awwad
   Daraghmi, Eman
   Yadav, Pranay
   Tiwari, Prayag
   Saxena, Amit
BE Sundaram, S
TI Fusion based En-FEC Transfer Learning Approach for Automobile Parts
   Recognition System
SO 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
CT 8th IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 18-21, 2018
CL Bengaluru, INDIA
DE Deep learning; convolution neural networks; transfer learning; image
   classification
ID FEATURES
AB The artificially supervised classification of real world entities have gained a phenomenal significance in recent year of computational advancements. An intelligent classification model focuses on rendering accurate outcomes vide the implicated paradigms with respect to the subjected data employed to train the classifier. This paper proposes a novel deep learning approach to classify the various parts of any operational engine such as crank shafts, rock-arms, distributer, air duct, assecorybelt etc. deployed in automobiles. The proposed architecture distinctively utilizes convolution neural networks for this typical classification problem and altogether constructs a robust transfer learning paradigm to render the correct class label against the validation and test images as the conclusive result of the classification. The proposed methodology poses in such a way that it can qualitatively classify and henceforth give the corresponding class label of the machinery/engine part under consideration. This computationally intelligent architecture requires the user to feed the image of the engine part to the model in order to achieve the requisite responses of classification. The main contribution of the proposed method is the development of a robust algorithm that can exhibit pronounced results without training the entire ConvNet architecture from scratch, thereby enabling the proposed paradigm to be deployable in application instances wherein limited labeled training data is available.
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315
   Huang Z., 2017, REMOTE SENSING, V9
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Razavian A. S., 2014, COMP VIS PATT REC WO
   Simonyan K., 2015, 3 INT C LEARN REPR
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 15
TC 0
Z9 0
BN 978-1-5386-9276-9
PY 2018
BP 2193
EP 2199
UT WOS:000459238800306
ER

PT B
AU Oliveira, FRD
   Farias, FC
AF da Silva Oliveira, Flavio Rosendo
   Farias, Felipe Costa
GP IEEE
TI Comparing transfer learning approaches applied to distracted driver
   detection
SO 2018 IEEE LATIN AMERICAN CONFERENCE ON COMPUTATIONAL INTELLIGENCE
   (LA-CCI)
CT 5th IEEE Latin American Conference on Computational Intelligence
   (LA-CCI)
CY NOV 06-09, 2018
CL Guadalajara, MEXICO
DE computer vision; deep learning; transfer learning; distracted driver
   detection
AB Studies show that the volume of traffic deaths per year is high and that a large part of these accidents are caused by distractions whose risk is aggravated by the use of cell phones while driving. This work presents results of a comparative study of three transfer learning approaches applied to classification of driver images in moments of concentration or distraction. For this study, four architectures of deep convolutional neural networks were evaluated: VGG19, Inception v3, Resnet152 and Densenet161. Results suggested that for the studied database, end-to-end transfer learning outperformed fine tuning only fully connected layers and also outperformed shallow classifiers trained with features extracted by the same deep convolutional networks.
CR Backes A., 2016, INTRO VISAO COMPUTAC
   Berg A, 2010, LARGE SCALE VISUAL R
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hssayeni M., 2017, ELECT IMAGING, P20
   Huang G, DENSELY CONNECTED CO
   Koesdwiady A., IMAGE ANAL RECOGNITI, P11
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Masood S., PATTERN RECOGNITION
   McEvoy SP, 2005, BRIT MED J, V331, P428, DOI 10.1136/bmj.38537.397512.55
   National Highway Traffic Safety Administration, 2006, IMP DRIV IN NEAR CRA
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Simonyan K., 2015, ICLR
   Szegedy C, RETHINKING INCEPTION
   World Health Organization, ROAD SAF BRAZ
NR 16
TC 0
Z9 0
BN 978-1-5386-4626-7
PY 2018
UT WOS:000459239300015
ER

PT B
AU Masita, KL
   Hasan, AN
   Paul, S
AF Masita, Katleho L.
   Hasan, Ali N.
   Paul, Satyakama
GP IEEE
TI Pedestrian Detection Using R-CNN Object Detector
SO 2018 IEEE LATIN AMERICAN CONFERENCE ON COMPUTATIONAL INTELLIGENCE
   (LA-CCI)
CT 5th IEEE Latin American Conference on Computational Intelligence
   (LA-CCI)
CY NOV 06-09, 2018
CL Guadalajara, MEXICO
DE Pedestrian detection; Deep learning; Convolutional neural networks;
   Region-based neural networks (RCNN)
ID HOUGH TRANSFORM
AB Pedestrian detection continues to hold a significant role in the concept, analysis and function of computer vision. Deep learning techniques in pedestrian detection have demonstrated powerful results in recent experiments and research. In this paper a powerful deep learning technique of R-CNN is evaluated for Pedestrian detection on two different pedestrian detection datasets. The experiment involves the use of a deep learning feature extraction model along with the R-CNN detector. The deep learning feature extraction used is the Alexnet. Transfer learning is performed on the feature extraction model to adjust the weights of the convolutional neural networks to favour classification on the selected datasets. The R-CNN detector is then trained on the deep learning feature extraction model for pedestrian detection. The results of the experiments as evidently demonstrated, indicate some important truths about the performance of R-CNN detector on varying datasets.
CR BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Cyganek B, 2008, INT J NEURAL SYST, V18, P339, DOI 10.1142/S0129065708001646
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Farayola A. M., 2018, INT J INNOVATIVE COM, V14
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I., 2013, DEEP LEARNING, P654
   Hasan A. N., 2014, INT JOINT C NEUR NET
   Hasan AN, 2016, INT J INNOV COMPUT I, V12, P1777
   Hazan T, 2005, IEEE I CONF COMP VIS, P50
   Hough P., 1959, P INT C HIGH EN ACC
   Hu D., 2015, COMPUTER SCI ENG TEC, P87
   Jahne B., 2005, DIGITAL IMAGE PROCES
   Kazemi V., 2013, P BMVC 2013
   Ke Y, 2004, PROC CVPR IEEE, P506
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li HL, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P796, DOI 10.1109/CISP-BMEI.2016.7852818
   Lopes N., 2015, STUDIES IN BIG DATA, V7
   McLaughlin RA, 1998, IEEE T PATTERN ANAL, V20, P396, DOI 10.1109/34.677267
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nam W., 2014, ADV NEURAL INFORM PR, P424
   Ouyang W., 2016, IEEE T PATTERN ANAL
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan  K., 2014, VERY DEEP CONVOLUTIO
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vapnik VN, 1998, STAT LEARNING THEORY
   Wang LM, 2007, LECT NOTES COMPUT SC, V4843, P189
   Wu CH, 2017, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2017.66
   Wu HY, 1999, IEEE T PATTERN ANAL, V21, P557, DOI 10.1109/34.771326
   Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 36
TC 0
Z9 0
BN 978-1-5386-4626-7
PY 2018
UT WOS:000459239300011
ER

PT B
AU Oldridge, E
AF Oldridge, Even
GP ACM
TI Adapting Session Based Recommendation for Features Through Transfer
   Learning
SO 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS)
CT 12th ACM Conference on Recommender Systems (RecSys)
CY OCT 02-07, 2018
CL Vancouver, CANADA
DE Recommender Systems; Deep Learning; Transfer Learning
AB This industry talk covers the deep learning architecture developed at Realtor.com to recommend real estate listings to our userbase. The recommendation of homes is a different problem than most other domains both in the sense that listings are unique and that there are additional geographic and time constraints that increase the sparsity of interactions and make recommendation of individual listings more challenging. In particular time on market in a hot area can be limited to weeks or even days, and listing cold-start is critical to providing up to date market information. Thankfully the structured feature data for listings is incredibly rich and provides a framework from which to map listings into a meaningful vector space. User first impressions are also incredibly important in this highly competitive field, and offline recommendation or models that don't adapt during the users session are less desirable.
   In order to solve this recommendation problem we have developed a model based off of session based recommendation [1]. The architecture utilizes state of the art techniques from Natural Language Processing, including the AWD-LSTM language model developed by Salesforce [2]. To solve for coldstart of listings a structured data based denoising autoencoder was adapted from the methodology described in the winning entry of the Puerto Segurno Safe Driver Kaggle Competition [3]. This model is not used in the common way of generating fixed feature vectors, but rather the entire head of the autoencoder model, from the feature inputs to the middle layer commonly used as the vector output, is first trained to encode listing features, and then becomes the input to the AWD-LSTM architecture. This style of transfer learning is common in Computer Vision, and has recently been utilized in NLP to achieve state of the art results for text classification [4]. By including the head we are able to further optimize the listing encoder network and embeddings to take user interactions into account. As in traditional session based recommendation users are represented as the sequence of listings that they view, however those listings are fed into the model as the sequence of features.
   The final system consists of several components. The first attempts to calculate and maintain the users' feature vector and model hidden weights in near realtime, providing a representation for the user within the system. This representation is used by several downstream components, most notably the search rerank and recommendation modules which calculate users' interest in listings both in the context of the output of more traditional elasticsearch queries via cosine similarity of user/listing vectors and through approximate nearest neighbor vector space searches for relevant listings which form the input set for a pointwise scoring model trained on time on listing as done by YouTube [5].
CR Covington, DEEP NEURAL NETWORKS
   Hidasi Karatzoglou, 2016, ICLR
   Merity Keskar, REGULARIZING OPTIMIZ
NR 3
TC 0
Z9 0
BN 978-1-4503-5901-6
PY 2018
BP 481
EP 481
DI 10.1145/3240323.3241728
UT WOS:000458675100075
ER

PT B
AU Sahebi, SS
   Zheng, Y
   Pan, WK
   Fernandez, I
AF Sahebi, Shaghayegh (Sherry)
   Zheng, Yong
   Pan, Weike
   Fernandez, Ignacio
GP ACM
TI The 2ndWorkshop on Intelligent Recommender Systems by Knowledge Transfer
   & Learning (RecSysKTL)
SO 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS)
CT 12th ACM Conference on Recommender Systems (RecSys)
CY OCT 02-07, 2018
CL Vancouver, CANADA
DE cross-domain; knowledge transfer; recommender system
AB Having data from multiple sources, cross-domain and context-aware recommender systems, with the help of transfer learning approaches, aim to integrate such data to improve recommendation quality and alleviate issues such as cold-start problem. With the advantages of these techniques, we host the second international workshop on intelligent recommender systems by knowledge transfer and learning (RecSysKTL) to provide such a forum for both academia and industry researchers as well as application developers from around the world to present their work and discuss exciting research ideas or outcomes. The workshop is held in conjunction with the ACM Conference on Recommender Systems 2018 on October 6th in Vancouver, Canada.
NR 0
TC 0
Z9 0
BN 978-1-4503-5901-6
PY 2018
BP 523
EP 524
DI 10.1145/3240323.3240339
UT WOS:000458675100100
ER

PT B
AU Kataoka, D
   Tajima, K
AF Kataoka, Daisuke
   Tajima, Keishi
GP IEEE
TI SNS Retrieval Based on User Profile Estimation Using Transfer Learning
   from Web Search
SO 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018)
CT IEEE/WIC/ACM International Conference on Web Intelligence (WI)
CY DEC 03-06, 2018
CL Santiago, CHILE
DE microblog; profile estimation; transfer learning
AB In this paper, we propose a method of retrieving posts on social networking services (SNSs) by specifying a pair of queries: a topic query and an entity query. A topic query specifies the topic of the posts to retrieve (e.g., "iPhone") and an entity query specifies the type of users who posted them (e.g., "students"). In the existing search systems for SNS posts, we can specify topics of posts by keywords, but we cannot specify types of users. Even if we include keywords specifying types of users in a query, such keywords are not usually included in tweets or user profile data. In our method, we estimate types of users by learning vocabulary whose appearance is correlated with specific types of users. We learn it from the datasets obtained through Web search. We retrieve Web documents through the search with a keyword specifying the type of users (e.g., "student"), and we also retrieve Web documents by using a keyword specifying its opposite (e.g., "adult"). We regard the documents retrieved by these queries as positive and negative examples of documents describing the target type, and we train a model for recognizing users of the given type. We recognize users of the target type by inputting their posts and their profile data into the model. We use Web documents instead of SNS posts for training the model because the Web has more documents describing types of people.
CR Albakour  M., 2013, P 10 C OP RES AR INF, P173
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2017, CLASSIFICATION REGRE
   Choi  J., 2012, P 21 ACM INT C INF K, P2491
   Efron M, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P787
   Halpin H, 2011, IJCAI, P2250
   Herzig D.M., 2012, P WWW NEW YORK, P141, DOI DOI 10.1145/2187836.2187856
   Jarvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Kataoka D, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P823, DOI 10.1145/3106426.3106527
   Lau C. H., 2011, P 20 TEXT RETRIEVAL
   Liang  F., 2012, P 12 ACM IEEE CS JOI, P267, DOI DOI 10.1145/2232817.2232867.3
   Lu JL, 2016, IEICE T INF SYST, VE99D, P2295, DOI 10.1587/transinf.2016EDP7015
   Luo  Z., 2012, P AAAI
   Metzler D., 2012, P 2012 C N AM CHAPT, P646
   Miyanishi T., 2013, P 22 ACM INT C INF K, P439, DOI DOI 10.1145/2505515.2505701
   Nagmoti Rinkesh, 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P153, DOI 10.1109/WI-IAT.2010.170
   Peddinti V. M. K., 2011, ANAL MICROTEXT, V11
   Pochampally  R., 2011, WORKSH ENR INF RETR, P1
   Rieman  D., 2017, P 8 INT JOINT C NAT, V1, P764
   Rocchio J. J., 1971, SMART RETRIEVAL SYST
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Whiting Stewart, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P522, DOI 10.1007/978-3-642-28997-2_55
   Whiting  S., 2011, P 34 INT ACM SIGIR C, P1245
NR 23
TC 0
Z9 0
BN 978-1-5386-7325-6
PY 2018
BP 278
EP 285
DI 10.1109/WI.2018.00-79
UT WOS:000458968200036
ER

PT B
AU Ali, K
   Wang, CY
   Chen, YS
AF Ali, Khurshed
   Wang, Chih-Yu
   Chen, Yi-Shin
GP IEEE
TI Boosting Reinforcement Learning in Competitive Influence Maximization
   with Transfer Learning
SO 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018)
CT IEEE/WIC/ACM International Conference on Web Intelligence (WI)
CY DEC 03-06, 2018
CL Santiago, CHILE
AB Companies aim to promote their products under competitions and try to gain more profit than other companies. This problem is formulated as a Competitive Influence Maximization (CIM). Recently, a reinforcement learning has been used to solve the CIM problem, that is, to find an optimal strategy against competitor in order to maximize the commutative reward under the competition from other agents. However, reinforcement learning agents require huge training time to find an optimal strategy whenever the settings of the agents or the networks change. To tackle this issue, we propose a transfer learning method in reinforcement learning to reduce the training time and utilize the knowledge gained on source network to target network. Our method relies on two ideas, the first one is the state representation of the source and target networks in order to efficiently utilize the knowledge gained on source network to target network. The second idea is to transfer the final Q-solution of source network while learning on the target network. We validate our transfer learning method in similar or different settings of source and target networks while competing against the competitor's known strategies. Experimental results show that our proposed transfer learning method achieves similar or better performance as a baseline model while significantly reducing training time in all settings.
CR Borodin A, 2010, LECT NOTES COMPUT SC, V6484, P539, DOI 10.1007/978-3-642-17572-5_48
   Budak C., 2011, P 20 INT C WORLD WID, DOI [10.1145/1963405.1963499, DOI 10.1145/1963405.1963499]
   Chang CW, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1592, DOI 10.1145/2808797.2809349
   Cheng WN, 2013, APPL LINGUIST, V34, P173, DOI 10.1093/applin/ams038
   Even-Dar E, 2003, J MACH LEARN RES, V5, P1
   Harathi S, 2007, LECT NOTES COMPUT SC, V4858, P306
   He X., 2012, SDM, P463, DOI [DOI 10.1137/1.9781611972825.40, DOI 10.1137/1.9781611972825.40.]
   Lazaric A., 2008, P 25 INT C MACH LEAR, P544
   Leskovec J., 2014, SNAP DATASETS STANFO
   Lin S.-C., 2015, P 21 ACM SIGKDD INT, P695, DOI DOI 10.1145/2783258.2783392
   Liu B, 2012, IEEE DATA MINING, P439, DOI 10.1109/ICDM.2012.158
   Ohsaka N., 2016, P EUR C MACH LEARN K, V9851, P132
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   Tanaka F, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P1108
   Taylor M, 2006, CONTEMP POLIT TH-SER, P1, DOI 10.2277/ 0521687047
   Taylor M. E., 1999, P NAT C ART INT, V20, P880
   Torrey L., 2009, HDB RES MACHINE LEAR, V1, P242, DOI DOI 10.1016/J.JBI.2011.04.009
   Wilson A., 2007, P 24 INT C MACH LEAR, P1015
NR 18
TC 0
Z9 0
BN 978-1-5386-7325-6
PY 2018
BP 395
EP 400
DI 10.1109/WI.2018.00-62
UT WOS:000458968200053
ER

PT B
AU Motshoane, K
   Tu, CL
   Owolawi, PA
AF Motshoane, Kefentse
   Tu, Chunling
   Owolawi, Pius Adewale
GP IEEE
TI Prohibition Signage Classification for the Visually Impaired Using
   AlexNet Transfer Learning Approach
SO 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AND INNOVATIVE COMPUTING
   APPLICATIONS (ICONIC)
CT International Conference on Intelligent & Innovative Computing
   Applications (ICONIC)
CY DEC 06-07, 2018
CL Plaine Magnien, MAURITIUS
DE CNN; AlexNet; Transfer Learning; Computer Vision; MSER; OCR
AB Prohibition signs are commonly used for safety purposes in order to prevent and protect individuals from dangerous situations. These signs are placed in or around areas whereby they are clearly visible to the public. However, the visually impaired cannot visualize such signs. To help them, this paper proposes a system that combines Convolutional Neural Network (CNN) model and Computer Vision (CV) algorithms to detect and recognize prohibition signs in real scenes. The system uses pre-trained AlexNet model, fine-tuned using Prohibition Signage Boards (PSB) dataset and combined with Maximally Stable Extremal Regions (MSER) and Optical Character Recognition (OCR) techniques for text extraction and classification, to enhance the system performance. The experiments indicate that high recognition accuracies are achieved from a variety of prohibition images and prohibition texts.
CR Acilo J. P. N., 2018, P 2018 IEEE 14 INT C
   Chen X, 2017, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON RELIABILITY SYSTEMS ENGINEERING (ICRSE 2017)
   Cordova-Cruzatty A., 2017, P 2017 IEEE 2 EC TEC
   Elmahdy M. S., 2017, P 2017 IEEE EMBS INT
   Gu S., 2017, P 2017 IEEE 10 INT W
   He K., 2015, P 2015 COMP VIS PATT
   Islam R., 2016, P 2016 5 INT C INF E
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Motshoane K, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P2802, DOI 10.1109/CompComm.2017.8323043
   Salahat E., 2017, P 2017 IEEE INT C IN
   Stolar M. N., 2017, P 2017 11 INT C SIGN
   Swathika R., 2016, P 2016 INT C INV COM
   Szegedy C., 2015, P 2015 COMP VIS PATT
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Zhu Z., 2017, 2017 INT C DIG IM CO
NR 15
TC 0
Z9 0
BN 978-1-5386-6477-3
PY 2018
BP 298
EP 302
UT WOS:000458689200089
ER

PT S
AU Nadeem, S
   Tahir, MA
   Naqvi, SSA
   Zaid, M
AF Nadeem, Shees
   Tahir, Muhammad Atif
   Naqvi, Syed Sadiq Ali
   Zaid, Muhammad
BE Nguyen, NT
   Pimenidis, E
   Khan, Z
   Trawinski, B
TI Ensemble of Texture and Deep Learning Features for Finding Abnormalities
   in the Gastro-Intestinal Tract
SO COMPUTATIONAL COLLECTIVE INTELLIGENCE, ICCCI 2018, PT II
SE Lecture Notes in Artificial Intelligence
CT 10th International Conference on Computational Collective Intelligence
   (ICCCI)
CY SEP 05-07, 2018
CL Bristol, ENGLAND
DE Gastro intestinal tract; Deep learning; Texture; Ensemble; Transfer
   learning
ID POLYP DETECTION; SYSTEM
AB An endoscopy is a strategy in which a specialist utilizes specific instruments to see and work on the inward vessels and organs of the body. This paper expects to predict the abnormalities and diseases in the Gastro-Intestinal Tract, utilizing multimedia data acquired from endoscopy. Deep Analysis of GI tract pictures can foresee diseases and abnormalities, in its early stages and accordingly spare human lives. In this paper, a novel ensemble method is presented, where texture and deep learning features are integrated to improve the prediction of the abnormalities in the GI tract e.g. Peptic ulcer disease. Multimedia content analysis (to extricate data from the visual information) and machine learning (for classification) have been explored. Deep learning has additionally been joined by means of Transfer learning. Medieval Benchmarking Initiative for Multimedia Evaluation provided the dataset, which includes 8000 pictures. The data is gathered from conventional colonoscopy process. Using logistic regression and ensemble of different extracted features, 83% accuracy and a F1 score of 0.821 is achieved on testing sample. The proposed approach is compared with several state-of-the-art methods and results have indicated significant performance gains when compared with other approaches.
CR Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bishop C.M., 2006, INFORM SCI STAT
   Cai D, 2011, VLDB J, V20, P21, DOI 10.1007/s00778-010-0189-3
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Ervik M., 2016, CANC TODAY
   Figueiredo Pedro N, 2011, Diagn Ther Endosc, V2011, P182435, DOI 10.1155/2011/182435
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hwang S., 2007, P ICIP
   Hwang S., 2011, P 7 INT C ADV VIS CO, P320
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B., 2009, ANN INT C IEEE ENG M
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Munzer B., 2013, P ICME
   Munzer B., 2013, P CBMS
   Naqvi S. A., 2017, P MEDIAEVAL WORKSH B
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Nawarathna RD, 2010, LECT NOTES COMPUT SC, V6165, P153, DOI 10.1007/978-3-642-13923-9_16
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park  S., 2015, POLYP DETECTION COLO
   Pogorelov K., 2017, P MEDIAEVAL 2017 WOR
   Pogorelov Konstantin, 2017, P MMSYS, P164, DOI DOI 10.1145/3083187.3083212
   Ribeiro E., 2016, COMPUT MATH METHOD M, V2016, P16
   Riegler M, 2017, MEDIAEVAL 2017
   Tahir MA, 2013, IEEE T MULTIMEDIA, V15, P1653, DOI 10.1109/TMM.2013.2264927
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
   Zhao S, 2011, I C WIREL COMM NETW
   Zhu R., 2015, 2015 8 INT C IM SIGN
NR 31
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-98446-9; 978-3-319-98445-2
PY 2018
VL 11056
BP 469
EP 478
DI 10.1007/978-3-319-98446-9_44
UT WOS:000458812900044
ER

PT B
AU Seker, A
AF Seker, Abdulkadir
GP IEEE
TI Evaluation of Fabric Defect Detection Based on Transfer Learning with
   Pre-trained AlexNet
SO 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA
   PROCESSING (IDAP)
CT International Conference on Artificial Intelligence and Data Processing
   (IDAP)
CY SEP 28-30, 2018
CL Inonu Univ, Malatya, TURKEY
HO Inonu Univ
DE deep learning; transfer learning; fabric defect; alexnet; CNN
ID NEURAL-NETWORKS
AB Deep learning methods are successful in many different domains such as image, natural language and signal processing. However, the number of samples affects success of deep learning algorithms significantly. Therefore, it is seen as a big challenge to obtain or produce lots of labeled data. A transfer learning method has been proposed to overcome this problem. Transfer learning aimed that using a pre-trained network instead of training it from scratch as the basis for new problem. In this paper, it is looked for a solution to fabric defect detection problem through transfer learning. The sale of defective fabrics damages both producers and customers. Accurate and rapid detection of fabric defects is a crucial problem for the textile industry. Since fabric has the features of unique own textures, it is a matter of curiosity how the transfer learning method will result in determining the fabric defect. In this study, using the AlexNet model trained with millions of images, the success rate of training from stratch to 75% was increased to 98% with transfer learning.
CR Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Karlekar VV, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P712, DOI 10.1109/ICCUBEA.2015.145
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Raj B., 2018, DATA AUGMENTATION US
   Seker A., 2017, SCI SCI J, V38
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2013, ADV NEURAL INFORM PR, V26, P2553
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
NR 13
TC 0
Z9 0
BN 978-1-5386-6878-8
PY 2018
UT WOS:000458717400165
ER

PT B
AU Sengur, A
   Akhtar, Z
   Akbulut, Y
   Ekici, S
   Budak, U
AF Sengur, Abdulkadir
   Akhtar, Zahid
   Akbulut, Yaman
   Ekici, Sami
   Budak, Umit
GP IEEE
TI Deep Feature Extraction for Face Liveness Detection
SO 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA
   PROCESSING (IDAP)
CT International Conference on Artificial Intelligence and Data Processing
   (IDAP)
CY SEP 28-30, 2018
CL Inonu Univ, Malatya, TURKEY
HO Inonu Univ
DE Face recognition; Face spoof detection; Deep learning; CNN; Feature
   extraction
ID CHALLENGES; IMAGE
AB Face recognition is now widely being used to verify the identity of the person in various applications ranging from border crossing to mobile authentication. However, most face recognition systems are vulnerable to spoofing or presentation attacks, where a photo, a video, or a 3D mask of a genuine user's face may be utilized to fool the biometric system. Although many face spoof detection techniques have been proposed, the issue is still unsolved. Recently deep learning based models have achieved impressive results in various challenging image and video classification tasks. Consequently, very few works have applied convolutional neural networks (CNNs) for face liveness detection. Nonetheless, it is still unclear how different CNN features and methods compare with each other for face spoof detection, since prior CNN based face liveness detection approaches employ different fine-tuning procedures and/or datasets for training. Thus, in this paper, an approach based on transfer learning using some well-known and well-adopted pre-trained CNNs architectures is presented. This study explores different deep features and compares them on a common ground for face liveness detection in videos. Experimental analysis on two publicly available databases, NUAA and CASIA-FASD, shows that the proposed method is able to attain satisfactory and comparable results to the state-of-the-art methods.
CR Agarwal A, 2017, IEEE COMPUT SOC CONF, P275, DOI 10.1109/CVPRW.2017.40
   Akbulut Y., 2017, INT ART INT DAT PROC, P1
   Akhtar Z, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.119
   Akhtar Z, 2015, IEEE SECUR PRIV, V13, P63, DOI 10.1109/MSP.2015.116
   Anjos A., 2011, BIOM IJCB 2011 INT J, P1, DOI DOI 10.1109/IJCB.2011.6117503
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Li LF, 2016, CRYSTALS, V6, DOI 10.3390/cryst6040045
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Zhang Z, 2012, IEEE INT C BIO BIO W
NR 18
TC 0
Z9 0
BN 978-1-5386-6878-8
PY 2018
UT WOS:000458717400082
ER

PT B
AU Wang, JD
   Zheng, VW
   Chen, YQ
   Huang, MY
AF Wang, Jindong
   Zheng, Vincent W.
   Chen, Yiqiang
   Huang, Meiyu
GP ACM
TI Deep Transfer Learning for Cross-domain Activity Recognition
SO PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON CROWD SCIENCE AND
   ENGINEERING (ICCSE 2018)
CT 3rd International Conference on Crowd Science and Engineering (ICCSE)
CY JUL 28-31, 2018
CL Nanyang Technol Univ, Singapore, SINGAPORE
HO Nanyang Technol Univ
DE Transfer Learning; Activity Recognition; Deep Learning; Domain
   Adaptation
ID KERNEL
AB Human activity recognition plays an important role in people's daily life. However, it is often expensive and time-consuming to acquire sufficient labeled activity data. To solve this problem, transfer learning leverages the labeled samples from the source domain to annotate the target domain which has few or none labels. Unfortunately, when there are several source domains available, it is difficult to select the right source domains for transfer. The right source domain means that it has the most similar properties with the target domain, thus their similarity is higher, which can facilitate transfer learning. Choosing the right source domain helps the algorithm perform well and prevents the negative transfer. In this paper, we propose an effective Unsupervised Source Selection algorithm for Activity Recognition (USSAR). USSAR is able to select the most similar K source domains from a list of available domains. After this, we propose an effective Transfer Neural Network to perform knowledge transfer for Activity Recognition (TNNAR). TNNAR could capture both the time and spatial relationship between activities while transferring knowledge. Experiments on three public activity recognition datasets demonstrate that: 1) The USSAR algorithm is effective in selecting the best source domains. 2) The TNNAR method can reach high accuracy when performing activity knowledge transfer.
CR Barshan B, 2014, COMPUT J, V57, P1649, DOI 10.1093/comjnl/bxt075
   Ben Tan, 2017, 31 AAAI C ART INT
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137, DOI DOI 10.1007/S10994-009-5152-4
   Bhatt Himanshu S, 2016, IJCAI 2016, P3691
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Chattopadhyay R, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382582
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen Yiqiang, 2016, ACM INT JOINT C ACM, P33
   Collier Edward, 2018, ARXIV180407846
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Fodor I. K., 2002, US DOE OFFICE SCI TE, P1, DOI DOI 10.2172/15002155
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Hamm J., 2008, P 25 INT C MACH LEAR, P376
   Hammerla N. Y., 2015, P 29 AAAI C ART INT, P1742
   Hu LS, 2016, 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD), P327, DOI [10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0066, 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.90]
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lasecki W. S., 2013, P 2013 C COMP SUPP C, P1203, DOI DOI 10.1145/2441776.2441912
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu YP, 2018, IEEE INT CONF COMM
   Long M., 2017, P 34 INT C MACH LEAR, P2208
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lu Z., 2014, P NAT C ART INT, P122
   Morales F. J. O., 2016, P 2016 ACM INT S WEA, P92
   Nguyen LT, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1053, DOI 10.1145/2750858.2804256
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Plotz T., 2011, IJCAI P INT JOINT C, V2, P1729, DOI DOI 10.5591/978-1-57735-516-8/LICA111-290
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Roy Nirmalya, 2016, P IEEE INT C PERV CO, P1
   Sung Flood, 2017, ARXIV171106025
   Tzeng E., 2014, ARXIV14123474
   Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150
   Wang Jindong, 2018, PATTERN RECOGNITION
   Wen Jiahui, 2016, 2016 IEEE INT C PERV, P1
   Xiang EW, 2011, IJCAI P INT JOINT C, V22, P2355
   Xu H, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P208, DOI 10.1145/2971648.2971668
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhao Ming, 2017, ICML
   Zhao Z., 2011, IJCAI, P2545
   Zheng V. W., 2011, IJCAI P INT JOINT C, V22, P2085
NR 48
TC 1
Z9 1
BN 978-1-4503-6587-1
PY 2018
DI 10.1145/3265689.3265705
UT WOS:000458141100016
ER

PT S
AU Baumann, U
   Huang, YY
   Glaser, C
   Herman, M
   Banzhaf, H
   Zollner, JM
AF Baumann, Ulrich
   Huang, Yuan-Yao
   Glaeser, Claudius
   Herman, Michael
   Banzhaf, Holger
   Zoellner, J. Marius
GP IEEE
TI Classifying Road Intersections using Transfer-Learning on a Deep Neural
   Network
SO 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)
SE IEEE International Conference on Intelligent Transportation Systems-ITSC
CT 21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC)
CY NOV 04-07, 2018
CL Maui, HI
AB With the steady rise of advanced driver assistance systems (ADAS), more and more aspects of the driving task are transferred from the human driver to the vehicle's control system. In order to handle many of these responsibilities, vehicles need to understand their environment and adjust their behavior according to it. An important aspect of the vehicle environment is the layout of the road segment right ahead of the vehicle, such as the presence and type of an intersection, as it defines the scenario, provides context information and constrains the future motion of traffic participants. The knowledge of upcoming intersections can help to improve various aspects in the context of driver assistance systems and automated driving, such as the prediction of traffic participants or the adjustment of a system with respect to the current scenario. The contribution of this paper is threefold: First, it introduces a model for intersection identification and classification ahead of a vehicle solely from on-board sensor data via deep learning. Second, it proposes a transfer-learning technique allowing to train with fewer samples and showing that intermediate features from path prediction are also beneficial for intersection classification tasks. Third, it allows to reduce necessary computational power since feature extraction is partially shared between the path prediction and the intersection classification model.
CR Barsi A., 2003, INT ARCH PHOTOGRAMME, V34, P113
   Baumann U., 2018, INT C ROB AUT ICRA
   Bittel S, 2017, IEEE SYS MAN CYBERN, P52, DOI 10.1109/SMC.2017.8122577
   Caltagirone L, 2017, IEEE INT C INTELL TR
   Chen Tongtong, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P754, DOI 10.1109/ICIG.2011.69
   Fathi A, 2010, LECT NOTES COMPUT SC, V6292, P56, DOI 10.1007/978-3-642-15300-6_5
   Glaser C, 2013, IEEE INT C INTELL TR, P1503, DOI 10.1109/ITSC.2013.6728443
   Glaser C, 2014, IEEE INT VEH SYM, P1270, DOI 10.1109/IVS.2014.6856388
   Hata A, 2013, COMM COM INF SC, V383, P112
   Ioffe S, 2015, INT C MACH LEARN
   Kingma D. P., 2014, 3 INT C LEARN REPR
   Kodagoda KRS, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P19, DOI 10.1109/IRDS.2002.1041355
   Nair V, 2010, P 27 INT C MACH LEAR
   Rasmussen C, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P422, DOI 10.1109/IVS.2003.1212948
   Rebai K, 2013, IEEE CONF OPEN SYST, P100, DOI 10.1109/ICOS.2013.6735056
   Seeger C., 2016, IEEE COMP SOC C COMP, P2722
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Teichmann M., 2016, CORR
   Wang L, 2017, IEEE INT VEH SYM, P1440, DOI 10.1109/IVS.2017.7995912
   Zhu QW, 2012, IEEE INT C INTELL TR, P1191, DOI 10.1109/ITSC.2012.6338795
   Zhu QW, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P456, DOI 10.1109/IVS.2012.6232219
NR 21
TC 0
Z9 0
SN 2153-0009
BN 978-1-7281-0323-5
PY 2018
BP 683
EP 690
UT WOS:000457881300102
ER

PT S
AU Krishnakumari, P
   Perotti, A
   Pinto, V
   Cats, O
   van Lint, H
AF Krishnakumari, Panchamy
   Perotti, Alan
   Pinto, Viviana
   Cats, Oded
   van Lint, Hans
GP IEEE
TI Understanding Network Traffic States using Transfer Learning
SO 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)
SE IEEE International Conference on Intelligent Transportation Systems-ITSC
CT 21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC)
CY NOV 04-07, 2018
CL Maui, HI
DE Network traffic; convolutional neural networks; deep learning; transfer
   learning
ID TRAVEL-TIME PREDICTION; FLOW PREDICTION
AB Large-scale network traffic analysis is crucial for many transport applications, ranging from estimation and prediction to control and planning. One of the key issues is how to integrate spatial and temporal analyses efficiently. Deep Learning is gaining momentum as a go-to approach for artificial vision, and transfer learning approaches allow to exploit pretrained models and apply them to new domains. In this paper, we encode traffic states as images and use a pretrained deep convolutional neural network as a feature extractor. Experimental results show how the extracted feature vectors cluster naturally into meaningful network traffic states and illustrate how these network states can be used for traffic state prediction.
CR Clark S, 2003, J TRANSP ENG, V129, P161, DOI 10.1061/(ASCE)0733-947X(2003)129:2(161)
   Everitt B., 2002, CAMBRIDGE DICT STAT, V106
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Geroliminis N, 2008, TRANSPORT RES B-METH, V42, P759, DOI 10.1016/j.trb.2008.02.002
   Geron Aurelien, 2017, HANDS ON MACHINE LEA
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Ji YX, 2012, TRANSPORT RES B-METH, V46, P1639, DOI 10.1016/j.trb.2012.08.005
   Koesdwiady A, 2016, IEEE T VEH TECHNOL, V65, P9508, DOI 10.1109/TVT.2016.2585575
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lopez C, 2017, TRANSPORT RES REC, P98, DOI 10.3141/2623-11
   Lopez C, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14237-8
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Ma XL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040818
   Oh S, 2015, TRANSPORT REV, V35, P4, DOI 10.1080/01441647.2014.992496
   Polson NG, 2017, TRANSPORT RES C-EMER, V79, P1, DOI 10.1016/j.trc.2017.02.024
   Rice J, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P227, DOI 10.1109/ITSC.2001.948660
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Saeedmanesh M, 2016, TRANSPORT RES B-METH, V91, P250, DOI 10.1016/j.trb.2016.05.008
   Struyf A., 1997, J STAT SOFTW, V1, P1, DOI DOI 10.18637/JSS.V001.I04
   Szegedy C., 2017, AAAI, V4, P12
   van Hinsbergen CPIJ, 2012, IEEE T INTELL TRANSP, V13, P385, DOI 10.1109/TITS.2011.2175728
   van Lint JWC, 2008, IEEE T INTELL TRANSP, V9, P38, DOI [10.1109/TITS.2008.915649, 10.1109/TITS.2007.915649]
   Van Lint J. W. C., 2012, ARTIF INTELL, V22, P22
   Vlahogianni EI, 2004, TRANSPORT REV, V24, P533, DOI 10.1080/0144164042000196000
   Vlahogianni EI, 2014, TRANSPORT RES C-EMER, V43, P3, DOI 10.1016/j.trc.2014.01.005
   Wang JQ, 2016, ENG APPL ARTIF INTEL, V52, P145, DOI 10.1016/j.engappai.2016.02.012
   Wang R, 2016, TRANSPORT RES C-EMER, V71, P521, DOI 10.1016/j.trc.2016.08.003
   Wang Y., 2006, IEEE T CONTROL SYSTE, V14
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu C.-H., 2003, P 2003 IEEE C INT TR
   Xu YY, 2016, J ADV TRANSPORT, V50, P489, DOI 10.1002/atr.1356
   Yang H., 2016, IEEE T NEURAL NETWOR
   YU HY, 2017, SENSORS BASEL, V17, DOI DOI 10.3390/S17071501
   Yuan YF, 2012, IEEE T INTELL TRANSP, V13, P59, DOI 10.1109/TITS.2011.2178837
   Zhang YL, 2013, COMPUT-AIDED CIV INF, V28, P594, DOI 10.1111/mice.12014
NR 35
TC 0
Z9 0
SN 2153-0009
BN 978-1-7281-0323-5
PY 2018
BP 1396
EP 1401
UT WOS:000457881301061
ER

PT S
AU Kreidieh, AR
   Wu, C
   Bayen, AM
AF Kreidieh, Abdul Rahman
   Wu, Cathy
   Bayen, Alexandre M.
GP IEEE
TI Dissipating stop-and-go waves in closed and open networks via deep
   reinforcement learning
SO 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)
SE IEEE International Conference on Intelligent Transportation Systems-ITSC
CT 21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC)
CY NOV 04-07, 2018
CL Maui, HI
ID CONVECTIVE INSTABILITY
AB This article demonstrates the ability for modelfree reinforcement learning (RL) techniques to generate traffic control strategies for connected and automated vehicles (CAVs) in various network geometries. This method is demonstrated to achieve near complete wave dissipation in a straight open road network with only 10% CAV penetration, while penetration rates as low as 2.5% are revealed to contribute greatly to reductions in the frequency and magnitude of formed waves. Moreover, a study of controllers generated in closed network scenarios exhibiting otherwise similar densities and perturbing behaviors confirms that closed network policies generalize to open network tasks, and presents the potential role of transfer learning in fine-tuning the parameters of these policies. Videos of the results are available at: https://sites.google.com/view/itsc-dissipating-waves.
CR Abdulhai B, 2003, J TRANSP ENG, V129, P278, DOI 10.1061/(ASCE)0733-947X(2003)129:3(278)
   Belletti F, 2018, IEEE T INTELL TRANSP, V19, P1198, DOI 10.1109/TITS.2017.2725912
   BELLMAN R, 1957, J MATH MECH, V6, P679
   Chung J., 2014, CORR
   Duan Y., 2016, INT C MACH LEARN, V48, P1329
   Haykin S., COMPREHENSIVE FDN
   HERMAN R, 1959, OPER RES, V7, P86, DOI 10.1287/opre.7.1.86
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Krajzewicz D., 2012, RECENT DEV APPL SUMO
   Levine S., 2015, ICML, P1889
   Li L, 2016, IEEE-CAA J AUTOMATIC, V3, P247, DOI 10.1109/JAS.2016.7508798
   Li ZB, 2017, IEEE T INTELL TRANSP, V18, P3204, DOI 10.1109/TITS.2017.2687620
   Mitarai N, 2000, J PHYS SOC JPN, V69, P3752, DOI 10.1143/JPSJ.69.3752
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Orosz G, 2006, P R SOC A, V462, P2643, DOI 10.1098/rspa.2006.1660
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schmidt-Dumont T., 2015, IEEE T INTELL TRANSP, V14, P1
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Stern R. E., 2017, ARXIV170501693
   Sugiyama Y, 2008, NEW J PHYS, V10, DOI 10.1088/1367-2630/10/3/033001
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Treiber M, 2000, PHYS REV E, V62, P1805, DOI 10.1103/PhysRevE.62.1805
   Treiber M., 2013, TRAFFIC FLOW DYNAMIC, DOI [10.1007/978-3-642-32460-4, DOI 10.1007/978-3-642-32460-4]
   Treiber M., 2017, TRANSPORTATION RES B
   Treiber M, 2011, TRANSPORT RES B-METH, V45, P1362, DOI 10.1016/j.trb.2011.05.011
   Ward J. A., 2011, P ROYAL SOC LOND MAT
   Wiering Marco, 2000, P 17 INT C MACH LEAR, P1151
   Wu C., 2017, CORR
   Wu C., 2017, C ROB LEARN, P398
NR 30
TC 0
Z9 0
SN 2153-0009
BN 978-1-7281-0323-5
PY 2018
BP 1475
EP 1480
UT WOS:000457881301073
ER

PT S
AU Yang, NM
   Kanji, T
   Fang, YC
   Fei, XX
   Kazunori, I
   Yuuki, I
AF Yang Naiming
   Kanji, Tanaka
   Fang Yichu
   Fei Xiaoxiao
   Kazunori, Inagami
   Yuuki, Ishikawa
GP IEEE
TI Long-Term Vehicle Localization Using Compressed Visual Experiences
SO 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)
SE IEEE International Conference on Intelligent Transportation Systems-ITSC
CT 21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC)
CY NOV 04-07, 2018
CL Maui, HI
AB Vision-based global localization without a prior location estimate is a fundamental task for safe and efficient vehicle navigation in GPS-denied environments. Cross-season localization, in which query and database images involve different seasons is one of the most challenging task scenarios, owing to appearance variations among seasons. Because of recent advances in deep convolutional neural networks (DCNs) and transfer learning techniques, the task can be solved accurately by training and fine-tuning a DCN-based visual place classifier. However, the direct implementation of this would require collecting and storing a large amount of visual experiences (i.e., training data) for every new season, which is impractical. The goal of our study is to suppress the space cost for long-term memory and to develop a constant cost framework for long-term global localization. Moreover, we formulate and consider the task of experience compression as a scheduling problem of how to choose the part of the previous season's experience that is to be replaced with the current season's experience, to achieve an optimal tradeoff between localization accuracy and training efficiency. Experimental results using the publicly available North Campus Long-Term autonomy dataset validate the efficacy of our proposed approach.
CR Anati R. C., 2016, SEMANTIC LOCALIZATIO
   Arroyo R., 2017, AUTON ROBOT, P1
   Arroyo R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4656, DOI 10.1109/IROS.2016.7759685
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Cao J, 2017, COMPUT ELECTR ENG, V63, P79, DOI 10.1016/j.compeleceng.2017.03.015
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Fei XX, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P109, DOI 10.23919/MVA.2017.7986802
   Gavves E, 2015, IEEE I CONF COMP VIS, P2731, DOI 10.1109/ICCV.2015.313
   Geiger A., 2011, INT VEH S 4
   Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832
   Kanji T, 2015, IEEE INT C INT ROBOT, P729, DOI 10.1109/IROS.2015.7353453
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kumar D, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P32, DOI 10.1109/CRV.2017.26
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Mancini M., 2018, IEEE ROBOTICS AUTOMA
   Massiceti Daniela, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5118, DOI 10.1109/ICRA.2017.7989598
   Morley D., 2017, P IEEE C COMP VIS PA
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467
   Shojaedini E., 2017, CORR
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Takahashi Y., 2017, IEEE INT C INT TRANS, P842
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 23
TC 0
Z9 0
SN 2153-0009
BN 978-1-7281-0323-5
PY 2018
BP 2203
EP 2208
UT WOS:000457881302032
ER

PT S
AU Nezafat, RV
   Salahshour, B
   Cetin, M
AF Nezafat, Reza Vatani
   Salahshour, Behrouz
   Cetin, Mecit
GP IEEE
TI Classification of truck body types using a deep transfer learning
   approach
SO 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)
SE IEEE International Conference on Intelligent Transportation Systems-ITSC
CT 21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC)
CY NOV 04-07, 2018
CL Maui, HI
DE Vehicle classification; Convolutional neural network; Resnet152; Support
   vector machines; Transfer learning
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Classification of vehicles is one of the most important tasks in intelligent transportation systems (ITS). While there are various types of sensors for measuring vehicle characteristics, this paper is focused on an image-based vehicle classification system. Most traditional approaches for image-based vehicle classification are computationally extensive and typically require a large amount of data for model training. This paper investigates whether it is possible to transfer the learning of a highly accurate pre-trained model for classifying truck images based on body type. Results show that using a pre-trained model to extract lowlevel features of images increases the accuracy of the model significantly, even with a relatively small size of training data. Furthermore, a convolutional neural network (CNN) is shown to outperform other types of models to classify trucks based on the extracted features.
CR Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chen ZZ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P214, DOI 10.1109/ICICISYS.2009.5357707
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Deo RC, 2018, RENEW ENERG, V116, P309, DOI 10.1016/j.renene.2017.09.078
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Girshick R, 2015, ARXIV150408083
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI [10.1016/j.conbuildmat.2017.09.110, 10.1016/j.conbuildmat2017.09.110]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez SV, 2016, TRANSPORT RES C-EMER, V68, P1, DOI 10.1016/j.trc.2016.03.003
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Kafai M, 2012, IEEE T IND INFORM, V8, P100, DOI 10.1109/TII.2011.2173203
   Kim HT, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P1342, DOI 10.1109/ICCAS.2013.6704164
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Mita Y., 1995, RANGE MEASUREMENT TY
   Ng LT, 2014, LECT NOTES ELECTR EN, V291, P221, DOI 10.1007/978-981-4585-42-2_26
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peiyu L., 2006, EMBEDDED FLEXIBLE AS
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI DOI 10.4249/SCHOLARPEDIA.1883
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richards J. A, 2013, REMOTE SENSING DIGIT, P247
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, ARXIV14091556
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Sohrabi S., 2017, 96 ANN M TRANSP RES
   Szegedy C, 2015, GOING DEEPER CONVOLU
   Wangerin Kristen A., 2014, 2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1, DOI [10.1109/URSIGASS.2014.6929321, 10.1109/NSSMIC.2014.7430811]
   Wei-Lin Ku, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457829
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou YR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P276, DOI 10.1109/ICDSP.2016.7868561
   Zhuo L, 2017, MACH VISION APPL, V28, P793, DOI 10.1007/s00138-017-0846-2
NR 33
TC 0
Z9 0
SN 2153-0009
BN 978-1-7281-0323-5
PY 2018
BP 3144
EP 3149
UT WOS:000457881303021
ER

PT S
AU Zhan, WJ
   Chen, JX
   Fan, L
   Ou, XQ
   Chen, L
AF Zhan, Wujing
   Chen, Jiaxing
   Fan, Lei
   Ou, Xinqi
   Chen, Long
GP IEEE
TI A New Feature Pyramid Network For Road Scene Segmentation
SO 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)
SE IEEE International Conference on Intelligent Transportation Systems-ITSC
CT 21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC)
CY NOV 04-07, 2018
CL Maui, HI
AB Road scene segmentation is of great significance in intelligent transportation system for different applications such as autonomous driving and semantic map building. Despite great progress in this field with the deep learning methods, there are still many difficulties such as robust segmentation of small objects and same type of objects with different sizes in different scenes. In this paper, we propose a new pyramid architecture for scene segmentation, which is a top-down architecture with lateral connections for multi-scale semantic feature maps building, and sufficiently incorporate the momentous global scenery prior. Besides, we also propose a novel training method, which combines the re-sampling, pixel-wise cost learning and transfer learning together, to deal with the imbalance problem. Experimental results on KITTI and Cityscapes dataset demonstrate effectiveness of the proposed method.
CR Chen L, 2017, IEEE T INTELL TRANSP, V18, P3093, DOI 10.1109/TITS.2017.2680538
   Cordts M., 2016, P IEEE C COMP VIS PA
   Driggs-Campbell K, 2015, IEEE INT C INTELL TR, P739, DOI 10.1109/ITSC.2015.125
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Li QQ, 2014, IEEE T VEH TECHNOL, V63, P540, DOI 10.1109/TVT.2013.2281199
   Lin T., 2017, P IEEE C COMP VIS PA, P4
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Menze M., 2015, C COMP VIS PATT REC
   Murali V., 2018, ARXIV180100858
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Paszke A., 2016, ARXIV COMPUTER VISIO
   ROS G, 2016, PROC CVPR IEEE, P3234, DOI DOI 10.1109/CVPR.2016.352
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Siam M., 2017, ARXIV170702432
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Zhang W., 2017, ARXIV171208745
   Zhao H., 2017, IEEE C COMP VIS PATT, P2881
NR 17
TC 0
Z9 0
SN 2153-0009
BN 978-1-7281-0323-5
PY 2018
BP 3487
EP 3492
UT WOS:000457881303073
ER

PT S
AU Ren, ZZ
   Lee, YJ
AF Ren, Zhongzheng
   Lee, Yong Jae
GP IEEE
TI Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic
   Imagery
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB In human learning, it is common to use multiple sources of information jointly. However, most existing feature learning approaches learn from only a single task. In this paper, we propose a novel multi-task deep network to learn generalizable high-level visual representations. Since multitask learning requires annotations for multiple properties of the same training instance, we look to synthetic images to train our network. To overcome the domain difference between real and synthetic data, we employ an unsupervised feature space domain adaptation method based on adversarial learning. Given an input synthetic RGB image, our network simultaneously predicts its surface normal, depth, and instance contour, while also minimizing the feature space domain differences between real and synthetic data. Through extensive experiments, we demonstrate that our network learns more transferable representations compared to single-task baselines. Our learned representation produces state-of-the-art transfer learning results on PASCAL VOC 2007 classification and 2012 detection.
CR Agrawal P., 2015, ICCV
   Arandjelovic R., 2017, ICCV
   Aubry  Mathieu, 2014, CVPR
   Bansal A., 2017, ARXIV170206506
   Bansal  Aayush, 2016, CVPR
   Bengio Y., 2013, PAMI
   Bojanowski P., 2017, ICML
   Bousmalis  K., 2017, CVPR
   Caruana  R., 1997, MACHINE LEARNING
   Chang A. X, 2015, ARXIV151203012
   Deng J., 2009, CVPR
   Doersch C., 2017, ICCV
   Doersch Carl, 2015, ICCV
   Donahue J., 2017, ICLR
   Eigen D., 2015, ICCV
   Eigen  D., 2014, NIPS
   Everingham M., 2010, IJCV
   Fei- Fei L., 2004, CVPR WORKSH
   Gaidon A., 2016, CVPR
   Ganin Y., 2015, ICML
   Ganin  Yaroslav, 2016, JMLR
   Girshick Ross, 2015, ICCV
   Gkioxari G., 2014, R CNNS POSE ESTIMATI
   Goodfellow I., 2014, NIPS
   Grauman K, 2016, CVPR
   Hinton G. E., 2006, SCIENCE
   Huang Q., 2015, SIGGRAPH
   Ioffe  S., 2015, ICML
   Isola P., 2017, CVPR
   Jayaraman Dinesh, 2015, ICCV
   Kim T., 2017, ICML
   Kokkinos I., 2017, CVPR
   Krahenbuhl P., 2016, ICLR
   Krizhevsky  A., 2012, NIPS
   Ladicky L., 2014, ECCV
   Larsson G., 2017, CVPR
   LeCun Y., 1998, P IEEE
   Lerer A., 2016, ICML
   Lin T., 2014, CORR
   Liu M.-Y., 2016, NIPS
   Long  J., 2015, CVPR
   Mayer N., 2016, CVPR
   McCormac J., 2017, ICCV
   Misra I., 2016, CVPR
   Misra Ishan, 2016, ECCV
   Mottaghi Roozbeh, 2016, CVPR
   Noroozi M., 2016, ECCV
   Noroozi M., 2017, ICCV
   Owens A., 2016, ECCV
   Pathak D., 2017, CVPR
   Pathak D., 2016, CVPR
   Peng X., 2015, ICCV
   Pinto L., 2016, ECCV
   Pinto  L., 2017, ICRA
   Richter S. R., 2016, ECCV
   Ros  G., 2016, CVPR
   Saenko K., 2010, ECCV
   Shafaei A., 2016, BMVC
   Shilane P., 2004, SHAPE MODELING INT
   Shrivastava Ashish, 2017, CVPR
   Silberman N., 2012, ECCV
   Song S., 2017, CVPR
   Su H., 2014, SIGGRAPH
   Tzeng  E., 2017, CVPR
   Tzeng E., 2015, ICCV
   Vincent P., 2010, JMLR
   Wang X., 2015, ICCV
   Wang X., 2017, ICCV
   Wu  Jiajun, 2015, NIPS, P2
   Xie  S., 2015, ICCV
   Yu F., 2015, ICLR
   Zhang R., 2017, CVPR
   Zhang R., 2016, ECCV
   Zhang  Y., 2016, UNREALSTEREO SYNTHET
   Zhang Y., 2017, CVPR
   Zhang Z., 2014, ECCV
   Zhou B., 2016, PLACES IMAGE DATABAS
   Zhu J.-Y., 2017, ICCV
   Zhu Y., 2017, ICRA
NR 79
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 762
EP 771
DI 10.1109/CVPR.2018.00086
UT WOS:000457843600079
ER

PT S
AU Uijlings, JRR
   Popov, S
   Ferrari, V
AF Uijlings, Jasper R. R.
   Popov, S.
   Ferrari, V.
GP IEEE
TI Revisiting knowledge transfer for training object class detectors
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB We propose to revisit knowledge transfer for training object detectors on target classes from weakly supervised training images, helped by a set of source classes with bounding-box annotations. We present a unified knowledge transfer framework based on training a single neural network multi-class object detector over all source classes, organized in a semantic hierarchy. This generates proposals with scores at multiple levels in the hierarchy, which we use to explore knowledge transfer over a broad range of generality, ranging from class-specific (bycicle to motorbike) to class-generic (objectness to any class). Experiments on the 200 object classes in the ILSVRC 2013 detection dataset show that our technique (1) leads to much better performance on the target classes (70.3% CorLoc, 36.9% mAP) than a weakly supervised baseline which uses manually engineered objectness [11] (50.5% CorLoc, 25.4% mAP). (2) delivers target object detectors reaching 80% of the mAP of their fully supervised counterparts. (3) outperforms the best reported transfer learning results on this dataset (+41% CorLoc and + 3% mAP over [18, 46], +16.2% mAP over [32]). Moreover, we also carry out several acrossdataset knowledge transfer experiments [27, 24, 35] and find that (4) our technique outperforms the weakly supervised baseline in all dataset pairs by 1.5 x -1.9x, establishing its general applicability.
CR Alexe B., 2010, CVPR
   Bilen H., 2016, CVPR
   Bilen H., 2015, CVPR
   Bilen H., 2014, BMVC
   Cesa-Bianchi N., 2006, ICML
   Cinbis R., 2016, IEEE T PAMI
   Deselaers T., 2010, ECCV
   Deselaers T., 2012, IJCV
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Dollar P., 2014, ECCV
   Everingham M., 2010, IJCV
   Girshick  R., 2014, CVPR
   Girshick Ross, 2015, ICCV
   Gokberk Cinbis R., 2014, CVPR
   Guillaumin M., 2012, CVPR
   He K., 2014, ECCV
   He K., 2016, CVPR
   Hoffman J., 2016, JMLR
   Huang J., 2017, CVPR
   Jia  Y., 2013, CAFFE OPEN SOURCE CO
   Kantorov V., 2010, ECCV
   Kim G., 2009, NIPS, P2
   Koller D., 1997, ICML
   Krasin I., 2017, OPEN IMAGES PUBLIC D
   Krizhevsky  A., 2012, NIPS
   Lin D., 1998, ICML
   Lin T.-Y., 2014, ECCV
   Liu  W., 2016, ECCV
   Nguyen M., 2009, ICCV
   Pandey M., 2011, ICCV
   Prest A., 2012, CVPR
   Redmon J, 2017, CVPR
   Ren  Shaoqing, 2015, NIPS
   Rochan M., 2015, CVPR
   Russakovsky O., 2012, ECCV
   Russakovsky Olga, 2015, IJCV
   Shapovalova N., 2012, ECCV
   Shi Z., 2012, BMVC
   Silla C., 2011, DATA MINING KNOWLEDG
   Siva P., 2011, ICCV
   Song  H., 2014, ICML
   Song H. O., 2014, NIPS
   Szegedy  C., 2016, CVPR
   Szegedy C., 2017, AAAI
   Tang K., 2014, CVPR
   Tang Y., 2016, CVPR
   Uijlings J., 2013, IJCV
   Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361
   Wang L., 2014, ECCV
   Zeng X., 2016, ECCV
NR 50
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 1101
EP 1110
DI 10.1109/CVPR.2018.00121
UT WOS:000457843601024
ER

PT S
AU Shen, T
   Lin, GS
   Shen, CH
   Reid, I
AF Shen, Tong
   Lin, Guosheng
   Shen, Chunhua
   Reid, Ian
GP IEEE
TI Bootstrapping the Performance of Webly Supervised Semantic Segmentation
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB Fully supervised methods for semantic segmentation require pixel-level class masks to train, the creation of which is expensive in terms of manual labour and time. In this work, we focus on weak supervision, developing a method for training a high-quality pixel-level classifier for semantic segmentation, using only image-level class labels as the provided ground-truth. Our method is formulated as a two-stage approach in which we first aim to create accurate pixel-level masks for the training images via a bootstrapping process, and then use these now-accurately segmented images as a proxy ground-truth in a more standard supervised setting. The key driver for our work is that in the target dataset we typically have reliable ground-truth image-level labels, while data crawled from the web may have unreliable labels, but can be filtered to comprise only easy images to segment, therefore having reliable boundaries. These two forms of information are complementary and we use this observation to build a novel bi-directional transfer learning framework. This framework transfers knowledge between two domains, target domain and web domain, bootstrapping the performance of weakly supervised semantic segmentation. Conducting experiments on the popular benchmark dataset PASCAL VOC 2012 based on both a VGG16 network and on ResNet50, we reach state-of-the-art performance with scores of 60.2% IoU and 63.9% IoU respectively(1).
CR Bearman A., 2016, ECCV
   Chen L.-C., 2015, INT C LEARN REPR, V1, P6
   Chen T., 2015, NIPS
   Chen X, 2013, APPL MECH MATER, V311, P3, DOI 10.4028/www.scientific.net/AMM.311.3
   Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168
   Dai J., 2015, ICCV
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Hariharan B., 2011, ICCV
   He K., 2016, CVPR
   Hong S., 2017, CVPR
   Jin B., 2017, CVPR
   Khoreva A., 2017, CVPR
   Kolesnikov A., 2016, ECCV
   Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19
   Krizsan A, 2012, GENDER POLIT, P1
   Lin D., 2016, CVPR
   Lin G., 2017, P IEEE C COMP VIS PA, V1, P3
   Lin G., 2016, CVPR
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noh H., 2015, ICCV, V1
   Oh S. Joon, 2017, CVPR
   Papandreou G., 2015, ICCV
   Pathak  Deepak, 2015, ICCV
   Pinheiro P. O., 2015, CVPR
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shen T., 2017, IJCAI
   Shen T., 2017, BMVC
   Simonyan K., 2015, ICLR
   Wei Y., 2017, TPAMI
   Wei Y., 2017, CVPR
   Xiao T., 2015, CVPR
   Zagoruyko S., 2016, BMVC
   Zhao Haiyu, 2017, CVPR
   Zhou B, 2016, CVPR
NR 34
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 1363
EP 1371
DI 10.1109/CVPR.2018.00148
UT WOS:000457843601051
ER

PT S
AU Pal, A
   Balasubramanian, VN
AF Pal, Arghya
   Balasubramanian, Vineeth N.
GP IEEE
TI Adversarial Data Programming: Using GANs to Relax the Bottleneck of
   Curated Labeled Data
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
ID REPRESENTATIONS; RECOGNITION
AB Paucity of large curated hand-labeled training data forms a major bottleneck in the deployment of machine learning models in computer vision and other fields. Recent work (Data Programming) has shown how distant supervision signals in the form of labeling functions can be used to obtain labels for given data in near-constant time. In this work, we present Adversarial Data Programming (ADP), which presents an adversarial methodology to generate data as well as a curated aggregated label, given a set of weak labeling functions. We validated our method on the MNIST, Fashion MNIST, CIFAR 10 and SVHN datasets, and it outperformed many state-of-the-art models. We conducted extensive experiments to study its usefulness, as well as showed how the proposed ADP framework can be used for transfer learning as well as multi-task learning, where data from two domains are generated simultaneously using the framework along with the label information. Our future work will involve understanding the theoretical implications of this new framework from a game-theoretic perspective, as well as explore the performance of the method on more complex datasets.
CR Alfonseca E., 2012, ACL, P54
   Arjovsky M., 2017, ARXIV170107875
   Barnes C, 2011, COMMUN ACM, V54, P103, DOI 10.1145/2018396.2018421
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Breuleux O., UNLEARNING BETTER MI
   Bunescu R., 2007, ACL
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen  X., 2016, ADV NEURAL INFORM PR, P2172
   Chen X., 2014, ADV NEURAL INFORM PR, V27, P1709
   Ciresan D., 2010, DEEP BIG SIMPLE NEUR
   Danihelka I, 2017, ARXIV170505263
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486
   DeVries T., 2017, ARXIV170205538
   Doersch C., 2016, ARXIV160605908
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Gan Z., 2017, ARXIV170906548
   Gao H, 2011, IEEE INTELL SYST, V26, P10, DOI 10.1109/MIS.2011.52
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Graham B., 2014, ARXIV14126071
   Hauberg S., 2016, ARTIF INTELL, P342
   Hu Z., 2017, ARXIV170300955
   Kim T., 2017, ARXIV170305192
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Kumar VV, 2010, SADHANA-ACAD P ENG S, V35, P419, DOI 10.1007/s12046-010-0031-z
   Laude E., 2017, ARXIV170505020
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Chongxuan, 2017, ARXIV170302291
   Li Y., 2015, P 32 INT C MACH LEAR, P1718
   Liu M., 2016, COUPLED GENERATIVE A
   Mandal S., 2011, INT C IM INF PROC IC, P1
   Miao Zhenjiang, 1994, ISSIPNN '94. 1994 International Symposium on Speech, Image Processing and Neural Networks Proceedings (Cat. No.94TH0638-7), P460, DOI 10.1109/SIPNN.1994.344871
   Mirza M., 2014, ARXIV14111784, DOI DOI 10.1029/2009WR008312
   Moudni H., 2013, INT J ADV COMPUTER S, P41
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, V2011, P5
   Odena A., 2016, ARXIV161009585
   Radford A., 2015, ARXIV151106434
   Radford A., 2015, ARXIV151106434
   Ratner A. J., 2017, ARXIV170901643
   Ratner Alexander, 2016, Adv Neural Inf Process Syst, V29, P3567
   Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10
   Rothacker L, 2012, INT CONF FRONT HAND, P149, DOI 10.1109/ICFHR.2012.185
   Schapire Robert E., 2012, BOOSTING FDN ALGORIT
   Sun C, 2017, ARXIV170702968
   Theis L., 2015, ARXIV151101844
   Varma P., 2017, ARXIV170902477
   Vondrick C., 2013, ICCV
   Xiao H., 2017, ARXIV170807747
   Yi Z., 2017, ARXIV170402510
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Zhang H. Q., 2016, THESIS
   Zhu J.-Y., 2017, ARXIV170310593
NR 52
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 1556
EP 1565
DI 10.1109/CVPR.2018.00168
UT WOS:000457843601071
ER

PT S
AU Cao, ZJ
   Long, MS
   Wang, JM
   Jordan, MI
AF Cao, Zhangjie
   Long, Mingsheng
   Wang, Jianmin
   Jordan, Michael I.
GP IEEE
TI Partial Transfer Learning with Selective Adversarial Networks
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB Adversarial learning has been successfully embedded into deep networks to learn transferable features, which reduce distribution discrepancy between the source and target domains. Existing domain adversarial networks assume fully shared label space across domains. In the presence of big data, there is strong motivation of transferring both classification and representation models from existing large-scale domains to unknown small-scale domains. This paper introduces partial transfer learning, which relaxes the shared label space assumption to that the target label space is only a subspace of the source label space. Previous methods typically match the whole source domain to the target domain, which are prone to negative transfer for the partial transfer problem. We present Selective Adversarial Network (SAN), which simultaneously circumvents negative transfer by selecting out the outlier source classes and promotes positive transfer by maximally matching the data distributions in the shared label space. Experiments demonstrate that our models exceed state-of-the-art results for partial transfer learning tasks on several benchmark datasets.
CR Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Busto P. P., 2017, P IEEE INT C COMP VI, V1, P3
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Donahue J., 2014, ICML
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Ganin Y, 2016, J MACH LEARN RES, V17
   Glorot X., 2011, ICML
   Gong B., 2012, CVPR
   Grandvalet Y., 2004, NIPS, P529
   Gretton A., 2012, NIPS
   Griffin G., 2007, TECHNICAL REPORT
   He K., 2016, IEEE C COMP VIS PATT
   Hoffman J., 2014, NIPS
   Krizhevsky  A., 2012, NIPS
   Long M., 2013, ICCV
   Long M., 2016, ADV NEURAL INFORM PR, P136
   Long M., 2015, ICML
   Mansour Y., 2009, COLT
   Ngiam  Jiquan, 2011, ICML
   Oquab M., 2013, CVPR
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Russakovsky O., 2014, IMAGENET LARGE SCALE
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saenko K., 2010, ECCV
   Simonyan K., 2015, ICLR
   Sun B., 2016, AAAI
   Tzeng E., 2014, DEEP DOMAIN CONFUSIO
   Tzeng  E., 2017, CVPR
   Tzeng E., 2015, ICCV
   Wang X., 2014, NIPS
   Yosinski J., 2014, NIPS
   Zhang K., 2013, ICML
NR 34
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 2724
EP 2732
DI 10.1109/CVPR.2018.00288
UT WOS:000457843602088
ER

PT S
AU Kozerawski, J
   Turk, M
AF Kozerawski, Jedrzej
   Turk, Matthew
GP IEEE
TI CLEAR: Cumulative LEARning for One-Shot One-Class Image Recognition
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB This work addresses the novel problem of one-shot one class classification. The goal is to estimate a classification decision boundary for a novel class based on a single image example. Our method exploits transfer learning to model the transformation from a representation of the input, extracted by a Convolutional Neural Network, to a classification decision boundary. We use a deep neural network to learn this transformation from a large labelled dataset of images and their associated class decision boundaries generated from ImageNet, and then apply the learned decision boundary to classify subsequent query images. We tested our approach on several benchmark datasets and significantly outperformed the baseline methods.
CR Al- Sahaf H., 2013, LECT NOTES COMPUTER, P110
   Athiwaratkun B, 2015, ARXIV150702313
   Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Burgess J., 2017, ARXIV170705562
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Fu Y., 2017, ARXIV171004837
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guyon I, 2014, MACH VISION APPL, V25, P1929, DOI 10.1007/s00138-014-0596-3
   Hussein N., 2017, ARXIV170502148
   Jia Y., 2014, ARXIV14085093
   Jiang B, 2017, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2017.66
   Karessli N., 2016, ARXIV161109309
   Khan SS, 2014, KNOWL ENG REV, V29, P345, DOI 10.1017/S026988891300043X
   Koch G., SIAMESE NEURAL NETWO
   Kodirov E., 2017, ARXIV170408345
   Krishna R., 2016, ARXIV160207332
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lake  Brenden, 2011, P COGN SCI SOC, V33
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li Y., 2017, ARXIV170305002
   Lin  T.-Y., 2014, EUR C COMP VIS, P740, DOI DOI 10.1007/978-3-319-10602-1_48
   Long Y., 2017, ARXIV170501782
   Manevitz L. M., 2000, SIGIR Forum, V34, P304
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Romera-Paredes B., 2015, P 32 INT C MACH LEAR, P2152
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scholkopf B, 2000, ADV NEUR IN, V12, P582
   Socher R., 2013, ADV NEURAL INFORM PR, P935
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tax D. M. J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P251
   Tax D. M. J., 2001, ONE CLASS CLASSIFICA
   Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2
   Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583
   Thrun S., 2012, LEARNING LEARN
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630
   Wah C., 2011, CNSTR2011001 CALTECH
   Wang YX, 2016, LECT NOTES COMPUT SC, V9910, P616, DOI 10.1007/978-3-319-46466-4_37
   Wu D., 2012, IEEE COMP SOC C COMP, P7, DOI DOI 10.1109/CVPRW.2012.6239179
NR 40
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 3446
EP 3455
DI 10.1109/CVPR.2018.00363
UT WOS:000457843603061
ER

PT S
AU Zamir, AR
   Sax, A
   Shen, W
   Guibas, L
   Malik, J
   Savarese, S
AF Zamir, Amir R.
   Sax, Alexander
   Shen, William
   Guibas, Leonidas
   Malik, Jitendra
   Savarese, Silvio
GP IEEE
TI Taskonomy: Disentangling Task Transfer Learning
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
ID NEURAL-NETWORKS
AB Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity.
   We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. We provide a set of tools for computing and probing this taxonomical structure including a solver users can employ to find supervision policies for their use cases.
CR Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13
   Andrychowicz M., 2016, ADV NEURAL INFORM PR, P3981
   Armeni I., 2017, ARXIV170201105
   Arora S., 2014, P 31 INT C MACH LEAR, P584
   Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berkhin P., 2006, GROUP MULTIDIMENS DA, V25, P71
   Bienenstock E, 1997, ADV NEUR IN, V9, P838
   Bilen H., 2016, ADV NEURAL INFORM PR, P235
   Bingel J., 2017, ARXIV170208303
   Boiman O., 2007, ADV NEURAL INFORM PR, P177
   Chang A., 2017, ARXIV170906158
   Chen Z., 2016, LIFELONG MACHINE LEA
   CPLEX I. I., 2009, INT BUSINESS MACHINE, V46, P157
   Doersch C., 2017, ARXIV170807860
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Donahue Jeff, 2016, ARXIV160509782
   Duan Y., 2016, ARXIV161102779
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Faktor A, 2012, LECT NOTES COMPUT SC, V7578, P474, DOI 10.1007/978-3-642-33786-4_35
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Finn C., 2016, ABS161200429 CORR
   Finn C., 2017, ABS170904905 CORR
   Finn  C., 2017, ARXIV170303400
   Finn C., 2016, ABS160300448 CORR
   Finn C, 2016, IEEE INT CONF ROBOT, P512, DOI 10.1109/ICRA.2016.7487173
   Fodor Imola K, 2002, TECHNICAL REPORT
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Ge R., 2013, THESIS
   Geman S, 2002, Q APPL MATH, V60, P707, DOI 10.1090/qam/1939008
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gopnik A, 2004, PSYCHOL REV, V111, P3, DOI 10.1037/0033-295X.111.1.3
   Gopnik A., 1999, SCI CRIB MINDS BRAIN
   Graves A., 2014, ARXIV14105401
   Henry K., 2008, THESIS
   Hinton  G., 2015, ARXIV150302531
   Hoffman J, 2014, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2014.116
   Hoshen Y., 2015, ABS150602264 CORR
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   I. Gurobi Optimization, 2016, GUROBI OPTIMIZER REF
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Kingma D.P., 2013, ARXIV13126114
   Kokkinos I., 2016, ARXIV160902132
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li Y., 2016, ARXIV161107709
   Lin  T.-Y., 2014, EUR C COMP VIS, P740, DOI DOI 10.1007/978-3-319-10602-1_48
   Liu F., 2015, ABS150308263 CORR
   Luo Z., LABEL EFFICIENT LEAR
   Malik J, 2016, PATTERN RECOGN LETT, V72, P4, DOI 10.1016/j.patrec.2016.01.019
   Masuda N, 2017, PHYS REP, V716, P1, DOI 10.1016/j.physrep.2017.07.007
   Mccloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P104, DOI DOI 10.1016/S0079-7421(08)60536-8
   Mihalkova L., 2007, P NAT C ART INT, P608
   Mikolov  Tomas, 2013, ABS13094168 CORR
   Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433
   Niculescu-Mizil A., 2007, J MACH LEARN RES WOR, P339
   Noroozi M., 2017, ARXIV170806734
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Norouzi  M., 2013, ARXIV13125650
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pentina Anastasia, 2017, STAT, V1050, P1
   Piaget J., 1952, ORIGINS INTELLIGENCE, V8
   Pratt L. Y., 1993, ADV NEURAL INFORM PR, P204
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Richter S. R., 2017, INT C COMP VIS ICCV
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SAATY RW, 1987, MATH MODELLING, V9, P161, DOI 10.1016/0270-0255(87)90473-8
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Salakhutdinov R., 2012, P ICML WORKSH UNS TR, P195
   Schulman J., 2015, ABS150205477 CORR
   Silver D. L., 2013, AAAI SPRING SERIES
   Silver DL, 2008, MACH LEARN, V73, P215, DOI 10.1007/s10994-008-5087-1
   Socher R., 2013, ADV NEURAL INFORM PR, P935
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2013, ABS13126199 CORR
   Tenenbaum J. B., 2001, BEHAV BRAIN SCI, V24
   Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Tervo DGR, 2016, CURR OPIN NEUROBIOL, V37, P99, DOI 10.1016/j.conb.2016.01.014
   Tessler C., 2017, AAAI, P1553
   Thrun S., 2012, LEARNING LEARN
   Turing AM, 1950, MIND, V49, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Wang X., 2017, ARXIV170802901
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Winograd T., 1991, THINKING MACHINES CA, V200
   Yang J., 2007, 7 IEEE INT C DAT MIN, P69
   Zamir A. R., 2018, 2018 IEEE C COMP VIS
   Zamir AR, 2016, LECT NOTES COMPUT SC, V9907, P535, DOI 10.1007/978-3-319-46487-9_33
   Zhang  C., 2016, ABS161103530 CORR
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 100
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 3712
EP 3722
DI 10.1109/CVPR.2018.00391
UT WOS:000457843603089
ER

PT S
AU Cui, Y
   Song, Y
   Sun, C
   Howard, A
   Belongie, S
AF Cui, Yin
   Song, Yang
   Sun, Chen
   Howard, Andrew
   Belongie, Serge
GP IEEE
TI Large Scale Fine-Grained Categorization and Domain-Specific Transfer
   Learning
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB Transferring the knowledge learned from large scale datasets (e.g., ImageNet) via fine-tuning offers an effective solution for domain-specific fine-grained visual categorization (FGVC) tasks (e.g., recognizing bird species or car make & model). In such scenarios, data annotation often calls for specialized domain knowledge and thus is difficult to scale. In this work, we first tackle a problem in large scale FGVC. Our method won first place in iNaturalist 2017 large scale species classification challenge. Central to the success of our approach is a training scheme that uses higher image resolution and deals with the long-tailed distribution of training data. Next, we study transfer learning via fine-tuning from large scale datasets to small scale, domain specific FGVC datasets. We propose a measure to estimate domain similarity via Earth Mover's Distance and demonstrate that transfer learning benefits from pre-training on a source domain that is similar to the target domain by this measure. Our proposed transfer learning outperforms ImageNet pre-training and obtains state-of-the-art results on multiple commonly used FGVC datasets.
CR Abadi M, 2016, OSDI
   Azizpour H., 2016, PAMI
   Bao J., 2017, ICCV
   Bossard L., 2014, ECCV
   Branson S., 2014, BMVC
   Branson S., 2010, ECCV
   Cai S., 2017, ICCV
   Cui Y., 2016, CVPR
   Cui Y., 2017, CVPR
   Deng J., 2009, CVPR
   Deng J., 2016, PAMI
   Donahue J., 2014, ICML
   Everingham M., 2010, IJCV
   Fu J., 2017, CVPR
   Gao Y., 2016, CVPR
   Gebru T., 2017, ICCV
   Girshick  R., 2014, CVPR
   He  K., 2016, ECCV
   He K., 2016, CVPR
   He X., 2017, CVPR
   Hendricks L. Anne, 2016, CVPR
   Hu J., 2017, ARXIV170901507
   Huh M., 2016, NIPS WORKSH
   Ioffe  S., 2015, ICML
   Jaderberg M., 2015, NIPS
   Johns E., 2015, CVPR
   Khosla A., 2011, CVPR WORKSH
   Kong S., 2017, CVPR
   Krause J., 2013, ICCV WORKSH
   Krause J., 2016, ECCV
   Krause J., 2015, CVPR
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lin T.-Y., 2014, ECCV
   Lin T.-Y., 2017, BMVC
   Lin  Tsung-Yu, 2015, ICCV
   Mac Aodha O., 2018, CVPR
   Maji S, 2013, ARXIV13065151
   Nilsback M.-E., 2008, ICVGIP
   Oquab M., 2014, CVPR
   Rachev S. T., 1985, THEORY PROBABILITY I
   Reed S., 2016, CVPR
   Rubner Y., 2000, IJCV
   Russakovsky Olga, 2015, IJCV
   Schroff F., 2015, CVPR
   Sharif Razavian  A., 2014, CVPR WORKSH
   Simon M., 2017, ICCV
   Simonyan K., 2014, ARXIV14091556
   Sun C., 2017, ICCV
   Szegedy  C., 2016, CVPR
   Szegedy C., 2017, AAAI
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Torralba A., 2011, CVPR
   Van Horn G., 2017, ARXIV17091450
   Van Horn G., 2018, CVPR
   Van Horn G., 2015, CVPR
   Vedaldi A., 2014, CVPR
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wegner J. D., 2016, CVPR
   Xiao T., 2015, CVPR
   Xie  S., 2017, CVPR
   Xu Z., 2016, PAMI
   Yang L., 2015, CVPR
   Yosinski J., 2014, NIPS
   Yu F., 2018, CVPR
   Zhang N., 2016, ICLR WORKSH
   Zhang N., 2014, ECCV
   Zhang X., 2016, CVPR
   Zheng H., 2017, ICCV
   Zhou B., 2017, PAMI
   Zhu X., 2014, CVPR
   Zoph B., 2018, CVPR
NR 71
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 4109
EP 4118
DI 10.1109/CVPR.2018.00432
UT WOS:000457843604027
ER

PT S
AU Chen, SX
   Zhang, CJ
   Dong, M
AF Chen, Shixing
   Zhang, Caojin
   Dong, Ming
GP IEEE
TI Coupled End-to-end Transfer Learning with Generalized Fisher Information
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB In transfer learning, one seeks to transfer related information from source tasks with sufficient data to help with the learning of target task with only limited data. In this paper, we propose a novel Coupled End-to-end Transfer Learning (CETL) framework, which mainly consists of two convolutional neural networks (source and target) that connect to a shared decoder. A novel loss function, the coupled loss, is used for CETL training. From a theoretical perspective, we demonstrate the rationale of the coupled loss by establishing a learning bound for CETL. Moreover, we introduce the generalized Fisher information to improve multi-task optimization in CETL. From a practical aspect, CETL provides a unified and highly flexible solution for various learning tasks such as domain adaption and knowledge distillation. Empirical result shows the superior performance of CETL on cross-domain and cross-task image classification.
CR Al-Rfou R., 2016, ARXIV160502688
   Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137, DOI DOI 10.1007/S10994-009-5152-4
   Bousmalis K., 2017, IEEE C COMP VIS PATT
   Chopra S., 2013, ICML WORKSH CHALL RE, V2
   Coates A., 2011, J MACHINE LEARNING R, V15, P215
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Ge W., 2017, IEEE C COMP VIS PATT
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong B., 2013, P 30 INT C MACH LEAR, P222
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Haeusser P., 2017, IEEE C COMP VIS PATT
   Haeusser P, 2017, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2017.301
   He K., 2016, IEEE C COMP VIS PATT
   Hinton  G., 2015, ARXIV150302531
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jia Y., 2014, ARXIV14085093
   Kirkpatrick J., 2017, P NATL ACAD SCI
   Krizhevsky A., 2009, THESIS
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kuzborskij I., 2013, IEEE C COMP VIS PATT
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Littwin E., 2016, IEEE C COMP VIS PATT
   Long M., 2015, INT C MACH LEARN, P97
   Mao J., 2017, IEEE C COMP VIS PATT
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, V2011, P5
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Romero A., 2014, ARXIV14126550
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C., 2015, IEEE C COMP VIS PATT
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Tzeng E., 2017, IEEE C COMP VIS PATT
   Xu D., 2017, IEEE C COMP VIS PATT
   Yan H, 2017, IEEE GLOB COMM CONF
   Yim J., 2017, IEEE C COMP VIS PATT
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 39
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 4329
EP 4338
DI 10.1109/CVPR.2018.00455
UT WOS:000457843604050
ER

PT S
AU Maqueda, AI
   Loquercio, A
   Gallego, G
   Garcia, N
   Scaramuzza, D
AF Maqueda, Ana I.
   Loquercio, Antonio
   Gallego, Guillermo
   Garcia, Narciso
   Scaramuzza, Davide
GP IEEE
TI Event-based Vision meets Deep Learning on Steering Prediction for
   Self-driving Cars
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB Event cameras are bio-inspired vision sensors that naturally capture the dynamics of a scene, filtering out redundant information. This paper presents a deep neural network approach that unlocks the potential of event cameras on a challenging motion-estimation task: prediction of a vehicle's steering angle. To make the best out of this sensor-algorithm combination, we adapt state-of-the-art convolutional architectures to the output of event sensors and extensively evaluate the performance of our approach on a publicly available large scale event-camera dataset (approximate to 1000 km). We present qualitative and quantitative explanations of why event cameras allow robust steering prediction even in cases where traditional cameras fail, e.g. challenging illumination conditions and fast motion. Finally, we demonstrate the advantages of leveraging transfer learning from traditional to event-based vision, and show that our approach outperforms state-of-the-art algorithms based on standard cameras.
CR Perez-Carrasco JA, 2013, IEEE T PATTERN ANAL, V35, P2706, DOI 10.1109/TPAMI.2013.71
   Binas Jonathan, 2017, ICML WORKSH MACH LEA
   Bojarski Mariusz, 2016, ARXIV E PRINTS
   Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715
   Buehler M, 2009, SPRINGER TRAC ADV RO, V56, P1, DOI 10.1007/978-3-642-03991-1
   Gallego Guillermo, 2017, IEEE T PATTERN ANAL
   Gallego Guillermo, 2018, IEEE INT C COMP VIS
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Kim H, 2016, LECT NOTES COMPUT SC, V9910, P349, DOI 10.1007/978-3-319-46466-4_21
   Kim J, 2017, IEEE I CONF COMP VIS, P2961, DOI 10.1109/ICCV.2017.320
   Lagorce X, 2017, IEEE T PATTERN ANAL, V39, P1346, DOI 10.1109/TPAMI.2016.2574707
   Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337
   Lungu IA, 2017, IEEE INT SYMP CIRC S, P624
   Moeys Diederik Paul, 2016, INT C EV BAS COMM SI
   Orchard G, 2015, IEEE T PATTERN ANAL, V37, P2028, DOI 10.1109/TPAMI.2015.2392947
   Orchard G, 2013, BIOMED CIRC SYST C, P298, DOI 10.1109/BioCAS.2013.6679698
   Pomerleau D.A., 1989, ADV NEURAL INFORMATI, P305
   Razavian Ali Sharif, 2014, IEEE INT C COMP VIS
   Rebecq H, 2018, INT J COMPUT VISION, V126, P1394, DOI 10.1007/s11263-017-1050-6
   Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1023/A:1022672621406
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 25
TC 3
Z9 3
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 5419
EP 5427
DI 10.1109/CVPR.2018.00568
UT WOS:000457843605059
ER

PT S
AU Hu, HX
   Chao, WL
   Sha, F
AF Hu, Hexiang
   Chao, Wei-Lun
   Sha, Fei
GP IEEE
TI Learning Answer Embeddings for Visual Question Answering
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB We propose a novel probabilistic model for visual question answering (Visual QA). The key idea is to infer two sets of embeddings: one for the image and the question jointly and the other for the answers. The learning objective is to learn the best parameterization of those embeddings such that the correct answer has higher likelihood among all possible answers. In contrast to several existing approaches of treating Visual QA as multi-way classification, the proposed approach takes the semantic relationships (as characterized by the embeddings) among answers into consideration, instead of viewing them as independent ordinal numbers. Thus, the learned embedded function can be used to embed unseen answers (in the training dataset). These properties make the approach particularly appealing for transfer learning for open-ended Visual QA, where the source dataset on which the model is learned has limited overlapping with the target dataset in the space of answers. We have also developed large-scale optimization techniques for applying the model to datasets with a large number of answers, where the challenge is to properly normalize the proposed probabilistic models. We validate our approach on several Visual QA datasets and investigate its utility for transferring models across datasets. The empirical results have shown that the approach performs well not only on in-domain learning but also on transfer learning.
CR Agrawal A., 2016, IJCV
   Anderson P., 2018, CVPR
   Antol S., 2015, ICCV
   Ben-Younes H., 2017, ICCV
   Chao W.-L., 2018, NAACL
   Frome A., 2013, NIPS
   Fukui A., 2016, EMNLP
   Gao  H., 2015, ADV NEURAL INFORM PR, P2296, DOI DOI 10.1145/2733373.2807418
   Goyal Y., 2017, CVPR
   Gupta A. K., 2017, ARXIV170503865
   He K., 2016, CVPR
   Ilievski I., 2017, CVPR WORKSH
   Jabri A., 2016, ECCV
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kazemi V, 2017, ARXIV170403162
   Krishna R., 2017, IJCV
   Lin T.-Y., 2014, ECCV
   Lu J., 2016, ADV NEURAL INFORM PR, P289
   Malinowski M., 2014, NIPS
   Norouzi M., 2014, ICLR
   Pennington  Jeffrey, 2014, EMNLP
   Ren M., 2015, NIPS
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shih K. J., 2016, CVPR
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Z., 1994, ACL
   Xu H., 2016, ECCV
   Yang Z., 2016, CVPR
   Yu Z., 2017, ICCV
   Zhou Y., 2017, ARXIV170803619
   Zhou Y., 2017, ICCV
   Zhu Y., 2016, CVPR
NR 32
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 5428
EP 5436
DI 10.1109/CVPR.2018.00569
UT WOS:000457843605060
ER

PT S
AU Lee, KH
   He, XD
   Zhang, L
   Yang, LJ
AF Lee, Kuang-Huei
   He, Xiaodong
   Zhang, Lei
   Yang, Linjun
GP IEEE
TI CleanNet: Transfer Learning for Scalable Image Classifier Training with
   Label Noise
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
ID MACHINE; SUPPORT
AB In this paper, we study the problem of learning image classification models with label noise. Existing approaches depending on human supervision are generally not scalable as manually identifying correct or incorrect labels is time-consuming, whereas approaches not relying on human supervision are scalable but less effective. To reduce the amount of human supervision for label noise cleaning, we introduce CleanNet, a joint neural embedding network, which only requires a fraction of the classes being manually verified to provide the knowledge of label noise that can be transferred to other classes. We further integrate CleanNet and conventional convolutional neural network classifier into one framework for image classification learning. We demonstrate the effectiveness of the proposed algorithm on both of the label noise detection task and the image classification on noisy data task on several large-scale datasets. Experimental results show that CleanNet can reduce label noise detection error rate on held-out classes where no human supervision available by 41.5% compared to current weakly supervised methods. It also achieves 47% of the performance gain of verifying all images with only 3.2% images verified on an image classification task. Source code and dataset will be available at kuanghuei.github.io/CleanNetProject.
CR Azadi S., 2016, ICLR
   Bossard L., 2014, ECCV
   Chen X., 2015, ICCV
   Dean T., 2013, CVPR
   Deng J., 2009, CVPR
   Fergus R, 2010, P IEEE, V98, P1453, DOI 10.1109/JPROC.2010.2048990
   Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Frome A., 2013, NIPS
   He K., 2016, CVPR
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Krause J., 2016, ECCV
   Krizhevsky  A., 2012, NIPS
   Li  Wen, 2017, ARXIV170802862
   Li Y., 2017, ICCV
   Lin T.-Y., 2014, ECCV
   Liu M.-Y., 2016, NIPS
   Liu W., 2014, CVPR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nettleton DF, 2010, ARTIF INTELL REV, V33, P275, DOI 10.1007/s10462-010-9156-z
   Patrini G., 2017, CVPR
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rolnick D, 2017, ARXIV170510694
   Salvador A., 2017, CVPR
   Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133
   Socher R., 2013, NIPS
   Sukhbaatar S., 2014, ARXIV14062080
   Szegedy C., 2017, AAAI
   Thongkam J, 2008, LECT NOTES COMPUT SC, V4977, P99, DOI 10.1007/978-3-540-89376-9_10
   Tsai Y.-H. H., 2017, ICCV
   Tzeng  E., 2017, CVPR
   Veit A., 2017, CVPR
   Vinyals O., 2016, NIPS
   Xia Y., 2015, ICCV
   Xiao T., 2015, CVPR
   Yang Z., 2016, NAACL HLT
   Yu F., 2015, ARXIV150603365
   Zhou B, 2017, IEEE T PATTERN ANAL
   Zhou D., 2004, NIPS
   Zhu X., 2002, CMUCALD02107
   Zhuang B., 2017, CVPR
NR 41
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 5447
EP 5456
DI 10.1109/CVPR.2018.00571
UT WOS:000457843605062
ER

PT S
AU Fajtl, J
   Argyriou, V
   Monekosso, D
   Remagnino, P
AF Fajtl, Jiri
   Argyriou, Vasileios
   Monekosso, Dorothy
   Remagnino, Paolo
GP IEEE
TI AMNet: Memorability Estimation with Attention
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB In this paper we present the design and evaluation of an end-to-end trainable, deep neural network with a visual attention mechanism for memorability estimation in still images. We analyze the suitability of transfer learning of deep models from image classification to the memorability task. Further on we study the impact of the attention mechanism on the memorability estimation and evaluate our network on the SUN Memorability and the LaMem datasets. Our network outperforms the existing state of the art models on both datasets in terms of the Spearman's rank correlation as well as the mean squared error, closely matching human consistency.
CR Bahdanau D, 2014, ARXIV14090473
   Baveye Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P491, DOI 10.1145/2964284.2967269
   Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005
   Celikkale B, 2013, IEEE COMPUT SOC CONF, P976, DOI 10.1109/CVPRW.2013.142
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Dubey R, 2015, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2015.130
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Greff K., 2017, IEEE T NEURAL NETWOR
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Isola Phillip, 2011, ADV NEURAL INFORM PR, P2429
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI DOI 10.1145/1150402.1150429
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Khosla A., 2012, ADV NEURAL INFORM PR, P296
   Khosla A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P867, DOI 10.1145/2566486.2567996
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Kriznar A, 2012, ACTA ARTIS ACADEMICA 2012: KNOWLEDGE AND EXPERIENCE IN THE FINE ART, P25
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Machaj J, 2010, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE, RADIOELETRONIKA 2010, P83, DOI 10.1145/1873951.1873965
   Mancas M, 2013, IEEE IMAGE PROC, P196, DOI 10.1109/ICIP.2013.6738041
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Peng HW, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1147, DOI 10.1145/2733373.2806303
   Pirie W., 1988, ENCY STAT SCI
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saleh B, 2013, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2013.107
   Shechtman E., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xu Kelvin, 2015, INT C MACH LEARN, P2048
   Zarezadeh S, 2017, IRAN CONF ELECTR ENG, P2176, DOI 10.1109/IranianCEE.2017.7985423
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 39
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 6363
EP 6372
DI 10.1109/CVPR.2018.00666
UT WOS:000457843606054
ER

PT S
AU Lv, JM
   Chen, WH
   Li, Q
   Yang, C
AF Lv, Jianming
   Chen, Weihang
   Li, Qing
   Yang, Can
GP IEEE
TI Unsupervised Cross-dataset Person Re-identification by Transfer Learning
   of Spatial-Temporal Patterns
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB Most of the proposed person re-identification algorithms conduct supervised training and testing on single labeled datasets with small size, so directly deploying these trained models to a large-scale real-world camera network may lead to poor performance due to underfitting. It is challenging to incrementally optimize the models by using the abundant unlabeled data collected from the target domain. To address this challenge, we propose an unsupervised incremental learning algorithm, TFusion, which is aided by the transfer learning of the pedestrians' spatio-temporal patterns in the target domain. Specifically, the algorithm firstly transfers the visual classifier trained from small labeled source dataset to the unlabeled target dataset so as to learn the pedestrians' spatial-temporal patterns. Secondly, a Bayesian fusion model is proposed to combine the learned spatio-temporal patterns with visual features to achieve a significantly improved classifier. Finally, we propose a learning-to-rank based mutual promotion procedure to incrementally optimize the classifiers based on the unlabeled data in the target domain. Comprehensive experiments based on multiple real surveillance datasets are conducted, and the results show that our algorithm gains significant improvement compared with the state-of-art cross-dataset unsupervised person re identification algorithms.
CR Ahmed E., 2015, CVPR
   Change C., 2009, COMP VIS IEEE INT C
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Dapeng C., 2016, ECCV
   Evgeniya U., 2016, NIPS
   Gray D., 2008, ECCV
   Gray D., 2007, EVALUATING APPEARANC
   He K, 2015, ARXIV151203385
   Huang W., 2016, MMM
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Kostinger M., 2012, CVPR
   Layne R., 2013, ARTEMIS ACM MULTIMED
   Liang C., 2015, MM
   Liao S., 2015, CVPR
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Ma AJ, 2015, IEEE T IMAGE PROCESS, V24, P1599, DOI 10.1109/TIP.2015.2395715
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018
   Martinel N, 2017, IEEE T CYBERNETICS, V47, P3530, DOI 10.1109/TCYB.2016.2568264
   Paisitkriangkrai S., 2015, CVPR
   Peixi P., 2016, CVPR
   Rahul V., 2016, ECCV
   Song B., 2017, CVPR
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tetsu M., 2016, CVPR
   Wang H., 2014, BMVC
   Wang H., 2016, ICIP
   Wei L., 2013, COMP VIS IEEE INT C
   Wei L., 2017, CVPR
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Yang Y., 2014, ECCV
   Yifan S., 2017, ICCV
   Yingcong C., 2017, CVPR
   Zhao R., 2014, CVPR
   Zhao  R., 2013, CVPR
   Zheng L., 2015, COMP VIS IEEE INT C
   Zheng Z., 2017, TOMM
NR 37
TC 2
Z9 2
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 7948
EP 7956
DI 10.1109/CVPR.2018.00829
UT WOS:000457843608012
ER

PT S
AU Rebuffi, SA
   Bilen, H
   Vedaldi, A
AF Rebuffi, Sylvestre-Alvise
   Bilen, Hakan
   Vedaldi, Andrea
GP IEEE
TI Efficient parametrization of multi-domain deep neural networks
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB A practical limitation of deep neural networks is their high degree of specialization to a single task and visual domain. Recently, inspired by the successes of transfer learning, several authors have proposed to learn instead universal feature extractors that, used as the first stage of any deep network, work well for several tasks and domains simultaneously. Nevertheless, such universal features are still somewhat inferior to specialized networks.
   To overcome this limitation, in this paper we propose to consider instead universal parametric families of neural networks, which still contain specialized problem-specific models, but differing only by a small number of parameters. We study different designs for such parametrization, including series and parallel residual adapters, joint adapter compression, and parameter allocations, and empirically identify the ones that yield the highest compression. We show that, in order to maximize performance, it is necessary to adapt both shallow and deep layers of a deep network, but the required changes are very small. We also show that these universal parametrization are very effective for transfer learning, where they outperform traditional fine-tuning techniques.
CR Bertinetto  L., 2016, ADV NEURAL INFORM PR, P523
   Bilen H., 2016, P NIPS
   Bilen H., 2017, ARXIV170107275
   Bousmalis K., 2016, ADV NEURAL INFORM PR, P343
   Caruana R., 1997, MACHINE LEARNING, V28
   Collobert R., 2008, P 25 ICML, V25, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Dahl GE, 2014, ARXIV14061231
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Ganin Y., 2015, P ICML
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He  Kaiming, 2017, ARXIV170306870
   Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081
   Kirkpatrick J., 2017, OVERCOMING CATASTROP
   Kokkinos I., 2017, P CVPR
   Krizhevsky A., 2009, TECHNICAL REPORT
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li D., 2017, ARXIV171003463
   LI ZZ, 2016, P ECCV, V9908, P614, DOI DOI 10.1007/978-3-319-46493-0_37
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Meyerson E., 2017, ARXIV171100108
   Mitchell T., 2010, NEVER ENDING LEARNIN
   Rannen A., 2017, CVPR, P1320
   Rebuffi S., 2017, P NIPS
   Rebuffi S. A., 2017, P CVPR
   Rosenfeld A., 2017, ARXIV170504228
   Rusu A. A., 2016, ARXIV160604671
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Terekhov AV, 2015, LECT NOTES ARTIF INT, V9222, P268, DOI 10.1007/978-3-319-22979-9_27
   Thrun S, 1998, LEARNING TO LEARN, P181
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Yang Y., 2016, ICLR
   Zagoruyko S., 2016, ARXIV160507146
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhang Z., 2014, P ECCV
NR 35
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 8119
EP 8127
DI 10.1109/CVPR.2018.00847
UT WOS:000457843608030
ER

PT S
AU Liu, B
   Wang, XD
   Dixit, M
   Kwitt, R
   Vasconcelos, N
AF Liu, Bo
   Wang, Xudong
   Dixit, Mandar
   Kwitt, Roland
   Vasconcelos, Nuno
GP IEEE
TI Feature Space Transfer for Data Augmentation
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
ID DIMENSIONALITY REDUCTION
AB The problem of data augmentation in feature space is considered. A new architecture, denoted the FeATure TransfEr Network (FATTEN), is proposed for the modeling of feature trajectories induced by variations of object pose. This architecture exploits a parametrization of the pose manifold in terms of pose and appearance. This leads to a deep encoder/ decoder network architecture, where the encoder factors into an appearance and a pose predictor. Unlike previous attempts at trajectory transfer, FATTEN can be efficiently trained end-to-end, with no need to train separate feature transfer functions. This is realized by supplying the decoder with information about a target pose and the use of a multi-task loss that penalizes category-and pose-mismatches. In result, FATTEN discourages discontinuous or non-smooth trajectories that fail to capture the structure of the pose manifold, and generalizes well on object recognition tasks involving large pose variation. Experimental results on the artificial ModelNet database show that it can successfully learn to map source features to target features of a desired pose, while preserving class identity. Most notably, by using feature space transfer for data augmentation (w.r.t. pose and depth) on SUN-RGBD objects, we demonstrate considerable performance improvements on one/few-shot object recognition in a transfer learning setup, compared to current state-of-the-art methods.
CR Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Deng J., 2009, CVPR
   Dixit M., 2017, CVPR
   Fei-Fei L., 2015, CVPR
   Finn C., 2017, CORR
   Gatys L. A., 2016, CVPR
   Girshick Ross, 2015, ICCV
   Goodfellow I., 2014, NIPS
   Hariharan B., 2016, CORR
   He K., 2016, CVPR
   Isola P., 2017, CVPR
   Kalogerakis E., 2016, CORR
   Knopp J., 2010, ECCV
   Krizhevsky  A., 2012, NIPS
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   LeCun Y, 2004, CVPR
   Nene S. A., 1996, CUCS00696
   Pathak D., 2016, CVPR
   Peng X., 2015, ICCV
   Qi C. R., 2016, CORR
   Ravi S., 2017, ICLR
   Ren  Shaoqing, 2015, NIPS
   Romera-Paredes  Bernardino, 2015, ICML
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Santoro A, 2016, ICML
   Simonyan K, 2015, P INT C LEARN REPR, P1, DOI DOI 10.1016/J.INFSOF.2008.09.005
   Socher R., 2013, NIPS
   Song S., 2015, CVPR
   Su H., 2015, ICCV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang K., 2010, CVPR
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinjays O., 2015, CVPR
   Vinyals O., 2016, NIPS
   Wu Z., 2015, CVPR
NR 35
TC 2
Z9 2
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 9090
EP 9098
DI 10.1109/CVPR.2018.00947
UT WOS:000457843609027
ER

PT S
AU Caicedo, JC
   McQuin, C
   Goodman, A
   Singh, S
   Carpenter, AE
AF Caicedo, Juan C.
   McQuin, Claire
   Goodman, Allen
   Singh, Shantanu
   Carpenter, Anne E.
GP IEEE
TI Weakly Supervised Learning of Single-Cell Feature Embeddings
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
ID CANCER
AB We study the problem of learning representations for single cells in microscopy images to discover biological relationships between their experimental conditions. Many new applications in drug discovery and functional genomics require capturing the morphology of individual cells as comprehensively as possible. Deep convolutional neural networks (CNNs) can learn powerful visual representations, but require ground truth for training; this is rarely available in biomedical profiling experiments. While we do not know which experimental treatments produce cells that look alike, we do know that cells exposed to the same experimental treatment should generally look similar. Thus, we explore training CNNs using a weakly supervised approach that uses this information for feature learning. In addition, the training stage is regularized to control for unwanted variations using mixup or RNNs. We conduct experiments on two different datasets; the proposed approach yields single-cell embeddings that are more accurate than the widely adopted classical features, and are competitive with previously proposed transfer learning approaches.
CR Bray MA, 2016, NAT PROTOC, V11, P1757, DOI 10.1038/nprot.2016.105
   Caicedo JC, 2017, NAT METHODS, V14, P849, DOI [10.1038/NMETH.4397, 10.1038/nmeth.4397]
   Caicedo JC, 2016, CURR OPIN BIOTECH, V39, P134, DOI 10.1016/j.copbio.2016.04.003
   Caie PD, 2010, MOL CANCER THER, V9, P1913, DOI 10.1158/1535-7163.MCT-09-1148
   Carpenter AE, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-10-r100
   Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168
   Chung J., 2014, EMPIRICAL EVALUATION
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Godinez WJ, 2017, BIOINFORMATICS, V33, P2010, DOI 10.1093/bioinformatics/btx069
   Goldsborough P., 2017, BIORXIV
   Goodfellow  I., 2014, GENERATIVE ADVERSARI
   Gough A, 2017, SLAS DISCOV, V22, P213, DOI 10.1177/2472555216682725
   Gross S., 2017, ARXIV170406363
   He  K., 2015, DEEP RESIDUAL LEARNI
   He  Kaiming, 2017, ARXIV170306870
   Huang Y., 2017, ARXIV170502596
   Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5
   Kraus OZ, 2017, MOL SYST BIOL, V13, DOI 10.15252/msb.20177551
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kudlur M, 2015, ARXIV151106391
   Lin  T.-Y., 2014, EUR C COMP VIS, P740, DOI DOI 10.1007/978-3-319-10602-1_48
   Ljosa V, 2013, J BIOMOL SCREEN, V18, P1321, DOI 10.1177/1087057113503553
   McLean C., 2017, IMPROVING PHENOTYPIC
   Pawlowski N., 2016, AUTOMATING MORPHOLOG
   Pawlowski N., 2016, THESIS
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohban MH, 2017, ELIFE, V6, DOI 10.7554/eLife.24060
   Ronneberger  O., 2015, U NET CONVOLUTIONAL
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan  K., 2014, VERY DEEP CONVOLUTIO
   Singh S, 2014, J MICROSC-OXFORD, V256, P231, DOI 10.1111/jmi.12178
   Styles E. B., 2016, TRENDS CELL BIOL
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang X., 2017, ARXIV170502315
   Zhang C, 2016, ARXIV161103530
   Zhang H., 2017, MIXUP EMPIRICAL RISK
   Zhuang B., 2016, ATTEND GROUPS WEAKLY
NR 37
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 9309
EP 9318
DI 10.1109/CVPR.2018.00970
UT WOS:000457843609050
PM 30918435
ER

PT S
AU Mundhenk, TN
   Ho, D
   Chen, BY
AF Mundhenk, T. Nathan
   Ho, Daniel
   Chen, Barry Y.
GP IEEE
TI Improvements to context based self-supervised learning
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
AB We develop a set of methods to improve on the results of self-supervised learning using context. We start with a baseline of patch based arrangement context learning and go from there. Our methods address some overt problems such as chromatic aberration as well as other potential problems such as spatial skew and mid-level feature neglect. We prevent problems with testing generalization on common self-supervised benchmark tests by using different datasets during our development. The results of our methods combined yield top scores on all standard self-supervised benchmarks, including classification and detection on PASCAL VOC 2007, segmentation on PASCAL VOC 2012, and "linear tests" on the ImageNet and CSAIL Places datasets. We obtain an improvement over our baseline method of between 4.0 to 7.1 percentage points on transfer learning classification tests. We also show results on different standard network architectures to demonstrate generalization as well as portability. All data, models and programs are available at: https://gdo-datasci.llnl.gov/selfsupervised/.
CR Agrawal P., 2015, ICCV
   [Anonymous], 2009, CORNELL LAB ORNITHOL, V23
   Bojanowski P., 2017, ICML
   Campr P., IMAGENET 21K INCEPTI
   Ciresan D., 2012, CORR
   Ciresan D. C., 2011, CORR
   Deng J., 2009, CVPR
   Dodge A., IAIN MTEFFECT WIKIME
   Doersch C., 2017, ICCV
   Doersch Carl, 2015, ICCV
   Donahue J., 2017, ICLR
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick Ross, 2015, ICCV
   Gomez L., 2017, CVPR
   He K, 2015, ARXIV151203385
   Huang G., 2017, CVPR
   Ioffe  S., 2015, ICML
   Jayaraman Dinesh, 2015, ICCV
   Jia Y., 2014, ARXIV14085093
   Kim D., 2018, WACV
   Krahenbuhl P., 2016, ICLR
   Krizhevsky A., 2013, NIPS
   Larsson G., 2017, CVPR
   Lee H.-Y., 2017, ICCV
   Li D., 2016, ECCV
   Livingstone M., 2002, 1 STAGES PROCESSING, P46
   Long  J., 2015, CVPR
   Misra Ishan, 2016, ECCV
   Mundhenk T. N., 2016, ECCV
   Noroozi M., 2016, CORR
   Noroozi M., 2016, ECCV
   Noroozi M., 2017, ICCV
   Owens A., 2016, ECCV
   Pathak D., 2017, CVPR
   Pathak D., 2016, CVPR
   Simard P., 2003, P 7 INT C DOC AN REC
   Simonyan K., 2014, CORR
   Szegedy C, 2016, ARXIV160207261
   Szegedy C., 2015, CVPR
   THOMPSON P, 1980, PERCEPTION, V9, P483, DOI 10.1068/p090483
   Umbert, KOLORA ABERACIO WIKI
   Wang X., 2015, ICCV
   Wang X., 2017, ICCV
   Welinder P., 2010, CNSTR2010001 CAL I T
   Yang L., 2015, CVPR
   Zhang R., 2017, CVPR
   Zhang R., 2016, ECCV
   Zhou B., 2014, NIPS
NR 49
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 9339
EP 9348
DI 10.1109/CVPR.2018.00973
UT WOS:000457843609053
ER

PT B
AU Yao, YB
   Cai, YG
   Wei, W
   Shuai, H
AF Yao Yeboah
   Cai Yanguang
   Wei Wu
   Shuai He
GP ACM
TI Autonomous Indoor Robot Navigation via Siamese Deep Convolutional Neural
   Network
SO 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN
   RECOGNITION (AIPR 2018)
CT International Conference on Artificial Intelligence and Pattern
   Recognition (AIPR)
CY AUG 18-20, 2018
CL Beijing, PEOPLES R CHINA
DE Deep Convolutional Neural Networks (DCNN); Indoor navigation; Semantic
   segmentation; Siamese network
ID LOCALIZATION
AB The vast majority of indoor navigation algorithms either rely on manual scene augmentation and labelling or exploit multi-sensor fusion techniques in achieving simultaneous localization and mapping (SLAM), leading to high computational costs, hardware complexities and robustness deficiencies. This paper proposes an efficient and robust deep learning-based indoor navigation framework for robots. Firstly, we put forward an end-to-end trainable siamese deep convolutional neural network (DCNN) which decomposes navigation into orientation and localization in one branch, while achieving semantic scene mapping in another. In mitigating the computational costs associated with DCNNs, the proposed model design shares a significant amount of convolutional operations between the two branches, streamlining the model and optimizing for efficiency in terms of memory and inference latency. Secondly, a transfer learning regime is explored in demonstrating how such siamese DCNNs can be efficiently trained for high convergence rates without extensive manual dataset labelling. The resulting siamese framework combines semantic scene understanding with orientation estimation towards predicting collision-free and optimal navigation paths. Experimental results demonstrate that the proposed framework achieves accurate and efficient navigation and outperforms existing "navigation-by-classification" variants.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bostelman RV, 2005, 2005 12th International Conference on Advanced Robotics, P460
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Chang CK, 2013, IEEE INT C INT ROBOT, P2079, DOI 10.1109/IROS.2013.6696642
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Correa D. S. O., 2012, 2012 Second Brazilian Conference on Critical Embedded Systems (CBSEC 2012), P36, DOI 10.1109/CBSEC.2012.18
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hou J, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P725, DOI 10.1109/ICBDA.2017.8078731
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Liu W., 2015, CORR
   Rao D. J., 2017, CORR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, CORR
   Solak S, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P685, DOI 10.1109/ELECO.2015.7394442
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Talib O., 2014, P INF TECHN BAS HIGH, P1
   Wei H, 2018, IEEE T IMAGE PROCESS, V27, P3164, DOI 10.1109/TIP.2018.2818931
   Xi WN, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P1012, DOI 10.1109/ICInfA.2017.8079050
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yuan W, 2016, IEEE ICARM 2016 - 2016 INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM), P82, DOI 10.1109/ICARM.2016.7606899
   Zheng WX, 2017, C IND ELECT APPL, P924, DOI 10.1109/ICIEA.2017.8282971
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou YM, 2014, IEEE ROMAN, P147, DOI 10.1109/ROMAN.2014.6926245
NR 27
TC 0
Z9 0
BN 978-1-4503-6524-6
PY 2018
BP 113
EP 119
DI 10.1145/3268866.3268886
UT WOS:000458142000023
ER

PT B
AU Diasse, A
   Li, ZY
AF Diasse, Abdoullahi
   Li, Zhiyong
GP ACM
TI Big Cities transfer learning: An unsupervised multi-view cross-domain
   classification with misses
SO PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING
   AND COMPUTING (ICMLC 2018)
CT 10th International Conference on Machine Learning and Computing (ICMLC)
CY FEB 26-28, 2018
CL Univ Macau, Zhuhai, PEOPLES R CHINA
HO Univ Macau
DE Big data; multi-view; transfer learning; data Insufficiency; subspace
   learning; Low rank
AB Big data has brought many new challenges for machine learning research. In many learning tasks, we have to deal with diverse data from different domains, different representations, different distributions, scale, and density in order to achieve a good performance. With the recent advances in data storage and internet technology, data become more prominent, noisier and more complex which bring new opportunities and challen ges into Transfer learning. In Urban computing when inferring knowledge for new or less developed cities we often need to deal with large-scale, multi-view, noisy and incomplete data. This calls for advanced techniques that can make practical use of massive, sparse and noisy data to efficiently transfer knowledge of multiple and diverse datasets (views) from a source domain to a target domain. Such a problem becomes much more challenging in an unsupervised learning setting where we do not dispose any label in the target domain which is not uncommon in my real-world scenarios. To tackle this challenge, in this paper we propose novel unsupervised multi-view transfer with missing data by learning a shared subspace across views from different domains through a latent low-rank transfer. Before performing knowledge transfer our approach learns an enriched representation of the source domain via a novel joint multi-view dictionary learning based on low-rank tensor. We also propose a multi-view co-classifier to predict the label in the target domain. Tailored for big data applications with EM-ADMM based optimization algorithm our method can efficiently perform knowledge transfer from a multi-view source domain to an unlabeled multi-view target domain with a high rate of missing values and noise.
CR Andersson F, 2014, IEEE T SIGNAL PROCES, V62, P5761, DOI 10.1109/TSP.2014.2358961
   Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Ding Z., 2014, P 28 AAAI C ART INT
   Ding ZM, 2015, IEEE T IMAGE PROCESS, V24, P4322, DOI 10.1109/TIP.2015.2462023
   Ding Zhengming, 2016, IEEE T NEURAL NETWOR
   Duda R. O., 2012, PATTERN CLASSIFICATI
   Fang Z., 2013, P 22 ACM INT C INF K, P1321
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   He J., 2011, P 28 INT C MACH LEAR, P25
   Jin X., 2014, P 23 ACM INT C INF K, P441
   Lin F, 2013, IEEE T AUTOMAT CONTR, V58, P2426, DOI 10.1109/TAC.2013.2257618
   Liu G., LATENT LOW RANK REPR
   Liu G., 2012, J MACH LEARN RES P T, P703
   liu G., 2010, CORR
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Tan B., 2013, SDM
   Wei Y., 2016, KDD 16
   Yang P., 2015, KDD, P1375
   Yang P., 2013, P 23 INT JOINT C ART, P1848
   Yang P., 2012, ACL, P270
   Yu Zheng, 2015, IEEE T BIG DATA  MAY
   Zhang Changqing, 2015, ICCV
   Zhang D., 2011, KDD, P1208
   Zhang J., 2012, P 18 ACM SIGKDD INT, P543, DOI DOI 10.1145/2339530.2339617
   Zheng Yu, 2015, KDD 15
   Zhou D., 2003, NIPS
NR 30
TC 0
Z9 0
BN 978-1-4503-6353-2
PY 2018
BP 312
EP 321
DI 10.1145/3195106.3195121
UT WOS:000458148400057
ER

PT B
AU Secerovic, L
   Papic, V
AF Secerovic, Luka
   Papic, Veljko
GP IEEE
TI Detecting missing products in commercial refrigerators using
   convolutional neural networks
SO 2018 14TH SYMPOSIUM ON NEURAL NETWORKS AND APPLICATIONS (NEUREL)
CT 14th Symposium on Neural Networks and Applications (NEUREL)
CY NOV 20-21, 2018
CL Belgrade, SERBIA
DE computer vision; convolutional neural network; object detection; out of
   stock; tensorflow
AB Out of stock (OOS) is a problem all stores are facing and it reduces their profit. Standard procedures for solving OOS are mostly manual and not scalable. This paper analyzes and proposes an automated and scalable solution for solving OOS problem inside commercial refrigerators. Small, low resolution cameras are placed inside refrigerators. Images taken with those cameras are analyzed with Faster R-CNN and Single Shot Multibox (SSD) models for object detection. Models were trained using transfer learning and their performances were analyzed and compared. After object detection, K-mean clustering algorithm is used to group objects on same shelves. Distance between objects on the same shelf determines if and where the OOS problem is present.
CR Girshick Ross B., 2015, 2015 IEEE INT C COMP
   Gonzalez R. C., 2008, DIGITAL IMAGE PROCES
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Springenberg J. T., 2014, 14126806 ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zeiler M. D, 2013, ARXIV13112901
NR 7
TC 0
Z9 0
BN 978-1-5386-6974-7
PY 2018
UT WOS:000457745100025
ER

PT S
AU Zelinka, M
AF Zelinka, Mikulas
GP IEEE
TI Baselines for Reinforcement Learning in Text Games
SO 2018 IEEE 30TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT 30th IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 05-07, 2018
CL Volos, GREECE
DE Text games; reinforcement learning; neural networks
AB The ability to learn optimal control policies in systems where action space is defined by sentences in natural language would allow many interesting real-world applications such as automatic optimisation of dialogue systems. Text-based games with multiple endings and rewards are a promising platform for this task, since their feedback allows us to employ reinforcement learning techniques to jointly learn text representations and control policies. We argue that the key property of AI agents, especially in the text-games context, is their ability to generalise to previously unseen games. We present a minimalistic text-game playing agent, testing its generalisation and transfer learning performance and showing its ability to play multiple games at once. We also present pyfiction, an open-source library for universal access to different text games that could, together with our agent that implements its interface, serve as a baseline for future research.
CR Bellman R, 2013, DYNAMIC PROGRAMMING
   Branavan S. R. K., 2014, ABS14015390 CORR
   Brockman G., 2016, ABS160601540 CORR
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chentanez N., 2004, 18 ANN C NEUR INF PR, P1281, DOI DOI 10.1109/TAMD.2010.2051031
   Dauphin Y. N., 2015, ABS150204390 CORR
   He J., 2015, ABS151104636 CORR
   Hochreiter S., 1991, DIPLOMA TU MUNCHEN, V91
   Huang A., 2008, P 6 NZ COMP SCI RES, P49
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Montfort N., 2005, TWISTY LITTLE PASSAG
   Narasimhan K., 2015, ABS150608941 CORR
   Schaul T., 2015, PRIORITIZED EXPERIEN
   Silver  D., 2017, ABS171201815 CORR
   Sutton R. S., 1998, NON TRADITIONAL REF
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P2
   Zelinka M., 2018, ABS180101999 CORR
NR 19
TC 0
Z9 0
SN 1082-3409
BN 978-1-5386-7449-9
PY 2018
BP 320
EP 327
DI 10.1109/ICTAI.2018.00058
UT WOS:000457750200048
ER

PT S
AU Du, YT
   Chen, Q
   Lu, HY
   Wang, CJ
AF Du, Yun-tao
   Chen, Qian
   Lu, Heng-yang
   Wang, Chong-jun
GP IEEE
TI Online Single Homogeneous Source Transfer Learning Based on AdaBoost
SO 2018 IEEE 30TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT 30th IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 05-07, 2018
CL Volos, GREECE
DE transfer learning; online learning; online transfer learning;
   homogeneous transfer
AB Transfer learning has made great achievements in many fields and many excellent algorithms have been proposed. In recent years, many scholars have focused on a new research area called online transfer learning, which is different from general transfer learning. Online transfer learning concentrates on how to build a good classifier on the target domain when the training data arrive in an online/sequential manner. This paper focuses on online transfer learning problem based on a single source domain under homogeneous space. The existing algorithms HomOTL-I and HomOTL-II simply ensemble the classifiers on the source and target domains directly. When the distribution difference between the source domain and the target domain is large, it will not result in a good transfer effect. We are inspired by the idea of the boosting algorithm, that is we could form a strong classification model by a combination of multiple weak classifications. We train multiple classifiers on the source domain in an offfine manner using AdaBoost algorithm, combine these classifiers on source domain with the classifier trained in an online manner on the target domain to form multiple weak combination in an ensemble manner. Based on the above ideas, we propose two algorithms AB-HomOTL-I and AB-HomOTLII, which have different ways to adjust the weights. We tested our algorithms on sentiment analysis dataset and 20newsgroup dataset. The results show that our algorithms are superior to other baseline algorithms.
CR Crammer K, 2006, J MACH LEARN RES, V7, P551
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Dalessandro B., 2014, P 20 ACM SIGKDD INT, P1573
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Ge Liang, 2013, P 22 ACM INT C INF K, P2423
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Wu QC, 2018, IEEE T SYST MAN CY-S, V48, P1005, DOI 10.1109/TSMC.2017.2771227
   Xia H., 2013, IEEE T PATTERN ANAL, V36, P1
   Yan YG, 2016, LECT NOTES COMPUT SC, V9915, P467, DOI 10.1007/978-3-319-49409-8_38
   Yuan Lei, 2012, KDD, P1149
   Zhao PL, 2014, ARTIF INTELL, V216, P76, DOI 10.1016/j.artint.2014.06.003
NR 14
TC 0
Z9 0
SN 1082-3409
BN 978-1-5386-7449-9
PY 2018
BP 344
EP 349
DI 10.1109/ICTAI.2018.00061
UT WOS:000457750200051
ER

PT S
AU Chen, Q
   Du, YT
   Xu, M
   Wang, CJ
AF Chen, Qian
   Du, Yun-tao
   Xu, Ming
   Wang, Chong-jun
GP IEEE
TI HetEOTL: An Algorithm for Heterogeneous Online Transfer Learning
SO 2018 IEEE 30TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT 30th IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 05-07, 2018
CL Volos, GREECE
DE online transfer learning; heterogeneous transfer learning; ensemble
   learning
AB Transfer learning is an important topic in machine learning and has been broadly studied for many years. However, most existing transfer learning methods assume the training sets are prepared in advance, which is often not the case in practice. Fortunately, online transfer learning (OTL), which addresses the transfer learning tasks in an online fashion, has been proposed to solve the problem. This paper mainly focuses on the heterogeneous OTL, which is in general very challenging because the feature space of target domain is different from that of the source domain. In order to enhance the learning performance, we design the algorithm called Heterogeneous Ensembled Online Transfer Learning (HetEOTL) using ensemble learning strategy. Finally, we evaluate our algorithm on some benchmark datasets, and the experimental results show that HetEOTL has better performance than some other existing online learning and transfer learning algorithms, which proves the effectiveness of HetEOTL.
CR Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Freund Yoav, 1995, COMPUT LEARN THEORY, P119
   Ge Liang, 2013, P 22 ACM INT C INF K, P2423
   Hoi Steven C. H, 2014, LIBOL LIB ONLINE LEA
   Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614
   Pan WK, 2013, ARTIF INTELL, V197, P39, DOI 10.1016/j.artint.2013.01.003
   Rosenblatt F, 1988, NEUROCOMPUTING FDN R, P386
   Thrun S., 1995, P NIPS, P640
   Wang Jialei, 2013, P 7 ACM C REC SYST, P237
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu QC, 2018, IEEE T SYST MAN CY-S, V48, P1005, DOI 10.1109/TSMC.2017.2771227
   Wu QY, 2014, IEEE INTELL SYST, V29, P26, DOI 10.1109/MIS.2013.32
   Xia H, 2014, IEEE T PATTERN ANAL, V36, P536, DOI 10.1109/TPAMI.2013.149
   Xiang EW, 2011, IJCAI P INT JOINT C, V22, P2355
   Zhao P., 2010, P INT C MACH LEARN, P1231, DOI DOI 10.1145/2505515.2505603
   Zhao PL, 2014, ARTIF INTELL, V216, P76, DOI 10.1016/j.artint.2014.06.003
NR 17
TC 0
Z9 0
SN 1082-3409
BN 978-1-5386-7449-9
PY 2018
BP 350
EP 357
DI 10.1109/ICTAI.2018.00062
UT WOS:000457750200052
ER

PT S
AU Kohli, N
   Yadav, D
   Noore, A
AF Kohli, Naman
   Yadav, Daksha
   Noore, Afzel
GP IEEE
TI Face Verification with Disguise Variations via Deep Disguise Recognizer
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB The performance of current automatic face recognition algorithms is hindered by different covariates such as facial aging, disguises, and pose variations. Specifically, disguises are employed for intentional or unintentional modifications in the facial appearance for hiding one's own identity or impersonating someone else's identity. In this paper, we utilize deep learning based transfer learning approach for face verification with disguise variations. We employ Residual Inception network framework with center loss for learning inherent face representations. The training for the Inception-ResNet model is performed using a large-scale face database which is followed by inductive transfer learning to mitigate the impact of facial disguises. To evaluate the performance of the proposed Deep Disguise Recognizer (DDR) framework, Disguised Faces in the Wild and IIIT-Delhi Disguise Version 1 face databases are used. Experimental evaluation reveals that for the two databases, the proposed DDR framework yields 90.36% and 66.9% face verification accuracy at the false accept rate of 10%.
CR Cao  Q., 2018, IEEE C AUT FAC GEST
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Dhamecha TI, 2013, INT CONF BIOMETR
   Dhamecha TI, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099212
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He K., 2015, ABS151203385 CORR
   Kim J, 2005, LECT NOTES ARTIF INT, V3533, P65
   Kohl N, 2015, IEEE ACCESS, V3, P2572, DOI 10.1109/ACCESS.2015.2505243
   Kushwaha V., 2018, DISGUISED FACES WILD
   Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Nguyen D.-L., 2018, IEEE INT C BIOM
   Olivas E. S., 2009, HDB RES MACHINE LEAR
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Ramanathan N, 2004, IEEE IMAGE PROC, P1999
   Rui Min, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P442, DOI 10.1109/FG.2011.5771439
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Singh A., 2017, ARXIV170809317
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Singh R, 2009, IMAGE VISION COMPUT, V27, P245, DOI 10.1016/j.imavis.2007.06.010
   Sun Y., 2015, ARXIV150200873
   Szegedy C., 2017, AAAI, V4, P12
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Zhang CL, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P584, DOI 10.1109/ASRU.2017.8268989
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 28
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 17
EP 24
DI 10.1109/CVPRW.2018.00010
UT WOS:000457636800003
ER

PT S
AU Iglovikov, V
   Seferbekov, S
   Buslaev, A
   Shvets, A
AF Iglovikov, Vladimir
   Seferbekov, Selim
   Buslaev, Alexander
   Shvets, Alexey
GP IEEE
TI TernausNetV2: Fully convolutional network for Instance Segmentation
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB The most common approaches to instance segmentation are complex and use two-stage networks with object proposals, conditional random-fields, template matching or recurrent neural networks. In this work we present Ternaus-NetV2 - a simple fully convolutional network that allows extracting objects from a high-resolution satellite imagery on an instance level. The network has popular encoder-decoder type of architecture with skip connections but has a few essential modifications that allows using for semantic as well as for instance segmentation tasks. This approach is universal and allows to extend any network that has been successfully applied for semantic segmentation to perform instance segmentation task. In addition, we generalize network encoder that was pre-trained for RGB images to use additional input channels. It makes possible to use transfer learning from visual to a wider spectral range. For DeepGlobe-CVPR 2018 building detection sub-challenge, based on public leaderboard score, our approach shows superior performance in comparison to other methods.
CR Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305
   BulO S. R., 2017, ARXIV171202616
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Demir I., 2018, ARXIV180506561
   Glorot X., 2011, INT C ARTIF INTELLIG, P315, DOI DOI 10.1177/1753193410395357
   Goldberg HR, 2018, PROC SPIE, V10645, DOI 10.1117/12.2304682
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Iglovikov V., 2018, ARXIV180105746
   Iglovikov V., 2017, ARXIV170606169
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Neuhold G., 2017, P INT C COMP VIS ICC, P22
   Ronneberger O., 2015, INT C MED IM COMP CO, V2015, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   San D. K., 2010, INT ARCH PHOTOGRAM 8, V38
   Zhang A., 2017, ARXIV170708952
NR 14
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 228
EP 232
DI 10.1109/CVPRW.2018.00042
UT WOS:000457636800035
ER

PT S
AU Li, YJ
   Yang, FE
   Liu, YC
   Yeh, YY
   Du, XF
   Wang, YCF
AF Li, Yu-Jhe
   Yang, Fu-En
   Liu, Yen-Cheng
   Yeh, Yu-Ying
   Du, Xiaofei
   Wang, Yu-Chiang Frank
GP IEEE
TI Adaptation and Re-Identification Network: An Unsupervised Deep Transfer
   Learning Approach to Person Re-Identification
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB Person re-identification (Re-ID) aims at recognizing the same person from images taken across different cameras. To address this task, one typically requires a large amount labeled data for training an effective Re-ID model, which might not be practical for real-world applications. To alleviate this limitation, we choose to exploit a sufficient amount of pre-existing labeled data from a different (auxiliary) dataset. By jointly considering such an auxiliary dataset and the dataset of interest (but without label information), our proposed adaptation and re-identification network (ARN) performs unsupervised domain adaptation, which leverages information across datasets and derives domain-invariant features for Re-ID purposes. In our experiments, we verify that our network performs favorably against state-of-the-art unsupervised Re-ID approaches, and even outperforms a number of baseline Re-ID methods which require fully supervised data for training.
CR Bousmalis K., 2016, ADV NEURAL INFORM PR, P343
   Cheng D., 2016, P IEEE C COMP VIS PA
   Deng W., 2018, P IEEE C COMP VIS PA
   Fan  H., 2017, UNSUPERVISED PERSON
   Geng  M., 2016, ARXIV161105244
   Hadsell R., 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hermans  A., 2017, DEFENSE TRIPLET LOSS
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Y., 2017, IMPROVING PERSON RE
   Liu M.-Y., 2016, ADV NEURAL INFORM PR
   Liu  Ming-Yu, 2017, ADV NEURAL INFORM PR
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Si J., 2018, DUAL ATTENTION MATCH
   Sun Y., 2017, SVDNET PEDESTRIAN RE
   Sun YH, 2017, IEEE ICC
   Tzeng E., 2014, DEEP DOMAIN CONFUSIO
   Wang LL, 2016, PROCEEDINGS OF THE ASME 35TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING , 2016, VOL 9
   Yu H.-X., 2017, P IEEE INT C COMP VI
   Zhang L, 2016, IEEE IC COMP COM NET
   Zheng L., 2016, PERSON REIDENTIFICAT
   Zheng L., 2015, PROCEEDINGS OF THE I
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, CAMERA STYLE ADAPTAT
NR 24
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 285
EP 291
DI 10.1109/CVPRW.2018.00054
UT WOS:000457636800047
ER

PT S
AU Huang, XY
   Cheng, XJ
   Geng, QC
   Cao, BB
   Zhou, DF
   Wang, P
   Lin, YQ
   Yang, RG
AF Huang, Xinyu
   Cheng, Xinjing
   Geng, Qichuan
   Cao, Binbin
   Zhou, Dingfu
   Wang, Peng
   Lin, Yuanqing
   Yang, Ruigang
GP IEEE
TI The ApolloScape Dataset for Autonomous Driving
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
ID OBJECT CLASSES
AB Scene parsing aims to assign a class (semantic) label for each pixel in an image. It is a comprehensive analysis of an image. Given the rise of autonomous driving, pixel-accurate environmental perception is expected to be a key enabling technical piece. However, providing a large scale dataset for the design and evaluation of scene parsing algorithms, in particular for outdoor scenes, has been difficult. The per-pixel labelling process is prohibitively expensive, limiting the scale of existing ones. In this paper, we present a large-scale open dataset, ApolloScape, that consists of RGB videos and corresponding dense 3D point clouds. Comparing with existing datasets, our dataset has the following unique properties. The first is its scale, our initial release contains over 140K images - each with its per-pixel semantic mask, up to 1M is scheduled. The second is its complexity. Captured in various traffic conditions, the number of moving objects averages from tens to over one hundred (Figure 1). And the third is the 3D attribute, each image is tagged with high-accuracy pose information at cm accuracy and the static background point cloud has mm relative accuracy. We are able to label these many images by an interactive and efficient labelling pipeline that utilizes the high-quality 3D point cloud. Moreover, our dataset also contains different lane markings based on the lane colors and styles. We expect our new dataset can deeply benefit various autonomous driving related applications that include but not limited to 2D/3D scene understanding, localization, transfer learning, and driving simulation.
CR [Anonymous], 2018, RIEGL VMX 1HA
   [Anonymous], 2018, HDL 64E
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Cordts M., 2016, P IEEE C COMP VIS PA
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Geiger  A., 2013, INT J ROBOTICS RES I
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Neuhold G., 2017, P INT C COMP VIS ICC, P22
   Qi Charles Ruizhongtai, 2017, ADV NEURAL INFORM PR, P5105
   Richter S. R., 2017, INT C COMP VIS ICCV
   ROS G, 2016, PROC CVPR IEEE, P3234, DOI DOI 10.1109/CVPR.2016.352
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wu Z., 2016, CORR
   Xie J, 2016, PROC CVPR IEEE, P3688, DOI 10.1109/CVPR.2016.401
NR 15
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 1067
EP 1073
DI 10.1109/CVPRW.2018.00141
UT WOS:000457636800134
ER

PT S
AU Levy, D
   Belfer, Y
   Osherov, E
   Bigal, E
   Scheinin, AP
   Nativ, H
   Tchernov, D
   Treibitz, T
AF Levy, Deborah
   Belfer, Yuval
   Osherov, Elad
   Bigal, Eyal
   Scheinin, Aviad P.
   Nativ, Hagai
   Tchernov, Dan
   Treibitz, Tali
GP IEEE
TI Automated Analysis of Marine Video With Limited Data
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB Monitoring of the marine environment requires large amounts of data, simply due to its vast size. Therefore, underwater autonomous vehicles and drones are increasingly deployed to acquire numerous photographs. However, ecological conclusions from them are lagging as the data requires expert annotation and thus realistically cannot be manually processed. This calls for developing automatic classification algorithms dedicated for this type of data. Current out-of-the-box solutions struggle to provide optimal results in these scenarios as the marine data is very different from everyday data. Images taken under water display low contrast levels and reduced visibility range thus making objects harder to localize and classify. Scale varies dramatically because of the complex 3 dimensionality of the scenes. In addition, the scarcity of labeled marine data prevents training these dedicated networks from scratch. In this work, we demonstrate how transfer learning can be utilized to achieve high quality results for both detection and classification in the marine environment. We also demonstrate tracking in videos that enables counting and measuring the organisms. We demonstrate the suggested method on two very different marine datasets, an aerial dataset and an underwater one.
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   [Anonymous], 2017, AUT SHARK DET UAV
   Balk H., 2000, AQUATIC LIVING RESOU, V13
   Berman D., 2017, P BRIT MACH VIS C BM
   Bertrand A., 2000, ICES J MARINE SCI, V57
   Bewley A., 2016, P IEEE ICIP
   Casella E, 2017, CORAL REEFS, V36, P269, DOI 10.1007/s00338-016-1522-0
   Cutter G., 2015, P IEEE APPL COMP VIS
   Deng J., 2009, P IEEE CVPR
   Durban J. W., 2016, MARINE MAMMAL SCI, V32
   Fisheries N. D., 2017, DRONES DETECT SHARKS
   Fukunaga K., 2013, INTRO STAT PATTERN R
   Girshick R., 2015, P IEEE ICCV
   Girshick R., 2014, P IEEE CVPR
   Goebel ME, 2015, POLAR BIOL, V38, P619, DOI 10.1007/s00300-014-1625-4
   Goodfellow I. J., 2013, P IEEE ICML
   Harvey E., 2002, FISHERIES RES, V57
   He K, 2016, IEEE INT CONF MULTI
   Hodgson A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079556
   Holmes J. A., 2006, ICES J MARINE SCI, V63
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   KALMAN R.E, 1960, J BASIC ENG
   Kim C, 2015, INT CONF ASIC
   Kingma D., 2014, ARXIV14126980
   Kinzey Douglas, 2003, Journal of Cetacean Research and Management, V5, P159
   Kiszka J. J., 2016, MARINE ECOLOGY PROGR, V560
   Krizhevsky A., 2012, P IEEE NIPS
   Kuhn H. W., 1955, NAVAL RES LOGISTICS, V2
   Le Cun B. B., 1990, P IEEE NIPS
   Letessier TB, 2017, BIOL REV, V92, P627, DOI 10.1111/brv.12246
   Li X., 2015, P MTS IEEE OCEANS
   Lin T. Y., 2014, P ECCV
   Lin T.-Y., 2017, P IEEE CVPR
   Lin  TY, 2017, ARXIV170802002
   Liu W., 2016, P ECCV
   Marburg A., 2016, P MTS IEEE OCEANS
   Morais E. F., 2005, P IEEE BRAZ S COMP G
   Osherov E., 2017, P IEEE ICCV
   Pan S. J., 2010, IEEE T KNOWLEDGE DAT, V2
   Pavuluri VK, 2015, IEEE VEHICLE POWER
   Pepik B., 2015, GERM C PATT REC
   Redmon J., 2016, P IEEE CVPR
   Redmon J., 2017, P IEEE CVPR
   Reid D. B., 1979, IEEE T AUTOMATIC CON
   Ren S., 2015, P IEEE NIPS
   Robbins WD, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083456
   Shrivakshan G., 2012, IJCSI INT J COMPUTER, V9
   Spampinato C., 2008, VISAPP
   Spampinato C., 2012, VISAPP
   Srivastava N., 2014, IJML, V15
   Sung M, 2017, OCEANS-IEEE
   Tripathi S., 2016, ARXIV160704648
   Ventura D., 2016, ESTUARINE COASTAL SH, V171
   Wan L., 2013, P IEEE ICML
   Xie Y., 1997, PACIFIC SALMON COMMI, P11
   Zeiler M. D., 2014, P ECCV
   Zhou J., 2006, P IEEE CAN C COMP RO
   Zivkovic Z., 2004, IEEE P ICPR
NR 58
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 1466
EP 1474
DI 10.1109/CVPRW.2018.00187
UT WOS:000457636800180
ER

PT S
AU Singh, A
   Nigam, A
AF Singh, Avantika
   Nigam, Aditya
GP IEEE
TI Encapsulating the impact of transfer learning, domain knowledge and
   training strategies in deep-learning based architecture: A biometric
   based case study
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB In this paper, efforts have been made to analyze the impact of training strategies, transfer learning and domain knowledge on two biometric-based problems namely: three class oculus classification and fingerprint sensor classification. For analyzing these problems we have considered deep-learning based architecture and evaluated our results on benchmark contact-lens datasets like IIIT-D, ND, IIT-K ( our model is publicly available) and on fingerprint datasets like FVC-2002, FVC-2004, FVC-2006, IIITD-MOLF, IIT-K. In-depth feature analysis of various proposed deep-learning models has been done in order to infer that indeed training in different ways along with transfer learning and domain knowledge plays a vital role in deciding the learning ability of any network.
CR Agarwal A, 2016, INT C PATT RECOG, P3001, DOI 10.1109/ICPR.2016.7900094
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Raghavendra R, 2017, IEEE WINT CONF APPL, P1160, DOI 10.1109/WACV.2017.134
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
NR 4
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 1947
EP 1949
DI 10.1109/CVPRW.2018.00242
UT WOS:000457636800235
ER

PT S
AU Khademi, M
   Schulte, O
AF Khademi, Mahmoud
   Schulte, Oliver
GP IEEE
TI Image Caption Generation with Hierarchical Contextual Visual Spatial
   Attention
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB We present a novel context-aware attention-based deep architecture for image caption generation. Our architecture employs a Bidirectional Grid LSTM, which takes visual features of an image as input and learns complex spatial patterns based on two-dimensional context, by selecting or ignoring its input. The Grid LSTM has not been applied to image caption generation task before. Another novel aspect is that we leverage a set of local region-grounded texts obtained by transfer learning. The region-grounded texts often describe the properties of the objects and their relationships in an image. To generate a global caption for the image, we integrate the spatial features from the Grid LSTM with the local region-grounded texts, using a two-layer Bidirectional LSTM. The first layer models the global scene context such as object presence. The second layer utilizes a novel dynamic spatial attention mechanism, based on another Grid LSTM, to generate the global caption word-by-word, while considering the caption context around a word in both directions. Unlike recent models that use a soft attention mechanism, our dynamic spatial attention mechanism considers the spatial context of the image regions. Experimental results on MS-COCO dataset show that our architecture outperforms the state-of-the-art.
CR Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen X., 2014, ARXIV14115654
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Denkowski M., 2014, P 9 WORKSH STAT MACH
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K, 2015, ARXIV151203385
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Johnson  Justin, 2015, ARXIV151107571
   Kalchbrenner N., 2015, ARXIV150701526
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R., 2014, P 31 INT C MACH LEAR, P595
   Krishna R., 2016, ARXIV160207332
   Kumar  A., 2016, P INT C MACH LEARN, P1378
   Lebret R., 2015, ARXIV150203671
   Lu  J., 2017, P IEEE C COMP VIS PA, V6
   Mao J., 2015, ABS150406692 CORR
   Mao J., 2014, ARXIV14126632
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Vinyals  Oriol, 2014, ABS14114555 CORR
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xiong C, 2016, ARXIV160301417
   Xu Kelvin, 2015, ARXIV150203044, V2, P5
   Yang  Zhilin, 2016, ADV NEURAL INFORM PR, P2361
   Yao T., 2016, ARXIV161101646
   You Q., 2016, ABS160303925
NR 29
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 2024
EP 2032
DI 10.1109/CVPRW.2018.00260
UT WOS:000457636800253
ER

PT S
AU Ranjan, R
   De Mello, S
   Kautz, J
AF Ranjan, Rajeev
   De Mello, Shalini
   Kautz, Jan
GP IEEE
TI Light-weight Head Pose Invariant Gaze Tracking
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
AB Unconstrained remote gaze tracking using off-the-shelf cameras is a challenging problem. Recently, promising algorithms for appearance-based gaze estimation using convolutional neural networks (CNN) have been proposed. Improving their robustness to various confounding factors including variable head pose, subject identity, illumination and image quality remain open problems. In this work, we study the effect of variable head pose on machine learning regressors trained to estimate gaze direction. We propose a novel branched CNN architecture that improves the robustness of gaze classifiers to variable head pose, without increasing computational cost. We also present various procedures to effectively train our gaze network including transfer learning from the more closely related task of object viewpoint estimation and from a large high-fidelity synthetic gaze dataset, which enable our ten times faster gaze network to achieve competitive accuracy to its current state-of-the-art direct competitor.
CR Chuang MC, 2014, IEEE COMPUT SOC CONF, P165, DOI 10.1109/CVPRW.2014.30
   Deng H, 2017, IEEE I CONF COMP VIS, P3162, DOI 10.1109/ICCV.2017.341
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hinton  G., 2015, ARXIV150302531
   Huang Q., 2015, ARXIV150801244
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LECUN Y, 1995, NEURAL NETW STAT MEC, V261, P276
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Mora K. A. F, 2012, P IEEE COMP SOC C CO, P25
   Mora KAF, 2014, PROC CVPR IEEE, P1773, DOI 10.1109/CVPR.2014.229
   Patney Anjul, 2016, ACM SIGGRAPH 2016 EM, P17
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrivastava Ashish, 2017, P IEEE C COMP VIS PA, V3, P6
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Smith B. A., 2013, P 26 ANN ACM S US IN, P271, DOI DOI 10.1145/2501988.2501994
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Wang K, 2017, IEEE I CONF COMP VIS, P1003, DOI 10.1109/ICCV.2017.114
   Wood E, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P131, DOI 10.1145/2857491.2857492
   Wood E, 2016, LECT NOTES COMPUT SC, V9905, P297, DOI 10.1007/978-3-319-46448-0_18
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Zeiler M. D., 2014, EUR C COMP VIS, P818, DOI DOI 10.1007/978-3-319-10590-1_53
   Zeng HQ, 2017, PROC INT CONF RECON
   Zhang X., 2017, IEEE T PATTERN ANAL
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
NR 27
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 2237
EP 2245
DI 10.1109/CVPRW.2018.00290
UT WOS:000457636800283
ER

PT S
AU Mormont, R
   Geurts, P
   Maree, R
AF Mormont, Romain
   Geurts, Pierre
   Maree, Raphael
GP IEEE
TI Comparison of deep transfer learning strategies for digital pathology
SO PROCEEDINGS 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 18-22, 2018
CL Salt Lake City, UT
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION; CANCER
AB In this paper, we study deep transfer learning as a way of overcoming object recognition challenges encountered in the field of digital pathology. Through several experiments, we investigate various uses of pre-trained neural network architectures and different combination schemes with random forests for feature selection. Our experiments on eight classification datasets show that densely connected and residual networks consistently yield best performances across strategies. It also appears that network fine-tuning and using inner layers features are the best performing strategies, with the former yielding slightly superior results.
CR Antony J, 2016, INT C PATT RECOG, P1195, DOI 10.1109/ICPR.2016.7899799
   Bar Y, 2015, I S BIOMED IMAGING, P294, DOI 10.1109/ISBI.2015.7163871
   Bayramoglu N, 2016, LECT NOTES COMPUT SC, V9915, P532, DOI 10.1007/978-3-319-49409-8_46
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chollet  F., 2015, KERAS
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kieffer B., 2017, ARXIV171005726
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Kraus OZ, 2017, MOL SYST BIOL, V13, DOI 10.15252/msb.20177551
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Maree R, 2016, I S BIOMED IMAGING, P1033, DOI 10.1109/ISBI.2016.7493442
   Maree R., 2017, J PATHOLOGY INFORN, V8
   Maree R, 2016, BIOINFORMATICS, V32, P1395, DOI 10.1093/bioinformatics/btw013
   Maree R, 2016, PATTERN RECOGN LETT, V74, P17, DOI 10.1016/j.patrec.2016.01.006
   McCann M., 2014, IEEE SIGNAL PROCESSI
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176.ARXIV:1312.6229
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C., 2017, AAAI, V4, P12
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler M. D., 2014, EUR C COMP VIS, P818, DOI DOI 10.1007/978-3-319-10590-1_53
NR 41
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-6100-0
PY 2018
BP 2343
EP 2352
DI 10.1109/CVPRW.2018.00303
UT WOS:000457636800296
ER

PT B
AU Bonini, RC
   Da Silva, FL
   Glatt, R
   Spina, E
   Costa, AHR
AF Bonini, Rodrigo Cesar
   Da Silva, Felipe Leno
   Glatt, Ruben
   Spina, Edison
   Reali Costa, Anna Helena
GP IEEE
TI A Framework to Discover and Reuse Object-Oriented Options in
   Reinforcement Learning
SO 2018 7TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS)
CT 7th Brazilian Conference on Intelligent Systems (BRACIS)
CY OCT 22-25, 2018
CL IBM Res, Sao Paulo, BRAZIL
HO IBM Res
DE reinforcement learning; transfer learning; object-oriented options
AB Reinforcement Learning is a successful yet slow technique to train autonomous agents. Option-based solutions can be used to accelerate learning and to transfer learned behaviors across tasks by encapsulating a partial policy. However, commonly these options are specific for a single task, do not take in account similar features between tasks and may not correspond exactly to an optimal behavior when transferred to another task. Therefore, unprincipled transfer might provide bad options to the agent, hampering the learning process. We here propose a way to discover and reuse learned object-oriented options in a probabilistic way in order to enable better actuation choices to the agent in multiple different tasks. Our experimental evaluation show that our proposal is able to learn and successfully reuse options across different tasks.
CR Bacon P.-L., 2017, AAAI, P1726
   Barto A., 2009, ADV NEURAL INFORM PR, V22, P1015
   Bernstein D. S., 1999, TECH REP
   Bonini R. C., 2017, AAAI WORKSH HUM MACH, P1
   Brunskill E., 2014, P 31 INT C MACH LEAR, P316
   Butz M. V., 2004, URBANA, V51, P61801
   Diuk C., 2008, P 25 INT C MACH LEAR, P240
   Fernandez F., 2006, P 5 INT JOINT C AUT, P720
   Glatt R., 2017, WORKSH SCAL UP REINF, P1
   Glatt R, 2016, PROCEEDINGS OF 2016 5TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS 2016), P91, DOI [10.1109/BRACIS.2016.17, 10.1109/BRACIS.2016.027]
   Koga ML, 2015, IEEE T CYBERNETICS, V45, P77, DOI 10.1109/TCYB.2014.2319733
   Macglashan J., 2013, THESIS
   Madden MG, 2004, ARTIF INTELL REV, V21, P375, DOI 10.1023/B:AIRE.0000036264.95672.64
   McGovern A., 1997, GRACE HOPPER CELEBRA, V1317
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ng AY, 2006, SPRINGER TRAC ADV RO, V21, P363
   Pickett M., 2002, P 19 INT C MACH LEAR, V2, P506
   Roijers D. M., 2014, SURVEY MULTIOBJECTIV
   Silva F. L., 2018, IJCAI
   Silva F. L., 2017, AAMAS WORKSH TRANSF
   Subramanian K., 2011, IJCAI
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   TESAURO G, 1994, NEURAL COMPUT, V6, P215, DOI 10.1162/neco.1994.6.2.215
   Topin N, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3856
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
NR 27
TC 0
Z9 0
BN 978-1-5386-8023-0
PY 2018
BP 109
EP 114
DI 10.1109/BRACIS.2018.00027
UT WOS:000457627300019
ER

PT B
AU Bispo, A
   Prudencio, R
   Veras, D
AF Bispo, Alysson
   Prudencio, Ricardo
   Veras, Douglas
GP IEEE
TI Instance Selection and Class Balancing Techniques for Cross Project
   Defect Prediction
SO 2018 7TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS)
CT 7th Brazilian Conference on Intelligent Systems (BRACIS)
CY OCT 22-25, 2018
CL IBM Res, Sao Paulo, BRAZIL
HO IBM Res
DE Software defect prediction; Cross-project; Transfer learning
ID METRICS
AB Various software metrics and statistical models have been developed to help companies to predict software defects. Traditional software defect prediction approaches use historical data about previous bugs on a project in order to build predictive machine learning models. However, in many cases the historical testing data available in a project is scarce, i.e., very few or even no labeled training instances are available, which will result on a low quality defect prediction model. In order to overcome this limitation, Cross-Project Defect Prediction (CPDP) can be adopted to learn a defect prediction model for a project of interest (i.e., a target project) by reusing (transferring) data collected from several previous projects (i.e., source projects). In this paper, we focused on neighborhood-based instance selection techniques for CPDP which select labeled instances in the source projects that are similar to the unlabeled instances available in the target project. Despite its simplicity, these techniques have limitations which were addressed in our work. First, although they can select representative source instances, the quality of the selected instances is usually not addressed. Additionally, bug prediction datasets are normally unbalanced (i.e., there are more nondefect instances than defect ones), which can harm learning performance. In this paper, we proposed a new transfer learning approach for CPDP, in which instances selected by a neighborhood-based technique are filtered by the FuzzyRough Instance Selection (FRIS) technique in order to remove noisy instances in the training set. Following, in order to solve class balancing problems, the Synthetic Minority Oversampling Technique (SMOTE) technique is adopted to oversample the minority (defect-prone) class, thus increasing the chance of finding bugs correctly. Experiments were performed on a benchmark set of Java projects, achieving promising results.
CR Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420
   Canfora G, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION AND VALIDATION (ICST 2013), P252, DOI 10.1109/ICST.2013.38
   Catal C, 2011, EXPERT SYST APPL, V38, P4626, DOI 10.1016/j.eswa.2010.10.024
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   CHIDAMBER SR, 1994, IEEE T SOFTWARE ENG, V20, P476, DOI 10.1109/32.295895
   Hall T, 2012, IEEE T SOFTWARE ENG, V38, P1276, DOI 10.1109/TSE.2011.103
   Jensen R, 2010, FUZZ SYST FUZZ 2010, V23, P1
   Jureczko M., 6 INT C PRED MOD SOF
   Jureczko M., 2010, MODELS METHODS SYSTE, P69
   Kabacoff R. I., 2010, R IN ACTION
   Kim S, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P481, DOI 10.1145/1985793.1985859
   Liu Y, 2010, IEEE T SOFTWARE ENG, V36, P852, DOI 10.1109/TSE.2010.51
   Ma Y, 2012, INFORM SOFTWARE TECH, V54, P248, DOI 10.1016/j.infsof.2011.09.007
   Menzies T, 2010, AUTOMAT SOFTW ENG, V17, P375, DOI 10.1007/s10515-010-0069-5
   Nam J., 2014, TECH REP
   Nam J, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P382, DOI 10.1109/ICSE.2013.6606584
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Peters Fayola, 2013, 2013 10th IEEE Working Conference on Mining Software Repositories (MSR 2013), P409, DOI 10.1109/MSR.2013.6624057
   Shepperd M, 2013, IEEE T SOFTWARE ENG, V39, P1208, DOI 10.1109/TSE.2013.11
   Turhan B, 2009, EMPIR SOFTW ENG, V14, P540, DOI 10.1007/s10664-008-9103-7
   Yu X., 2017, 29 INT C SOFTW ENG K
   Zhang  F., 2014, P 11 WORK C MIN SOFT, P182
   Zhang F, 2016, PROC INT CONF SOFTW, P309, DOI 10.1145/2884781.2884839
   Zimmerman T, 2009, 7TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P91, DOI 10.1145/1595696.1595713
NR 25
TC 0
Z9 0
BN 978-1-5386-8023-0
PY 2018
BP 552
EP 557
DI 10.1109/BRACIS.2018.00101
UT WOS:000457627300093
ER

PT B
AU He, M
   Zhang, JL
   Yang, P
   Yao, KS
AF He, Ming
   Zhang, Jiuling
   Yang, Peng
   Yao, Kaisheng
GP ACM
TI Robust Transfer Learning for Cross-domain Collaborative Filtering Using
   Multiple Rating Patterns Approximation
SO WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB
   SEARCH AND DATA MINING
CT 11th ACM International Conference on Web Search and Data Mining
CY FEB 05-09, 2018
CL Marina Del Rey, CA
ID RECOMMENDATION; ALGORITHM
AB Collaborative filtering techniques are a common approach for building recommendations, and have been widely applied in real recommender systems. However, collaborative filtering usually suffers from limited performance due to the sparsity of user-item interaction. To address this issue, auxiliary information is usually used to improve the performance. Transfer learning provides the key idea of using knowledge from auxiliary domains. An assumption of transfer learning in collaborative filtering is that the source domain is a full rating matrix, which may not hold in many real-world applications. In this paper, we investigate how to leverage rating patterns from multiple incomplete source domains to improve the quality of recommender systems. First, by exploiting the transferred learning, we compress the knowledge from the source domain into a cluster-level rating matrix. The rating patterns in the low-level matrix can be transferred to the target domain. Specifically, we design a knowledge extraction method to enrich rating patterns by relaxing the full rating restriction on the source domain. Finally, we propose a robust multiple-rating-pattern transfer learning model for cross-domain collaborative filtering, which is called MINDTL, to accurately predict missing values in the target domain. Extensive experiments on real-world datasets demonstrate that our proposed approach is effective and outperforms several alternative methods.
CR Abdollahi B, 2016, P INT C COMP WORLD W, P5, DOI DOI 10.1145/2872518.2889405
   Alfeld M, 2017, MICROCHEM J, V132, P179, DOI 10.1016/j.microc.2017.02.001
   Alqadah F, 2015, KNOWL INF SYST, V44, P475, DOI 10.1007/s10115-014-0771-x
   Bokde D, 2015, PROCEDIA COMPUT SCI, V49, P136, DOI 10.1016/j.procs.2015.04.237
   Chinnu P., 2016, INT J COMPUTER APPL, V133
   Ding  C., 2006, P 12 ACM SIGKDD INT, P126, DOI DOI 10.1145/1150402.1150420
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Fang Z, 2015, 2015 IEEE International Conference on Data Mining Workshop (ICDMW), P1235, DOI 10.1109/ICDMW.2015.133
   Fu JJ, 2016, SYST CONTROL LETT, V93, P1, DOI 10.1016/j.sysconle.2016.03.006
   Gao S., 2011, P 20 ACM INT C INF K, P1169
   Grolman E, 2016, KNOWL-BASED SYST, V107, P70, DOI 10.1016/j.knosys.2016.05.057
   Ji K, 2016, NEUROCOMPUTING, V173, P912, DOI 10.1016/j.neucom.2015.08.046
   Ji K, 2015, NEUROCOMPUTING, V165, P228, DOI 10.1016/j.neucom.2015.03.013
   Jiang M, 2015, IEEE T KNOWL DATA EN, V27, P3084, DOI 10.1109/TKDE.2015.2432811
   Kiers HAL, 2002, COMPUT STAT DATA AN, V41, P157, DOI 10.1016/S0167-9473(02)00142-1
   Kumar V, 2017, INFORM SCIENCES, V380, P1, DOI 10.1016/j.ins.2016.11.003
   Langseth H., 2015, SCALABLE LEARNING PR
   Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454
   Li B, 2015, IEEE T CYBERNETICS, V45, P1054, DOI 10.1109/TCYB.2014.2343982
   Li B, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2052
   Li JQ, 2017, IEEE ACCESS, V5, P35, DOI 10.1109/ACCESS.2016.2600258
   Li X, 2017, NEUROCOMPUTING, V230, P197, DOI 10.1016/j.neucom.2016.12.024
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Liu JX, 2016, IEEE T SERV COMPUT, V9, P686, DOI 10.1109/TSC.2015.2433251
   Liu XF, 2017, CONT TRENDS ISS SCI, V45, P1
   Moreno O., 2012, P 21 ACM INT C INF K, P425
   Santos A, 2017, IEEE T INSTRUM MEAS, V66, P661, DOI 10.1109/TIM.2017.2663478
   Vander Aa T, 2016, IEEE INT C CL COMP, P346, DOI 10.1109/CLUSTER.2016.13
   Wang Yu Xiang, 2012, COMPUTER SCI NUMERIC, V49, P136
   Wu X., 1939, IEEE T SERV COMPUT, V10. 3, P352
   Yu YH, 2017, APPL INTELL, V46, P521, DOI 10.1007/s10489-016-0841-8
   Zhao LL, 2017, ARTIF INTELL, V245, P38, DOI 10.1016/j.artint.2016.12.004
   Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003
NR 33
TC 0
Z9 0
BN 978-1-4503-5581-0
PY 2018
BP 225
EP 233
DI 10.1145/3159652.3159675
UT WOS:000456363600032
ER

PT B
AU Yu, JF
   Qiu, MH
   Jiang, J
   Huang, J
   Song, SY
   Chu, W
   Chen, HQ
AF Yu, Jianfei
   Qiu, Minghui
   Jiang, Jing
   Huang, Jun
   Song, Shuangyong
   Chu, Wei
   Chen, Haiqing
GP ACM
TI Modelling Domain Relationships for Transfer Learning on Retrieval-based
   Question Answering Systems in E-commerce
SO WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB
   SEARCH AND DATA MINING
CT 11th ACM International Conference on Web Search and Data Mining
CY FEB 05-09, 2018
CL Marina Del Rey, CA
AB Nowadays, it is a heated topic for many industries to build automatic question-answering (QA) systems. A key solution to these QA systems is to retrieve from a QA knowledge base the most similar question of a given question, which can be reformulated as a paraphrase identification (PI) or a natural language inference (NLI) problem. However, most existing models for PI and NLI have at least two problems: They rely on a large amount of labeled data, which is not always available in real scenarios, and they may not be efficient for industrial applications.
   In this paper, we study transfer learning for the PI and NLI problems, aiming to propose a general framework, which can effectively and efficiently adapt the shared knowledge learned from a resource-rich source domain to a resource-poor target domain. Specifically, since most existing transfer learning methods only focus on learning a shared feature space across domains while ignoring the relationship between the source and target domains, we propose to simultaneously learn shared representations and domain relationships in a unified framework. Furthermore, we propose an efficient and effective hybrid model by combining a sentence encoding-based method and a sentence interaction-based method as our base model. Extensive experiments on both paraphrase identification and natural language inference demonstrate that our base model is efficient and has promising performance compared to the competing models, and our transfer learning method can help to significantly boost the performance. Further analysis shows that the inter-domain and intra-domain relationship captured by our model are insightful. Last but not least, we deploy our transfer learning model for PI into our online chatbot system, which can bring in significant improvements over our existing system.
CR Argyriou Andreas, 2007, NIPS
   arikh Ankur P, 2016, EMNLP
   Blitzer John, 2006, EMNLP
   Bowman S. R., 2015, EMNLP
   Bowman Samuel R., 2016, ACL
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Chen Qian, 2017, ACL
   Cui L, 2017, IEEE C ELEC DEVICES
   Dai Wenyuan, 2007, ICML
   Daume Hal, 2007, ACL
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gillick Laurence, 1989, ICASSP
   Hu Baotian, 2014, NIPS
   Jeon Jiwoon, 2005, CIKM
   Jiang J., 2007, ACL
   Kusner M. J., 2015, ICML
   Lee Su-In, 2007, ICML
   Liu Pengfei, 2017, ACL
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Mou Lili, 2016, ACL
   Mou Lili, 2016, EMNLP
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pang Liang, 2016, AAAI
   Pennington  Jeffrey, 2014, EMNLP
   Qiu Minghui, 2017, ICDM
   Qiu Minghui, 2017, ACL
   Rocktaschel Tim, 2015, ICLR
   Socher Richard, 2011, NIPS
   Taigman Y., 2017, ICLR
   Vinyals O., 2015, ARXIV150605869
   Wang Chang, 2008, ICML
   Wang Di, 2015, ACL IJCNLP
   Wang Dong, 2015, SIGN INF PROC ASS AN
   Wang  Shuohang, 2017, ICLR
   Wieting John, 2016, ICLR
   Williams Adina, 2017, ARXIV170405426
   Wu HC, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361686
   Yan Rui, 2016, SIGIR
   Yang Zhilin, 2017, ICLR
   Yin W., 2016, T ASS COMPUT LINGUIS, V4, P259
   Yin Wenpeng, 2015, NAACL HLT
   Yosinski J., 2014, NIPS
   Yu Jianfei, 2016, EMNLP
   Zhang Yu, 2010, UAI
NR 45
TC 0
Z9 0
BN 978-1-4503-5581-0
PY 2018
BP 682
EP 690
DI 10.1145/3159652.3159685
UT WOS:000456363600083
ER

PT B
AU Xu, JJ
   Tong, HH
   Lu, TC
   He, JR
   Bliss, N
AF Xu, Jiejun
   Tong, Hanghang
   Lu, Tsai-Ching
   He, Jingrui
   Bliss, Nadya
GP ACM
TI GTA(3) 2018: Workshop on Graph Techniques for Adversarial Activity
   Analytics
SO WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB
   SEARCH AND DATA MINING
CT 11th ACM International Conference on Web Search and Data Mining
CY FEB 05-09, 2018
CL Marina Del Rey, CA
AB Networks are natural analytic tools in modeling adversarial activities (e.g., human trafficking, illicit drug production, terrorist financial transaction) using different intelligence data sources. However, such activities are often covert and embedded across multiple domains and contexts. They are generally not detectable and recognizable from the perspective of an isolated network, and only become apparent when multiple networks are analyzed in a joint manner. Thus, one of the main research topics in modeling adversarial activities is to develop effective techniques to align and fuse information from different networks into a unified representation for global analysis. Based on the combined network representation, an equally important research topic is on detecting and matching indicating patterns to recognize the underlining adversarial activities in the integrated network. Two key challenge problems involved in the modeling process include:
   Network alignment and merging: develop accurate and scalable methods for mapping of nodes across heterogeneous networks based on different associational and causal dependencies.
   Subgraph detection and matching: develop robust and efficient algorithms for richly attributed networks to support recognition of complex query patterns for networks.
   The focus of this workshop is to gather together the researchers from all relevant fields to share their experience and opinions on graph mining techniques in the era of big data, with emphasis on two fundamental problems - "Connecting the dots" and "finding a needle in a haystack", in the context of graph-based adversarial activity analytics. A best paper will be selected and announced in our workshop based on the collective feedback from our reviewers.
   This workshop (co-located with the 11th ACM Conference on Web Search and Data Mining) aims to bring together a cross-disciplinary audience of researchers from both academia and industry to share experience with techniques, resources and best practices, and to exchange perspectives and future directions. We expect the workshop to develop a community of interested researchers and facilitate their future collaborations.
   Topics of Interest
   Data integration and alignment from multiple heterogeneous networks
   Novel algorithms for subgraph detection and matching in large networks
   Graph construction and modeling for different domains (e.g., financial fraud, human trafficking,DDoS attack)
   Complex anomaly (e.g., group anomaly) detection and interpretation
   Atypical behavior and rare event detection
   Limits of detectability and identifiability
   Evolution analysis and forecasting
   Game theoretic approach on anticipating opponent intents and actions
   Identification of novel datasets and/or evaluation metrics
   Multilayer and multiplex network analytics
   Clustering and ranking methods for composite networks
   Large-scaled link prediction and recommendation algorithms
   Community detection in big networks
   Information diffusion and influence maximization
   Interactive visualization for big graphs
   New methods and frontiers in spectral graph theory
   Analysis of network topologies (e.g., centrality and network motif analysis)
   Semi-supervised learning, Transductive inference, Active learning, and Transfer learning
NR 0
TC 0
Z9 0
BN 978-1-4503-5581-0
PY 2018
BP 803
EP 803
DI 10.1145/3159652.3160595
UT WOS:000456363600114
ER

PT B
AU Serra, E
   Sharma, A
   Joaristi, M
   Korzh, O
AF Serra, Edoardo
   Sharma, Ashish
   Joaristi, Mikel
   Korzh, Oxana
BE Brandes, U
   Reddy, C
   Tagarelli, A
TI Unknown Landscape Identification with CNN Transfer Learning
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS
   ANALYSIS AND MINING (ASONAM)
CT IEEE/ACM International Conference on Advances in Social Networks
   Analysis and Mining (ASONAM)
CY AUG 28-31, 2018
CL Barcelona, SPAIN
ID CLASSIFICATION
AB Unknown landscape identification is the problem of identifying an unknown landscape from a set of already provided landscape images that are considered to be known. The aim of this work is to extract the intrinsic semantic of landscape images in order to automatically generalize concepts like a stadium, roads, a parking lot etc., and use this concept to identify unknown landscapes. This problem can be easily extended to many security applications. We propose two effective semi-supervised novelty detection approaches for the unknown landscape identification problem using Convolutional Neural Network (CNN) Transfer Learning. This is based on the use of pre-trained CNNs (i.e. already trained on large datasets) already containing general image knowledge that we transfer to our domain. Our best values of AUROC and Average Precision scores for the identification problem are 0.96 and 0.94, respectively. In addition, we statistically prove that our semi-supervised methods outperform the baseline.
CR Agarwal D, 2007, KNOWL INF SYST, V11, P29, DOI 10.1007/s10115-006-0036-4
   Dai DX, 2011, IEEE GEOSCI REMOTE S, V8, P173, DOI 10.1109/LGRS.2010.2055033
   Deng J., 2009, CVPR 09
   Han J, 2005, DATA MINING CONCEPTS
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Marsland S., 2003, NEURAL COMP SURVEYS
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026
   Reyes A.K., 2015, FINE TUNING DEEP CON
   Sabokrou M., 2016, ARXIV160900866
   Shamir L., 2013, THEORY APPL MATH COM, V3, P13
   Shin H., 2016, IEEE T MED IMAGING
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 19
TC 0
Z9 0
BN 978-1-5386-6051-5
PY 2018
BP 813
EP 820
UT WOS:000455640600142
ER

PT B
AU Dalal, R
   Moh, TS
AF Dalal, Rahul
   Moh, Teng-Sheng
BE Brandes, U
   Reddy, C
   Tagarelli, A
TI Fine-Grained Object Detection Using Transfer Learning and Data
   Augmentation
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS
   ANALYSIS AND MINING (ASONAM)
CT IEEE/ACM International Conference on Advances in Social Networks
   Analysis and Mining (ASONAM)
CY AUG 28-31, 2018
CL Barcelona, SPAIN
DE Object Detection; Computer Vision; Deep Learning; Convolutional Neural
   Networks; Region based Convolutional Neural Network; Inception; You Only
   Look Once; Single Shot Detection
AB Object detection plays a vital role in many real-world computer vision applications such as self-driving cars, human-less stores and general purpose robotic systems. Convolutional Neural Network(CNN) based Deep Learning has evolved to become the backbone of most computer vision algorithms, including object detection. Most of the research has focused on detecting objects that differ significantly e.g. a car, a person, and a bird. Achieving fine-grained object detection to detect different types within one class of objects can be crucial in tasks like automated retail checkout. This research has developed deep learning models to detect 200 types of similar birds. The models were trained and tested on CUB-200-2011 dataset. To the best of our knowledge, by attaining a mean Average Precision (mAP) of 71.5% we achieved an improvement of 5 percentage points over the previous best mAP of 66.2%.
CR Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R., 2015, IEEE INT C COMP VIS
   Girshick R., 2015, REGION BASED CONVOLU
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M., 2013, ABS13124400 CORR
   Lin T.-Y., 2014, ECCV
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2016, ARXIV161208242
   Redmon Joseph, 2015, ARXIV150602640
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sermanet P, 2014, INT C LEARN REPR ICL
   Szegedy C., 2014, ABS14094842 CORR
   Turner J. T., 2015, ABS160300502 CORR
   Wah C., CALTECH UCSD BIRDS 2
NR 14
TC 0
Z9 0
BN 978-1-5386-6051-5
PY 2018
BP 893
EP 896
UT WOS:000455640600154
ER

PT B
AU Skryzalin, J
   Link, H
   Wendt, J
   Field, R
   Richter, SN
AF Skryzalin, Jacek
   Link, Hamilton
   Wendt, Jeremy
   Field, Richard
   Richter, Samuel N.
BE Brandes, U
   Reddy, C
   Tagarelli, A
TI Efficient transfer learning for neural network language models
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS
   ANALYSIS AND MINING (ASONAM)
CT IEEE/ACM International Conference on Advances in Social Networks
   Analysis and Mining (ASONAM)
CY AUG 28-31, 2018
CL Barcelona, SPAIN
AB We apply transfer learning techniques to create topically and/or stylistically biased natural language models from small data samples, given generic long short-term memory (LSTM) language models trained on larger data sets. Although LSTM language models are powerful tools with wide-ranging applications, they require enormous amounts of data and time to train. Thus, we build general purpose language models that take advantage of large standing corpora and computational resources proactively, allowing us to build more specialized analytical tools from smaller data sets on demand. We show that it is possible to construct a language model from a small, focused corpus by first training an LSTM language model on a large corpus (e.g., the text from English Wikipedia) and then retraining only the internal transition model parameters on the smaller corpus. We also show that a single general language model can be reused through transfer learning to create many distinct special purpose language models quickly with modest amounts of data.
CR Abadi Martin, 2016, P 12 USENIX S OP SYS, P265, DOI DOI 10.1038/NN.3331
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Bowman S. R., 2016, P 54 ANN M ASS COMP, V1, P1466
   Chelba  Ciprian, 2013, ARXIV13123005
   Dyer Chris, 2016, NAACL HLT, P199
   Filippova K, 2015, P 2015 C EMP METH NA, P360
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Ghosh S, 2016, ARXIV160206291
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Howard J, 2018, ARXIV180106146
   Hu Z., 2017, P ICML 17, P1587
   Jean S., 2015, ACL ICJNLP
   Ji S., 2016, ICLR
   Ji Y., 2015, ARXIV151103962
   Jozefowicz R., 2016, ARXIV160202410
   Kingma D., 2015, ICLR
   Li Jiwei, 2016, P 54 ANN M ASS COMP, P994, DOI DOI 10.18653/V1/P16-1094
   Lipton Z. C., 2015, CAPTURING MEANING PR
   Luong T., 2015, P 2015 C EMP METH NA, P1412, DOI DOI 10.18653/V1/D15-1166
   Manning C.D., 2014, P 52 ANN M ASS COMP, P55, DOI DOI 10.3115/V1/P14-5010
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Mueller J., 2017, INT C MACH LEARN, P2536
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pang B., 2004, P ACL
   Rush A. M., 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044
   Sak H., 2014, 15 ANN C INT SPEECH
   Shen T., 2017, P ADV NEUR INF PROC, P6833
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaswani A., 2017, ADV NEURAL INFORM PR, P6000
   Xiong C., 2016, P INT C MACH LEARN, P2397
   Yang Z., 2016, HLT NAACL, P1480
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zaremba W., 2015, ICLR
NR 33
TC 0
Z9 0
BN 978-1-5386-6051-5
PY 2018
BP 897
EP 902
UT WOS:000455640600155
ER

PT B
AU Miscikis, J
   Brijacak, I
   Yahyanejad, S
   Glette, K
   Elle, OJ
   Torresen, J
AF Miscikis, Justinas
   Brijacak, Inka
   Yahyanejad, Saeed
   Glette, Kyrre
   Elle, Ole Jakob
   Torresen, Jim
GP IEEE
TI Transfer Learning for Unseen Robot Detection and Joint Estimation on a
   Multi-Objective Convolutional Neural Network
SO 2018 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SAFETY FOR
   ROBOTICS (ISR)
CT IEEE International Conference on Intelligence and Safety for Robotics
   (ISR)
CY AUG 24-27, 2018
CL Shenyang, PEOPLES R CHINA
AB A significant problem of using deep learning techniques is the limited amount of data available for training. There are some datasets available for the popular problems like item recognition and classification or self-driving cars, however, it is very limited for the industrial robotics field. In previous work, we have trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in the image and estimate 3D positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR). In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a significantly different appearance and an additional joint. However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot having different shapes and visual features. We have proven that transfer learning is not only applicable in this field, but it requires smaller well-prepared training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.
CR Fankhauser P., 2015, IEEE INT C ADV UNPUB
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Heikkila T, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P2292, DOI 10.1109/IROS.2000.895310
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lee Jay, 2015, Manufacturing Letters, V3, P18, DOI 10.1016/j.mfglet.2014.12.001
   Mainprice J, 2013, IEEE INT C INT ROBOT, P299, DOI 10.1109/IROS.2013.6696368
   Meeussen W., 2012, URDF UNIFIED ROBOT D
   Miseikis J., 2016, COMP INT SSCI 2016 I, P1
   Miseikis J., 2018, ARXIV180403005
   Miseikis J, 2016, IEEE/SICE I S SYS IN, P735, DOI 10.1109/SII.2016.7844087
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sucan I. A., 2013, MOVEIT
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xie M., 2015, ARXIV151000098
NR 16
TC 0
Z9 0
BN 978-1-5386-5547-4
PY 2018
BP 337
EP 342
UT WOS:000455843900059
ER

PT B
AU Bonazza, P
   Miteran, J
   Ginhac, D
   Dubois, J
AF Bonazza, Pierre
   Miteran, Johel
   Ginhac, Dominique
   Dubois, Julien
GP ACM
TI PhD Forum : Machine Learning VS Transfer Learning Smart Camera
   Implementation for Face Authentication
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART
   CAMERAS (ICDSC'18)
CT 12th International Conference on Distributed Smart Cameras (ICDSC)
CY SEP 03-04, 2018
CL Eindhoven, NETHERLANDS
DE Face authentication; Machine Learning; Transfer Learning
AB The aim of this paper is to highlight differences between classical machine learning and transfer learning applied to low cost real-time face authentication. Furthermore, in an access control context, the size of biometric data should be minimized so it can be stored on a remote personal media. These constraints have led us to compare only lightest versions of these algorithms. Transfer learning applied on Mobilenet vl raises to 85% of accuracy, for a 457Ko model, with 3680s and 1.43s for training and prediction tasks. In comparison, the fastest integrated method (Random Forest) shows accuracy up to 90% for a 7,9Ko model, with a fifth of a second to be trained and a hundred of microseconds for the prediction, enabling embedded real-time face authentication at 10 fps.
RI Ginhac, Dominique/C-5088-2008
OI Ginhac, Dominique/0000-0002-5911-2010
CR Bonazza P., 2017, IM PROC C GRETS 2017
   Howard A. G., 2017, MOBILENETS EFFICIENT
   Learned-miller E., 2016, LABELED FACES WILD S
   Sandler M., 2018, MOBILENETV2 INVERTED
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
NR 5
TC 0
Z9 0
BN 978-1-4503-6511-6
PY 2018
DI 10.1145/3243394.3243710
UT WOS:000455840700021
ER

PT B
AU Bircanoglu, C
   Atay, M
   Beser, F
   Genc, O
   Kizrak, MA
AF Bircanoglu, Cenk
   Atay, Meltem
   Beser, Fuat
   Genc, Ozgun
   Kizrak, Merve Ayyuce
BE Yildirim, T
   Manolopoulos, Y
   Angelov, P
   Iliadis, L
TI RecycleNet: Intelligent Waste Sorting Using Deep Neural Networks
SO 2018 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
CT IEEE (SMC) International Conference on Innovations in Intelligent
   Systems and Applications (INISTA)
CY JUL 03-05, 2018
CL Thessaloniki, GREECE
AB Waste management and recycling is the fundamental part a sustainable economy. For more efficient and safe recycling, it is necessary to use intelligent systems instead of employing humans as workers in the dump-yards. This is one of the early works demonstrating the efficiency of latest intelligent approaches. In order to provide the most efficient approach, we experimented on well-known deep convolutional neural network architectures. For training without any pre-trained weights, Inception-Resnet, Inception-v4 outperformed all others with 90% test accuracy. For transfer learning and fine-tuning of weight parameters using ImageNet, DenseNet121 gave the best result with 95% test accuracy. One disadvantage of these networks, however, is that they are slightly slower in prediction time. To enhance the prediction performance of the models we altered the connection patterns of the skip connections inside dense blocks. Our model RecycleNet is carefully optimized deep convolutional neural network architecture for classification of selected recyclable object classes. This novel model reduced the number of parameters in a 121 layered network from 7 million to about 3 million.
CR A. Google, 2017, GOOGL COL
   Alchon Suzanne Austin, 2003, PEST LAND NEW WORLD
   Alvarez-Chavez CR, 2012, J CLEAN PROD, V23, P47, DOI 10.1016/j.jclepro.2011.10.003
   Amick DS, 2014, LITHIC TECHNOL, V39, P64, DOI 10.1179/0197726113Z.00000000025
   Awe O., 2017, SMART TRASH NET WAST
   Barles S, 2014, BASIC ENV HIST, P199
   Chollet F., 2016, XCEPTION DEEP LEARNI
   Chollet  F., 2015, KERAS
   CUMMINGS LD, 1977, J VOLUNT ACTION RES, V6, P153
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lipsett C. H., 1974, 100 YEARS RECYCLING
   Liu C, 2010, PROC CVPR IEEE, P239, DOI [10.1109/CVPR.2010.5540207, 10.1109/ICCET.2010.5485248]
   PALMER JA, 1995, ENV ED RES, V0001
   Szegedy C., 2017, AAAI, V4, P12
   Williams PT, 2005, WASTE TREATMENT AND DISPOSAL, 2ND EDITION, P1, DOI 10.1002/0470012668
   Witkowski TH, 2003, J ADVERTISING, V32, P69, DOI 10.1080/00913367.2003.10639053
   Yang M., 2016, CLASSIFICATION TRASH
   Zeiler M. D., 2012, ARXIV12125701
NR 23
TC 0
Z9 0
BN 978-1-5386-5150-6
PY 2018
UT WOS:000455620700013
ER

PT B
AU Markowska-Kaczmar, U
   Skiba, M
AF Markowska-Kaczmar, Urszula
   Skiba, Michal
BE Yildirim, T
   Manolopoulos, Y
   Angelov, P
   Iliadis, L
TI Is Convolutional Network Competitive for Vision Method in the Furniture
   Dowel Quality Control?
SO 2018 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
CT IEEE (SMC) International Conference on Innovations in Intelligent
   Systems and Applications (INISTA)
CY JUL 03-05, 2018
CL Thessaloniki, GREECE
DE deep learning; convolutional network; quality control system; production
   spoilage detection
ID NEURAL-NETWORKS
AB The paper presents a method of the furniture dowel quality control based on the convolutional neural network. We applied AlexNet, testing the ability of transfer learning. The paper presents details of the method and experiments performed to justify our solution on images datasets collected from real dowels production. The outcomes are compared with the results of baseline vision method. The experiments show that both methods have their strengths and weaknesses, but they complement each other.
CR Abdel-Hakim A. E., 2006, P IEEE COMP SOC C CO, V2, P1978, DOI DOI 10.1109/CVPR.2006.95
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   Clevert D. A, 2016, FAST ACCURATE DEEP N
   He K, 2015, DELVING DEEP RECTIFI
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vasilic S, 2006, 2006 IEEE International Symposium on Industrial Electronics, Vols 1-7, P469, DOI 10.1109/ISIE.2006.295640
   Wang T, 2018, INT J ADV MANUF TECH, V94, P3465, DOI 10.1007/s00170-017-0882-0
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 11
TC 0
Z9 0
BN 978-1-5386-5150-6
PY 2018
UT WOS:000455620700016
ER

PT B
AU Goh, GB
   Siegel, C
   Vishnu, A
   Hodas, N
AF Goh, Garrett B.
   Siegel, Charles
   Vishnu, Abhinav
   Hodas, Nathan
GP ACM
TI Using Rule-Based Labels for Weak Supervised Learning A ChemNet for
   Transferable Chemical Property Prediction
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE Bioinformatics; Cheminformatics; Computer Vision; Natural Language
   Processing; Transfer Learning; Weak Supervised Learning
ID QSAR
AB With access to large datasets, deep neural networks (DNN) have achieved human-level accuracy in image and speech recognition tasks. However, in chemistry data is inherently small and fragmented. In this work, we develop an approach of using rule-based knowledge for training ChemNet, a transferable and generalizable deep neural network for chemical property prediction that learns in a weak-supervised manner from large unlabeled chemical databases. When coupled with transfer learning approaches to predict other smaller datasets for chemical properties that it was not originally trained on, we show that ChemNet's accuracy outperforms contemporary DNN models that were trained using conventional supervised learning. Furthermore, we demonstrate that the ChemNet pre-training approach is equally effective on both CNN (Chemception) and RNN (SMILES2vec) models, indicating that this approach is network architecture agnostic and is effective across multiple data modalities. Our results indicate a pre-trained ChemNet that incorporates chemistry domain knowledge and enables the development of generalizable neural networks for more accurate prediction of novel chemical properties.
CR Abadi Martin, 2016, P 12 USENIX S OP SYS, P265, DOI DOI 10.1038/NN.3331
   BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2
   Bjerrum EJ, 2017, ARXIV170307076
   Buchwald P, 2002, DRUG FUTURE, V27, P577, DOI 10.1358/dof.2002.027.06.856934
   Cherkasov A, 2014, J MED CHEM, V57, P4977, DOI 10.1021/jm4004285
   Chodera JD, 2011, CURR OPIN STRUC BIOL, V21, P150, DOI 10.1016/j.sbi.2011.01.011
   Chollet  F., 2015, KERAS
   Dahl GE, 2014, ARXIV14061231
   Duvenaud D. K., 2015, ADV NEURAL INFORM PR, V28, P2224
   Gaulton A, 2012, NUCLEIC ACIDS RES, V40, pD1100, DOI 10.1093/nar/gkr777
   Gawehn E, 2016, MOL INFORM, V35, P3, DOI 10.1002/minf.201501008
   Goh G. B., 2017, J COMPUTATIONAL CHEM
   Goh G. B, 2017, ARXIV170606689
   Goh Garrett B, 2017, ARXIV171202034
   Goh GB, 2017, ARXIV171002238
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton G, 2012, NEURAL NETWORKS MACH, V6e
   Hughes TB, 2016, ACS CENTRAL SCI, V2, P529, DOI 10.1021/acscentsci.6b00162
   Kearnes S, 2016, J COMPUT AID MOL DES, V30, P595, DOI 10.1007/s10822-016-9938-8
   Kim S, 2016, NUCLEIC ACIDS RES, V44, pD1202, DOI 10.1093/nar/gkv951
   Kruhlak NL, 2007, ADV DRUG DELIVER REV, V59, P43, DOI 10.1016/j.addr.2006.10.008
   Landrum G., 2016, RDKIT OPEN SOURCE CH
   Mayr A, 2016, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00080
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   PLATT JR, 1947, J CHEM PHYS, V15, P419, DOI 10.1063/1.1746554
   Ramsundar B, 2015, ARXIV150202072
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shie CK, 2015, IEEE ENG MED BIO, P711, DOI 10.1109/EMBC.2015.7318461
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Todeschini R, 2008, HDB MOL DESCRIPTORS, V11
   Wallach I., 2015, ARXIV151002855
   WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005
   Wu Z., 2017, ARXIV170300564
NR 33
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 302
EP 310
DI 10.1145/3219819.3219838
UT WOS:000455346400032
ER

PT B
AU Hu, A
   Flaxman, S
AF Hu, Anthony
   Flaxman, Seth
GP ACM
TI Multimodal Sentiment Analysis To Explore the Structure of Emotions
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE Deep learning; sentiment analysis; visual analysis; transfer learning;
   natural language processing
AB We propose a novel approach to multimodal sentiment analysis using deep neural networks combining visual analysis and natural language processing. Our goal is different than the standard sentiment analysis goal of predicting whether a sentence expresses positive or negative sentiment; instead, we aim to infer the latent emotional state of the user. Thus, we focus on predicting the emotion word tags attached by users to their Tumblr posts, treating these as "self-reported emotions." We demonstrate that our multi-modal model combining both text and image features outperforms separate models based solely on either images or text. Our model's results are interpretable, automatically yielding sensible word lists associated with emotions. We explore the structure of emotions implied by our model and compare it to what has been posited in the psychology literature, and validate our model on a set of images that have been used in psychology studies. Finally, our work also provides a useful tool for the growing academic study of images-both photographs and memes-on social networks.
CR [Anonymous], 2017, DISGUSTED POST
   [Anonymous], 2017, OPTIMISTIC POST
   [Anonymous], 2017, SURPRISED POST
   [Anonymous], 2017, AMBIGUOUS SURPRISED
   [Anonymous], 2017, SAD POST
   [Anonymous], 2017, ANGRY POST
   [Anonymous], 2017, HAPPY POST
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2007, LARGE SCALE KERNEL M
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Borth Damian, 2013, ACM INT C MULT ACM M
   Chen Tao, 2015, AAAI
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Flaxman Seth, 2015, KDD
   Gilbert D. T, 2006, STUMBLING HAPPINESS
   Golder SA, 2011, SCIENCE, V333, P1878, DOI 10.1126/science.1202775
   Gong Yunchao, 2014, INT J COMPUTER VISIO, V2014
   Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174
   Guillaumin M., 2010, CVPR
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Katsurai M., 2016, ICASSP
   Kurdi B, 2017, BEHAV RES METHODS, V49, P457, DOI 10.3758/s13428-016-0715-3
   Lang P. J., 2005, TECHNICAL REPORT
   Lindquist Kristen A., 2013, 100 YEAR EMOTION WAR, P2013
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mikolov Tomas, 2011, INT C AC SPEECH SIGN
   Miller Daniel, 2017, VISUALISING FACEBOOK
   Muandet K, 2017, FOUND TRENDS MACH LE, V10, P1, DOI 10.1561/2200000060
   Pak Alexander, 2010, LREC
   Pennebaker James W., 2007, OPERATORS MANUAL
   Pennington J, 2014, EMPIRICAL METHODS NA
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Radford  Alec, 2016, ICLR
   Rosenthal S, 2017, P 11 INT WORKSH SEM, P502
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shifman L, 2014, MIT PRESS ESSENT, P1
   Sutskever  Ilya, 2014, NIPS
   Szegedy C., 2015, CVPR
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Tellegen A, 1999, PSYCHOL SCI, V10, P297, DOI 10.1111/1467-9280.00157
   Wang Y., 2015, IJCAI
   Watson D., 1999, PANAS X MANUAL POSIT
   Wojnicki Andrea C., 2008, WORD OF MOUTH SELF E
   You Q., 2015, AAAI
NR 46
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 350
EP 358
DI 10.1145/3219819.3219853
UT WOS:000455346400037
ER

PT B
AU Liu, ZY
   Shen, YY
   Zhu, YM
AF Liu, Zhaoyang
   Shen, Yanyan
   Zhu, Yanmin
GP ACM
TI Where Will Dockless Shared Bikes be Stacked? - Parking Hotspots
   Detection in a New City
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE Dockless shared bikes; hotspots detection; urban computing; transfer
   learning
AB Dockless shared bikes, which aim at providing a more flexible and convenient solution to the first-and-last mile connection, come into China and expand to other countries at a very impressing speed. The expansion of shared bike business in new cities brings many challenges among which, the most critical one is the parking chaos caused by too many bikes yet insufficient demands. To allow possible actions to be taken in advance, this paper studies the problem of detecting parking hotspots in a new city where no dockless shared bike has been deployed. We propose to measure road hotness by bike density with the help of the Kernal Density Estimation. We extract useful features from multi-source urban data and introduce a novel domain adaption network for transferring hotspots knowledge learned from one city with shared bikes to a new city. The extensive experimental results demonstrate the effectiveness of our proposed approach compared with various baselines.
CR Bao Jie, 2017, TRAJECTORIES
   Burges C., 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Burges Christopher JC, 2010, LEARNING, V11, P81
   Burges CJC, 2007, P ADV NEUR INF PROC, V19, P193
   Cao Zhangjie, 2017, PARTIAL TRANSFER LEA
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dehnad Khosrow, 2012, TECHNOMETRICS, V29, P495
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gast N, 2015, P 24 ACM INT C INF K, P703, DOI DOI 10.1145/2806416.2806569
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Hoang MX, 2016, 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016), DOI 10.1145/2996913.2996934
   Hoffman  J., 2014, ADV NEURAL INFORM PR, P3536
   Ioffe S, 2015, INT C MACH LEARN, V37, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Lin M, 2013, COMPUTER SCI
   Liu J, 2016, P 22 ACM SIGKDD INT, P1005
   Liu JM, 2015, IEEE DATA MINING, P883, DOI 10.1109/ICDM.2015.99
   Long M., 2016, ADV NEURAL INFORM PR, P136
   Long M., 2015, INT C MACH LEARN, P97
   Manning C. D., 2008, INTRO INFORM RETRIEV, V1
   Martinez LM, 2012, PROCD SOC BEHV, V54, P513, DOI 10.1016/j.sbspro.2012.09.769
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sculley D, 2010, P 16 ACM SIGKDD INT, P979, DOI DOI 10.1145/1835804.1835928
   SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683
   Singla A., 2015, P 29 AAAI C ART INT, P723
   Smola A, 2007, LECT NOTES ARTIF INT, V4754, P13
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Toh Michelle, 2017, CHINAS BIKE SHARING
   Tzeng E., 2014, DEEP DOMAIN CONFUSIO
   Van Brummelen Glen, 2012, HEAVENLY MATH FORGOT, P1
   VANDERMAATEN L, 2008, VIGILIAE CHRISTIAN, V9, P2579
   Yang Z., 2016, P 14 ANN INT C MOB S, P165, DOI DOI 10.1145/2906388
   Zeng Ming, 2016, IMPROVING DEMAND PRE
NR 38
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 566
EP 575
DI 10.1145/3219819.3219920
UT WOS:000455346400060
ER

PT B
AU Sato, I
   Nomura, Y
   Hanaoka, S
   Miki, S
   Hayashi, N
   Abe, O
   Masutani, Y
AF Sato, Issei
   Nomura, Yukihiro
   Hanaoka, Shouhei
   Miki, Soichiro
   Hayashi, Naoto
   Abe, Osamu
   Masutani, Yoshitaka
GP ACM
TI Managing Computer-Assisted Detection System Based on Transfer Learning
   with Negative Transfer Inhibition
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE Medical image analysis; Computer-assisted detection; Machine learning;
   Transfer learning; Negative transfer
ID CONVOLUTIONAL NEURAL-NETWORKS; AIDED DIAGNOSIS; DEEP; SEGMENTATION
AB The reading workload for radiologists is increasing because the numbers of examinations and images per examination are increasing due to the technical progress on imaging modalities such as computed tomography and magnetic resonance imaging. A computer-assisted detection (CAD) system based on machine learning is expected to assist radiologists. The preliminary results of a multi-institutional study indicate that the performance of the CAD system for each institution improved using training data of other institutions. This indicates that transfer learning may be useful for developing the CAD systems among multiple institutions. In this paper, we focus on transfer learning without sharing training data due to the need to protect personal information in each institution. Moreover, we raise a problem of negative transfer in CAD system and propose an algorithm for inhibiting negative transfer. Our algorithm provides a theoretical guarantee for managing CAD software in terms of transfer learning and exhibits experimentally better performance compared to that of the current algorithm in cerebral aneurysm detection.
CR Belharbi S, 2017, COMPUT BIOL MED, V87, P95, DOI 10.1016/j.compbiomed.2017.05.018
   Cesa-Bianchi N., 2006, PREDICTION LEARNING
   Conjeti S, 2016, MED IMAGE ANAL, V32, P1, DOI 10.1016/j.media.2016.02.005
   Giger ML, 2008, MED PHYS, V35, P5799, DOI 10.1118/1.3013555
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Gruszauskas NP, 2009, RADIOLOGY, V253, P661, DOI 10.1148/radiol.2533090280
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Herbster M, 1998, MACH LEARN, V32, P151, DOI 10.1023/A:1007424614876
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li H, 2008, ACAD RADIOL, V15, P1437, DOI 10.1016/j.acra.2008.05.004
   Littlestone N., 1994, INFORM COMPUT, V108, P2
   Mozer Michael C., 2001, ADV NEURAL INFORM PR, V14, P1409
   Nomura Y., 2014, J BIOMEDICAL GRAPHIC, V4, P12
   Nomura Y., 2010, T MASS DATA ANAL IMA, V2, P112
   Nomura Y, 2013, 2013 FIRST INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR), P320, DOI 10.1109/CANDAR.2013.57
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345
   Schapire RE, 1998, ANN STAT, V26, P1651
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sonoyama S, 2015, IEEE ENG MED BIO, P785, DOI 10.1109/EMBC.2015.7318479
   Summers RM, 2008, AM J ROENTGENOL, V191, P168, DOI 10.2214/AJR.07.3354
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   van Engelen A, 2015, IEEE T MED IMAGING, V34, P1294, DOI 10.1109/TMI.2014.2384733
   van Ginneken B, 2011, RADIOLOGY, V261, P719, DOI 10.1148/radiol.11091710
   van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792
   Willinek WA, 2003, RADIOLOGY, V229, P913, DOI 10.1148/radiol.2293020782
   Zhao P., 2010, P INT C MACH LEARN, P1231, DOI DOI 10.1145/2505515.2505603
NR 27
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 695
EP 704
DI 10.1145/3219819.3219868
UT WOS:000455346400073
ER

PT B
AU Shashikumar, SP
   Shah, AJ
   Clifford, GD
   Nemati, S
AF Shashikumar, Supreeth P.
   Shah, Amit J.
   Clifford, Gari D.
   Nemati, Shamim
GP ACM
TI Detection of Paroxysmal Atrial Fibrillation using Attention-based
   Bidirectional Recurrent Neural Networks
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE atrial fibrillation; convolutional neural network; recurrent neural
   network; deep learning; transfer learning
ID PHYSIOLOGICAL TIME-SERIES; QRST CANCELLATION; WAVELET TRANSFORM;
   ENTROPY; BURDEN
AB Detection of atrial fibrillation (AF), a type of cardiac arrhythmia, is difficult since many cases of AF are usually clinically silent and undiagnosed. In particular paroxysmal AF is a form of AF that occurs occasionally, and has a higher probability of being undetected. In this work, we present an attention based deep learning framework for detection of paroxysmal AF episodes from a sequence of windows. Time-frequency representation of 30 seconds recording windows, over a 10 minute data segment, are fed sequentially into a deep convolutional neural network for image-based feature extraction, which are then presented to a bidirectional recurrent neural network with an attention layer for AF detection. To demonstrate the effectiveness of the proposed framework for transient AF detection, we use a database of 24 hour Holter Electrocardiogram (ECG) recordings acquired from 2850 patients at the University of Virginia heart station. The algorithm achieves an AUC of 0.94 on the testing set, which exceeds the performance of baseline models. We also demonstrate the cross-domain generalizablity of the approach by adapting the learned model parameters from one recording modality (ECG) to another (photoplethysmogram) with improved AF detection performance. The proposed high accuracy, low false alarm algorithm for detecting paroxysmal AF has potential applications in long-term monitoring using wearable sensors.
CR Abadi Martin, 2016, P 12 USENIX S OP SYS, P265, DOI DOI 10.1038/NN.3331
   Andreotti Fernando, 2017, COMPUTING CARDIOLOGY, V44
   Bahdanau D, 2014, ARXIV14090473
   Ball J, 2013, INT J CARDIOL, V167, P1807, DOI 10.1016/j.ijcard.2012.12.093
   Behar J, 2013, IEEE T BIO-MED ENG, V60, P1660, DOI 10.1109/TBME.2013.2240452
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Camm AJ, 2012, EUR HEART J, V33, P2719, DOI 10.1093/eurheartj/ehs253
   Carlucci Fabio Maria, 2017, INT C COMP VIS
   Carrara M, 2015, PHYSIOL MEAS, V36, P1873, DOI 10.1088/0967-3334/36/9/1873
   Chorowski J.K., 2015, ADV NEURAL INFORM PR, P577
   Clifford G., 2017, COMPUTING CARDIOLOGY, V44
   Clifford Gari, 2017, PHYSIONET CHALLENGE
   Colloca R, 2013, COMPUT CARDIOL, V40, P1047
   Cook NR, 2009, ANN INTERN MED, V150, P795, DOI 10.7326/0003-4819-150-11-200906020-00007
   Dash S, 2009, ANN BIOMED ENG, V37, P1701, DOI 10.1007/s10439-009-9740-z
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312
   Drew BJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110274
   Fuster V, 2006, EUROPACE, V8, P651, DOI 10.1093/europace/eul097
   Ghassemi M, 2014, COMPUT CARDIOL, V41, P993
   GILES CL, 1994, IEEE T NEURAL NETWOR, V5, P153
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Grinsted A, 2004, NONLINEAR PROC GEOPH, V11, P561, DOI 10.5194/npg-11-561-2004
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hsu Yen-Chang, 2017, ARXIV171110125
   Johnson AEW, 2015, PHYSIOL MEAS, V36, P1665, DOI 10.1088/0967-3334/36/8/1665
   Johnson AEW, 2014, COMPUT CARDIOL, V41, P281
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lake DE, 2011, AM J PHYSIOL-HEART C, V300, pH319, DOI 10.1152/ajpheart.00561.2010
   Larochelle H., 2010, P ADV NEUR INF PROC, P1243
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Yann, 1995, HDB BRAIN THEORY NEU, V3361, P10
   Li Q, 2008, PHYSIOL MEAS, V29, P15, DOI 10.1088/0967-3334/29/1/002
   Linker David Thor, 2009, US Patent, Patent No. [7,630,756, 7630756]
   Lip GYH, 2001, QJM-INT J MED, V94, P665, DOI 10.1093/qjmed/94.12.665
   Long M., 2016, ARXIV160506636
   Martinez JP, 2004, IEEE T BIO-MED ENG, V51, P570, DOI 10.1109/TBME.2003.821031
   MATLAB, 2016, VERS 9 1 R2016B
   Mnih V., 2014, ADV NEURAL INFORM PR, P2204
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moody G. B., 1983, Computers in Cardiology 10th Annual Meeting (IEEE Cat. No. 83CH1927-3), P227
   Nemati S, 2016, IEEE ENG MED BIO, P3394, DOI 10.1109/EMBC.2016.7591456
   Peng Zhou, 2016, P 54 ANN M ASS COMP, P207, DOI DOI 10.18653/V1/P16-2034
   Petrenas A, 2012, IEEE T BIO-MED ENG, V59, P2950, DOI 10.1109/TBME.2012.2212895
   Rajpurkar P., 2017, ARXIV170701836
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Rush A. M., 2015, ARXIV150900685
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Settles B., 2012, SYNTHESIS LECT ARTIF, V6, P1, DOI [DOI 10.2200/S00429ED1V01Y201207AIM018, 10.2200/S00429ED1V01Y201207AIM018]
   Shashikumar SP, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P141, DOI 10.1109/BHI.2017.7897225
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Stewart S, 2002, AM J MED, V113, P359, DOI 10.1016/S0002-9343(02)01236-6
   Stridh M, 2001, IEEE T BIO-MED ENG, V48, P105, DOI 10.1109/10.900266
   Sun B., 2016, AAAI, V6, P8
   Tateno K, 2001, MED BIOL ENG COMPUT, V39, P664, DOI 10.1007/BF02345439
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P2
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wong CX, 2012, ARCH INTERN MED, V172, P739, DOI 10.1001/archinternmed.2012.878
   Xu Kelvin, 2015, INT C MACH LEARN, P2048
   Yang Z., 2016, HLT NAACL, P1480
   Yonghui, 2016, ARXIV160908144
   Zhu TT, 2015, ANN BIOMED ENG, V43, P2892, DOI 10.1007/s10439-015-1344-1
   Zhu TT, 2014, ANN BIOMED ENG, V42, P871, DOI 10.1007/s10439-013-0964-6
NR 63
TC 1
Z9 1
BN 978-1-4503-5552-0
PY 2018
BP 715
EP 723
DI 10.1145/3219819.3219912
UT WOS:000455346400075
ER

PT B
AU Di, SM
   Peng, JS
   Shen, YY
   Chen, L
AF Di, Shimin
   Peng, Jingshu
   Shen, Yanyan
   Chen, Lei
GP ACM
TI Transfer Learning via Feature Isomorphism Discovery
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE Transfer learning; cross-lingual; subgraph isomorphism
AB Transfer learning has gained increasing attention due to the inferior performance of machine learning algorithms with insufficient training data. Most of the previous homogeneous or heterogeneous transfer learning works aim to learn a mapping function between feature spaces based on the inherent correspondence across the source and target domains or labeled instances. However, in many real world applications, existing methods may not be robust when the correspondence across domains is noisy or labeled instances are not representative. In this paper, we develop a novel transfer learning framework called Transfer Learning via Feature Isomorphism Discovery (abbreviated to TLFid), which owns high tolerance for noisy correspondence between domains as well as scarce or non-existing labeled instances. More specifically, we propose a feature isomorphism approach to discovering common substructures across feature spaces and learning a feature mapping function from the target domain to the source domain. We evaluate the performance of TLFid on the cross-lingual sentiment classification tasks. The results show that our method achieves significant improvement in terms of accuracy compared with the state-of-the-art methods.
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conte Donatello, 2007, Journal of Graph Algorithms and Applications, V11, P99
   Cook S. A., 1971, Proceedings of the 3rd annual ACM symposium on theory of computing, P151
   Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75
   Dai  Wenyuan, 2009, P NEUR INF PROC SYST, P353
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Duan L., 2012, ARXIV12064660
   Egghe L, 2009, J AM SOC INF SCI TEC, V60, P1027, DOI 10.1002/asi.21009
   Evans J. D, 1996, STRAIGHTFORWARD STAT
   Fernandez AM, 2016, J ARTIF INTELL RES, V55, P131
   Grover Aditya, 2016, KDD, V2016, P855
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hoffman Judy, 2013, ARXIV13013224
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1118
   Quan CQ, 2010, COMPUT SPEECH LANG, V24, P726, DOI 10.1016/j.csl.2010.02.002
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi XX, 2013, IEEE T KNOWL DATA EN, V25, P906, DOI 10.1109/TKDE.2011.252
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang C., 2011, IJCAI, P1541
   Xiao M, 2014, P 28 AAAI C ART INT, P1607
   Zhou J. T., 2014, AAAI, P2213
NR 28
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 1301
EP 1309
DI 10.1145/3219819.3220029
UT WOS:000455346400135
ER

PT B
AU Kumagai, A
   Iwata, T
AF Kumagai, Atsutoshi
   Iwata, Tomoharu
GP ACM
TI Learning Dynamics of Decision Boundaries without Additional Labeled Data
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE Transfer learning; Semi-supervised learning; Concept drift
AB We propose a method for learning the dynamics of the decision boundary to maintain classification performance without additional labeled data. In various applications, such as spam-mail classification, the decision boundary dynamically changes over time. Accordingly, the performance of classifiers deteriorates quickly unless the classifiers are retrained using additional labeled data. However, continuously preparing such data is quite expensive or impossible. The proposed method alleviates this deterioration in performance by using newly obtained unlabeled data, which are easy to prepare, as well as labeled data collected beforehand. With the proposed method, the dynamics of the decision boundary is modeled by Gaussian processes. To exploit information on the decision boundaries from unlabeled data, the low-density separation criterion, i.e., the decision boundary should not cross high-density regions, but instead lie in low-density regions, is assumed with the proposed method. We incorporate this criterion into our framework in a principled manner by introducing the entropy posterior regularization to the posterior of the classifier parameters on the basis of the generic regularized Bayesian framework. We developed an efficient inference algorithm for the model based on variational Bayesian inference. The effectiveness of the proposed method was demonstrated through experiments using two synthetic and four real-world data sets.
CR Abdallah ZS, 2012, PROC INT C TOOLS ART, P1163, DOI 10.1109/ICTAI.2012.169
   Babcock Brian, 2002, P 21 ACM SIGMOD SIGA, P1, DOI DOI 10.1145/543613.543615
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Bishop CM, 2006, PATTERN RECOGNITION
   Bitarafan A, 2016, IEEE T KNOWL DATA EN, V28, P2128, DOI 10.1109/TKDE.2016.2551241
   Crammer Koby, 2009, NIPS
   Dyer KB, 2014, IEEE T NEUR NET LEAR, V25, P12, DOI 10.1109/TNNLS.2013.2277712
   Freund Yoav, 1996, ICML
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Gao Jin, 2014, ECCV
   Goldberg Andrew B, 2008, ECML PKDD
   Gomes Heitor M, 2017, MACH LEARN, P1
   Goodfellow  I., 2016, DEEP LEARNING, V1
   Grandvalet Y., 2004, NIPS
   Hoffman J., 2014, CVPR
   Kalman R. E., 1960, J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]
   Kanamori Takafumi, 2009, NIPS
   Kingma Diederik P, 2014, NIPS, P4
   Kingma Diederik P., 2014, ICLR
   Klinkenberg R., 2004, Intelligent Data Analysis, V8, P281
   Kolter JZ, 2007, J MACH LEARN RES, V8, P2755
   Koychev I, 2000, P ECAI 2000 WORKSH C
   Kumagai Atsutoshi, 2017, IJCAI
   Kumagai Atsutoshi, 2016, AAAI
   Kumagai Atsutoshi, 2017, AAAI
   Li Peipei, 2010, ACML
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Long M., 2016, NIPS
   Long M., 2017, ICML
   Ma Justin, 2009, ICML
   Miyato  T., 2016, ICLR
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rasmussen C. E, 2006, GAUSSIAN PROCESS MAC
   Ruvolo Paul, 2013, ICML
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Souza Vinicius MA, 2015, SDM
   Sykacek Peter, 2003, NIPS
   Tang K., 2012, NIPS
   Thang D., 2018, ICLR
   Umer Muhammad, 2017, IJCAN
   Wang Boyu, 2015, AAAI
   Wang Haixun, 2003, SIGKDD
   Wang J, 2012, ICML
   Yoon JW, 2009, NEURAL NETWORKS, V22, P1286, DOI 10.1016/j.neunet.2009.06.005
   Zenke Friedemann, 2017, ICML
   Zhang P, 2009, IEEE DATA MINING, P627, DOI 10.1109/ICDM.2009.76
   Zhao Peilin, 2010, ICML
   Zhu Jun, 2014, JMLR, V15, P17
   Zliobaite I, 2014, IEEE T NEUR NET LEAR, V25, P27, DOI 10.1109/TNNLS.2012.2236570
NR 51
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 1627
EP 1636
DI 10.1145/3219819.3219967
UT WOS:000455346400169
ER

PT B
AU Satoh, S
   Takahashi, Y
   Yamakawa, H
AF Satoh, Seiya
   Takahashi, Yoshinobu
   Yamakawa, Hiroshi
GP ACM
TI Accelerated Equivalence Structure Extraction via Pairwise Incremental
   Search
SO KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)
CY AUG 19-23, 2018
CL London, ENGLAND
DE equivalence structure; transfer learning; imitation learning
AB Equivalence structure (ES) extraction can allow for finding correspondence relations between different sequential datasets. A K-dimensional ES is a set of K-tuples to specify K-dimensional sequences that are considered equivalent. Whether or not two K-dimensional sequences are equivalent is decided based on comparisons of all of their subsequences. ES extraction can be used for preprocessing for transfer learning or imitation learning, as well as an analysis of multidimensional sequences. A recently proposed method called incremental search (IS) was much faster than brute-force search. However, IS can still take a long time to obtain ESs, because ESs obtained by IS can be subsets of other ESs and such subsets must be removed in the process. In this paper, we propose a new fast method called pairwise incremental search (PIS). In the process of PIS, the aforementioned problem about subsets of ESs does not exist, because the elements of ESs are searched pairwise. As shown by results of two experiments we conducted, PIS was 48 times faster than IS in an experiment using synthetic datasets and 171 times faster in an experiment using motion capture datasets.
CR Du Simon S., 2017, ADV NEURAL INFORM PR, P574
   Duan  Yan, 2017, ADV NEURAL INF PROCE, V30, P1087
   Hussein A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054912
   Luo Zelun, 2017, ADV NEURAL INFORM PR, P164
   Yeh CCM, 2016, IEEE DATA MINING, P1317, DOI [10.1109/ICDM.2016.89, 10.1109/ICDM.2016.0179]
   Minnen D, 2007, IEEE DATA MINING, P601, DOI 10.1109/ICDM.2007.52
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Satoh S, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00063
   Satoh S, 2017, IEEE IJCNN, P1518, DOI 10.1109/IJCNN.2017.7966032
   Sipser Michael, 2006, INTRO THEORY COMPUTA, V2
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yeh Chin-Chia Michael, 2017, 2017 IEEE 17 INT C D
   Zeestraten MJA, 2017, IEEE ROBOT AUTOM LET, V2, P1240, DOI 10.1109/LRA.2017.2657001
NR 13
TC 0
Z9 0
BN 978-1-4503-5552-0
PY 2018
BP 2160
EP 2169
DI 10.1145/3219819.3220011
UT WOS:000455346400222
ER

PT S
AU Yin, HW
   Li, FZ
   Zhang, L
AF Yin, Hongwei
   Li, Fanzhang
   Zhang, Li
GP IEEE
TI Multi-Source Clustering based on spectral recovery
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
DE multi-source clustering; Laplace operator; spectral learning; multi-view
   spectral embedding
AB The research and analysis on multi-source data is one of important tasks in information science. Compared with traditional single-source data learning algorithms, multi-source data learning ones can describe objects more real and complete. Meanwhile, the learning process of multi-source data is more in line with the cognitive mechanism of human brain. So far, the research on multi-source data learning algorithms includes three classes, multi-source data transfer learning, multi-source data collaborative learning and multi-source multi-view learning. The traditional multi-source multi-view learning algorithms lack the ability of handling with the data missing issue, which means that these algorithms require the multi-source data to be complete. This paper proposes a multi-source clustering algorithm. Based on the spectral properties of Laplace operator, we first obtain the complete representation of multi-source data. Then, we utilize the multi-view spectral embedding (MVSE) to construct the fusion model. Experimental results show that our proposed method can improve the ability of clustering efficiently in the case of data missing.
CR Dhillon P., 2011, ADV NEURAL INFORM PR, P199
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Fang M, 2015, PATTERN RECOGN LETT, V51, P101, DOI 10.1016/j.patrec.2014.08.011
   Feng L., 2016, S CHINA GEOL MAG, P1
   Fromont E, 2004, LECT NOTES ARTIF INT, V3202, P503
   Guven B, 2012, LINEAR ALGEBRA APPL, V436, P3337, DOI 10.1016/j.laa.2011.11.028
   Haeffele B. D., 2014, P 31 INT C MACH LEAR, V32, P2007, DOI 10.1109/ICGPR.2014.6970495
   Kumar A., 2011, P 28 INT C MACH LEAR, P393
   Kumar A, 2011, ADV NEURAL INFORM PR, V24, P1413
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li S.-Y., 2014, AAAI, P1968
   Li Y., 2015, P 29 AAAI C ART INT, V29, P2750
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nie  F., 2016, P 30 AAAI C ART INT, P1969
   Ouyang WL, 2014, PROC CVPR IEEE, P2337, DOI 10.1109/CVPR.2014.299
   Rosasco L, 2010, J MACH LEARN RES, V11, P905
   Shao WX, 2016, IEEE IJCNN, P2714, DOI 10.1109/IJCNN.2016.7727540
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Xia  R., 2014, AAAI, P2149
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu XX, 2016, IEEE T PATTERN ANAL, V38, P1113, DOI 10.1109/TPAMI.2015.2476813
   Xu ZJ, 2012, LECT NOTES COMPUT SC, V7665, P332, DOI 10.1007/978-3-642-34487-9_41
   Yager RR, 2004, INFORM SCIENCES, V163, P175, DOI 10.1016/j.ins.2003.03.018
   Yin Hongwei, 2015, Journal of Frontiers of Computer Science and Technology, V9, P1409, DOI 10.3778/j.issn.1673-9418.1505049
   Yu Zheng, 2015, IEEE Transactions on Big Data, V1, P16, DOI 10.1109/TBDATA.2015.2465959
   Zhou Dengyong, 2007, P 24 INT C MACH LEAR, P1159, DOI DOI 10.1145/1273496.1273642
NR 29
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 231
EP 236
UT WOS:000455146800039
ER

PT S
AU Lu, W
   Chung, FL
AF Lu, Wei
   Chung, Fu-lai
GP IEEE
TI A Deep Graphical Model for Layered Knowledge Transfer
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
ID DOMAIN ADAPTATION
AB Deep architectures can now be well trained on massive labeled data. However, there exist many application scenarios where labeled data are sparse or absent. Domain adaptation and multi-task transfer learning provide attractive options when related labeled data or tasks are abundant from different domains. In this paper, a new graphical modeling approach to multi-layer factorization based domain adaptation is explored to address the scenarios that insufficient labeled data are available for supervised learning. A deep convolutional factorization based transfer learning (DCFTL) algorithm is proposed to facilitate layer-wise transfer learning between domains. Completely based on graphical model representation, the proposed framework can seamlessly merge inference and learning, and has clear interpretability of conditional independence. The empirical performances on image classification tasks in both supervised and semi-supervised adaptation settings illustrate the effectiveness and generalization of the proposed deep layered knowledge transfer framework.
CR Chen B., 2013, IEEE T PATTERN ANAL, V35
   Chen M., 2014, P MACHINE LEARNING R, V32, P1476
   Chopra S, 2005, PROC CVPR IEEE, P539
   Daume H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Ganin Y, 2016, J MACH LEARN RES, V17
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Hinton G E., 2009, SCHOLARPEDIA, V4, P5947, DOI DOI 10.4249/SCH0LARPEDIA.5947
   Kandemir M., 2015, P 32 INT C MACH LEAR, P730
   Lee  H., 2009, P ANN INT C MACH LEA, P609, DOI [DOI 10.1145/1553374.1553453, 10.1145/1553374.1553453]
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Saenko K., 2010, ADAPTING VISUAL CATE, P213
   Saul L, 1998, NATO ADV SCI I D-BEH, V89, P541
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Xiao  T., 2016, ARXIV160407528
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 22
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 260
EP 265
UT WOS:000455146800044
ER

PT S
AU Manessi, F
   Rozza, A
   Bianco, S
   Napoletano, P
   Schettini, R
AF Manessi, Franco
   Rozza, Alessandro
   Bianco, Simone
   Napoletano, Paolo
   Schettini, Raimondo
GP IEEE
TI Automated Pruning for Deep Neural Network Compression
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
AB In this work we present a method to improve the pruning step of the current state-of-the-art methodology to compress neural networks. The novelty of the proposed pruning technique is in its differentiability, which allows pruning to be performed during the backpropagation phase of the network training. This enables an end-to-end learning and strongly reduces the training time. The technique is based on a family of differentiable pruning functions and a new regularizer specifically designed to enforce pruning. The experimental results show that the joint optimization of both the thresholds and the network weights permits to reach a higher compression rate, reducing the number of weights of the pruned network by a further 14% to 33% compared to the current state-of-the-art. Furthermore, we believe that this is the first study where the generalization capabilities in transfer learning tasks of the features extracted by a pruned network are analyzed. To achieve this goal, we show that the representations learned using the proposed pruning methodology maintain the same effectiveness and generality of those learned by the corresponding non-compressed network on a set of different recognition tasks.
CR Abadi Martin, 2016, P 12 USENIX S OP SYS, P265, DOI DOI 10.1038/NN.3331
   Arandjelovic R, 2011, IEEE I CONF COMP VIS, P375, DOI 10.1109/ICCV.2011.6126265
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Chen W., 2015, P INT C MACH LEARN, P2285
   Chollet  F., 2015, KERAS
   Coates A., 2011, J MACHINE LEARNING R, V15, P215
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Courbariaux  M., 2015, ADV NEURAL INFORM PR, P3123
   Cun Y. L., 1990, ADV NEURAL INFORMATI, P598
   Denil M., 2013, ADV NEURAL INFORM PR, V26, P2148
   Denton E. L., 2014, ADV NEURAL INFORM PR, P1269
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Gong Y., 2014, ARXIV14126115
   Gregor K., 2010, ARXIV10060448
   Han S., 2015, ADV NEURAL INFORM PR, P1135
   Han S., 2016, ICLR
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   HANSON SJ, 1989, ADV NEURAL INFORMATI, V1, P177
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Hwang Kyuyeon, 2014, SIGN PROC SYST SIPS, P1, DOI DOI 10.1109/SIPS.2014.6986082
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kingma D., 2015, ICLR
   Konda K., 2014, ARXIV14023337
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1998, MNIST DATABASE HANDW
   MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264
   Philbin J., 2007, COMPUT VIS PATTERN R, P1, DOI DOI 10.1109/CVPR.2007.383172
   Philbin J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587635
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rozell CJ, 2008, NEURAL COMPUT, V20, P2526, DOI 10.1162/neco.2008.03-07-486
   Shwartz-Ziv R, 2017, ARXIV170300810
   Thrun S., 2012, LEARNING LEARN
   Vanhoucke V., 2011, P DEEP LEARN UNS FEA, V1, P4
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 44
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 657
EP 664
UT WOS:000455146800110
ER

PT S
AU Yan, YP
   Rangarajan, A
   Ranka, S
AF Yan, Yupeng
   Rangarajan, Anand
   Ranka, Sanjay
GP IEEE
TI An Efficient Deep Representation Based Framework for Large-Scale Terrain
   Classification
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
DE remote sensing; superpixel segmentation; convolutional neural network;
   transfer learning; feature selection; semi-supervised learning
AB In this paper, we present a novel terrain classification framework for large-scale remote sensing images. A well-performing multi-scale superpixel tessellation based segmentation approach is employed to generate homogeneous and irregularly shaped regions, and a transfer learning technique is sequentially deployed to derive representative deep features by utilizing successful pre-trained convolutional neural network (CNN) models. This design is aimed to overcome the big problem of lacking available ground-truth data and to increase the generalization power of the multi-pixel descriptor. In the subsequent classification step, we train a fast and robust support vector machine (SVM) to assign the pixel-level labels. Its maximum-margin property can be easily combined with a graph Laplacian propagation approach. Moreover, we analyze the advantages of applying a feature selection technique to the deep CNN features which are extracted by transfer learning. In the experiments, we evaluate the whole framework based on different geographical types. Compared with other region-based classification methods, the results show that our framework can obtain state-of-the-art performance w.r.t. both classification accuracy and computational efficiency.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Athiwaratkun B, 2015, ARXIV150702313
   Audebert N, 2016, INT GEOSCI REMOTE SE, P5091, DOI 10.1109/IGARSS.2016.7730327
   Castelluccio M., 2015, ARXIV150800092
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Gu Q., 2012, ARXIV12023725
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sethi M., 2015, P 21 ACM SIGKDD INT, P2069
   Sethi M, 2014, INT CONF CONTEMP, P635, DOI 10.1109/IC3.2014.6897247
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Vatsavai R. R, 2013, 19 ACM SIGKDD INT C, P1419
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Yan Y., 2013, MULT EXP ICME 2013 I, P1
   Yan Y., 2017, INT J BIG DATA INTEL, V4, P108, DOI [10.1504/IJBDI.2017.083130, DOI 10.1504/IJBDI.2017.083130]
   Yu W., 2016, INT C MACH LEARN ICM
   Yupeng Yan, 2017, 2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech). Proceedings, P1127, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.182
   Zhang GY, 2015, IEEE T GEOSCI REMOTE, V53, P5861, DOI 10.1109/TGRS.2015.2423688
NR 25
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 940
EP 945
UT WOS:000455146800157
ER

PT S
AU Yi, HY
   Xu, Z
   Wen, YM
   Fan, ZG
AF Yi, Haiyang
   Xu, Zhi
   Wen, Yimin
   Fan, Zhigang
GP IEEE
TI Multi-source Domain Adaptation for Face Recognition
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
DE domain adaptation; multi-source transfer learning; common subspace
   learning; face recognition
AB For transfer learning, many research works have demonstrated that effective use of information from multi-source domains will improve classification performance. In this paper, we propose a method of Targetize Multi-source Domain Bridged by Common Subspace (TMSD) for face recognition, which transfers rich supervision knowledge from more than one labeled source domains to the unlabeled target domain. Specifically, a common subspace is learnt for several domains by keeping the maximum total correlation. In this way, the discrepancy of each domain is reduced, and the structures of both the source and target domains are well preserved for classification. In the common subspace, each sample projected from the source domains is sparsely represented as a linear combination of several samples projected from the target domain, such that the samples projected from different domains can be well interlaced. Then, in the original image space, each source domain image can be represented as a linear combination of neighbors in the target domain. Finally, the discriminant subspace can be obtained by targetized multi-source domain images using supervised learning algorithm. The experimental results illustrate the superiority of TMSD over those competitive ones.
CR Banerjee S., 2014, IND C COMP VIS GRAPH
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Chattopadhyay R., 2011, P 17 ACM SIGKDD INT, P717
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   Dredze M, 2010, MACH LEARN, V79, P123, DOI 10.1007/s10994-009-5148-0
   Duan L, 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Efron B, 2004, ANN STAT, V32, P407
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Ho HT, 2014, INT J COMPUT VISION, V109, P110, DOI 10.1007/s11263-014-0720-x
   Kan MN, 2014, INT J COMPUT VISION, V109, P94, DOI 10.1007/s11263-013-0693-1
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   Qiu Q, 2015, IEEE T IMAGE PROCESS, V24, P5152, DOI 10.1109/TIP.2015.2479456
   Rupnik  J., 2010, P C DAT MIN DAT WAR, P1
   Shao M, 2012, IEEE DATA MINING, P1104, DOI 10.1109/ICDM.2012.102
   Shawe-Taylor J, 2011, NEUROCOMPUTING, V74, P3609, DOI 10.1016/j.neucom.2011.06.026
   Shi  Y., 2012, P 29 INT C MACH LEAR, P1275
   Sun SN, 2017, NEUROCOMPUTING, V257, P79, DOI 10.1016/j.neucom.2016.11.063
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Uribe D, 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P857, DOI 10.1109/ICMLA.2010.133
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
NR 29
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 1349
EP 1354
UT WOS:000455146801060
ER

PT S
AU Elezi, I
   Torcinovich, A
   Vascon, S
   Pelillo, M
AF Elezi, Ismail
   Torcinovich, Alessandro
   Vascon, Sebastiano
   Pelillo, Marcello
GP IEEE
TI Transductive Label Augmentation for Improved Deep Network Learning
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
ID ALGORITHM
AB A major impediment to the application of deep learning to real-world problems is the scarcity of labeled data. Small training sets are in fact of no use to deep networks as, due to the large number of trainable parameters, they will very likely be subject to overfitting phenomena. On the other hand, the increment of the training set size through further manual or semi-automatic labellings can be costly, if not possible at times. Thus, the standard techniques to address this issue are transfer learning and data augmentation, which consists of applying some sort of "transformation" to existing labeled instances to let the training set grow in size. Although this approach works well in applications such as image classification, where it is relatively simple to design suitable transformation operators, it is not obvious how to apply it in more structured scenarios. Motivated by the observation that in virtually all application domains it is easy to obtain unlabeled data, in this paper we take a different perspective and propose a label augmentation approach. We start from a small, curated labeled dataset and let the labels propagate through a larger set of unlabeled data using graph transduction techniques. This allows us to naturally use (second-order) similarity information which resides in the data, a source of information which is typically neglected by standard augmentation techniques. In particular, we show that by using known game theoretic transductive processes we can create larger and accurate enough labeled datasets which use results in better trained neural networks. Preliminary experiments are reported which demonstrate a consistent improvement over standard image classification datasets.
CR CIRESAN D, 2012, PROC CVPR IEEE, P3642, DOI [10.1109/CVPR.2012.6248110, DOI 10.1109/CVPR.2012.6248110]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Erdem A, 2012, NEURAL COMPUT, V24, P700, DOI 10.1162/NECO_a_00233
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   Griffin G., 2007, TECH REP
   Haeusser P, 2017, PROC CVPR IEEE, P626, DOI 10.1109/CVPR.2017.74
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   HOWSON JT, 1972, MANAGE SCI, V18, P312, DOI 10.1287/mnsc.18.5.312
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kadar I., 2014, EUR C COMP VIS ECCV, P385
   Kingma D. P., 2014, ADV NEURAL INFORM PR, P3581
   Kingma D. P., 2014, INT C LEARN REPR ICL
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Krizhevsky G. H. Alex, 2009, LEARNING MULTIPLE LA
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee D. hyun, 2013, ICML, V2, P3
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MILLER DA, 1991, OPER RES LETT, V10, P285, DOI 10.1016/0167-6377(91)90015-H
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Pelillo M, 1997, J MATH IMAGING VIS, V7, P309, DOI 10.1023/A:1008255111261
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Smith J., 1982, EVOLUTION THEORY GAM
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tripodi R, 2016, INT C PATT RECOG, P1719, DOI 10.1109/ICPR.2016.7899884
   Vapnik VN, 1998, STAT LEARNING THEORY
   Vascon S., 2018, PATTERN RECOGNITION
   Weibull J. W., 1997, EVOLUTIONARY GAME TH
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zelnik-Manor  L., 2005, ADV NEURAL INFORM PR, P1601
   Zhu X., 2005, THESIS
NR 34
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 1432
EP 1437
UT WOS:000455146801074
ER

PT S
AU Combinido, JS
   Mendoza, JR
   Aborot, J
AF Samuel Combinido, Jay
   Robert Mendoza, John
   Aborot, Jeffrey
GP IEEE
TI A Convolutional Neural Network Approach for Estimating Tropical Cyclone
   Intensity Using Satellite-based Infrared Images
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
AB Existing techniques for satellite-based tropical cyclone (TC) intensity estimation involve an explicit feature extraction step to model TC intensity on a set of relevant TC features or patterns such as eye formation and cloud organization. However, crafting such a feature set is often time-consuming and requires expert knowledge. In this paper, a convolutional neural network (CNN) approach, which eliminates explicit feature extraction, for estimating the intensity of tropical cyclones is proposed. Utilizing a Visual Geometry Group 19-layer CNN (VGG19) model pre-trained on ImageNet, transfer learning experiments were performed using grayscale IR images of TCs obtained from various geostationary satellites in the Western North Pacific region (1996 - 2016) to estimate TC intensity. The model re-trained on TC images achieved a root-mean-square error (RMSE) of 13.23 knots - a performance comparable to existing feature-based approaches (RMSE ranging from 12 to 20 knots). Moreover, the model was able to learn generic TC features that were previously identified in feature-based approaches as important indicators of TC intensity.
CR Bankert RL, 2002, J APPL METEOROL, V41, P461, DOI 10.1175/1520-0450(2002)041<0461:AAMTET>2.0.CO;2
   Bessho K, 2016, J METEOROL SOC JPN, V94, P151, DOI 10.2151/jmsj.2016-009
   Castelluccio M., 2015, ARXIV150800092
   Chandra R., 2015, LECT NOTES COMPUTER, V9491
   Chollet F., 2016, CONVOLUTIONAL NEURAL
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dvorak V. F., 1984, 11 NAT OC ATM ADM, V11
   DVORAK VF, 1975, MON WEATHER REV, V103, P420, DOI 10.1175/1520-0493(1975)103<0420:TCIAAF>2.0.CO;2
   GENTRY RC, 1980, MON WEATHER REV, V108, P445, DOI 10.1175/1520-0493(1980)108<0445:PTCIUS>2.0.CO;2
   GMS (Geostationary Meteorological Satellite) Series of Japan, GMS GEOST MET SAT SE
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Jaiswal N, 2012, ATMOS RES, V118, P215, DOI 10.1016/j.atmosres.2012.07.006
   Japan Meteorological Agency (JMA), MET SAT JAP MET AG J
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D.P., 2015, P 3 INT C LEARN REPR
   Koba H., 1991, Geophysical Magazine, V44, P15
   Koba H., 1989, J METEOR RES, V41, P157
   Kochi University, 2015, GMS GOES9 MTSAT DAT
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kulkarni A., 2010, ASPRS ANN C SAN DIEG
   Langkvist M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040329
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Y., 2016, INT C ADV BIG DAT AN
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pineros MF, 2011, WEATHER FORECAST, V26, P690, DOI 10.1175/WAF-D-10-05062.1
   Pineros MF, 2008, IEEE T GEOSCI REMOTE, V46, P3574, DOI 10.1109/TGRS.2008.2000819
   Roy C., 2016, THESIS
   Sakuragi T., 2014, TECH REP, V16
   Simonyan Karen, 2015, P IEEE C COMP VIS PA
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Velden C, 2006, B AM METEOROL SOC, V87, P1195, DOI 10.1175/BAMS-87-9-1195
   Velden CS, 1998, WEATHER FORECAST, V13, P172, DOI 10.1175/1520-0434(1998)013<0172:DOAOST>2.0.CO;2
   Yao SX, 2016, ATMOSPHERE-BASEL, V7, DOI 10.3390/atmos7010005
NR 35
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 1474
EP 1480
UT WOS:000455146801081
ER

PT S
AU Das, A
   Roy, S
   Bhattacharya, U
   Parui, SK
AF Das, Arindam
   Roy, Saikat
   Bhattacharya, Ujjwal
   Parui, Swapan K.
GP IEEE
TI Document Image Classification with Intra-Domain Transfer Learning and
   Stacked Generalization of Deep Convolutional Neural Networks
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
DE document structure learning; deep convolutional neural network; document
   recognition; deep learning; transfer learning; intra-domain; neural
   network
AB In this article, a region-based Deep Convolutional Neural Network framework is presented for document structure learning. The contribution of this work involves efficient training of region based classifiers and effective ensembling for document image classification. A primary level of 'inter-domain' transfer learning is used by exporting weights from a pre-trained VGG16 architecture on the ImageNet dataset to train a document classifier on whole document images. Exploiting the nature of region based influence modelling, a secondary level of 'intra-domain' transfer learning is used for rapid training of deep learning models for image segments. Finally, a stacked generalization based ensembling is utilized for combining the predictions of the base deep neural network models. The proposed method achieves state-of-the-art accuracy of 92.21% on the popular RVL-CDIP document image dataset, exceeding the benchmarks set by the existing algorithms.
CR Afzal M. Z., 2009, ARXIV170403557
   Afzal M. Z., 2015, P 13 INT C DOC AN RE, P1111
   Appiani E., 2001, International Journal on Document Analysis and Recognition, V4, P69, DOI 10.1007/PL00010904
   Cesarini F., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1131, DOI 10.1109/ICDAR.2001.953962
   Chen N, 2007, INT J DOC ANAL RECOG, V10, P1, DOI 10.1007/s10032-006-0020-2
   Csurka G., 2016, ARXIV160301076
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dengel A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P86, DOI 10.1109/ICDAR.1993.395776
   Dengel A., 1994, TECH REP
   Diligenti M, 2003, IEEE T PATTERN ANAL, V25, P519, DOI 10.1109/TPAMI.2003.1190578
   Gordo A, 2013, PATTERN RECOGN, V46, P1898, DOI 10.1016/j.patcog.2012.12.004
   Harley AW, 2015, 2015 13TH IAPR INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), P991, DOI 10.1109/ICDAR.2015.7333910
   Heroux P, 1998, INT C PATT RECOG, P926, DOI 10.1109/ICPR.1998.711385
   Hoch R., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P31
   Hu J., 2000, Information Retrieval, V2, P227, DOI 10.1023/A:1009910911387
   Junker M, 1997, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, P1060, DOI 10.1109/ICDAR.1997.620671
   Kang L, 2014, INT C PATT RECOG, P3168, DOI 10.1109/ICPR.2014.546
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Kolsch A., 2017, ARXIV171105862
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kumar J, 2014, PATTERN RECOGN LETT, V43, P119, DOI 10.1016/j.patrec.2013.10.030
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   RABINER LR, 1989, READINGS SPEECH RECO, V77, P257
   Roy S, 2016, INT C PATT RECOG, P1273, DOI 10.1109/ICPR.2016.7899812
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shin C., 2001, International Journal on Document Analysis and Recognition, V3, P232, DOI 10.1007/PL00013566
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang Y., 1991, P INT C DOC AN REC, P17
   Tensmeyer C., 2017, ARXIV170803273
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
NR 35
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 3180
EP 3185
UT WOS:000455146803031
ER

PT S
AU Nguyen, D
   Nguyen, K
   Sridharan, S
   Abbasnejad, I
   Dean, D
   Fookes, C
AF Dung Nguyen
   Kien Nguyen
   Sridharan, Sridha
   Abbasnejad, Iman
   Dean, David
   Fookes, Clinton
GP IEEE
TI Meta Transfer Learning for Facial Emotion Recognition
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
AB The use of deep learning techniques for automatic facial expression recognition has recently attracted great interest but developed models are still unable to generalize well due to the lack of large emotion datasets for deep learning. To overcome this problem, in this paper, we propose utilizing a novel transfer learning approach relying on PathNet and investigate how knowledge can be accumulated within a given dataset and how the knowledge captured from one emotion dataset can be transferred into another in order to improve the overall performance. To evaluate the robustness of our system, we have conducted various sets of experiments on two emotion datasets: SAVEE and eNTERFACE. The experimental results demonstrate that our proposed system leads to improvement in performance of emotion recognition and performs significantly better than the recent state-of-the-art schemes adopting fine-tuning/pre-trained approaches.
CR Abbasnejad I., 2017, ICCV
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fernando C., 2017, CORR
   Ghasemi A., 2017, 2017 ICIP
   Gideon J., 2017, CORR
   Hamester  D., 2015, 2015 INT JOINT C NEU, P1
   Haq S., 2009, P INT C AUD VIS SPEE
   Harvey Inman, 2011, ADV ARTIFICIAL LIFE, V5778, P126
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Howard A. G., 2017, CORR
   Jung H., 2015, CORR
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Krizhevsky A., 2009, THESIS
   Lee  Sang-Woo, 2017, NIPS, P4655
   Lopes AT, 2015, SIBGRAPI, P273, DOI 10.1109/SIBGRAPI.2015.14
   Mallya A., 2017, CORR
   Martin O., 2006, P 22 INT C DAT ENG W, P8
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Nguyen D, 2017, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2017.140
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Rusu A. A., 2016, CORR
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Szegedy C., 2017, AAAI
   Szegedy C., 2015, ARXIV151200567
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Victor-Emil N., 2013, RECENT ADV IMAGE AUD, P93
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yunfan Liu, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P125, DOI 10.1109/SMARTCOMP.2014.7043849
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
NR 33
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 3543
EP 3548
UT WOS:000455146803091
ER

PT S
AU Niu, XS
   Han, H
   Shan, SG
   Chen, XL
AF Niu, Xuesong
   Han, Hu
   Shan, Shiguang
   Chen, Xilin
GP IEEE
TI SynRhythm: Learning a Deep Heart Rate Estimator from General to Specific
SO 2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 24th International Conference on Pattern Recognition (ICPR)
CY AUG 20-24, 2018
CL Chinese Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA
HO Chinese Acad Sci, Inst Automat
ID NONCONTACT
AB Remote photoplethysmography (rPPG) based non-contact heart rate (HR) measurement from a face video has drawn increasing attention recently because of its potential applications in many scenarios such as training aid, health monitoring, and nursing care. Although a number of methods have been proposed, most of them are designed under certain assumptions and could fail when such assumptions do not hold. At the same time, while deep learning based methods have been reported to achieve promising results in many computer vision tasks, their use in rPPG-based heart rate estimation has been limited due to the very limited data available in public domain. To overcome this limitation and leverage the strong modeling ability of deep neural networks, in this paper, we propose a novel spatial-temporal representation for the HR signal and design a general-to-specific transfer learning strategy to train a deep heart rate estimator from a large volume of synthetic rhythm signals and a limited number of available face video data. Experiment results on the public-domain databases show the effectiveness of the proposed approach.
CR Balakrishnan G, 2013, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2013.440
   BLAND JM, 1986, LANCET, V1, P307
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   Gee-Sern Hsu M.-S. C., 2017, P IJCB
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kumar M, 2015, BIOMED OPT EXPRESS, V6, P1565, DOI 10.1364/BOE.6.001565
   Kwon S., 2015, P EMBS, P851
   Lam A, 2015, IEEE I CONF COMP VIS, P3640, DOI 10.1109/ICCV.2015.415
   Li XB, 2014, PROC CVPR IEEE, P4264, DOI 10.1109/CVPR.2014.543
   Mishkin D., 2015, ARXIV151106422
   Niu X., 2017, P IJCB
   Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Tulyakov S., 2016, P IEEE CVPR
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Wang WJ, 2015, IEEE T BIO-MED ENG, V62, P415, DOI 10.1109/TBME.2014.2356291
   White B, 2015, IEEE W CONTR MODEL
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   YungChien Hsu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4433, DOI 10.1109/ICASSP.2014.6854440
NR 24
TC 0
Z9 0
SN 1051-4651
BN 978-1-5386-3788-3
PY 2018
BP 3580
EP 3585
UT WOS:000455146803097
ER

PT B
AU Yang, K
   Wan, WG
   Lu, J
AF Yang, Kai
   Wan, Wanggen
   Lu, Jie
GP IEEE
TI Domain Adaptation for Gaussian Process Classification
SO 2018 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING
   (ICALIP)
CT International Conference on Audio, Language and Image Processing
   (ICALIP)
CY JUL 16-17, 2018
CL Shanghai, PEOPLES R CHINA
DE Gaussian Process; Domain Adaptation; Transfer Learning; Homogeneous
AB Traditional machining learning method aims at using the labeled data or unlabeled data to train a mathematic model then it can be used to predict the unlabeled data for Data mining problem, but it requires that the data which be trained should have same distribution with the predicting data. For the real world datasets, it is hard to get enough training datasets which has the same distribution. Thus, how to train a good mathematic model by using different distribution data is crucial problem, and the researchers using the probability view to solve transfer classification problem is relative less. In this paper, we propose a transfer classification algorithm based on the Gaussian Process model, which can be used to solve the homogeneous transfer classification problem. We use the probability theory to propose a novel classification transfer learning model based on the Gaussian Process (GP) model. We experiment on the synthetic and real-world datasets and compare to other method, the result has verified the effectiveness of our approach.
CR Cao B, 2010, PROCEEDINGS OF THE TWENTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-10), P407
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Lawrence N. D., 2004, P 21 INT C MACH LEAR
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63
   Williams C. K., 2006, GAUSSIAN PROCESSES M, V2, P33
   Wu P., 2004, P 21 INT C MACH LEAR, P110
NR 9
TC 0
Z9 0
BN 978-1-5386-5195-7
PY 2018
BP 226
EP 229
UT WOS:000455120900042
ER

PT S
AU Hu, H
   Hong, X
   Hou, DY
   Shi, ZZ
AF Hu, Hong
   Hong, Xin
   Hou, Dan Yang
   Shi, Zhongzhi
BE Shi, Z
   MercierLaurent, E
   Li, J
TI Forward Learning Convolutional Neural Network
SO INTELLIGENT INFORMATION PROCESSING IX
SE IFIP Advances in Information and Communication Technology
CT 10th IFIP TC 12 International Conference on Intelligent Information
   Processing (IIP)
CY OCT 19-22, 2018
CL Nanning, PEOPLES R CHINA
DE Forward learning; Convolutional neural network; Transfer learning;
   Extreme learning machine
AB A conventional convolutional neural network (CNN) is trained by back-propagation (BP) from output layer to input layer through the entire network. In this paper, we propose a novel training approach such that CNN can be trained in forward way unit by unit. For example, we separate a CNN network with three convolutional layers into three units. Each unit contains one convolutional layer and will be trained one by one in sequence. Experiments shows that training can be restricted in local unit and processed one by one from input to output. In most cases, our novel feed forward approach has equal or better performance compared to the traditional approach. In the worst case, our novel feed forward approach is inferior to the traditional approach less than 5% accuracy. Our training approach also obtains benefits from transfer learning by setting different targets for middle units. As the full network back propagation is unnecessary, BP learning becomes more efficiently and least square method can be applied to speed learning. Our novel approach gives out a new focus on training methods of convolutional neural network.
CR Aghdam H.H., 2017, CONVOLUTIONAL NEURAL
   Atlas L.E., 1987, NEURAL INFORM PROCES, P31
   CIRESAN D, 2012, PROC CVPR IEEE, P3642, DOI [10.1109/CVPR.2012.6248110, DOI 10.1109/CVPR.2012.6248110]
   Clouse DS, 1997, IEEE T NEURAL NETWOR, V8, P1065, DOI 10.1109/72.623208
   Glauner P. O., 2015, IEEE-ACM T AUDIO SPE, V22, P1533
   Haykin S., 2009, THESIS
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hu H, 2014, EXPERT SYST APPL, V41, P2729, DOI 10.1016/j.eswa.2013.11.006
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Callet P, 2006, IEEE T NEURAL NETWOR, V17, P1316, DOI 10.1109/TNN.2006.879766
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, P45
   Rumelhart David E., 1988, LEARNING REPRESENTAT
   Szegedy C., 2015, CVPR
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Xie S., 2016, ARXIV161105431
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 21
TC 0
Z9 0
SN 1868-4238
EI 1868-422X
BN 978-3-030-00828-4; 978-3-030-00827-7
PY 2018
VL 538
BP 51
EP 61
DI 10.1007/978-3-030-00828-4_6
UT WOS:000455377500006
ER

PT S
AU Tensmeyer, C
   Wigington, C
   Davis, B
   Stewart, S
   Martinez, T
   Barrett, W
AF Tensmeyer, Chris
   Wigington, Curtis
   Davis, Brian
   Stewart, Seth
   Martinez, Tony
   Barrett, William
GP IEEE
TI Language Model Supervision for Handwriting Recognition Model Adaptation
SO PROCEEDINGS 2018 16TH INTERNATIONAL CONFERENCE ON FRONTIERS IN
   HANDWRITING RECOGNITION (ICFHR)
SE International Conference on Handwriting Recognition
CT 16th International Conference on Frontiers in Handwriting Recognition
   (ICFHR)
CY AUG 05-08, 2018
CL Niagara Falls, NY
DE Handwriting Recognition; Language Model; Transfer Learning; Bootstrap;
   Historical Document Analysis
AB Not all languages and domains of handwriting have large labeled datasets available for training handwriting recognition (HWR) models. One way to address this problem is to leverage high resource languages to help train models for low resource languages. In this work, we adapt HWR models trained on a source language to a target language that uses the same writing script. We do so using only labeled data in the source language, unlabeled data in the target language, and a language model in the target language. The language model is used to produce target transcriptions to allow regular example based training. Using this approach we demonstrate improved transferability among French, English, and Spanish languages using both historical and modern handwriting datasets.
CR Sanchez JA, 2014, INT CONF FRONT HAND, P785, DOI 10.1109/ICFHR.2014.137
   Augustin E., 2006, WORKSH FRONT HANDWR
   Ball Gregory R, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P26, DOI 10.1109/ICDAR.2009.249
   Bluche Theodore, 2014, Statistical Language and Speech Processing. Second International Conference, SLSP 2014, P199, DOI 10.1007/978-3-319-11397-5_15
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Elarian Y, 2015, PATTERN RECOGN, V48, P849, DOI 10.1016/j.patcog.2014.09.013
   Frinken V, 2011, PROC INT CONF DOC, P314, DOI 10.1109/ICDAR.2011.71
   Granell E, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010015
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Koehn P., 2005, MT SUMMIT, P79, DOI DOI 10.3115/1626355.1626380
   Lee DH, 1998, INT J PATTERN RECOGN, V12, P45, DOI 10.1142/S0218001498000051
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Mohri M., 2008, SPRINGER HDB SPEECH, P559, DOI DOI 10.1007/978-3-540-49127-9_28
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Povey  D., 2011, WORKSH AUT SPEECH RE
   Serrano N., 2010, INT C LANG RES EV, P19
   Simard PY, 2003, SEVENTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P958
   TUNG CH, 1994, PATTERN RECOGN, V27, P221, DOI 10.1016/0031-3203(94)90055-8
   Varga T, 2008, STUD COMPUT INTELL, V90, P333
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Wigington Curtis, 2017, 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), P639, DOI 10.1109/ICDAR.2017.110
   Wolf C, 2002, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.2002.1048482
NR 24
TC 0
Z9 0
SN 2167-6445
BN 978-1-5386-5875-8
PY 2018
BP 133
EP 138
DI 10.1109/ICFHR-2018.2018.00032
UT WOS:000454983200023
ER

PT S
AU Granet, A
   Morin, E
   Mouchere, H
   Quiniou, S
   Viard-Gaudin, C
AF Granet, Adeline
   Morin, Emmanuel
   Mouchere, Harold
   Quiniou, Solen
   Viard-Gaudin, Christian
GP IEEE
TI Separating Optical and Language Models through Encoder-Decoder Strategy
   for Transferable Handwriting Recognition
SO PROCEEDINGS 2018 16TH INTERNATIONAL CONFERENCE ON FRONTIERS IN
   HANDWRITING RECOGNITION (ICFHR)
SE International Conference on Handwriting Recognition
CT 16th International Conference on Frontiers in Handwriting Recognition
   (ICFHR)
CY AUG 05-08, 2018
CL Niagara Falls, NY
DE Handwriting recognition; knowledge transfer; Optical model; Language
   model
AB Lack of data can be an issue when beginning a new study on historical handwritten documents. To deal with this, we propose a deep-learning based recognizer which separates the optical and the language models in order to train them separately using different resources. In this work, we present the optical encoder part of a multilingual transductive transfer learning applied to historical handwriting recognition. The optical encoder transforms the input word image into a non-latent space that depends only on the letter-n-grams: it enables it to be independent of the language. This transformation avoids embedding a language model and operating the transfer learning across languages using the same alphabet. The language decoder creates from a vector of letter-n-grams a word as a sequence of characters. Experiments show that separating optical and language model can be a solution for multilingual transfer learning.
CR Bahdanau D., 2014, P ICLR
   Bengio S., 2014, P INT
   Bluche T., 2017, P ICDAR
   Bojanowski Piotr, 2017, TACL, V5, P135, DOI DOI 10.1162/tacl_a_00051
   Cho Kyunghyun, 2014, P 8 WORKSH SYNT SEM, P103, DOI DOI 10.3115/V1/W14-4012
   Cloppet F, 2016, INT CONF FRONT HAND, P590, DOI [10.1109/ICFHR.2016.106, 10.1109/ICFHR.2016.0113]
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V., 2013, P 2 INT WORKSH HIST, P67
   Granell E, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010015
   Granet A., 2018, P LREC
   Granet A., 2018, P COLING
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Grosicki E, 2011, PROC INT CONF DOC, P1459, DOI 10.1109/ICDAR.2011.290
   Llados J., 2012, INT J PRAI, V26
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Nakayama H, 2017, MACH TRANSL, V31, P49, DOI 10.1007/s10590-017-9197-z
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sanchez Joan Andreu, 2017, 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), P1383, DOI 10.1109/ICDAR.2017.226
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
NR 20
TC 0
Z9 0
SN 2167-6445
BN 978-1-5386-5875-8
PY 2018
BP 309
EP 314
DI 10.1109/ICFHR-2018.2018.00061
UT WOS:000454983200052
ER

PT S
AU Roy, P
   Ghosh, S
   Pal, U
AF Roy, Prasun
   Ghosh, Subhankar
   Pal, Umapada
GP IEEE
TI A CNN Based Framework for Unistroke Numeral Recognition in Air-Writing
SO PROCEEDINGS 2018 16TH INTERNATIONAL CONFERENCE ON FRONTIERS IN
   HANDWRITING RECOGNITION (ICFHR)
SE International Conference on Handwriting Recognition
CT 16th International Conference on Frontiers in Handwriting Recognition
   (ICFHR)
CY AUG 05-08, 2018
CL Niagara Falls, NY
DE Air-writing; human-computer interaction; gesture recognition;
   handwritten character recognition; convolutional neural networks
AB Air-writing refers to virtually writing linguistic characters through hand gestures in three dimensional space with six degrees of freedom. In this paper a generic video camera dependent convolutional neural network (CNN) based air-writing framework has been proposed. Gestures are performed using a marker of fixed color in front of a generic video camera followed by color based segmentation to identify the marker and track the trajectory of marker tip. A pre-trained CNN is then used to classify the gesture. The recognition accuracy is further improved using transfer learning with the newly acquired data. The performance of the system varies greatly on the illumination condition due to color based segmentation. In a less fluctuating illumination condition the system is able to recognize isolated unistroke numerals of multiple languages. The proposed framework achieved 97.7%, 95.4% and 93.7% recognition rate in person independent evaluation over English, Bengali and Devanagari numerals, respectively.
CR Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P436, DOI 10.1109/THMS.2015.2492599
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Dash Ayushman, 2017, 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), P908, DOI 10.1109/ICDAR.2017.153
   Kristensson P. O., 2012, P 2012 ACM INT C INT, P89, DOI DOI 10.1145/2166966.2166983
   LeCun Y., 1998, MNIST DATABASE HANDW
   Microsoft Corporation, 2010, NON TRADITIONAL REF
   Pal U, 2007, ICDAR 2007: NINTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P749
   Schick A, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P217
NR 8
TC 0
Z9 0
SN 2167-6445
BN 978-1-5386-5875-8
PY 2018
BP 404
EP 409
DI 10.1109/ICFHR-2018.2018.00077
UT WOS:000454983200068
ER

PT S
AU Aradillas, JC
   Murillo-Fuentes, JJ
   Olmos, PM
AF Carlos Aradillas, Jose
   Jose Murillo-Fuentes, Juan
   Olmos, Pablo M.
GP IEEE
TI Boosting Handwriting Text Recognition in Small Databases with Transfer
   Learning
SO PROCEEDINGS 2018 16TH INTERNATIONAL CONFERENCE ON FRONTIERS IN
   HANDWRITING RECOGNITION (ICFHR)
SE International Conference on Handwriting Recognition
CT 16th International Conference on Frontiers in Handwriting Recognition
   (ICFHR)
CY AUG 05-08, 2018
CL Niagara Falls, NY
AB In this paper we deal with the offline handwriting text recognition (HTR) problem with reduced training data sets. Recent HTR solutions based on artificial neural networks exhibit remarkable solutions in referenced databases. These deep learning neural networks are composed of both convolutional (CNN) and long short-term memory recurrent units (LSTM). In addition, connectionist temporal classification (CTC) is the key to avoid segmentation at character level, greatly facilitating the labeling task. One of the main drawbacks of the CNN-LSTM-CTC (CRNN) solutions is that they need a considerable part of the text to be transcribed for every type of calligraphy, typically in the order of a few thousands of lines. Furthermore, in some scenarios the text to transcribe is not that long, e.g. in the Washington database. The CRNN typically overfits for this reduced number of training samples. Our proposal is based on the transfer learning (TL) from the parameters learned with a bigger database. We first investigate, for a reduced and fixed number of training samples, 350 lines, how the learning from a large database, the IAM, can be transferred to the learning of the CRNN of a reduced database, Washington. We focus on which layers of the network could not be re-trained. We conclude that the best solution is to re-train the whole CRNN parameters initialized to the values obtained after the training of the CRNN from the larger database. We also investigate results when the training size is further reduced. For the sake of comparison, we study the character error rate (CER) with no dictionary or any language modeling technique. The differences in the CER are more remarkable when training with just 350 lines, a CER of 3.3% is achieved with TL while we have a CER of 18.2% when training from scratch. As a byproduct, the learning times are quite reduced. Similar good results are obtained from the Parzival database when trained with this reduced number of lines and this new approach.
CR Bluche T., 2016, SCAN ATTEND READ END
   Bluche T., 2016, P ADV NEUR INF PROC, V29, P838
   Bluche T, 2013, PROC INT CONF DOC, P285, DOI 10.1109/ICDAR.2013.64
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Granet A., 2018, INT C PATT REC APPL
   Graves A., 2009, ADV NEURAL INFORM PR, V21, P545
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Grosicki Emmanuele, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1398, DOI 10.1109/ICDAR.2009.184
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Kingma D. P., 2014, INT C LEARN REPR
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Puigcerver Joan, 2017, 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), P67, DOI 10.1109/ICDAR.2017.20
   Serrano N., 2010, LREC
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Yaeger L., 1996, NIPS, P807
   Yousefi MR, 2015, 2015 13TH IAPR INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), P1121, DOI 10.1109/ICDAR.2015.7333935
NR 20
TC 0
Z9 0
SN 2167-6445
BN 978-1-5386-5875-8
PY 2018
BP 429
EP 434
DI 10.1109/ICFHR-2018.2018.00081
UT WOS:000454983200072
ER

PT B
AU Azarbarzin, S
   Afsari, F
AF Azarbarzin, Samaneh
   Afsari, Fatemeh
GP IEEE
TI Robust two stage unsupervised metric learning for domain adaptation
SO 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING
   (ICCKE)
CT 8th International Conference on Computer and Knowledge Engineering
   (ICCKE)
CY OCT 25-26, 2018
CL Ferdowsi Univ Mashhad, Mashhad, IRAN
HO Ferdowsi Univ Mashhad
DE transfer learning; metric learning; marginalized denoising; low-rank
   constraint
AB Most commonly used metric learning procedures suppose that the input feature space and domain of the training and test data are identical. In such cases these algorithms cannot improve target learning problems. This paper presents a robust distance metric for domain adaptation in two stages. At first stage both source and target features are transferred to a newly found latent feature space, which minimizes the difference between domains as well as the data properties are preserved. Then in the second stage, the desired metric is learned with a marginalized denoising strategy and the low-rank constraint. To show the superiority and power of the proposed method it is tested on distinct kinds of cross-domain image categorization datasets and the results prove that our approach remarkably exceeds other existing domain adaptation algorithms in the classification tasks.
CR Alcala-Fdez J, 2009, SOFT COMPUT, V13, P307, DOI 10.1007/s00500-008-0323-y
   Bellet A., 2013, ARXIV13066709
   Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299
   Chen M., 2012, ARXIV12064683
   Davis JV, 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.1273523
   Ding Z., 2015, P 11 IEEE INT C WORK, V1, P1
   Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887
   Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107
   Guoqiang Zhong, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1266, DOI 10.1109/ICDM.2011.95
   Hu J, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Li Z., 2012, P ACM INT C MULT, P853
   Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386
   Liu Wei, 2015, P 29 AAAI C ART INT, P2792
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang H., 2014, AAAI, P2099
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xing Eric P., 2003, ADV NEURAL INFORM PR, P521
   Zhang Y., 2010, P 16 ACM SIGKDD INT, P1199, DOI DOI 10.1145/1835804.1835954
NR 25
TC 0
Z9 0
BN 978-1-5386-9569-2
PY 2018
BP 52
EP 57
UT WOS:000455025700010
ER

PT B
AU Taghiyarrenani, Z
   Fanian, A
   Mahdavi, E
   Mirzaei, A
   Farsi, H
AF Taghiyarrenani, Zahra
   Fanian, Ali
   Mahdavi, Ehsan
   Mirzaei, Abdolreza
   Farsi, Hamed
GP IEEE
TI Transfer Learning based Intrusion Detection
SO 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING
   (ICCKE)
CT 8th International Conference on Computer and Knowledge Engineering
   (ICCKE)
CY OCT 25-26, 2018
CL Ferdowsi Univ Mashhad, Mashhad, IRAN
HO Ferdowsi Univ Mashhad
DE machine learning; intrusion detection; transfer learning; training
   samples
AB In the past decades, machine learning based intrusion detection systems have been developed. This paper discloses a new aspect of machine learning based intrusion detection systems. The proposed method detects normal and anomaly behaviors in the desired network where there are not any labeled samples as training dataset. That is while a plenty of labeled samples may exist in another network that is different from the desired network. Because of the difference between two networks, their samples produce in different manners. So, direct utilizing of labeled samples of a different network as training samples does not provide acceptable accuracy to detect anomaly behaviors in the desired network. In this paper, we propose a transfer learning based intrusion detection method which transfers knowledge between the networks and eliminates the problem of providing training samples that is a costly procedure. Comparing the experimental results with the results of a basic machine learning method (SVM) and also baseline method(DAMA) shows the effectiveness of the proposed method for transferring knowledge for intrusion detection systems.
CR Agrawal S, 2015, PROCEDIA COMPUT SCI, V60, P708, DOI 10.1016/j.procs.2015.08.220
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Gao J, 2008, KDD, P283, DOI DOI 10.1145/1401890.1401928
   Ham JH, 2003, LEARNING HIGH DIMENS
   Haq Nutan Farah, 2015, International Journal of Advanced Research in Artificial Intelligence, V4, P9
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Singh J., 2013, INT J ADV RES COMPUT, V2, P4349
   Tao JW, 2012, PATTERN RECOGN, V45, P3962, DOI 10.1016/j.patcog.2012.04.014
   Vapnik V., 2013, NATURE STAT LEARNING
   Wang C., 2011, IJCAI, P1541
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
NR 17
TC 0
Z9 0
BN 978-1-5386-9569-2
PY 2018
BP 92
EP 97
UT WOS:000455025700017
ER

PT S
AU Kloss, RB
   Ao, AJ
   Schwartz, WR
AF Kloss, Ricardo Barbosa
   Ao, Artur Jord
   Schwartz, William Robson
GP IEEE
TI Face Verification: Strategies for Employing Deep Models
SO PROCEEDINGS 2018 13TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE &
   GESTURE RECOGNITION (FG 2018)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 13th IEEE International Conference on Automatic Face & Gesture
   Recognition (FG)
CY MAY 15-19, 2018
CL Xi an, PEOPLES R CHINA
DE Transfer Learning; Artificial Neural Networks; Face Verification; Metric
   Learning
AB Features extracted with deep learning have now achieved state-of-the-art results in many tasks. However, to reuse a learned deep model, transfer learning with fine-tuning needs to be employed, which requires to re-train the whole model or part of it to extract useful features in the new domain. This step is burdensome and requires heavy computing power. Therefore, this work investigates alternatives in transfer-learning that do not involve performing fine-tuning for a model with the new domain. Namely, we explore the correlation of depth and scale in deep models, and look for the layer/scale that yields the best results for the new domain, we also explore metrics for the verification task, using locally connected convolutions to learn distance metrics. Our experiments use a model pre-trained in face identification and adapt it to the face verification task with different data, but still on the face domain. We achieve 96.65% mean accuracy on the Labeled Faces in the Wild dataset and 93.12% mean accuracy on the Youtube Faces dataset comparable to the state-of-the-art.
OI Schwartz, William/0000-0003-1449-8834
CR Chellappa R, 2010, COMPUTER, V43, P46, DOI 10.1109/MC.2010.37
   Haykin S., 2001, NEURAL NETWORKS COMP
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang G. B., 2012, NIPS
   Huang GL, 2017, IEEE ICC
   Jain R., 1990, ART COMPUTER SYSTEMS
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Ouamane A., 2015, AUT FAC GEST REC FG, V02, P1, DOI DOI 10.1109/FG.2015.7284837
   Parkhi O. M., 2015, BRIT MACH VIS C
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wagner Andrew, 2012, T PATTERN ANAL MACHI
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wright John, 2009, T PATTERN ANAL MACHI
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 23
TC 0
Z9 0
SN 2326-5396
BN 978-1-5386-2335-0
PY 2018
BP 258
EP 262
DI 10.1109/FG.2018.00045
UT WOS:000454996700035
ER

PT S
AU Yang, HY
   Zhang, Z
   Yin, LJ
AF Yang, Huiyuan
   Zhang, Zheng
   Yin, Lijun
GP IEEE
TI Identity-Adaptive Facial Expression Recognition Through Expression
   Regeneration Using Conditional Generative Adversarial Networks
SO PROCEEDINGS 2018 13TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE &
   GESTURE RECOGNITION (FG 2018)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 13th IEEE International Conference on Automatic Face & Gesture
   Recognition (FG)
CY MAY 15-19, 2018
CL Xi an, PEOPLES R CHINA
DE FER; GAN; Identity-adaptive; CNN
AB Subject variation is a challenging issue for facial expression recognition, especially when handling unseen subjects with small-scale lableled facial expression databases. Although transfer learning has been widely used to tackle the problem, the performance degrades on new data. In this paper, we present a novel approach (so-called LA-gen) to alleviate the issue of subject variations by regenerating expressions from any input facial images. First of all, we train conditional generative models to generate six prototypic facial expressions from any given query face image while keeping the identity related information unchanged. Generative Adversarial Networks are employed to train the conditional generative models, and each of them is designed to generate one of the prototypic facial expression images. Second, a regular CNN (FER-Net) is fine-tuned for expression classification. After the corresponding prototypic facial expressions are regenerated from each facial image, we output the last EC layer of FER-Net as features for both the input image and the generated images. Based on the minimum distance between the input image and the generated expression images in the feature space, the input image is classified as one of the prototypic expressions consequently. Our proposed method can not only alleviate the influence of inter-subject variations, but will also be flexible enough to integrate with any other FER CNNs for person-independent facial expression recognition. Our method has been evaluated on CK+, Oulu-CASIA, BU-3DFE and BU-4DFE databases, and the results demonstrate the effectiveness of our proposed method.
CR Abadi M., 2016, ARXIV160304467
   Berretti S, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Chen J., 2013, PATTERN RECOGNITION, V34
   Dapogny A., 2015, FG, V1
   Dapogny A, 2015, IEEE I CONF COMP VIS, P3783, DOI 10.1109/ICCV.2015.431
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Gauthier J., 2014, CLASS PROJECT STANFO, V2014, P2
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45
   Isola Phillip, 2016, ARXIV161107004
   Jeni L. A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2168, DOI 10.1109/ICCVW.2011.6130516
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Klaser Alexander, 2008, BMVC 2008 19 BRIT MA, P275
   Ledig C., 2016, PHOTOREALISTIC SINGL
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, CVPR WORKSH
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Mirza M., 2014, ARXIV14111784, DOI DOI 10.1029/2009WR008312
   Mollahosseini A., 2016, APPL COMPUTER VISION
   Pan ZL, 2016, LECT NOTES ARTIF INT, V10011, P369, DOI 10.1007/978-3-319-47665-0_35
   Radford A., 2015, ARXIV151106434
   Ronneberger O., 2015, INT C MED IM COMP CO
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Wang J., 2006, P IEEE INT C COMP VI, P1399
   Xudong Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163090
   Yin L, 2008, AUTOMATIC FACE GESTU, P1, DOI DOI 10.1109/AFGR.2008.4813324
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeiler M. D., 2014, EUR C COMP VIS, P818, DOI DOI 10.1007/978-3-319-10590-1_53
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 39
TC 2
Z9 2
SN 2326-5396
BN 978-1-5386-2335-0
PY 2018
BP 294
EP 301
DI 10.1109/FG.2018.00050
UT WOS:000454996700040
ER

PT S
AU Luo, ZM
   Hu, JN
   Deng, WH
   Shen, HF
AF Luo, Zimeng
   Hu, Jiani
   Deng, Weihong
   Shen, Haifeng
GP IEEE
TI Deep Unsupervised Domain Adaptation for Face Recognition
SO PROCEEDINGS 2018 13TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE &
   GESTURE RECOGNITION (FG 2018)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 13th IEEE International Conference on Automatic Face & Gesture
   Recognition (FG)
CY MAY 15-19, 2018
CL Xi an, PEOPLES R CHINA
AB Face recognition is challenge task which involves determining the identity of facial images. With availability of a massive amount of labeled facial images gathered from Internet, deep convolution neural networks(DCNNs) have achieved great success in face recognition tasks. Those images are gathered from unconstrain environment, which contain people with different ethnicity, age, gender and so on. However, in the actual application scenario, the target face database may be gathered under different conditions compered with source training dataset, e.g. different ethnicity, different age distribution, disparate shooting environment. These factors increase domain discrepancy between source training database and target application database and make the learnt model degenerate in target database. Meanwhile, for the target database where labeled data are lacking or unavailable, directly using target data to fine-tune pre-learnt model becomes intractable and impractical. In this paper, we adopt unsupervised transfer learning methods to address this issue. To alleviate the discrepancy between source and target face database and ensure the generalization ability of the model, we constrain the maximum mean discrepancy (MMD) between source database and target database and utilize the massive amount of labeled facial images of source database to training the deep neural network at the same time. We evaluate our method on two face recognition benchmarks and significantly enhance the performance without utilizing the target label.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen B., 2017, IEEE C COMP VIS PATT
   Gretton A., 2012, ADV NEURAL INFORM PR, P1205
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang G. B., 2007, 0749 U MASS
   Kan MN, 2015, IEEE I CONF COMP VIS, P3846, DOI 10.1109/ICCV.2015.438
   KEMELMACHERSHLIZER, 2016, P IEEE C COMP VIS PA, P4873, DOI DOI 10.1109/CVPR.2016.527
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Long M., 2015, INT C MACH LEARN, P97
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Phillips PJ, 2017, IEEE INT CONF AUTOMA, P705, DOI 10.1109/FG.2017.89
   Phillips PJ, 2012, IMAGE VISION COMPUT, V30, P177, DOI 10.1016/j.imavis.2012.01.004
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K., 2014, COMPUTER SCI
   Tzeng E., 2014, ARXIV14123474
   Wen  Y., 2016, DISCRIMINATIVE FEATU
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Yan H, 2017, IEEE GLOB COMM CONF
   Yi D., 2014, ARXIV14117923
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhang J, 2017, IEEE GLOB COMM CONF
NR 25
TC 0
Z9 0
SN 2326-5396
BN 978-1-5386-2335-0
PY 2018
BP 453
EP 457
DI 10.1109/FG.2018.00073
UT WOS:000454996700063
ER

PT S
AU Peng, M
   Wu, Z
   Zhang, ZH
   Chen, T
AF Peng, Min
   Wu, Zhan
   Zhang, Zhihao
   Chen, Tong
GP IEEE
TI From Macro to Micro Expression Recognition: Deep Learning on Small
   Datasets Using Transfer Learning
SO PROCEEDINGS 2018 13TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE &
   GESTURE RECOGNITION (FG 2018)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 13th IEEE International Conference on Automatic Face & Gesture
   Recognition (FG)
CY MAY 15-19, 2018
CL Xi an, PEOPLES R CHINA
DE micro expression recognition; deep learning; trasnfer learning
AB This paper presents the methods used in our submission to 2018 Facial Micro-Expression Grand Challenge (MEGC). The object of the challenge is to recognize micro-expression in two provided databases, including holdout-database recognition and composite database recognition. Considering the small size of the databases, we follow a rout of transfer learning to implement convolutional neural network to recognize the micro expression. ResNetlO pre-trained on ImageNet dataset was fine-tuned on macro-expression datasets with large size and then on the provided micro-expression datasets. Experimental results show that the method can achieve weighted average recall (WAR) of 0.561 and unweighted average recall (UAR) of 0.389 in Holdout-database Evaluation Task, and F1 Score of 0.64 in Composite Database Evaluation Task, which are much higher than what baseline methods (LBP-TOP, HOOF, HOG3D) can achieve.
CR Aifanti N., 2010, P 11 INT WORKSH AN M
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484
   Davison A. K., ARXIV170807549
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Kamishima T., 2010, J JAPANESE SOC ARTIF, V25, P572
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Liu W., ARXIV14094842
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lucey P., 2010, IEEE COMP SOC C COMP, V2010, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Porter S, 2008, PSYCHOL SCI, V19, P508, DOI 10.1111/j.1467-9280.2008.02116.x
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell TA, 2006, BRIT J CLIN PSYCHOL, V45, P579, DOI 10.1348/014466505X90866
   Sherwood T, 2016, SOFTWARE PRACT EXPER, V46, P931, DOI 10.1002/spe.2339
   Simon M., ARXIV161201452
   Wang Y., 2014, P AS C COMP VIS SING, P21
   Weinberger S, 2010, NATURE, V465, P412, DOI 10.1038/465412a
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 25
TC 1
Z9 1
SN 2326-5396
BN 978-1-5386-2335-0
PY 2018
BP 657
EP 661
DI 10.1109/FG.2018.00103
UT WOS:000454996700093
ER

PT S
AU Guo, X
   Polania, LF
   Barner, KE
AF Guo, Xin
   Polania, Luisa F.
   Barner, Kenneth E.
GP IEEE
TI Smile Detection in the Wild Based on Transfer Learning
SO PROCEEDINGS 2018 13TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE &
   GESTURE RECOGNITION (FG 2018)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 13th IEEE International Conference on Automatic Face & Gesture
   Recognition (FG)
CY MAY 15-19, 2018
CL Xi an, PEOPLES R CHINA
DE smile detection; CNN; deep learning; transfer learning
AB Smile detection from unconstrained facial images is a specialized and challenging problem. As one of the most informative expressions, smiles convey basic underlying emotions, such as happiness and satisfaction, and leads to multiple applications, such as human behavior analysis and interactive controlling. Compared to the size of databases for face recognition, far less labeled data is available for training smile detection systems. This paper proposes an efficient transfer learning-based smile detection approach to leverage the large amount of labeled data from face recognition datasets and to alleviate overfitting on smile detection. A well-trained deep face recognition model is explored and fine-tuned for smile detection in the wild, unlike previous works which use either hand-engineered features or train deep convolutional networks from scratch. Three different models are built as a result of fine-tuning the face recognition model with different inputs, including aligned, unaligned and grayscale images generated from the GENKI-4K dataset. Experiments show that the proposed approach achieves improved state-of-the-art performance. Robustness of the model to noise and blur artifacts is also evaluated in this paper.
CR Abel EL, 2010, PSYCHOL SCI, V21, P542, DOI 10.1177/0956797610363775
   An L, 2015, NEUROCOMPUTING, V149, P354, DOI 10.1016/j.neucom.2014.04.072
   Chen J., 2016, MICROCHIM ACTA, V76, P1
   Deniz O, 2008, LECT NOTES COMPUT SC, V5359, P602, DOI 10.1007/978-3-540-89646-3_59
   Dodge S., 2016, ARXIV160404004
   Ekman P., 1988, SELF DECEPTION ADAPT, P229
   Freire-Obregon D., 2009, P COMP VIS THEOR APP
   Gao Y, 2016, NEUROCOMPUTING, V174, P1077, DOI 10.1016/j.neucom.2015.10.022
   Glauner P.O., 2015, ARXIV150806535
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Harker LA, 2001, J PERS SOC PSYCHOL, V80, P112, DOI 10.1037//0022-3514.80.1.112
   Jain V., 2014, 12 WSEAS INT C SIGN
   Kazemi V., 2014, P IEEE C COMP VIS PA
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LeCun Yann, 1995, HDB BRAIN THEORY NEU, V3361, P10
   Liu M., 2012, LNCS, P577, DOI DOI 10.1007/978-3-642-37444-9_
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Parkhi  O.M., 2015, P BRIT MACH VIS C BM
   Potapova E., 2009, GRAPHICON 2009 P 19, P117
   Seder JP, 2012, SOC PSYCHOL PERS SCI, V3, P407, DOI 10.1177/1948550611424968
   Shan CF, 2012, IEEE T IMAGE PROCESS, V21, P431, DOI 10.1109/TIP.2011.2161587
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Tavares C., 2004, System and method for capturing and using biometrics to review a product, service, creative work or thing, Patent No. [uS Patent App. 10/876,848, 10876848]
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Yadappanavar H., 2012, INT J IMAGE PROCESSI, V1
   Zhang KH, 2015, Proceedings 3rd IAPR Asian Conference on Pattern Recognition ACPR 2015, P534, DOI 10.1109/ACPR.2015.7486560
NR 29
TC 0
Z9 0
SN 2326-5396
BN 978-1-5386-2335-0
PY 2018
BP 679
EP 686
DI 10.1109/FG.2018.00107
UT WOS:000454996700097
ER

PT S
AU Chen, DM
   Yang, S
   Zhou, FN
AF Chen, Danmin
   Yang, Shuai
   Zhou, Funa
GP IEEE
TI Incipient Fault Diagnosis Based on DNN with Transfer Learning
SO 2018 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND INFORMATION
   SCIENCES (ICCAIS)
SE International Conference on Control Automation and Information Sciences
CT 7th International Conference on Control Automation and Information
   Sciences (ICCAIS)
CY OCT 24-27, 2018
CL Hangzhou Dianzi Univ, Hangzhou, PEOPLES R CHINA
HO Hangzhou Dianzi Univ
DE incipient fault diagnosis; DNN; transfer learning
AB Diagnosis of incipient fault is critical for safe operation of the system because it can prevent disastrous accidents from happening by diagnosing the early fault before deterioration. Deep learning is efficient in feature extraction but it requires a large number of samples to train traditional deep neural network (DNN). It is thus inevitable that the efficiency of DNN will be affected when it is applied to incipient fault diagnosis for there are usually a very limited number of incipient fault samples. Furthermore, a large amount of information involved in significant fault samples was not adequately used for incipient fault diagnosis. To solve this problem, this paper proposes an incipient fault diagnosis model with DNN-based transfer learning. The model can extract fault feature involved in a large number of significant fault samples and apply it to extract insignificant fault feature with a small number of incipient fault samples. In this way, the proposed transfer learning method can efficiently diagnose incipient fault in the case when only a limited number of incipient fault data is available. The efficiency of the proposed model is demonstrated by utilizing the Case Western Reserve University bearing data set.
CR Cao Hongliu, 2018, ICIAR 2018, P779
   Cao P, 2018, IEEE ACCESS, V6, P26241, DOI 10.1109/ACCESS.2018.2837621
   Delpha C, 2018, ENG APPL ARTIF INTEL, V73, P68, DOI 10.1016/j.engappai.2018.04.007
   Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887
   Han DM, 2018, EXPERT SYST APPL, V95, P43, DOI 10.1016/j.eswa.2017.11.028
   Huang DR, 2018, IEEE ACCESS, V6, P26001, DOI 10.1109/ACCESS.2018.2829803
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   LI Q, 2017, ENTROPY-SWITZ, V19, DOI DOI 10.3390/E19080421
   Li WH, 2010, INT J MODEL IDENTIF, V10, P246, DOI 10.1504/IJMIC.2010.034577
   Li YB, 2017, IEEE T IND ELECTRON, V64, P6506, DOI 10.1109/TIE.2017.2650873
   Namdari M, 2014, ENG APPL ARTIF INTEL, V28, P22, DOI 10.1016/j.engappai.2013.11.013
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Turki T, 2017, IEEE ACCESS, V5, P7381, DOI 10.1109/ACCESS.2017.2696523
   Wagh N, 2014, APPL COMPUT INTELL S, DOI 10.1155/2014/845815
   Xiao Yang, 2017, ASONAM 2017, P341
   Xu LJ, 2010, CIRC SYST SIGNAL PR, V29, P577, DOI 10.1007/s00034-010-9160-1
   Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258
   Yue Du, ANN BIOMEDICAL ENG
   Zhang R, 2017, IEEE ACCESS, V5, P14347, DOI 10.1109/ACCESS.2017.2720965
   Zhao CH, 2017, P AMER CONTR CONF, P5430, DOI 10.23919/ACC.2017.7963799
   Zoph Barret, 2016, EMNLP 2016, P1568
NR 21
TC 0
Z9 0
SN 2475-7896
BN 978-1-5386-6020-1
PY 2018
BP 303
EP 308
UT WOS:000454989200056
ER

PT B
AU Wang, M
   Wu, ZY
   Wu, XX
   Meng, H
   Kang, SY
   Jia, J
   Cai, LH
AF Wang, Mu
   Wu, Zhiyong
   Wu, Xixin
   Meng, Helen
   Kang, Shiyin
   Jia, Jia
   Cai, Lianhong
GP IEEE
TI Emphatic Speech Synthesis and Control Based on Characteristic
   Transferring in End-to-End Speech Synthesis
SO 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT
   INTERACTION (ACII ASIA)
CT 1st Asian Conference on Affective Computing and Intelligent Interaction
   (ACII Asia)
CY MAY 20-22, 2018
CL Beijing, PEOPLES R CHINA
DE end-to-end; expressive speech; multi-speaker speech synthesis; transfer
   learning; emphatic speech
AB End-to-end text-to-speech (E2E TTS) synthesis has achieved great success. This work investigates the emphatic speech synthesis and control mechanisms in the E2E framework and proposes an E2E-based method for transferring emphasis characteristic between speakers. Characteristic differences between emphatic and neutral speech are learned from a small-scale corpus containing parallel neutral and emphasis speech utterances recorded by one speaker and further transferred to another speaker so that we can generate emphatic speech with latter speakers voice. Emphasis embedding is injected to the encoder of the extended E2E TTS model to capture the aforementioned differences; while the decoder and attention module are used to decode those differences into synthetic neutral / emphatic speech. Speaker codes linked to the decoder and attention module provide the E2E model the ability for characteristic transferring between speakers. To control the emphatic strength, an encoder memory manipulation mechanism is proposed. Experimental results indicate the effectiveness of our proposed model.
CR Arik S., 2017, P 34 INT C MACH LEAR, P195
   Arik Sercan, 2017, P NIPS, P2966
   Chen Szu-wei, 2009, P ANN C INT SPEECH C
   Costa Francisco, 2004, P INT C SPEECH PROS
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Henter GE, 2017, INTERSPEECH, P3956, DOI 10.21437/Interspeech.2017-171
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Luong HT, 2017, INT CONF ACOUST SPEE, P4905, DOI 10.1109/ICASSP.2017.7953089
   Ning YS, 2015, INT CONF ACOUST SPEE, P4934, DOI 10.1109/ICASSP.2015.7178909
   Nose T, 2007, IEICE T INF SYST, VE90D, P1406, DOI 10.1093/ietisy/e90-d.9.1406
   Wang Yunjia, 2006, CHINESE TEACHING WOR, V2, P12
   Wang Yuxuan, 2017, ABS170310135 CORR
   Yamagishi J, 2007, IEICE T INF SYST, VE90D, P533, DOI 10.1093/ietisy/e90-d.2.533
NR 13
TC 0
Z9 0
BN 978-1-5386-5311-1
PY 2018
UT WOS:000454864700012
ER

PT B
AU Chen, CT
   Chen, AP
   Huang, SH
AF Chen, Chiao-Ting
   Chen, An-Pin
   Huang, Szu-Hao
GP IEEE
TI Cloning Strategies from Trading Records using Agent-based Reinforcement
   Learning Algorithm
SO 2018 IEEE INTERNATIONAL CONFERENCE ON AGENTS (ICA)
CT IEEE International Conference on Agents (ICA)
CY JUL 28-31, 2018
CL Nanyang Technolog Univ, Singapore, SINGAPORE
HO Nanyang Technolog Univ
DE reinforcement learning; policy gradient financial trading; transfer
   learning; strategy cloning
AB Investment decision making is considered as a series of complicated processes, which are difficult to be analyzed and imitated. Given large amounts of trading records with rich expert knowledge in financial domain, extracting its original decision logics and cloning the trading strategies are also quite challenging. In this paper, an agent-based reinforcement learning (RL) system is proposed to mimic professional trading strategies. The concept of continuous Markov decision process (MDP) in RL is similar to the trading decision making in financial time series data. With the specific-designed RL components, including states, actions, and rewards for financial applications, policy gradient method can successfully imitate the expert's strategies. In order to improve the convergence of RL agent in such highly dynamic environment, a pre-trained model based on supervised learning is transferred to the deep policy networks. The experimental results show that the proposed system can reproduce around eighty percent trading decisions both in training and testing stages. With the discussion of the tradeoff between explorations and model updating, this paper tried to fine-tuning the system parameters to get reasonable results. Finally, an advanced strategy is proposed to dynamically adjust the number of explorations in each episode to achieve better results.
CR Chen Y, 2008, J ADV COMPUT INTELL, V12, P383, DOI 10.20965/jaciii.2008.p0383
   Dempster MAH, 2006, EXPERT SYST APPL, V30, P543, DOI 10.1016/j.eswa.2005.10.012
   Deng Y., 2016, IEEE T NEUR NET LEAR, V99, P1
   Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209
   Lee JW, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P690, DOI 10.1109/ISIE.2001.931880
   Moody J, 2001, IEEE T NEURAL NETWOR, V12, P875, DOI 10.1109/72.935097
   Nevmyvaka Y, 2006, P 23 INT C MACH LEAR, P673, DOI DOI 10.1145/.1143929
   Takeuchi L., 2013, APPL DEEP LEARNING E
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1023/A:1022672621406
NR 9
TC 0
Z9 0
BN 978-1-5386-8180-0
PY 2018
BP 34
EP 37
UT WOS:000454758300007
ER

PT B
AU Spryn, M
   Sharma, A
   Parkar, D
   Shrimal, M
AF Spryn, Mitchell
   Sharma, Aditya
   Parkar, Dhawal
   Shrimal, Madhur
GP IEEE
TI Distributed Deep Reinforcement Learning on the Cloud for Autonomous
   Driving
SO PROCEEDINGS 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE
   ENGINEERING FOR AI IN AUTONOMOUS SYSTEMS (SEFAIAS)
CT 1st IEEE/ACM International Workshop on Software Engineering for AI in
   Autonomous Systems (SEFAIAS)
CY MAY 28, 2018
CL Gothenburg, SWEDEN
DE Autonomous Driving; Deep Reinforcement Learning; Distributed Machine
   Learning; Cloud Computing; Simulation
AB This paper proposes an architecture for leveraging cloud computing technology to reduce training time for deep reinforcement learning models for autonomous driving by distributing the training process across a pool of virtual machines. By parallelizing the training process, careful design of the reward function and use of techniques like transfer learning, we demonstrate a decrease in training time for our example autonomous driving problem from 140 hours to less than 1 hour. We go over our network architecture, job distribution paradigm, reward function design and report results from experiments on small sized cluster (1-6 training nodes) of machines. We also discuss the limitations of our approach when trying to scale up to massive clusters.
CR Abadi M, 2015, TENSORFLOW LARGE SCA
   Abdou M., 2016, END TO END DEEP REIN
   Bojarski M., 2016, CORR
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chollet  F., 2015, KERAS
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   John Christopher, 1989, THESIS
   Kalra N., 2016, DRIVING SAFETY MANY
   Melo Francisco S., CONVERGENCE Q LEARNI
   Mnih V., 2013, NIPS DEEP LEARN WORK
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nair A., 2015, CORR
   Shah S., 2017, FIELD SERVICE ROBOTI
   Shalev-Shwartz Shai, 2016, CORR
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhang Wei, 2015, CORR
NR 19
TC 0
Z9 0
BN 978-1-4503-5739-5
PY 2018
BP 16
EP 22
DI 10.1145/3194085.3194088
UT WOS:000454722500004
ER

PT S
AU Delas Penas, K
   Rivera, PT
   Naval, PC
AF Delas Penas, Kristofer
   Rivera, Pilarita T.
   Naval, Prospero C., Jr.
BE Nguyen, NT
   Hoang, DH
   Hong, TP
   Pham, H
   Trawinski, B
TI Analysis of Convolutional Neural Networks and Shape Features for
   Detection and Identification of Malaria Parasites on Thin Blood Smears
SO INTELLIGENT INFORMATION AND DATABASE SYSTEMS, ACIIDS 2018, PT II
SE Lecture Notes in Artificial Intelligence
CT 10th Asian Conference on Intelligent Information and Database Systems
   (ACIIDS)
CY MAR 19-21, 2018
CL Dong Hoi, VIETNAM
AB The gold standard for malaria diagnosis still remains to be microscopy. However, cases from remote areas needing immediate diagnosis and treatment can benefit from a faster diagnostic process. Several intelligent systems for malaria diagnosis have been proposed using different computer vision techniques. In this research, models using convolutional neural networks, and a model using extracted shape features are implemented and compared. The CNN models, one trained from scratch and the other utilizing transfer learning, with accuracies of 92.4% and 93.60%, both outperform the shape feature model in malaria parasite recognition.
CR [Anonymous], 2016, WORLD MAL REP 2016
   Centers for Disease Control Prevention, 2015, MAL
   Delas Penas KE, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P1, DOI 10.1109/CHASE.2017.51
   Makkapati VV, 2009, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.2009.4959845
   Math Works, 2014, MEAS PROP IM REG
   Nanoti A., 2016, P 2016 INT C INV COM, V1, P1
   Paniker C.J., 2013, PANIKERS TXB MED PAR
   Pinkaew A, 2015, 2015 8TH BIOMEDICAL ENGINEERING INTERNATIONAL CONFERENCE (BMEICON)
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
NR 9
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-75420-8; 978-3-319-75419-2
PY 2018
VL 10752
BP 472
EP 481
DI 10.1007/978-3-319-75420-8_45
UT WOS:000453510500045
ER

PT S
AU Moon, T
   Nakamura, N
   Gonsalves, T
AF Moon, TaeJun
   Nakamura, Noriyuki
   Gonsalves, Tad
BE Su, R
TI Obstacle detection and recognition using SSD
SO 2018 INTERNATIONAL CONFERENCE ON IMAGE AND VIDEO PROCESSING, AND
   ARTIFICIAL INTELLIGENCE
SE Proceedings of SPIE
CT International Conference on Image and Video Processing, and Artificial
   Intelligence (IVPAI)
CY AUG 15-17, 2018
CL Shanghai, PEOPLES R CHINA
DE Times Roman; image area; acronyms; references
AB Fast obstacle detection is essential for autonomous driving. In this research, we have developed an obstacle detection model using Single Shot Multi Box Detector. SSD is a regression-based object detecting convolutional neural network that takes images as an input to compute localization and classification at once. By using SSD, processing time is dramatically reduced compare to multi shot detector. SSD object detection model was trained using APIs provided by Google in different patterns of number of classes and availability of transfer learning. Increase of the number of classes tended to decrease the detection rate. Training with transfer learning increased the average precision in general. The effectiveness of transfer learning in image recognition can be confirmed. Also there is a difference in average precision depending on the class.
CR Everingham M, 2018, PASCAL          0512
   Liu W., 2015, ARXIV151202325
   Okaya Takayuki, 2015, MLP MACHINE LEARNING
   Ren  Shaoqing, 2016, ARXIV150601497V3
   Russakovsky O., 2014, ARXIV14090575
   Tatsuya Harada, 2017, MLP MACHINE LEARNING
NR 6
TC 0
Z9 0
SN 0277-786X
EI 1996-756X
BN 978-1-5106-2311-8
PY 2018
VL 10836
AR UNSP 108360M
DI 10.1117/12.2514269
UT WOS:000452643100020
ER

PT B
AU Silva, PH
   Luz, E
   Zanlorensi, LA
   Menotti, D
   Moreira, G
AF Silva, Pedro H.
   Luz, Eduardo
   Zanlorensi, Luiz A., Jr.
   Menotti, David
   Moreira, Gladston
GP IEEE
TI Multimodal Feature Level Fusion based on Particle Swarm Optimization
   with Deep Transfer Learning
SO 2018 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)
SE IEEE Congress on Evolutionary Computation
CT IEEE Congress on Evolutionary Computation (IEEE CEC) as part of the IEEE
   World Congress on Computational Intelligence (IEEE WCCI)
CY JUL 08-13, 2018
CL Rio de Janeiro, BRAZIL
AB There are several biometric-based systems which rely on a single biometric modality, most of them focus on face, iris or fingerprint. Despite the good accuracies obtained with single modalities, these systems are more susceptible to attacks, i.e, spoofing attacks, and noises of all kinds, especially in non-cooperative (in-the-wild) environments. Since noncooperative environments are becoming more and more common, new approaches involving multi-modal biometrics have received more attention. One challenge in multimodal biometric systems is how to integrate the data from different modalities. Initially, we propose a deep transfer learning optimized from a model trained for face recognition achieving outstanding representation for only iris modality. Our feature level fusion by means of features selection targets the use of the Particle Swarm Optimization (PSO) for such aims. In our pool, we have the proposed iris fine-tuned representation and a periocular one from previous work of us. We compare this approach for fusion in feature level against three basic function rules for matching at score level: sum, multi, and min. Results are reported for iris and periocular region (NICE. II competition database) and also in an open-world scenario. The experiments in the NICE. II competition databases showed that our transfer learning representation for iris modality achieved a new state-of-the-art, i.e., decidability of 2.22 and 14.56% of EER. We also yielded a new state-of-the-art result when the fusion at feature level by PSO is done on periocular and iris modalities, i.e., decidability of 3.45 and 5.55% of EER.
OI Moreira, Gladston/0000-0001-7747-5926
CR Andersen-Hoppe E., 2017, 5 INT WORKSH BIOM FO
   Bharadwaj S, 2010, IEEE INT C BIOM THEO, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Crihalmeanu S, 2012, PATTERN RECOGN LETT, V33, P1860, DOI 10.1016/j.patrec.2011.11.006
   Daugman J. G., 1996, P CARDTECH SECURETEC, P223
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2607.903540
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Ghosh S, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P611, DOI 10.1145/2818346.2823313
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hollingsworth K., 2010, P IEEE INT C BIOM TH, P1
   Huang G. B., 2007, 0749 U MASS
   Juefei F., 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117600
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Luz E., 2011, INT C BIOINF COMP BI
   Luz E., 2017, PATTERN RECOGNITION
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Park U., 2009, BIOM THEOR APPL SYST, P1
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Proenca H., 2018, IEEE T INFORM FORENS, V13
   Proenca H, 2012, IEEE T INF FOREN SEC, V7, P798, DOI 10.1109/TIFS.2011.2177659
   Proenca H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Santos G, 2012, PATTERN RECOGN LETT, V33, P984, DOI 10.1016/j.patrec.2011.08.017
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Tan TN, 2012, PATTERN RECOGN LETT, V33, P970, DOI 10.1016/j.patrec.2011.08.009
   Vajaria H, 2007, PATTERN RECOGN LETT, V28, P1572, DOI 10.1016/j.patrec.2007.03.019
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang Q, 2012, PATTERN RECOGN LETT, V33, P978, DOI 10.1016/j.patrec.2011.08.014
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xu J, 2010, B ENTOMOL RES, V100, P359, DOI 10.1017/S0007485310000015
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 35
TC 0
Z9 0
BN 978-1-5090-6017-7
PY 2018
BP 2036
EP 2043
DI 10.1109/CEC.2018.8477817
UT WOS:000451175500260
ER

PT S
AU Liu, F
   Zhang, GQ
   Lu, J
AF Liu, Feng
   Zhang, Guangquan
   Lu, Jie
GP IEEE
TI Unconstrained fuzzy feature fusion for heterogeneous unsupervised domain
   adaptation
SO 2018 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE)
SE IEEE International Conference on Fuzzy Systems
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
CY JUL 08-13, 2018
CL Rio de Janeiro, BRAZIL
DE transfer learning; domain adaptation; fuzzy features; machine learning
AB Domain adaptation can transfer knowledge from the source domain to improve pattern recognition accuracy in the target domain. However, it is rarely discussed when the target domain is unlabeled and heterogeneous with the source domain, which is a very challenging problem in the domain adaptation field. This paper presents a new feature reconstruction method: unconstrained fuzzy feature fusion. Through the reconstructed features of a source and a target domain, a geodesic flow kernel is applied to transfer knowledge between them. Furthermore, the original information of the target domain is also preserved when reconstructing the features of the two domains. Compared to the previous work, this work has two advantages: 1) the sum of the memberships of the original features to fuzzy features no longer must be one, and 2) the original information of the target domain is persevered. As a result of these advantages, this work delivers a better performance than previous studies using two public datasets.
RI Zhang, Guangquan/G-2553-2017
OI Zhang, Guangquan/0000-0003-3960-0583
CR Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Behbood V, 2015, IEEE T FUZZY SYST, V23, P1917, DOI 10.1109/TFUZZ.2014.2387872
   Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921
   Deng W., 2017, ARXIV1711070727CSCV, P1
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Gong BQ, 2014, INT J COMPUT VISION, V109, P3, DOI 10.1007/s11263-014-0718-4
   Gong Mingming, 2016, JMLR Workshop Conf Proc, V48, P2839
   Jiang J., 2007, P 16 ACM C INF KNOWL, P401
   Kanamori T, 2009, J MACH LEARN RES, V10, P1391
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Liu F, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P1, DOI [10.1109/EMC-B.2017.8260468, 10.1109/ICCIS.2017.8274739]
   Liu T., 2017, P INT JOINT C ART IN, P2365
   Long MS, 2016, IEEE T KNOWL DATA EN, V28, P2027, DOI 10.1109/TKDE.2016.2554549
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Muller JS, 2011, J MACH LEARN RES, V12, P3065
   Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rie K. Ando, 2006, P NEUR INF PROC SYST, P25
   Shi XX, 2013, IEEE T KNOWL DATA EN, V25, P906, DOI 10.1109/TKDE.2011.252
   Shi  Yuan, 2012, P INT C MACH LEARN, P1079
   Sun B., 2016, P 30 AAAI C ART INT, P2058
   Tan B., 2017, P 31 AAAI C ART INT, P2604
   Wang C., 2011, IJCAI, P1541
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Xiao M, 2015, IEEE T PATTERN ANAL, V37, P54, DOI 10.1109/TPAMI.2014.2343216
   Xu JL, 2014, IEEE T PATTERN ANAL, V36, P2367, DOI 10.1109/TPAMI.2014.2327973
   Yang J., 2007, P 15 INT C MULT, P188, DOI DOI 10.1145/1291233.1291276
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
   Zhong Z., 2017, ARXIV171110295CSCV, P1
   Zuo H, 2017, IEEE T FUZZY SYST, V25, P1795, DOI 10.1109/TFUZZ.2016.2633376
   Zuo H, 2016, WD SCI P COMP ENG, V10, P175
NR 33
TC 0
Z9 0
SN 1098-7584
BN 978-1-5090-6020-7
PY 2018
UT WOS:000451248900190
ER

PT S
AU Papez, M
   Quinn, A
AF Papez, Milan
   Quinn, Anthony
BE Pustelnik, N
   Ma, Z
   Tan, ZH
   Larsen, J
TI DYNAMIC BAYESIAN KNOWLEDGE TRANSFER BETWEEN A PAIR OF KALMAN FILTERS
SO 2018 IEEE 28TH INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL
   PROCESSING (MLSP)
SE IEEE International Workshop on Machine Learning for Signal Processing
CT IEEE 28th International Workshop on Machine Learning for Signal
   Processing (MLSP)
CY SEP 17-20, 2018
CL Aalborg, DENMARK
DE Bayesian transfer learning; fully probabilistic design; incomplete
   modelling; Kalman filtering
ID FULLY PROBABILISTIC DESIGN
AB Transfer learning is a framework that includes-among other topics-the design of knowledge transfer mechanisms between Bayesian filters. Transfer learning strategies in this context typically rely on a complete stochastic dependence structure being specified between the participating learning procedures (filters). This paper proposes a method that does not require such a restrictive assumption. The solution in this incomplete modelling case is based on the fully probabilistic design of an unknown probability distribution which conditions on knowledge in the form of an externally supplied distribution. We are specifically interested in the situation where the external distribution accumulates knowledge dynamically via Kalman filtering. Simulations illustrate that the proposed algorithm outperforms alternative methods for transferring this dynamic knowledge from the external Kalman filter.
CR Bengio Y., 2012, J MACHINE LEARNING R, P17
   Bernardo JM, 1994, BAYESIAN THEORY
   Doucet A, 2009, OXFORD HDB NONLINEAR
   Faragher R, 2012, IEEE SIGNAL PROC MAG, V29, P128, DOI 10.1109/MSP.2012.2203621
   Foley C, 2018, IEEE SIGNAL PROC LET, V25, P487, DOI 10.1109/LSP.2017.2776223
   Isele D., 2017, ARXIV171201106
   Karbalayghareh A., 2018, ARXIV180100857
   Karny M, 1996, AUTOMATICA, V32, P1719, DOI 10.1016/S0005-1098(96)80009-4
   Karny M, 2012, INFORM SCIENCES, V186, P105, DOI 10.1016/j.ins.2011.09.018
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Mayne D.Q., 1966, Automatica, V4, P73, DOI 10.1016/0005-1098(66)90019-7
   Murphy K, 2012, MACHINE LEARNING PRO
   Pan S. J., 2015, DATA CLASSIFICATION, P537
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Quinn A, 2017, INT J APPROX REASON, V84, P150, DOI 10.1016/j.ijar.2017.02.001
   Quinn A, 2016, INFORM SCIENCES, V369, P532, DOI 10.1016/j.ins.2016.07.035
   Sarkka S., 2013, BAYESIAN FILTERING S
   SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Torrey  L., 2010, HDB RES MACHINE LEAR, P242
   van Kasteren TLM, 2010, LECT NOTES COMPUT SC, V6030, P283, DOI 10.1007/978-3-642-12654-3_17
   Willner D., 1976, Proceedings of the 1976 IEEE Conference on Decision and Control including the 15th Symposium on Adaptive Processes, P570
   Wilson A., 2012, P ICML WORKSH UNS TR, P217
NR 23
TC 0
Z9 0
SN 2161-0363
BN 978-1-5386-5477-4
PY 2018
UT WOS:000450651000042
ER

PT S
AU Serrano, SA
   Benitez-Jimenez, R
   Nunez-Rosas, L
   Arizmendi, MD
   Greeney, H
   Reyes-Meza, V
   Morales, E
   Escalante, HJ
AF Serrano, Sergio A.
   Benitez-Jimenez, Ricardo
   Nunez-Rosas, Laura
   del Coro Arizmendi, Ma
   Greeney, Harold
   Reyes-Meza, Veronica
   Morales, Eduardo
   Jair Escalante, Hugo
BE MartinezTrinidad, JF
   CarrascoOchoa, JA
   OlveraLopez, JA
   Sarkar, S
TI Automated Detection of Hummingbirds in Images: A Deep Learning Approach
SO PATTERN RECOGNITION
SE Lecture Notes in Computer Science
CT 10th Mexican Conference on Pattern Recognition (MCPR)
CY JUN 27-30, 2018
CL Puebla, MEXICO
DE Image classification; Convolutional neural network; Transfer learning;
   Animal behavior analysis; Hummingbird detection
AB The analysis of natural images has been the topic of research in uncountable articles in computer vision and pattern recognition (e.g., natural images has been used as benchmarks for object recognition and image retrieval). However, despite the research progress in such field, there is a gap in the analysis of certain type of natural images, for instance, those in the context of animal behavior. In fact, biologists perform the analysis of natural images manually without the aid of techniques that were supposedly developed for this purpose. In this context, this paper presents a study on automated methods for the analysis of natural images of hummingbirds with the goal to assist biologists in the study of animal behavior. The automated analysis of hummingbird behavior is challenging mainly because of (1) the speed at which these birds move and interact; (2) the unpredictability of their trajectories; and (3) its camouflage skills. We report a comparative study of two deep learning approaches for the detection of hummingbirds in their nest. Two variants of transfer learning from convolutional neural networks (CNNs) are evaluated in real imagery for hummingbird behavior analysis. Transfer learning is adopted because not enough images are available for training a CNN from scratch, besides, transfer learning is less time consuming. Experimental results are encouraging, as acceptable classification performance is achieved with CNN-based features. Interestingly, a pretrained CNN without fine tunning and a standard classifier performed better in the considered data set.
CR Abadi M, 2016, ARXIV1603044067
   BALTOSSER WH, 1986, WILSON BULL, V98, P353
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bleiweiss R, 1998, PHYLOGENY BODY MASS
   BROWN BT, 1992, J FIELD ORNITHOL, V63, P393
   Colwell RK, 2000, AM NAT, V156, P495, DOI 10.1086/303406
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   del Coro Arizmendi M, 2012, ORNITOLOGIA NEOTRO S, V23, P71
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng J., 2009, CVPR 2009
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Elliott A, 1999, HDB BIRDS WORLD, V5, P388
   Everingham M., 2006, PASCAL VISUAL OBJECT
   Fei-Fei  L., 2004, P IEEE C COMP VIS PA, P178, DOI DOI 10.1109/CVPR.2004.109
   Fink M, 2008, INT J COMPUT VISION, V77, P143, DOI 10.1007/s11263-007-0066-8
   Greeney Harold F., 2008, Huitzil, V9, P35
   Greeney HF, 2009, WILSON J ORNITHOL, V121, P809, DOI 10.1676/08-174.1
   Griffin G., 2007, TECHNICAL REPORT
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Johnsgard P. A, 2016, HUMMINGBIRDS N AM
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Memisevic R, 2010, ADV NEURAL INFORM PR, P1603
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pasquale G, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4904, DOI 10.1109/IROS.2016.7759720
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F., 2015, CVPR
   Smith DM, 2009, CONDOR, V111, P641, DOI 10.1525/cond.2009.090089
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   VLECK CM, 1981, OECOLOGIA, V51, P199, DOI 10.1007/BF00540601
NR 35
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-92198-3; 978-3-319-92197-6
PY 2018
VL 10880
BP 155
EP 166
DI 10.1007/978-3-319-92198-3_16
UT WOS:000450922800016
ER

PT S
AU Chen, XY
   Lengelle, R
AF Chen, Xiaoyi
   Lengelle, Regis
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Domain Adaptation Transfer Learning by Kernel Representation Adaptation
SO PATTERN RECOGNITION APPLICATIONS AND METHODS
SE Lecture Notes in Computer Science
CT 6th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY FEB 24-26, 2017
CL Porto, PORTUGAL
AB Domain adaptation, where no labeled target data is available, is a challenging task. To solve this problem, we first propose a new SVM based approach with a supplementary Maximum Mean Discrepancy (MMD)-like constraint. With this heuristic, source and target data are projected onto a common subspace of a Reproducing Kernel Hilbert Space (RKHS) where both data distributions are expected to become similar. Therefore, a classifier trained on source data might perform well on target data, if the conditional probabilities of labels are similar for source and target data, which is the main assumption of this paper. We demonstrate that adding this constraint does not change the quadratic nature of the optimization problem, so we can use common quadratic optimization tools. Secondly, using the same idea that rendering source and target data similar might ensure efficient transfer learning, and with the same assumption, a Kernel Principal Component Analysis (KPCA) based transfer learning method is proposed. Different from the first heuristic, this second method ensures other higher order moments to be aligned in the RKHS, which leads to better performances. Here again, we select MMD as the similarity measure. Then, a linear transformation is also applied to further improve the alignment between source and target data. We finally compare both methods with other transfer learning methods from the literature to show their efficiency on synthetic and real datasets.
CR Blobaum P., 2015, P 23 EUR S ART NEUR
   Chen X, 2017, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON RELIABILITY SYSTEMS ENGINEERING (ICRSE 2017)
   Dudley R. M., 1984, LECT NOTES MATH, V1097, P1, DOI DOI 10.1007/BFB0099432
   DUDLEY R. M., 2002, REAL ANAL PROBABILIT, V74
   Fortet R, 1953, ANN SCI ECOLE NORM S, P266
   Gao J, 2008, KDD, P283, DOI DOI 10.1145/1401890.1401928
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Huang CH, 2012, LECT NOTES COMPUT SC, V7583, P342, DOI 10.1007/978-3-642-33863-2_34
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   Jiang J., 2008, LIT SURVEY DOMAIN AD
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Liang FD, 2014, MACH VISION APPL, V25, P1697, DOI 10.1007/s00138-013-0549-2
   Ling X, 2008, P 14 ACM SIGKDD INT, P488, DOI DOI 10.1145/1401890.1401951
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Paulsen V. I, 2009, INTRO THEORY REPROD
   Quanz  Brian, 2009, CIKM, P1327, DOI DOI 10.1145/1645953.1646121
   Ren JT, 2010, LECT NOTES ARTIF INT, V6441, P63, DOI 10.1007/978-3-642-17313-4_7
   Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416
   Serfling R J., 2009, APPROXIMATION THEORE, V162
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Smola A, 2006, P 13 INT C ICONIP 20
   Sriperumbudur BK, 2010, J MACH LEARN RES, V11, P1517
   Steinwart I, 2002, J MACH LEARN RES, V2, P67
   Tan Q., 2012, ADV DATA MINING APPL, V7713, P223, DOI [10.1007/978-3-642-35527-119, DOI 10.1007/978-3-642-35527-119]
   Tu WT, 2011, PROC INT C TOOLS ART, P865, DOI 10.1109/ICTAI.2011.134
   Uguroglu S, 2011, LECT NOTES ARTIF INT, V6913, P430, DOI 10.1007/978-3-642-23808-6_28
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Z, 2008, LECT NOTES ARTIF INT, V5212, P550, DOI 10.1007/978-3-540-87481-2_36
   Yang SZ, 2012, NEURAL COMPUT APPL, V21, P1801, DOI 10.1007/s00521-012-1084-1
   Zhang P, 2009, IEEE DATA MINING, P627, DOI 10.1109/ICDM.2009.76
NR 35
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-93647-5; 978-3-319-93646-8
PY 2018
VL 10857
BP 45
EP 61
DI 10.1007/978-3-319-93647-5_3
UT WOS:000450777400003
ER

PT S
AU Tirumala, SS
AF Tirumala, Sreenivas Sremath
BE Chaki, N
   Cortesi, A
   Devarakonda, N
TI A Deep Autoencoder-Based Knowledge Transfer Approach
SO PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE
   AND DATA ENGINEERING
SE Lecture Notes on Data Engineering and Communications Technologies
CT 1st International Conference on Computational Intelligence & Data
   Engineering (ICCIDE)
CY JUL 14-15, 2017
CL Lakireddy Bali Reddy Coll Engn, Mylavaram, INDIA
HO Lakireddy Bali Reddy Coll Engn
DE Deep autoencoders; Knowledge transfer; Hierarchical dataset; Corrupted
   dataset
AB Deep Transfer Learning or DTS has proven successful with deep neural networks and deep belief networks. However, there has been limited research on to using deep autoencoder (DAE)-based network to implement DTS. This paper for the first time attempts to identify transferable features in the form of learning and transfer them to another network implementing a simple DTS mechanism. In this paper, a transfer of knowledge process is proposed where in knowledge is transferred from one Deep autoencoder network to another. This knowledge transfer has helped to improve the classification accuracy of the receiving autoencoder, particularly when experimented using corrupted dataset. The experiments are carried out on a texa based hierarchical dataset. Firstly, a DAE is trained with regular undamaged dataset to achieve maximum accuracy. Then, a distorted dataset was used to train second DAEN for classification with which only 56.7% of the data is correctly classified. Then a set of weights are transferred from from first DAEN to the second DAEN which resulted in an an improvement of classification accuracy by about 22%. The key contribution of this paper is highlighting importance of knowledge transfer between two deep autoencoder networks which is proposed for the first time.
CR Bengio Y., 2007, P ADV NEUR INF PROC, P153
   Bengio Y, 2007, LARGE SCALE KERNEL M
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Ciresan Dan C., 2012, NEUR NETW IJCNN 2012, P1, DOI DOI 10.1109/IJCNN.2012.6252544
   Graves A., 2009, OFFLINE HANDWRITING, P545
   Gutstein S, 2008, INT J ARTIF INTELL T, V17, P555, DOI 10.1142/S0218213008004059
   He K., 2015, P INT C COMP VIS, P1
   Hingu Dharmendra, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045732
   Kandaswamy Chetak, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P265, DOI 10.1007/978-3-319-11179-7_34
   LI EY, 1994, INFORM MANAGE, V27, P303, DOI 10.1016/0378-7206(94)90024-8
   Long M., 2015, INT C MACH LEARN, P97
   Milligan D. K., 1990, FUNDAMENTAL STRUCTUR, P997
   Terekhov A. V., 2015, KNOWLEDGE TRANSFER D, P268
   Tirumala SS, 2015, LECT NOTES COMPUT SC, V9489, P492, DOI 10.1007/978-3-319-26532-2_54
   Tirumala SS, 2014, P 2 INT WORKSH ART I, P164
   Waszczyszyn Z., 1999, FUNDAMENTALS ARTIFIC, P1
   Xiong C., 2015, CIRCUITS SYSTEMS VID, P1
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 18
TC 0
Z9 0
SN 2367-4512
BN 978-981-10-6319-0; 978-981-10-6318-3
PY 2018
VL 9
BP 277
EP 284
DI 10.1007/978-981-10-6319-0_23
UT WOS:000450834400023
ER

PT B
AU Al Mufti, M
   Al Hadhrami, E
   Taha, B
   Werghi, N
AF Al Mufti, Maha
   Al Hadhrami, Esra
   Taha, Bilal
   Werghi, Naoufel
GP IEEE
TI SAR Automatic Target Recognition Using Transfer Learning Approach
SO 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS)
CT International Conference on Intelligent Autonomous Systems (ICoIAS)
CY MAR 01-03, 2018
CL Singapore, SINGAPORE
DE component; deep learning; synthetic aperture radar; automatic target
   recognition
ID SUPPORT VECTOR MACHINES; IMAGES; CLASSIFICATION; MODELS
AB In this paper we propose a new approach for Synthetic Aperture Radar (SAR) automatic target recognition (ATR). One of the main obstacles in SAR ATR is the limited availability of datasets that are used for training. In this paper, a deep learning approach is employed for ATR. The proposed scheme is based on employing a pre-trained convolutional neural network (CNNs) as transfer learning. A pre-trained CNN namely AlexNet is utilized as a feature extractor whereas the output features are used to train a multiclass support vector machine (SVM) classifier. The effectiveness of the proposed framework is verified on a public database where the final result using three target classes attain an accuracy of 99.4%.
CR Cao ZJ, 2012, IEEE GLOBE WORK, P1450, DOI 10.1109/GLOCOMW.2012.6477798
   Chen SZ, 2016, IEEE T GEOSCI REMOTE, V54, P4806, DOI 10.1109/TGRS.2016.2551720
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Dong GG, 2017, IEEE T IMAGE PROCESS, V26, P2892, DOI 10.1109/TIP.2017.2692524
   Dong GG, 2015, IEEE GEOSCI REMOTE S, V12, P199, DOI 10.1109/LGRS.2014.2332076
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Kang CY, 2016, INT GEOSCI REMOTE SE, P1146, DOI 10.1109/IGARSS.2016.7729290
   Keydel ER, 1996, P SOC PHOTO-OPT INS, V2757, P228, DOI 10.1117/12.242059
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lin Zhao, 2017, IEEE GEOSCIENCE REMO
   Malmgren-Hansen D, 2017, IEEE GEOSCI REMOTE S, V14, P1484, DOI 10.1109/LGRS.2017.2717486
   NOVAK LM, 1997, LINCOLN LAB J, V10
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Song HB, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6010026
   Tison C, 2007, INT GEOSCI REMOTE SE, P456, DOI 10.1109/IGARSS.2007.4422829
   VASUKI P, 2012, RES J APPL SCI ENG T, V4, P5510
   Wang HP, 2015, INT GEOSCI REMOTE SE, P3743, DOI 10.1109/IGARSS.2015.7326637
   Wilmanski Michael, 2016, SPIE DEFENSE SECURIT
   Yang Y, 2005, Sixth International Conference on Software Engineerng, Artificial Intelligence, Networking and Parallel/Distributed Computing and First AICS International Workshop on Self-Assembling Wireless Networks, Proceedings, P2
   Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475
NR 20
TC 0
Z9 0
BN 978-1-5386-6331-8
PY 2018
BP 1
EP 4
UT WOS:000450670500001
ER

PT B
AU Xie, ZP
   Lv, WF
   Ali, SMA
   Du, BW
   Huang, RH
AF Xie, Zhipu
   Lv, Weifeng
   Ali, Syed Muhammad Asim
   Du, Bowen
   Huang, Runhe
GP IEEE
TI Anomaly Prediction in Passenger Flow with Knowledge Transfer Method
SO 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH
   IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG
   DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS
   (DASC/PICOM/DATACOM/CYBERSCITECH)
CT 16th IEEE Int Conf on Dependable, Autonom and Secure Comp/16th IEEE Int
   Conf on Pervas Intelligence and Comp/4th IEEE Int Conf on Big Data
   Intelligence and Comp/3rd IEEE Cyber Sci and Technol Congress
   (DASC/PiCom/DataCom/CyberSciTech)
CY AUG 12-15, 2018
CL Athens, GREECE
DE Passenger Flow; Prediction Model; Knowledge Transfer
AB Predicting anomaly in travel demand is a crucial finding from smart card data analytics. The output of these predictions is a significant contribution to planning sustainable public transport system and generating possible knowledge for transportation learning models. This paper investigates the anomaly effects of the surge in bus passengers demand and compare it with an increase in taxi demand. Indeed, both short-term and long-term demands reveal different patterns of passengers in uncertain situations. In pursuit of our goal, we estimated the similarity in stations by both selected and latent features where pre trained knowledge are combined as an ensemble with different weights. We present Surge Prediction and Knowledge Transfer (SPKT) model that uses Seq2Seq method combined with Multi-source Transfer Learning method on travel patterns extracted from smart card data to classify source stations and target station. To illustrate the demands blueprint, we considered multiple source stations as input to the predictor, to develop a mechanism that bridges the knowledge transfer learning with the targeted stations. To exemplify our method, we use a case study of an event with passenger surge. From experiments, we found that transferring knowledge can make the surge prediction better compared to only limited training data for the target stations. The results have proved the effectiveness of surge predictions and knowledge transfer for learning models.
CR Anvari S, 2016, J ADV TRANSPORT, V50, P25, DOI 10.1002/atr.1332
   Bai Y, 2017, APPL SOFT COMPUT, V58, P669, DOI 10.1016/j.asoc.2017.05.011
   Bai Y, 2015, J HYDROL ENG, V20, DOI 10.1061/(ASCE)HE.1943-5584.0001101
   Box G. E. P, 2013, TIME SERIES ANAL FOR
   Chen JH, 2016, WEB INF SYST ENG INT, P27, DOI 10.1007/978-3-319-44198-6_2
   Chen YH, 2012, APPL SOFT COMPUT, V12, P274, DOI 10.1016/j.asoc.2011.08.045
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Dai W., 2007, P 24 INT C MACH LEAR
   Ding ZM, 2018, IEEE T NEUR NET LEAR, V29, P310, DOI 10.1109/TNNLS.2016.2618765
   Drucker Harris, 1997, INT C MACH LEARN ICM
   Du BW, 2016, IEEE T COMPUT, V65, P3524, DOI 10.1109/TC.2016.2529623
   Feng Kaiyu, 2017, ARXIV170909287
   Gan M, 2014, APPL SOFT COMPUT, V24, P13, DOI 10.1016/j.asoc.2014.06.047
   He J., 2011, P 28 INT C MACH LEAR, P25
   Hu YR, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.112
   Lee Roy Ka-Wei, 2014, International Journal of Engineering and Technology, V6, P431, DOI 10.7763/IJET.2014.V6.737
   Li Linchao, 2017, KSCE J CIV ENG, P1
   Mikolov Tomas, 2013, ADV NEURAL INFORM PR
   Milenkovi'c M., 2016, TRANSPORT
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pang SN, 2014, COGN COMPUT, V6, P304, DOI 10.1007/s12559-013-9238-8
   Pardoe David, 2010, P 27 INT C INT C MAC
   Sato A, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P609, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.120
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Susanty A, 2012, PROC ECON FINANC, V4, P23, DOI 10.1016/S2212-5671(12)00317-6
   Tang Tao, 2018, IET INTELLIGENT TRAN
   Vapnik Vladimir, 2015, J MACHINE LEARNING R, V16, P55
   Wang L, 2018, ARXIV180200386
   Wei Ying, 2016, P 22 ACM SIGKDD INT
   Wei Y, 2012, TRANSPORT RES C-EMER, V21, P148, DOI 10.1016/j.trc.2011.06.009
   Williams C, 2007, STRATEG MANAGE J, V28, P867, DOI 10.1002/smj.614
   Yang Yang, 2015, CICTP 2015. Efficient, Safe and Green Multimodal Transportation. 15th COTA International Conference of Transportation Professionals. Proceedings, P1143, DOI 10.1061/9780784479292.106
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Yuan Zhixiang, 2017, COMP INT INF SYST CI
   Zhang K., 2015, P 29 AAAI C ART INT, P3150
   Zhen Jiangjie, 2017, ROB BIOM ROBIO 2017
NR 36
TC 0
Z9 0
BN 978-1-5386-7518-2
PY 2018
BP 270
EP 277
DI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00054
UT WOS:000450146600039
ER

PT S
AU Adama, DA
   Lotfi, A
   Langensiepen, C
   Lee, K
AF Adama, David Ada
   Lotfi, Ahmad
   Langensiepen, Caroline
   Lee, Kevin
BE Chao, F
   Schockaert, S
   Zhang, Q
TI Human Activities Transfer Learning for Assistive Robotics
SO ADVANCES IN COMPUTATIONAL INTELLIGENCE SYSTEMS
SE Advances in Intelligent Systems and Computing
CT 17th Annual UK Workshop on Computational Intelligence (UKCI)
CY SEP 06-08, 2017
CL Cardiff, ENGLAND
DE Activity recognition; Activity classification; Assistive robotics
ID RECOGNITION
AB Assisted living homes aim to deploy tools to promote better living of elderly population. One of such tools is assistive robotics to perform tasks a human carer would normally be required to perform. For assistive robots to perform activities without explicit programming, a major requirement is learning and classifying activities while it observes a human carry out the activities. This work proposes a human activity learning and classification system from features obtained using 3D RGB-D data. Different classifiers are explored in this approach and the system is evaluated on a publicly available data set, showing promising results which is capable of improving assistive robots performance in living environments.
OI Lee, Kevin/0000-0002-2730-9150
CR Adama D. A., 2017, P 10 C PERV TECHN RE
   Iglesias JA, 2010, INT J NEURAL SYST, V20, P355, DOI 10.1142/S0129065710002462
   Bezdek J.C., 1981, PATTERN RECOGNITION
   Cippitelli E., 2016, COMPUT INTEL NEUROSC, V2016, DOI [10.1155/2016/4351435, DOI 10.1155/2016/4351435]
   Faria DR, 2014, IEEE ROMAN, P732, DOI 10.1109/ROMAN.2014.6926340
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Huiquan Zhang, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1058, DOI 10.1109/ICMLC.2012.6359501
   Hussein M. E., 2013, IJCAI, P2466
   Jalal A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P74, DOI 10.1109/AVSS.2014.6918647
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kviatkovsky I., 2014, IEEE C COMP VIS PATT
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Microsoft, DEV KIN WIND
   Shell J, 2015, INFORM SCIENCES, V293, P59, DOI 10.1016/j.ins.2014.09.004
   Sung J., 2011, P AAAI WORKSH PATT A, V64, P47
   Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Ye Gu, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1379, DOI 10.1109/ROBIO.2012.6491161
NR 19
TC 0
Z9 0
SN 2194-5357
EI 2194-5365
BN 978-3-319-66939-7; 978-3-319-66938-0
PY 2018
VL 650
BP 253
EP 264
DI 10.1007/978-3-319-66939-7_22
UT WOS:000449922000022
ER

PT B
AU Al Hadhrami, E
   Al Mufti, M
   Taha, B
   Werghi, N
AF Al Hadhrami, Esra
   Al Mufti, Maha
   Taha, Bilal
   Werghi, Naoufel
GP IEEE
TI Transfer Learning with Convolutional Neural Networks for Moving Target
   Classification with Micro-Doppler Radar Spectrograms
SO 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA
   (ICAIBD)
CT International Conference on Artificial Intelligence and Big Data
   (ICAIBD)
CY MAY 26-28, 2018
CL Chengdu, PEOPLES R CHINA
DE convolutional neural network; transfer learning; AlexNet; micro-doppler;
   radar classification; automatic target recognition
AB In this work, we propose a transfer learning approach with Convolutional Neural Networks (CNNs) for radar Automatic Target Recognition (ATR). Radar echo signals of moving targets introduce micro-Doppler signatures that are widely used in classifying moving targets. Spectrograms have the advantage of expressing the distinctive micro-Doppler signatures of different targets, and thus fed as 2D images to a CNN model. A pre-trained CNN model namely AlexNet is employed as a feature extractor in which feature maps can be extracted from any of the layers to train a classical classifier. SoftMax classifier have been used in this approach. The efficiency of the presented framework is demonstrated on the public RadEch database of 8 ground moving target classes, in which the experimental results indicate that our methodology significantly outperforms other competitive state-of-the-art methods with an accuracy of 99.9%.
OI Werghi, Naoufel/0000-0002-5542-448X
CR Andric M., 2010, 10 S NEUR NETW APPL
   Andric M., 2010, 18 TEL FOR TELFOR BE
   Andric M, 2014, RADIOENGINEERING, V23, P11
   Bjorklund S., 2012, 2012 IEEE Radar Conference (RadarCon), P934, DOI 10.1109/RADAR.2012.6212271
   Bjorklund S, 2015, IET RADAR SONAR NAV, V9, P1181, DOI 10.1049/iet-rsn.2015.0084
   Chen VC, 2006, IEEE T AERO ELEC SYS, V42, P2, DOI 10.1109/TAES.2006.1603402
   Clemente C, 2015, IEEE T AERO ELEC SYS, V51, P417, DOI 10.1109/TAES.2014.130762
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Kim BK, 2017, IEEE GEOSCI REMOTE S, V14, P38, DOI 10.1109/LGRS.2016.2624820
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Molchanov P., 2012, 2012 IEEE Radar Conference (RadarCon), P366, DOI 10.1109/RADAR.2012.6212166
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Park J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16121990
   Serir A., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P995, DOI 10.1109/ISSPA.2012.6310701
   Simonyan K., 2014, CORR
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van Dorp P, 2003, IEE P-RADAR SON NAV, V150, P356, DOI 10.1049/ip-rsn:20030568
   Zabalza J, 2014, IEEE T AERO ELEC SYS, V50, P2304, DOI 10.1109/TAES.2014.130082
NR 19
TC 0
Z9 0
BN 978-1-5386-6987-7
PY 2018
BP 148
EP 154
UT WOS:000449008400029
ER

PT B
AU Al Mufti, M
   Al Hadhrami, E
   Taha, B
   Werghi, N
AF Al Mufti, Maha
   Al Hadhrami, Esra
   Taha, Bilal
   Werghi, Naoufel
GP IEEE
TI Automatic Target Recognition in SAR Images Comparison Between
   Pre-trained CNNs in a Tranfer Learning Based Approach
SO 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA
   (ICAIBD)
CT International Conference on Artificial Intelligence and Big Data
   (ICAIBD)
CY MAY 26-28, 2018
CL Chengdu, PEOPLES R CHINA
DE deep learning; synthetic aperture radar; transfer learning; automatic
   target recognition
AB Synthetic aperture radar (SAR) are high resolution imaging radar systems. In many SAR applications classifying objects that are detected within the SAR image is important. In this paper an approach is proposed to tackle the Synthetic SAR Automatic Target Recognition (ATR) problem. The proposed scheme is based on a transfer leaning approach where three different pre-trained Convolutional Neural Networks (CNNs) are used as feature extractors in combination with a Support Vector Machine classifier (SVM). The CNNs used in this paper are AlexNet, VGG16 and GoogLeNet. The performance of these three CNNs is compared in regards to the SAR-ATR problem; where it is observed that AlexNet gives the best performance accuracy of 99.27%.
OI Werghi, Naoufel/0000-0002-5542-448X
CR Agarap A. F. M., 2017, ARXIV171203541
   Alalshekmubarak A., 2013, INN INF TECHN IIT 20, P42
   Anagnostopoulos GC, 2009, NONLINEAR ANAL-THEOR, V71, pE2934, DOI 10.1016/j.na.2009.07.030
   Chen SZ, 2014, 2014 INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA), P541, DOI 10.1109/DSAA.2014.7058124
   Chen SZ, 2016, IEEE T GEOSCI REMOTE, V54, P4806, DOI 10.1109/TGRS.2016.2551720
   Clemente C, 2015, IET RADAR SONAR NAV, V9, P457, DOI 10.1049/iet-rsn.2014.0296
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080848
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lin Z, 2017, IEEE GEOSCI REMOTE S, V14, P1091, DOI 10.1109/LGRS.2017.2698213
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park JI, 2013, IEEE GEOSCI REMOTE S, V10, P476, DOI 10.1109/LGRS.2012.2210385
   Simonyan K., 2014, ARXIV14091556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang  Y., 2013, ARXIV13060239
   Wagner S., 2014, P 17 INT C INF FUS F, P1
   Wilmanski Michael, 2016, SPIE DEFENSE SECURIT
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeng Q, 2017, IEEE CONF IMAGING SY, P122
   Zhu Z. Q., 2017, 20 INT C EC VECH REN, P1
NR 21
TC 0
Z9 0
BN 978-1-5386-6987-7
PY 2018
BP 160
EP 164
UT WOS:000449008400031
ER

PT B
AU Xue, YJ
   Beauseroy, P
AF Xue, Yongjian
   Beauseroy, Pierre
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Transfer Learning to Adapt One Class SVM Detection to Additional
   Features
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM 2018)
CT 7th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY JAN 16-18, 2018
CL Funchal, PORTUGAL
DE Transfer Learning; Multi-task Learning; Outliers Detection; One Class
   Classification
ID SUPPORT
AB In this paper, we use the multi-task learning idea to solve a problem of detection with one class SVM when new sensors are added to the system. The main idea is to adapt the detection system to the upgraded sensor system. To solve that problem, the kernel matrix of multi-task learning model can be divided into two parts, one part is based on the former features and the other part is based on the new features. Typical estimation methods can be used to fill the corresponding new features in the old detection system, and a variable kernel is used for the new features in order to balance the importance of the new features with the number of observed samples. Experimental results show that it can keep the false alarm rate relatively stable and decrease the miss alarm rate rapidly as the number of samples increases in the target task.
CR Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   He XY, 2014, NEUROCOMPUTING, V133, P416, DOI 10.1016/j.neucom.2013.12.022
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Silverman B.W., 1986, DENSITY ESTIMATION S, V26
   Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2
   Xue Y, 2017, PATTERN RECOGNITION
   Xue YJ, 2016, INT C PATT RECOG, P1571, DOI 10.1109/ICPR.2016.7899861
   Yang HC, 2011, NEUROSURGERY, V68, P682, DOI 10.1227/NEU.0b013e318207a58b
NR 10
TC 0
Z9 0
BN 978-989-758-276-9
PY 2018
BP 78
EP 85
DI 10.5220/0006553200780085
UT WOS:000447747100007
ER

PT B
AU Sakurai, S
   Uchiyama, H
   Shimada, A
   Arita, D
   Taniguchi, R
AF Sakurai, Shunsuke
   Uchiyama, Hideaki
   Shimada, Atsushi
   Arita, Daisaku
   Taniguchi, Rin-ichiro
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Two-step Transfer Learning for Semantic Plant Segmentation
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM 2018)
CT 7th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY JAN 16-18, 2018
CL Funchal, PORTUGAL
DE Semantic Segmentation; Transfer Learning; Deep Learning; CNN; Plant
   Segmentation
AB We discuss the applicability of a fully convolutional network (FCN), which provides promising performance in semantic segmentation tasks, to plant segmentation tasks. The challenge lies in training the network with a small dataset because there are not many samples in plant image datasets, as compared to object image datasets such as ImageNet and PASCAL VOC datasets. The proposed method is inspired by transfer learning, but involves a two-step adaptation. In the first step, we apply transfer learning from a source domain that contains many objects with a large amount of labeled data to a major category in the plant domain. Then, in the second step, category adaptation is performed from the major category to a minor category with a few samples within the plant domain. With leaf segmentation challenge (LSC) dataset, the experimental results confirm the effectiveness of the proposed method such that F-measure criterion was, for instance, 0.953 for the A2 dataset, which was 0.355 higher than that of direct adaptation, and 0.527 higher than that of non-adaptation.
OI Arita, Daisaku/0000-0002-2138-6796
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Minervini M, 2014, ECOL INFORM, V23, P35, DOI 10.1016/j.ecoinf.2013.07.004
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pape J.-M., 2014, P 13 EUR C COMP VIS, P61
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scharr H., 2014, EUR C COMP VIS, P6
   Scharr H, 2015, MACHI VISION, P1
   van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792
   Yin X, 2014, P IEEE C IMAG PROC
NR 11
TC 0
Z9 0
BN 978-989-758-276-9
PY 2018
BP 332
EP 339
DI 10.5220/0006576303320339
UT WOS:000447747100036
ER

PT B
AU Roman-Jimenez, G
   Viard-Gaudin, C
   Granet, A
   Mouchere, H
AF Roman-Jimenez, Geoffrey
   Viard-Gaudin, Christian
   Granet, Adeline
   Mouchere, Harold
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Transfer Learning for Structures Spotting in Unlabeled Handwritten
   Documents using Randomly Generated Documents
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM 2018)
CT 7th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY JAN 16-18, 2018
CL Funchal, PORTUGAL
DE Handwritting Recognition; Image Generation; Digit Detection; Deep Neural
   Networks; Knowledge Transfer
AB Despite recent achievements in handwritten text recognition due to major advances in deep neural networks, historical handwritten documents analysis is still a challenging problem because of the requirement of large annotated training database. In this context, knowledge transfer of neural networks pre-trained on already available labeled data could allow us to process new collections of documents. In this study, we focus on localization of structures at the word-level, distinguishing words from numbers, in unlabeled handwritten documents. We based our approach on a transductive transfer learning paradigm using a deep convolutional neural network pre-trained on artificial labeled images randomly generated with strokes, word and number patches. We designed our model to predict a mask of the structures positions at the pixel-level, directly from the pixel values. The model has been trained using 100,000 generated images. The classification performances of our model were assessed by using randomly generated images coming from a different set of images of words and digits. At the pixel level, the averaged accuracy of the proposed structures detection system reach 96.1%. We evaluated the transfer capability of our model on two datasets of real handwritten documents unseen during the training. Results show that our model is able to distinguish most "digits" structures from "word" structures while avoiding other various structures present in the documents, showing the good transferability of the system to real documents.
CR Augustin E., 2006, P WORKSH FRONT HANDW
   Bergstra J., 2010, P 9 PYTH SCI C, P1
   Butt UM, 2016, INT CONF FRONT HAND, P19, DOI [10.1109/ICFHR.2016.14, 10.1109/ICFHR.2016.0017]
   Cethefi T, 2016, ANR14CE310017
   Delalandre M, 2010, INT J DOC ANAL RECOG, V13, P187, DOI 10.1007/s10032-010-0120-x
   Dieleman S, 2015, LASAGNE 1 RELEASE
   Dumoulin V., 2016, ARXIV160307285
   Gorodkin J, 2004, COMPUT BIOL CHEM, V28, P367, DOI 10.1016/j.compbiolchem.2004.09.006
   Grosicki E, 2011, PROC INT CONF DOC, P1459, DOI 10.1109/ICDAR.2011.290
   Kieu V. C, 2013, 12 INT C DOC AN REC
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Luca E. D, 2011, REPERTOIRE COMEDIE I
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Moysset B, 2016, INT CONF FRONT HAND, P1, DOI [10.1109/ICFHR.2016.0014, 10.1109/ICFHR.2016.11]
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Viard-Gaudin C., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P455, DOI 10.1109/ICDAR.1999.791823
NR 20
TC 0
Z9 0
BN 978-989-758-276-9
PY 2018
BP 417
EP 425
DI 10.5220/0006598204170425
UT WOS:000447747100047
ER

PT B
AU Granet, A
   Morin, E
   Mouchere, H
   Quiniou, S
   Viard-Gaudin, C
AF Granet, Adeline
   Morin, Emmanuel
   Mouchere, Harold
   Quiniou, Solen
   Viard-Gaudin, Christian
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Transfer Learning for Handwriting Recognition on Historical Documents
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM 2018)
CT 7th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY JAN 16-18, 2018
CL Funchal, PORTUGAL
DE Handwriting Recognition; Historical Document; Transfer Learning; Deep
   Neural Network; Unlabeled Data
AB In this work, we investigate handwriting recognition on new historical handwritten documents using transfer learning. Establishing a manual ground-truth of a new collection of handwritten documents is time consuming but needed to train and to test recognition systems. We want to implement a recognition system without performing this annotation step. Our research deals with transfer learning from heterogeneous datasets with a ground-truth and sharing common properties with a new dataset that has no ground-truth. The main difficulties of transfer learning lie in changes in the writing style, the vocabulary, and the named entities over centuries and datasets. In our experiment, we show how a CNN-BLSTM-CTC neural network behaves, for the task of transcribing handwritten titles of plays of the Italian Comedy, when trained on combinations of various datasets such as RIMES, Georges Washington, and Los Esposalles. We show that the choice of the training datasets and the merging methods are determinant to the results of the transfer learning task.
CR Arvanitopoulos N, 2014, INT CONF FRONT HAND, P726, DOI 10.1109/ICFHR.2014.127
   Augustin E, 2006, ICFHR
   BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P
   Cloppet F, 2016, INT CONF FRONT HAND, P590, DOI [10.1109/ICFHR.2016.106, 10.1109/ICFHR.2016.0113]
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Fischer A, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P137, DOI 10.1109/VSMM.2009.26
   Frinken V, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P352, DOI 10.1109/ICFHR.2010.61
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Graves A., 2009, ADV NEURAL INFORM PR, V21, P545
   Grosicki Emmanuele, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1398, DOI 10.1109/ICDAR.2009.184
   Grosicki E, 2011, PROC INT CONF DOC, P1459, DOI 10.1109/ICDAR.2011.290
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Koerich AL, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P99, DOI 10.1109/IWFHR.2002.1030893
   Kozielski M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P121, DOI 10.1109/DAS.2014.8
   Lavrenko V, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P278, DOI 10.1109/DIAL.2004.1263256
   Llados J, 2012, IJPRAI, V26
   Moysset B, 2014, INT CONF FRONT HAND, P297, DOI 10.1109/ICFHR.2014.57
   Murdock M, 2015, 2015 13TH IAPR INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), P1171, DOI 10.1109/ICDAR.2015.7333945
   Oprean C, 2013, PROC INT CONF DOC, P989, DOI 10.1109/ICDAR.2013.199
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Puigcerver J, 2015, 2015 13TH IAPR INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), P1176, DOI 10.1109/ICDAR.2015.7333946
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI [10.1007/s10032-006-0027-8, 10.1007/s10032-007-0027-8]
   Romero V, 2013, PATTERN RECOGN, V46, P1658, DOI 10.1016/j.patcog.2012.11.024
   Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887
   Suryani D, 2016, INT CONF FRONT HAND, P193, DOI [10.1109/ICFHR.2016.0046, 10.1109/ICFHR.2016.43]
   Terasawa Kengo, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P116, DOI 10.1109/ICDAR.2009.118
   Voigtlaender P, 2016, ICFHR, P2228
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
NR 30
TC 1
Z9 1
BN 978-989-758-276-9
PY 2018
BP 432
EP 439
DI 10.5220/0006598804320439
UT WOS:000447747100049
ER

PT B
AU Jia, KG
   Liu, ZY
   Wei, Q
   Qiao, F
   Liu, XJ
   Yang, Y
   Fan, H
   Yang, HZ
AF Jia, Kaige
   Liu, Zheyu
   Wei, Qi
   Qiao, Fei
   Liu, Xinjun
   Yang, Yi
   Fan, Hua
   Yang, Huazhong
GP IEEE
TI Calibrating Process Variation at System Level with In-Situ Low-Precision
   Transfer Learning for Analog Neural Network Processors
SO 2018 55TH ACM/ESDA/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
CT 55th ACM/ESDA/IEEE Design Automation Conference (DAC)
CY JUN 24-28, 2018
CL San Francisco, CA
DE Analog Neural Network; Process Variation; Low-Precision; In-Situ
   Transfer Learning
ID ERROR RESILIENCE; IMPLEMENTATION
AB Process Variation (PV) may cause accuracy loss of the analog neural network (ANN) processors, and make it hard to be scaled down, as well as feasibility degrading. This paper first analyses the impact of PV on the performance of ANN dhips. Then proposes an in-situ transfer learning method at system level to reduce PV's influence with low-precision back-propagation. Simulation results show the proposed method could increase 50% tolerance of operating point drift and 70% 100% tolerance of mismatch with less than I% accuracy loss of benchmarks. It also reduces 66.7% memories and has about 50x energy-efficiency improvement of multiplication in the learning stage, compared with the conventional full-precision (32bit float) training system.
CR Bathen LAD, 2012, DES AUT TEST EUROPE, P284
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Dighe S, 2011, IEEE J SOLID-ST CIRC, V46, P184, DOI 10.1109/JSSC.2010.2080550
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Fick L, 2017, IEEE CUST INTEGR CIR
   Gatet L, 2008, IEEE SENS J, V8, P1413, DOI 10.1109/JSEN.2008.920713
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Jia Y., 2014, ARXIV14085093
   Kang K, 2010, IEEE T CIRCUITS-I, V57, P1513, DOI 10.1109/TCSI.2009.2034234
   Krizhevsky Alex, ALEXAAZS CIFAR 10 TU
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lei Jiang, 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P127, DOI 10.1109/ISLPED.2011.5993624
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Lu J, 2015, IEEE J SOLID-ST CIRC, V50, P270, DOI 10.1109/JSSC.2014.2356197
   Paul S, 2011, IEEE T COMPUT, V60, P20, DOI 10.1109/TC.2010.203
   PELGROM MJM, 1989, IEEE J SOLID-ST CIRC, V24, P1433, DOI 10.1109/JSSC.1989.572629
   Valle M, 2002, ANALOG INTEGR CIRC S, V33, P263, DOI 10.1023/A:1020717929709
   Zhang LD, 2009, DES AUT CON, P694
   Zhao M., 2014, P 51 ANN DES AUT C, P1
NR 20
TC 0
Z9 0
BN 978-1-4503-5700-5
PY 2018
DI 10.1145/3195970.3196004
UT WOS:000446034500040
ER

PT S
AU Bu, SJ
   Cho, SB
AF Bu, Seok-Jun
   Cho, Sung-Bae
BE Juez, FJD
   Villar, JR
   DeLaCal, EA
   Herrero, A
   Quintian, H
   Saez, JA
   Corchado, E
TI A Hybrid Deep Learning System of CNN and LRCN to Detect Cyberbullying
   from SNS Comments
SO HYBRID ARTIFICIAL INTELLIGENT SYSTEMS (HAIS 2018)
SE Lecture Notes in Artificial Intelligence
CT 13th International Conference on Hybrid Artificial Intelligent Systems
   (HAIS)
CY JUN 20-22, 2018
CL Oviedo, SPAIN
AB The cyberbullying is becoming a significant social issue, in proportion to the proliferation of Social Network Service (SNS). The cyberbullying commentaries can be categorized into syntactic and semantic subsets. In this paper, we propose an ensemble method of the two deep learning models: One is character-level CNN which captures low-level syntactic information from the sequence of characters and is robust to noise using the transfer learning. The other is word-level LRCN which captures high-level semantic information from the sequence of words, complementing the CNN model. Empirical results show that the performance of the ensemble method is significantly enhanced, outperforming the state-of-the-art methods for detecting cyberbullying comment. The model is analyzed by t-SNE algorithm to investigate the mutually cooperative relations between syntactic and semantic models.
CR Abadi M., 2016, P 12 USENIX S OP SYS
   Bengio Y., 2012, J MACHINE LEARNING R, P17
   Bu SJ, 2017, LECT NOTES ARTIF INT, V10334, P615, DOI 10.1007/978-3-319-59650-1_52
   Collobert R., 2008, P 25 ICML, V25, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Forman G., 2008, P 17 ACM C INF KNOWL, P263, DOI DOI 10.1145/1458082.1458119
   Goldberg  Y., 2014, ARXIV14023722
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Mikolov T., 2013, COMPUTING RES REPOSI, V1301, P3781, DOI DOI 10.1109/TNN.2003.820440]
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Olweus D., 1995, BULLYING SCH WHAT WE
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79
   Patchin JW, 2006, YOUTH VIOLENCE JUV J, V4, P148, DOI DOI 10.1177/1541204006286288
   Reynolds K., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P241, DOI 10.1109/ICMLA.2011.152
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Ybarra M., 2010, NATL SUMMIT INTERPER
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649
   Zhang Yun-tao, 2005, Journal of Zhejiang University (Science), V6A, P49, DOI 10.1631/jzus.2005.A0049
NR 21
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-92639-1; 978-3-319-92638-4
PY 2018
VL 10870
BP 561
EP 572
DI 10.1007/978-3-319-92639-1_47
UT WOS:000443487900047
ER

PT S
AU Peng, B
   Li, W
   He, JP
AF Peng, Bo
   Li, Wei
   He, Jiping
BE Tseng, J
   Kotenko, I
TI Online Calibration of Intracortical Neural Interface Based on Transfer
   Learning
SO 3RD ANNUAL INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL
   INTELLIGENCE (ISAI2018)
SE Journal of Physics Conference Series
CT 3rd Annual International Conference on Information System and Artificial
   Intelligence (ISAI)
CY JUN 22-24, 2018
CL Suzhou, PEOPLES R CHINA
ID GRASP; REACH
AB In the application of neural interface, the neural activity of neurons and neuronal groups is not fixed even under the same task conditions. Meanwhile, the recording conditions of neural signals are also very unstable, with a high degree of within-and across-day variability. This results in a very unstable firing pattern for the recorded neural spike signals. In order to get better performance, the decoder often requires a lot of online calibration samples. This brings a heavy training burden to neural interface users. To solve this problem, this paper proposes to apply transfer learning (TL) to online calibration of intracortical neural interface to reduce the dependence of decoder on a large number of online calibration samples. Experimental results show that through transferring from a large amount of historical data, decoder can achieve satisfactory classification accuracy with only a small amount of online data.
CR Aflalo T, 2015, SCIENCE, V348, P906, DOI 10.1126/science.aaa5417
   Bamdadian A, 2013, IEEE ENG MED BIO, P2188, DOI 10.1109/EMBC.2013.6609969
   Collinger JL, 2013, LANCET, V381, P557, DOI 10.1016/S0140-6736(12)61816-9
   Devlaminck D, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/217987
   Guo YY, 2014, IEEE ENG MED BIO, P2322, DOI 10.1109/EMBC.2014.6944085
   Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970
   Hochberg LR, 2012, NATURE, V485, P372, DOI 10.1038/nature11076
   Li Y, 2010, IEEE T BIO-MED ENG, V57, P1318, DOI 10.1109/TBME.2009.2039997
   McKhann GM, 2008, NEUROSURGERY, V62
   Musallam S, 2004, SCIENCE, V305, P258, DOI 10.1126/science.1097938
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Samek W, 2013, IEEE T BIO-MED ENG, V60, P2289, DOI 10.1109/TBME.2013.2253608
   Tu WT, 2012, NEUROCOMPUTING, V82, P109, DOI 10.1016/j.neucom.2011.10.024
   Vidaurre C, 2011, IEEE T BIO-MED ENG, V58, P587, DOI 10.1109/TBME.2010.2093133
   Wang PT, 2015, INT CONF INFO SCI, P315, DOI 10.1109/ICIST.2015.7288989
   Wu D, 2015, IEEE SYS MAN CYBERN, P3209, DOI 10.1109/SMC.2015.557
   Wu DR, 2014, IEEE SYS MAN CYBERN, P2801, DOI 10.1109/SMC.2014.6974353
   Wu W, 2009, IEEE T NEUR SYS REH, V17, P370, DOI 10.1109/TNSRE.2009.2023307
NR 18
TC 0
Z9 0
SN 1742-6588
EI 1742-6596
PY 2018
VL 1069
AR UNSP 012090
DI 10.1088/1742-6596/1069/1/012090
UT WOS:000443503700090
ER

PT S
AU Sato, M
   Orihara, R
   Sei, YC
   Tahara, Y
   Ohsuga, A
AF Sato, Minato
   Orihara, Ryohei
   Sei, Yuichi
   Tahara, Yasuyuki
   Ohsuga, Akihiko
BE VanDenHerik, J
   Rocha, AP
   Filipe, J
TI Text Classification and Transfer Learning Based on Character-Level Deep
   Convolutional Neural Networks
SO AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART 2017)
SE Lecture Notes in Artificial Intelligence
CT 9th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 24-26, 2017
CL Porto, PORTUGAL
DE Deep learning; Temporal ConvNets; Transfer learning Text classification;
   Sentiment analysis
AB Temporal (one-dimensional) Convolutional Neural Network (Temporal CNN, ConvNet) is an emergent technology for text understanding. The input for the ConvNets could be either a sequence of words or a sequence of characters. In the latter case there are no needs for natural language processing. Past studies showed that the character-level ConvNets worked well for text classification in English and romanized Chinese corpus. In this article we apply the character-level ConvNets to Japanese corpus. We confirmed that meaningful representations are extracted by the ConvNets in English corpus and Japanese corpus. We attempt to reuse the meaningful representations that are learned in the ConvNets from a large-scale dataset in the form of transfer learning. As for the application to the news categorization and the sentiment analysis tasks in Japanese corpus, the ConvNets outperformed N-gram-based classifiers. In addition, our ConvNets transfer learning frameworks worked well for a task which is similar to one used for pre-training.
CR Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   Bengio Y., 2013, P 2013 IEEE INT C AC
   Del Corso G. M., 2005, P 14 INT C WORLD WID, P97
   Deng J., 2009, P 2009 IEEE C COMP V
   Gatti  M., 2014, COLING, P69
   Girshick R, 2014, P 2014 IEEE C COMP V
   Glorot X, 2010, P 13 INT C ART INT S
   Glorot X, 2011, P 28 INT C MACH LEAR
   Gulli A., 2005, INT C WORLD WID WEB, P880
   Kim  Y., 2014, P 2014 C EMP METH NA, P1746, DOI DOI 10.3115/V1/D14-1181
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kudo T., 2004, P 2004 C EMP METH NA, P230
   Maas A. L., 2011, P 49 ANN M ASS COMP, P142
   McAuley J. J., 2015, P 21 ACM SIGKDD INT, P785, DOI [10.1145/2783258.2783381, DOI 10.1145/2783258.2783381]
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Mikolov T., 2013, P NAACL 2013, P746
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Santos C. N. dos, 2015, P ANN M ASS COMP LIN, V1, P626
   Sato M, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P175, DOI 10.5220/0006193401750184
   Severyn A., 2015, P 9 INT WORKSH SEM E, P464
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Sharif Razavian  A., 2014, IEEE C COMP VIS PATT
   Socher R., 2013, P C EMP METH NAT LAN, P1631
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649
   Zhang Xucong, 2015, CORR
NR 27
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-93581-2; 978-3-319-93580-5
PY 2018
VL 10839
BP 62
EP 81
DI 10.1007/978-3-319-93581-2_4
UT WOS:000443493600004
ER

PT S
AU Perre, A
   Alexandre, LA
   Freire, LC
AF Perre, Ana
   Alexandre, Luis A.
   Freire, Luis C.
BE Tavares, JMRS
   Jorge, RMN
TI Lesion Classification in Mammograms Using Convolutional Neural Networks
   and Transfer Learning
SO VIPIMAGE 2017
SE Lecture Notes in Computational Vision and Biomechanics
CT 6th ECCOMAS Thematic Conference on Computational Vision and Medical
   Image Processing (VipIMAGE)
CY OCT 18-20, 2017
CL Porto, PORTUGAL
AB Computer-Aided Detection/Diagnosis (CAD) tools were created to assist the detection and diagnosis of early stage cancers, decreasing false negative rate and improving radiologists' efficiency. Convolutional Neural Networks (CNNs) are one example of deep learning algorithms that proved to be successful in image classification. In this paper we aim to study the application of CNNs to the classification of lesions in mammograms. One major problem in the training of CNNs for medical applications is the large dataset of images that is often required but seldom available. To solve this problem, we use a transfer learning approach, which is based on three different networks that were pre-trained on the Imagenet dataset. We then investigate the performance of these pretrained CNNs and two types of image normalization to classify lesions in mammograms. The best results were obtained using the Caffe reference model for the CNN with no image normalization.
CR Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Chatfield K., 2014, AW RET DEV DET DELV
   Ganesan Karthikeyan, 2013, IEEE Rev Biomed Eng, V6, P77, DOI 10.1109/RBME.2012.2232289
   Jalalian A, 2013, CLIN IMAG, V37, P420, DOI 10.1016/j.clinimag.2012.09.024
   Jia Y., 2014, ARXIV14085093
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Pisco J.M., 2003, IMAGIOLOGIA BSICA TE
   Sampat MP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1195, DOI 10.1016/B978-012119792-6/50130-3
   Tang JS, 2014, IEEE SYST J, V8, P907, DOI 10.1109/JSYST.2014.2317378
   Vedaldi A., 2015, P ACM INT C MULT
   Wang  D., 2016, DEEP LEARNING IDENTI
   Wichakam I, 2016, INT CONF KNOWL SMART, P239, DOI 10.1109/KST.2016.7440527
NR 12
TC 0
Z9 0
SN 2212-9391
BN 978-3-319-68195-5; 978-3-319-68194-8
PY 2018
VL 27
BP 360
EP 368
DI 10.1007/978-3-319-68195-5_40
UT WOS:000437032100040
ER

PT S
AU Chang, YJ
   Smedby, O
AF Chang, Yongjun
   Smedby, Orjan
BE Tavares, JMRS
   Jorge, RMN
TI Effects of Preprocessing in Slice-Level Classification of Interstitial
   Lung Disease Based on Deep Convolutional Networks
SO VIPIMAGE 2017
SE Lecture Notes in Computational Vision and Biomechanics
CT 6th ECCOMAS Thematic Conference on Computational Vision and Medical
   Image Processing (VipIMAGE)
CY OCT 18-20, 2017
CL Porto, PORTUGAL
DE Deep learning; Preprocessing; Transfer learning; Deep convolutional
   network
ID RESOLUTION COMPUTED-TOMOGRAPHY
AB Several preprocessing methods are applied to the automatic classification of interstitial lung disease (ILD). The proposed methods are used for the inputs to an established convolutional neural network in order to investigate the effect of those preprocessing techniques to slice-level classification accuracy. Experimental results demonstrate that the proposed preprocessing methods and a deep learning approach outperformed the case of the original images input to deep learning without preprocessing.
OI Smedby, Orjan/0000-0002-7750-1917
CR Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bartholmai BJ, 2013, J THORAC IMAG, V28, P298, DOI 10.1097/RTI.0b013e3182a21969
   Delorme S, 1997, INVEST RADIOL, V32, P566, DOI 10.1097/00004424-199709000-00009
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Uchiyama Y, 2003, MED PHYS, V30, P2440, DOI 10.1118/1.1597431
   Xu Y, 2006, ACAD RADIOL, V13, P969, DOI 10.1016/j.acra.2006.04.017
NR 6
TC 0
Z9 0
SN 2212-9391
BN 978-3-319-68195-5; 978-3-319-68194-8
PY 2018
VL 27
BP 624
EP 629
DI 10.1007/978-3-319-68195-5_67
UT WOS:000437032100067
ER

PT S
AU Utkin, LV
   Ryabinin, MA
AF Utkin, Lev V.
   Ryabinin, Mikhail A.
BE Filchenkov, A
   Pivovarova, L
   Zizka, J
TI A Deep Forest for Transductive Transfer Learning by Using a Consensus
   Measure
SO ARTIFICIAL INTELLIGENCE AND NATURAL LANGUAGE
SE Communications in Computer and Information Science
CT 6th Conference on Artificial Intelligence and Natural Language (AINL)
CY SEP 20-23, 2017
CL Saint Petersburg, RUSSIA
DE Classification; Random forest; Decision tree; Transfer learning;
   Quadratic optimization
AB A Transfer Learning Deep Forest (TLDF) is proposed in the paper. It is based on the Deep Forest or gcForest proposed by Zhou and Feng and can be viewed as a gcForest modification whose aim is to implement the transductive transfer learning. The transfer learning is based on introducing weights of trees in forests which impact on the forest class probability distributions. The weights can be regarded as training parameters of the deep forest and are determined in order to maximize the agreement on target and source domains. The convex quadratic optimization problem with linear constraints is obtained to compute optimal weights for every forest taking into account the consensus principle. The numerical experiments illustrate the proposed distance metric method.
RI Utkin, Lev/F-6480-2013
OI Utkin, Lev/0000-0002-5637-1420
CR Arnold A., 2007, 7 IEEE INT C DAT MIN, P77, DOI DOI 10.1109/ICDMW.2007.109
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137, DOI DOI 10.1007/S10994-009-5152-4
   Chen  M., 2011, P ADV NEUR INF PROC, P2456
   Ding ZM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3453
   Duan L, 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411
   Epstein B., 2017, ARXIV170510494V1
   Farajidavar N., 2014, BRIT MACH VIS C, V25, P1
   Fuzhen Zhuang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P417, DOI 10.1007/978-3-662-44845-8_27
   Gong T, 2012, IEEE C EVOL COMPUTAT
   Habrard A, 2016, KNOWL INF SYST, V47, P45, DOI 10.1007/s10115-015-0839-2
   Hu J, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Lu J, 2015, INFORMATION, V6, P388, DOI 10.3390/info6030388
   Luo L, 2017, ARXIV170508620V1
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Reddi S., 2016, ARXIV160708254V2
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Utkin L., 2017, ARXIV170408715V1
   Utkin L., 2017, ARXIV170509620V1
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xu C., 2013, ARXIV13045634, P1
   Xu ZJ, 2012, LECT NOTES COMPUT SC, V7665, P332, DOI 10.1007/978-3-642-34487-9_41
   Zhang X., 2015, ARXIV150300591V1
   Zhou Z., 2017, ARXIV170208835V2
   Zhuang FZ, 2010, IEEE T KNOWL DATA EN, V22, P1664, DOI 10.1109/TKDE.2009.205
NR 27
TC 1
Z9 1
SN 1865-0929
EI 1865-0937
BN 978-3-319-71746-3; 978-3-319-71745-6
PY 2018
VL 789
BP 194
EP 208
DI 10.1007/978-3-319-71746-3_17
UT WOS:000437301200017
ER

PT S
AU Gandarias, JM
   Gomez-de-Gabriel, JM
   Garcia-Cerezo, AJ
AF Gandarias, Juan M.
   Gomez-de-Gabriel, Jesus M.
   Garcia-Cerezo, Alfonso J.
BE Ollero, A
   Sanfeliu, A
   Montano, L
   Lau, N
   Cardeira, C
TI Tactile Sensing and Machine Learning for Human and Object Recognition in
   Disaster Scenarios
SO ROBOT 2017: THIRD IBERIAN ROBOTICS CONFERENCE, VOL 2
SE Advances in Intelligent Systems and Computing
CT 3rd Iberian Robotics Conference (Robot)
CY NOV 22-24, 2017
CL Seville, SPAIN
DE Tactile sensors; Rescue robotics; Machine learning; Deep learning;
   Transfer learning; Object recognition
AB This paper presents the application of machine learning to tactile sensing for rescue robotics. Disaster situations often exhibit low-visibility scenarios where haptic feedback provides a valuable information for the search of potential victims. To extract haptic information from the environment, a tactile sensor attached to a lightweight robotic arm is used. Then, methods based on the SURF descriptor, support vector machines (SVM), Deep Convolutional Neural Networks (DCNN) and transfer learning are implemented to classify the data. Besides, experiments have been carried out, to compare those procedures, using different contact elements, such as human parts and objects that could be found in catastrophe scenarios. The best achieved accuracy of 92.22%, results from the application of the transfer learning procedure using a pre-trained DCNN and fine-tuning the classification layer of the network.
RI Gomez-de-Gabriel, Jesus/H-2563-2015
OI Gomez-de-Gabriel, Jesus/0000-0001-5960-3453
CR Abdelrahman W, 2012, IEEE SYS MAN CYBERN, P2213, DOI 10.1109/ICSMC.2012.6378069
   Ang QZ, 2015, IEEE SYST J, V9, P86, DOI 10.1109/JSYST.2013.2283955
   Baishya SS, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P8, DOI 10.1109/IROS.2016.7758088
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Espes D., 2013, ARXIV13124162
   Garcia-Cerezo A., 2007, IEEE INT WORKSH SAF, P1, DOI DOI 10.1109/SSRR2007.4381269
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Khasnobish A., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252593
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 1995, HDB BRAIN THEORY NEU, V3361, P1995, DOI DOI 10.1007/S13398-014-0173-7.2
   Likas A, 2003, PATTERN RECOGN, V36, P451
   Liu HB, 2012, IEEE INT CONF ROBOT, P1410, DOI 10.1109/ICRA.2012.6224872
   Liu HP, 2016, IEEE T INSTRUM MEAS, V65, P656, DOI 10.1109/TIM.2016.2514779
   Liu YG, 2013, J INTELL ROBOT SYST, V72, P147, DOI 10.1007/s10846-013-9822-x
   Luo S, 2015, LECT NOTES ARTIF INT, V9245, P15, DOI 10.1007/978-3-319-22876-1_2
   Luo S, 2015, IEEE SENS J, V15, P5001, DOI 10.1109/JSEN.2015.2432127
   Luo S, 2016, IEEE ICC
   Madry M, 2014, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ICRA.2014.6907172
   Murphy R. R., 2008, SPRINGER HDB ROBOTIC, P1151, DOI DOI 10.1007/978-3-540-30301-5_51
   Navarro S. E., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P497, DOI 10.1109/HAPTIC.2012.6183837
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ranasinghe A, 2016, IEEE T CYBERNETICS, V46, P568, DOI 10.1109/TCYB.2015.2409772
   Schmitz A, 2014, IEEE-RAS INT C HUMAN, P1044, DOI 10.1109/HUMANOIDS.2014.7041493
   Serrano-Cuerda J., 2011, 2011 7th International Conference on Intelligent Environments, P354, DOI 10.1109/IE.2011.21
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Vidal-Verdu F, 2011, SENSORS-BASEL, V11, P5489, DOI 10.3390/s110505489
NR 28
TC 1
Z9 1
SN 2194-5357
EI 2194-5365
BN 978-3-319-70836-2; 978-3-319-70835-5
PY 2018
VL 694
BP 165
EP 175
DI 10.1007/978-3-319-70836-2_14
UT WOS:000436471400014
ER

PT S
AU Kim, D
   Cho, D
   Yoo, D
   Kweon, IS
AF Kim, Dahun
   Cho, Donghyeon
   Yoo, Donggeun
   Kweon, In So
GP IEEE
TI Learning Image Representations by Completing Damaged Jigsaw Puzzles
SO 2018 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV
   2018)
SE IEEE Winter Conference on Applications of Computer Vision
CT 18th IEEE Winter Conference on Applications of Computer Vision (WACV)
CY MAR 12-15, 2018
CL NV
AB In this paper, we explore methods of complicating self-supervised tasks for representation learning. That is, we do severe damage to data and encourage a network to recover them. First, we complicate each of three powerful self-supervised task candidates: jigsaw puzzle, inpainting, and colorization. In addition, we introduce a novel complicated self-supervised task called "Completing damaged jigsaw puzzles" which is puzzles with one piece missing and the other pieces without color. We train a convolutional neural network not only to solve the puzzles, but also generate the missing content and colorize the puzzles. The recovery of the aforementioned damage pushes the network to obtain robust and general-purpose representations. We demonstrate that complicating the self-supervised tasks improves their original versions and that our final task learns more robust and transferable representations compared to the previous methods, as well as the simple combination of our candidate tasks. Our approach achieves state-of-the-art performance in transfer learning on PASCAL classification and semantic segmentation.
CR Bilen H., 2016, P COMP VIS PATT REC
   Diederik M. W., 2014, P INT C LEARN REPR I
   Doersch C., 2015, P INT C COMP VIS ICC
   Doersch C., 2017, P INT C COMP VIS ICC
   Donahue J., 2017, P INT C LEARN REPR I
   Everingham M., PASCAL VISUAL OBJECT
   Girshick R., 2015, P INT C COMP VIS ICC
   He K., 2016, P COMP VIS PATT REC
   Isola P., 2015, ICLR WORKSH
   Jayaraman D, 2017, INT J COMPUT VISION, V125, P136, DOI 10.1007/s11263-017-1001-2
   Jia Y., 2014, ARXIV14085093
   Jie Z., 2017, P COMP VIS PATT REC
   Kantorov V., 2016, P EUR C COMP VIS ECC
   Kim D., 2017, P INT C COMP VIS ICC
   Kingma D., 2015, P INT C LEARN REPR I
   Krahenbuhl P., 2016, P INT C LEARN REPR I
   Krizhevsky A., 2012, P NEUR INF PROC SYST
   Larsson G., 2017, P COMP VIS PATT REC
   Lee H.-Y., 2017, P INT C COMP VIS ICC
   Long Jonathan, 2015, P COMP VIS PATT REC
   Misra I., 2016, P EUR C COMP VIS ECC
   Noroozi M., 2017, P INT C COMP VIS ICC
   Noroozi M., 2016, P EUR C COMP VIS E
   Oquab M., 2015, P COMP VIS PATT REC
   Owens A., 2016, P EUR C COMP VIS ECC
   Pathak D., 2017, P COMP VIS PATT REC
   Pathak D., 2016, P COMP VIS PATT REC
   Radford A., 2016, P INT C LEARN REPR I
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, ABS14091556 CORR
   Szegedy C., 2015, P COMP VIS PATT REC
   Tang MF, 2015, IEEE INT CON MULTI
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang X., 2015, P INT C COMP VIS ICC
   Wang X., 2017, P INT C COMP VIS ICC
   Zhang R., 2017, P COMP VIS PATT REC
   Zhang R., 2016, P EUR C COMP VIS ECC
   Zisserman A., 2017, P INT C COMP VIS ICC
NR 38
TC 0
Z9 0
SN 2472-6737
BN 978-1-5386-4886-5
PY 2018
BP 793
EP 802
DI 10.1109/WACV.2018.00092
UT WOS:000434349200086
ER

PT S
AU Dominguez, M
   Dhamdhere, R
   Petkar, A
   Jain, S
   Sah, S
   Ptucha, R
AF Dominguez, Miguel
   Dhamdhere, Rohan
   Petkar, Atir
   Jain, Saloni
   Sah, Shagan
   Ptucha, Raymond
GP IEEE
TI General-Purpose Deep Point Cloud Feature Extractor
SO 2018 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV
   2018)
SE IEEE Winter Conference on Applications of Computer Vision
CT 18th IEEE Winter Conference on Applications of Computer Vision (WACV)
CY MAR 12-15, 2018
CL NV
AB Depth sensors used in autonomous driving and gaming systems often report back 3D point clouds. The lack of structure from these sensors does not allow these systems to take advantage of recent advances in convolutional neural networks which are dependent upon traditional filtering and pooling operations. Analogous to image based convolutional architectures, recently introduced graph based architectures afford similar filtering and pooling operations on arbitrary graphs. We adopt these graph based methods to 3D point clouds to introduce a generic vector representation of 3D graphs, we call graph 3D (G3D). We believe we are the first to use large scale transfer learning on 3D point cloud data and demonstrate the discriminant power of our salient latent representation of 3D point clouds on unforeseen test sets. By using our G3D network (G3DNet) as a feature extractor, and then pairing G3D feature vectors with a standard classifier, we achieve the best accuracy on ModelNet10 (93.1%) and ModelNet 40 (91.7%) for a graph network, and comparable performance on the Sydney Urban Objects dataset to other methods. This general-purpose feature extractor can be used as an off-the-shelf component in other 3D scene understanding or object tracking works.
CR Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   Arvind V., 2017, ARXIV E PRINTS
   Atwood J, 2016, ADV NEURAL INFORM PR, P1993
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Bell W. N., 2015, PYAMG ALGEBRAIC MULT
   Bell W. N., 2008, THESIS
   Ben-Shabat Y., 2017, ARXIV E PRINTS
   Brock A., GENERATIVE DISCRIMIN
   Bruna J., 2013, ARXIV13126203
   Chang A. X, 2015, ARXIV151203012
   Chen TT, 2014, IEEE INT VEH SYM, P667, DOI 10.1109/IVS.2014.6856425
   Chen XG, 2015, LECT N MECH ENG, P1, DOI 10.1007/978-3-319-09507-3_1
   Cignoni P., 2008, ERCIM NEWS, V73, P45, DOI DOI 10.2312/L0CALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPC0NF2008/129-136
   Defferrard M., ADV NEURAL INFORM PR, V29, P3844
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Deuge M. D., 2013, AUSTR C ROB AUT, V2
   Dominguez M., 2017, INT C IM PROC
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Edwards M., BRIT MACH VIS C
   Gomez-Donoso F, 2017, IEEE IJCNN, P412, DOI 10.1109/IJCNN.2017.7965883
   Henaff Mikael, 2015, ARXIV150605163
   Ioffe S, 2015, INT C MACH LEARN, V37, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Johns E., 2016, IEEE C COMP VIS PATT
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma Diederik P., 2014, CORR
   Kipf T. N., P ICLR 2017
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Maturana D, 2015, IEEE RSJ INT C INT R
   Monti F., 2016, ARXIV161108402
   Niepert M., 2016, INT C MACH LEARN, P2014
   Perozzi B., 2014, KDD, P701, DOI DOI 10.1145/2623330.2623732
   Qi C. R., 2017, IEEE C COMP VIS PATT
   Ravanbakhsh S., P ICLR 2017, V1611
   Riemenschneider Hayko, 2014, LEARNING CLASSIFY MU, P516
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandryhaila A, 2013, IEEE T SIGNAL PROCES, V61, P1644, DOI 10.1109/TSP.2013.2238935
   Sedaghat N., 2016, CORR
   Sedaghat N., 2017, BRIT MACH VIS C BMVC
   Sedaghat N, 2015, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2015.155
   Serna A., 3 INT C PATT REC APP
   Sfikas K., 2017, EUR WORKSH 3D OBJ RE
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Simonovsky M., 2017, IEEE C COMP VIS PATT
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Sinha A., 2016, DEEP LEARNING 3D SHA, P223
   Soltani A. A., 2017, IEEE C COMP VIS PATT
   Su H., 2015, P ICCV
   Such FP, 2017, IEEE J-STSP, V11, P884, DOI 10.1109/JSTSP.2017.2726981
   Trottenberg U., 2000, MULTIGRID
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang C., 2017, BRIT MACH VIS C
   Wu J., 2016, ADV NEURAL INFORM PR, P82
   Xu Kelvin, 2015, INT C MACH LEARN, P2048
   Xu X, 2016, INT C PATT RECOG, P3506, DOI 10.1109/ICPR.2016.7900177
   Yi L., 2017, IEEE C COMP VIS PATT
   Zamir AR, 2016, LECT NOTES COMPUT SC, V9907, P535, DOI 10.1007/978-3-319-46487-9_33
   Zanuttigh P., 2017, INT C IM PROC
   Zhi S., 2017, COMPUTERS GRAPHICS
   Zhi S., 2017, EUR WORKSH 3D OBJ RE
   Zhirong W., 2015 IEEE C COMP VIS, P1912
NR 63
TC 0
Z9 0
SN 2472-6737
BN 978-1-5386-4886-5
PY 2018
BP 1972
EP 1981
DI 10.1109/WACV.2018.00218
UT WOS:000434349200212
ER

PT B
AU Hong, YX
   Ling, C
   Ye, ZC
AF Hong, Yuxi
   Ling, Chen
   Ye, Zuochang
GP IEEE
TI End-to-End Soccer Video Scene and Event Classification with Deep
   Transfer Learning
SO 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION
   (ISCV2018)
CT International Conference on Intelligent Systems and Computer Vision
   (ISCV)
CY APR 02-04, 2018
CL Fac Sci Dhar Mahraz, Fez, MOROCCO
HO Fac Sci Dhar Mahraz
DE Soccer video scene and event classification; Deep transfer learning; CNN
AB Soccer video scene and event classification are two essential tasks for the soccer video semantic analysis and have attracted many interests of researchers because of their importance and practicability. However most proposed methods solve these two tasks separately. In order to solve two tasks at the same time and improve the efficiency of video processing, we treat them as one end-to-end classification task. We introduce a new Soccer Video Scene and Event Dataset (SVSED) with six categories from the scenes and events, which contains 600 video clips. Then, we show that frame features extracted from pretrained CNN model of different categories are separable in 3-D space. Finally, we construct a CNN model for the classification task and deep transfer learning method is used for optimizing classification task result considering relative small training datasets. We fine-tuned several state-of-art CNN models and achieves accuracy above 89% within several minutes training.
CR DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Jiang HH, 2016, PROC INT C TOOLS ART, P490, DOI [10.1109/ICTAI.2016.78, 10.1109/ICTAI.2016.0081]
   Kolekar M. H., 2008, TENCON 2008 2008 IEE, P1
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li B., 2003, P IEEE INT C AC SPEE, V3, P169
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Simonyan K., 2014, ARXIV14091556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tingxi Liu, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P440, DOI 10.1007/978-3-319-70096-0_46
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
NR 15
TC 0
Z9 0
BN 978-1-5386-4396-9
PY 2018
UT WOS:000435239200078
ER

PT S
AU Habibzadeh, M
   Jannesari, M
   Rezaei, Z
   Baharvand, H
   Totonchi, M
AF Habibzadeh, Mehdi
   Jannesari, Mahboobeh
   Rezaei, Zahra
   Baharvand, Hossein
   Totonchi, Mehdi
BE Verikas, A
   Radeva, P
   Nikolaev, D
   Zhou, J
TI Automatic White Blood Cell Classification Using Pre-trained Deep
   Learning Models: ResNet and Inception
SO TENTH INTERNATIONAL CONFERENCE ON MACHINE VISION (ICMV 2017)
SE Proceedings of SPIE
CT 10th International Conference on Machine Vision (ICMV)
CY NOV 13-15, 2017
CL Vienna, AUSTRIA
DE Deep learning; Inception; ResNet; transfer learning; fine-tuning; white
   blood cell classification
AB This works gives an account of evaluation of white blood cell differential counts via computer aided diagnosis (CAD) system and hematology rules. Leukocytes, also called white blood cells (WBCs) play main role of the immune system. Leukocyte is responsible for phagocytosis and immunity and therefore in defense against infection involving the fatal diseases incidence and mortality related issues. Admittedly, microscopic examination of blood samples is a time consuming, expensive and error-prone task. A manual diagnosis would search for specific Leukocytes and number abnormalities in the blood slides while complete blood count (CBC) examination is performed. Complications may arise from the large number of varying samples including different types of Leukocytes, related sub-types and concentration in blood, which makes the analysis prone to human error. This process can be automated by computerized techniques which are more reliable and economical. In essence, we seek to determine a fast, accurate mechanism for classification and gather information about distribution of white blood evidences which may help to diagnose the degree of any abnormalities during CBC test. In this work, we consider the problem of pre-processing and supervised classification of white blood cells into their four primary types including Neutrophils, Eosinophils, Lymphocytes, and Monocytes using a consecutive proposed deep learning framework. For first step, this research proposes three consecutive pre-processing calculations namely are color distortion; bounding box distortion (crop) and image flipping mirroring. In second phase, white blood cell recognition performed with hierarchy topological feature extraction using Inception and ResNet architectures. Finally, the results obtained from the preliminary analysis of cell classification with (11200) training samples and 1244 white blood cells evaluation data set are presented in confusion matrices and interpreted using accuracy rate, and false positive with the classification framework being validated with experiments conducted on poor quality blood images sized 320 x 240 pixels. The deferential outcomes in the challenging cell detection task, as shown in result section, indicate that there is a significant achievement in using Inception and ResNet architecture with proposed settings. Our framework detects on average 100% of the four main white blood cell types using ResNet V1 50 while also alternative promising result with 99.84% and 99.46% accuracy rate obtained with ResNet V1 152 and ResNet 101, respectively with 3000 epochs and fine-tuning all layers. Further statistical confusion matrix tests revealed that this work achieved 1, 0.9979, 0.9989 sensitivity values when area under the curve (AUC) scores above 1, 0.9992, 0.9833 on three proposed techniques. In addition, current work shows negligible and small false negative 0, 2, 1 and substantial false positive with 0, 0, 5 values in Leukocytes detection.
CR Aubreville M., 2017, ARXIV170301622
   Bahadori MT, 2014, KNOWL INF SYST, V38, P61, DOI 10.1007/s10115-013-0647-5
   Bruegel M, 2015, CLIN CHEM LAB MED, V53, P1057, DOI 10.1515/cclm-2014-0945
   Chang H., 2017, ARXIV170300534
   Chen CL, 2016, SCI REP-UK, V6, DOI 10.1038/srep21471
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Daume H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Dorini LB, 2013, IEEE J BIOMED HEALTH, V17, P250, DOI 10.1109/TITB.2012.2207398
   Grimaldi E, 2000, AM J CLIN PATHOL, V113, P497
   Gui L., 2017, INT J MACHINE LEARNI, P1
   Habibzadeh Mehdi, 2014, Artificial Neural Networks in Pattern Recognition. 6th IAPR TC 3 International Workshop, ANNPR 2014. Proceedings: LNCS 8774, P216, DOI 10.1007/978-3-319-11656-3_20
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hinton G., 2012, NEURAL NETWORKS MACH
   Ioffe S., 2015, CORR
   Joshi M. D., 2013, INT J EMERGING TREND, V2
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lee C. - Y., 2015, ARTIF INTELL, P562
   Liu Y., 2017, ARXIV170302442
   Naz S., 2017, IEEE C COMP VIS PATT
   Nazlibilek S., 2015, BIOMEDICAL RES, V26
   Parthasarathy D., 2017, WBC CLASSIFICATION
   Ramesh N., 2012, J PATHOLOGY INFORN, V3
   Ramoser H., 2006, P IEEE EMBS, P3371, DOI DOI 10.1109/IEMBS.2005.1617200
   Rezatofighi SH, 2011, COMPUT MED IMAG GRAP, V35, P333, DOI 10.1016/j.compmedimag.2011.01.003
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruzicka K, 2001, ARCH PATHOL LAB MED, V125, P391
   Sajjad M, 2016, INT CONF FRONT INFO, P99, DOI [10.1109/FIT.2016.24, 10.1109/FIT.2016.026]
   Schaul T., 2013, P 30 INT C MACH LEAR, P343
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Sutskever I., 2013, P 30 INT C MACH LEAR, P1139
   Szegedy C., 2017, AAAI, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   T. G. Developers, 2017, DISTR TENS
   T. G. Developers, 2017, INST TENS UB
   T. N. Developers, 2017, NVIDIA GPUS ENG DEEP
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Wang D., 2016, ARXIV160605718
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zadrozny B., 2004, ICML, P114, DOI DOI 10.1145/1015330.1015425
   Zeiler M. D., 2012, ARXIV12125701
NR 43
TC 1
Z9 1
SN 0277-786X
EI 1996-756X
BN 978-1-5106-1942-5
PY 2018
VL 10696
AR UNSP 1069612
DI 10.1117/12.2311282
UT WOS:000432481200036
ER

PT S
AU Patel, VA
   Joshi, MV
AF Patel, Vaibhav Amit
   Joshi, Manjunath V.
BE Verikas, A
   Radeva, P
   Nikolaev, D
   Zhou, J
TI Convolutional Neural Network with Transfer Learning for Rice Type
   Classification
SO TENTH INTERNATIONAL CONFERENCE ON MACHINE VISION (ICMV 2017)
SE Proceedings of SPIE
CT 10th International Conference on Machine Vision (ICMV)
CY NOV 13-15, 2017
CL Vienna, AUSTRIA
DE Convolutional neural network; computer vision; transfer learning
AB Presently, rice type is identified manually by humans, which is time consuming and error prone. Therefore, there is a need to do this by machine which makes it faster with greater accuracy. This paper proposes a deep learning based method for classification of rice types. We propose two methods to classify the rice types. In the first method, we train a deep convolutional neural network (CNN) using the given segmented rice images. In the second method, we train a combination of a pretrained VGG16 network and the proposed method, while using transfer learning in which the weights of a pretrained network are used to achieve better accuracy. Our approach can also be used for classification of rice grain as broken or fine. We train a 5-class model for classifying rice types using 4000 training images and another 2- class model for the classification of broken and normal rice using 1600 training images. We observe that despite having distinct rice images, our architecture, pretrained on ImageNet data boosts classification accuracy significantly.
CR Guzman J. D., 2008, World conference on agricultural information and IT, IAALD AFITA WCCA 2008, Tokyo University of Agriculture, Tokyo, Japan, 24 - 27 August, 2008, P41
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Huang Xing-yi, 2004, J JIANGSU U NATL SCI, V2
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun  Y., 1990, ADV NEURAL INFORM PR, P396, DOI DOI 10.1111/DSU.12130
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LeCun Yann, 1995, HDB BRAIN THEORY NEU, V3361, P10
   Liu Zhao-yan, 2005, J Zhejiang Univ Sci B, V6, P1095, DOI 10.1631/jzus.2005.B1095
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Singh B., 2013, INT J SCI RES PUBL, V3, P1
   Sonnadara Upul, 2013, P TECHNICAL SESSIONS, V29, P9
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 17
TC 0
Z9 0
SN 0277-786X
EI 1996-756X
BN 978-1-5106-1942-5
PY 2018
VL 10696
AR UNSP 1069613
DI 10.1117/12.2309482
UT WOS:000432481200037
ER

PT S
AU Li, XD
   Mao, WJ
   Jiang, W
   Yao, Y
AF Li, Xiaodong
   Mao, Weijie
   Jiang, Wei
   Yao, Ye
BE Cao, J
   Cambria, E
   Lendasse, A
   Miche, Y
   Vong, CM
TI Multi-kernel Transfer Extreme Learning Classification
SO PROCEEDINGS OF ELM-2016
SE Proceedings in Adaptation Learning and Optimization
CT 7th International Conference on Extreme Learning Machines (ELM)
CY DEC 13-15, 2016
CL Singapore, SINGAPORE
DE Extreme learning machine; Transfer learning (TL); Multiple kernel
   learning
ID FEEDFORWARD NETWORKS; MACHINE; ALGORITHM
AB In this paper, a novel transfer extreme learning machine (TELM) algorithm based on multi-kernel (MK) framework has been proposed for classification. In this case, the problem is transformed into a semi-supervised learning problem, which allows multi-kernel extreme learning machine (MK-TELM) classifiers to be trained for the data categorization. Compared with many popular algorithms, the proposed method, named as MK-TELM, shows its satisfactorily experimental results on the variety of data sets, which highlights the robustness and effectiveness for classification applications.
CR CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Huang G, 2014, IEEE T CYBERNETICS, V44, P2405, DOI 10.1109/TCYB.2014.2307349
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2015, IEEE COMPUT INTELL M, V10, P18, DOI 10.1109/MCI.2015.2405316
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Kim CT, 2008, IEEE T NEURAL NETWOR, V19, P371, DOI 10.1109/TNN.2007.911739
   Lam D., 2013, NEUR NETW IJCNN 2013, P1
   Li GH, 2010, COMPUT MATH APPL, V60, P377, DOI 10.1016/j.camwa.2010.03.023
   Li XD, 2016, NEURAL COMPUT APPL, V27, P175, DOI 10.1007/s00521-014-1709-7
   Liu XW, 2015, NEUROCOMPUTING, V149, P253, DOI 10.1016/j.neucom.2013.09.072
   Pan J, 2014, NEUROCOMPUTING, V137, P57, DOI 10.1016/j.neucom.2013.04.045
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng Y, 2015, NEUROCOMPUTING, V149, P340, DOI 10.1016/j.neucom.2013.12.065
   Rong HJ, 2008, NEUROCOMPUTING, V72, P359, DOI 10.1016/j.neucom.2008.01.005
   Scardapane S, 2014, RECENT ADV NEURAL NE, P25, DOI [10.1007/978-3-319-04129-2, DOI 10.1007/978-3-319-04129-2.]
   Wang YG, 2011, NEUROCOMPUTING, V74, P2483, DOI 10.1016/j.neucom.2010.11.030
   Zeng GQ, 2016, INFORM SCIENCES, V330, P49, DOI 10.1016/j.ins.2015.10.010
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 20
TC 0
Z9 0
SN 2363-6084
BN 978-3-319-57421-9; 978-3-319-57420-2
PY 2018
VL 9
BP 159
EP 170
DI 10.1007/978-3-319-57421-9_13
UT WOS:000432226700013
ER

PT S
AU Lopez-Sanchez, D
   Arrieta, AG
   Corchado, JM
AF Lopez-Sanchez, Daniel
   Gonzalez Arrieta, Angelica
   Corchado, Juan M.
BE Omatu, S
   Rodriguez, S
   Villarrubia, G
   Faria, P
   Sitek, P
   Prieto, J
TI Deep neural networks and transfer learning applied to multimedia web
   mining
SO DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE
SE Advances in Intelligent Systems and Computing
CT 14th International Symposium on Distributed Computing and Artificial
   Intelligence (DCAI)
CY JUN 21-23, 2017
CL Porto, PORTUGAL
DE Web mining; deep learning; transfer learning
AB The growth in the amount of multimedia content available online supposes a challenge for search and recommender systems. This information in the form of visual elements is of great value to a variety of web mining tasks; however, the mining of these resources is a difficult task due to the complexity and variability of the images. In this paper, we propose applying a deep learning model to the problem of web categorization. In addition, we make use of a technique known as transfer or inductive learning to drastically reduce the computational cost of the training phase. Finally, we report experimental results on the effectiveness of the proposed method using different classification methods and features from various depths of the deep model.
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Masoudnia S, 2014, ARTIF INTELL REV, V42, P275, DOI 10.1007/s10462-012-9338-y
   Nair V.G., 2014, GETTING STARTED BEAU
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 12
TC 2
Z9 2
SN 2194-5357
EI 2194-5365
BN 978-3-319-62410-5
PY 2018
VL 620
BP 124
EP 131
DI 10.1007/978-3-319-62410-5_15
UT WOS:000426343700015
ER

PT J
AU Chen, JC
   Liu, CF
AF Chen, Ju-Chin
   Liu, Chao-Feng
TI Deep net architectures for visual-based clothing image recognition on
   large database
SO SOFT COMPUTING
CT 5th ASE International Conference on Big Data (ASE BIGDATA) / 4th ASE
   International Conference on Social Informatics (SOCIAL INFORMATICS)
CY OCT 07-09, 2015
CL Natl Univ Kaohsiung, Kaohsiung, TAIWAN
HO Natl Univ Kaohsiung
DE Deep Learning; Convolutional neural network; Clothing image recognition
ID PERSPECTIVES; BIG
AB In the Big Data era, there is a need for powerful visual-based analytics tools when pictures have replaced texts and become main contents on the Internet. Hence, in this study, we explore convolutional neural networks with a goal of resolving clothing style classification and retrieval tasks. To reduce training complexity, low-level and mid-level features were learned in the deep models on large-scale datasets and then transfer learning is incorporated by fine-tuning pre-trained models using the clothing dataset. However, a large amount of collected data needs huge computations for tuning parameters. Therefore, one architecture inspired from Adaboost is designed to use multiple deep nets that are trained with a sub-dataset. Thus, the training time can be accelerated if each net is computed in one client node in a distributed computing environment. Moreover, to increase system flexibility, two architectures with multiple deep nets with two outputs are proposed for binary-class classification. Therefore, when new classes are added, no additional computation is needed for all training data. In order to integrate output responses from multiple nets, classification rules are proposed as well. Experiments are performed to compare existing systems with hand-crafted features. According to the results, the proposed system can provide significant improvements on three public clothing datasets for style classifications, particularly on the large dataset with 80,000 images where an improvement of 18% in accuracy was recognized.
CR Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Bengio Y., 2007, ADV NEURAL INFORM PR, V2007, P153
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bossard L., 2013, LNCS, V7727, P321, DOI DOI 10.1007/978-3-642-37447-0
   Chen JC, 2015, ASE BIGDATA SOCIALIN
   Chen JC, 2015, CEC WORKSH
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Couprie C, 2013, IEEE T PATTERN RECOG, V35
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dean J, 2012, INT C NEUR INF PROC, P1232
   Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492
   Deng J, 2011, IEEE C COMP VIS PATT, P785
   Di W, 2013, IEEE COMPUT SOC CONF, P8, DOI 10.1109/CVPRW.2013.6
   Donahue J., 2013, ARXIV13101531
   Efrati A., 2013, DEEP LEARNING WORKS
   Gantz J., 2011, EXTRACTING VALUE CHA
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2011, INT C ARTIF INTELLIG, P315, DOI DOI 10.1177/1753193410395357
   Goodfellow I. J., 2013, ARXIV13024389, P3
   Hinton G.E., 2012, ARXIV12070508
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang J, 2015, ARXIV150507922
   Jagadeesh V, 2014, ACM SIGKDD INT C KNO, P1925
   Jia Y., 2014, INT C MULT, P675
   Jones N, 2014, NATURE, V505, P146, DOI 10.1038/505146a
   Kalantidis Y, 2013, ACM C INT C MULT RET, P105
   Khosla N, 2015, CS231N COURSE PROJEC
   Kiapour M. H., 2014, EUR C COMP VIS, P472
   Krizhevsky A, 2012, IMAGENET CLASSIFICAT, P1106
   Krizhevsky A., 2012, CUDA CONVNET
   Le Q, 2012, INT C MACH LEARN, P81
   Le Q. V., 2011, IEEE C COMP VIS PATT, P3361
   LECUN Y, 1998, IEEE, V86, P2278
   Lin K, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P499, DOI 10.1145/2671188.2749318
   Lin M., 2013, ARXIV13124400
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu S, 2012, INT C MULT, P619
   Liu S., 2015, ARXIV150401220
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Long J, 2014, INT C NEUR INF PROC, P1601
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Najafabadi M, 2015, J BIG DATA, V2, P1, DOI DOI 10.1186/S40537-014-0007-7
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sermanet P., 2014, ARXIV13126229
   Socher R, 2011, INT C NEUR INF PROC, P801
   Socher R., 2011, ICML, P129
   Song Z, 2011, IEEE I CONF COMP VIS, P1084, DOI 10.1109/ICCV.2011.6126355
   Sukumar SR, 2014, ACM SIGKDD C KNOWL D
   Sun Y., 2015, IEEE C COMP VIS PATT
   Tung F, 2014, LECT NOTES COMPUT SC, V8694, P511, DOI 10.1007/978-3-319-10599-4_33
   Wang Y, 2011, LANGUAGE UNDERSTANDI, P119
   Yamada K., 2014, ACM MM, P773
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
NR 61
TC 1
Z9 1
SN 1432-7643
EI 1433-7479
PD JUN
PY 2017
VL 21
IS 11
SI SI
BP 2923
EP 2939
DI 10.1007/s00500-017-2585-8
UT WOS:000401696600011
ER

PT J
AU Quinn, A
   Karny, M
   Guy, TV
AF Quinn, Anthony
   Karny, Miroslav
   Guy, Tatiana V.
TI Optimal design of priors constrained by external predictors
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
CT 9th Biannual International Symposium on Imprecise Probability - Theories
   and Applications (ISIPTA)
CY JUL 20-24, 2015
CL Pescara, ITALY
DE Fully probabilistic design; Parameter prior; External predictive
   distribution; Bayesian transfer learning; Kullback-Leibler divergence
ID FULLY PROBABILISTIC DESIGN; INFERENCE; MODELS
AB This paper exploits knowledge made available by an external source in the form of a predictive distribution in order to elicit a parameter prior. It uses the terminology of Bayesian transfer learning, one of many domains dealing with reasoning as coherent knowledge processing. An empirical solution of the addressed problem was provided in [19], based on an interpretation of the external predictor as an empirical distribution constructed from fictitious data. In this paper, two main contributions are provided. First, the problem is solved using formal hierarchical Bayesian modeling [25], and the knowledge transfer is achieved optimally, i.e. in the minimum-KLD sense. Second, this hierarchical setting yields a distribution on the set of possible priors, with the choice [19] acting as the base distribution. This allows randomized choices of the prior to be generated, avoiding costly and/or intractable estimation of this prior. It also provides measures of uncertainty in the prior choice, allowing subsequent learning tasks to be assessed for robustness to this prior choice. The instantiation of the method in already published applications in knowledge elicitation, recursive learning and flat cooperation of adaptive controllers is recalled, and prospective application domains are also mentioned. (C) 2017 Elsevier Inc. All rights reserved.
CR Barndorff-Nielsen O., 1978, INFORM EXPONENTIAL F
   Berger J. O., 1985, STAT DECISION THEORY
   BERNARDO JM, 1979, J R STAT SOC B, V41, P113
   BERNARDO JM, 1979, ANN STAT, V7, P686, DOI 10.1214/aos/1176344689
   Bernardo JM, 1994, BAYESIAN THEORY
   Cattivelli FS, 2010, IEEE T AUTOMAT CONTR, V55, P2069, DOI 10.1109/TAC.2010.2042987
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   Guan P, 2014, IEEE T AUTOMAT CONTR, V59, P1423, DOI 10.1109/TAC.2014.2301558
   Guyon I, 2010, J MACH LEARN RES, V11, P61
   Jayaram V, 2016, IEEE COMPUT INTELL M, V11, P20, DOI 10.1109/MCI.2015.2501545
   Jaynes E, 2003, PROBABILITY THEORY L
   Kappen HJ, 2012, MACH LEARN, V87, P159, DOI 10.1007/s10994-012-5278-7
   Kappen HJ, 2005, PHYS REV LETT, V95, DOI [10.1103/PhysRevLett.95.200201, 10.1103/PhysRevLett.200201]
   Karny M., 2017, WORKSHOP C P SERIES, V58
   Karny M, 2017, IEEE T SYST MAN CY-S, V47, P394, DOI 10.1109/TSMC.2015.2502427
   Karny M, 2014, STAT INTERFACE, V7, P503, DOI 10.4310/SII.2014.v7.n4.a7
   Karny M, 2012, INFORM SCIENCES, V186, P105, DOI 10.1016/j.ins.2011.09.018
   Koopman BO, 1936, T AM MATH SOC, V39, P399, DOI 10.2307/1989758
   Kracik J., 2005, P 2 INT C INF CONTR, P229
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Mason W, 2014, MACH LEARN, V95, P257, DOI 10.1007/s10994-013-5426-8
   O'Hagan A., 2006, UNCERTAIN JUDGEMENT
   Peterka V., 1981, TRENDS PROGR SYSTEM, P239, DOI DOI 10.1016/B978-0-08-025683-2.50013-2
   Quinn A, 2007, INT J ADAPT CONTROL, V21, P827, DOI 10.1002/acs.949
   Quinn A, 2016, INFORM SCIENCES, V369, P532, DOI 10.1016/j.ins.2016.07.035
   RAO M, 1987, MEASURE THEORY INTEG
   Rios-Insua D., 2000, ROBUST BAYESIAN ANAL
   Shao YH, 2012, PATTERN RECOGN, V45, P2299, DOI 10.1016/j.patcog.2011.11.028
   SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144
   Tang Y, 2014, ANNU REV CONTROL, V38, P184, DOI 10.1016/j.arcontrol.2014.09.003
   TANNER M. A., 1993, TOOLS STAT INFERENCE
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Todorov E., 2006, ADV NEURAL INFORM PR, V19, P1369
   Torrey L., 2009, HDB RES MACHINE LEAR, P242
   Visweswaran S, 2010, J MACH LEARN RES, V11, P3333
NR 35
TC 1
Z9 1
SN 0888-613X
EI 1873-4731
PD MAY
PY 2017
VL 84
BP 150
EP 158
DI 10.1016/j.ijar.2017.02.001
UT WOS:000400231600008
ER

PT J
AU Shoeleh, F
   Asadpour, M
AF Shoeleh, Farzaneh
   Asadpour, Masoud
TI Graph based skill acquisition and transfer Learning for continuous
   reinforcement learning domains
SO PATTERN RECOGNITION LETTERS
CT 10th IAPR-TC15 Workshop on Graph-Based Representations in Pattern
   Recognition (GbR)
CY MAY 13-15, 2015
CL Beijing, PEOPLES R CHINA
DE Reinforcement learning; Skill acquisition; Transfer learning; Graph
   learning
ID FRAMEWORK; ABSTRACTION
AB Since reinforcement learning algorithms suffer from the curse of dimensionality in continuous domains, generalization is the most challenging issue in this area. Both skill acquisition and transfer learning are successful techniques to overcome such problem that result in big improvements in agent learning performance. In this paper, we propose a novel graph based skill acquisition method, named GSL, and a skill based transfer learning framework, named STL. GSL discovers skills as high-level knowledge using community detection from connectivity graph, a model to capture not only the agent's experience but also the environment's dynamics. STL incorporates skills previously learned from source task to speed up learning on a new target task. The experimental results indicate the effectiveness of the proposed methods in dealing with continuous reinforcement learning problems. (C) 2016 Elsevier B.V. All rights reserved.
CR Aiello W, 2001, EXP MATH, V10, P53, DOI 10.1080/10586458.2001.10504428
   Asadi M., 2015, P INT C ART INT ICAI, V8, P22
   Asadi M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2054
   Barto A., 2009, ADV NEURAL INFORM PR, V22, P1015
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bohlin L., 2014, MEASURING SCHOLARLY
   Dabney W, 2012, 26 AAAI C ART INT, P872
   Dayan E, 2014, LEARN MEMORY, V21, P140, DOI 10.1101/lm.032417.113
   Fang M, 2015, PATTERN RECOGN LETT, V51, P101, DOI 10.1016/j.patrec.2014.08.011
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Konidaris G., 2011, P 25 C ART INT, P380
   Konidaris G., 2011, P ICML WORKSH NEW DE
   Konidaris G., 2011, THESIS
   Konidaris G., 2010, ADV IN NEURAL, P1
   Konidaris G, 2012, INT J ROBOT RES, V31, P360, DOI 10.1177/0278364911428653
   Lazaric A., 2011, ADV NEURAL INFORM PR, V24, P1746
   Lazaric A., 2008, P 25 INT C MACH LEAR, P544
   Lazaric A, 2012, ADAPT LEARN OPTIM, V12, P143
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1805, DOI 10.1109/TKDE.2013.97
   Mahadevan S, 2007, J MACH LEARN RES, V8, P2169
   Miller GL, 1997, J ACM, V44, P1, DOI 10.1145/256292.256294
   Moradi P, 2012, INTELL DATA ANAL, V16, P113, DOI 10.3233/IDA-2011-0513
   Moradi P, 2010, COMM COM INF SC, V120, P51
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shell J, 2015, INFORM SCIENCES, V293, P59, DOI 10.1016/j.ins.2014.09.004
   Sheskin D. J., 2007, HDB PARAMETRIC NONPA
   Simsek O, 2008, ADV NEURAL INFORM PR, V21, P1497, DOI DOI 10.1145/1102351.1102454
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Taghizadeh N, 2013, ROBOT AUTON SYST, V61, P821, DOI 10.1016/j.robot.2013.04.010
   Taylor ME, 2011, AI MAG, V32, P15, DOI 10.1609/aimag.v32i1.2329
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968
   Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149
   Zhang W., 2015, P 21 ACM SIGKDD INT, P1475
NR 35
TC 3
Z9 4
SN 0167-8655
EI 1872-7344
PD FEB 1
PY 2017
VL 87
SI SI
BP 104
EP 116
DI 10.1016/j.patrec.2016.08.009
UT WOS:000395616700014
ER

PT S
AU Devlin, J
   Bunel, R
   Singh, R
   Hausknecht, M
   Kohli, P
AF Devlin, Jacob
   Bunel, Rudy
   Singh, Rishabh
   Hausknecht, Matthew
   Kohli, Pushmeet
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Neural Program Meta-Induction
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB Most recently proposed methods for Neural Program Induction work under the assumption of having a large set of input/output (I/O) examples for learning any underlying input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a k-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language [17]. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance.
CR Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   Andrychowicz Marcin, 2016, CORR
   Cai Jonathon, 2017, ICLR
   Danihelka Ivo, 2016, ICML
   Devlin Jacob, 2017, CORR
   Duan Y., 2017, CORR
   Graves A., 2014, ARXIV14105401
   Grefenstette Edward, 2015, NIPS
   Gulwani Sumit, 2012, COMMUNICATIONS ACM
   Huh Mi-Young, 2016, CORR
   Joulin A, 2015, ADV NEURAL INFORM PR, P190
   Kurach K., 2016, ICLR
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Li Chengtao, 2017, ICLR
   Luong Minh-Thang, 2015, STANFORD NEURAL MACH
   Neelakantan Arvind, 2016, ICLR
   Pattis Richard E, 1981, KAREL ROBOT GENTLE I
   Reed SE, 2016, ICLR
   Santoro  A., 2016, P 33 INT C MACH LEAR, P1842
   Sukhbaatar S., 2015, NIPS
   Zaremba Wojciech, 2015, CORR
NR 21
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649402013
ER

PT S
AU Du, SS
   Koushik, J
   Singh, A
   Poczos, B
AF Du, Simon S.
   Koushik, Jayanth
   Singh, Aarti
   Poczos, Barnabas
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Hypothesis Transfer Learning via Transformation Functions
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB We consider the Hypothesis Transfer Learning (HTL) problem where one incorporates a hypothesis trained on the source domain into the learning procedure of the target domain. Existing theoretical analysis either only studies specific algorithms or only presents upper bounds on the generalization error but not on the excess risk. In this paper, we propose a unified algorithm-dependent framework for HTL through a novel notion of transformation function, which characterizes the relation between the source and the target domains. We conduct a general risk analysis of this framework and in particular, we show for the first time, if two domains are related, HTL enjoys faster convergence rates of excess risks for Kernel Smoothing and Kernel Ridge Regression than those of the classical non-transfer learning settings. Experiments on real world data demonstrate the effectiveness of our framework.
CR Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137, DOI DOI 10.1007/S10994-009-5152-4
   Ben-David Shai, 2013, NEW DIR TRANSF MULT
   Blitzer J., 2008, P ADV NEUR INF PROC, P129
   Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704
   Carroll R.J., 2006, MEASUREMENT ERROR NO
   Cortes C, 2014, THEOR COMPUT SCI, V519, P103, DOI 10.1016/j.tcs.2013.09.027
   Cortes C, 2011, LECT NOTES ARTIF INT, V6925, P308, DOI 10.1007/978-3-642-24412-4_25
   Cortes Corinna, 2015, INT C KNOWL DISC DAT, P169
   Craig CC, 1933, ANN MATH STAT, V4, P94, DOI 10.1214/aoms/1177732803
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   Kpotufe S., 2013, ADV NEURAL INFORM PR, V26, P3075
   Kuzborskij I., 2013, P 30 INT C MACH LEAR, P942
   Kuzborskij I, 2013, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2013.431
   Kuzborskij Ilja, 2016, COMPUTER VISION IMAG
   Kuzborskij Ilja, 2016, MACH LEARN, P1
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu T, 2016, IEEE INT POWER ELEC
   Mansour Y., 2009, ARXIV09023430
   Mohri Mehryar, 2012, Algorithmic Learning Theory. 23rd International Conference (ALT 2012). Proceedings, P124, DOI 10.1007/978-3-642-34106-9_13
   Nuske Stephen, 2014, FIELD SERVICE ROBOTI, P343
   Orabona Francesco, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P2897, DOI 10.1109/ROBOT.2009.5152247
   Rasmussen Carl Edward, 1996, DELVE DATA EVALUATIN
   Steinwart I., 2009, COLT
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/0096-3445.121.1.15
   Sugiyama M., 2008, ADV NEURAL INFORM PR, P1433
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Verstynen TD, 2014, J NEUROPHYSIOL, V112, P2457, DOI 10.1152/jn.00221.2014
   Vovk V., 2013, EMPIRICAL INFERENCE, P105, DOI DOI 10.1007/978-3-642-41136-6_11
   Wang  X., 2014, P ADV NEUR INF PROC, P1898
   Wang Xuezhi, 2016, 25 INT JOINT C ART I, V1, P2
   Wang Xuezhi, 2015, GEN BOUNDS TRANSFER
   Wasserman L., 2006, ALL NONPARAMETRIC ST
   Yang J., 2007, P 15 INT C MULT, P188, DOI DOI 10.1145/1291233.1291276
   Yu Y., 2012, ARXIV12064650
   Zhang L, 2013, PROCEEDINGS OF 2013 CHINA INTERNATIONAL CONFERENCE ON INSURANCE AND RISK MANAGEMENT, P819
   Zhang Yu, 2015, AAAI, V2, P6
   Zhou DX, 2008, J COMPUT APPL MATH, V220, P456, DOI 10.1016/j.cam.2007.08.023
NR 37
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649400055
ER

PT S
AU Killian, T
   Daulton, S
   Konidaris, G
   Doshi-Velez, F
AF Killian, Taylor
   Daulton, Samuel
   Konidaris, George
   Doshi-Velez, Finale
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Robust and Efficient Transfer Learning with Hidden Parameter Markov
   Decision Processes
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB We introduce a new formulation of the Hidden Parameter Markov Decision Process (HiP-MDP), a framework for modeling families of related tasks using low-dimensional latent embeddings. Our new framework correctly models the joint uncertainty in the latent parameters and the state space. We also replace the original Gaussian Process-based model with a Bayesian Neural Network, enabling more scalable inference. Thus, we expand the scope of the HiP-MDP to applications with higher dimensions and more complex dynamics.
CR Adams BM, 2004, MATH BIOSCI ENG, V1, P223
   Alvarez MA, 2012, FOUND TRENDS MACH LE, V4, P195, DOI 10.1561/2200000036
   Bai HY, 2013, IEEE INT CONF ROBOT, P2853, DOI 10.1109/ICRA.2013.6630972
   Blundell  C., 2015, P 32 INT C MACH LEAR, P1613
   Bonilla E. V., 2008, NIPS, P153
   Brunskill E, 2013, C UNC ART INT
   Caruana R, 1998, LEARNING TO LEARN, P95
   Chen M, 2016, IEEE INT CONF ROBOT, P5427, DOI 10.1109/ICRA.2016.7487754
   Delhaisse B, 2017, INT JOINT C NEUR NET
   Depeweg S, 2017, ARXIV170608495
   Depeweg S, 2017, INT C LEARN REPR
   Dietrich CR, 1997, SIAM J SCI COMPUT, V18, P1088, DOI 10.1137/S1064827592240555
   Doshi-Velez Finale, 2016, IJCAI (U S), V2016, P1432
   Ernst D, 2006, P 45 IEEE C DEC CONT
   Fern A, 2010, ADV NEURAL INFORM PR, P577
   Gal Y., 2016, P 33 INT C MACH LEAR
   Gal Y., 2016, DAT EFF MACH LEARN W
   Genton MG, 2015, STAT SCI, V30, P147, DOI 10.1214/14-STS487
   Gupta A, 2017, INT C LEARN REPR
   Hernandez-Lobato JM, 2016, P 33 INT C MACH LEAR
   Jaques  N., 2015, P NIPS WORKSH MULT M
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   Kendall Alex, 2017, ARXIV170304977
   Kingma D. P., 2015, INT C LEARN REPR
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448
   Marivate VN, 2014, WORKSH 28 AAAI C ART
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moerland TM, 2017, ARXIV170500470
   MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1007/BF00993104
   Moore BL, 2014, J MACH LEARN RES, V15, P655
   Neal RM, 1992, TECHNICAL REPORT
   Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939
   Rasmussen C., 2011, P INT C MACH LEARN
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rasmussen CE, 2003, ADV NEURAL INFORM PR, V15
   Rosman B, 2016, MACH LEARN, V104, P99, DOI 10.1007/s10994-016-5547-y
   Schaul T., 2016, INT C LEARN REPR
   Sehulam P, 2016, J MACH LEARN RES, V17
   Shortreed SM, 2011, MACH LEARN, V84, P109, DOI 10.1007/s10994-010-5229-0
   Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1257
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Tenenbaum M, 2010, WORKSH NIPS
   Van Hasselt H., 2016, AAAI, P2094
   Williams JD, 2006, AAAI WORKSH STAT EMP, P37
NR 45
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649406032
ER

PT S
AU Lee, SW
   Kim, JH
   Jun, J
   Ha, JW
   Zhang, BT
AF Lee, Sang-Woo
   Kim, Jin-Hwa
   Jun, Jaehyun
   Ha, Jung-Woo
   Zhang, Byoung-Tak
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Overcoming Catastrophic Forgetting by Incremental Moment Matching
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB Catastrophic forgetting is a problem of neural networks that loses the information of the first task after training the second task. Here, we propose a method, i.e. incremental moment matching (IMM), to resolve this problem. IMM incrementally matches the moment of the posterior distribution of the neural network which is trained on the first and the second task, respectively. To make the search space of posterior parameter smooth, the IMM procedure is complemented by various transfer learning techniques including weight transfer, L2-norm of the old and the new parameter, and a variant of dropout with the old parameter. We analyze our approach on a variety of datasets including the MNIST, CIFAR-10, Caltech-UCSDBirds, and Lifelog datasets. The experimental results show that IMM achieves state-of-the-art performance by balancing the information between an old and a new network.
CR Amendola Carlos, 2017, ARXIV170205066
   Baldi Pierre, 2013, ADV NEURAL INFORM PR, P2814
   Blundell  C., 2015, P 32 INT C MACH LEAR, P1613
   Broderick T., 2013, ADV NEURAL INFORM PR, P1727
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Fernando C., 2017, ARXIV170108734
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Ghahramani Z., 2000, NIPS WORKSH ONL LEAR
   Goldberger J, 2005, ADV NEURAL INFORM PR, P505
   Goodfellow I. J., 2013, ARXIV13126211
   Goodfellow Ian J, 2014, ARXIV14126544
   Huang Z, 2014, INTERSPEECH, P1214
   Huang Zhen, 2015, 16 ANN C INT SPEECH
   Kienzle W., 2006, P 23 INT C MACH LEAR, P457
   Kingma D.P., 2013, ARXIV13126114
   Kirkpatrick J., 2017, P NATL ACAD SCI
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lee S. W., 2016, P INT JOINT C ART IN, P1669
   Lee Sang- Woo, 2017, NEURAL NETWORKS
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Louizos C., 2016, ARXIV160304733
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448
   Mccloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P104, DOI DOI 10.1016/S0079-7421(08)60536-8
   Pascanu R, 2013, ARXIV13013584
   Pathak Manas, 2010, ADV NEURAL INFORM PR, P1876
   Rashwan A., 2016, P 19 INT C ART INT S, P1469
   Ray S, 2005, ANN STAT, V33, P2042, DOI 10.1214/00905360500000417
   Ray S, 2012, J MULTIVARIATE ANAL, V108, P41, DOI 10.1016/j.jmva.2012.02.006
   Rusu A. A., 2016, ARXIV160604671
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   SRIVASTAVA RK, 2013, ADV NEURAL INFORM PR, P2310
   Wah C., 2011, CNSTR2011001
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhang K, 2010, IEEE T NEURAL NETWOR, V21, P644, DOI 10.1109/TNN.2010.2040835
NR 34
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649404070
ER

PT S
AU Luo, ZL
   Zou, YL
   Hoffman, J
   Fei-Fei, L
AF Luo, Zelun
   Zou, Yuliang
   Hoffman, Judy
   Fei-Fei, Li
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Label Efficient Learning of Transferable Representations across Domains
   and Tasks
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB We propose a framework that learns a representation transferable across different domains and tasks in a label efficient manner. Our approach battles domain shift with a domain adversarial loss, and generalizes the embedding to novel task using a metric learning-based approach. Our model is simultaneously optimized on labeled source data and unlabeled or sparsely labeled data in the target domain. Our method shows compelling results on novel classes within a new domain even when only a few labeled examples per class are available, outperforming the prevalent fine-tuning approach. In addition, we demonstrate the effectiveness of our framework on the transfer learning task from image object recognition to video action recognition.
CR Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Bousmalis Konstantinos, 2016, ARXIV161205424
   Castrejon L, 2016, PROC CVPR IEEE, P2940, DOI 10.1109/CVPR.2016.321
   Csurka  G., 2017, ARXIV170205374
   de Sa V. R., 1994, ADV NEURAL INFORM PR, P112
   Deng J., 2009, CVPR09
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Donahue Jeff, 2016, ARXIV160509782
   Dumoulin V, 2016, ARXIV160600704
   Finn  C., 2017, ARXIV170303400
   Ganin Y, 2016, J MACH LEARN RES, V17
   Girshick  R., 2014, COMPUTER VISION PATT
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Grandvalet Y., 2004, NIPS, P529
   Gretton A, 2009, NEURAL INF PROCESS S, P131
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 1986, PARALLEL DISTRILMTED, V1
   Hoffman  J., 2016, ARXIV161202649
   Hoffman J, 2016, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2016.96
   Hoffman J, 2016, IEEE INT CONF ROBOT, P5032, DOI 10.1109/ICRA.2016.7487708
   Kalogeiton V, 2016, IEEE T PATTERN ANAL, V38, P2327, DOI 10.1109/TPAMI.2016.2551239
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Kingma D.P., 2013, ARXIV13126114
   Koch G, 2015, THESIS
   Krizhevsky Alex, 2012, NEURAL INFORM PROCES
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lempitsky Victor, 2014, ARXIV14097495
   Li Y., 2016, ARXIV160304779
   Lim J.J., 2011, ADV NEURAL INFORM PR, P118
   Liu M.-Y., 2016, ADV NEURAL INFORM PR, P469
   Liu  Ming-Yu, 2017, ARXIV170300848
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long M., 2016, ARXIV160506636
   Long M., 2016, ADV NEURAL INFORM PR, P136
   Long M., 2015, INT C MACH LEARN, P97
   Luo Zelun, 2017, ARXIV170101821
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, V2011, P5
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Palubinskas Gintautas, 1999, AAAI
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pathak D., 2016, ARXIV161206370
   Ravi Sachin, 2017, INT C LEARN REPR, V1, P6
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rozantsev  Artem, 2016, ARXIV160306432
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov R., 2009, ARTIF INTELL, V5, P1967, DOI DOI 10.1109/CVPRW.2009.5206577
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Simonyan K., 2014, ADV NEURAL INFORM PR, P568, DOI DOI 10.1109/ICCVW.2017.368
   Snell Jake, 2017, ARXIV170305175
   Soomro K., 2012, ARXIV12120402
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Taigman  Y., 2016, ARXIV161102200
   Tang  Kevin, 2012, ADV NEURAL INFORM PR, P638
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Tzeng E., 2014, ARXIV14123474
   Tzeng E., 2015, INT C COMP VIS ICCV
   Tzeng E., 2017, COMPUTER VISION PATT
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   van den Oord A., 2016, ADV NEURAL INFORM PR, P4790
   van den Oord Aaron, 2016, ARXIV160106759
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2012, MACH LEARN, V87, P33, DOI 10.1007/s10994-011-5273-4
   Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang X, 2015, ARXIV150300591
NR 73
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649400016
ER

PT S
AU Teh, YW
   Bapst, V
   Czarnecki, WM
   Quan, J
   Kirkpatrick, J
   Hadsell, R
   Heess, N
   Pascanu, R
AF Teh, Yee Whye
   Bapst, Victor
   Czarnecki, Wojciech Marian
   Quan, John
   Kirkpatrick, James
   Hadsell, Raia
   Heess, Nicolas
   Pascanu, Razvan
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Distral: Robust Multitask Reinforcement Learning
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB Most deep reinforcement learning algorithms are data inefficient in complex and rich environments, limiting their applicability to many scenarios. One direction for improving data efficiency is multitask learning with shared neural network parameters, where efficiency may be improved through transfer across related tasks. In practice, however, this is not usually observed, because gradients from different tasks can interfere negatively, making learning unstable and sometimes even less data efficient. Another issue is the different reward schemes between tasks, which can easily lead to one task dominating the learning of a shared model. We propose a new approach for joint training of multiple tasks, which we refer to as Distral (distill & transfer learning). Instead of sharing parameters between the different workers, we propose to share a "distilled" policy that captures common behaviour across tasks. Each worker is trained to solve its own task while constrained to stay close to the shared policy, while the shared policy is trained by distillation to be the centroid of all task policies. Both aspects of the learning process are derived by optimizing a joint objective function. We show that our approach supports efficient transfer on complex 3D environments, outperforming several related methods. Moreover, the proposed learning process is more robust to hyperparameter settings and more stable-attributes that are critical in deep reinforcement learning.
CR Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912
   Bengio Yoshua, 2012, JMLR WORKSH UNS TRAN
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Bucila Cristian, 2006, P INT C KNOWL DISC D
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Choromanska Anna E., 2015, ADV NEURAL INFORM PR
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Fox R., 2016, UNCERTAINTY ARTIFICI
   Fox Roy, 2016, EUR WORKSH REINF LEA
   Gelman A., 2014, BAYESIAN DATA ANAL, V2
   Haarnoja  T., 2017, ARXIV170208165
   Hinton G., 2014, NIPS DEEP LEARN WORK
   Jaderberg Max, 2016, INT C LEARN REPR ICL
   Kappen HJ, 2012, MACH LEARN, V87, P159, DOI 10.1007/s10994-012-5278-7
   Lample Guillaume, 2017, PLAYING FPS GAMES DE
   Levine  S., 2014, P 31 INT C MACH LEAR, P829
   Levine S., 2013, ADV NEURAL INFORM PR, P207
   Levine S., 2014, ADV NEURAL INFORM PR, P1071
   Levine S, 2016, J MACH LEARN RES, V17
   Mirowski Piotr, 2016, INT C LEARN REPR ICL
   Mnih  V., 2016, INT C MACH LEARN ICM
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nachum Ofir, 2017, ARXIV170208892
   Parisotto Emilio, 2016, INT C LEARN REPR ICL
   Pascanu Razvan, 2014, INT C LEARN REPR ICL
   Rawlik Konrad, 2012, ROBOTICS SCI SYSTEMS
   Rusu Andrei A, 2016, INT C LEARN REPR ICL
   Schaul  T., 2015, ABS151105952 CORR
   Schulman  J., 2015, INT C MACH LEARN ICM
   Schulman J., 2017, ARXIV170406440
   SUTTON R.S., 1999, NIPS, V99, P1057
   Taylor ME, 2011, AI MAG, V32, P15, DOI 10.1609/aimag.v32i1.2329
   Toussaint Marc, 2006, EDIINFRR0934 U ED SC
   van Hasselt Hado, 2016, DEEP REINFORCEMENT L
   Yosinski Jason, 2014, ADV NEURAL INFORM PR
NR 35
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649404055
ER

PT S
AU Wang, YX
   Ramanan, D
   Hebert, M
AF Wang, Yu-Xiong
   Ramanan, Deva
   Hebert, Martial
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Learning to Model the Tail
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB We describe an approach to learning from long-tailed, imbalanced datasets that are prevalent in real-world settings. Here, the challenge is to learn accurate "few-shot" models for classes in the tail of the class distribution, for which little data is available. We cast this problem as transfer learning, where knowledge from the data-rich classes in the head of the distribution is transferred to the data-poor classes in the tail. Our key insights are as follows. First, we propose to transfer meta-knowledge about learning-to-learn from the head classes. This knowledge is encoded with a meta-network that operates on the space of model parameters, that is trained to predict many-shot model parameters from few-shot model parameters. Second, we transfer this meta-knowledge in a progressive manner, from classes in the head to the "body", and from the "body" to the tail. That is, we transfer knowledge in a gradual fashion, regularizing meta-networks for few-shot regression with those trained with more training data. This allows our final network to capture a notion of model dynamics, that predicts how model parameters are likely to change as more training data is gradually added. We demonstrate results on image classification datasets (SUN, Places, and ImageNet) tuned for the long-tailed setting, that significantly outperform common heuristics, such as data resampling or reweighting.
CR Agrawal P., 2014, ECCV
   Andrychowicz M., 2016, NIPS
   Ba J. Lei, 2015, ICCV
   Bengio S., 2015, ICMI
   Bertinetto L., 2016, NIPS
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Donahue J., 2014, ICML
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Finn C., 2017, ICML
   Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441
   George D, 2017, SCIENCE, V358, DOI 10.1126/science.aag2612
   Girshick R., 2017, ICCV
   Ha D., 2017, ICLR
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He  K., 2016, ECCV
   He K., 2016, CVPR
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang C., 2016, CVPR
   Huh M., 2016, NIPS WORKSH
   Jia Y., 2014, ACM MM
   Koch G., 2015, ICML WORKSH
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky  A., 2012, NIPS
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li K., 2017, ICLR
   Li Z., 2016, ECCV
   Lin T.-Y., 2014, ECCV
   Munkhdalai T., 2017, ICML
   Noh Hyeonwoo, 2016, CVPR
   Ouyang W., 2016, CVPR
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ravi S., 2017, ICLR
   Rebuffi S.-A., 2017, NIPS
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santoro A, 2016, ICML
   Schmidhuber J, 1997, MACH LEARN, V28, P105, DOI 10.1023/A:1007383707642
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P131, DOI 10.1162/neco.1992.4.1.131
   SCHMIDHUBER J, 1987, THESIS
   Schmidhuber J., 1993, IEEE INT C NEUR NETW
   Shen L., 2016, ECCV
   Simonyan K., 2015, ICLR
   Sinha A., 2017, ICLR
   Snell J., 2017, NIPS
   Socher R., 2013, NIPS
   Sun C., 2017, ICCV
   Szegedy C., 2015, CVPR
   Thrun S., 2012, LEARNING LEARN
   Triantafillou E., 2017, NIPS
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Horn G., 2017, ARXIV170901450
   Vinyals O., 2016, NIPS
   Wang Y., 2017, CVPR
   Wang Y.-X., 2016, ECCV
   Wang Y.-X., 2016, AAAI
   Wang Y.-X., 2016, NIPS
   Wang Y.-X., 2015, CVPR
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   Yosinski J., 2014, NIPS
   Zhong Q., 2016, CVPR WORKSH
   Zhou B., 2017, TPAMI
   Zhu X., 2014, CVPR
   Zhu XX, 2016, INT J COMPUT VISION, V119, P76, DOI 10.1007/s11263-015-0812-2
NR 64
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649407012
ER

PT S
AU Zhao, J
   Xiong, L
   Jayashree, K
   Li, JS
   Zhao, F
   Wang, ZC
   Pranata, S
   Shen, SM
   Yan, SC
   Feng, JS
AF Zhao, Jian
   Xiong, Lin
   Jayashree, Karlekar
   Li, Jianshu
   Zhao, Fang
   Wang, Zhecan
   Pranata, Sugiri
   Shen, Shengmei
   Yan, Shuicheng
   Feng, Jiashi
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face
   Synthesis
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
CT 31st Conference on Neural Information Processing Systems (NIPS)
CY 2017
CL Long Beach, CA
AB Synthesizing realistic profile faces is promising for more efficiently training deep pose-invariant models for large-scale unconstrained face recognition, by populating samples with extreme poses and avoiding tedious annotations. However, learning from synthetic faces may not achieve the desired performance due to the discrepancy between distributions of the synthetic and real face images. To narrow this gap, we propose a Dual-Agent Generative Adversarial Network (DA-GAN) model, which can improve the realism of a face simulator's output using unlabeled real faces, while preserving the identity information during the realism refinement. The dual agents are specifically designed for distinguishing real v.s. fake and identities simultaneously. In particular, we employ an off-the-shelf 3D face model as a simulator to generate profile face images with varying poses. DA-GAN leverages a fully convolutional network as the generator to generate high-resolution images and an auto-encoder as the discriminator with the dual agents. Besides the novel architecture, we make several key modifications to the standard GAN to preserve pose and texture, preserve identity and stabilize training process: (i) a pose perception loss; (ii) an identity perception loss; (iii) an adversarial loss with a boundary equilibrium regularization term. Experimental results show that DA-GAN not only presents compelling perceptual results but also significantly outperforms state-of-the-arts on the large-scale and challenging NIST IJB-A unconstrained face recognition benchmark. In addition, the proposed DA-GAN is also promising as a new approach for solving generic transfer learning problems more effectively. DA-GAN is the foundation of our submissions to NIST IJB-A 2017 face recognition competitions, where we won the 1st places on the tracks of verification and identification.
CR Abdalmageed  W., 2016, 2016 IEEE WINT C APP, P1
   Berthelot  David, 2017, ARXIV170310717
   Chen J, 2015, IEEE ICC, P1801, DOI 10.1109/ICC.2015.7248586
   Chen  X., 2016, ADV NEURAL INFORM PR, P2172
   Chen J. P., 2016, 2016 Compound Semiconductor Week (CSW) [includes 28th International Conference on Indium Phosphide & Related Materials (IPRM) and 43rd International Symposium on Compound Semiconductors (ISCS)], P1, DOI [10.1109/ICCE-TW.2016.7520909, 10.1109/ICIPRM.2016.7528763]
   Chowdhury Animesh R., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534285
   Crosswhite N., 2016, ARXIV160303958
   Gong K., 2017, ARXIV170305446
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Hassner T., 2016, P IEEE C COMP VIS PA, P59
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Huang R, 2017, ARXIV170404086
   Kingma D.P., 2013, ARXIV13126114
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Li JH, 2016, P IEEE RAS-EMBS INT, P1068, DOI 10.1109/BIOROB.2016.7523773
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Masi I, 2016, ARXIV160307057
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Mirza M., 2014, ARXIV14111784, DOI DOI 10.1029/2009WR008312
   Odena A., 2016, ARXIV161009585
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Ranjan R., 2016, ARXIV161100851
   Ranjan R., 2017, ARXIV170309507
   Rezende D. J., 2014, ARXIV14014082
   Sankaranarayanan S., 2016, BIOM THEOR APPL SYST, P1, DOI DOI 10.1145/2910674.2910680
   Shrivastava A., 2016, ARXIV161207828
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang D., 2015, ARXIV150707242
   Xiao S., 2016, P ACM C MULT ACM MM, P691
   Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4
   Xie S., 2016, ARXIV161105431
   Yang J., 2016, ARXIV160305474
   Zhu X., 2015, 2015 11 IEEE INT C W, V1, P1
NR 34
TC 0
Z9 0
SN 1049-5258
PY 2017
VL 30
UT WOS:000452649400007
ER

PT S
AU Simoes, D
   Lau, N
   Reis, LP
AF Simoes, David
   Lau, Nuno
   Reis, Luis Paulo
BE Oliveira, E
   Gama, J
   Vale, Z
   Cardoso, HL
TI Multi-agent Double Deep Q-Networks
SO PROGRESS IN ARTIFICIAL INTELLIGENCE (EPIA 2017)
SE Lecture Notes in Artificial Intelligence
CT 18th EPIA Conference on Artificial Intelligence (EPIA)
CY SEP 05-08, 2017
CL Univ Porto, Fac Engn, Porto, PORTUGAL
HO Univ Porto, Fac Engn
AB There are many open issues and challenges in the multi-agent reward-based learning field. Theoretical convergence guarantees are lost, and the complexity of the action-space is also exponential to the amount of agents calculating their optimal joint-action. Function approximators, such as deep neural networks, have successfully been used in singleagent environments with high dimensional state-spaces. We propose the Multi-agent Double Deep Q-Networks algorithm, an extension of Deep Q-Networks to the multi-agent paradigm. Two common techniques of multi-agent Q-learning are used to formally describe our proposal, and are tested in a Foraging Task and a Pursuit Game. We also demonstrate how they can generalize to similar tasks and to larger teams, due to the strength of deep-learning techniques, and their viability for transfer learning approaches. With only a small fraction of the initial task's training, we adapt to longer tasks, and we accelerate the task completion by increasing the team size, thus empirically demonstrating a solution to the complexity issues of the multi-agent field.
RI Reis, Luis Paulo/M-3202-2013; Lau, Nuno/E-5934-2010
OI Reis, Luis Paulo/0000-0002-4709-1718; Lau, Nuno/0000-0003-0513-158X
CR Becker R., 2003, P 2 INT JOINT C AUT, P41
   Busoniu L, 2008, IEEE T SYST MAN CY C, V38, P156, DOI 10.1109/TSMCC.2007.913919
   Claus C, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P746
   Egorov M., 2016, TECHNICAL REPORT
   Foerster J. N., 2016, ABS160202672 CORR
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Kapetanakis S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P326
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Lau N., 2007, FC PORTUGAL HIGH LEV
   Lauer M., 2000, P 17 INT C MACH LEAR, P535
   Mnih V., 2013, ARXIV, V1312, P5602, DOI DOI 10.1038/NATURE14236
   Nair R., 2003, P 18 INT JOINT C ART, P705
   Reis L. P., 2001, Balancing reactivity and social deliberation in multi-agent systems. From RoboCup to real-world applications, P175
   Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299
   Stone P., 2000, INTEL ROB AUTON AGEN
   Tampuu A., 2015, ABS151108779 CORR
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   van Hasselt H, 2015, ABS150906461 CORR
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
NR 19
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-65340-2; 978-3-319-65339-6
PY 2017
VL 10423
BP 123
EP 134
DI 10.1007/978-3-319-65340-2_11
UT WOS:000452455800011
ER

PT S
AU Ni, WJ
   Liu, T
   Sun, HH
   Wei, ZS
AF Ni, Weijian
   Liu, Tong
   Sun, Haohao
   Wei, Zhensheng
BE Chen, L
   Jensen, CS
   Shahabi, C
   Yang, X
   Lian, X
TI An Active Learning Approach to Recognizing Domain-Specific Queries From
   Query Log
SO WEB AND BIG DATA, APWEB-WAIM 2017, PT II
SE Lecture Notes in Computer Science
CT 1st Asia-Pacific Web (APWeb) and Web-Age Information Management (WAIM)
   Joint International Conference on Web and Big Data
CY JUL 07-09, 2017
CL Beijing, PEOPLES R CHINA
DE Query classification; Active learning; Transfer learning; Search engine;
   Query log
AB In this paper, we address the problem of recognizing domain-specific queries from general search engine's query log. Unlike most previous work in query classification relying on external resources or annotated training queries, we take query log as the only resource for recognizing domain-specific queries. In the proposed approach, we represent query log as a heterogeneous graph and then formulate the task of domain-specific query recognition as graph-based transductive learning. In order to reduce the impact of noisy and insufficient of initial annotated queries, we further introduce an active learning strategy into the learning process such that the manual annotations needed are reduced and the recognition results can be continuously refined through interactive human supervision. Experimental results demonstrate that the proposed approach is capable of recognizing a certain amount of high-quality domain-specific queries with only a small number of manually annotated queries.
CR Arguello J, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P315, DOI 10.1145/1571941.1571997
   Fuxman A., 2008, P 17 INT C WORLD WID, P61, DOI [10.1145/1367497.1367506, DOI 10.1145/1367497.1367506]
   Giachanou A, 2015, INFORM RETRIEVAL J, V18, P559, DOI 10.1007/s10791-015-9270-2
   Gu Q., 2014, P 30 C UNC ART INT, P300
   JI M., 2011, SIGIR, P55
   Ji M., 2012, J MACHINE LEARNING R, P556
   Jiang D, 2016, WORLD WIDE WEB, V19, P475, DOI 10.1007/s11280-015-0336-2
   Lee U., 2005, P 14 INT C WORLD WID, P391, DOI DOI 10.1145/1060745.1060804
   Li X., 2008, P 31 ANN INT ACM SIG, P339
   Li Y., 2013, CIKM, P2029
   Qian Y., 2013, P 22 ACM INT C INF K, P1205
   Ren X., 2014, P 7 ACM INT C WEB SE, P23
   Shen D, 2006, ACM T INFORM SYST, V24, P320, DOI 10.1145/1165774.1165776
   Shi LX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089109
   Yan Xing-long, 2013, Journal of Software, V24, P2089, DOI 10.3724/SP.J.1001.2013.04358
   Yunhua Hu, 2012, Proceedings of the 35th Annual International ACM SIGIR Conference on Research & Development in Information Retrieval (SIGIR 2012), P305, DOI 10.1145/2348283.2348327
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X., 2003, ICML 2003 WORKSH CON
NR 18
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-63564-4; 978-3-319-63563-7
PY 2017
VL 10367
BP 18
EP 32
DI 10.1007/978-3-319-63564-4_2
PN II
UT WOS:000452448300002
ER

PT S
AU Devi, VS
   Padmanabhan, V
   Pujari, AK
AF Devi, V. Sowmini
   Padmanabhan, Vineet
   Pujari, Arun K.
BE Shankar, BU
   Ghosh, K
   Mandal, DP
   Ray, SS
   Zhang, D
   Pal, SK
TI A Matrix Factorization & Clustering Based Approach for Transfer Learning
SO PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PREMI 2017
SE Lecture Notes in Computer Science
CT 7th International Conference on Pattern Recognition and Machine
   Intelligence (PReMI)
CY DEC 05-08, 2017
CL Indian Stat Inst, Kolkata, INDIA
HO Indian Stat Inst
AB Recommender systems that make use of collaborative filtering tend to suffer from data sparsity as the number of items rated by the users are very small as compared to the very large item space. In order to alleviate it, recently transfer learning (TL) methods have seen a growing interest wherein data is considered from multiple domains so that ratings from the first (source) domain can be used to improve the prediction accuracy in the second (target) domain. In this paper, we propose a model for transfer learning in collaborative filtering wherein the latent factor model for the source domain is obtained through Matrix Factorization (MF). User and Item matrices are combined in a novel way to generate cluster level rating pattern and a Code Book Transfer (CBT) is used for transfer of information from source to the target domain. Results from experiments using benchmark datasets show that our model approximates the target matrix well.
OI PUJARI, ARUN/0000-0003-2482-8948
CR Anil KJ, 1988, ALGORITHMS CLUSTERIN
   Devi VS, 2014, IEEE SYS MAN CYBERN, P569, DOI 10.1109/SMC.2014.6973968
   Ji K, 2016, NEUROCOMPUTING, V173, P912, DOI 10.1016/j.neucom.2015.08.046
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li B, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2052
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan WK, 2010, PROCEEDINGS OF THE TWENTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-10), P230
   Rennie J., 2005, P 22 INT C MACH LEAR, P713, DOI 10.1145/1102351.1102441
   Rosenstein M. T., 2005, NIPS 2005 WORKSH TRA, V898
   Ruslan S, 2007, NIPS, V1
   Srebro N., 2004, ADV NEURAL INFORM PR, V17, P1329
   Wu M, 2007, P KDD CUP WORKSH, V2007
NR 13
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-69900-4; 978-3-319-69899-1
PY 2017
VL 10597
BP 77
EP 83
DI 10.1007/978-3-319-69900-4_10
UT WOS:000450772100010
ER

PT S
AU Ullah, I
   Petrosino, A
AF Ullah, Ihsan
   Petrosino, Alfredo
BE Shankar, BU
   Ghosh, K
   Mandal, DP
   Ray, SS
   Zhang, D
   Pal, SK
TI A Spatio-temporal Feature Learning Approach for Dynamic Scene
   Recognition
SO PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PREMI 2017
SE Lecture Notes in Computer Science
CT 7th International Conference on Pattern Recognition and Machine
   Intelligence (PReMI)
CY DEC 05-08, 2017
CL Indian Stat Inst, Kolkata, INDIA
HO Indian Stat Inst
ID PYRAMIDAL NEURAL-NETWORK
AB The dynamic scene in a video comprises of a specific spatio-temporal pattern. A mask can learn the features efficiently compared to a sliding kernel approach as in a convolutional neural network that shrinks many parameters with respect to non-sliding or fully connected neural networks. In this paper, 3DPyraNet-F a discriminative approach of spatio-temporal feature learning is proposed for dynamic scene recognition. It performs transfer learning by considering the highest layer of the learned network structure and combines it with a linear-SVM classifier, in a way that enhances dynamic scenes in videos. Encouraging results are achieved despite the lower computational cost, fewer parameters, and camera-induced motion. It outperforms the state-of-the-art for MaryLand-in-the-wild and shows a comparable result for YUPPEN dataset.
OI Petrosino, Alfredo/0000-0002-8736-1997; Ullah, Ihsan/0000-0002-7964-5199
CR BEIL W, 1994, PATTERN RECOGN LETT, V15, P453, DOI 10.1016/0167-8655(94)90136-8
   Cantoni V, 2002, IEEE T NEURAL NETWOR, V13, P472, DOI 10.1109/72.991433
   Chen L. C, 2015, SEMANTIC IMAGE SEGME
   Feichtenhofer C., 2013, BMVC
   Feichtenhofer C., 2016, COMPUTER VISION PATT, P1
   Feichtenhofer C, 2014, PROC CVPR IEEE, P2681, DOI 10.1109/CVPR.2014.343
   Fernandes BJT, 2013, IEEE T CYBERNETICS, V43, P2082, DOI 10.1109/TCYB.2013.2240295
   Han Song, 2015, CORR
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lazebnik  S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68
   Liu Weifeng, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P502, DOI 10.1007/978-3-319-14442-9_55
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pang Y, 2016, IEEE T CYBERNETICS, P1
   Phung SL, 2007, IEEE T NEURAL NETWOR, V18, P329, DOI 10.1109/TNN.2006.884677
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Theriault C, 2013, PROC CVPR IEEE, P2603, DOI 10.1109/CVPR.2013.336
   Tran D., 2015, ICCV
   Ullah I, 2016, LECT NOTES COMPUT SC, V10016, P638, DOI 10.1007/978-3-319-48680-2_56
   Ullah I, 2015, LECT NOTES COMPUT SC, V9279, P236, DOI 10.1007/978-3-319-23231-7_22
   Wang P, 2016, IEEE TCSVT, P1
NR 22
TC 1
Z9 1
SN 0302-9743
EI 1611-3349
BN 978-3-319-69900-4; 978-3-319-69899-1
PY 2017
VL 10597
BP 591
EP 598
DI 10.1007/978-3-319-69900-4_75
UT WOS:000450772100075
ER

PT S
AU Sarker, MMK
   Leyva, M
   Saleh, A
   Singh, VK
   Akram, F
   Radeva, P
   Puig, D
AF Kamal Sarker, Md. Mostafa
   Leyva, Maria
   Saleh, Adel
   Kumar Singh, Vivek
   Akram, Farhan
   Radeva, Petia
   Puig, Domenec
BE Aguilo, I
   Alquezar, R
   Angulo, C
   Ortiz, A
   Torrens, J
TI FoodPlaces: Learning Deep Features for Food Related Scene Understanding
SO RECENT ADVANCES IN ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT
SE Frontiers in Artificial Intelligence and Applications
CT 20th International Conference of the
   Catalan-Association-for-Artificial-Intelligence
CY OCT 25-27, 2017
CL Deltebre, SPAIN
DE Scene understanding; food related scene classification; fine-tuning;
   convolutional neural networks
AB In human smart nutrition systems, environment based food classification has become popular to help analyzing the food intake based on the nutrition related activity. In this paper, we address the problem of food related environments, which refer to different eating places such as, bars, restaurants, coffee shops, etc. using state-of-the-art convolutional neural networks (CNNs). We collected a new dataset on different food related environments by integrating three publicly available datasets: Places365, ImageNet and SUN397. We have named it "FoodPlaces" and it contains 35 different types of classes. In order to achieve satisfactory results on the food related environment recognition, we fine-tuned several state-of-the-art CNNs, such as VGG16, RsNet50 and InceptionV3 using different transfer learning approaches. The results show that the fully fine-tunned InceptionV3 yields 75.22% classification accuracy among the discussed state-of-the-art CNNs.
RI Akram, Farhan/P-3092-2016
OI Akram, Farhan/0000-0003-4109-2645
CR Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chollet F., 2015, KERAS DEEP LEARNING
   Dohan M, 2011, INT J HEALTHC INF SY, V6, P60, DOI 10.4018/jhisi.2011040105
   He K., 2015, ARXIV151203385, P2357
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu C, 2016, LECT NOTES COMPUT SC, V9677, P37, DOI 10.1007/978-3-319-39601-9_4
   Matsuda Y, 2012, INT C PATT RECOG, P2017
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Noronha Jon, 2011, P 24 ANN ACM S US IN, P1, DOI 10.1145/2047196.2047198
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Simonyan K., 2014, ARXIV14091556
   Sutskever I., 2013, P 30 INT C MACH LEAR, P1139
   Szegedy C, 2015, ARXIV151200567
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Zeiler M. D., 2012, ARXIV12125701
   Zhang Weiyu, 2015, J Diabetes Sci Technol, V9, P525, DOI 10.1177/1932296815582222
   Zhou B., 2016, ARXIV161002055
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 22
TC 0
Z9 0
SN 0922-6389
EI 1879-8314
BN 978-1-61499-806-8; 978-1-61499-805-1
PY 2017
VL 300
BP 156
EP 165
DI 10.3233/978-1-61499-806-8-156
UT WOS:000450895400019
ER

PT S
AU Hajinoroozi, M
   Mao, ZJ
   Lin, YP
   Huang, YF
AF Hajinoroozi, Mehdi
   Mao, Zijing
   Lin, Yuan-Pin
   Huang, Yufei
BE Schmorrow, DD
   Fidopiastis, CM
TI Deep Transfer Learning for Cross-subject and Cross-experiment Prediction
   of Image Rapid Serial Visual Presentation Events from EEG Data
SO AUGMENTED COGNITION: NEUROCOGNITION AND MACHINE LEARNING, AC 2017, PT I
SE Lecture Notes in Artificial Intelligence
CT 11th International Conference on Universal Access in Human-Computer
   Interaction (UAHCI) held as part of 19th International Conference on
   Human-Computer Interaction (HCI International)
CY JUL 09-14, 2017
CL Vancouver, CANADA
DE Transfer learning; Deep convolutional neural networks; EEG signals
ID CLASSIFICATION
AB Transfer learning (TL) has gained significant interests recently in brain computer interface (BCI) as a key approach to design robust predictors for cross-subject and cross-experiment prediction of the brain activities in response to cognitive events. We carried out in this.aper the first comprehensive investigation of the transferability of deep convolutional neural network (CNN) for cross-subject and cross-experiment prediction of image Rapid Serial Visual Presentation (RSVP) events. We show that for both cross-subject and cross-experiment predictions, all convolutional layers and fully connected layers contain both general and subject/experiment-specific features and transfer learning with weights fine-tuning can improve the prediction performance over that without transfer. However, for cross-subject prediction, the convolutional layers capture more subject-specific features, whereas for cross-experiment prediction, the convolutional layers capture more general features across experiment. Our study provides important information that will guide the design of more sophisticated deep transfer learning algorithms for EEG based classifications in BCI applications.
CR Aytar Y, 2011, 2011 IEEE INT C COMP
   Azizpour H, 2015, IEEE COMPUT SOC CONF
   Bigdely-Shamlo N, 2008, IEEE T NEUR SYS REH, V16, P432, DOI 10.1109/TNSRE.2008.2003381
   Cecotti H, 2014, IEEE T NEUR NET LEAR, V25, P2030, DOI 10.1109/TNNLS.2014.2302898
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Donahue J., 2013, ARXIV13101531
   Hajinoroozi M, 2015, IEEE 6 INT WORKSH CO
   Hajinoroozi M, 2016, SIGNAL PROCESS IMAGE
   Hajinoroozi M, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P812, DOI 10.1109/ChinaSIP.2015.7230517
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Krizhevsky A., 2012, ADV NEURAL INFORM PR
   Lei X, 2009, IEEE T NEUR SYS REH, V17, P521, DOI 10.1109/TNSRE.2009.2027705
   Li X., 2007, THESIS
   Mirowski P. W, 2008, IEEE WORKSH MACH LEA
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel A. B., 2015, ARXIV150400641
   Rivet B, 2009, IEEE T BIO-MED ENG, V56, P2035, DOI 10.1109/TBME.2009.2012869
   Shao L, 2014, TRANSFER LEARNING VI
   Touryan Jon, 2013, Foundations of Augmented Cognition. 7th International Conference, AC 2013. Held as Part of HCI International 2013. Proceedings, P521, DOI 10.1007/978-3-642-39454-6_56
   Touryan J, 2015, USING NEUROPHYSIOLOG, P268
   U. S. Department of the Army, 1990, 7025 AR US DEP ARM
   Yang J., 2007, ICDM WORKSH 2007
   Yosinski Jason, 2014, ADV NEURAL INFORM PR
NR 24
TC 1
Z9 1
SN 0302-9743
EI 1611-3349
BN 978-3-319-58628-1; 978-3-319-58627-4
PY 2017
VL 10284
BP 45
EP 55
DI 10.1007/978-3-319-58628-1_4
PN I
UT WOS:000449655200004
ER

PT S
AU Aghaebrahimian, A
AF Aghaebrahimian, Ahmad
BE Ekstein, K
   Matousek, V
TI Constrained Deep Answer Sentence Selection
SO TEXT, SPEECH, AND DIALOGUE, TSD 2017
SE Lecture Notes in Artificial Intelligence
CT 20th International Conference on Text, Speech, and Dialogue (TSD)
CY AUG 27-31, 2017
CL Charles Univ, Fac Math & Phys, Prague, CZECH REPUBLIC
HO Charles Univ, Fac Math & Phys
DE Deep neural network; Sentence selection; Transfer learning
AB In this paper, we propose Constrained Deep Neural Network (CDNN) a simple deep neural model for answer sentence selection. CDNN makes its predictions based on neural reasoning compound with some symbolic constraints. It integrates pattern matching technique into sentence vector learning. When trained using enough samples, CDNN outperforms regular models. We show how using other sources of training data as a mean of transfer learning can enhance the performance of the network. In a well-studied dataset for answer sentence selection, our network improves the state of the art in answer sentence selection significantly.
OI Aghaebrahimian, Ahmad/0000-0003-0480-2505
CR Aghaebrahimian A, 2016, P WORKSH HUM COMP QU
   Aghaebrahimian A, 2016, LECT NOTES ARTIF INT, V9924, P28, DOI 10.1007/978-3-319-45510-5_4
   Bordes A., 2015, ARXIV150602075
   Chen Kai, 2013, P WORKSH ICLR
   Clarke J., 2010, P C COMPUTATIONAL NA
   Feng M., 2015, P IEEE ASRU WORKSH
   He H., 2015, P C EMP METH NAT LAN
   Hermann KM, 2015, ADV NEURAL INFORM PR
   Kadlec R., 2014, 2014 IEEE SPOK LANG
   Khashabi D., 2016, P INT JOINT C ART IN
   Kingma D., 2014, ARXIV14126980
   Kwiatkowski T., 2010, P C EMP METH NAT LAN
   Lin J, 2016, N AM ASS COMPUTATION
   Madnani N., 2012, P 2012 C N AM ASS CO
   Min S., 2017, ARXIV170202171
   Pennington J., 2014, P EMP METH NAT LANG
   Rajpurkar P, 2016, ARXIV160605250
   Rao Jinfeng, 2016, P 25 ACM INT C INF K
   Santos C., 2016, ARXIV160203609
   Stevenson M., 2008, P 11 ANN RES C UK SP
   Tellex S., 2003, SIGIR
   Xu Wei, 2014, T ASS COMPUT LINGUIS, V2, P435
   Yang Y., 2015, P C EMP METH NAT LAN
   Yao X., 2014, P ASS COMP LING
   Yao Xuchen, 2013, HLT NAACL
   Yih W. T., 2013, P ASS COMP LING ACL
   Yin  W., 2015, ARXIV151205193
   Yu L., 2014, NIPS DEEP LEARN WORK
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 29
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-64206-2; 978-3-319-64205-5
PY 2017
VL 10415
BP 57
EP 65
DI 10.1007/978-3-319-64206-2_7
UT WOS:000449869200007
ER

PT S
AU Liu, JH
   Sun, CJ
   Qin, B
AF Liu, Jiahao
   Sun, Chengjie
   Qin, Bing
BE Sun, M
   Wang, X
   Chang, B
   Xiong, D
TI Deep Learning Based Document Theme Analysis for Composition Generation
SO CHINESE COMPUTATIONAL LINGUISTICS AND NATURAL LANGUAGE PROCESSING BASED
   ON NATURALLY ANNOTATED BIG DATA, CCL 2017
SE Lecture Notes in Artificial Intelligence
CT 16th China National Conference on Computational Linguistics (CCL) / 5th
   International Symposium on Natural Language Processing Based on
   Naturally Annotated Big Data (NLP-NABD)
CY OCT 13-15, 2017
CL Nanjing Normal Univ, Nanjing, PEOPLES R CHINA
HO Nanjing Normal Univ
DE Theme analysis; Deep learning; Transfer learning
AB This paper puts forward theme analysis problem in order to automatically solve composition writing questions in Chinese college entrance examination. Theme analysis is to distillate the embedded semantic information from the given materials or documents. We proposes a hierarchical neural network framework to address this problem. Two deep learning based models under the proposed framework are presented. Besides, two transfer learning strategies based on the proposed deep learning models are tried to deal with the lack of large training data for composition theme analysis problems. Experimental results on two tag recommendation data sets show the effect of the proposed deep learning based theme analysis models. Also, we show the effect of the proposed model with transfer learning on a composition writing questions data set built by ourself.
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Blunsom  P., 2014, ACL
   Cheng G., 2016, P 25 INT JOINT C ART, V16, P2479
   Cho K., 2014, ARXIV14061078, P1724, DOI DOI 10.3115/V1/D14-1179
   Kim  Y., 2014, P 2014 C EMP METH NA, P1746, DOI DOI 10.3115/V1/D14-1181
   Konstas I, 2013, J ARTIF INTELL RES, V48, P305, DOI 10.1613/jair.4025
   Liang P., 2009, P JOINT C 47 ANN M A, P91
   Liu Z., 2011, P C EMP METH NAT LAN, P1577
   Meng R, 2017, ACL 2017
   Mihalcea R., 2004, P EMNLP, P404
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Schmidhuber J., 2015, CORR
   Si XC, 2010, IEEE INTELL SYST, V25, P42, DOI 10.1109/MIS.2010.148
   Sigurbjornsson Borkur, 2008, P 17 INT C WORLD WID, P327, DOI DOI 10.1145/1367497.1367542
   Uchimoto K, 2002, 19 INT C COMP LING C
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler M. D., 2012, CORR
   Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119
NR 19
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-69005-6; 978-3-319-69004-9
PY 2017
VL 10565
BP 333
EP 342
DI 10.1007/978-3-319-69005-6_28
UT WOS:000449848300028
ER

PT S
AU Wang, SQ
   Shen, YY
   Chen, W
   Xiao, TF
   Hu, JX
AF Wang, Shuqiang
   Shen, Yanyan
   Chen, Wei
   Xiao, Tengfei
   Hu, Jinxing
BE Lintas, A
   Rovetta, S
   Verschure, PFMJ
   Villa, AEP
TI Automatic Recognition of Mild Cognitive Impairment from MRI Images Using
   Expedited Convolutional Neural Networks
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2017, PT I
SE Lecture Notes in Computer Science
CT 26th International Conference on Artificial Neural Networks (ICANN)
CY SEP 11-14, 2017
CL Alghero, ITALY
DE Expedited convolutional neural network; Mild cognitive impairment;
   Tucker decomposition; Magnetic resonance imaging
ID ALZHEIMERS-DISEASE; CLASSIFICATION; STANDARDIZATION; CONSORTIUM
AB Few studies have focused on the potential of applying deep learning algorithms into magnetic resonance imaging (MRI) for automatic recognition of subjects with mild cognitive impairment (MCI). In this work, we propose the expedited convolutional neural networks involving Tucker decomposition to recognize MCI using MRI images. We employ transfer learning and data augmentation to deal with limited training data. The effect of Tucker decomposition on saving computational time is discussed. The experimental results show that the proposed model outperforms the previous methods. The expedited convolutional neural networks can provide a good guidance for the applications of deep learning in real-world classification with large training dataset.
CR Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Bastien F, 2012, ARXIV12115590
   Bischkopf J, 2002, ACTA PSYCHIAT SCAND, V106, P403, DOI 10.1034/j.1600-0447.2002.01417.x
   Ciodaro T, 2012, J PHYS CONF SER, V368, DOI 10.1088/1742-6596/368/1/012030
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu X, 2013, NEUROIMAGE, V83, P148, DOI 10.1016/j.neuroimage.2013.06.033
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   MIRRA SS, 1991, NEUROLOGY, V41, P479, DOI 10.1212/WNL.41.4.479
   Reese LC, 2011, J NEUROCHEM, V119, P791, DOI 10.1111/j.1471-4159.2011.07447.x
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881
   Wee CY, 2013, HUM BRAIN MAPP, V34, P3411, DOI 10.1002/hbm.22156
   Wolz R, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025446
   Wyman BT, 2013, ALZHEIMERS DEMENT, V9, P332, DOI 10.1016/j.jalz.2012.06.004
NR 22
TC 3
Z9 3
SN 0302-9743
EI 1611-3349
BN 978-3-319-68600-4; 978-3-319-68599-1
PY 2017
VL 10613
BP 373
EP 380
DI 10.1007/978-3-319-68600-4_43
PN I
UT WOS:000449802500043
ER

PT S
AU Hu, K
   Sun, B
   Deng, Q
   Yang, Q
AF Hu, Kai
   Sun, Bin
   Deng, Qiao
   Yang, Qi
BE Yang, J
   Hu, Q
   Cheng, MM
   Wang, L
   Liu, Q
   Bai, X
   Meng, D
TI A Novel Layer Based Image Fusion Approach via Transfer Learning and
   Coupled Dictionary
SO COMPUTER VISION, PT II
SE Communications in Computer and Information Science
CT 2nd CCF Chinese Conference on Computer Vision (CCCV)
CY OCT 11-14, 2017
CL China Comp Federat, Tianjin, PEOPLES R CHINA
HO China Comp Federat
DE Image fusion; Layer division; Transfer learning; Coupled dictionary
ID SPARSE REPRESENTATION; FRAMEWORK; PERFORMANCE
AB A novel layer based image fusion method is proposed in this paper. It exploits and utilizes the implicated patterns among source images with two parts: (i) proposed a more precise model roots in transfer learning and coupled dictionary for layering source images; (ii) designed appropriate fusion scheme which bases on multi-scale transformation for recombining layers into final fused image efficiently. Rigorous experimental comparison in subjective and objective demonstrates that proposed image fusion method achieves better result in visual perception and computer process.
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Chen C, 2015, IEEE T IMAGE PROCESS, V24, P4213, DOI 10.1109/TIP.2015.2456415
   Dai W, 2008, ICML 2008
   Gao R, 2016, INT C AC SPEECH SIGN
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Kong WW, 2015, COMM COM INF SC, V546, P1, DOI 10.1007/978-3-662-48558-3_1
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li TJ, 2011, INFORM FUSION, V12, P85, DOI 10.1016/j.inffus.2010.03.007
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panagakis Y, 2016, IEEE T PATTERN ANAL, V38, P1665, DOI 10.1109/TPAMI.2015.2497700
   Son CH, 2016, IEEE T IMAGE PROCESS, V25, P2866, DOI 10.1109/TIP.2016.2556618
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
NR 23
TC 0
Z9 0
SN 1865-0929
EI 1865-0937
BN 978-981-10-7302-1; 978-981-10-7301-4
PY 2017
VL 772
BP 199
EP 209
DI 10.1007/978-981-10-7302-1_17
UT WOS:000449831600017
ER

PT S
AU Song, Y
   Yue, TB
   Wang, HZ
   Li, JZ
   Gao, H
AF Song, Yang
   Yue, Tianbai
   Wang, Hongzhi
   Li, Jianzhong
   Gao, Hong
BE Zou, B
   Li, M
   Wang, H
   Song, X
   Xie, W
   Lu, Z
TI Disease Prediction Based on Transfer Learning in Individual Healthcare
SO DATA SCIENCE, PT 1
SE Communications in Computer and Information Science
CT 3rd International Conference of Pioneering Computer Scientists,
   Engineers and Educators (ICPCSEE)
CY SEP 22-24, 2017
CL Cent S Univ, Changsha, PEOPLES R CHINA
HO Cent S Univ
DE Individual healthcare; Transfer learning; Neural networks; Disease
   prediction; Unlabeled data
AB Nowadays, emerging mobile medical technology and disease prevention become new trends of disease prevention and control. Based on this technology, we present disease prediction models based on transfer learning. Breast cancer disease data has been used to build our model. According to the neural networks, the basic model has been provided. With unlabeled data, transfer learning is a appropriate way to revise the module to increase accuracy. The test results show that the algorithm is suitable for data classification, especially for unlabeled health data.
OI Wang, Hongzhi/0000-0002-7521-2871
CR Anbarasi M, 2010, INT J ENG SCI TECHNO, V2, P5370
   Chadha R, 2016, CSI T ICT, P1
   Di Angelantonio E, 2012, JAMA-J AM MED ASSOC, V307, P2499, DOI 10.1001/jama.2012.6571
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hastie T, 2001, J ROY STAT SOC, P192
   Haykin S, 1994, NEURAL NETWORKS COMP, P71
   Huang W, 2016, NEUROCOMPUTING, V204, P125, DOI 10.1016/j.neucom.2015.07.148
   Ordonez C, 2006, IEEE T INF TECHNOL B, V10, P334, DOI 10.1109/TITB.2005.864475
   Palaniappan S, 2008, I C COMP SYST APPLIC, P108, DOI 10.1109/AICCSA.2008.4493524
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Soni J, 2011, INT J COMPUT APPL, V17, P43, DOI DOI 10.5120/2237-2860
   Weng CH, 2016, TELEMAT INFORM, V33, P277, DOI 10.1016/j.tele.2015.08.006
NR 12
TC 0
Z9 0
SN 1865-0929
EI 1865-0937
BN 978-981-10-6385-5; 978-981-10-6384-8
PY 2017
VL 727
BP 110
EP 122
DI 10.1007/978-981-10-6385-5_10
UT WOS:000449710600010
ER

PT S
AU Fu, CM
   Sheng, WH
   Wang, F
   Ye, F
   Liu, QY
   Jiang, Q
AF Fu, Chunmeng
   Sheng, Weihua
   Wang, Fei
   Ye, Feng
   Liu, Qiongyang
   Jiang, Qi
GP IEEE
TI Research and Implementation of Fast Identity Registration System Based
   on Audio-visual Fusion
SO 2017 IEEE 7TH ANNUAL INTERNATIONAL CONFERENCE ON CYBER TECHNOLOGY IN
   AUTOMATION, CONTROL, AND INTELLIGENT SYSTEMS (CYBER)
SE IEEE Annual International Conference on Cyber Technology in Automation
   Control and Intelligent Systems
CT 7th IEEE Annual International Conference on CYBER Technology in
   Automation, Control, and Intelligent Systems (CYBER)
CY JUL 31-AUG 04, 2017
CL Honolulu, HI
DE Face recognition; Service robot; Audio-visual fusion; Deep learning
AB In the research of family service robot, face recognition has become a hotspot because of its wide application prospect in home security, human-computer interaction and authentication. The robot must first solve the user's identity registration problem before performing the task of face recognition. To make the registration process more natural and convenient, this paper combines the human audio-visual information, first use the voice interactive way to collect the user's name and face image information, and then use the improved deep neural network and transfer learning method quickly training out the face recognition model to achieve the user's identity registration. The experimental results show that the proposed method not only improves the convenience of identity registration but also shortens the time it takes for user's identity registration.
CR Deng J., 2009, IEEE INT C COMP VIS
   Jiang M, 2016, TRANSFER LEARNING BA
   Krizhevsky A., 2012, P NEUR INF PROC SYST
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun Y., 2014, P NEUR INF PROC SYST
   Sun Y., 2014, P IEEE INT C COMP VI
   Taigman Y., 2014, P IEEE INT C COMP VI
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
NR 10
TC 0
Z9 0
SN 2379-7711
BN 978-1-5386-0490-8
PY 2017
BP 1442
EP 1445
UT WOS:000447628700259
ER

PT S
AU Marrone, S
   Piantadosi, G
   Fusco, R
   Petrillo, A
   Sansone, M
   Sansone, C
AF Marrone, Stefano
   Piantadosi, Gabriele
   Fusco, Roberta
   Petrillo, Antonella
   Sansone, Mario
   Sansone, Carlo
BE Battiato, S
   Gallo, G
   Schettini, R
   Stanco, F
TI An Investigation of Deep Learning for Lesions Malignancy Classification
   in Breast DCE-MRI
SO IMAGE ANALYSIS AND PROCESSING (ICIAP 2017), PT II
SE Lecture Notes in Computer Science
CT 19th International Conference on Image Analysis and Processing (ICIAP)
CY SEP 11-15, 2017
CL Catania, ITALY
DE Deep convolutional neural network; DCE-MRI; Breast; Cancer
ID CONVOLUTIONAL NEURAL-NETWORKS; CANCER; IMAGES; RECOGNITION; PATTERNS
AB Dynamic Contrast Enhanced-Magnetic Resonance Imaging (DCE-MRI) is gaining popularity as a complementary diagnostic method for early detection and diagnosis of breast cancer. However, due to the large amount of data, DCE-MRI can hardly be inspected without the use of a Computer Aided Diagnosis (CAD) system. Among the major issues in developing CAD for breast DCE-MRI there is the classification of regions of interest according to their aggressiveness. For this task newer hand-crafted features are continuously proposed by domain experts. On the other hand, deep learning approaches have gained popularity in many pattern recognition tasks, being able to outperform classical machine learning techniques in different fields, by learning compact hierarchical representations of an image which well fit the specific task to solve. The aim of this work is to explore the applicability of Convolutional Neural Networks (CNN) in automatic lesion malignancy assessment for breast DCE-MRI data. Our findings show that while promising results in treating DCE-MRI can be obtained by using transfer learning, CNNs have to be carefully designed and tuned in order to outperform approaches specifically designed to exploit all the available data information.
RI Fusco, Roberta/I-4062-2018
OI Fusco, Roberta/0000-0002-0469-9969; Piantadosi,
   Gabriele/0000-0002-0764-8542; Marrone, Stefano/0000-0001-6852-0377
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Antropova N, 2016, MED PHYS, V43, P3349, DOI 10.1118/1.4955674
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   El-Kwae EA, 1998, J DIGIT IMAGING, V11, P83, DOI 10.1007/BF03168730
   Ferlay J, 2010, BREAST CANCER EPIDEMIOLOGY, P1, DOI 10.1007/978-1-4419-0685-4_1
   Fusco R., 2012, 25 INT S COMP BAS ME, p[1, 692], DOI 10.1007/978-3-642-34166-375
   Fusco R, 2016, J MED BIOL ENG, V36, P449, DOI 10.1007/s40846-016-0163-7
   Fusco R, 2012, LECT NOTES COMPUT SC, V7626, P684, DOI 10.1007/978-3-642-34166-3_75
   Glasser S, 2013, 2013 IEEE 26TH INTERNATIONAL SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS (CBMS), P77, DOI 10.1109/CBMS.2013.6627768
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lehman C. D., 2007, TECHNICAL REPORT
   Liao S, 2013, LECT NOTES COMPUT SC, V8150, P254, DOI 10.1007/978-3-642-40763-5_32
   Marrone S, 2014, COMP MED SY, P209, DOI 10.1109/CBMS.2014.57
   Marrone S, 2013, LECT NOTES COMPUT SC, V8157, P359, DOI 10.1007/978-3-642-41184-7_37
   Nodine C F, 1987, Radiographics, V7, P1241
   Olsen O, 2001, LANCET, V358, P1340, DOI 10.1016/S0140-6736(01)06449-2
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Piantadosi G, 2015, LECT NOTES COMPUT SC, V9279, P647, DOI 10.1007/978-3-319-23231-7_58
   Reda I, 2016, I S BIOMED IMAGING, P1237, DOI 10.1109/ISBI.2016.7493490
   Rosset A, 2004, J DIGIT IMAGING, V17, P205, DOI 10.1007/s10278-004-1014-6
   Tofts PS, 2010, MAGNETOM FLASH, V3, P30
   Twellmann T, 2004, P ANN INT IEEE EMBS, V26, P454
   Wang YB, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P1697, DOI 10.1109/ICMA.2016.7558819
   Zheng YJ, 2009, MED PHYS, V36, P3192, DOI 10.1118/1.3151811
   Zoorob R, 2001, AM FAM PHYSICIAN, V63, P1101
NR 26
TC 1
Z9 1
SN 0302-9743
EI 1611-3349
BN 978-3-319-68548-9; 978-3-319-68547-2
PY 2017
VL 10485
BP 479
EP 489
DI 10.1007/978-3-319-68548-9_44
PN II
UT WOS:000445230400044
ER

PT B
AU Mhalla, A
   Chateau, T
   Gazzah, S
   Ben Amara, NE
AF Mhalla, Ala
   Chateau, Thierry
   Gazzah, Sami
   Ben Amara, Najoua Essoukri
BE Imai, F
   Tremeau, A
   Braz, J
TI Specialization of a Generic Pedestrian Detector to a Specific Traffic
   Scene by the Sequential Monte-Carlo Filter and the Faster R-CNN
SO PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP
   2017), VOL 4
CT 12th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP)
CY FEB 27-MAR 01, 2017
CL Porto, PORTUGAL
DE Transfer Learning; Deep Learning; Faster R-CNN; Sequential Monte Carlo
   Filter (SMC); Pedestrian Detection
AB The performance of a generic pedestrian detector decreases significantly when it is applied to a specific scene due to the large variation between the source dataset used to train the generic detector and samples in the target scene. In this paper, we suggest a new approach to automatically specialize a scene-specific pedestrian detector starting with a generic detector in video surveillance without further manually labeling any samples under a novel transfer learning framework. The main idea is to consider a deep detector as a function that generates realizations from the probability distribution of the pedestrian to be detected in the target. Our contribution is to approximate this target probability distribution with a set of samples and an associated specialized deep detector estimated in a sequential Monte Carlo filter framework. The effectiveness of the proposed framework is demonstrated through experiments on two public surveillance datasets. Compared with a generic pedestrian detector and the state-of-the-art methods, our proposed framework presents encouraging results.
CR Dauphin G, 2012, JMLR P TRACK, P97
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]
   Everingham M., 2010, IJCV
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Goodfellow I.J, 2012, SPIKE SLAB SPARSE CO
   Guyon I, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P793, DOI 10.1109/IJCNN.2011.6033302
   Htike KK, 2014, INT C PATT RECOG, P654, DOI 10.1109/ICPR.2014.123
   Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XD, 2015, INT J CONTROL AUTOM, V13, P1020, DOI 10.1007/s12555-014-0119-z
   Maamatou Houda, 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: VISAPP 2016, P411
   Mao YX, 2015, IEEE WINT CONF APPL, P170, DOI 10.1109/WACV.2015.30
   Nair V, 2004, PROC CVPR IEEE, P317
   Ren S., 2015, CORR
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Smith A., 2013, SEQUENTIAL MONTE CAR
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang M, 2012, PROC CVPR IEEE, P3274, DOI 10.1109/CVPR.2012.6248064
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Zeng XY, 2014, LECT NOTES COMPUT SC, V8691, P472, DOI 10.1007/978-3-319-10578-9_31
NR 23
TC 0
Z9 0
BN 978-989-758-225-7
PY 2017
BP 17
EP 23
DI 10.5220/0006097900170023
UT WOS:000444907000001
ER

PT B
AU Hagerty, J
   Stanley, RJ
   Stoecker, WV
AF Hagerty, Jason
   Stanley, R. Joe
   Stoecker, William V.
BE Imai, F
   Tremeau, A
   Braz, J
TI Medical Image Processing in the Age of Deep Learning Is There Still Room
   for Conventional Medical Image Processing Techniques?
SO PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP
   2017), VOL 4
CT 12th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP)
CY FEB 27-MAR 01, 2017
CL Porto, PORTUGAL
DE Deep Learning; Convolution Neural Networks; Fusion; Transfer Learning
AB Deep learning, in particular convolutional neural networks, has increasingly been applied to medical images. Advances in hardware coupled with availability of increasingly large data sets have fueled this rise. Results have shattered expectations. But it would be premature to cast aside conventional machine learning and image processing techniques. All that deep learning comes at a cost, the need for very large datasets. We discuss the role of conventional manually tuned features combined with deep learning. This process of fusing conventional image processing techniques with deep learning can yield results that are superior to those obtained by either learning method in isolation. In this article, we review the rise of deep learning in medical image processing and the recent onset of fusion of learning methods. We discuss supervision equilibrium point and the factors that favor the role of fusion methods for histopathology and quasi-histopathology modalities.
CR Allen Kate, 2015, TORONTO STAR
   [Anonymous], 2016, IMAGENET
   Arevalo J, 2015, ARTIF INTELL MED, V64, P131, DOI 10.1016/j.artmed.2015.04.004
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Brown L, 2015, DEEP LEARNING GPUS
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Guo P, 2015, IEEE J BIOMED HLTH I
   KRIEGER N, 1994, J CLIN EPIDEMIOL, V47, P897, DOI 10.1016/0895-4356(94)90193-7
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Suzuki S, 2016, MED PHYS, V43, P3817, DOI 10.1118/1.4957862
   VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wang JH, 2016, SCI REP-UK, V6, DOI 10.1038/srep27327
   Zhong C, 2017, MED IMAGE ANAL, V35, P530, DOI 10.1016/j.media.2016.08.010
NR 16
TC 0
Z9 0
BN 978-989-758-225-7
PY 2017
BP 306
EP 311
DI 10.5220/0006273803060311
UT WOS:000444907000038
ER

PT B
AU Sun, C
   Lee, WS
AF Sun, Chao
   Lee, Won-Sook
BE Imai, F
   Tremeau, A
   Braz, J
TI Braid Hairstyle Recognition based on CNNs
SO PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP
   2017), VOL 4
CT 12th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP)
CY FEB 27-MAR 01, 2017
CL Porto, PORTUGAL
DE Braid Hairstyle Recognition; Convolutional Neural Networks
AB In this paper, we present a novel braid hairstyle recognition system based on Convolutional Neural Networks (CNNs). We first build a hairstyle patch dataset that is composed of braid hairstyle patches and non-braid hairstyle patches (straight hairstyle patches, curly hairstyle patches, and kinky hairstyle patches). Then we train our hairstyle recognition system via transfer learning on a pre-trained CNN model in order to extract the features of different hairstyles. Our hairstyle recognition CNN model achieves the accuracy of 92.7% on image patch dataset. Then the CNN model is used to perform braid hairstyle detection and recognition in full-hair images. The experiment results shows that the patch-level trained CNN model can successfully detect and recognize braid hairstyle in image-level.
CR Achanta R, 2012, 2012 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Bell S, 2014, ABS14120623 CORR
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Cimpoi M, 2013, ABS13113618 CORR
   Dass J, 2013, COMP VIS PATT REC IM
   Deng J., 2009, CVPR 09
   Hu  D., 2011, P IEEE GLOBECOM 11 H, V2, P1
   Hu L, 2014, ACM T GRAPH
   Krizhevsky A., 2012, ADV NEURAL INFORM PR
   Liu C, 2010, PROC CVPR IEEE, P239, DOI [10.1109/CVPR.2010.5540207, 10.1109/ICCET.2010.5485248]
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Yacoob Y, 2006, IEEE T PATTERN ANAL
NR 13
TC 1
Z9 1
BN 978-989-758-225-7
PY 2017
BP 548
EP 555
DI 10.5220/0006169805480555
UT WOS:000444907000064
ER

PT B
AU Ghosh, S
   Amon, P
   Hutter, A
   Kaup, A
AF Ghosh, Sanjukta
   Amon, Peter
   Hutter, Andreas
   Kaup, Andre
BE Imai, F
   Tremeau, A
   Braz, J
TI Pedestrian Counting using Deep Models Trained on Synthetically Generated
   Images
SO PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP
   2017), VOL 5
CT 12th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP)
CY FEB 27-MAR 01, 2017
CL Porto, PORTUGAL
DE Pedestrian Counting; Deep Learning; Convolutional Neural Networks;
   Synthetic Images; Transfer Learning; Cross Entropy Cost Function;
   Squared Error Cost Function
AB Counting pedestrians in surveillance applications is a common scenario. However, it is often challenging to obtain sufficient annotated training data, especially so for creating models using deep learning which require a large amount of training data. To address this problem, this paper explores the possibility of training a deep convolutional neural network (CNN) entirely from synthetically generated images for the purpose of counting pedestrians. Nuances of transfer learning are exploited to train models from a base model trained for image classification. A direct approach and a hierarchical approach are used during training to enhance the capability of the model for counting higher number of pedestrians. The trained models are then tested on natural images of completely different scenes captured by different acquisition systems not experienced by the model during training. Furthermore, the effectiveness of the cross entropy cost function and the squared error cost function are evaluated and analyzed for the scenario where a model is trained entirely using synthetic images. The performance of the trained model for the test images from the target site can be improved by fine-tuning using the image of the background of the target site.
OI Kaup, Andre/0000-0002-0929-5074
CR Andriluka M., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587583
   Angelova  A., 2015, P BMVC 2015
   Angelova A, 2015, P ICRA 2015
   Arteta C, 2014, INTERACTIVE OBJECT C, P504
   Baltieri D., 2011, P 1 INT ACM WORKSH M
   Bengio IGY, 2016, DEEP LEARNING
   Chan A.B., 2008, IEEE C COMP VIS PATT, V2008, P1, DOI DOI 10.1109/CVPR.2008.4587569
   Chandler A, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P101
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Cheng K. Y., 2012, P IEEE ICNP, P1, DOI [10.1109/ICNP.2012.6459982, DOI 10.1109/APPEEC.2012.6307134]
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Fiaschi L, 2012, INT C PATT RECOG, P2685
   Fujii Y, 2010, PROCEDIA SOCIAL BEHA, V2, P143
   Girshick R. B., 2013, CORR, V1311, P2524
   Golik P, 2013, INTERSPEECH, P1755
   Hattori Hironori, 2015, IEEE C COMP VIS PATT
   Hinton G.E., 2012, CORR
   Jia Y., 2014, ARXIV14085093
   Kline DM, 2005, NEURAL COMPUT APPL, V14, P310, DOI 10.1007/s00521-005-0467-y
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lempitsky V. S., 2010, ADV NEURAL INFORM PR, P1324, DOI DOI 10.1111/1467-9280.03439
   Liu W., 2016, ICML
   Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329
   Merad D, 2010, AVSS IEEE, P151
   MOODY JE, 1992, ADV NEUR IN, V4, P847
   Overett G, 2008, IEEE INT VEH SYM, P1038
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G., 2016, IEEE C COMP VIS PATT
   Segui S, 2015, IEEE COMPUT SOC CONF
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Yosinski J., 2015, DEEP LEARN WORKSH IN
   Yu ZJ, 2014, IEEE IMAGE PROC, P2432, DOI 10.1109/ICIP.2014.7025492
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhao H, 2015, 151108861 ARXIV
NR 37
TC 0
Z9 0
BN 978-989-758-226-4
PY 2017
BP 86
EP 97
DI 10.5220/0006132600860097
UT WOS:000444905600008
ER

PT B
AU Michelsanti, D
   Ene, AD
   Guichi, Y
   Stef, R
   Nasrollahi, K
   Moeslund, TB
AF Michelsanti, Daniel
   Ene, Andreea-Daniela
   Guichi, Yanis
   Stef, Rares
   Nasrollahi, Kamal
   Moeslund, Thomas B.
BE Imai, F
   Tremeau, A
   Braz, J
TI Fast Fingerprint Classification with Deep Neural Networks
SO PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP
   2017), VOL 5
CT 12th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP)
CY FEB 27-MAR 01, 2017
CL Porto, PORTUGAL
DE Fingerprint Classification; Transfer Learning; Convolutional Neural
   Networks
AB Reducing the number of comparisons in automated fingerprint identification systems is essential when dealing with a large database. Fingerprint classification allows to achieve this goal by dividing fingerprints into several categories, but it presents still some challenges due to the large intra-class variations and the small inter-class variations. The vast majority of the previous methods uses global characteristics, in particular the orientation image, as features of a classifier. This makes the feature extraction stage highly dependent on preprocessing techniques and usually computationally expensive. In this work we evaluate the performance of two pretrained convolutional neural networks fine-tuned on the NIST SD4 benchmark database. The obtained results show that this approach is comparable with other results in the literature, with the advantage of a fast feature extraction stage.
CR Candela G. T., 1995, 5647 NISTIR
   Cao K, 2013, PATTERN RECOGN, V46, P3186, DOI 10.1016/j.patcog.2013.05.008
   Cappelli R, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P183, DOI 10.1007/0-387-21685-5_9
   Cappelli R, 1999, P WORKSH AUT ID ADV, P117
   Cappelli R, 2003, P 2003 ACM SIGMM WOR, P95
   Chatfield K., 2014, P BRIT MACH VIS C, P1, DOI [10.5244/C.28.6, DOI 10.5244/C.28.6]
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Galar M, 2015, KNOWL-BASED SYST, V81, P76, DOI 10.1016/j.knosys.2015.02.008
   Hertel L., 2015, 2015 INT JOINT C NEU, P1
   Ioffe S, 2015, INT C MACH LEARN, V37, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Krizhevsky A., 2009, TECHNICAL REPORT
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y., 1998, MNIST DATABASE HANDW
   Li J, 2008, PATTERN RECOGN, V41, P353, DOI 10.1016/j.patcog.2007.03.015
   Maltoni J. A., 2009, HDB FINGERPRINT RECO
   Mayhew S, 2015, HIST BIOMETRICS
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Park CH, 2005, PATTERN RECOGN, V38, P495, DOI 10.1016/j.patcog.2004.08.013
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176.ARXIV:1312.6229
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan X, 2005, IEEE T SYST MAN CY C, V35, P287, DOI 10.1109/TSMCC.2005.848167
   Tan XJ, 2003, LECT NOTES COMPUT SC, V2688, P318
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Watson C. I., 1992, NIST SPECIAL DATABAS
   Watson C. I., 1993, NIST SPECIAL DATABAS
   Zhang QZ, 2004, PATTERN RECOGN, V37, P2233, DOI 10.1016/j.patcog.2003.12.020
NR 28
TC 0
Z9 0
BN 978-989-758-226-4
PY 2017
BP 202
EP 209
DI 10.5220/0006116502020209
UT WOS:000444905600021
ER

PT S
AU Nguyen, HTH
   Wistuba, M
   Schmidt-Thieme, L
AF Nguyen, Hanh T. H.
   Wistuba, Martin
   Schmidt-Thieme, Lars
BE Ceci, M
   Hollmen, J
   Todorovski, L
   Vens, C
   Dzeroski, S
TI Personalized Tag Recommendation for Images Using Deep Transfer Learning
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2017,
   PT II
SE Lecture Notes in Artificial Intelligence
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 18-22, 2017
CL Skopje, MACEDONIA
DE Image tagging; Convolutional neural networks; Personalized tag
   recommendation; Factorization models
AB Image tag recommendation in social media systems provides the users with personalized tag suggestions which facilitate the users' tagging task and enable automatic organization and many image retrieval tasks. Factorization models are a widely used approach for personalized tag recommendation and achieve good results. These methods rely on the user's tagging preferences only and ignore the contents of the image. However, it is obvious that especially the contents of the image, such as the objects appearing in the image, colors, shapes or other visual aspects, strongly influence the user's tagging decisions.
   We present a personalized content-aware image tag recommendation approach that combines both historical tagging information and image-based features in a factorization model. Employing transfer learning, we apply state of the art deep learning image classification and object detection techniques to extract powerful features from the images. Both, image information and tagging history, are fed to an adaptive factorization model to recommend tags. Empirically, we can demonstrate that the visual and object-based features can improve the performance up to 1.5% over the state of the art.
CR Chua Tat-Seng, 2009, P ACM INT C IM VID R, P48, DOI DOI 10.1145/1646396.1646452
   Garg N, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P67
   Gong Y., 2013, ARXIV13124894
   Jaschke R, 2007, LECT NOTES ARTIF INT, V4702, P506
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li X., 2008, P 1 ACM INT C MULT I, P180, DOI DOI 10.1145/1460096.1460126
   Marin L, 2012, REV OCCIDENTE, P11, DOI 10.1007/978-1-4614-1894-8
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Rae A., 2010, ADAPTIVITY PERSONALI, P92
   Redmon J, 2016, ARXIV161208242
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.1145/1772690.1772773
   Rendle S., 2010, P 3 ACM INT C WEB SE, P81, DOI DOI 10.1145/1718487.1718498
   Rendle S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727
   Sigurbjornsson Borkur, 2008, P 17 INT C WORLD WID, P327, DOI DOI 10.1145/1367497.1367542
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Wei Y., 2014, ARXIV14065726
NR 19
TC 3
Z9 3
SN 0302-9743
EI 1611-3349
BN 978-3-319-71246-8; 978-3-319-71245-1
PY 2017
VL 10535
BP 705
EP 720
DI 10.1007/978-3-319-71246-8_43
PN II
UT WOS:000443110500043
ER

PT S
AU Wu, D
   Wang, BY
   Precup, D
   Boulet, B
AF Wu, Di
   Wang, Boyu
   Precup, Doina
   Boulet, Benoit
BE Altun, Y
   Das, K
   Mielikainen, T
   Malerba, D
   Stefanowski, J
   Read, J
   Zitnik, M
   Ceci, M
   Dzeroski, S
TI Boosting Based Multiple Kernel Learning and Transfer Regression for
   Electricity Load Forecasting
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2017,
   PT III
SE Lecture Notes in Artificial Intelligence
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 18-22, 2017
CL Skopje, MACEDONIA
DE Electricity load forecasting; Boosting; Multiple kernel learning;
   Transfer learning
ID ALGORITHMS; MACHINE; MODEL
AB Accurate electricity load forecasting is of crucial importance for power system operation and smart grid energy management. Different factors, such as weather conditions, lagged values, and day types may affect electricity load consumption. We propose to use multiple kernel learning (MKL) for electricity load forecasting, as it provides more flexibilities than traditional kernel methods. Computation time is an important issue for short-term load forecasting, especially for energy scheduling demand. However, conventional MKL methods usually lead to complicated optimization problems. Another practical aspect of this application is that there may be very few data available to train a reliable forecasting model for a new building, while at the same time we may have prior knowledge learned from other buildings. In this paper, we propose a boosting based framework for MKL regression to deal with the aforementioned issues for short-term load forecasting. In particular, we first adopt boosting to learn an ensemble of multiple kernel regressors, and then extend this framework to the context of transfer learning. Experimental results on residential data sets show the effectiveness of the proposed algorithms.
CR Atsawathawichok P., 2014, 11 INT C EL ENG EL C, P1, DOI DOI 10.1109/ECTICON.2014.6839869
   Bach F. R., 2004, P 21 INT C MACH LEAR, P6, DOI DOI 10.1145/1015330.1015424
   Buhlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242
   Bunn D.W., 1985, COMP MODELS ELECT LO
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chapelle O, 2011, MACH LEARN, V85, P149, DOI 10.1007/s10994-010-5231-6
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Fiot J.B., 2016, IEEE T SMART GRID, P1
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gonen M, 2011, J MACH LEARN RES, V12, P2211
   Hastie T., 2009, ELEMENTS STAT LEARNI, DOI [10.1007/978-0-387-84858-7, DOI 10.1007/978-0-387-84858-7]
   Hippert HS, 2001, IEEE T POWER SYST, V16, P44, DOI 10.1109/59.910780
   Kamyab F, 2016, IEEE T SMART GRID, V7, P1277, DOI 10.1109/TSG.2015.2430364
   Mason L, 2000, ADV NEUR IN, V12, P512
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pardoe D., 2010, P 27 INT C MACH LEAR, P863
   Rosset S, 2004, J MACH LEARN RES, V5, P941
   Soliman SAH, 2010, ELECTRICAL LOAD FORECASTING: MODELING AND MODEL CONSTRUCTION, P1
   Wang B., 2015, P 29 AAAI C ART INT, P3038
   Xia H, 2013, IEEE T KNOWL DATA EN, V25, P1574, DOI 10.1109/TKDE.2012.89
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Zhang R, 2013, IET GENER TRANSM DIS, V7, P391, DOI 10.1049/iet-gtd.2012.0541
   Zhuang J., 2011, ICML, V15, P909
NR 24
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-71273-4; 978-3-319-71272-7
PY 2017
VL 10536
BP 39
EP 51
DI 10.1007/978-3-319-71273-4_4
PN III
UT WOS:000443111100004
ER

PT B
AU Salami, A
   Khodabakhshi, MB
   Moradi, MH
AF Salami, Abbas
   Khodabakhshi, Mohammad Bagher
   Moradi, Mohammad Hasan
GP IEEE
TI Fuzzy Transfer Learning Approach for Analysing Imagery BCI Tasks
SO 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND
   SIGNAL PROCESSING (AISP)
CT 19th CSI International Symposium on Artificial Intelligence and Signal
   Processing (AISP)
CY OCT 25-27, 2017
CL Shiraz, IRAN
DE component; Fuzzy Transfer Learning; Brain-Computer Interface (BCI);
   Generalized Hidden-Mapping Ridge Regression (GHRR); Classification;
   Fuzzy Rule Generation
ID EEG
AB In brain-computer interfaces (BCI), the statistical distribution of the data could differ across subjects as well as across sessions for an individual subject. Moreover, the lack of data due to the difficulties in collecting data in BCI is a common challenge in training the systems. Since most of machine learning tools are based on the assumption that the distribution of training and testing data are the same and they need adequate training data, they would fail in such situations. To overcome this problem and because of the vague and uncertain essence of EEG data, in this paper, we used a fuzzy transfer learning (FTL) method based on Generalized Hidden-Mapping Ridge Regression (GHRR) to improve the classification task in BCI. Takagi-Sugeno-Kang fuzzy logical system (TSK) with proposed modified Wang-Mendel fuzzy rule generation were employed for classification. Then the session-to-session transfer of knowledge is adopted. The results demonstrate the effectiveness of our proposed method in classification and outperform the well-known SVM classifier.
CR Blankertz B, 2003, BCI COMPETITION
   Cheng MM, 2017, COGN NEURODYNAMICS, V11, P173, DOI 10.1007/s11571-016-9417-x
   Deng ZH, 2014, IEEE T CYBERNETICS, V44, P2585, DOI 10.1109/TCYB.2014.2311014
   Ishibuchi H, 2004, FUZZY SET SYST, V141, P59, DOI 10.1016/S0165-0114(03)00114-3
   Jayaram V, 2016, IEEE COMPUT INTELL M, V11, P20, DOI 10.1109/MCI.2015.2501545
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946
   Shell Jethro, 2012, Ambient Intelligence. Third International Joint Conference (AML 2012). Proceedings, P145, DOI 10.1007/978-3-642-34898-3_10
   Shell J, 2015, INFORM SCIENCES, V293, P59, DOI 10.1016/j.ins.2014.09.004
   Thrun S, 1996, ADV NEUR IN, V8, P640
   WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466
   Wei CS, 2015, IEEE SYS MAN CYBERN, P3229, DOI 10.1109/SMC.2015.560
   Yang CJ, 2014, ARTIF INTELL MED, V62, P165, DOI 10.1016/j.artmed.2014.10.002
NR 14
TC 0
Z9 0
BN 978-1-5386-2585-9
PY 2017
BP 300
EP 305
UT WOS:000442162300055
ER

PT S
AU Lin, J
   Zheng, TY
   Liao, YB
   Deng, WH
AF Lin, Jian
   Zheng, Tianyue
   Liao, Yanbing
   Deng, Weihong
BE Sun, Y
   Lu, H
   Zhang, L
   Yang, J
   Huang, H
TI CNN-Based Age Classification via Transfer Learning
SO INTELLIGENCE SCIENCE AND BIG DATA ENGINEERING, ISCIDE 2017
SE Lecture Notes in Computer Science
CT 7th International Conference on Intelligence Science and Big Data
   Engineering (IScIDE)
CY SEP 22-23, 2017
CL Dalian, PEOPLES R CHINA
DE Unconstrained age estimation; Convolutional Neural Network; Transform
   learning
AB Age estimation has always hit people's eyes. While most previous works have focused on constrained images taken under lab condition, which is far from real-world age estimation. The benchmark we used in this paper is the unconstrained Adience [3], which is believed to better reflect the traits of age in the wild condition. In this paper, we adapted contrastive loss to fine-tune the pre-trained VGG-16 over FG-NET to get a better start point and proposed AvgOut-FC Layer to enhance the performance of the models over Audience. We have achieved better results over the Adience benchmark than previous works, which demonstrated the effectiveness of our methods.
CR Chopra S., 2005, IEEE COMP SOC C COMP, V1
   Eidinger E., 2014, T INFORM FORENSICS S, V9, P6
   Eidinger E., 2014, T INFORM FORENSICS S, V9, P5
   Eidinger E., 2014, T INFORM FORENSICS S, V9, P2
   Eidinger E., 2014, T INFORM FORENSICS S, V9, P1
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Goodfellow I., 2013, JMLR W CP, V28, P1319
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lanitis A., 2002, FG NET AGING DATABAS
   Levi G., 2015, IEEE C CVPR WORKSH
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Oquab M., 2014, CVPR
   Ozbulak G., 2016, P INT C BIOM SPEC IN, P1, DOI [10.1109/BIOSIG.2016.7736925, DOI 10.1109/BIOSIG.2016.7736925]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Yosinski Jason, 2014, ADV NEURAL INFORM PR
NR 19
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-67777-4; 978-3-319-67776-7
PY 2017
VL 10559
BP 161
EP 168
DI 10.1007/978-3-319-67777-4_14
UT WOS:000441466300014
ER

PT S
AU Shan, W
   Sun, GL
   Zhou, XF
   Liu, Z
AF Shan, Wei
   Sun, Guangling
   Zhou, Xiaofei
   Liu, Zhi
BE Sun, Y
   Lu, H
   Zhang, L
   Yang, J
   Huang, H
TI Two-Stage Transfer Learning of End-to-End Convolutional Neural Networks
   for Webpage Saliency Prediction
SO INTELLIGENCE SCIENCE AND BIG DATA ENGINEERING, ISCIDE 2017
SE Lecture Notes in Computer Science
CT 7th International Conference on Intelligence Science and Big Data
   Engineering (IScIDE)
CY SEP 22-23, 2017
CL Dalian, PEOPLES R CHINA
DE Convolutional neural networks; End-to-End; Webpage saliency prediction;
   Two-stage transfer learning
AB With the great success of convolutional neural networks (CNN) achieved on various computer vision tasks in recent years, CNN has also been applied in natural image saliency prediction. As a specific visual stimuli, web-pages exhibit evident similarities whereas also significant differences from natural image. Consequently, the learned CNN for natural image saliency prediction cannot be directly used to predict webpage saliency. Only a few researches on webpage saliency prediction have been developed till now. In this paper, we propose a simple yet effective scheme of two-stage transfer learning of end-to-end CNN to predict the webpage saliency. In the first stage, the output layer of two typical CNN architectures with instances of AlexNet and VGGNet are reconstructed, and the parameters between the fully connected layers are relearned from a large natural image database for image saliency prediction. In the second stage, the parameters between the fully connected layers are relearned from a scarce webpage database for webpage saliency prediction. In fact, the two-stage transfer learning can be regarded as a task transfer in the first stage and a domain transfer in the second stage, respectively. The experimental results indicate that the proposed two-stage transfer learning of end-to-end CNN can obtain a substantial performance improvement for webpage saliency prediction.
CR Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Buscher G, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P21
   Garcia-Diaz A, 2012, J VISION, V12, DOI 10.1167/12.6.17
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kummerer M, 2014, ARXIV14111045
   Li J, 2016, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2016.7532442
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nielsen J., 2006, F SHAPED PATTERN REA
   Shen CY, 2015, IEEE T MULTIMEDIA, V17, P2084, DOI 10.1109/TMM.2015.2483370
   Shen CY, 2014, LECT NOTES COMPUT SC, V8695, P33, DOI 10.1007/978-3-319-10584-0_3
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Still J.D., 2010, P 5 INT WORKSH MOD D, P25
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
NR 17
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-67777-4; 978-3-319-67776-7
PY 2017
VL 10559
BP 316
EP 324
DI 10.1007/978-3-319-67777-4_27
UT WOS:000441466300027
ER

PT S
AU Huang, TW
   Jiao, F
AF Huang, Tianwen
   Jiao, Fei
BE Huang, DS
   Bevilacqua, V
   Premaratne, P
   Gupta, P
TI Data Transfer and Extension for Mining Big Meteorological Data
SO INTELLIGENT COMPUTING THEORIES AND APPLICATION, ICIC 2017, PT I
SE Lecture Notes in Computer Science
CT 13th International Conference on Intelligent Computing (ICIC)
CY AUG 07-10, 2017
CL Liverpool, ENGLAND
DE Big data; Transfer learning; Temperature forecast
ID REGRESSION
AB It is necessary for mining meteorological big data to build a machine learning model by using historical data to predict the future meteorological elements. This work is significant and has a technical challenge. However, the maintained data of the small cities and the medium cities are very limited due to historical reasons. It is adverse to build an accurate forecast model. Aiming at this problem, a temperature forecast method based on transfer learning technique is proposed. It extends the data of the target city by transferring the data from related cities. It builds a forecast model based on the extended dataset, and then solves the problem of the insufficient samples in machine learning. In this experiment, the temperature sequence of Gaoyao weather station in Zhaoqing area is extended according to the yearly average temperature from 1884 to 1997 of Hongkong. It is corrected by Macau data. Temperature trend of Zhaoqing area is modeled by the time power function and the least square method. The fitting curves and the regression function of the temperature change are obtained. The forecasting model is tested by the actual temperature data of 2014, 2015 and 2016. The results support the effectiveness of the proposed method and they also justify the superiority of applying data transfer to temperature forecast.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P97, DOI 10.1002/wics.51
   Akoz O., 2010, P IEEE INT C INT TRA, P474
   Cleophas TJ, 2014, SPRINGERBRIEF STAT, P19, DOI 10.1007/978-3-319-04181-0_4
   Haylock MR, 2006, J CLIMATE, V19, P1490, DOI 10.1175/JCLI3695.1
   He Q, 2008, INT J PATTERN RECOGN, V22, P95, DOI 10.1142/S0218001408006132
   Jin X., 2002, P 8 ACM SIGKDD INT C
   Kruger U., 2012, STAT MONITORING COMP, P375
   Nandi A, 2012, IEEE T KNOWL DATA EN, V24, P1747, DOI 10.1109/TKDE.2011.257
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   [曲付勇 Qu Fuyong], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P1075
   Rohde R., 2013, GEOINFOR GEOSTAT OVE, V1, P1, DOI [10.4172/2327-4581.1000101, 10.4172/gigs.1000101, DOI 10.4172/2327-4581.1000101]
   Seghouane AK, 2011, IEEE T AERO ELEC SYS, V47, P1154, DOI 10.1109/TAES.2011.5751249
   Thorne P., 2001, B AM METEOROL SOC, V92, pES40
   Wan C., 2015, P 29 AAAI C ART INT
   Wang M, 2012, PROC CVPR IEEE, P3274, DOI 10.1109/CVPR.2012.6248064
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Wang Y., 2012, J NANJING U INF SCI, V4, P316
   Wang ZK, 2013, IEEE T KNOWL DATA EN, V25, P2010, DOI 10.1109/TKDE.2012.113
   Xiaoming Jin, 2002, Advances in Knowledge Discovery and Data Mining. 6th Pacific-Asia Conference, PAKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2336), P469
   [熊波 Xiong Bo], 2012, [中国图象图形学报, Journal of Image and Graphics], V17, P628
   Yu BQ, 2013, PROCEEDINGS OF 2ND CONFERENCE ON LOGISTICS, INFORMATICS AND SERVICE SCIENCE (LISS 2012), VOLS 1 AND 2, DOI 10.1007/978-3-642-32054-5_123
   Zhang Z., 2016, P 30 AAAI C ART INT
NR 22
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-63309-1; 978-3-319-63308-4
PY 2017
VL 10361
BP 57
EP 66
DI 10.1007/978-3-319-63309-1_6
UT WOS:000441208400006
ER

PT S
AU Wahyono
   Jo, KH
AF Wahyono
   Jo, Kang-Hyun
BE Huang, DS
   Bevilacqua, V
   Premaratne, P
   Gupta, P
TI Human Carrying Baggage Classification Using Transfer Learning on CNN
   with Direction Attribute
SO INTELLIGENT COMPUTING THEORIES AND APPLICATION, ICIC 2017, PT I
SE Lecture Notes in Computer Science
CT 13th International Conference on Intelligent Computing (ICIC)
CY AUG 07-10, 2017
CL Liverpool, ENGLAND
DE Human carrying baggage classification; Convolution neural network;
   Transfer learning; Direction attribute; Region division
ID NETWORKS
AB Human carrying baggage classification is one of the important stages in identifying the owner of unattended baggage for a vision-based intelligent surveillance system. In this paper, an approach to classifying human carrying baggage region on surveillance video is proposed. The proposed approach utilized transfer learning strategy under convolution neural network with human pose direction attribute. For this purpose, we first constructed convolution neural network with the target including the presence of baggage and viewing direction of the human region. The network kernels are then fine-tuned to learning a new task in verifying whether the human carrying baggage or not. Rather than using the entire human region as input to the network, we divided the region into several sub-regions and assign them as a channel of the input layer. In the experiment, the standard public dataset is re-annotated with direction information of human pose to evaluate the effectiveness of the proposed approach.
CR CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Damen D, 2012, IEEE T PATTERN ANAL, V34, P1056, DOI 10.1109/TPAMI.2011.205
   Deng Y., 2014, P IEEE INT COMM C IC, P1
   Ghadiri F, 2016, LECT NOTES COMPUT SC, V9911, P852, DOI 10.1007/978-3-319-46478-7_52
   He X, 2016, LECT NOTES COMPUT SC, V9772, P332, DOI 10.1007/978-3-319-42294-7_29
   Kam H.T., 1995, P 3 INT C DOC AN REC, P14
   Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40
   Lin  Y., 2017, ARXIV170307220
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Satpathy A, 2013, INT CONF ACOUST SPEE, P2376, DOI 10.1109/ICASSP.2013.6638080
   Tzanidou G, 2013, IEEE T INF FOREN SEC, V8, P1620, DOI 10.1109/TIFS.2013.2279797
   Wahyono, 2017, NEUROCOMPUTING, V228, P106, DOI 10.1016/j.neucom.2016.10.038
   Wahyono, 2016, IEEE T IND INFORM, V12, P2247, DOI 10.1109/TII.2016.2605582
   Wang ZQ, 2016, LECT NOTES COMPUT SC, V9772, P311, DOI 10.1007/978-3-319-42294-7_27
NR 15
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-63309-1; 978-3-319-63308-4
PY 2017
VL 10361
BP 717
EP 724
DI 10.1007/978-3-319-63309-1_63
UT WOS:000441208400063
ER

PT S
AU Xie, G
   Sun, Y
   Lin, ML
   Tang, K
AF Xie, Ge
   Sun, Yu
   Lin, Minlong
   Tang, Ke
BE Cong, F
   Leung, A
   Wei, Q
TI A Selective Transfer Learning Method for Concept Drift Adaptation
SO ADVANCES IN NEURAL NETWORKS, PT II
SE Lecture Notes in Computer Science
CT 14th International Symposium on Neural Networks (ISNN)
CY JUN 21-26, 2017
CL JAPAN
DE Incremental learning; Transfer learning; Concept drift
AB Concept drift is one of the key challenges that incremental learning needs to deal with. So far, a lot of algorithms have been proposed to cope with it, but it is still difficult to response quickly to the change of concept. In this paper, a novel method named Selective Transfer Incremental Learning (STIL) is proposed to deal with this tough issue. STIL uses a selective transfer strategy based on the well-known chunk-based ensemble algorithm. In this way, STIL can adapt to the new concept of data well through transfer learning, and prevent negative transfer and overfitting that may occur in the transfer learning effectively by an appropriate selective policy. The algorithm was evaluated on 15 synthetic datasets and three real-world datasets, the experiment results show that STIL performs better in almost all of the datasets compared with five other state-of-the-art methods.
CR Bache K., 2013, UCI MACHINE LEARNING
   Bifet A, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P443
   Brzezinski D, 2014, IEEE T NEUR NET LEAR, V25, P81, DOI 10.1109/TNNLS.2013.2251352
   Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107
   Elwell R, 2011, IEEE T NEURAL NETWOR, V22, P1517, DOI 10.1109/TNN.2011.2160459
   Forman G., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P252, DOI 10.1145/1148170.1148216
   Gama J, 2004, LECT NOTES ARTIF INT, V3171, P286
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Hulten G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P97
   Kuncheva LI, 2000, INT C PATT RECOG, P168, DOI 10.1109/ICPR.2000.906041
   Minku LL, 2012, IEEE T KNOWL DATA EN, V24, P619, DOI 10.1109/TKDE.2011.58
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schlimmer J. C., 1986, Machine Learning, V1, P317, DOI 10.1007/BF00116895
   Street W. N., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P377
   Sun Y, 2016, CCIS, V681, P473, DOI [10.1007/978-981-10-3611-843, DOI 10.1007/978-981-10-3611-843]
   Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019
NR 16
TC 1
Z9 1
SN 0302-9743
EI 1611-3349
BN 978-3-319-59081-3; 978-3-319-59080-6
PY 2017
VL 10262
BP 353
EP 361
DI 10.1007/978-3-319-59081-3_42
UT WOS:000439964300042
ER

PT B
AU Li, ZB
   Liu, B
   Xiao, YS
AF Li, Zibin
   Liu, Bo
   Xiao, Yanshan
BE Liu, Y
   Zhao, L
   Cai, G
   Xiao, G
   Li, KL
   Wang, L
TI Cluster and Dynamic-TrAdaBoost- Based Transfer Learning for Text
   Classification
SO 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS
   AND KNOWLEDGE DISCOVERY (ICNC-FSKD)
CT 13th International Conference on Natural Computation, Fuzzy Systems and
   Knowledge Discovery (ICNC-FSKD)
CY JUL 29-31, 2017
CL Guilin, PEOPLES R CHINA
DE Object; transfer learning; data mining; dynamic-TrAdaBoost; K-means
AB Transfer learning can use the knowledge of closed fields to enhance complete the learning tasks in the target field. After several years of development, it has been widely used in research, data mining and deep learning. The problem that the sample weight of TrAdaBoost is prone to polarization in the source domain and the target domain when is in the transfer learning process. So we propose a transfer learning algorithm which based on dynamic-TrAdaBoost and k-means algorithm. This experiment proved to be a good solution to this problem.
CR Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137, DOI DOI 10.1007/S10994-009-5152-4
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Callum A. K. Mc, SIMULATED REAL AVIAT
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Dai W, 2009, P 26 ANN INT C MACH, P193, DOI DOI 10.1145/1553374.1553399
   Eaton E, 2009, INT CONF DAT MIN WOR, P422, DOI 10.1109/ICDMW.2009.97
   Gao J, 2008, KDD, P283, DOI DOI 10.1145/1401890.1401928
   Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331
   Lawrence N. D., 2004, P 21 INT C MACH LEAR, P65, DOI 10.1145/1015330.1015382
   Liao X., 2005, P 22 INT C MACH LEAR, V119, P505, DOI DOI 10.1145/1102351.1102415
   Mahmud MMH, 2007, LECT NOTES ARTIF INT, V4754, P135
   Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187
   Rosenstein MT, 2005, P NEUR INF PROC SYST
   Selim S Z, 2005, J CLASSIF, P287
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Wu P., 2004, P 21 INT C MACH LEAR, P871
   Xing DK, 2007, LECT NOTES ARTIF INT, V4702, P324
   Yang Qiang, 2009, INT C WIR COMM SIGN, P1
   Zhu X., 2008, SEMISUPERVISED LEARN, P32
   Zhuang Fu-then, 2015, Journal of Software, V26, P26, DOI 10.13328/j.cnki.jos.004631
NR 20
TC 1
Z9 1
BN 978-1-5386-2165-3
PY 2017
BP 2291
EP 2295
UT WOS:000437355302051
ER

PT B
AU Dai, MJ
   Huang, SS
   Zhong, JP
   Yang, CG
   Yang, SW
AF Dai, Mingjun
   Huang, Shansong
   Zhong, Junpei
   Yang, Chenguang
   Yang, Shiwei
BE Liu, Y
   Zhao, L
   Cai, G
   Xiao, G
   Li, KL
   Wang, L
TI Influence of Noise on Transfer Learning in Chinese Sentiment
   Classification using GRU
SO 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS
   AND KNOWLEDGE DISCOVERY (ICNC-FSKD)
CT 13th International Conference on Natural Computation, Fuzzy Systems and
   Knowledge Discovery (ICNC-FSKD)
CY JUL 29-31, 2017
CL Guilin, PEOPLES R CHINA
DE sentiment classification; neural network; Gated Recurrent Unit; transfer
   learning
AB Sentiment classification for product reviews is of great significance for business feedback for manufactures, sellers and users. However, since a large amount of training data for a specific product domain is not always available, transfer learning is often utilized to do sentiment analysis applications. Specifically, after a pre-training of the large Chinese corpus by a word-embedding method, a larger size of training data for a specific domain was trained using a Gated Recurrent Unit. And then the trained model was used for testing the sentiment classification for a smaller amount of product reviews. The performances of this transfer learning method was also examined, especially to testify different factors affecting the performance of the transfer learning. The experimental results showed that different wording in the review domain (which we call it "noise") will have a greater impact on transfer learning. We also calculate the difference of the wording to verify our hypothesis. According to these results, we have explored the impacts of the dataset wording, while we are doing Chinese text sentiment classification. We also shed a light in optimizing the transfer learning effect in general.
CR BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   CesaBianchi N, 1997, J ACM, V44, P427, DOI 10.1145/258128.258179
   Chung J., 2014, CORR
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Daum H., 2009, ARXIV09071815
   Ding X, 2008, P 2008 INT C WEB SEA, P231, DOI DOI 10.1145/1341531.1341561
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hinton G. E., 2012, ARXIV12070580
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Jiang J., 2007, ACL, V7, P264
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Mikolov T., 2013, COMPUTING RES REPOSI, V1301, P3781, DOI DOI 10.1109/TNN.2003.820440]
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79
   Pang B., 2005, P 43 ANN M ASS COMP, V43, P115, DOI DOI 10.3115/1219840.1219855
   Snyder Benjamin, 2007, HLT NAACL, P300
   Socher R., 2011, P C EMP METH NAT LAN, P151
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang D., 2015, P 2015 C EMP METH NA, P1422, DOI DOI 10.18653/V1/D15-1167
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu P., 2004, P 21 INT C MACH LEAR, P110
   Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072
   Zhong J., 2017, INT JOINT C ART NEUR
   Zhong J., 2017, DEV LEARN EP ROB ICD
NR 30
TC 0
Z9 0
BN 978-1-5386-2165-3
PY 2017
UT WOS:000437355301140
ER

PT S
AU Zhao, CJ
   Wang, SG
   Li, DY
AF Zhao, Chuanjun
   Wang, Suge
   Li, Deyu
BE Cheng, X
   Ma, W
   Liu, H
   Shen, H
   Feng, S
   Xie, X
TI Deep Transfer Learning for Social Media Cross-Domain Sentiment
   Classification
SO SOCIAL MEDIA PROCESSING, SMP 2017
SE Communications in Computer and Information Science
CT 6th National Conference on Social Media Processing (SMP)
CY SEP 14-17, 2017
CL Beijing, PEOPLES R CHINA
DE Transfer learning; Long short-term memory; Parameters transfer;
   Cross-domain sentiment classification
AB Social media sentiment classification has important theoretical research value and broad application prospects. Deep neural networks have been applied into social media sentiment mining tasks successfully with excellent representation learning and high efficiency classification abilities. However, it is very difficult to collect and label large scale training data for deep learning. In this case, deep transfer learning (DTL) can transfer abundant source domain knowledge to target domain using deep neural networks. In this paper, we propose a two-stage bidirectional long short-term memory (Bi-LSTM) and parameters transfer framework for short texts cross-domain sentiment classification tasks. Firstly, Bi-LSTM networks are pre-trained on a large amount of fine-labeled source domain training data. We fine-tune the pre-trained Bi-LSTM networks and transfer the parameters using target domain training data and continuing back propagation. The fine-tuning strategy is to transfer bottom-layer (general features) and retrain top-layer (specific features) to the target domain. Extensive experiments on four Chinese social media data sets show that our method outperforms other baseline algorithms for cross-domain sentiment classification tasks.
OI Li, Deyu/0000-0003-2489-9404
CR Ge W., 2017, ARXIV170208690
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Guan L, 2016, COMM COM INF SC, V669, P85, DOI 10.1007/978-981-10-2993-6_7
   Haaren J. V., 2015, P 29 AAAI C ART INT, P3007
   Huang M., 2016, ARXIV160501478
   Kandaswamy C, 2015, LECT NOTES COMPUT SC, V9094, P335, DOI 10.1007/978-3-319-19258-1_29
   Kotzias D., 2014, ARXIV14113128
   Li S., 2013, P 23 INT JOINT C ART, P2127
   Long M., 2015, INT C MACH LEARN, P97
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Pan Sinno Jialin, 2010, P 19 INT C WORLD WID, P751, DOI DOI 10.1145/1772690.1772767
   Papernot N, 2016, ARXIV161005755
   Tan S., 2007, P 16 ACM C C INF KNO, P979, DOI DOI 10.1145/1321440.1321590
   Tang  D., 2015, ARXIV151201100
   Tang J, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2746230
   Wang J., 2016, P 54 ANN M ASS COMP, V2016, P225, DOI DOI 10.18653/V1/P16-2037
   Wang SG, 2013, KNOWL-BASED SYST, V37, P451, DOI 10.1016/j.knosys.2012.09.003
   Wang SG, 2011, EXPERT SYST APPL, V38, P8696, DOI 10.1016/j.eswa.2011.01.077
   Zhao CJ, 2014, 2014 IEEE International Conference on Data Mining Workshop (ICDMW), P1191, DOI 10.1109/ICDMW.2014.137
NR 19
TC 0
Z9 0
SN 1865-0929
EI 1865-0937
BN 978-981-10-6805-8; 978-981-10-6804-1
PY 2017
VL 774
BP 232
EP 243
DI 10.1007/978-981-10-6805-8_19
UT WOS:000437040400019
ER

PT S
AU Weiss, KR
   Khoshgoftaar, TM
AF Weiss, Karl R.
   Khoshgoftaar, Taghi M.
GP IEEE
TI Evaluation of Transfer Learning Algorithms using Different Base Learners
SO 2017 IEEE 29TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI 2017)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT IEEE 29th International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 06-08, 2017
CL Boston, MA
DE Transfer learning; Traditional machine learning; Test framework
ID UNSUPERVISED DOMAIN ADAPTATION
AB In the field of supervised machine learning, a transfer learning environment is defined as the training data having different distribution characteristics than the testing data. This is due to the lack of available labeled data for the domain of interest, which prompts an alternate domain to be used as the training data. Because there is insufficient labeled data from the domain of interest, validation techniques cannot be reliably used for the algorithm selection process in a transfer learning environment. A transfer learning algorithm is typically comprised of a domain adaptation step followed by a learning step. The learning step is usually implemented using a traditional machine learning algorithm. In this paper, we examine and analyze the impact that the traditional machine learning algorithm (the learning step) has on the overall performance of a transfer learning algorithm. Using the transfer learning test framework, we test five state-of-the-art transfer learning algorithms coupled with seven different traditional learning algorithms for a total of 35 unique transfer learning algorithms. For our experiment, no labeled data from the domain of interest is available for the training process. Since validation techniques cannot be reliably used for the algorithm selection process in a transfer learning environment, it is important for machine learning researchers and practitioners to understand the impact of a traditional machine learner on the overall performance of a transfer learning algorithm.
CR Abdi H., 2010, ENCY RES DESIGN, P1, DOI [DOI 10.4135/9781412961288.N178, 10.4135/9781412961288]
   Aha D. W., 1997, LAZY LEARNING
   Freund R. J., 1981, SAS LINEAR MODELS GU, V1
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gretton A., 2006, P ADV NEUR INF PROC, P513
   Hastie T, 1996, J ROY STAT SOC B MET, V58, P155
   Kendall M. G, 1990, RANK CORRELATION MET
   Khoshgoftaar T., 1999, INT J RELIABILITY QU, V6, P303
   Khoshgoftaar TM, 2007, PROC INT C TOOLS ART, P310, DOI 10.1109/ICTAI.2007.46
   Lichman M, 2013, UCI MACHINE LEARNING
   Lin Chih-Jen, LIBSVM LIB SUPPORT V
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Quinlan J., 1993, C4 5 PROGRAMS MACHIN
   Roweis S., SAM ROWEIS DATA
   Scholkopf B, 1999, ADV KERNEL METHODS S
   Shi  Yuan, 2012, P INT C MACH LEARN, P1079
   Shimodaira H., 2000, J STAT PLAN INFER, V90
   The MathWorks Inc, MATL STAT TOOLB REL
   Wald Randall, 2013, 2013 IEEE 14th International Conference on Information Reuse & Integration (IRI), P232, DOI 10.1109/IRI.2013.6642477
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Weiss KR, 2017, 2017 IEEE 18TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI 2017), P338, DOI 10.1109/IRI.2017.43
   Weiss KR, 2016, PROC INT C TOOLS ART, P283, DOI [10.1109/ICTAI.2016.0051, 10.1109/ICTAI.2016.48]
   Weiss KR, 2016, PROCEEDINGS OF 2016 IEEE 17TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI), P152, DOI 10.1109/IRI.2016.27
   Witten IH, 2011, MOR KAUF D, P3, DOI 10.1016/B978-0-12-374856-0.00001-8
   Xia R, 2013, IEEE INTELL SYST, V28, P10, DOI 10.1109/MIS.2013.27
   Zhang K., 2008, P 25 INT C MACH LEAR, P1232, DOI DOI 10.1145/1390156.1390311
   Zhong EH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1027
NR 32
TC 0
Z9 0
SN 1082-3409
BN 978-1-5386-3876-7
PY 2017
BP 187
EP 196
DI 10.1109/ICTAI.2017.00039
UT WOS:000435294700028
ER

PT S
AU Liu, BL
   Lyu, XZ
   Li, C
   Zhang, SY
   Hong, ZJ
   Ye, XZ
AF Liu, Baolong
   Lyu, Xingzheng
   Li, Chao
   Zhang, Sanyuan
   Hong, Zhenjie
   Ye, Xiuzi
GP IEEE
TI Using transferred deep model in combination with prior features to
   localize multi-style ship license numbers in nature scenes
SO 2017 IEEE 29TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI 2017)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT IEEE 29th International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 06-08, 2017
CL Boston, MA
DE Ship License Numbers localization; Convolution Neural Network; Text
   Detection
AB Ship License Numbers (SLNs) localization is an important part of waterway intelligent transportation systems. Unfortunately, this issue has been neglected for a long time. In this paper, we present an effective approach for localizing multi-style SLNs in nature scenes. The problem of locating SLNs is posed as the detection of character sequences which possess SLNs prior features. First, faced with the difficulty of no training data, a transfer learning-based deep convolutional neural network is designed to detect character sequences in SLNs. In the second step, to accurately locate SLNs from the detected character sequences, the prior features of SLNs are considered. Three SLNs prior features are summarized. An SLNs region generating algorithm and a low-level similarity-based fake SLNs filtering algorithm are presented, respectively. The accurate positions of the SLNs in the input image are obtained in this stage. The proposed approach is finally tested on ZJUSHIPS950 dataset. The approach achieves a FPPI of 0.42 and a F-measure of 0.614 on 1374 labeled SLNs, surpassing several related methods by a large margin. Controlled experiment results also prove the impressive performances of the proposed SLNs region generating and fake SLNs filtering algorithms.
CR Bo Li, 2012, 2012 9th IEEE International Conference on Networking, Sensing and Control (ICNSC), P399, DOI 10.1109/ICNSC.2012.6204952
   Dollar P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Gomez L, 2013, PROC INT CONF DOC, P467, DOI 10.1109/ICDAR.2013.100
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   Liao M., 2017, AAAI
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Ojala T., 2000, MULTIRESOLUTION GRAY
   Puzicha J., 1999, P IEEE INT C COMP VI, P25
   Simonyan K., 2014, COMPUTER SCI
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
NR 10
TC 0
Z9 0
SN 1082-3409
BN 978-1-5386-3876-7
PY 2017
BP 506
EP 510
DI 10.1109/ICTAI.2017.00083
UT WOS:000435294700072
ER

PT S
AU Baykara, HC
   Biyik, E
   Gul, G
   Onural, D
   Ozturk, AS
   Yildiz, I
AF Baykara, Huseyin Can
   Biyik, Erdem
   Gul, Gamze
   Onural, Deniz
   Ozturk, Ahmet Safa
   Yildiz, Ilkay
GP IEEE
TI Real-Time Detection, Tracking and Classification of Multiple Moving
   Objects in UAV Videos
SO 2017 IEEE 29TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI 2017)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT 29th Annual IEEE International Conference on Tools with Artificial
   Intelligence (ICTAI)
CY NOV 06-08, 2017
CL Boston, MA
DE surveillance; moving object detection; object tracking; aerial image
   classification; deep learning; transfer learning; real time; low
   altitude; aerial video; automation
AB Unnamed Aerial Vehicles (UAVs) are becoming increasingly popular and widely used for surveillance and reconnaissance. There are some recent studies regarding moving object detection, tracking, and classification from UAV videos. A unifying study, which also extends the application scope of such previous works and provides real-time results, is absent from the literature. This paper aims to fill this gap by presenting a framework that can robustly detect, track and classify multiple moving objects in real-time, using commercially available UAV systems and a common laptop computer. The framework can additionally deliver practical information about the detected objects, such as their coordinates and velocities. The performance of the proposed framework, which surpasses human capabilities for moving object detection, is reported and discussed.
RI Gul, Gamze/U-4051-2018
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cai GW, 2011, ADV IND CONTROL, P1, DOI 10.1007/978-0-85729-635-1_1
   Dedeoglu Y., 2004, THESIS
   Iandola F., 2016, ARXIV160207360
   Itseez, 2015, OP SOURC COMP VIS LI
   Iwashita Y., 2013, BMVC, V1, P6
   Jia Y., 2014, ARXIV14085093
   Joglekar J., 2012, INT J EMERG TECHNOL, V2, P130
   Kale Kiran, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359323
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mattyus G., 2010, MULTITARGET TRACKING
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Moller B, 2008, Pattern Recognition and Image Analysis, V18, P201, DOI 10.1134/S105466180802003X
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Reilly V., 2012, DETECTING TRACKING R
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430
   Singla N., 2014, INT J INFORM COMPUT, V4, P1559
   Walha A, 2013, LECT NOTES COMPUT SC, V8192, P310, DOI 10.1007/978-3-319-02895-8_28
   Zhan CH, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P519, DOI 10.1109/ICIG.2007.153
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 24
TC 1
Z9 1
SN 1082-3409
BN 978-1-5386-3876-7
PY 2017
BP 945
EP 950
DI 10.1109/ICTAI.2017.00145
UT WOS:000435294700134
ER

PT S
AU Lucena, O
   Junior, A
   Moia, V
   Souza, R
   Valle, E
   Lotufo, R
AF Lucena, Oeslle
   Junior, Amadeu
   Moia, Vitor
   Souza, Roberto
   Valle, Eduardo
   Lotufo, Roberto
BE Karray, F
   Campilho, A
   Cheriet, F
TI Transfer Learning Using Convolutional Neural Networks for Face
   Anti-spoofing
SO IMAGE ANALYSIS AND RECOGNITION, ICIAR 2017
SE Lecture Notes in Computer Science
CT 14th International Conference on Image Analysis and Recognition (ICIAR)
CY JUL 05-07, 2017
CL Montreal, CANADA
DE Face anti-spoofing; Transfer learning; Deep learning; Face recognition
ID IMAGE
AB Face recognition systems are gaining momentum with current developments in computer vision. At the same time, tactics to mislead these systems are getting more complex, and counter-measure approaches are necessary. Following the current progress with convolutional neural networks (CNN) in classification tasks, we present an approach based on transfer learning using a pre-trained CNN model using only static features to recognize photo, video or mask attacks. We tested our approach on the REPLAY-ATTACK and 3DMAD public databases. On the REPLAY-ATTACK database our accuracy was 99.04% and the half total error rate (HTER) of 1.20%. For the 3DMAD, our accuracy was of 100.00% and HTER 0.00%. Our results are comparable to the state-of-the-art.
RI Lotufo, Roberto/C-1496-2009
OI Lotufo, Roberto/0000-0002-5652-0852
CR Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   Amos B., 2016, CMUCS16118
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Bastien F, 2012, DEEP LEARN UNS FEAT
   Chingovska I., 2012, P INT C BIOM SPEC IN, P1
   Chollet  F., 2015, KERAS
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   Duch W., 1999, NEURAL COMPUTING SUR, V2, P163
   Erdogmus N., 2013, P IEEE 6 INT C BIOM, V2, P1, DOI DOI 10.1109/BTAS.2013.6712688
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He K., 2016, IEEE C COMP VIS PATT
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Kollreider K, 2008, PROC CVPR IEEE, P1200
   Komulainen Jukka, 2013, BIOM THEOR APPL SYST, P1
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li JW, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2852, DOI 10.1109/ICMLC.2008.4620894
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seal A., 2013, ABS13091000 CORR
   Sharif Razavian A., 2014, IEEE C COMP VIS PATT
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504
   Wang Liting, 2009, Tsinghua Science and Technology, V14, P685, DOI 10.1016/S1007-0214(09)70135-X
   Yang J., 2014, ABS14085601 CORR
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 36
TC 3
Z9 3
SN 0302-9743
EI 1611-3349
BN 978-3-319-59876-5; 978-3-319-59875-8
PY 2017
VL 10317
BP 27
EP 34
DI 10.1007/978-3-319-59876-5_4
UT WOS:000432877600004
ER

PT S
AU Dahmane, M
   Foucher, S
   Byrns, D
AF Dahmane, M.
   Foucher, S.
   Byrns, D.
BE Karray, F
   Campilho, A
   Cheriet, F
TI Are You Smiling as a Celebrity? Latent Smile and Gender Recognition
SO IMAGE ANALYSIS AND RECOGNITION, ICIAR 2017
SE Lecture Notes in Computer Science
CT 14th International Conference on Image Analysis and Recognition (ICIAR)
CY JUL 05-07, 2017
CL Montreal, CANADA
DE Face analysis; Smile detection; Gender recognition; Deep learning
AB Person gender detection is an important feature in many vision-based research fields including surveillance, human computer interaction, Biometrics, stratified behavior understanding, and content based indexing. Researchers are still facing big challenges to establish automated systems to recognize gender from images where human face represents the most important source of information. In the present study, we elaborated and validated a methodology for gender perception by transfer learning. First, the face is located and the corresponding cropped image is fed to a pre-trained convolutional neural network, the generated deep "latent" features are used to train a linear-SVM classifier. The overall classification performance reached 90.69% on the FotW validation set and 91.52% on the private test set.
   In this paper, we investigated also whether these features can deliver a smile recognizer. A similar trained architecture for classification of smiling and non-smiling faces gave a rate of 88.14% on the validation set and 82.12% on the private test set.
OI Foucher, Samuel/0000-0001-9557-6907
CR Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Castrillon-Santana M, 2017, COMPUT VIS IMAGE UND, V156, P4, DOI 10.1016/j.cviu.2016.09.004
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Demirkus M., 2010, P IEEE COMP SOC C CO, P55
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Huang G. B., 2007, 0749 U MASS
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Ng C. B, 2012, ARXIV12041611
   Nian F., 2015, P 7 INT C INT MULT C
   Parkhi  O.M., 2015, P BRIT MACH VIS C BM
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Vedaldi A., 2014, CORR
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
NR 14
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-59876-5; 978-3-319-59875-8
PY 2017
VL 10317
BP 304
EP 311
DI 10.1007/978-3-319-59876-5_34
UT WOS:000432877600034
ER

PT S
AU Farazi, M
   Abbas-Zadeh, MJ
   Moradi, H
AF Farazi, Mohammad
   Abbas-Zadeh, Mohammad Javad
   Moradi, Hadi
GP IEEE
TI A machine vision based pistachio sorting using transferred mid-level
   image representation of Convolutional Neural Network
SO 2017 10TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING
   (MVIP)
SE Iranian Conference on Machine Vision and Image Processing
CT 10th Iranian Conference on Machine Vision and Image Processing (MVIP)
CY NOV 22-23, 2017
CL Isfahan Univ Technol, Isfahan, IRAN
HO Isfahan Univ Technol
DE Active contour; Convolutional Neural Netwrok; transfer learning; image
   segmentation; Support Vector machine; Pistachio sorting
AB Convolutional neural networks have proved to be prominent in various fields of machine vision and image classification. Although it necessitates a large-scale dataset for promising performance, the mid-level representation of these networks can be exploited for specified tasks with smaller annotated image dataset. To this end, by evaluating the generality specificity of the desired layer as a feature extractor layer, the parameters of Convolutional Neural Networks learned on massive-size dataset like ImageNet can be transferred to a new model. In this study, the images of different sort of pistachios including trashes have been acquired to feed into a new model using a support vector classifier. The ultimate goal of our machine vision system is to separate the desired open-shell pistachios from other defected pistachios as well as trashes. For image segmentation, we use active contour method to detect objects and form both new images of each object type and their augmented images. Since our dataset is not large-scale compared to ImageNet classes, a feature reduction method is performed after the feature extractor layer of pre-trained Convolutional Neural Network. The results show the better performance of the proposed approach in detection of desired-formed pistachio facing unseen test set of images compared to basic approaches.
CR Blasco J, 2009, J FOOD ENG, V90, P27, DOI 10.1016/j.jfoodeng.2008.05.035
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Griffin G., 2007, CALTECH UNPUB, V11, P20
   Jha SN, 2010, NONDESTRUCTIVE EVALUATION OF FOOD QUALITY: THEORY AND PRACTICE, P1, DOI 10.1007/978-3-642-15796-7
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lowe G., 2004, INT J, V2, P91, DOI DOI 10.1023/B:VISI.0000029664.99615.94
   Omid M, 2011, EXPERT SYST APPL, V38, P4339, DOI 10.1016/j.eswa.2010.09.103
   Omid M, 2009, EXPERT SYST APPL, V36, P11528, DOI 10.1016/j.eswa.2009.03.040
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Sankaran S., 2016, ENG AGR ENV FOOD, V9, P50, DOI [10.1016/j.eaef.2015.06.001, DOI 10.1016/J.EAEF.2015.06.001]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yosinski J., 2014, ADV NEURAL INF PROCE, V27, P1
NR 15
TC 0
Z9 0
SN 2166-6776
BN 978-1-5386-4405-8
PY 2017
BP 145
EP 148
UT WOS:000434974500027
ER

PT S
AU Yang, TQ
   Huang, SX
AF Yang, Tianqi
   Huang, Shuangxi
BE Pang, Z
   Li, L
   Li, G
TI Fault Diagnosis Based on improved Deep Belief Network
SO 2017 5TH INTERNATIONAL CONFERENCE ON ENTERPRISE SYSTEMS (ES)
SE International Conference on Enterprise Systems (ES)
CT 5th International Conference on Enterprise Systems (ES) - Industrial
   Digitalization by Enterprise Systems
CY SEP 22-24, 2017
CL Beijing, PEOPLES R CHINA
DE DBN; RBM; Semi-supervised; Rectified Linear Units; Transfer Learning
ID CLASSIFICATION; REGRESSION; PROGNOSIS; MACHINE
AB A fault diagnosis method based on improved Deep Belief Network is proposed. This paper proposed an network named Semi-DBN, which adapts an adaptive semi supervised method to train the RBM structure to improve the performance of DBN, replaces the Sigmoid activation function with Rectified Linear Units to improve the performance of the network, and combines the model with Transfer Learning to solve the problem of lack of data. It can get rid of the dependence of the traditional machine learning methods on the extraction of the sample characteristics, and effectively overcome the problem of gradient vanishing, local extremum and so on. The identification and generalization ability of the method is verified when we used it in the experiment of rolling bearing data.
CR [Anonymous], 2002, MECH SYSTEMS SIGNAL, V16, P817
   Bengio Y., 2007, P ADV NEUR INF PROC, P153
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Biagetti T, 2004, ENERGY, V29, P2553, DOI 10.1016/j.energy.2004.03.031
   Bunks C, 2000, MECH SYST SIGNAL PR, V14, P597, DOI 10.1006/mssp.2000.1309
   Caesarendra W, 2010, MECH SYST SIGNAL PR, V24, P1161, DOI 10.1016/j.ymssp.2009.10.011
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kacprzynski GJ, 2004, JOM-US, V56, P29, DOI 10.1007/s11837-004-0029-2
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee  H., 2009, P ANN INT C MACH LEA, P609, DOI [DOI 10.1145/1553374.1553453, 10.1145/1553374.1553453]
   Luo JH, 2003, AUTOTESTCON 2003, PROCEEDINGS, P330
   Mikolov T, 2010, NTFRSPEECH, V2, P3
   Oppenheimer CH, 2002, P SOC PHOTO-OPT INS, V4733, P122, DOI 10.1117/12.475502
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qiu J., 1999, J MECH SYSTEMS SIGNA, V2, P385
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Rao BKN, 2012, J PHYS CONF SER, V364, DOI 10.1088/1742-6596/364/1/012023
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Simonyan K, ARXIV14091556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tran V, 2010, CONTROL CYBERN, V39, P25
NR 23
TC 0
Z9 0
SN 2377-8636
EI 2572-6609
BN 978-1-5386-0936-1
PY 2017
BP 305
EP 310
DI 10.1109/ES.2017.57
UT WOS:000434642300050
ER

PT S
AU Cheng, Q
   Wang, XK
   Shen, LC
AF Cheng, Qiao
   Wang, Xiangke
   Shen, Lincheng
BE Liu, T
   Zhao, Q
TI Transfer Learning via Linear Multi-variable Mapping under Reinforcement
   Learning Framework
SO PROCEEDINGS OF THE 36TH CHINESE CONTROL CONFERENCE (CCC 2017)
SE Chinese Control Conference
CT 36th Chinese Control Conference (CCC)
CY JUL 26-28, 2017
CL Dalian, PEOPLES R CHINA
DE Transfer Learning; Reinforcement Learning; Linear Multi-variable
   Mapping; Inter-task Mapping; Keepaway
AB Though popular in many agent learning tasks, reinforcement learning still faces problems, such as long learning time in complex environment. Transfer learning could shorten the learning time and improve the performance in reinforcement learning by reusing the knowledge acquired from different but related source task. Due to the difference in state space and/or action space of the target and source task, transfer via inter-task mapping is a popular method. The design of the inter-task mapping is very critical to this transfer learning method. In this paper, we propose a linear multi-variable mapping (LMVM) for the transfer learning to make a better use of the knowledge learned from the source task. Unlike the inter-task mapping used before, the LMVM is not a one-to-one mapping but a one-to-many mapping, which is based on the idea that the element in target task is related with several similar elements from source task. We test transfer learning via our new mapping on the Keepaway platform. The experimental results show that our method could make the reinforcement learning agents learn much faster than those without transfer and those transfer with simpler mappings.
CR Ammar Haitham Bou, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P449, DOI 10.1007/978-3-642-40991-2_29
   Fachantidis A., 2011, EUR WORKSH REINF LEA, P225
   Fachantidis A, 2015, ADAPT BEHAV, V23, P3, DOI 10.1177/1059712314559525
   Konidaris G, 2012, J MACH LEARN RES, V13, P1333
   Stone P., 2005, ROBOCUP 2005 ROBOT S, P93
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   Taylor M. E., 2008, 7 INT JOINT C AUT AG
   Taylor ME, 2007, J MACH LEARN RES, V8, P2125
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
NR 9
TC 1
Z9 1
SN 2161-2927
BN 978-9-8815-6393-4
PY 2017
BP 8795
EP 8799
UT WOS:000432015502148
ER

PT S
AU Wang, ZQ
   Liu, J
AF Wang Zhiqiang
   Liu Jun
BE Liu, T
   Zhao, Q
TI A Review of Object Detection Based on Convolutional Neural Network
SO PROCEEDINGS OF THE 36TH CHINESE CONTROL CONFERENCE (CCC 2017)
SE Chinese Control Conference
CT 36th Chinese Control Conference (CCC)
CY JUL 26-28, 2017
CL Dalian, PEOPLES R CHINA
DE Convolutional Neural Network; object detection; region proposal;
   regression; datasets
AB With the development of intelligent device and social media, the data bulk on Internet has grown with high speed. As an important aspect of image processing, object detection has become one of the international popular research fields. In recent years, the powerful ability with feature learning and transfer learning of Convolutional Neural Network (CNN) has received growing interest within the computer vision community, thus making a series of important breakthroughs in object detection. So it is a significant survey that how to apply CNN to object detection for better performance. First the paper introduced the basic concept and architecture of CNN. Secondly the methods that how to solve the existing problems of conventional object detection are surveyed, mainly analyzing the detection algorithm based on region proposal and based on regression. Thirdly it mentioned some means which improve the performance of object detection. Then the paper introduced some public datasets of object detection and the concept of evaluation criterion. Finally, it combed the current research achievements and thoughts of object detection, summarizing the important progress and discussing the future directions.
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bouvrie J., 2006, NEURAL NETS
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Chumerin N., 2015, CONVOLUTIONAL NEURAL
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Donahue J., 2013, COMPUTER SCI, V50, P815
   Felzenszwalb P. F., 2014, IEEE T SOFTWARE ENG, V32, P1627
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hoiem D, 2008, WORLD LIT TODAY
   Huang K. Q., 2014, CHINESE J COMPUTERS
   Kim K. -H., 2016, PVANET DEEP LIGHTWEI
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, SSD SINGLE SHOT MULT
   Nixon, 2013, FEATURE EXTRACTION I
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J., 2015, COMPUTER SCI
   Ren SJF, 2017, INT J PROD RES, V55, P5011, DOI 10.1080/00207543.2016.1154209
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shang W, 2016, UNDERSTANDING IMPROV
   Shrivastava A., 2016, TRAINING REGION BASE
   Simonyan K., 2014, COMPUTER SCI
   Szegedy C., 2013, ADV NEURAL INFORM PR, V26, P2553
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wu H., 2015, MAX POOLING DROPOUT
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng X., 2016, GATED BIDIRECTIONAL
   Zhang Xin, 2013, ACM COMPUT SURV, V46, P28
   Zitnick C. L., 2014, EDGE BOXES LOCATING
NR 37
TC 4
Z9 5
SN 2161-2927
BN 978-9-8815-6393-4
PY 2017
BP 11104
EP 11109
UT WOS:000432015504178
ER

PT S
AU Cai, GY
   Lv, GR
AF Cai, Guoyong
   Lv, Guangrui
GP IEEE
TI Heterogeneous Transfer with Deep Latent Correlation for Sentiment
   Analysis
SO 2017 10TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND
   DESIGN (ISCID), VOL 2
SE International Symposium on Computational Intelligence and Design
CT 10th International Symposium on Computational Intelligence and Design
   (ISCID)
CY DEC 09-10, 2017
CL Hangzhou, PEOPLES R CHINA
DE image sentiment analysis; multi-modal embedding; heterogeneous transfer
   learning; multimodal deep learning
ID RECOGNITION
AB Most traditional methods of image sentiment analysis focus on the design of visual features, and the usefulness of texts associated to the images have not been sufficiently investigated. Heterogeneous transfer learning has recently gained much attention as a new machine learning paradigm in which knowledge can be transferred from source domain feature space to target domain feature space. This paper proposes a novel approach that exploits deep latent correlation between visual and textual modalities. In our proposed method, we build a latent embedding space for symmetric heterogeneous feature transfer. The latent space is able to generate domain-specific and maximally correlative cross-domain features which are regarded as the semantic-intensive visual feature representation and used to train sentiment polarity classifiers. The results of experiments conducted on real-world data sets show that the proposed approach can achieve better sentiment classification accuracy by using multi-layer neural network to capture deeper internal relations.
CR Andrew G., 2013, P 30 INT C MACH LEAR, V28, P1247
   Bo Zhang, 2013, 2013 IEEE International Conference on Big Data, P493, DOI 10.1109/BigData.2013.6691612
   BORTH D., 2013, P 21 ACM INT C MULT, P223, DOI DOI 10.1145/2502081.2502282
   Borth  Damian, 2013, P 21 ACM INT C MULT, P459
   Cai GY, 2015, LECT NOTES ARTIF INT, V9362, P159, DOI 10.1007/978-3-319-25207-0_14
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Jing XY, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P496, DOI 10.1145/2786805.2786813
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rasiwasia  N., 2010, P ACM MULT 2010, P251, DOI [DOI 10.1145/1873951.1873987, 10.1145/1873951.1873987]
   Sagha H, 2016, INT CONF ACOUST SPEE, P5800, DOI 10.1109/ICASSP.2016.7472789
   Siersdorfer S., 2010, P 18 ACM INT C MULT, P715, DOI [10.1145/1873951.1874060, DOI 10.1145/1873951.1874060]
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu XX, 2013, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2013.81
   Yang L, 2015, IEEE T IMAGE PROCESS, V24, P4701, DOI 10.1109/TIP.2015.2465157
   Yeh Y, 2013, IEEE T IMAGE PROCESS, P2009
   You Q, 2015, 29 AAAI C ART INT AA
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   Yuan J., 2013, WISDOM
   Zhu  Y., 2011, P 25 AAAI C ART INT, P1304
NR 26
TC 0
Z9 0
SN 2165-1701
BN 978-1-5386-3674-9
PY 2017
BP 252
EP 256
DI 10.1109/ISCID.2017.172
UT WOS:000426978600054
ER

PT B
AU Pereira, FLF
   Lima, FDS
   Leite, LGM
   Gomes, JPP
   Machado, JC
AF Pereira, Francisco Lucas F.
   Lima, Fernando Dione S.
   Leite, Lucas G. M.
   Gomes, Joao Paulo P.
   Machado, Javam C.
GP IEEE
TI Transfer Learning for Bayesian Networks with Application on Hard Disk
   Drives Failure Prediction
SO 2017 6TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS)
CT 6th Brazilian Conference on Intelligent Systems (BRACIS)
CY OCT 02-05, 2017
CL Uberlandia, BRAZIL
AB Predicting failure in Hard Disk Drives (HDD) is of fundamental importance for data loss avoidance as well as to lower the downtime costs of a system. As a consequence, an increasing effort may be observed from both universities and industry to find suitable failure prediction methods. Despite the encouraging performances achieved by various methods one important aspect that shall be noticed is the lack of data available to build reliable models. Considering the HDD failure prediction task, this problem arises with the numerous HDD models. To overcome such problem, transfer learning strategies offer a valid alternative since it can be used to transfer learning from HDD model with enough data to build failure prediction methods for HDD models with lack of data. In this work we evaluate several transfer learning strategies in the task of HDD failure prediction. Additionally we propose a new strategy to build information sources based on the clustering of similar HDD models. This approach may be a valid alternative when no HDD model has enough data to generate a reliable model. Results showed that all transfer learning scenarios can improve the performance of HDDs failure prediction methods, mainly for HDDs with very limited data. Moreover, the clustering-based information source also results in performance gains in all transfer methods and HDD models tested.
CR Ankan A., 2015, P 14 PYTH SCI C SCIP
   Backblaze, 2016, HARD DRIV DAT STATS
   Chaves IC, 2016, PROCEEDINGS OF 2016 5TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS 2016), P427, DOI [10.1109/BRACIS.2016.083, 10.1109/BRACIS.2016.81]
   Chi JT, 2016, AM STAT, V70, P91, DOI 10.1080/00031305.2015.1086685
   Duygulu P, 2016, PATTERN ANAL APPL, V19, P647, DOI 10.1007/s10044-014-0420-8
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hess A., 2006, INTELLIGENT FAULT DI
   Hughes GF, 2002, IEEE T RELIAB, V51, P350, DOI 10.1109/tTR.2002.802886
   Li RP, 2014, IEEE T WIREL COMMUN, V13, P2000, DOI 10.1109/TWC.2014.022014.130840
   Luis R, 2010, MACH LEARN, V79, P227, DOI 10.1007/s10994-009-5160-4
   McKinney W., 2008, PANDAS PYTHON DATA A
   Mesquita D. P., 2016, EUR S ART NEUR NETW
   Murray JF, 2005, J MACH LEARN RES, V6, P783
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pearl J., 1988, PROBABILISTIC REASON
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Queiroz L. P., 2016, IEEE T IND INFORM
   Queiroz L. P., 2016, 2016 BRAZ C INT SYST
   Shopbell P., 2005, ASP C SERIES, V30, P1297
   Spirtes P, 2000, CAUSATION PREDICTION
   Wai Lam, 1994, Computational Intelligence, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x
   Wang Y, 2014, IEEE T IND INFORM, V10, P419, DOI 10.1109/TII.2013.2264060
   Wang Y, 2013, IEEE T RELIAB, V62, P136, DOI 10.1109/TR.2013.2241204
   Xu C, 2016, IEEE T COMPUT, V65, P3502, DOI 10.1109/TC.2016.2538237
   Yuan Y, 2017, IEEE J-STARS, V10, P1963, DOI 10.1109/JSTARS.2017.2655112
   Zhou Y, 2016, EXPERT SYST APPL, V55, P361, DOI 10.1016/j.eswa.2016.02.011
NR 26
TC 0
Z9 0
BN 978-1-5386-2407-4
PY 2017
BP 228
EP 233
DI 10.1109/BRACIS.2017.64
UT WOS:000428685400039
ER

PT S
AU Su, X
   Yao, Y
   He, Q
   Lu, J
   Tong, HH
AF Su, Xing
   Yao, Yuan
   He, Qing
   Lu, Jie
   Tong, Hanghang
BE Nie, JY
   Obradovic, Z
   Suzumura, T
   Ghosh, R
   Nambiar, R
   Wang, C
   Zang, H
   BaezaYates, R
   Hu, X
   Kepner, J
   Cuzzocrea, A
   Tang, J
   Toyoda, M
TI Personalized Travel Mode Detection with Smartphone Sensors
SO 2017 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
CT IEEE International Conference on Big Data (IEEE Big Data)
CY DEC 11-14, 2017
CL Boston, MA
ID ACTIVITY RECOGNITION
AB Detecting the travel modes such as walking and driving a car is an important task for user behavior understanding as well as transportation planning and management. Existing solutions for this task mainly train a generic classifier for all users although the walking or driving behaviors may differ greatly from one user to another. In this paper, we propose to build a personalized travel mode detection method. In particular, the proposed method can be divided into two stages. First, for a given target user, it applies user similarity computation to borrow data from a set of pre-collected data for transfer learning. Second, it estimates the data distribution in feature space, and uses it to reweight the borrowed data so as to minimize the model loss with respect to the target user. Experimental evaluations on real travel data show that the proposed method outperforms the generic method and the transfer learning method with kernel mean matching in terms of prediction accuracy.
CR [Anonymous], 2017, SENSOR DATA
   Araki M., 2017, SERVICEOLOGY SMART S
   Bamberg S, 2003, BASIC APPL SOC PSYCH, V25, P175, DOI 10.1207/S15324834BASP2503_01
   Chen M. - F., 2016, J CLEANER PRODUCTION
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Ding N., 2014, TRANSPORTATION RES R
   Ding N, 2015, IEEE T INTELL TRANSP, V16, P2467, DOI 10.1109/TITS.2015.2409174
   Hong J.-H., 2016, IEEE T HUMAN MACHINE
   Huang J, 2006, NIPS
   Jahangiri A., 2016, ACCIDENT ANAL PREVEN
   Jahangiri A., 2014, TRANSP RES BOARD 201
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Scholkopf B., 2002, LEARNING KERNELS SUP
   Stenneth L., 2011, P 19 ACM INT C ADV, P54, DOI DOI 10.1145/2093973.2093982
   Su X., 2015, SENSORS, V15, P16
   Su X., 2016, IEEE T INTELLIGENT T
   Su X., 2014, TSINGHUA SCI TECHNOL
   Sun X., 2013, IEEE T KNOWLEDGE DAT
   Sun Z., 2013, TRANSPORTATION RES C
   Zhou XL, 2016, COMPUT ENVIRON URBAN, V58, P52, DOI 10.1016/j.compenvurbsys.2016.03.001
NR 21
TC 0
Z9 0
SN 2639-1589
BN 978-1-5386-2715-0
PY 2017
BP 1341
EP 1348
UT WOS:000428073701045
ER

PT S
AU Zang, YZ
   Hu, XH
AF Zang, Yizhou
   Hu, Xiaohua
BE Nie, JY
   Obradovic, Z
   Suzumura, T
   Ghosh, R
   Nambiar, R
   Wang, C
   Zang, H
   BaezaYates, R
   Hu, X
   Kepner, J
   Cuzzocrea, A
   Tang, J
   Toyoda, M
TI Heterogeneous Knowledge Transfer via Domain Regularization for Improving
   Cross-Domain Collaborative Filtering
SO 2017 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
CT IEEE International Conference on Big Data (IEEE Big Data)
CY DEC 11-14, 2017
CL Boston, MA
DE Cross-Domain Collaborative Filtering; transfer learning; recommender
   system; similarity network fusion
AB Cross-Domain Collaborative Filtering(CDCF) methods transfer knowledge from auxiliary domains (e.g., books) to improve recommendation in a target domain (e.g. movies). Most CDCF methods exploit homogeneous user feedback, e.g. numeric ratings, from auxiliary domains as the knowledge source. However, in a typical recommender system, the usage data is usually heterogeneous and therefore is potential to better improve recommendation in other domains. In this paper, we propose a novel and generic CDCF solution called Heterogeneous Knowledge Transfer via Domain Regularization (HKT-DR). Our solution is able to mine high quality knowledge from heterogeneous knowledge sources, i.e. both explicit and implicit feedbacks from multiple auxiliary domains, by building a fused user similarity network, and to incorporate the knowledge by imposing domain regularization to constrain matrix factorization objective function. Extensive experiments on real world datasets show that the proposed HKT-DR model outperforms the state-of-the-art CDCF solutions.
CR Bin Wang, 2012, Advances in Knowledge Discovery and Data Mining. Proceedings 16th Pacific-Asia Conference (PAKDD 2012), P604, DOI 10.1007/978-3-642-30217-6_50
   Hu L., 2013, WWW 13
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI DOI 10.1145/1401890.1401944
   Koren Y, 2009, KDD, P426
   Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727
   Liu Nathan N., 2010, P 19 ACM INT C INF K, P1445, DOI DOI 10.1145/1871437.1871643
   Loni Babak, 2014, P 36 EUR C INF RETR
   Moreno O., 2012, P 21 ACM INT C INF K, P425
   Pan WK, 2016, NEUROCOMPUTING, V177, P447, DOI 10.1016/j.neucom.2015.11.059
   Pan Weike, 2010, AAAI
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Salakhutdinov R., 2007, ADV NEURAL INFORM PR, P1257, DOI DOI 10.1145/1390156.1390267
   Sheng Gao, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P161, DOI 10.1007/978-3-642-40991-2_11
   Shi Y., ACM COMPUTI IN PRESS
   Shi Y., 2011, UMAP 11
   Zang Y., 2017, ECML PKDD
   ZHANG Yan-bin, 2014, RES, V10, P11
NR 18
TC 0
Z9 0
SN 2639-1589
BN 978-1-5386-2715-0
PY 2017
BP 3968
EP 3974
UT WOS:000428073703134
ER

PT S
AU Kumar, D
   Kumar, C
   Shao, M
AF Kumar, Deepak
   Kumar, Chetan
   Shao, Ming
BE Nie, JY
   Obradovic, Z
   Suzumura, T
   Ghosh, R
   Nambiar, R
   Wang, C
   Zang, H
   BaezaYates, R
   Hu, X
   Kepner, J
   Cuzzocrea, A
   Tang, J
   Toyoda, M
TI Cross-Database Mammographic Image Analysis through Unsupervised Domain
   Adaptation
SO 2017 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
CT IEEE International Conference on Big Data (IEEE Big Data)
CY DEC 11-14, 2017
CL Boston, MA
DE Breast cancer diagnosis; mammographic image analysis; deep learning;
   transfer learning
ID BREAST-CANCER
AB World Health Organization report shows 519,000 deaths due to breast cancer in 2014 and it was much more in 2008. Therefore, it is required to take early steps in detection and diagnosis of breast cancer to decrease the associated death rate. Computer Aided Diagnosis (CAD) is useful in mass screening of breast cancer datasets. Data mining and machine learning technologies have already achieved significant success in many knowledge engineering areas including classification, regression and clustering, and most recently, have been employed to assist the diagnosis of cancers with promising outcomes. Traditional machine learning models are characterized by training and testing data with the same input feature space and data distribution. But when distribution changes, most machine learning models need to be modified or rebuilt from scratch to work on newly collected data. In many real world applications, it is expensive or impossible to recollect the needed data and rebuild the models. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred as Transfer Learning. In this paper, we explore the usage of transfer learning, specially, unsupervised domain adaptation for breast cancer diagnosis to address the issues of fewer training data on target image dataset. On the strength of recent developed deep descriptors, we are able to adapt recent transfer learning methodologies, e.g., TCA (Transfer Component Analysis), CORAL (Correlation Alignment), BDA(Balanced Distribution Adaptation) to breast cancer diagnosis across multiple mammographic image databases including CBIS-DDSM, InBreast, MIAS, etc, and evaluate their performance. Experiments demonstrate that, without any labels in the target database, transfer learning is able to help improve the classification accuracy.
CR [Anonymous], 2016, A C SOC BREAST CANC
   [Anonymous], 2015, W C R FUND BREAST CA
   Arevalo J, 2015, IEEE ENG MED BIO, P797, DOI 10.1109/EMBC.2015.7318482
   Astley SM, 2004, CLIN RADIOL, V59, P390, DOI 10.1016/j.crad.2003.11.017
   CARNEIRO G, 2015, INT C MED IM COMP, V9351, P652, DOI DOI 10.1007/978-3-319-24574-4_78
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   DeSantis C, 2014, CA-CANCER J CLIN, V64, P52, DOI 10.3322/caac.21203
   Dhahbi S, 2015, COMPUT BIOL MED, V64, P79, DOI 10.1016/j.compbiomed.2015.06.012
   Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160
   Ding ZM, 2015, IEEE T IMAGE PROCESS, V24, P4322, DOI 10.1109/TIP.2015.2462023
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Jamieson A. R., 2012, SPIE MED IMAGING STR, V2012
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Jotwani AC, 2009, MOL DIAGN THER, V13, P349, DOI 10.2165/11318220-000000000-00000
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lee R. S., 2016, CURATED BREAST IMAGI
   Levy D., 2016, ARXIV161200542
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patricia N, 2014, PROC CVPR IEEE, P1442, DOI 10.1109/CVPR.2014.187
   Ramon J, 2007, LECT NOTES ARTIF INT, V4701, P699
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao M., 2016, AAAI C ART IN PRESS, P1
   Shao M., 2014, INT J COMPUTER VISIO
   Shen L., 2017, ARXIV170809427
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Suckling J., 1994, P INT WORKSHOP DIG M, P375
   Sun B., 2016, AAAI, V6, P8
   Taylor ME, 2007, P 24 INT C MACH LEAR, P879
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang J., 2017, BALANCE DISTRIBUTION
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
NR 34
TC 1
Z9 1
SN 2639-1589
BN 978-1-5386-2715-0
PY 2017
BP 4035
EP 4042
UT WOS:000428073704003
ER

PT B
AU Berger, K
   Schulz, A
   Paassen, B
   Hammer, B
AF Berger, Kolja
   Schulz, Alexander
   Paassen, Benjamin
   Hammer, Barbara
GP IEEE
TI Linear Supervised Transfer Learning for the Large Margin Nearest
   Neighbor Classifier
SO 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
CT IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 27-DEC 01, 2017
CL Honolulu, HI
AB The performance of many artificial intelligence systems critically depends on classification methods. Unfortunately, most classifiers are highly sensitive to distortions in the input distribution, for example, due to sensor failures or a switch of the sensor system. In such a case, new labeled data has to be recorded to retrain the classifier under the distorted input distribution, which can be expensive. Transfer learning addresses this issue by reusing the original model and adapting it to the new domain using as few new data points as possible.
   In this contribution, we present a novel supervised transfer learning scheme for the Large Margin Nearest Neighbor classifier. We evaluate our approach on a real-world example of a transfer between two hyper-spectral sensors applied to chemical molecule classification. Our results show that transfer learning outperforms the original model as well as a newly trained model on the new data and requires only very little data to be trained.
CR Arnold A., 2007, 7 IEEE INT C DAT MIN, P77, DOI DOI 10.1109/ICDMW.2007.109
   Ditzler G, 2015, IEEE COMPUT INTELL M, V10, P12, DOI 10.1109/MCI.2015.2471196
   Driscoll T. A., 2014, CHEBFUN GUIDE
   Gama J., 2014, ACM COMPUT SURV, V46, P1, DOI DOI 10.1145/2523813
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Melchert F., 2016, SUGAR DATASET MULTIM
   Minku LL, 2012, IEEE T KNOWL DATA EN, V24, P619, DOI 10.1109/TKDE.2011.58
   Paassen B., 2017, P 25 EUR S ART NEUR, P129
   Paassen B., 2016, MACHINE LEARNING REP, V4, P11
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Riedmiller M, 1992, P ISCIS 7 U
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
NR 12
TC 0
Z9 0
BN 978-1-5386-2726-6
PY 2017
BP 1842
EP 1847
UT WOS:000428251401128
ER

PT B
AU Bussey, D
   Glandon, A
   Vidyaratne, L
   Alam, M
   Iftekharuddin, KM
AF Bussey, D.
   Glandon, A.
   Vidyaratne, L.
   Alam, M.
   Iftekharuddin, K. M.
GP IEEE
TI Convolutional Neural Network Transfer Learning for Robust Face
   Recognition in NAO Humanoid Robot
SO 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
CT IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 27-DEC 01, 2017
CL Honolulu, HI
DE Transfer Learning; Convolutional Neural Network (CNN); Facial
   Recognition; Humanoid Robot
AB Applications of transfer learning for convolutional neural networks (CNNs) have shown to be an efficient alternative for solving recognition tasks rather than designing and training a new neural network from scratch. However, there exists several popular CNN architectures available for various recognition tasks. Therefore, choosing an appropriate network for a specific recognition task, specifically designed for a humanoid robotic platform, is often challenging. This study evaluates the performance of two well-known CNN architectures; AlexNet, and VCC-Face for a face recognition task. This is accomplished by applying the transfer learning concept to the networks pre-trained for different recognition tasks. The proposed face recognition framework is then implemented on a humanoid robot known as NAO to demonstrate the practicality and flexibility of the algorithm. The results suggest that the proposed pipeline shows excellent performance in recognizing a new person from a single example image under varying distance and resolution conditions usually applicable to a mobile humanoid robotic platform.
CR Best-Rowden L, 2014, IEEE T INF FOREN SEC, V9, P2144, DOI 10.1109/TIFS.2014.2359577
   Collohert R., 2008, P 25 INT C MACH LEAR
   George D., 2017, ARXIV1706074461
   Huang G. B., 2007, 0749 U MASS
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Torrey L., 2005, P 16 EUR C MACH LEAR
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang T, 2012, INT C PATT RECOG, P3304
   Yi D., 2014, ARXIV14117923
   Yusinski J., 2014, P 27 INT C NEUR INF
NR 18
TC 0
Z9 0
BN 978-1-5386-2726-6
PY 2017
UT WOS:000428251402058
ER

PT B
AU Peng, XS
   Li, YX
   Wei, X
   Luo, JH
   Murphey, YL
AF Peng, Xishuai
   Li, Yuanxiang
   Wei, Xian
   Luo, Jianhua
   Murphey, Yi Lu
GP IEEE
TI Traffic Sign Recognition with Transfer Learning
SO 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
CT IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY NOV 27-DEC 01, 2017
CL Honolulu, HI
DE transfer learning; traffic sign recognition; stacked auto-encoder; local
   coordinate coding; deep learning
ID DIMENSIONALITY
AB Traffic signs are characterized by a wide variability in their visual appearance in real-world environments. Supervised algorithms have achieved superior results on German Traffic Sign Recognition Bench-mark (GTSRB) database. However, these models cannot transfer knowledge across domains, e.g. transfer knowledge learned from Synthetic Signs database to recognize the traffic signs in GTSRB database. Through Synthetic Signs database shares exactly the same class label with GTSRB, the data distribution between them are divergent. Such task is called transfer learning, that is a basic ability for human being but a challenge problem for machines.
   In order to make these algorithms have ability to transfer knowledge between domains, we propose a variant of Generalized Auto-Encoder (GAE) in this paper. Traditional transfer learning algorithms, e.g. Stacked Autoencoder(SA), usually attempt to reconstruct target data from source data or man-made corrupted data. In contrast, we assume the source and target data are two different corrupted versions of a domain-invariant data. And there is a latent subspace that can reconstruct the domain-invariant data as well as preserve the local manifold of it. Therefore, the domain-invariant data can be obtained not only by de-noising from the nearest source and target data but also by reconstructing from the latent subspace. In order to make the statistical and geometric property preserved simultaneously, we additionally propose a Local Coordinate Coding (LCC)-based relational function to construct the deep nonlinear architecture. The experimental results on several benchmark datasets demonstrate the effectiveness of our proposed approach in comparison with several traditional methods.
CR Belkin M, 2002, ADV NEUR IN, V14, P585
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chattopadhyay R, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382582
   Chen M., 2012, ARXIV12064683
   Ding ZM, 2016, LECT NOTES COMPUT SC, V9910, P567, DOI 10.1007/978-3-319-46466-4_34
   Ding ZM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3453
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duda R., 1973, PATTERN CLASSIFICATI
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Kan MN, 2015, IEEE I CONF COMP VIS, P3846, DOI 10.1109/ICCV.2015.438
   Li J., 2016, IJCAI 2016, P1697
   Lin Y., 2010, ADV NEURAL INFORM PR, P1405
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Moiseev B, 2013, LECT NOTES COMPUT SC, V8192, P576, DOI 10.1007/978-3-319-02895-8_52
   Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Stallkamp J., 2012, NEURAL NETWORKS
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang W, 2014, IEEE COMPUT SOC CONF, P496, DOI 10.1109/CVPRW.2014.79
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Yu K, 2009, P ADV NEUR INF PROC, P2223
   Yu K., 2010, P 27 INT C MACH LEAR, P1215
   Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119
NR 29
TC 0
Z9 0
BN 978-1-5386-2726-6
PY 2017
UT WOS:000428251402055
ER

PT S
AU Tong, R
   Wang, L
   Ma, B
AF Tong, Rong
   Wang, Lei
   Ma, Bin
BE Tong, R
   Zhang, Y
   Lu, Y
   Dong, M
TI Transfer learning for children's speech recognition
SO 2017 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY DEC 05-07, 2017
CL Natl Univ Singapore, Singapore, SINGAPORE
HO Natl Univ Singapore
DE Automatic speech recognition; acoustic model; transfer learning; deep
   neural network; multi-task learning; children's speech processing
AB Children's speech processing is more challenging than that of adults due to lacking of large scale children's speech corpora. With the developing of the physical speech organ, high inter speaker and intra speaker variabilities are observed in children's speech. On the other hand, data collection on children is difficult as children usually have short attention span and their language proficiency is limited. In this paper, we propose to improve children's automatic speech recognition performance with transfer learning technique. We compare two transfer learning approaches in enhancing children's speech recognition performance with adults' data. The first method is to perform acoustic model adaptation on the pre-trained adult model. The second is to train acoustic model with deep neural network based multi-task learning approach: the adults' and children's acoustic characteristics are learnt jointly in the shared hidden layers, while the output layers are optimized with different speaker groups. Our experiment results show that both transfer learning approaches are effective in transferring rich phonetic and acoustic information from adults' model to children model. The multi-task learning approach outperforms the acoustic adaptation approach. We further show that the speakers' acoustic characteristics in languages can also benefit the target language under the multi-task learning framework.
CR Caruana R, 1998, LEARNING TO LEARN, P95
   Chen N. F., 2016, SPEECH COMMUNICATION
   Chen Nancy F., 2016, INTERSPEECH
   Fainberg J, 2016, INTERSPEECH, P1598, DOI 10.21437/Interspeech.2016-1348
   Gerosa M, 2007, SPEECH COMMUN, V49, P847, DOI 10.1016/j.specom.2007.01.002
   Gray S. S., 2014, WORKSH CHILD COMP IN
   Huang Z, 2016, NEUROCOMPUTING, V218, P448, DOI 10.1016/j.neucom.2016.09.018
   Kunze Julius, 2 ACL WORKSH REPR LE
   Liao  H., 2015, INTERSPEECH
   Potamianos Alexandros, 1997, EUROSPEECH, V97, P2371
   Serizel  R., 2014, IEEE WORKSH SPOK LAN
   Shivakumar P. G., 2014, WORKSH CHILD COMP IN
   Tong Rong, 2017, INTERSPEECH
   Wang Dong, 2015, ARXIV151106066CS
NR 14
TC 0
Z9 0
SN 2159-1962
EI 2159-1970
BN 978-1-5386-1981-0
PY 2017
BP 36
EP 39
UT WOS:000428370700009
ER

PT S
AU Tagawa, Y
   Shimada, K
AF Tagawa, Yuuki
   Shimada, Kazutaka
BE Tong, R
   Zhang, Y
   Lu, Y
   Dong, M
TI Simple and sophisticated inning summary generation based on
   encoder-decoder model and transfer learning
SO 2017 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY DEC 05-07, 2017
CL Natl Univ Singapore, Singapore, SINGAPORE
HO Natl Univ Singapore
DE Sports sununarization; Encoder Decoder model; Transfer learning
AB This paper describes an inning sununarization method for a baseball game by using an encoder-decoder model. Each inning in a baseball game contains some events, such as hits, strikeouts, homeruns and scoring. Simplified description of the events leads to the improvement of readability of the inning information. Our method learns a relation between play-by-play data in each inning and inning reports. We also incorporate sophisticated expressions acquired from game summaries with the model. We call them Game-changing Phrase, GP. One problem in our task is the size of training data for the learning. To solve this problem, we apply a transfer learning approach into our method. In the experiment, we evaluate the effectiveness of our method with the transfer learning.
CR Allen N. D., 2010, AAAI FALL S SERIES
   Barret Z., 2016, P 2016 C EMP METH NA
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Jianmin Z., 2016, P 54 ANN M ASS COMP
   Kingma D., 2015, INT C LEARN REPR ICL
   Li Jiwei, 2016, P 54 ANN M ASS COMP, P994, DOI DOI 10.18653/V1/P16-1094
   Luong Minh-Thang, 2015, P 2015 C EMP METH NA
   Murakami S., 2017, P 55 ANN M ASS COMP
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Robin J., 1994, THESIS
   Rush A. M., 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044
   Sutskever  I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.1007/S10107-014-0839-0
NR 12
TC 0
Z9 0
SN 2159-1962
EI 2159-1970
BN 978-1-5386-1981-0
PY 2017
BP 252
EP 255
UT WOS:000428370700060
ER

PT S
AU Michael, J
   Teixeira, LF
AF Michael, John
   Teixeira, Luis F.
BE Alexandre, LA
   Sanchez, JS
   Rodrigues, JMF
TI Pre-trained Convolutional Networks and Generative Statistical Models: A
   Comparative Study in Large Datasets
SO PATTERN RECOGNITION AND IMAGE ANALYSIS (IBPRIA 2017)
SE Lecture Notes in Computer Science
CT 8th Iberian Conference on Pattern Recognition and Image Analysis
   (IbPRIA)
CY JUN 20-23, 2017
CL Univ Algarve, Faro, PORTUGAL
HO Univ Algarve
DE Computational geometry; Graph theory; Hamilton cycles
AB This study explored the viability of out-the-box, pre-trained ConvNet models as a tool to generate features for large-scale classification tasks. A juxtaposition with generative methods for vocabulary generation was drawn. Both methods were chosen in an attempt to integrate other datasets (transfer learning) and unlabelled data, respectively. Both methods were used together, studying the viability of a ConvNet model to estimate category labels of unlabelled images. All experiments pertaining to this study were carried out over a two-class set, later expanded into a 5-category dataset. The pre-trained models used were obtained from the Caffe Model Zoo.
   The study showed that the pre-trained model achieved best results for the binary dataset, with an accuracy of 0.945. However, for the 5-class dataset, generative vocabularies outperformed the ConvNet (0.91 vs. 0.861). Furthermore, when replacing labelled images with unlabelled ones during training, acceptable accuracy scores were obtained (as high as 0.903). Additionally, it was observed that linear kernels perform particularly well when utilized with generative models. This was especially relevant when compared to ConvNets, which require days of training even when utilizing multiple GPUs for computations.
RI Teixeira, Luis/E-1319-2011
OI Teixeira, Luis/0000-0002-4050-7880
CR Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Jia Y., 2014, CAFFE CONVOLUTIONAL
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lazebnik  S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68
   Lee C., 2010, P INT MULTICONFERENC, V2, P17
   Sanchez J., 2013, CVPR 2013
   Yang J., 2009, CVPR 2009
NR 7
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-58838-4; 978-3-319-58837-7
PY 2017
VL 10255
BP 69
EP 75
DI 10.1007/978-3-319-58838-4_8
UT WOS:000429969200008
ER

PT S
AU Fernandes, K
   Cardoso, JS
   Fernandes, J
AF Fernandes, Kelwin
   Cardoso, Jaime S.
   Fernandes, Jessica
BE Alexandre, LA
   Sanchez, JS
   Rodrigues, JMF
TI Transfer Learning with Partial Observability Applied to Cervical Cancer
   Screening
SO PATTERN RECOGNITION AND IMAGE ANALYSIS (IBPRIA 2017)
SE Lecture Notes in Computer Science
CT 8th Iberian Conference on Pattern Recognition and Image Analysis
   (IbPRIA)
CY JUN 20-23, 2017
CL Univ Algarve, Faro, PORTUGAL
HO Univ Algarve
DE Transfer learning; Regularization; Cervical cancer; Digital colposcopy
AB Cervical cancer remains a significant cause of mortality in low-income countries. As in many other diseases, the existence of several screening/diagnosis methods and subjective physician preferences creates a complex ecosystem for automated methods. In order to diminish the amount of labeled data from each modality/expert we propose a regularization-based transfer learning strategy that encourages source and target models to share the same coefficient signs. We instantiated the proposed framework to predict cross-modality individual risk and cross-expert subjective quality assessment of colposcopic images for different modalities. Thus, we are able to transfer knowledge gained from one expert/modality to another.
RI ; Cardoso, Jaime/I-3286-2013
OI Fernandes, Jessica/0000-0002-9369-8983; Fernandes,
   Kelwin/0000-0002-6838-9484; Cardoso, Jaime/0000-0002-3760-2473
CR Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Fernandes K, 2015, LECT NOTES COMPUT SC, V9117, P262, DOI 10.1007/978-3-319-19390-8_30
   Garcke Jochen, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P466, DOI 10.1007/978-3-662-44848-9_30
   Kuzborskij I., 2013, ICML
   Lee C, 2011, ETRI J, V33, P712, DOI 10.4218/etrij.11.0110.0571
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perrot  Michael, 2015, P 32 INT C MACH LEAR, P1708
   Ruckert U, 2008, LECT NOTES ARTIF INT, V5212, P220, DOI 10.1007/978-3-540-87481-2_15
NR 8
TC 10
Z9 11
SN 0302-9743
EI 1611-3349
BN 978-3-319-58838-4; 978-3-319-58837-7
PY 2017
VL 10255
BP 243
EP 250
DI 10.1007/978-3-319-58838-4_27
UT WOS:000429969200027
ER

PT S
AU Zhuang, FZ
   Huang, L
   He, J
   Ma, JX
   He, Q
AF Zhuang, Fuzhen
   Huang, Lang
   He, Jia
   Ma, Jixin
   He, Qing
BE Li, G
   Ge, Y
   Zhang, Z
   Jin, Z
   Blumenstein, M
TI Transfer Learning with Manifold Regularized Convolutional Neural Network
SO KNOWLEDGE SCIENCE, ENGINEERING AND MANAGEMENT (KSEM 2017): 10TH
   INTERNATIONAL CONFERENCE, KSEM 2017, MELBOURNE, VIC, AUSTRALIA, AUGUST
   19-20, 2017, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT 10th International Conference on Knowledge Science, Engineering and
   Management (KSEM)
CY AUG 19-20, 2017
CL Melbourne, AUSTRALIA
DE Transfer learning; Convolutional neural network; Manifold learning
AB Deep learning has been recently proposed to learn robust representation for various tasks and deliver state-of-the-art performance in the past few years. Most researchers attribute such success to the substantially increased depth of deep learning models. However, training a deep model is time-consuming and need huge amount of data. Though techniques like fine-tuning can ease those pains, the generalization performance drops significantly in transfer learning setting with little or without target domain data. Since the representation in higher layers must transition from general to specific eventually, generalization performance degrades without integrating sufficient label information of target domain. To address such problem, we propose a transfer learning framework called manifold regularized convolutional neural networks (MRCNN). Specifically, MRCNN fine-tunes a very deep convolutional neural network on source domain, and simultaneously tries to preserve the manifold structure of target domain. Extensive experiments demonstrate the effectiveness of MRCNN compared to several state-of-the-art baselines.
CR Abadi M., 2016, ARXIV160304467
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Chen M., 2012, ARXIV12064683
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoffman  J., 2014, ADV NEURAL INFORM PR, P3536
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Kingma D., 2014, ARXIV14126980
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Simonyan K., 2014, ARXIV14091556
   Torrey L., 2009, HDB RES MACHINE LEAR, V1, P242, DOI DOI 10.1016/J.JBI.2011.04.009
   Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119
   Zhuang FZ, 2010, IEEE T KNOWL DATA EN, V22, P1664, DOI 10.1109/TKDE.2009.205
NR 26
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-63558-3; 978-3-319-63557-6
PY 2017
VL 10412
BP 483
EP 494
DI 10.1007/978-3-319-63558-3_41
UT WOS:000428907900041
ER

PT S
AU Wu, DR
AF Wu, Dongrui
GP IEEE
TI Active Semi-supervised Transfer Learning (ASTL) for Offline BCI
   Calibration
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 05-08, 2017
CL Banff, CANADA
DE Brain-computer interface; event-related potential; EEG; active learning;
   domain adaptation; semi-supervised learning; transfer learning
ID SERIAL VISUAL PRESENTATION; MULTIPLE COMPARISONS; CLASSIFICATION
AB Single-trial classification of event-related potentials in electroencephalogram (EEG) signals is a very important paradigm of brain-computer interface (BCI). Because of individual differences, usually some subject-specific calibration data are required to tailor the classifier for each subject. Transfer learning has been extensively used to reduce such calibration data requirement, by making use of auxiliary data from similar/relevant subjects/tasks. However, all previous research assumes that all auxiliary data have been labeled. This paper considers a more general scenario, in which part of the auxiliary data could be unlabeled. We propose active semi-supervised transfer learning (ASTL) for offline BCI calibration, which integrates active learning, semi-supervised learning, and transfer learning. Using a visual evoked potential oddball task and three different EEG headsets, we demonstrate that ASTL can achieve consistently good performance across subjects and headsets, and it outperforms some state-of-the-art approaches in the literature.
OI Wu, Dongrui/0000-0002-7153-9703
CR BENJAMINI Y, 1995, J R STAT SOC B, V57, P289
   Bigdely-Shamlo N, 2008, IEEE T NEUR SYS REH, V16, P432, DOI 10.1109/TNSRE.2008.2003381
   BULAYEVA KB, 1993, BEHAV GENET, V23, P443, DOI 10.1007/BF01067978
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chapelle O, 2006, SEMISUPERVISED LEARN
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Jayaram V, 2016, IEEE COMPUT INTELL M, V11, P20, DOI 10.1109/MCI.2015.2501545
   Li Y, 2008, MACH LEARN, V71, P33, DOI 10.1007/s10994-007-5039-1
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Lotte F., 2010, P IEEE INT C AC SPEE
   Marathe AR, 2016, IEEE T NEUR SYS REH, V24, P333, DOI 10.1109/TNSRE.2015.2502323
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parisi F, 2014, P NATL ACAD SCI USA, V111, P1253, DOI 10.1073/pnas.1219097111
   Ries A J, 2014, J NEUROSCI NEUROENG, V3, P1
   Sajda P, 2010, P IEEE, V98, P462, DOI 10.1109/JPROC.2009.2038406
   Scholkopf B, 2001, LEARNING KERNELS SUP
   Settles B., 2009, 1648 U WISC MAD
   US Department of the Army, 1990, 7025 AR US DEP ARM G
   Wu D., 2016, IEEE T HUMA IN PRESS
   Wu D., 2016, IEEE T FUZZ IN PRESS
   Wu D, 2016, IEEE SYS MAN CYBERN, P743, DOI 10.1109/SMC.2016.7844330
   Wu D, 2016, IEEE SYS MAN CYBERN, P730, DOI 10.1109/SMC.2016.7844328
   Wu D, 2016, IEEE T NEUR SYS REH, V24, P1125, DOI 10.1109/TNSRE.2016.2544108
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
NR 27
TC 0
Z9 0
SN 1062-922X
BN 978-1-5386-1645-1
PY 2017
BP 246
EP 251
UT WOS:000427598700043
ER

PT S
AU Hossain, I
   Khosravi, A
   Hettiarachchi, IT
   Nahavandhi, S
AF Hossain, Ibrahim
   Khosravi, Abbas
   Hettiarachchi, Imali Thanuja
   Nahavandhi, Saeid
GP IEEE
TI Informative instance transfer learning with subject specific frequency
   responses for motor imagery Brain Computer Interface
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 05-08, 2017
CL Banff, CANADA
ID SPATIAL FILTERS
AB Motor imagery based brain computer interface (BCI) has drawback of long subject dependent calibration session times. This can be a very exhausting and a time consuming process. In order to alleviate it, transfer learning and active learning approaches can be utilised. Informative instances are selected by applying active learning concept from other subjects under similar circumstances. Then, they are transferred to target user domain which has low number of training data. This informative transfer learning approach is associated with common spatial pattern (CSP) as feature extraction method in our previous attempt. CSP features are widely used for motor imagery-based BCI systems. However, the classical CSP algorithm will perform poorly when operational frequency bands are inadequately selected. Therefore, in the present study, filter bank common spatial pattern (FBCSP) algorithm has been applied for extracting features from the multi-class motor imagery data. FBCSP algorithm selects subject-specific operational frequency bands for extracting discriminative features. We incorporated FBCSP features into informative instance transfer learning framework to investigate the effect of subject specific feature selection. Results show that performance of new users can be improved with reduced number of training samples when FBCSP features are used compared to the classical CSP-based features.
CR Ang K. K., 2012, FRONTIERS NEUROSCIEN, V6
   Ang KK, 2008, IEEE IJCNN, P2390, DOI 10.1109/IJCNN.2008.4634130
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI [10.1109/MSP.2008.4408441, 10.1109/MSP.200790.900,9]
   Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051
   Chen M., 2014, J FIBER BIOENGINEERI, V7, P627
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Nicolas-Alonso LF, 2012, SENSORS-BASEL, V12, P1211, DOI 10.3390/s120201211
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Hochberg Y., 2009, MULTIPLE COMP PROCED
   Hossain I, 2016, IEEE IJCNN, P4048, DOI 10.1109/IJCNN.2016.7727726
   Jayaram  V., 2015, ARXIV151200296
   Kai Keng Ang, 2013, Journal of Computing Science and Engineering, V7, P139, DOI 10.5626/JCSE.2013.7.2.139
   Leeb R., 2008, BCI COMPETITION 2008
   Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8
   Novi Q., 2007, NEUR ENG 2007 CNE 07, P204
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pfurtscheller G, 2008, COMPUTER, V41, P58, DOI 10.1109/MC.2008.432
   Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946
   Rosenstein MT, 2005, NIPS 2005 WORKSH IND, V2, P7
   Samek W, 2013, IEEE T BIO-MED ENG, V60, P2289, DOI 10.1109/TBME.2013.2253608
   Settles Burr, 2010, U WISCONSIN MADISON, V52, P55
   Nguyen TV, 2017, IEEE INT ENTERP, P8, DOI 10.1109/EDOCW.2017.11
   Wolpaw J., 2012, BRAIN COMPUTER INTER
   Wu  D., 2015, P IEEE INT C SYST MA
   Wu  D., 2014, P IEEE INT C SYST MA
   YE J., 2004, ADV NEURAL INFORM PR, V17, P1569
NR 29
TC 3
Z9 3
SN 1062-922X
BN 978-1-5386-1645-1
PY 2017
BP 252
EP 257
UT WOS:000427598700044
ER

PT S
AU Goyal, M
   Reeves, ND
   Rajbhandari, S
   Spragg, J
   Yap, MH
AF Goyal, Manu
   Reeves, Neil D.
   Rajbhandari, Satyan
   Spragg, Jennifer
   Yap, Moi Hoon
GP IEEE
TI Fully Convolutional Networks for Diabetic Foot Ulcer Segmentation
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 05-08, 2017
CL Banff, CANADA
AB Diabetic Foot Ulcer (DFU) is a major complication of Diabetes, which if not managed properly can lead to amputation. DFU can appear anywhere on the foot and can vary in size, colour, and contrast depending on various pathologies. Current clinical approaches to DFU treatment rely on patients and clinician vigilance, which has significant limitations such as the high cost involved in the diagnosis, treatment and lengthy care of the DFU. We introduce a dataset of 705 foot images. We provide the ground truth of ulcer region and the surrounding skin that is an important indicator for clinicians to assess the progress of ulcer. Then, we propose a two-tier transfer learning from bigger datasets to train the Fully Convolutional Networks (FCNs) to automatically segment the ulcer and surrounding skin. Using 5-fold cross-validation, the proposed two-tier transfer learning FCN Models achieve a Dice Similarity Coefficient of 0.794 (+/- 0.104) for ulcer region, 0.851 (+/- 0.148) for surrounding skin region, and 0.899 (+/- 0.072) for the combination of both regions. This demonstrates the potential of FCNs in DFU segmentation, which can be further improved with a larger dataset.
OI Reeves, Neil/0000-0001-9213-4580
CR Alarifi JS, 2017, LECT NOTES COMPUT SC, V10317, P479, DOI 10.1007/978-3-319-59876-5_53
   Armstrong DG, 1998, DIABETES CARE, V21, P855, DOI 10.2337/diacare.21.5.855
   Bakker K, 2016, DIABETES-METAB RES, V32, P2, DOI 10.1002/dmrr.2694
   Castro A, 2006, LECT NOTES COMPUT SC, V4142, P491
   Chung DH, 2000, IEEE T MED IMAGING, V19, P763, DOI 10.1109/42.875204
   Edmonds M, 2006, DRUGS, V66, P913, DOI 10.2165/00003495-200666070-00003
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Hewitt B., 2016, J OPEN RES SOFTWARE, V4
   Jeffcoate WJ, 2003, LANCET, V361, P1545, DOI 10.1016/S0140-6736(03)13169-8
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Kolesnik M, 2005, LECT NOTES COMPUT SC, V3656, P1014
   Kolesnik M, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P50
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lipsky BA, 2004, CLIN INFECT DIS, V39, P885, DOI 10.1086/424846
   Liu C, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.2.026003
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Papazoglou ES, 2010, WOUND REPAIR REGEN, V18, P349, DOI 10.1111/j.1524-475X.2010.00594.x
   Rajbhandari SM, 1999, DIABETIC MED, V16, P339, DOI 10.1046/j.1464-5491.1999.00053.x
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Steed DL, 1996, J AM COLL SURGEONS, V183, P61
   Veredas F, 2010, IEEE T MED IMAGING, V29, P410, DOI 10.1109/TMI.2009.2033595
   Wang L., 2016, SYSTEMS MAN CYBERN A
   Wild S, 2004, DIABETES CARE, V27, P1047, DOI 10.2337/diacare.27.5.1047
   Yadav MK, 2013, J MED IMAG HEALTH IN, V3, P22, DOI 10.1166/jmihi.2013.1124
   Yap M. H., 2007, FULLY AUTOMATIC LESI
   Yap M. H., 2015, J DIABETES SCI TECHN
   Yap M. H, 2017, J DIABETES SCI TECHN
NR 28
TC 3
Z9 3
SN 1062-922X
BN 978-1-5386-1645-1
PY 2017
BP 618
EP 623
UT WOS:000427598700108
ER

PT S
AU Cote-Allard, U
   Fall, CL
   Campeau-Lecours, A
   Gosselin, C
   Laviolette, F
   Gosselin, B
AF Cote-Allard, Ulysse
   Fall, Cheikh Latyr
   Campeau-Lecours, Alexandre
   Gosselin, Clement
   Laviolette, Francois
   Gosselin, Benoit
GP IEEE
TI Transfer Learning for sEMG Hand Gestures Recognition Using Convolutional
   Neural Networks
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 05-08, 2017
CL Banff, CANADA
ID UPPER-LIMB PROSTHESES; SURFACE EMG
AB In the realm of surface electromyography (sEMG) gesture recognition, deep learning algorithms are seldom employed. This is due in part to the large quantity of data required for them to train on. Consequently, it would be prohibitively time consuming for a single user to generate a sufficient amount of data for training such algorithms.
   In this paper, two datasets of 18 and 17 able-bodied participants respectively are recorded using a low-cost, low-sampling rate (200Hz), 8-channel, consumer-grade, dry electrode sEMG device named Myo armband (Thalmic Labs). A convolutional neural network (CNN) is augmented using transfer learning techniques to leverage inter-user data from the first dataset and alleviate the data generation burden imposed on a single individual. The results show that the proposed classifier is robust and precise enough to guide a 6DoF robotic arm (in conjunction with orientation data) with the same speed and precision as with a joystick. Furthermore, the proposed CNN achieves an average accuracy of 97.81% on seven hand/wrist gestures on the 17 participants of the second dataset.
CR Al-Rfou R, 2016, ARXIV160502688
   Al-Timemy AH, 2016, IEEE T NEUR SYS REH, V24, P650, DOI 10.1109/TNSRE.2015.2445634
   Allard UC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2464, DOI 10.1109/IROS.2016.7759384
   Andri R., 2017, IEEE T COMPUTER AIDE
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   Atzori M, 2016, FRONT NEUROROBOTICS, V10, DOI 10.3389/fnbot.2016.00009
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Bengio Y., 2012, J MACHINE LEARNING R, P17
   Campeau-Lecours A., 2016, REHABILITATION ENG A
   Cavigelli Lukas, 2016, IEEE T CIRCUITS SYST
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dauphin G, 2012, JMLR P TRACK, P97
   Du Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030458
   Farina D, 2014, IEEE T NEUR SYS REH, V22, P797, DOI 10.1109/TNSRE.2014.2305111
   Farrell TR, 2007, IEEE T NEUR SYS REH, V15, P111, DOI 10.1109/TNSRE.2007.891391
   Feng G., 2017, INTEGRATION VLSI J
   Gal Y., 2015, ARXIV150602158
   Geng W., 2016, SCI REPORTS, V6
   Guo H., 2016, IM PROC ICIP 2016 IE, P2608
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   HUDGINS B, 1993, IEEE T BIO-MED ENG, V40, P82, DOI 10.1109/10.204774
   Ioffe S, 2015, INT C MACH LEARN, V37, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li C, 2016, PROCEEDINGS OF 2016 IEEE 9TH UK-EUROPE-CHINA WORKSHOP ON MILLIMETRE WAVES AND TERAHERTZ TECHNOLOGIES (UCMMT), P54
   Li Y., 2016, ARXIV160304779
   Liu JW, 2016, IEEE J BIOMED HEALTH, V20, P166, DOI 10.1109/JBHI.2014.2380454
   Merletti R, 1999, J ELECTROMYOGR KINES, V9, P3, DOI DOI 10.1016/S1050-6411(97)90001-8
   Oskoei MA, 2007, BIOMED SIGNAL PROCES, V2, P275, DOI 10.1016/j.bspc.2007.07.009
   Peerdeman B, 2011, J REHABIL RES DEV, V48, P719, DOI 10.1682/JRRD.2010.08.0161
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rusu A. A., 2016, ARXIV160604671
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stegeman DF, 2012, BIOCYBERN BIOMED ENG, V32, P3
   Vu D.-S., 2017, INT C REH R IN PRESS, P1
   Wang C, 2017, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2017.7858304
   Yang D., 2015, IEEE J BIOMEDICAL HL
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 41
TC 5
Z9 5
SN 1062-922X
BN 978-1-5386-1645-1
PY 2017
BP 1663
EP 1668
UT WOS:000427598701119
ER

PT S
AU Ali, M
   Sahin, F
   Kumar, S
   Savur, C
AF Ali, Mazin
   Sahin, Ferat
   Kumar, Shitij
   Savur, Celal
GP IEEE
TI 360 degrees View Camera Based Visual Assistive Technology for Contextual
   Scene Information
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 05-08, 2017
CL Banff, CANADA
DE Machine Learning; Deep Learning; Convolutional Neural Network (CNN);
   Support Vector Machine; SVM; Ensemble Subspace Discriminant; Visual
   Impairment
AB In this paper, a system to aid the visually impaired by providing contextual information of the surroundings using 360 degrees view camera combined with deep learning is proposed. The system uses a 360 degrees view camera with a mobile device to capture surrounding scene information and provide contextual information to the user in the form of audio. The scene information from the spherical camera feed is classified by identifying objects that contain contextual information of the scene. That is achieved using convolutional neural networks (CNN) for classification by leveraging CNN transfer learning properties using the pre-trained VGG-19 network. There are two challenges related to this paper, a classification and a segmentation challenge. As an initial prototype, we have experimented with general classes such restaurants, coffee shops and street signs. We have achieved a 92.8% classification accuracy in this paper.
CR Beckett J., 2016, WEARABLE DEVICE BLIN
   Cascianelli S., 2017, INTELLIGENT INTERACT, P21
   Ciresan DC, 2012, IEEE IJCNN
   Erkilinc MS, 2011, ANN IEEE SYST CONF, P417
   Girshick R. B., 2015, CORR
   Girshick R. B., 2013, CORR
   Liu W., 2016, SSD SIGLE SHOT MULTI
   Redmon J., 2015, CORR
   Ren S., 2015, CORR
   Robitaille S., 2010, ILLUSTRATED GUIDE AS
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Yosinski J., 2014, CORR
NR 12
TC 0
Z9 0
SN 1062-922X
BN 978-1-5386-1645-1
PY 2017
BP 2135
EP 2140
UT WOS:000427598702030
ER

PT S
AU Jeon, S
   Paul, A
   Lee, H
   Eun, Y
   Son, SH
AF Jeon, Sanghoon
   Paul, Anand
   Lee, Haengju
   Eun, Yongsoon
   Son, Sang Hyuk
GP IEEE
TI SleePS: Sleep Position Tracking System for Screening Sleep Quality by
   Wristbands
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 05-08, 2017
CL Banff, CANADA
ID APNEA
AB Sleep plays an important role in recovering physical and mental functions. Sleep position is known to affect sleep quality, hence, managing sleep position is beneficial for patients suffering from sleep disorders. For a long-term sleep management, we propose a sleep position tracking system using two wristbands. From the data collected from the wristbands, the system detects sleep positions and their changes. We define a sleep position motion model that consists of seven transitions between three sleep positions. Then, we propose pre-processing methods to overcome difficulties in analyzing sleep motion data, i.e., discontinuity, uncertainty, and time-variability. We tested experimental data in state-of-art pre-trained convolution neural networks by transfer learning. The accuracy of our proposed system was 96.03% and 88.02% in pilot experiment and on-site sleep experiment, respectively. Our experimental results demonstrate that the proposed system effectively and accurately keeps track of sleep positions without causing any inconvenience to users, and hence, serves as a key building block for cost-effective 24/7 sleep monitoring solutions
OI Jeon, Sanghoon/0000-0001-5636-7555
CR Bignold JJ, 2011, J CLIN SLEEP MED, V7, P376, DOI 10.5664/JCSM.1194
   Chang KM, 2011, TELEMED E-HEALTH, V17, P177, DOI 10.1089/tmj.2010.0078
   DEKONINCK J, 1983, SLEEP, V6, P52, DOI 10.1093/sleep/6.1.52
   Grimm T, 2016, INT C PATT RECOG, P319, DOI 10.1109/ICPR.2016.7899653
   Kushida CA, 2005, SLEEP, V28, P499, DOI 10.1093/sleep/28.4.499
   Lee J., 2015, INT J DISTRIBUTED SE
   Liu JJ, 2013, INT CONF PERVAS COMP, P207, DOI 10.1109/PerCom.2013.6526734
   Oksenberg A, 1998, Sleep Med Rev, V2, P139
   Olivares A, 2012, SENSORS-BASEL, V12, P5791, DOI 10.3390/s120505791
   Ong AA, 2016, WORLD J OTORHINOLARY, V2, P45, DOI [DOI 10.1016/J.WJORL.2016.02.001, 10.1016/j.wjorl.2016.02.001]
   Palmero C, 2017, INT J COMPUT VISION, V122, P212, DOI 10.1007/s11263-016-0919-0
   Perneger TV, 1998, ARCH INTERN MED, V158, P1940, DOI 10.1001/archinte.158.17.1940
   Pouyan MB, 2013, INT CONF BIOMED, P121, DOI 10.1109/BMEI.2013.6746919
   Reimer MA, 2003, SLEEP MED REV, V7, P335, DOI 10.1053/smrv.2001.0220
   Richard W, 2006, EUR ARCH OTO-RHINO-L, V263, P946, DOI 10.1007/s00405-006-0090-2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sasidharan A., 2014, INT J CLIN EXPT PHYS, V1, P3
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Tang  Y., 2013, ARXIV13060239
   Tuomilehto H, 2009, AM J RESP CRIT CARE, V180, P101, DOI 10.1164/ajrccm.180.1.101a
   van Maanen JP, 2014, SLEEP, V37, P1209, DOI 10.5665/sleep.3840
   Wong ML, 2013, J PSYCHOSOM RES, V74, P271, DOI 10.1016/j.jpsychores.2012.08.014
   Zou D, 2006, SLEEP, V29, P367, DOI 10.1093/sleep/29.3.367
NR 23
TC 0
Z9 0
SN 1062-922X
BN 978-1-5386-1645-1
PY 2017
BP 3141
EP 3146
UT WOS:000427598703033
ER

PT B
AU Namikoshi, D
   Ohta, M
   Takasu, A
   Adachi, J
AF Namikoshi, Daiki
   Ohta, Manabu
   Takasu, Atsuhiro
   Adachi, Jun
GP IEEE
TI CRP-Based Bibliography Extraction from Reference Strings Using a Small
   Amount of Training Data
SO 2017 TWELFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT
   (ICDIM)
CT 12th International Conference on Digital Information Management (ICDIM)
CY SEP 12-14, 2017
CL Kyushu Univ, Fukuoka, JAPAN
HO Kyushu Univ
DE Terms bibliography extraction; CRF; confidence measure; active learning;
   transfer learning
AB The effective use of digital libraries demands maintenance of bibliographic databases. Useful bibliographic information appears in the reference fields of academic papers, so we are developing a method for automatic extraction of bibliographic information from reference strings using a conditional random field (CRF). However, at least a few hundred reference strings are necessary to learn an accurate CRF. In this paper, we propose active learning and transfer learning techniques to reduce the required training data for CRFs. We evaluate extraction accuracies and the associated training cost by experiments.
CR Councill IG, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P661
   Cuong N. V., 2015, P JCDL 2015, P61
   Do HHN, 2013, JCDL'13: PROCEEDINGS OF THE 13TH ACM/IEEE-CS JOINT CONFERENCE ON DIGITAL LIBRARIES, P219
   Kawakami N, 2014, LECT NOTES COMPUT SC, V8839, P268, DOI 10.1007/978-3-319-12823-8_28
   Kopcke H, 2010, PROC VLDB ENDOW, V3, P484
   Ohta M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P287, DOI 10.1109/DAS.2014.64
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pereira DA, 2014, 2014 IEEE/ACM JOINT CONFERENCE ON DIGITAL LIBRARIES (JCDL), P77, DOI 10.1109/JCDL.2014.6970153
   Settles B., 2008, P C EMP METH NAT LAN, P1070, DOI DOI 10.3115/1613715.1613855
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Williams K, 2014, 2014 IEEE 30TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOPS (ICDEW), P68, DOI 10.1109/ICDEW.2014.6818305
   Xia F, 2017, IEEE TRANS BIG DATA, V3, P18, DOI 10.1109/TBDATA.2016.2641460
NR 12
TC 0
Z9 0
BN 978-1-5386-0664-3
PY 2017
BP 59
EP 64
UT WOS:000428615600010
ER

PT B
AU Boggavarapu, LNP
   Prabukumar, M
AF Boggavarapu, L. N. P.
   Prabukumar, M.
GP IEEE
TI Survey on Classification Methods for Hyper Spectral Remote Sensing
   Imagery
SO 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL
   SYSTEMS (ICICCS)
CT International Conference on Intelligent Computing and Control Systems
   (ICICCS)
CY JUN 15-16, 2017
CL Vaigai Coll Engn, Madurai, INDIA
HO Vaigai Coll Engn
DE Hyperspectral remote sensing; Classification; Active Learning; Transfer
   Learning
ID HYPERSPECTRAL IMAGES; ROTATION FOREST; SEGMENTATION; DICTIONARY;
   SELECTION; ENSEMBLE
AB Classification of hyperspectral remote sensing images is key to extract abundant information. The researchers are focusing on the development of algorithms for accurate classifiers from last few decades. With the technological advancement and new modern methods of learning provide confidence for efficient and accurate classification when compared to the direct implementation of conventional learning algorithms. The variations in the conventional algorithm leads to active learning based and transfer learning based approaches and provide promising results. This paper attempt to explore various recent technologies applied to Hyperspectral imagery for classification.
CR Ammanouil R, 2017, IEEE T IMAGE PROCESS, V26, P340, DOI 10.1109/TIP.2016.2627815
   Briottet X., 2006, P SOC PHOTO-OPT INS, V6239, P62390
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Chutia D, 2016, T GIS, V20, P463, DOI 10.1111/tgis.12164
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Dong YN, 2017, IEEE T GEOSCI REMOTE, V55, P2509, DOI 10.1109/TGRS.2016.2645703
   Gan L., IEEE GEOSCIENCE REMO, VPP, P1
   Guo JL, 2017, IEEE J-STARS, V10, P347, DOI 10.1109/JSTARS.2016.2609404
   Jia S, 2017, IEEE T GEOSCI REMOTE, V55, P2575, DOI 10.1109/TGRS.2017.2647815
   Kemker R, 2017, IEEE T GEOSCI REMOTE, V55, P2693, DOI 10.1109/TGRS.2017.2651639
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Li JY, 2014, IEEE T GEOSCI REMOTE, V52, P3707, DOI 10.1109/TGRS.2013.2274875
   Li J, 2010, IEEE T GEOSCI REMOTE, V48, P4085, DOI 10.1109/TGRS.2010.2060550
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Liang J, 2017, IEEE T GEOSCI REMOTE, V55, P862, DOI 10.1109/TGRS.2016.2616489
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590
   Mitra P, 2004, PATTERN RECOGN LETT, V25, P1067, DOI 10.1016/j.patrec.2004.03.004
   Olmanson LG, 2013, REMOTE SENS ENVIRON, V130, P254, DOI 10.1016/j.rse.2012.11.023
   Pascucci S., 2009, IEEE INT GEOSC REM S
   Persello C, 2016, IEEE T GEOSCI REMOTE, V54, P2615, DOI 10.1109/TGRS.2015.2503885
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Prasad S, 2015, IEEE J-STSP, V9, P961, DOI 10.1109/JSTSP.2015.2457631
   Qiao T, 2017, IEEE T GEOSCI REMOTE, V55, P119, DOI 10.1109/TGRS.2016.2598065
   Rajan S, 2008, IEEE T GEOSCI REMOTE, V46, P1231, DOI 10.1109/TGRS.2007.910220
   Rajan Suju, 2008, ACTIVE LEARNING APPR, V46
   Rem o, 2013, EURASIPJOURNAL ADV S, V68
   Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Sakarya U., 2014, UZ ALG COGR BILG SIS
   Sun B, 2017, IEEE T GEOSCI REMOTE, V55, P212, DOI 10.1109/TGRS.2016.2604290
   Toksoz MA, 2017, IEEE T GEOSCI REMOTE, V55, P715, DOI 10.1109/TGRS.2016.2613931
   Torrey L., 2009, MACH LEARN, P1
   Xia JS, 2017, IEEE T GEOSCI REMOTE, V55, P421, DOI 10.1109/TGRS.2016.2607755
   Xia JS, 2016, IEEE GEOSCI REMOTE S, V13, P584, DOI 10.1109/LGRS.2016.2528043
   Xia JS, 2015, IEEE GEOSCI REMOTE S, V12, P1471, DOI 10.1109/LGRS.2015.2409112
   Xia JS, 2014, ADV COMPUT VIS PATT, P135, DOI 10.1007/978-3-319-05696-8_6
   Ye MC, 2017, IEEE T GEOSCI REMOTE, V55, P1544, DOI 10.1109/TGRS.2016.2627042
   Ye ZJ, 2017, IEEE T GEOSCI REMOTE, V55, P1199, DOI 10.1109/TGRS.2016.2621058
   Zarco-Tejada PJ, 2005, REMOTE SENS ENVIRON, V99, P271, DOI 10.1016/j.rse.2005.09.002
   Zhai H, 2017, IEEE GEOSCI REMOTE S, V14, P43, DOI 10.1109/LGRS.2016.2625200
   Zhang HY, 2016, IEEE T GEOSCI REMOTE, V54, P3672, DOI 10.1109/TGRS.2016.2524557
   Zhu W, 2017, IEEE T GEOSCI REMOTE, V55, P2786, DOI 10.1109/TGRS.2017.2654486
NR 42
TC 0
Z9 0
BN 978-1-5386-2745-7
PY 2017
BP 538
EP 542
UT WOS:000427931800103
ER

PT S
AU Tong, YZ
   Zhou, B
   Huang, JH
AF Tong, Yongzhi
   Zhou, Bin
   Huang, Jianhui
GP IEEE
TI Topic-adaptive Sentiment Analysis on Tweets via Learning from
   Multi-sources Data
SO 2017 10TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND
   DESIGN (ISCID), VOL. 1
SE International Symposium on Computational Intelligence and Design
CT 10th International Symposium on Computational Intelligence and Design
   (ISCID)
CY DEC 09-10, 2017
CL Hangzhou, PEOPLES R CHINA
DE sentiment analysis; topic adaption; transfer learning
ID DOMAIN ADAPTATION
AB Twitter sentiment analysis model trained from data of one topic may per-forms worse on another topic. While tweets have diverse topics, and the topic of target data of sentiment analysis task is change with the application requirement, which makes it hard to get a good performance. We also notice that one model cannot performs well on every topic, and tweets have no sentiment label to train the model. On the other hand, there are plenty of available text data with sentiment label and topic information such as online movie and product reviews. So we propose a method based on transfer learning, which use topic information and term distribution as a bridge between target tweets and texts from other sources. It could quickly find appropriate in-stances from other sources, and then use them to train a model adapting to target tweets of specific topic for getting better performance. The experiment result shows the effectiveness of the proposed method.
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Daume H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   Dong L., 2014, P 52 ANN M ASS COMP, V2, P49, DOI DOI 10.3115/V1/P14-2009
   Go A, 2009, TWITTER SENTIMENT CL
   Jiang L., 2011, P 49 ANN M ASS COMP, V1, P151
   Kouloumpis Efthymios, 2011, ICWSM, V11, P164
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu S.H, 2013, P 22 ACM INT C INF K, P2079, DOI DOI 10.1145/2505515.2505569
   Liu SH, 2015, IEEE T KNOWL DATA EN, V27, P1696, DOI 10.1109/TKDE.2014.2382600
   MCAULEY J, 2015, INT ACM SIGIR C RES, P43
   McAuley J. J., 2015, P 21 ACM SIGKDD INT, P785, DOI [10.1145/2783258.2783381, DOI 10.1145/2783258.2783381]
   Mejova Y, 2012, ICWSM
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan Sinno Jialin, 2010, P 19 INT C WORLD WID, P751, DOI DOI 10.1145/1772690.1772767
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79
   Pennington J, 2014, EMNLP, V14, P1532, DOI DOI 10.3115/V1/D14-1162
   Remus R, 2012, INT CONF DAT MIN WOR, P717, DOI 10.1109/ICDMW.2012.46
   Ren YF, 2016, INFORM SCIENCES, V369, P188, DOI 10.1016/j.ins.2016.06.040
   Saif H, 2013, WORKSH EM SENT SOC E
   Severyn A., 2015, P 9 INT WORKSH SEM E, P464
   Tang D., 2014, SEMEVAL, V2014, P208
   Tang Duyu, 2014, P 52 ANN M ASS COMP, P1555, DOI DOI 10.3115/V1/P14-1146
   Vo DT, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1347
   Wu Fangzhao, 2016, P 54 ANN M ASS COMP, V1, P301
   Xiang B., 2014, P 52 ANN M ASS COMP, V2, P434
NR 28
TC 0
Z9 0
SN 2165-1701
BN 978-1-5386-3675-6
PY 2017
BP 241
EP 246
DI 10.1109/ISCID.2017.143
UT WOS:000427991100054
ER

PT B
AU Wydya, KS
   Murfi, H
   Satria, Y
AF Wydya, Kartika Syskya
   Murfi, Hendri
   Satria, Yudi
GP IEEE
TI Evaluation of the Accuracy of Transfer Learning on Sentiment Analysis
   for Indonesian Tweets
SO 2017 1ST INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL
   SCIENCES (ICICOS)
CT 1st International Conference on Informatics and Computational Sciences
   (ICICoS)
CY NOV 15-16, 2017
CL Univ Diponegoro, Dept Informat, Semarang, INDONESIA
HO Univ Diponegoro, Dept Informat
DE Sentiment Analysis; Transfer Learning; Support Vector Machine; Twitter
AB Sentiment analysis is an automatic process of understanding, extracting and processing textual data to obtain the sentiment information. From machine learning point of view, the sentiment analysis is a supervised learning problem whose training and predicting data come from a similar domain. When domain changes, the machine learning model must be rebuilt from scratch using new training data. New training data requires manual labeling process which is very costly and time-consuming. Therefore, it would be more effective and efficient using transfer learning which uses the training data from an already available domain to deal with the estimating data on different domains. In this paper, we evaluate the accuracy of the transfer learning on sentiment analysis for Indonesian tweets. Our simulations show that the accuracy of the transfer learning is still lower than that of the supervised learning. Moreover, the bi-gram features can improve the accuracy of the transfer learning.
CR Bishop CM, 2006, PATTERN RECOGNITION
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Hsu C. W., 2013, PRACTICAL GUIDE SUPP
   Jun S., 2016, ICDM INT WORKSH DAT
   Manning C. D., 2008, INTRO INFORM RETRIEV
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Scholkopf B., 2002, LEARNING KERNELS SUP
   Whitehead M., 2009, 2009 WRI WORLD C COM
NR 8
TC 0
Z9 0
BN 978-1-5386-0903-3
PY 2017
BP 231
EP 236
UT WOS:000428164000040
ER

PT S
AU Ahmad, R
   Naz, S
   Afzal, MZ
   Rashid, SF
   Liwicki, M
   Dengel, A
AF Ahmad, Riaz
   Naz, Saeeda
   Afzal, M. Zeshan
   Rashid, S. Faisal
   Liwicki, Marcus
   Dengel, Andreas
GP IEEE
TI The Impact of Visual Similarities of Arabic-like Scripts Regarding
   Learning in an OCR System
SO 2017 14TH IAPR INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND
   RECOGNITION (ICDAR 2017), VOL 7
SE Proceedings of the International Conference on Document Analysis and
   Recognition
CT 14th IAPR International Conference on Document Analysis and Recognition
   (ICDAR)
CY NOV 09-15, 2017
CL Kyoto, JAPAN
DE Arabic script based languages; Generalized OCR; MDLSTM; CTC
ID HANDWRITTEN TEXT DATABASE; NEURAL-NETWORKS; RECOGNITION; KHATT
AB Many languages use Arabic script for written communication either in basic or augmented form. These languages include Urdu, Pashto, Persian, etc. As the primary characters are shared among all these languages, it is possible to take advantage of the visual similarities for Optical Character Recognition (OCR). OCR models optimized for individual languages have been proposed. However, to the best of our knowledge, there is no attempt to develop a single system for more than one language. The contributions of the presented work are: First, it investigates the effect on the recognition accuracy when different languages are combined (A pioneering study). Second, it introduces publicly available synthetic datasets for Arabic and Pashto languages for experimental purposes. Third, this paper provides statistical analysis as clues for transfer learning concerning OCR systems for Arabic, Urdu, and Pashto languages.
CR Ahmad R., 2016, DAS 2016
   Ahmad R, 2016, INT CONF FRONT HAND, P453, DOI [10.1109/ICFHR.2016.70, 10.1109/ICFHR.2016.0090]
   Ahmad R, 2015, 2015 13TH IAPR INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), P1101, DOI 10.1109/ICDAR.2015.7333931
   Ahmad R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133648
   Graves A., 2012, GUIDE OCR ARABIC SCR, P1
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Mahmoud SA, 2012, INT CONF FRONT HAND, P449, DOI 10.1109/ICFHR.2012.224
   Naz S., 2016, NEURAL COMPUT APPL, V26, P1
   Naz S., 2017, NEUROCOMPUT IN PRESS
   Naz S, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3442-4
   Naz S, 2016, PROCEDIA COMPUT SCI, V96, P16, DOI 10.1016/j.procs.2016.08.084
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Naz S, 2014, PATTERN RECOGN, V47, P1229, DOI 10.1016/j.patcog.2013.09.037
   Parvez M., 2013, ACM COMPUTING SURVEY
   Pechwitz M., 2002, P CIFED CIT, V2, P127
   Rashid S. F., 2013, P 4 INT WORKSH MULT, P6
   Sabbour N., 2013, P SPIE INT SOC OPTIC, V86580
   Yousefi M. R., 2015, IS T SPIE ELECT IMAG
NR 20
TC 1
Z9 1
SN 1520-5363
BN 978-1-5386-3586-5
PY 2017
BP 15
EP 19
DI 10.1109/ICDAR.2017.359
UT WOS:000428139600003
ER

PT B
AU Thao, LT
   Quang, NH
AF Le Thu Thao
   Nguyen Hong Quang
BE Bui, LT
   Binh, HTT
   Nguyen, VG
   Namatame, A
   Ong, YS
   Nguyen, TT
TI Automatic skin lesion analysis towards melanoma detection
SO 2017 21ST ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS
   (IES)
CT 21st Asia Pacific Symposium on Intelligent and Evolutionary Systems
   (IES)
CY NOV 15-17, 2017
CL Quy Don Tech Univ, Hanoi, VIETNAM
HO Quy Don Tech Univ
DE convolutional neural networks; deep learning; transfer learning; skin
   lesions
AB Deep learning methods for image analysis have shown impressive performance in recent years. In this paper, we present deep learning based approaches to solve two problems in skin lesion analysis using a dermoscopic image containing skin tumor. In the first problem, we use a fully convolutional-deconvolutional architecture to automatically segment skin tumor from the surrounding skin. In the second problem, we use a simple convolutional neural network and VGG-16 architecture using transfer learning to address the two different tasks in skin tumor classification. The proposed models are trained and evaluated on standard benchmark datasets from the International Skin Imaging Collaboration (ISIC) 2017 Challenge, which consists of 2000 training samples and 600 testing samples. The result shows that the proposed methods achieve promising performances. In the first problem, the average value of Jaccard index for lesion segmentation using hilly convolutional-deconvolutional architecture is 0.507. In the second problem, the values of area under the receiver operating characteristic curve (AUC) on two different lesion classifications using VGG16 with transfer learning are 0.763 and 0.869, respectively; the average value of AUC in two tasks is 0.816.
CR Gutman D, INT S BIOM IM ISBI 2
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Kingma Diederik P., 2015, 3 INT C LEARN REPR I
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K., 2015, INT C LEARN REPR ICL
NR 8
TC 0
Z9 0
BN 978-1-5386-0743-5
PY 2017
BP 106
EP 111
UT WOS:000427680100019
ER

PT B
AU Feng, YL
   Cai, YY
AF Feng, Yeli
   Cai Yiyu
GP IEEE
TI No-reference Image Quality Assessment through Transfer Learning
SO 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING
   (ICSIP)
CT 2nd IEEE International Conference on Signal and Image Processing (ICSIP)
CY AUG 04-06, 2017
CL Singapore, SINGAPORE
DE image quality; no reference; transfer learning
ID NEURAL-NETWORKS
AB Transfer learning has emerged from recent years' great success of applying convolutional neural networks to object recognition tasks. In this work, we describe a transfer learning framework that learns an image quality estimator end-to-end in classification or regression. Experiments show this approach achieves state of the art performance on four publicly available image quality databases. Image quality is ignored in visual recognition challenges such as PASCAL VOC and ILSVRC. However, it poses a practical challenge to the design of robust vision applications. This work responds to such challenge without impacting the performance of recognition tasks.
RI Cai, Yiyu/A-3816-2011
OI Cai, Yiyu/0000-0002-8406-9536
CR Bianco S., 2016, ARXIV160205531
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Ghadiyaram D, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P946, DOI 10.1109/GlobalSIP.2014.7032260
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kilmmerer M., 2016, ARXIV161001563
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh H. R., 2005, LIVE IMAGE QUALITY A
   Simonyan K., 2014, ARXIV14091556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 28
TC 0
Z9 0
BN 978-1-5386-0969-9
PY 2017
BP 90
EP 94
UT WOS:000427487200019
ER

PT S
AU Naseer, T
   Burgard, W
AF Naseer, Tayyab
   Burgard, Wolfram
BE Bicchi, A
   Okamura, A
TI Deep Regression for Monocular Camera-based 6-DoF Global Localization in
   Outdoor Environments
SO 2017 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY SEP 24-28, 2017
CL Vancouver, CANADA
AB Precise localization of robots is imperative for their safe and autonomous navigation in both indoor and outdoor environments. In outdoor scenarios, the environment typically undergoes significant perceptual changes and requires robust methods for accurate localization. Monocular camerabased approaches provide an inexpensive solution to such challenging problems compared to 3D LiDAR-based methods. Recently, approaches have leveraged deep convolutional neural networks (CNNs) to perform place recognition and they turn out to outperform traditional handcrafted features under challenging perceptual conditions. In this paper, we propose an approach for directly regressing a 6-DoF camera pose using CNNs and a single monocular RGB image. We leverage the idea of transfer learning for training our network as this technique has shown to perform better when the number of training samples are not very high. Furthermore, we propose novel data augmentation in 3D space for additional pose coverage which leads to more accurate localization. In contrast to the traditional visual metric localization approaches, our resulting map size is constant with respect to the database. During localization, our approach has a constant time complexity of O (1) and is independent of the database size and runs in real-time at similar to 80 Hz using a single GPU. We show the localization accuracy of our approach on publicly available datasets and that it outperforms CNN-based state-of-the-art methods.
CR Badino H., 2012, P IEEE INT C ROB AUT
   Caselitz T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1926, DOI 10.1109/IROS.2016.7759304
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huynh DQ, 2009, J MATH IMAGING VIS, V35, P155, DOI 10.1007/s10851-009-0161-2
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kendall Alex, 2016, P IEEE INT C ROB AUT
   Kingma D., 2014, ARXIV14126980
   Li YP, 2016, ADV COMPUT VIS PATT, P147, DOI 10.1007/978-3-319-25781-5_8
   Ling YH, 2015, INT CONF ASIC
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   McManus Colin, 2014, P ROBOTICS SCI SYSTE
   Milford  M., 2012, P IEEE INT C ROB AUT
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Neubert P, 2016, IEEE ROBOT AUTOM LET, V1, P484, DOI 10.1109/LRA.2016.2517824
   Pascoe G., 2015, P IEEE INT C COMP VI, P9
   Sattler T., 2016, IEEE T PATTERN ANAL
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Simonyan K., 2014, ARXIV14091556
   Sunderhauf Niko, 2015, P ROBOTICS SCI SYSTE
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790
   Walch F., 2016, ARXIV161107890
   Zeisl Bernhard, 2015, P IEEE INT C COMP VI
   Zhou B., 2014, ADV NEURAL INFORM PR
NR 26
TC 4
Z9 4
SN 2153-0858
BN 978-1-5386-2682-5
PY 2017
BP 1525
EP 1530
UT WOS:000426978201126
ER

PT S
AU Schilling, F
   Chen, X
   Folkesson, J
   Jensfelt, P
AF Schilling, Fabian
   Chen, Xi
   Folkesson, John
   Jensfelt, Patric
BE Bicchi, A
   Okamura, A
TI Geometric and Visual Terrain Classification for Autonomous Mobile
   Navigation
SO 2017 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY SEP 24-28, 2017
CL Vancouver, CANADA
ID TRAVERSABILITY ANALYSIS; VISION
AB In this paper, we present a multi-sensory terrain classification algorithm with a generalized terrain representation using semantic and geometric features. We compute geometric features from lidar point clouds and extract pixel-wise semantic labels from a fully convolutional network that is trained using a dataset with a strong focus on urban navigation. We use data augmentation to overcome the biases of the original dataset and apply transfer learning to adapt the model to new semantic labels in off-road environments. Finally, we fuse the visual and geometric features using a random forest to classify the terrain traversability into three classes: safe, risky and obstacle.
   We implement the algorithm on our four-wheeled robot and test it in novel environments including both urban and off-road scenes which are distinct from the training environments and under summer and winter conditions. We provide experimental result to show that our algorithm can perform accurate and fast prediction of terrain traversability in a mixture of environments with a small set of training data.
CR Bajracharya M, 2009, J FIELD ROBOT, V26, P3, DOI 10.1002/rob.20269
   Berczi LP, 2015, IEEE INT CONF ROBOT, P3178, DOI 10.1109/ICRA.2015.7139637
   Chen L.-C., 2016, IEEE T PATTERN ANAL, P1, DOI DOI 10.1109/INFOCOM.2016.7524570
   Cordts M., 2016, P IEEE C COMP VIS PA
   Dahlkamp H., 2006, ROBOTICS SCI SYSTEMS, V38
   Dodge S., 2016, UNDERSTANDING IMAGE
   Droeschel D, 2014, IEEE INT CONF ROBOT, P5221, DOI 10.1109/ICRA.2014.6907626
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Filitchkin P, 2012, IEEE INT C INT ROBOT, P1387, DOI 10.1109/IROS.2012.6386042
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gennery DB, 1999, AUTON ROBOT, V6, P131, DOI 10.1023/A:1008831426966
   Goldberg S. B., 2002, 2002 IEEE Aerospace Conference Proceedings (Cat. No.02TH8593), P5, DOI 10.1109/AERO.2002.1035370
   Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276
   He K., 2015, CORR
   Howard A, 2001, J ROBOTIC SYST, V18, P577, DOI 10.1002/rob.1046
   Ioannou Y, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P501, DOI 10.1109/3DIMPVT.2012.12
   Jansen P., 2005, COLOUR BASED OFF ROA
   Khan Y. N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1014, DOI 10.1109/ICCVW.2011.6130362
   Kim D, 2006, IEEE INT CONF ROBOT, P518, DOI 10.1109/ROBOT.2006.1641763
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Laible S, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P172, DOI 10.1109/ECMR.2013.6698838
   Long J., 2015, IEEE C COMP VIS PATT
   Ojeda L, 2006, J FIELD ROBOT, V23, P103, DOI 10.1002/rob.20113
   Papadakis P, 2013, ENG APPL ARTIF INTEL, V26, P1373, DOI 10.1016/j.engappai.2013.01.006
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell B. C., 2001, INT J COMPUT VISION, V77, P157
   Schmidt J, 2004, GEODERMA, V121, P243, DOI 10.1016/j.geoderma.2003.10.008
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Sock J, 2016, IEEE INT CONF ROBOT, P5631, DOI 10.1109/ICRA.2016.7487782
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suger B, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3608, DOI 10.1109/IROS.2016.7759531
NR 31
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-2682-5
PY 2017
BP 2678
EP 2684
UT WOS:000426978202117
ER

PT S
AU Liu, AS
   Li, ZJ
   Yeh, TH
   Yang, YH
   Fu, LC
AF Liu, An-Sheng
   Li, Zi-Jun
   Yeh, Tso-Hsin
   Yang, Yu-Huan
   Fu, Li-Chen
BE Bicchi, A
   Okamura, A
TI Partially Transferred Convolution Neural Network with Cross-Layer
   Inheriting for Posture Recognition from Top-view Depth Camera
SO 2017 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY SEP 24-28, 2017
CL Vancouver, CANADA
ID HUMAN POSE ESTIMATION
AB This paper proposes a new method for human posture recognition from top-view depth maps on small training datasets. There are two strategies developed to leverage the capability of convolution neural network (CNN) in mining the fundamental and generic features for recognition. First, the early layers of CNN should serve the function to extract feature without specific representation. By applying the concept of transfer learning, the first few layers from the pre-learned VGG model can be used directly without further fine-tuning. To alleviate the computational loading and to increase the accuracy of our partially transferred model, a cross-layer inheriting feature fusion (CLIFF) is proposed by using the information from the early layer in fully connected layer without further processing. The experimental result shows that combination of partial transferred model and CLIFF can provide better performance than VGG16 [1] model with re-trained FC layer and other hand-crafted features like RBPs [2].
CR Abadi M., 2016, P 12 USENIX C OP SYS
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fu LR, 2017, IEEE T IMAGE PROCESS, V26, P927, DOI 10.1109/TIP.2016.2639441
   Hague A., 2016, ARXIV160307076
   Hsu TW, 2016, IEEE SYS MAN CYBERN, P4058, DOI 10.1109/SMC.2016.7844868
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A., 2012, P 25 INT C NEUR INF
   Lei J, 2016, 2016 INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2016), P63, DOI 10.1109/ICIVC.2016.7571275
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/CVPRW.2010.5543273
   Lin SC, 2015, IEEE SYS MAN CYBERN, P2968, DOI 10.1109/SMC.2015.516
   Pfister T., 2015, ARXIV150602897
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Rafi Umer, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P67, DOI 10.1109/CVPRW.2015.7301338
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Song J., 2016, IEEE SIGNAL PROCESSI, P1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yosinski J., 2014, P 27 INT C NEUR INF
   Zeiler M. D, 2013, ARXIV13112901
NR 21
TC 0
Z9 0
SN 2153-0858
BN 978-1-5386-2682-5
PY 2017
BP 4139
EP 4143
UT WOS:000426978204009
ER

PT S
AU Helwa, MK
   Schoellig, AP
AF Helwa, Mohamed K.
   Schoellig, Angela P.
BE Bicchi, A
   Okamura, A
TI Multi-Robot Transfer Learning: A Dynamical System Perspective
SO 2017 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)
SE IEEE International Conference on Intelligent Robots and Systems
CT IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS)
CY SEP 24-28, 2017
CL Vancouver, CANADA
AB Multi-robot transfer learning allows a robot to use data generated by a second, similar robot to improve its own behavior. The potential advantages are reducing the time of training and the unavoidable risks that exist during the training phase. Transfer learning algorithms aim to find an optimal transfer map between different robots. In this paper, we investigate, through a theoretical study of single-input single-output (SISO) systems, the properties of such optimal transfer maps. We first show that the optimal transfer learning map is, in general, a dynamic system. The main contribution of the paper is to provide an algorithm for determining the properties of this optimal dynamic map including its order and regressors (i.e., the variables it depends on). The proposed algorithm does not require detailed knowledge of the robots' dynamics, but relies on basic system properties easily obtainable through simple experimental tests. We validate the proposed algorithm experimentally through an example of transfer learning between two different quadrotor platforms. Experimental results show that an optimal dynamic map, with correct properties obtained from our proposed algorithm, achieves 60-70% reduction of transfer learning error compared to the cases when the data is directly transferred or transferred using an optimal static map.
CR Berkenkamp Felix, 2015, EUR CONTR C, P2501
   Bocsi B., 2013, 2013 INT JOINT C NEU, P1
   Boutsioukis Georgios, 2012, Recent Advances in Reinforcement Learning. 9th European Workshop (EWRL 2011). Revised Selected Papers, P249, DOI 10.1007/978-3-642-29946-9_25
   Devin Coline, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2169, DOI 10.1109/ICRA.2017.7989250
   Doyle III F., 1997, NONLINEAR PROCESS CO
   Nguyen-Tuong D, 2011, COGN PROCESS, V12, P319, DOI 10.1007/s10339-011-0404-1
   Gupta A, 2017, INT C LEARN REPR
   Hamer M, 2013, IEEE INT C INT ROBOT, P1714, DOI 10.1109/IROS.2013.6696580
   Helwa MK, 2016, IEEE DECIS CONTR P, P3000, DOI 10.1109/CDC.2016.7798717
   Isidori A, 1995, NONLINEAR CONTROL SYSTEMS DESIGN 1995, VOLS 1 AND 2, P87
   Janssens P, 2012, P AMER CONTR CONF, P610
   Lakshmanan Balaji, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P3251, DOI 10.1109/IROS.2010.5649422
   Levine S, 2015, IEEE INT CONF ROBOT, P156, DOI 10.1109/ICRA.2015.7138994
   Makondo N, 2015, IEEE-RAS INT C HUMAN, P1075, DOI 10.1109/HUMANOIDS.2015.7363502
   Marco Alonso, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1557, DOI 10.1109/ICRA.2017.7989186
   Ostafew CJ, 2016, INT J ROBOT RES, V35, P1547, DOI 10.1177/0278364916645661
   Qiyang Li, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5183, DOI 10.1109/ICRA.2017.7989607
   Raimalwala KV, 2015, IEEE INT C INT ROBOT, P5253, DOI 10.1109/IROS.2015.7354118
   Schollig A, 2011, P AMER CONTR CONF, P3843
   Schoellig AP, 2012, ASIAN J CONTROL, V14, P613, DOI 10.1002/asjc.398
   Sontag Eduardo, 1997, 1997 European Control Conference (ECC), P3862
   Tuyls K, 2012, AI MAG, V33, P41, DOI 10.1609/aimag.v33i3.2426
   Um TT, 2014, IEEE INT CONF ROBOT, P5679, DOI 10.1109/ICRA.2014.6907694
   Wang C., 2008, P 25 INT C MACH LEAR, P1120
   Wang C., 2009, AAAI FALL S MAN LEAR, P53
NR 25
TC 2
Z9 2
SN 2153-0858
BN 978-1-5386-2682-5
PY 2017
BP 4702
EP 4708
UT WOS:000426978204078
ER

PT S
AU Li, WT
   Hu, JL
AF Li, Weite
   Hu, Jinglu
GP IEEE
TI A Multilayer Gated Bilinear Classifier: from Optimizing a Deep Rectified
   Network to a Support Vector Machine
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB A deep neural network (DNN) is called as a deep rectified network (DRN), if using Rectified Linear Units (ReLUs) as its activation function. In this paper, we show its parameters can be seen to play two important roles simultaneously: one for determining the subnetworks corresponding to the inputs and the other for the parameters of those subnetworks. This observation leads our paper to proposing a method to combine a DNN and an SVM, as a deep classifier. For a DRN trained by a common tuning algorithm, a multilayer gated bilinear classifier is designed to mimic its functionality. Its parameter set is duplicated into two independent sets, playing different roles. One set is used to generate gate signals so as to determine subnetworks corresponding to its inputs, and keeps fixed when optimizing the classifier. The other set serves as parameters of subnetworks, which are linear classifiers. Therefore, their parameters can be implicitly optimized by applying SVM optimizations. Since the DRN is only to generate gate signals, we show in experiments, that it can be trained by using supervised, or unsupervised learning, and even by transfer learning.
CR Bengio Y., 2007, P ADV NEUR INF PROC, P153
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Clevert D. A., 2015, ARXIV151107289 ARXIV
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Glorot X., 2011, INT C ARTIF INTELLIG, P315, DOI DOI 10.1177/1753193410395357
   Goodfellow I. J., 2013, ARXIV13024389 ARXIV
   He K., 2015, ARXIV151203385 ARXIV
   Hinton G., 2015, ARXIV150302531 ARXIV
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Ioffe S., 2015, ARXIV150203167 ARXIV
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lee C., 2014, ARXIV14095185 ARXIV
   Li H., 2016, 33 INT C MACH LEARN
   Lin M., 2013, ARXIV13124400 ARXIV
   Makhzani A., 2013, ARXIV13125663 ARXIV
   Makhzani A., 2015, ADV NEURAL INFORM PR, P2773
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Romero A., 2014, ARXIV14126550 ARXIV
   Salakhutdinov R., 2009, ARTIF INTELL, V5, P1967, DOI DOI 10.1109/CVPRW.2009.5206577
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Springenberg J. T., 2014, 14126806 ARXIV
   Srivastava R. K., 2014, ARXIV14101165 ARXIV
   SRIVASTAVA RK, 2013, ADV NEURAL INFORM PR, P2310
   Tang Y., 2013, P 30 INT C MACH LEAR
   Tokui Seiya, CHAINER NEXT GENERAT
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
NR 32
TC 0
Z9 0
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 140
EP 146
UT WOS:000426968700020
ER

PT S
AU Liu, XB
   Liu, ZT
   Wang, GJ
   Cai, ZH
   Zhang, H
AF Liu, Xiaobo
   Liu, Zhentao
   Wang, Guangjun
   Cai, Zhihua
   Zhang, Harry
GP IEEE
TI A Weighted-resampling based Transfer Learning Algorithm
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
ID ADAPTIVE DIFFERENTIAL EVOLUTION; ENSEMBLE; CLASSIFICATION; EXTRACTION;
   RESOLUTION; MODEL
AB Transfer learning has attracted more and more attention, and many scholars proposed some useful strategies. Boosting is the main strategy for transfer learning. In boosting, resampling is preferred over reweighting, and it can be applied to any base learner. In this paper, we propose a weighted-resampling method for transfer learning, called TrResampling. Firstly, resampling is applied to the data with heaven weight in the source domain, and the resampled data is used with the target data as the training data to build a classifier. Then the TrAdaBoost algorithm is used to adjust the weights of source data and target data. We discuss Decision Tree, Naive Bayes, and SVM as the base learner in TrResampling, and choose the suitable for TrResampling. In order to illustrate the performance of the proposed algorithm, we compare TrResampling with the state-of-the-art algorithm TrAdaBoost and the base learner Decision Tree, experimental results on UCI data sets indicate that TrResampling is superior to TrAdaBoost and Decision Tree on many data sets.
CR Acharya A, 2014, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2601435
   Bhatt HS, 2014, IEEE T IMAGE PROCESS, V23, P5654, DOI 10.1109/TIP.2014.2362658
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Eaton E, 2009, INT CONF DAT MIN WOR, P422, DOI 10.1109/ICDMW.2009.97
   Feng L, 2015, MEMET COMPUT, V7, P159, DOI 10.1007/s12293-015-0166-x
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gong WY, 2015, ENERGY, V86, P139, DOI 10.1016/j.energy.2015.03.117
   Kamishima T, 2009, IEEE DATA MINING, P219, DOI 10.1109/ICDM.2009.9
   Kandaswamy C, 2015, LECT NOTES COMPUT SC, V9094, P335, DOI 10.1007/978-3-319-19258-1_29
   Kearns M, 1999, J COMPUT SYST SCI, V58, P109, DOI 10.1006/jcss.1997.1543
   La L, 2014, NEURAL COMPUT APPL, V24, P807, DOI 10.1007/s00521-012-1297-3
   Liu XB, 2015, J ADV COMPUT INTELL, V19, P381
   Mahmood Z, 2016, IET BIOMETRICS, V5, P111, DOI 10.1049/iet-bmt.2015.0008
   Mei SY, 2014, J THEOR BIOL, V340, P105, DOI 10.1016/j.jtbi.2013.09.007
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schaefer G, 2014, MEMET COMPUT, V6, P233, DOI 10.1007/s12293-014-0144-8
   Seiffert C, 2008, PROC INT C TOOLS ART, P445, DOI 10.1109/ICTAI.2008.59
   Sheskin D. J, 2006, HDB PARAMETRIC NONPA
   Wu J, 2014, J INTELL INF SYST, V42, P671, DOI 10.1007/s10844-013-0279-y
   Wu J, 2012, INT J COMPUT APPL T, V43, P378, DOI 10.1504/IJCAT.2012.047164
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Xiao J, 2014, INT JOINT CONF COMPU, P64, DOI 10.1109/CSO.2014.21
   Xing YF, 2013, SCI WORLD J, DOI 10.1155/2013/381219
   Xu ZJ, 2011, PROC INT C TOOLS ART, P399, DOI 10.1109/ICTAI.2011.65
   Zhou Z. H., 2012, ENSEMBLE METHODS FDN
   Zhou Zhi- Hua, 2009, ENCY BIOMETRICS, P270, DOI 10.1007/978-0-387-73003-5_293
NR 28
TC 0
Z9 0
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 185
EP 190
UT WOS:000426968700026
ER

PT S
AU Wang, GJ
   Zhang, GQ
   Choi, KS
   Lam, KM
   Lu, J
AF Wang, Guanjin
   Zhang, Guangquan
   Choi, Kup-Sze
   Lam, Kin-Man
   Lu, Jie
GP IEEE
TI An output-based knowledge transfer approach and its application in
   bladder cancer prediction
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
DE transfer learning; machine learning; support vector machine; cancer
   prediction
ID RADICAL CYSTECTOMY; MORTALITY
AB Many medical applications face a situation that the on-hand data cannot fully fit an existing predictive model or on-line tool, since these models or tools only use the most common predictors and the other valuable features collected in the current scenario are not considered altogether. On the other hand, the training data in the current scenario is not sufficient to learn a predictive model effectively yet. In order to overcome these problems and construct an efficient classifier, for these real situations in medical fields, in this work we present an approach based on the least squares support vector machine (LS-SVM), which utilizes a transfer learning framework to make maximum use of the data and guarantee its enhanced generalization capability. The proposed approach is capable of effectively learning a target domain with limited samples by relying on the probabilistic outputs from the other previously learned model using a heterogeneous method in the source domain. Moreover, it autonomously and quickly decides how much output knowledge to transfer from source domain to the target one using a fast leave-one-out cross validation strategy. This approach is applied on a real-world clinical dataset to predict 5-year mortality of bladder cancer patients after radical cystectomy, and the experimental results indicate that the proposed method can achieve better performances compared to traditional machine learning methods, consistently showing the potential of the proposed method under the circumstances with insufficient data.
RI Zhang, Guangquan/G-2553-2017
OI Zhang, Guangquan/0000-0003-3960-0583
CR Bonilla E. V., 2007, NEURAL INFORM PROCES, P153
   Buscema M, 1998, SUBST USE MISUSE, V33, P233, DOI 10.3109/10826089809115863
   Chan ESY, 2013, HONG KONG MED J, V19, P400, DOI 10.12809/hkmj133964
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cruz Joseph A., 2006, CANC INFORM, V2
   Deng ZH, 2016, ACM T INTEL SYST TEC, V8, DOI 10.1145/2903725
   Deng ZH, 2013, IEEE T NEUR NET LEAR, V24, P1200, DOI 10.1109/TNNLS.2013.2253617
   Duan L., 2012, P 29 INT C MACH LEAR
   Frank  M., 1956, NAVAL RES LOGIST QUA, V3, P95, DOI [10.1002/nav.3800030109, DOI 10.1002/NAV.3800030109]
   Gao J, 2008, KDD, P283, DOI DOI 10.1145/1401890.1401928
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   Jebara T, 2004, P 21 INT C MACH LEAR, P55, DOI DOI 10.1145/1015330.1015426
   Liu B., 2002, ICML, V2, P387
   Lughezzani G, 2011, CANCER-AM CANCER SOC, V117, P103, DOI 10.1002/cncr.25345
   Mihalkova L., 2007, P NAT C ART INT, P608
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI DOI 10.4249/SCHOLARPEDIA.1883
   Schwaighofer A, 2004, NIPS, P1209
   Suykens J.A.K., 2002, LEAST SQUARES SUPPOR
   Wang GJ, 2015, COMPUT BIOL MED, V63, P124, DOI 10.1016/j.compbiomed.2015.05.015
   Zuo H, 2015, ADV INTEL SYS RES, V89, P1000
NR 22
TC 0
Z9 0
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 356
EP 363
UT WOS:000426968700049
ER

PT S
AU Sargano, AB
   Wang, XF
   Angelov, P
   Habib, Z
AF Sargano, Allah Bux
   Wang, Xiaofeng
   Angelov, Plamen
   Habib, Zulfiqar
GP IEEE
TI Human Action Recognition using Transfer Learning with Deep
   Representations
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
DE action recognition; deep learning; transfer learning; hybrid classifier
ID SILHOUETTE
AB Human action recognition is an imperative research area in the field of computer vision due to its numerous applications. Recently, with the emergence and successful deployment of deep learning techniques for image classification, object recognition, and speech recognition, more research is directed from traditional handcrafted to deep learning techniques. This paper presents a novel method for human action recognition based on a pre-trained deep CNN model for feature extraction & representation followed by a hybrid Support Vector Machine (SVM) and K-Nearest Neighbor (KNN) classifier for action recognition. It has been observed that already learnt CNN based representations on large-scale annotated dataset could be transferred to action recognition task with limited training dataset. The proposed method is evaluated on two well-known action datasets, i.e., UCF sports and KTH. The comparative analysis confirms that the proposed method achieves superior performance over state-of-the-art methods in terms of accuracy.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   Angelov P., P EUR S ART NNS
   Atmosukarto I., 2015, 2015 IEEE WINT C APP
   Aytar Y., 2014, TRANSFER LEARNING OB
   Azizpour H., 2015, P IEEE C COMP VIS PA
   Bux A, 2017, ADV INTELL SYST, V513, P341, DOI 10.1007/978-3-319-46562-3_23
   Cao L., 2010, COMP VIS PATT REC CV
   Cao XB, 2013, NEUROCOMPUTING, V100, P51, DOI 10.1016/j.neucom.2011.12.043
   Charalampous K, 2016, PATTERN ANAL APPL, V19, P337, DOI 10.1007/s10044-014-0404-8
   Chatfield  K., 2014, ARXIV14053531
   Chiu T.-H., 2014, ARXIV14094127
   Ding S., 2016, CONTR DEC C CCDC 201
   Tran DN, 2015, IEEE INT CON MULTI
   Fathi A., 2012, EUR C COMP VIS
   Fei-Fei L., 2006, P INT C DEV LEARN IC
   Girshick R., 2014, P IEEE C COMP VIS PA
   He K., 2016, P IEEE C COMP VIS PA
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jain M., 2013, P IEEE C COMP VIS PA
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A., 2014, P IEEE C COMP VIS PA
   Klaser A., 2008, BMVC 2008
   Kovashka A., 2010, COMP VIS PATT REC CV
   Krizhevsky A., 2012, ADV NEURAL INFORM PR
   Le QV, 2011, COMP VIS PATT REC CV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li F, 2015, IEEE COMPUT SOC CONF
   Nam H S, 2015, ARXIV151007945
   Noh H, 2015, P IEEE INT C COMP VI
   Oquab Maxime, 2014, P IEEE C COMP VIS PA
   Rahman Ahad M. A., 2016, J MULTIMODAL USER IN
   Razavian S. A., 2014, P IEEE C COMP VIS PA
   Rodriguez M., 2010, SPATIOTEMPORAL MAXIM
   Sargano AB, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010110
   Sargano AB, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6100309
   Schuldt C., 2004, PATT REC 2004 ICPR 2
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Simonyan K., 2014, ADV NEURAL INFORM PR
   Smeaton A.F., 2006, P 8 ACM INT WORKSH M
   Szegedy C., 2015, P IEEE C COMP VIS PA
   Taylor Graham W., 2010, EUR C COMP VIS
   Tian Y., 2016, P 2016 ACM MULT C
   Vishwakarma DK, 2015, EXPERT SYST APPL, V42, P6957, DOI 10.1016/j.eswa.2015.04.039
   Wang H., 2009, BMVC 2009
   Wang H., 2013, P IEEE INT C COMP VI
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang H, 2011, PROC CVPR IEEE
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Willems Geert, 2008, EUR C COMP VIS
   Wu D, 2012, IEEE GLOB COMM CONF
   Yuan CF, 2014, IEEE T IMAGE PROCESS, V23, P658, DOI 10.1109/TIP.2013.2291319
   Zeiler M.D., 2014, EUR C COMP VIS
   Zhu F., 2016, IMAGE VISION COMPUTI
NR 55
TC 6
Z9 6
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 463
EP 469
UT WOS:000426968700063
ER

PT S
AU Gutstein, S
   Stump, E
AF Gutstein, Steven
   Stump, Ethan
GP IEEE
TI The Effects of Output Codes on Transfer Learning in a Deep Convolutional
   Neural Net
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB The output encodings of neural nets determine the structure of the space in which inference occurs. Yet, they are generally given very little thought. It is common practice for neural nets to use 1-Hot encoding when training to discriminate among many classes. The primary exceptions to this are error correcting output codes, and semantic output encodings. Output encodings based upon semantic descriptors cause a net to learn responses for classes to which it has not been exposed, provided those classes may be characterized by the same semantic descriptors. This raises a number of questions, such as "Can a net implicitly learn encodings for unobserved classes in the absence of a semantic encoding, or any encoding that requires some form of prior knowledge and hand crafting?". Also, are some output encodings better than others for learning these implicit encodings?
   In this paper, we will compare how effectively different non-semantic encodings are at causing a neural net to implicitly learn encodings for unobserved classes. Also, while evaluating the efficacy of these implicit encodings, we will look for evidence of a phenomenon akin to over-training. Specifically, as training on the observed classes occurs, we initially see improvement in how well the implicitly learned encodings can be used to differentiate among the classes which are unobserved during the net's training. However, as training continues to improve discrimination among the observed classes, the efficacy of the implicit codes either remains steady, or undergoes a degradation. This degradation is akin to the overtraining that one generally tries to guard against when training a neural net.
CR Bromley J., 1993, INT J PATTERN RECOGN, V7
   Caruana R., 1995, Advances in Neural Information Processing Systems 7, P657
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chopra Sumit, 2005, P COMP VIS PATT REC
   Dietterich T. G., 1991, AAAI-91. Proceedings Ninth National Conference on Artificial Intelligence, P572
   Fink M., 2005, ADV NEURAL INFORM PR, P449
   Gutstein S, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1316, DOI 10.1109/IJCNN.2011.6033376
   Gutstein Steven, 2015, 2015 INT JOINT C NEU, P1
   Hadsell R., 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Honzik C. H., 1930, U CALIFORNIA PUBLICA, V4, P215
   James G, 1998, J COMPUT GRAPH STAT, V7, P377, DOI 10.2307/1390710
   Koch G, 2015, THESIS
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Larochelle H., 2008, P 23 AAAI C ART INT, P646
   LeCun Yann A., 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P9, DOI 10.1007/978-3-642-35289-8_3
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Palatucci  Mark, 2009, ADV NEURAL INFORM PR, P1410
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rastegari M., 2012, ECCV, V7577, P876, DOI DOI 10.1007/978-3-642-33783-3_63
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shu Zhang, 2015, IEEE Transactions on Big Data, V1, P84, DOI 10.1109/TBDATA.2015.2499191
   Socher R., 2013, ADV NEURAL INFORM PR, P935
   Wan Ji, 2015, ARXIV151001991
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Weiss Y., 2009, ADV NEURAL INFORM PR, V21, P1753
NR 27
TC 0
Z9 0
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 542
EP 548
UT WOS:000426968700073
ER

PT S
AU Zeng, P
   Wu, D
   Jin, M
AF Zeng, Pan
   Wu, Di
   Jin, Min
GP IEEE
TI Compress-Filtering and Transfer-Expanding of Data Set for Short-Term
   Load Forecasting
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
ID NEURAL-NETWORKS; SYSTEM; MODEL; SVR
AB In short-term load forecasting, dataset construction plays a vital role in the improvement of forecasting accuracy. This paper begins with filtering the load data of the target city, transferring and expanding the load data of the nearby cities, and analysing the influence of the periodicity of load, holiday and load growth rate on dataset construction. A dataset construction method combining compress-filtering and transfer-expanding is then proposed based on the analysis. In this method, firstly, we apply the mean compress method to compress monthly data into weekly data in which both the periodic trend and the randomness of other related factors are taken into consideration. The training set is selected according to the similarity between the load variation pattern of the predicted month and that of the historical data. Secondly, based on the analysis of the similarity of the load data between the target city and the nearby cities, we introduce the load growth rate to measure the difference of the load variation patterns between different cities. Based on the load growth rate, a transfer learning method is put forward which transfers the data of the source city to the target city. The case study on real load data shows that, compared with the mutual information filtering-based predicting method and the knowledge transfer expanding method, the mean absolute percent error is decreased by 26% and 9.5%, respectively.
CR Amjady N, 2010, ELECTR POW SYST RES, V80, P318, DOI 10.1016/j.epsr.2009.09.015
   Blitzer J., 2007, ANN M ASS COMP LING, V7, P440, DOI DOI 10.1109/IRPS.2011.5784441
   Bozic M, 2013, ENERGIES, V6, P2130, DOI 10.3390/en6042130
   Bozic M, 2013, ENTROPY-SWITZ, V15, P926, DOI 10.3390/e15030926
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Che JX, 2014, APPL ENERG, V132, P602, DOI 10.1016/j.apenergy.2014.07.064
   Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679
   CHRISTIAANSE WR, 1971, IEEE T POWER AP SYST, VPA90, P900, DOI 10.1109/TPAS.1971.293123
   Collobert R., 2008, P 25 ICML, V25, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Duan P, 2011, ENERGIES, V4, P173, DOI 10.3390/en4010173
   Goia A, 2010, INT J FORECASTING, V26, P700, DOI 10.1016/j.ijforecast.2009.05.015
   HAGAN MT, 1987, IEEE T POWER SYST, V2, P785, DOI 10.1109/TPWRS.1987.4335210
   Hernandez L, 2013, ENERGIES, V6, P1385, DOI 10.3390/en6031385
   HO KL, 1990, IEEE T POWER SYST, V5, P1214, DOI 10.1109/59.99372
   Hong WC, 2009, APPL MATH MODEL, V33, P2444, DOI 10.1016/j.apm.2008.07.010
   Hu ZY, 2015, ENG APPL ARTIF INTEL, V40, P17, DOI 10.1016/j.engappai.2014.12.014
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Jianguang Deng, 2010, 2010 IEEE Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P231, DOI 10.1109/ICCIS.2010.5518553
   Jin M, 2014, NEUROCOMPUTING, V133, P309, DOI 10.1016/j.neucom.2013.11.005
   Jin M, 2012, EXPERT SYST APPL, V39, P773, DOI 10.1016/j.eswa.2011.07.072
   Khotanzad A, 2002, IEEE T POWER SYST, V17, P1273, DOI 10.1109/TPWRS.2002.804999
   Khotanzad A, 1997, IEEE T NEURAL NETWOR, V8, P835, DOI 10.1109/72.595881
   Kodogiannis VS, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S012906571350024X
   Koprinska I, 2015, KNOWL-BASED SYST, V82, P29, DOI 10.1016/j.knosys.2015.02.017
   Malki HA, 2004, EXPERT SYST, V21, P157, DOI 10.1111/j.1468-0394.2004.00272.x
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   VAHAKYLA P, 1980, INT J ELEC POWER, V2, P29, DOI 10.1016/0142-0615(80)90004-6
   Yang HT, 1998, IEEE T POWER SYST, V13, P217, DOI 10.1109/59.651639
   Zhang WY, 2012, ENERGY, V45, P850, DOI 10.1016/j.energy.2012.07.006
   Zhang YL, 2015, INFORM SYST, V53, P161, DOI 10.1016/j.is.2015.01.005
NR 31
TC 0
Z9 0
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 1095
EP 1101
UT WOS:000426968701048
ER

PT S
AU Saralajew, S
   Villmann, T
AF Saralajew, Sascha
   Villmann, Thomas
GP IEEE
TI Transfer Learning in Classification based on Manifold Models and its
   Relation to Tangent Metric Learning
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
ID SUPPORT VECTOR MACHINES; QUANTIZATION
AB The paper deals with realizations of transfer learning for classification, i.e. the adaptation of a classifier model to a changed data distribution. This change could be a data drift or a more complex transformation. We propose to model those data changes by manifolds describing continuous transformations of the data. This description can be seen as a generalization of function based transfer models considered so far. The manifold description of the transfer function allows either to adjust the classifier model to the changed data distribution or a back-transformation of those data to the original data space. To get the approach feasible, the manifold is approximated by the affine part of the Taylor expansion of the manifold structure. Moreover, the affine approximation shows mathematical correspondences to tangent metric leaning, which was developed for handling of data with drifts in classification methods.
   The paper provides the mathematical background for manifold based transfer data learning. Further, the approach is exemplarily applied for the generalized learning vector quantization classifier. This classifier is a prominent method which frequently achieves a high performance and a robust behavior while the classifier complexity is low compared to more sophisticated approaches like deep learning architectures or support vector machines. Moreover, the good interpretability of learning vector quantization classifiers also contributes to an intuitive practical understanding of transfer learning.
CR Amari S, 2016, APPL MATH SCI, V194
   Amari SI, 1985, LECT NOTES STAT, V28
   Bai Z, 2014, IEEE T CYBERNETICS, V44, P1858, DOI 10.1109/TCYB.2014.2298235
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Biehl M., 2015, P INT JOINT C NEUR N, P1
   Biehl M, 2016, WIRES COGN SCI, V7, P92, DOI 10.1002/wcs.1378
   Graf S., 2000, LECT NOTES MATH, V1730
   Haasdonk B, 2002, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2002.1048439
   Hadamard J., PRINCETON U B, P49
   Hamker FH, 2001, NEURAL NETWORKS, V14, P551, DOI 10.1016/S0893-6080(01)00018-1
   Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5
   Hastie T., 1995, Advances in Neural Information Processing Systems 7, P999
   Kabanikhin S.I., 2011, INVERSE ILL POSED PR, V55
   Kaden M, 2014, FOUND COMPUT DECIS S, V39, P79, DOI 10.2478/fcds-2014-0006
   Kaden M, 2015, SOFT COMPUT, V19, P2423, DOI 10.1007/s00500-014-1496-1
   Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198
   Kohonen T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P545, DOI 10.1109/IJCNN.1990.137622
   KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2
   Kohonen T., 1995, SPRINGER SERIES INFO, V30
   Lange M, 2015, NEUROCOMPUTING, V147, P107, DOI 10.1016/j.neucom.2013.11.049
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Paassen B., 2016, MACHINE LEARNING REP, V4, P11
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Prahm C, 2017, BIOSYST BIOROBOT, V15, P153, DOI 10.1007/978-3-319-46669-9_28
   Saralajew S., 2017, MACHINE LEARNING REP
   Saralajew S, 2016, IEEE IJCNN, P2672, DOI 10.1109/IJCNN.2016.7727534
   Saralajew S, 2016, LECT NOTES COMPUT SC, V9949, P362, DOI 10.1007/978-3-319-46675-0_40
   Sato A, 1996, ADV NEUR IN, V8, P423
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schneider P, 2009, NEURAL COMPUT, V21, P3532, DOI 10.1162/neco.2009.11-08-908
   Schneider P, 2009, NEURAL COMPUT, V21, P2942, DOI 10.1162/neco.2009.10-08-892
   Scholkopf B., 2002, LEARNING KERNELS SUP
   Schwenk H., 1995, ICANN '95. International Conference on Artificial Neural Networks. Neuronimes '95 Scientific Conference, P585
   Simard P, 1993, ADV NEURAL INFORM PR, p50~58
   Villmann T, 2018, COMPUTATION STAT, V33, P1173, DOI 10.1007/s00180-016-0678-y
   Villmann T, 2015, NEUROCOMPUTING, V147, P83, DOI 10.1016/j.neucom.2013.11.048
   Villmann T, 2011, NEURAL COMPUT, V23, P1343, DOI 10.1162/NECO_a_00110
NR 37
TC 0
Z9 0
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 1756
EP 1765
UT WOS:000426968702001
ER

PT S
AU Zhou, YQ
   Shi, BE
AF Zhou, Yuqian
   Shi, Bertram E.
GP IEEE
TI Action Unit Selective Feature Maps in Deep Networks for Facial
   Expression
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
ID RECOGNITION
AB Facial expression recognizers based on hand-crafted features have achieved satisfactory performance on many databases. Recently, deep neural networks, e.g. deep convolutional neural networks (CNNs) have been shown to boost performance on vision tasks. However, the mechanisms exploited by CNNs are not well established. In this paper, we establish the existence and utility of feature maps selective to action units in a deep CNN trained by transfer learning. We transfer a network pre-trained on the Image-Net dataset to the facial expression recognition task using the Karolinska Directed Emotional Faces (KDEF), Radboud Faces Database(RaFD) and extended Cohn-Kanade (CK+) database. We demonstrate that higher convolutional layers of the deep CNN trained on generic images are selective to facial action units. We also show that feature selection is critical in achieving robustness, with action unit selective feature maps being more critical in the facial expression recognition task. These results support the hypothesis that both human and deeply learned CNNs use similar mechanisms for recognizing facial expressions.
CR Berretti S, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Dhall A., 2012, COLLECTING LARGE RIC
   EKMAN P, 1980, J PERS SOC PSYCHOL, V39, P1125, DOI 10.1037/h0077722
   Ekman P., 1977, FACIAL ACTION CODING
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Jung H., 2015, ARXIV150301532
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI [10.1007/s12193-015-0209-0, 10.1007/s11227-016-1730-y]
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Libralon Giampaolo L., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8227, P409, DOI 10.1007/978-3-642-42042-9_51
   Liew CF, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1294, DOI 10.1109/ROBIO.2013.6739643
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Liu M., 2013, 10 IEEE INT C WORKSH, P1, DOI DOI 10.1128/GEN0MEA.00300-13
   Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Lucey P., 2010, IEEE COMP SOC C COMP, V2010, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Lundqvist D., 1998, KAROLINSKA DIRECTED, DOI 10.1017/S0048577299971664
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons M. J., 1998, JAPANESE FEMALE FACI
   Mery D., 2014, P EUR C COMP VIS WOR, P778
   Mousavi M, 2016, IEEE ICC
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pantic M., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Rao QY, 2015, INT CONF AFFECT, P630, DOI 10.1109/ACII.2015.7344635
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sun Y., 2015, ARXIV150200873
   Susskind J. M., 2010, TECH REP, V3
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Whitehill J., 2006, IEEE 7 INT C AUT FAC, P101
   Zeiler M. D., 2014, EUR C COMP VIS, P818, DOI DOI 10.1007/978-3-319-10590-1_53
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 36
TC 4
Z9 5
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 2031
EP 2038
UT WOS:000426968702038
ER

PT S
AU Kim, S
   Kim, W
   Noh, YK
   Park, FC
AF Kim, Seunghyeon
   Kim, Wooyoung
   Noh, Yung-Kyun
   Park, Frank C.
GP IEEE
TI Transfer Learning for Automated Optical Inspection
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB One of the challenges in applying convolutional neural networks to automated optical inspection is the lack of sufficient training data. In this paper we show that transfer learning can be successfully applied using image data from an entirely different domain. Focusing on optical inspection of texture images, we transfer weights from a source network trained with arbitrary unrelated images from the ImageNet dataset. Inspection experiments using our method show that one epoch of fine-tuning is sufficient to achieve 99.95% classification accuracy, while conventional transfer learning without fine-tuning achieves only 78.76%. An in-depth analysis of the effects of fine-tuning reveals that after fine-tuning, most of the unnecessary features encoded in the weights of the source network are deactivated, while meaningful features of the target data are amplified to capture new variations in the target domain.
CR Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Erhan D., 2009, VISUALIZING HIGHER L, V1341
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hafemann L. G., 2015, NEUR NETW IJCNN 2015, P1, DOI 10.1109/IJCNN.2015.7280558
   Jiang X, 2008, CIRP ANN-MANUF TECHN, V57, P555, DOI 10.1016/j.cirp.2008.03.110
   Kumaraswamy S. K., 2016, P 8 AS C MACH LEARN, P334
   Masci  J., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252468
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pernkopf F, 2002, EURASIP J APPL SIG P, V2002, P667, DOI 10.1155/S1110865702203145
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Scholz-Reiter B, 2012, CIRP ANN-MANUF TECHN, V61, P531, DOI 10.1016/j.cirp.2012.03.131
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, ARXIV14091556
   SOUKUP D, 2014, INT S VIS COMP, V8887, P668, DOI DOI 10.1007/978-3-319-14249-464
   Timm F., 2011, IS T SPIE ELECT IMAG
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Weimer D., 2016, CIRP ANN MANUFACTURI
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Yosinski J., 2015, ARXIV150606579
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 20
TC 1
Z9 1
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 2517
EP 2524
UT WOS:000426968702100
ER

PT S
AU Singh, MS
   Pondenkandath, V
   Zhou, B
   Lukowicz, P
   Liwicki, M
AF Singh, Monit Shah
   Pondenkandath, Vinaychandran
   Zhou, Bo
   Lukowicz, Paul
   Liwicki, Marcus
GP IEEE
TI Transforming Sensor Data to the Image Domain for Deep Learning - an
   Application to Footstep Detection
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB Convolutional Neural Networks (CNNs) have become the state-of-the-art in various computer vision tasks, but they are still premature for most sensor data, especially in pervasive and wearable computing. A major reason for this is the limited amount of annotated training data. In this paper, we propose the idea of leveraging the discriminative power of pre-trained deep CNNs on 2-dimensional sensor data by transforming the sensor modality to the visual domain. By three proposed strategies, 2D sensor output is converted into pressure distribution imageries. Then we utilize a pre-trained CNN for transfer learning on the converted imagery data. We evaluate our method on a gait dataset of floor surface pressure mapping. We obtain a classification accuracy of 87.66%, which outperforms the conventional machine learning methods by over 10%.
CR Amft O, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P160, DOI 10.1109/ISWC.2005.17
   Banaee H, 2013, SENSORS-BASEL, V13, P17472, DOI 10.3390/s131217472
   Caruana R, 1998, LEARNING TO LEARN, P95
   Cheng J, 2016, PERVASIVE MOBILE COM
   Cheng JY, 2010, LECT NOTES COMPUT SC, V6030, P319
   Cho K., 2014, ARXIV14091259
   Corbishley P., IEEE T BIOMEDICAL EN, V55, P196
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fukushima K., 1979, ELECTR COMMUN JPN, V62, P11
   Graves A., 2008, ADV NEURAL INFORM PR, V20, P577
   He K, 2015, ARXIV151203385
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun  Y., 1990, ADV NEURAL INFORM PR, P396, DOI DOI 10.1111/DSU.12130
   Li  L.-J., 2010, P ADV NEUR INF PROC, P1378
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maurer U., 2006, P INT WORKSH WEAR IM, P113, DOI DOI 10.1109/BSN.2006.6
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Sundholm M, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P373, DOI 10.1145/2632048.2636088
   Szegedy C, 2016, ARXIV160207261
   Szegedy C., 2015, ARXIV151200567
   Tao WJ, 2012, SENSORS-BASEL, V12, P2255, DOI 10.3390/s120202255
   Zeiler M. D., 2013, VISUALIZING UNDERSTA
   Zhang X., 2016, ARXIV161105725
   Zhou B., 2017, PERV COMP COMM PERCO
   Zhou B., 2016NINTH IEEE INT C
NR 30
TC 3
Z9 3
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 2665
EP 2672
UT WOS:000426968702120
ER

PT S
AU Lee, M
   Anderson, CW
AF Lee, Minwoo
   Anderson, Charles W.
GP IEEE
TI Can A Reinforcement Learning Agent Practice Before It Starts Learning?
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
ID DEEP; ALGORITHM
AB A reinforcement learning (RL) agent needs a fair amount of experience to find a near-optimal policy. Transfer learning has been investigated as a means to reduce the amount of experience required. Transfer learning, however, requires another similar reinforcement learning task as a transfer source, which can also be costly in the amount of experience required. In this research, we examine the possible "practice" approach that transfers knowledge from a non-RL task to a target RL task to avoid the expensive data sampling. We analyze how practice captures the distributions of state and action spaces in an environment. For this, we develop a novel learning approach that acquires important samples from practice and then applies them to a target RL task without changing learned bases. Results show an improved learning efficiency through practice in classical benchmark problems and limitations in OpenAI Gym problems.
CR Anderson CW, 2015, IEEE IJCNN
   BARTO AG, 1983, IEEE T SYST MAN CYB, V13, P834, DOI 10.1109/TSMC.1983.6313077
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Fernandez F., 2006, P 5 INT JOINT C AUT, P720
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Gao J, 2008, KDD, P283, DOI DOI 10.1145/1401890.1401928
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Konidaris G., 2011, P 25 C ART INT, P380
   Lagoudakis M., 2003, J MACHINE LEARNING R, V4, P1107, DOI DOI 10.1162/JMLR.2003.4.6.1107
   Lee M., 2016, ROB SCI SYST RSS WOR
   Lee M., 2014, P IEEE S AD DYN PROG
   Lee M., 2016, 15 IEEE INT C MACH L
   LINSKER R, 1990, ANNU REV NEUROSCI, V13, P257, DOI 10.1146/annurev.neuro.13.1.257
   Madden MG, 2004, ARTIF INTELL REV, V21, P375, DOI 10.1023/B:AIRE.0000036264.95672.64
   Mahadevan S, 2007, J MACH LEARN RES, V8, P2169
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Raina R., 2006, P 23 INT C MACH LEAR, P713
   Rexakis I, 2012, PROC INT C TOOLS ART, P25, DOI 10.1109/ICTAI.2012.13
   Riedmiller M, 2005, LECT NOTES ARTIF INT, V3720, P317
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sutton R. S., 1988, Machine Learning, V3, P9, DOI 10.1007/BF00115009
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Taylor ME, 2007, P 24 INT C MACH LEAR, P879
   Tipping M. E., 2003, P 9 INT WORKSH ART I, P3
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Torrey L, 2005, LECT NOTES ARTIF INT, V3720, P412
   Torrey L., 2006, ICML WORKSH STRUCT K
   Wipf D., 2003, ADV NEURAL INFORM PR, V16
   Wu P., 2004, P 21 INT C MACH LEAR, P110
   Zheng V, 2008, AAAI, P1427
NR 35
TC 1
Z9 1
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 4006
EP 4013
UT WOS:000426968704034
ER

PT S
AU Delhaisse, B
   Esteban, D
   Rozo, L
   Caldwell, D
AF Delhaisse, Brian
   Esteban, Domingo
   Rozo, Leonel
   Caldwell, Darwin
GP IEEE
TI Transfer Learning of Shared Latent Spaces between Robots with Similar
   Kinematic Structure
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB Learning complex manipulation tasks often requires to collect a large training dataset to obtain a model of a specific skill. This process may become laborious when dealing with high-DoF robots, and even more tiresome if the skill needs to be learned by multiple robots. In this paper, we investigate how this learning process can be accelerated by using shared latent variable models for knowledge transfer among similar robots in an imitation setting. For this purpose, we take advantage of a shared Gaussian process latent variable model to learn a common latent representation of robot skills. Such representation is then reused as prior information to train new robots by reducing the learning process to a latent-to-output mapping. We show that our framework exhibits faster training convergence and similar performance when compared to single-and multi-robot models. All experiments were conducted in simulation on three different robotic platforms: WALK-MAN, COMAN and CENTAURO robots.
OI Esteban, Domingo/0000-0002-3134-0281
CR Billard AG, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1995
   Bocsi B., 2013, 2013 INT JOINT C NEU, P1
   Ek C.H., 2009, THESIS
   Field M, 2016, IEEE T CYBERNETICS, V46, P706, DOI 10.1109/TCYB.2015.2414277
   GPy, 2012, GPY GAUSS PROC FRAM
   Kamedula M, 2016, ICINCO: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL 2, P485, DOI 10.5220/0006001404850491
   Koenemann J, 2014, IEEE INT CONF ROBOT, P2806, DOI 10.1109/ICRA.2014.6907261
   Lawrence N. D., 2006, P 23 INT C MACH LEAR, P513
   Lawrence N. D., 2007, P 24 INT C MACH LEAR, P481
   Lawrence ND, 2004, ADV NEUR IN, V16, P329
   Lee D, 2010, INT J ROBOT RES, V29, P1684, DOI 10.1177/0278364910364164
   Makondo N, 2015, IEEE-RAS INT C HUMAN, P1075, DOI 10.1109/HUMANOIDS.2015.7363502
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pastor P., 2009, P IEEE INT C ROB AUT, P763, DOI DOI 10.1109/ROBOT.2009.5152385
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rozo L, 2016, IEEE T ROBOT, V32, P513, DOI 10.1109/TRO.2016.2540623
   Shon A. P., 2006, ADV NEURAL INFORM PR, P129
   Shon AP, 2005, IEEE-RAS INT C HUMAN, P129
   Silverio J., 2015, IEEE RSJ INT C INT R
   Stanton C., 2012, AUSTR C ROB AUT
   Tsagarakis N. G., 2016, J FIELD ROBOTICS
   Tsagarakis NG, 2013, IEEE INT CONF ROBOT, P673, DOI 10.1109/ICRA.2013.6630645
   Yamane K, 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P504, DOI 10.1109/ICHR.2010.5686312
   Yamane K., 2010, P 2010 ACM SIGGRAPH, P169
NR 25
TC 5
Z9 5
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 4142
EP 4149
UT WOS:000426968704052
ER

PT S
AU Ahmad, T
   Campr, P
   Cadik, M
   Bebis, G
AF Ahmad, Touqeer
   Campr, Pavel
   Cadik, Martin
   Bebis, George
GP IEEE
TI Comparison of Semantic Segmentation Approaches for Horizon/Sky Line
   Detection
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB Horizon or skyline detection plays a vital role towards mountainous visual geo-localization, however most of the recently proposed visual geo-localization approaches rely on user-in-the-loop skyline detection methods. Detecting such a segmenting boundary fully autonomously would definitely be a step forward for these localization approaches. This paper provides a quantitative comparison of four such methods for autonomous horizon/sky line detection on an extensive data set. Specifically, we provide the comparison between four recently proposed segmentation methods; one explicitly targeting the problem of horizon detection[2], second focused on visual geo-localization but relying on accurate detection of skyline [15] and other two proposed for general semantic segmentation Fully Convolutional Networks (FCN) [21] and SegNet[22]. Each of the first two methods is trained on a common training set [11] comprised of about 200 images while models for the third and fourth method are fine tuned for sky segmentation problem through transfer learning using the same data set. Each of the method is tested on an extensive test set (about 3K images) covering various challenging geographical, weather, illumination and seasonal conditions. We report average accuracy and average absolute pixel error for each of the presented formulation.
RI Cadik, Martin/O-4824-2014
OI Cadik, Martin/0000-0001-7058-9912
CR Ahmad T., 2015, 6 IEEE INT C INF INT
   Ahmad T., 2013, ISVC
   Ahmad T., 2015, ICMLA
   Ahmad T., 2014, ISVC
   Ahmad T, 2015, INT J ARTIF INTELL T, V24, DOI [10.1142/S0218213015400187, 10.1142/s0218213015400187]
   Baatz G., 2012, ECCV
   Baboud L., 2011, COMPUTER VISION PATT
   Badrinarayanan V., 2015, ARXIV151100561V2CSCV
   Boroujeni N. S., 2012, IEEE 2012 9 C COMP R
   Brejcha J., 2017, IMAGE VISION C UNPUB
   Cadik M., 2015, BRIT MACH VIS C BMVC
   Chen Y, 2015, CHEM ENG SCI, V132, P1, DOI 10.1016/j.ces.2015.04.006
   de Croon G. C. H. E., 2011, IEEE AER C
   Ettinger S. M., 2002, INT C INT ROB SYST I
   Fefilatyev S, 2006, ICMLA 2006: 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P17
   Hays J., 2008, COMPUTER VISION PATT
   Ho N., 2014, INT C ROB AUT ICRA
   Hung Y., 2013, ICME
   Krizhevsky  A., 2012, NIPS
   Ladicky L., 2010, EUR C COMP VIS ECCV
   Lie WN, 2005, PATTERN RECOGN LETT, V26, P221, DOI 10.1016/j.patrec.2004.08.021
   Liu CJ, 2014, IEEE T INSTRUM MEAS, V63, P620, DOI 10.1109/TIM.2013.2272843
   Liu W., 2014, ADV TECHNOLOGIES EMB
   Long  J., 2015, CVPR
   McGee T., 2005, ICRA
   Porzi L., 2016, ACM MULT C
   Porzi L., 2014, ACM IEEE INT C DISTR
   Saurer O, 2016, INT J COMPUT VISION, V116, P213, DOI 10.1007/s11263-015-0830-0
   Simonyan K., 2014, VERY DEEP CONVOLUTIO, V1556, P2
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2014, CORR
   Thurrowgood S., 2009, INT C INT ROB SYST I
   Todorovic S., 2003, INT C ROB AUT ICRA
   Tzeng E., 2013, COMP VIS PATT REC WO
   Yosinski J., 2014, NIPS
   Zamir A. R., 2010, EUR C COMP VIS ECCV
   Zheng S., 2015, ARXIV150203240CSCV
   Zheng YN, 2009, CHINA POLICY SER, V7, P1
NR 38
TC 1
Z9 1
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 4436
EP 4443
UT WOS:000426968704091
ER

PT B
AU Hacene, GB
   Gripon, V
   Farrugia, N
   Arzel, M
   Jezequel, M
AF Hacene, Ghouthi Boukli
   Gripon, Vincent
   Farrugia, Nicolas
   Arzel, Matthieu
   Jezequel, Michel
GP IEEE
TI Budget Restricted Incremental Learning with Pre-Trained Convolutional
   Neural Networks and Binary Associative Memories
SO 2017 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS)
CT IEEE International Workshop on Signal Processing Systems (SiPS)
CY OCT 03-05, 2017
CL Lorient, FRANCE
DE Incremental Learning; Transfer Learning; Convolutional Neural Networks;
   Associative Memories
AB Thanks to their ability to absorb large amounts of data, Convolutional Neural Networks (CNNs) have become state-of-the-art in numerous vision challenges, sometimes even on par with biological vision. They rely on optimisation routines that typically require intensive computational power, thus the question of embedded architectures is a very active field of research. Of particular interest is the problem of incremental learning, where the device adapts to new observations or classes. To tackle this challenging problem, we propose to combine pre-trained CNNs with binary associative memories, using product random sampling as an intermediate between the two methods. The obtained architecture requires significantly less computational power and memory usage than existing counterparts. Moreover, using various challenging vision datasets we show that the proposed architecture is able to perform one-shot learning-and even use only a small portion of the dataset-while keeping very good accuracy.
CR Cadieu CF, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003963
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409
   Deng J., 2012, LARGE SCALE VISUAL R, V1
   Erdem Z, 2005, LECT NOTES COMPUT SC, V3541, P246
   Forrest N, 2016, ARXIV160207360
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I. J., 2013, ARXIV13126211
   Hong S., 2015, CORR
   Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kasabov N., 2013, EVOLVING CONNECTIONI
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lin D. D., 2016, INT C MACH LEARN ICM
   Molina JFG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093600
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Sun Y, 2016, IEEE T KNOWL DATA EN, V28, P1532, DOI 10.1109/TKDE.2016.2526675
   Syed N. A., 1999, INCREMENTAL LEARNING
   Szegedy C., 2015, ARXIV151200567
   Zheng J, 2013, NEURAL COMPUT APPL, V22, P1023, DOI 10.1007/s00521-011-0793-1
   Zhou ZH, 2002, KNOWL-BASED SYST, V15, P515, DOI 10.1016/S0950-7051(02)00038-2
NR 22
TC 0
Z9 0
BN 978-1-5386-0446-5
PY 2017
UT WOS:000427392400011
ER

PT B
AU Farooq, A
   Anwar, SM
   Awais, M
   Alnowami, M
AF Farooq, Ammara
   Anwar, Syed Muhammad
   Awais, Muhammad
   Alnowami, Majdi
GP IEEE
TI Artificial Intelligence based Smart Diagnosis of Alzheimer's Disease and
   Mild Cognitive Impairment
SO 2017 INTERNATIONAL SMART CITIES CONFERENCE (ISC2)
CT International Smart Cities Conference (ISC2)
CY SEP 14-17, 2017
CL Wuxi, PEOPLES R CHINA
DE smart healthcare; smart diagnosis; MRI; artificial intelligence; pattern
   recognition; Alzheimer's disease
AB Modern pattern recognition and artificial intelligence systems can help in providing better health care and medical solutions. The performance of human diagnosis degrades due to fatigue, cognitive biases, systems faults, and distractions. However, artificial intelligence based diagnosis systems are less error prone and give safe support to clinicians in detection and decision making. This work presents a smart and reliable way of diagnosing Alzheimer's disease (AD) and its possible early stage i.e., mild cognitive impairment. Alzheimer's is a neurodegenerative disease and leads to severe memory loss and inability to cope with daily life tasks. The diagnosis of AD from structural images requires great skill and is challenging for human diagnostics. The presented framework is based on deep learning and detects Alzheimer's and its initial stages accurately from structural MRI scans. The framework analyzes four different classes simultaneously in a single setup. The testing accuracy of diagnosis obtained by the method is 98.88%. Experiments are also performed on binary data and transfer learning is applied for multiclass classification achieving 99.7% accuracy. Once a good trained model is obtained, the decision for an unseen test scan is given within a few seconds. These models are free from the factors that are responsible for causing human diagnostic errors. Therefore, these models are dependable and can provide much faster diagnosis.
CR Altaf T., 2017, IEEE FUT TE IN PRESS
   Alzheimer's Association, 2016, Alzheimers Dement, V12, P459
   Farooq A., 2017, IEEE C IM S IN PRESS
   Graber ML, 2005, ARCH INTERN MED, V165, P1493, DOI 10.1001/archinte.165.13.1493
   Gupta A., 2013, INT C MACH LEARN, V30, P987
   He K, 2015, ARXIV151203385
   Hosseini-Asl E., 2016, ARXIV160700556
   Hussain S., 2017, IEEE C ENG MED BIOL
   Hussain S., 2017, ARXIV170800377
   Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049
   Korolev S., 2017, ARXIV170106643
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CS, 2013, AM J ROENTGENOL, V201, P611, DOI 10.2214/AJR.12.10375
   Liu SQ, 2015, LECT NOTES ARTIF INT, V8955, P350, DOI 10.1007/978-3-319-14803-8_27
   Liu SQ, 2015, IEEE T BIO-MED ENG, V62, P1132, DOI 10.1109/TBME.2014.2372011
   Payan A., 2015, ARXIV150202506
   Qayyum A., ARXIV170902250
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarraf S., 2016, BIORXIV070441
   Shi J., 2017, IEEE J BIOMEDICAL HL
   Sorensen L, 2017, NEUROIMAGE-CLIN, V13, P470, DOI 10.1016/j.nicl.2016.11.025
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong T, 2017, PATTERN RECOGN, V63, P171, DOI 10.1016/j.patcog.2016.10.009
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
NR 25
TC 0
Z9 0
BN 978-1-5386-2524-8
PY 2017
UT WOS:000427345600089
ER

PT S
AU Banerjee, D
   Islam, K
   Mei, G
   Xiao, LM
   Zhang, GF
   Xu, R
   Ji, SW
   Li, J
AF Banerjee, Debrup
   Islam, Kazi
   Mei, Gang
   Xiao, Lemin
   Zhang, Guangfan
   Xu, Roger
   Ji, Shuiwang
   Li, Jiang
BE Raghavan, V
   Aluru, S
   Karypis, G
   Miele, L
   Wu, X
TI A Deep Transfer Learning Approach for Improved Post-Traumatic Stress
   Disorder Diagnosis
SO 2017 17TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING (ICDM)
SE IEEE International Conference on Data Mining
CT 17th IEEE International Conference on Data Mining (ICDMW)
CY NOV 18-21, 2017
CL New Orleans, LA
ID NEURAL-NETWORKS
AB Post-traumatic stress disorder (PTSD) is a traumatic-stressor related disorder developed by exposure to a traumatic or adverse environmental event that caused serious harm or injury. Structured interview is the only widely accepted clinical practice for PTSD diagnosis but suffers from several limitations including the stigma associated with the disease. Diagnosis of PTSD patients by analyzing speech signals has been investigated as an alternative since recent years, where speech signals are processed to extract frequency features and these features are then fed into a classification model for PTSD diagnosis. In this paper, we developed a deep belief network (DBN) model combined with a transfer learning (TL) strategy for PTSD diagnosis. We computed three categories of speech features and utilized the DBN model to fuse these features. The TL strategy was utilized to transfer knowledge learned from a large speech recognition database, TIMIT, for PTSD detection where PTSD patient data is difficult to collect. We evaluated the proposed methods on two PTSD speech databases, each of which consists of audio recordings from 26 patients. We compared the proposed methods with other popular methods and showed that the state-of-the-art support vector machine (SVM) classifier only achieved an accuracy of 57.68%, and TL strategy boosted the performance of the DBN from 61.53% to 74.99%. Altogether, our method provides a pragmatic and promising tool for PTSD diagnosis.
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Brown S., 2015, P 29 AAAI C ART INT, P1700
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Deng L., 2013, ICCASP
   Dieleman S., 2014, ICCASP
   Grinage BD, 2003, AM FAM PHYSICIAN, V68, P2401
   Hansen JHL, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/906789
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HOVENS JE, 1994, J CLIN PSYCHOL, V50, P325, DOI 10.1002/1097-4679(199405)50:3<325::AID-JCLP2270500304>3.0.CO;2-M
   Kamishima T, 2009, IEEE DATA MINING, P219, DOI 10.1109/ICDM.2009.9
   Knoth B., 2015, WO, Patent No. [2016028495A1, 2016028495]
   Krothapalli SR, 2013, INT J SPEECH TECHNOL, V16, P181, DOI 10.1007/s10772-012-9175-z
   Kumaraswamy R, 2015, IEEE DATA MINING, P811, DOI 10.1109/ICDM.2015.138
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel Kashyap, 2013, INT J EMERGING SCI E, V1, P33
   Ramaswamy Sriram, 2005, Prim Care Companion J Clin Psychiatry, V7, P180
   Razavian A. S., 2014, CVPR, P807
   Sparr LF, 2005, J AM ACAD PSYCHIATRY, V33, P71
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tychtl Z., 1999, EUROSPEECH 99, P2335
   Vergyri D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3729
   Zhang Q., 2016, FRONTIERS NEUROSCIEN
   Zhang W., 2015, P 21 ACM SIGKDD INT, P1475
   Zhuang XD, 2014, IEEE W SP LANG TECH, P260, DOI 10.1109/SLT.2014.7078584
NR 24
TC 2
Z9 2
SN 1550-4786
BN 978-1-5386-3835-4
PY 2017
BP 11
EP 20
DI 10.1109/ICDM.2017.10
UT WOS:000427187400002
ER

PT S
AU Wang, JD
   Chen, YQ
   Hao, SJ
   Feng, WJ
   Shen, ZQ
AF Wang, Jindong
   Chen, Yiqiang
   Hao, Shuji
   Feng, Wenjie
   Shen, Zhiqi
BE Raghavan, V
   Aluru, S
   Karypis, G
   Miele, L
   Wu, X
TI Balanced Distribution Adaptation for Transfer Learning
SO 2017 17TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING (ICDM)
SE IEEE International Conference on Data Mining
CT 17th IEEE International Conference on Data Mining (ICDMW)
CY NOV 18-21, 2017
CL New Orleans, LA
DE Transfer learning; domain adaptation; distribution adaptation; class
   imbalance
AB Transfer learning has achieved promising results by leveraging knowledge from the source domain to annotate the target domain which has few or none labels. Existing methods often seek to minimize the distribution divergence between domains, such as the marginal distribution, the conditional distribution or both. However, these two distances are often treated equally in existing algorithms, which will result in poor performance in real applications. Moreover, existing methods usually assume that the dataset is balanced, which also limits their performances on imbalanced tasks that are quite common in real problems. To tackle the distribution adaptation problem, in this paper, we propose a novel transfer learning approach, named as Balanced Distribution Adaptation (BDA), which can adaptively leverage the importance of the marginal and conditional distribution discrepancies, and several existing methods can be treated as special cases of BDA. Based on BDA, we also propose a novel Weighted Balanced Distribution Adaptation (W-BDA) algorithm to tackle the class imbalance issue in transfer learning. W-BDA not only considers the distribution adaptation between domains but also adaptively changes the weight of each class. To evaluate the proposed methods, we conduct extensive experiments on several transfer learning tasks, which demonstrate the effectiveness of our proposed algorithms over several state-of-the-art methods.
CR Ando S., 2017, ARXIV170407515
   Chen Yiqiang, 2016, ACM INT JOINT C ACM, P33
   Gong B., 2012, CVPR
   Hao S., 2017, IJCAI
   Hou CA, 2015, AVSS, P1
   Hou CA, 2016, IEEE T IMAGE PROCESS, V25, P5552, DOI 10.1109/TIP.2016.2609820
   Hsiao PH, 2016, IEEE T IMAGE PROCESS, V25, P3518, DOI 10.1109/TIP.2016.2572602
   Hsu TMH, 2015, IEEE I CONF COMP VIS, P4121, DOI 10.1109/ICCV.2015.469
   Hu LS, 2016, 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD), P327, DOI [10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0066, 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.90]
   Li J., 2016, IJCAI
   Li SJ, 2016, TRANSPORT RES REC, P1, DOI 10.3141/2549-01
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   SATPAL S, 2007, PKDD, V4702, P224
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Tahmoresnezhad J., 2016, KNOWL INF SYST
   Wang J., 2017, ARXIV170703502
   Wu F., 2017, AAAI
   Yan H., 2017, CVPR
NR 20
TC 4
Z9 4
SN 1550-4786
BN 978-1-5386-3835-4
PY 2017
BP 1129
EP 1134
DI 10.1109/ICDM.2017.150
UT WOS:000427187400142
ER

PT B
AU Chahyati, D
   Fanany, MI
   Arymurthy, AM
AF Chahyati, Dina
   Fanany, Mohamad Ivan
   Arymurthy, Aniati Murni
GP IEEE
TI Man Woman Detection in Surveillance Images
SO 2017 5TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION
   TECHNOLOGY (ICOIC7)
CT 5th International Conference on Information and Communication Technology
   (ICoIC7)
CY MAY 17-19, 2017
CL MALAYSIA
DE region based CNN; fast feature pyramids; detection; gender; man woman;
   transfer learning
AB Human gender detection from body profile is an important task for surveillance. Most surveillance cameras are placed at a distance such that it is not possible to see people's face clearly. In this paper, we report the comparison between fast-feature pyramids and deep region-based convolutional neural network (RCNN) to detect a person in surveillance images. Since RCNN performs better in detecting a person, further training is applied to the RCNN to detect man and woman. Transfer learning strategy is used due to a small number of training images. The result shows that the trained RCNN can detect man and woman with promising result.
CR Cao L., 2008, P ACM INT C MULT
   Collins M., 2009, IEEE INT C COMP VIS
   Dollar P., 2014, IEEE T PATTERN ANAL
   Everingham M., 2010, INT J COMPUTER VISIO
   Girshick  R., 2014, CVPR
   Girshick Ross, 2015, ICCV
   Milan A., MOT16 BENCHMARK MULT
   Ng C. B., 2012, LECT NOTES COMPUTER, V7458
   Pan S. J., 2009, IEEE T KNOWLEDGE DAT, V22
   Ren S., 2016, IEEE T PATTERN ANAL
   Simonyan K, VERY DEEP CONVOLUTIO
   Zheng J, 2011, NEUROCOMPUTING, V74, P1926, DOI 10.1016/j.neucom.2010.07.032
NR 12
TC 0
Z9 0
BN 978-1-5090-4912-7
PY 2017
UT WOS:000427146300043
ER

PT S
AU Gupta, B
   Awasthi, S
   Singh, P
   Ram, L
   Kumar, P
   Prasad, BR
   Agarwal, S
AF Gupta, Bharat
   Awasthi, Shivam
   Singh, Parshant
   Ram, Likhama
   Kumar, Pramod
   Prasad, Bakshi Rohit
   Agarwal, Sonali
GP IEEE
TI Cross Domain Sentiment Analysis Using Transfer Learning
SO 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS
   (ICIIS)
SE International Conference on Industrial and Information Systems
CT IEEE International Conference on Industrial and Information Systems
   (ICIIS)
CY DEC 15-16, 2017
CL Univ Peradeniya,Fac Engn, Peradeniya, SRI LANKA
HO Univ Peradeniya,Fac Engn
DE Transfer Learning; knowledge transfer; sentiment analysis; Twitter; Yelp
   reviews
AB Transfer learning is an emerging research area which extracts knowledge from one or more than one source domains and utilizes this gained knowledge to perform some task in a target domain. It has emerged as a popular topic in recent years, because this technique is considered to be helpful in reducing the cost of labeling. It has many applications on different domains such as Natural Language Processing, Image and Video Processing, etc. The aim is to study transfer learning and implement it for Sentiment Analysis of Tweets by using the knowledge of Yelp reviews. We find that transfer Learning approach is faster than the conventional machine learning approach and give comparable accuracy at much smaller dataset.
CR Agarwal S, 2015, INT CONF IND INF SYS, P413, DOI 10.1109/ICIINFS.2015.7399047
   Blitzer John, DOMAIN ADAPTATION ST
   Calais Pedro H., BIAS OPINION TRANSFE
   Carroll J, 2013, CROSS DOMAIN SENTIME
   Glorot X., DOMAIN ADAPTATION LA
   LI Shoushan, 2008, MULTIDOMAIN ADAPTATI
   Mullers Thomas, ROBUST MORPHOLOGICAL
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Pan Sinno Jialin, 2010, CROSS DOMAIN SENTIME
   Peddinti Viswa mani kiran, 2011, DOMAIN ADAPTATION SE
   Prasad B. R., 2016, INT J DATABASE THEOR, V9, P45
   Prasad Bakshi Rohit, 2016, INT J DATABASE THEOR, V9, P201
   Torrey Lisa, TRANSFER LEARNING
   Wang Dong, TRANSFER LEARNING SP
   Weiss Karl, 2016, J BIG DATA SPRI 0528
   Yang L., 2015, IEEE 10 ICDIM
   Yasuhisa T. H, 2011, TRANSFER LEARNING MU
NR 17
TC 0
Z9 0
SN 2164-7011
BN 978-1-5386-1676-5
PY 2017
BP 175
EP 179
UT WOS:000426990100031
ER

PT B
AU Xing, X
   Xu, GC
   Cai, BL
   Qing, CM
   Xu, XM
AF Xing, Xiaofen
   Xu, Guicong
   Cai, Bolun
   Qing, Chunmei
   Xu, Xiangmin
BE Wu, Y
   Min, G
   Georgalas, N
   AlDubi, A
   Jin, X
   Yang, L
   Ma, J
   Yang, P
TI Face Verification Based on Feature Transfer via PCA-SVM Framework
SO 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND
   IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER,
   PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA)
CT EEE International Conference on Internet of Things (iThings) and IEEE
   Green Computing and Communications (GreenCom) and IEEE Cyber, Physical
   and Social Computing (CPSCom) and IEEE Smart Data (SmartData)
CY JUN 21-23, 2017
CL Exeter, ENGLAND
AB Face verification is a task to determine whether a pair of given facial images belong to the same person. In unconstrained real applications, inter and intra variations, including illumination, pose, occlusion, and expression, will seriously decrease the verification performance. Due to the lack of annotated data for face verification, extended datasets for face recognition with large samples are used to assist learning a robust feature representation generally. However, the extended data for face recognition is different from face verification on distribution and task. In this paper, a transfer learning based on PCA-SVM is proposed to alleviate above problem. The original feature representation is learnt from a deep convolutional neural network by face classification. Then a PCA-SVM based transfer method is used for feature reprojection from the source domain (face recognition) to the target domain (face verification), which reduces the divergence of feature distribution and task inconsistency. The proposed framework yields comparable results and the accuracy is 98.5% on LFW dataset.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gunther M., 2013, P IEEE IAPR INT C BI, P1
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Huang G. B., 2007, TECH REP
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lin M., 2013, ARXIV13124400
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Long M., 2015, INT C MACH LEARN, P97
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tzeng E., 2014, ARXIV14123474
   Wang D., 2015, ARXIV150707242
   Wang W, 2015, IEEE INFOCOM SER
   Wilson P., 2006, J COMPUTING SCI COLL, V21, P127
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yi D., 2014, ARXIV14117923
NR 26
TC 0
Z9 0
BN 978-1-5386-3066-2
PY 2017
BP 1086
EP 1091
DI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.166
UT WOS:000426972400165
ER

PT B
AU Kim, D
   Hernandez, M
   Choi, J
   Medioni, G
AF Kim, Donghyun
   Hernandez, Matthias
   Choi, Jongmoo
   Medioni, Gerard
GP IEEE
TI Deep 3D Face Identification
SO 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB)
CT IEEE International Joint Conference on Biometrics (IJCB)
CY OCT 01-04, 2017
CL Denver, CO
ID RECOGNITION; EXPRESSIONS
AB We propose a novel 3D face recognition algorithm using a deep convolutional neural network (DCNN) and a 3D face expression augmentation technique. The performance of 2D face recognition algorithms has significantly increased by leveraging the representationalp ower of deep neural networks and the use of large-scale labeled training data. In this paper, we show that transfer learning from a CNN trained on 2D face images can effectively work for 3D face recognition by fine-tuning the CNN with an extremely small number of 3D facial scans. We also propose a 3D face expression augmentation technique which synthesizes a number of different facial expressions from a single 3D face scan. Our proposed method shows excellent recognition results on Bosphorus, BU-3DFE, and 3D-TEC datasets without using hand-crafted features. The 3D face identification using our deep features also scales well for large databases.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Alyuz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081
   Amberg B, 2008, IEEE INT C AUT FAC G, P1, DOI DOI 10.1109/AFGR.2008.4813376
   Bartoli A., 2012, 3D IMAGING ANAL APPL, P221
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Cao C., 2014, FACEWARE HOUSE 3D FA
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Di Huang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P1, DOI 10.1109/FG.2011.5771323
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   FALTEMIER T., 2007, IEEE INT C BIOM THEO, P1
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Hernandez M, 2015, IMAGE VISION COMPUT, V36, P61, DOI 10.1016/j.imavis.2014.12.004
   Huang D., 2011, COMP VIS PATT REC WO, P1
   Jaderberg  M., 2015, ADV NEURAL INFORM PR, P2017
   Jia Y., 2014, CAFFE CONVOLUTIONAL
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Laptev D., 2016, ARXIV160406318
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li H., 2015, MATH PROBL ENG
   Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018
   Masi I, 2016, ARXIV160307057
   Ocegueda O., 2011, 2011 IEEE INT JOINT, P1
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   SAVRAN A, 2008, EUR WORKSH BIOM ID, V5372, P47
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   ter Haar FB, 2010, COMPUT GRAPH-UK, V34, P231, DOI 10.1016/j.cag.2010.03.010
   Vijayan V., 2011, BIOM IJCB 2011 INT J, P1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Z., 2014, ARXIV E PRINTS, V2
   Yin L, 2008, AUTOMATIC FACE GESTU, P1, DOI DOI 10.1109/AFGR.2008.4813324
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
NR 40
TC 0
Z9 0
BN 978-1-5386-1124-1
PY 2017
BP 133
EP 142
UT WOS:000426973200017
ER

PT B
AU Asgarian, A
   Ashraf, AB
   Fleet, D
   Taati, B
AF Asgarian, Azin
   Ashraf, Ahmed Bilal
   Fleet, David
   Taati, Babak
GP IEEE
TI Subspace Selection to Suppress Confounding Source Domain Information in
   AAM Transfer Learning
SO 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB)
CT IEEE International Joint Conference on Biometrics (IJCB)
CY OCT 01-04, 2017
CL Denver, CO
AB Active appearance models (AAMs) have seen tremendous success in face analysis. However model learning depends on the availability of detailed annotation of canonical landmark points. As a result, when accurate AAM fitting is required on a different set of variations (expression, pose, identity), a new dataset is collected and annotated. To overcome the need for time consuming data collection and annotation, transfer learning approaches have received recent attention. The goal is to transfer knowledge from previously available datasets (source) to a new dataset (target). We propose a subspace transfer learning method, in which we select a subspace from the source that best describes the target space. We propose a metric to compute the directional similarity between the source eigenvectors and the target subspace. We show an equivalence between this metric and the variance of target data when projected onto source eigenvectors. Using this equivalence, we select a subset of source principal directions that capture the variance in target data. To define our model, we augment the selected source subspace with the target subspace learned from a handful of target examples. In experiments done on six public datasets, we show that our approach outperforms the state of the art in terms of the RMS fitting error as well as the percentage of test examples for which AAM fitting converges to the ground truth.
CR Alabort-i-Medina J, 2014, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2014.439
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Haase D, 2014, PROC CVPR IEEE, P1426, DOI 10.1109/CVPR.2014.185
   Heap T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P140, DOI 10.1109/AFGR.1996.557255
   Kausar S., 2011, Proceedings of the 2011 Frontiers of Information Technology (FIT 2011), P95, DOI 10.1109/FIT.2011.25
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lucey P, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, V2010, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Luo ZR, 2014, MINERVA MED, V105, P157
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Medina J. Alabort-i, 2014, P ACM INT C MULT OP, P679, DOI DOI 10.1145/2647868.2654890
   Medina J. Alabort-i, 2016, INT J COMPUT VISION, V121, P1
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 18
TC 0
Z9 0
BN 978-1-5386-1124-1
PY 2017
BP 466
EP 473
UT WOS:000426973200057
ER

PT B
AU Ribeiro, E
   Uhl, A
AF Ribeiro, Eduardo
   Uhl, Andreas
BE Bromme, A
   busch, C
   Dantcheva, A
   Rathgeb, C
   Uhl, A
TI Exploring Texture Transfer Learning via Convolutional Neural Networks
   for Iris Super Resolution
SO 2017 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP
   (BIOSIG)
CT International Conference of the Biometrics Special Interest Group
   (BIOSIG)
CY SEP 20-22, 2017
CL Darmstadt, GERMANY
DE Single-Image Super Resolution; Iris Recognition; Transfer Learning;
   Convolutional Neural Networks
AB Increasingly, iris recognition towards more relaxed conditions has issued a new super-resolution field direction. In this work we evaluate the use of deep learning and transfer learning for single image super resolution applied to iris recognition. For this purpose, we explore if the nature of the images as well as if the pattern from the iris can influence the CNN transfer learning and, consequently, the results in the recognition process. The good results obtained by the texture transfer learning using a deep architecture suggest that features learned by Convolutional Neural Networks used for image super-resolution can be highly relevant to increase iris recognition rate.
OI Ribeiro, Olivia/0000-0003-2316-1643
CR Aljadaany R, 2015, IEEE IMAGE PROC, P3856, DOI 10.1109/ICIP.2015.7351527
   Alonso-Fernandez F., 2015, 2015 23 EUR SIGN PRO
   Barcelos CAZ, 2008, PROC INT C TOOLS ART, P325, DOI 10.1109/ICTAI.2008.71
   Burghouts GJ, 2009, PATTERN RECOGN LETT, V30, P306, DOI 10.1016/j.patrec.2008.10.005
   Cimpoi M., 2014, P IEEE C COMP VIS PA
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   haran L., 2009, J VISION, V9, P784, DOI DOI 10.1167/9.8.784
   Hofbauer H, 2014, INT C PATT RECOG, P527, DOI 10.1109/ICPR.2014.101
   Hsieh SH, 2016, IEEE T CYBERNETICS, V46, P3342, DOI 10.1109/TCYB.2015.2504388
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Johnson J., 2016, CORR
   Kalka ND, 2010, IEEE T SYST MAN CY A, V40, P509, DOI 10.1109/TSMCA.2010.2041658
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   LeCun Y., 2001, INTELLIGENT SIGNAL P
   Ledig C., 2016, CORR
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li J., 2015, NEUROCOMPUTING, V154
   Rathgeb C., 2016, ADV COMPUTER VISION
   Shi W., 2016, CORR, Vabs/1609.05158
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Su M., 2016, TRANSFER LEARNING BA, P325
   Sun L., 2017, CORR
   Timofte R., 2015, 12 AS C COMP VIS
   Vedaldi A., 2014, CORR
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P3296, DOI 10.1109/TIP.2012.2190085
   Yuan Y, 2017, IEEE J-STARS, V10, P1963, DOI 10.1109/JSTARS.2017.2655112
NR 27
TC 0
Z9 0
BN 978-3-8857-9664-0
PY 2017
UT WOS:000427098800008
ER

PT B
AU Xue, J
   Chan, PPK
   Hu, X
AF Xue, Jin
   Chan, Patrick P. K.
   Hu, Xian
GP IEEE
TI EXPERIMENTAL STUDY ON STACKED AUTOENCODER ON INSUFFICIENT TRAINING
   SAMPLES
SO 2017 INTERNATIONAL CONFERENCE ON WAVELET ANALYSIS AND PATTERN
   RECOGNITION (ICWAPR)
SE International Conference on Wavelet Analysis and Pattern Recognition
CT International Conference on Wavelet Analysis and Pattern Recognition
   (ICWAPR)
CY JUL 09-12, 2017
CL Ningbo, PEOPLES R CHINA
DE Deep learning; Small dataset; Stacked autoencoder
AB Many studies have shown that deep learning outperforms traditional machine learning methods in many applications. To prevent overfitting, a huge number of training samples is usually required in training process of deep learning. However, collecting such a large dataset is time-consumed and costly. Recently, several methods have been proposed to effectively learn the models with a limited number of training samples. In this paper, we experimentally evaluate the data augmentation and the transfer learning methods on the MNIST dataset with stacked autoencoders. The experiment results suggest that the transfer learning method can improve the performance of the SAE when training samples are insufficient.
CR Battle A., 2007, P 24 INT C MACH LEAR
   Bengio Y., 2007, P ADV NEUR INF PROC, P153
   Bengio Y., 2012, P ICML WORKSH UNS TR
   Bengio Y., 2013, FDN TRENDS MACHINE L
   Bengio Y., 2011, ALGORITHMIC LEARNING
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cho KyungHyun, 2013, INT C MACH LEARN
   Dai W., 2007, P 24 INT C MACH LEAR
   Graves A, 2013, 2013 IEEE INT C AC S, P6646, DOI [10.1109/icassp.2013.6638947, DOI 10.1109/ICASSP.2013.6638947, 10.1109/ICASSP.2013.6638947]
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Krizhevsky A., 2012, INT C NEUR INF PROC
   Lawrence N. D., 2004, P 21 INT C MACH LEAR
   Moosavi-Dezfooli, 2016, P IEEE C COMP VIS PA
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ren S., 2015, ARXIV150601497
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wong S. C., 2016, ARXIV160908764
   Xiaodong Cui, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5582, DOI 10.1109/ICASSP.2014.6854671
   Yosinski Jason, 2015, P IEEE C COMP VIS PA
NR 20
TC 0
Z9 0
BN 978-1-5386-0412-0
PY 2017
BP 223
EP 229
UT WOS:000426943600041
ER

PT B
AU Gjoreski, M
   Lustrek, M
   Gams, M
   Gjoreski, H
AF Gjoreski, Martin
   Lustrek, Mitja
   Gams, Matjaz
   Gjoreski, Hristijan
GP ACM
TI Deep Affect Recognition from R-R Intervals
SO PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE
   AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL
   SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT)
CT ACM International Joint Conference on Pervasive and Ubiquitous Computing
   (UBICOMP) / ACM International Symposium on Wearable Computers (ISWC)
CY SEP 11-15, 2017
CL Maui, HI
DE Arousal recognition; Affect; Deep neural networks; Machine learning;
   Transfer learning; Stress; Emotions
AB Affect recognition is an important task in ubiquitous computing, in particular in health and human-computer interaction. In the former, it contributes to the timely detection and treatment of emotional and mental disorders, and in the latter, it enables indigenous interaction and enhanced user experience. We present an inter-domain study for affect recognition on seven different datasets, recorded with six different sensors, three different sensor placements, 211 subjects and nearly 1000 hours of labelled data. The datasets are processed and translated into a common spectrotemporal space. The data represented in the common spectro-temporal space is used to train a deep neural network (DNN) for arousal recognition that benefits from the large amounts of data even when the data are heterogeneous (i.e., different sensors and different datasets). The DNN approach outperforms the classical machine-learning approaches in six out of seven datasets.
CR Abadi M.K., 2015, IEEE T AFFECTIVE COM
   Abdic I., 2016, P INT JOINT C ART IN
   Bashivan P., LEARNING REPRESENTAT
   Castaldoa R., 2015, BIOMEDICAL SIGNAL PR
   Garbarino M., 2014, 4 INT C WIR MOB COMM, P3
   Gjoreski  M., 2016, P 2016 ACM INT JOINT, P1185
   Gjoreski M., 2017, J BIOMEDICA IN PRESS
   Iacovielloa D., 2015, COMPUTER METHODS PRO
   Khezria M., RELIABLE EMOTION REC
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/1830483.1830503
   Koelstra S., 2012, IEEE T AFFECTIVE COM
   Liu Wei, 2016, MULTIMODAL EMOTION R
   LOMB NR, 1976, ASTROPHYS SPACE SCI, V39, P447, DOI 10.1007/BF00648343
   Martinez F, 2013, IEEE INT CONF AUTOMA
   Mehmooda R. M., 2016, COMPUTERS ELECT ENG
   Mikuckas A., 2014, EMOTION RECOGNITION
   Morales F. J. O., 2016, P 2016 ACM INT S WEA
   Negri L. H., PEAK DETECTION ALGOR
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Russell J. A, 1980, J PERSONALITY SOCIAL
   SCARGLE JD, 1982, ASTROPHYS J, V263, P835, DOI 10.1086/160554
   Schneegass S., 2013, 5 INT C AUT US INT I
   Soleymani M., 2012, IEEE T AFFECTIVE COM
   Subramanian R., 2016, IEEE T AFFECTIVE COM
   Trigeorgis G., 2016, C AC SPEECH SIGN PRO
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verma G. K., 2014, NEUROIMAGE
   Weiss K., 2016, J BIG DATA
   Wu M., 2006, THESIS
   Yin Z., 2017, COMPUT METHODS PROGR
   Zheng WL, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa5a98
NR 31
TC 1
Z9 1
BN 978-1-4503-5190-4
PY 2017
BP 754
EP 762
DI 10.1145/3123024.3125608
UT WOS:000426932500150
ER

PT B
AU Velioglu, B
   Vural, FTY
AF Velioglu, Burak
   Vural, Fatos T. Yarman
BE Howard, N
   Wang, Y
   Hussain, A
   Hamdy, F
   Widrow, B
   Zadeh, LA
TI Transfer Learning for Brain Decoding using Deep Architectures
SO 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS &
   COGNITIVE COMPUTING (ICCI*CC)
CT IEEE 16th International Conference on Cognitive Informatics and
   Cognitive Computing (ICCI*CC)
CY JUL 26-28, 2017
CL Oxford, ENGLAND
DE Deep Neural Network; Transfer Learning; Feature Learning; Brain Decoding
ID NETWORK
AB Is there a general representation of the information content of human brain, which can be extracted from the functional magnetic resonance imaging (fMRI) data? Is it possible to learn this representation automatically from big data sets by unsupervised learning methods? Is it possible to transfer this representation to learn and decode a set of cognitive states in other fMRI data sets? This study addresses partial answers to the above questions by using transfer learning in deep architectures. First, a hierarchical representation for fMRI data is learned from a large data set in Human Connectome Project (HCP) by a 3-layered stacked denoising autoencoder (SDAE). Then, the learned representations are used to train and recognize the cognitive states recorded by a relatively small data set of one-back repetition detection experiment. Results show that, it is possible to learn a general representation and transfer the learned representation of an fMRI data set to another dataset for brain decoding problem. The learned representation has a better discriminative power compared to the Pearson correlation features. Results also show us that deep neural networks transfer representations better than factor models commonly used in pattern recognition and neuroscience literature.
CR Bazargani N, 2014, MED IMAGE ANAL, V18, P711, DOI 10.1016/j.media.2014.03.005
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boyd  S., 2004, CONVEX OPTIMIZATION
   Cobre Group, 2012, MR DAT 75 SCHIZ 72 H
   Collobert R, 2011, BIGLEARN NIPS WORKSH
   Kim J, 2016, NEUROIMAGE, V124, P127, DOI 10.1016/j.neuroimage.2015.05.018
   Koyamada S, 2015, ARXIV150200093
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Onal I, 2015, 2015 INTERNATIONAL WORKSHOP ON PATTERN RECOGNITION IN NEUROIMAGING (PRNI) 2015, P5, DOI 10.1109/PRNI.2015.26
   Ozay Mete, 2012, ARXIV12052382
   Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007
   Plis S. M., 2013, ARXIV13125847
   Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Zeiler M. D., 2012, ARXIV12125701
NR 15
TC 0
Z9 0
BN 978-1-5386-0771-8
PY 2017
BP 65
EP 70
UT WOS:000426941300013
ER

PT B
AU Su, YH
   Jin, ZM
   Chen, Y
   Sun, XH
   Yang, YM
   Qiao, FZ
   Xia, F
   Xu, W
AF Su, Yuhan
   Jin, Zhongming
   Chen, Ying
   Sun, Xinghai
   Yang, Yaming
   Qiao, Fangzheng
   Xia, Fen
   Xu, Wei
GP ACM
TI Improving Click-Through Rate Prediction Accuracy in Online Advertising
   by Transfer Learning
SO 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017)
CT IEEE/WIC/ACM International Conference on Web Intelligence (WI)
CY AUG 23-26, 2017
CL Leipzig, GERMANY
DE Online Advertising; Transfer Learning; CTR Prediction
AB As the main revenue source of Internet companies, online advertising is always a significant topic, where click-through rate (CTR) prediction plays a central role. In online advertising systems, there are often many advertisement products. Due to the competition in the bidding mechanism, some advertising products may get lots of data to train the CTR prediction model while some may lack highquality data. However, to predict accurate CTR, a large amount of data is needed. Therefore, transfer knowledge from the large product (source) to the small product (target) is necessary. We propose a transfer learning method that iteratively updates the data weights to selectively combine source data with target data for training. To efficiently process huge advertisement data, we design a sampling strategy based on the gradient information, and implement the algorithm with a MapReduce-like machine learning framework. We do experiments on real advertisement datasets. The results show that our approach improves the accuracy of CTR prediction compared to the supervised learning method.
CR Argyriou A., 2007, NEURAL INFORM PROCES, V19, P41
   Blitzer J., 2007, ANN M ASS COMP LING, V7, P440, DOI DOI 10.1109/IRPS.2011.5784441
   CHAKRABARTI D., 2008, P 17 INT C WORLD WID, P117
   Chapelle O, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2532128
   Chen-Guang He, 2010, Proceedings 2010 IEEE Youth Conference on Information, Computing and Telecommunications (YC-ICT 2010), P351, DOI 10.1109/YCICT.2010.5713117
   Cheng  Haibin, 2012, P 18 ACM SIGKDD INT, P777
   Cheng YP, 2012, ADV MATER RES-SWITZ, V599, P795, DOI 10.4028/www.scientific.net/AMR.599.795
   Dai W., 2007, INT C MACH LEARN
   Dalessandro Brian, 2014, INT C KNOWL DISC DAT
   DAVE K, 2010, INT C RES DEV INF RE, P897
   FREUND Y, 1997, EUR C COMP LEARN, V55, P119
   Graepel T., 2010, P 27 INT C MACH LEAR, P13
   Jiang J., 2007, ACL, V7, P264
   Lawrence N. D., 2004, P 21 INT C MACH LEAR, P65, DOI 10.1145/1015330.1015382
   Liu Yandong, 2012, INT C WEB SEARCH DAT
   Long Mingsheng, 2015, CORR, V2
   McMahan H.B., 2013, P 19 ACM SIGKDD INT, P1222, DOI DOI 10.1145/2487575.2488200
   Mihalkova Lilyana, 2008, AAAI 08 WORKSH TRANS
   Mihalkova Lilyana, 2010, AAAI C ART INT, P608
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perlich C, 2014, MACH LEARN, V95, P103, DOI 10.1007/s10994-013-5375-2
   Pontil M., 2004, INT C KNOWL DISC DAT
   Regelson M., 2006, P 2 WORKSH SPONS SEA, V9623
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhao Peilin, 2015, P INT C MACH LEARN, V37, P1
   Zhu  Y., 2011, P 25 AAAI C ART INT, P1304
NR 26
TC 0
Z9 0
BN 978-1-4503-4951-2
PY 2017
BP 1018
EP 1025
DI 10.1145/3106426.3109037
UT WOS:000426965100135
ER

PT B
AU Yan, ZX
   Wei, L
   Lu, YS
   Wu, ZQ
   Tao, B
AF Yan, Zhixian
   Wei, Lai
   Lu, Yunshan
   Wu, Zhongqiang
   Tao, Bo
GP ACM
TI You are what apps you use - Transfer Learning for Personalized Content
   and Ad Recommendation
SO PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS
   (RECSYS'17)
CT 11th ACM Conference on Recommender Systems (RecSys)
CY AUG 27-31, 2017
CL Como, ITALY
DE User Profile; Personalized Recommendation; Transfer Learning
AB Cold start is always a key challenge for building real-life recommendation systems. Thanks to the ever-growing multi-modal data in the mobile Internet age and the latest deep learning techniques, transfer-learning based cross-domain recommendation starts to play a crucial role in tackling the cold start problem and to provide "warm-start" recommendation for new users. At Cheetah Mobile, we apply transfer learning to build personalized recommendation systems for both advertisement and content scenarios, serving 600+ millions monthly active mobile users. In particular, we leveraged the app install & usage and many other mobile data, built a Unified User Profile (UUP) by the state-of-the-art deep learning techiniques, and developed cross-domain personalized Ad and news recommendation. Our approaches enable us to solve the cold start problem with close to full coverage of our user base while yielding significant CTR increase and better user experience.
CR Bojanowski P., 2016, CORR
   Cheng H., 2016, DLRS
   Covington Paul, 2016, P 10 ACM C REC SYST, P191, DOI DOI 10.1145/2959100.2959190
   Elkahky A., 2015, WWW
   Tang Jie, 2012, KDD
NR 5
TC 0
Z9 1
BN 978-1-4503-4652-8
PY 2017
BP 350
EP 350
DI 10.1145/3109859.3109923
UT WOS:000426967000062
ER

PT B
AU Zheng, Y
   Pan, WK
   Sahebi, S
   Fernaandez, I
AF Zheng, Yong
   Pan, Weike
   Sahebi, Shaghayegh (Sherry)
   Fernandez, Ignacio
GP ACM
TI The 1st Workshop on Intelligent Recommender Systems by Knowledge
   Transfer & Learning (RecSysKTL)
SO PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS
   (RECSYS'17)
CT 11th ACM Conference on Recommender Systems (RecSys)
CY AUG 27-31, 2017
CL Como, ITALY
DE cross-domain; knowledge transfer; recommender system
AB Cross-domain recommender systems and transfer learning approaches are useful to help integrate knowledge from different places, so that we alleviate some existing problems (such as the cold-start problem), or improve the quality of recommender systems. With the advantages of these techniques, we host the first international workshop on intelligent recommender systems by knowledge transfer and learning (RecSysKTL) to provide such a forum for academia researchers and application developers from around the world to present their work and discuss exciting research ideas or outcomes. The workshop is held in conjunction with the ACM Conference on Recommender Systems 2017 on August 27th at Como, Italy.
NR 0
TC 1
Z9 1
BN 978-1-4503-4652-8
PY 2017
BP 366
EP 367
DI 10.1145/3109859.3109951
UT WOS:000426967000070
ER

PT B
AU Jaradat, S
AF Jaradat, Shatha
GP ACM
TI Deep Cross-Domain Fashion Recommendation
SO PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS
   (RECSYS'17)
CT 11th ACM Conference on Recommender Systems (RecSys)
CY AUG 27-31, 2017
CL Como, ITALY
DE Fashion recommendation; deep learning; cross-domain knowledge transfer;
   transfer learning; domain adaptation; CNN
AB With the increasing number of online shopping services, the number of users and the quantity of visual and textual information on the Internet, there is a pressing need for intelligent recommendation systems that analyze the user's behavior amongst multiple domains and help them to find the desirable information without the burden of search. However, there is little research that has been done on complex recommendation scenarios that involve knowledge transfer across multiple domains. This problem is especially challenging when the involved data sources are complex in terms of the limitations on the quantity and quality of data that can be crawled. The goal of this paper is studying the connection between visual and textual inputs for better analysis of a certain domain, and to examine the possibility of knowledge transfer from complex domains for the purpose of efficient recommendations. The methods employed to achieve this study include both design of architecture and algorithms using deep learning technologies to analyze the effect of deep pixel-wise semantic segmentation and text integration on the quality of recommendations. We plan to develop a practical testing environment in a fashion domain.
CR Alter Nicole, 2016, LAUNCH METRICS 4 WAY
   Bowman Eric, 2017, MINUTETACK FASHIONS
   Chen Qiang, 2015, CVPR
   Covington Paul, 2016, RECSYS
   Dai J., 2016, CVPR
   Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423
   He K., 2016, CVPR
   HUANG JS, 2015, CVPR, P1062, DOI DOI 10.1109/ICCV.2015.127
   Jagadeesh Vignesh, 2014, ARXIV14011778
   Kiapour M. Hadi, 2015, ICCV
   LeCun Y., 1995, HDB BRAIN THEORY NEU, P255, DOI DOI 10.1109/1JCNN.2004
   Li Z, 2015, COMM COM INF SC, V547, P120, DOI 10.1007/978-3-662-48570-5_12
   Liang Xiaodan, 2015, P IEEE INT C COMP VI, P136
   Liu Si, 2012, P 20 ACM INT C MULT, P619
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Ren  Shaoqing, 2015, NIPS
   Shaw Michael D., 2017, HUFFINGTION POST MAC
   Simonyan K., 2015, ICLR
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
NR 20
TC 1
Z9 1
BN 978-1-4503-4652-8
PY 2017
BP 407
EP 410
DI 10.1145/3109859.3109861
UT WOS:000426967000089
ER

PT B
AU Lee, SJ
   Koo, G
   Choi, H
   Kim, SW
AF Lee, Sang Jun
   Koo, Gyogwon
   Choi, Hyeyeon
   Kim, Sang Woo
GP IEEE
TI Transfer learning of a deep convolutional neural network for localizing
   handwritten slab identification numbers
SO PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE
   VISION APPLICATIONS - MVA2017
CT 15th IAPR International Conference on Machine Vision Applications (MVA)
CY MAY 08-12, 2017
CL Nagoya Univ, Nagoya, JAPAN
HO Nagoya Univ
AB Most machine learning methods assume that previous and future data have same distribution in same feature space. This paper presents a real-world problem that violates the common assumption, and we propose a practical methodology to handle the problem. In the steel making industry, automated marking systems are widely used to inscribe slab identification numbers (SINS). In the previous work, a deep learning based algorithm was developed to automatically extract regions of printed SINs. However, as the marking system is outdated, few SINs are marked by hand in uncommon situations, and the existing algorithm does not work for the handwritten SINs. This paper proposes a practical method that uses very small training data (10 images) to localize handwritten SINs. The knowledge of mid-level layers or entire layers in the pre-trained deep convolutional neural network is transferred to overcome the shortage of training data in the target domain. Experiments were conducted with actual industrial data to demonstrate the effectiveness of the proposed algorithm.
CR Branson S, 2014, ARXIV14062952
   Choi S, 2012, EXPERT SYST APPL, V39, P7621, DOI 10.1016/j.eswa.2012.01.124
   Donahue J., 2014, P 31 INT C MACH LEAR, P647
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee SJ, 2017, EXPERT SYST APPL, V77, P34, DOI 10.1016/j.eswa.2017.01.026
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sawada Y, 2015, 2015 14th IAPR International Conference on Machine Vision Applications (MVA), P110, DOI 10.1109/MVA.2015.7153145
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Szegedy C., 2013, ADV NEURAL INFORM PR, V26, P2553
   Wang D, 2015, ASIAPAC SIGN INFO PR, P1225, DOI 10.1109/APSIPA.2015.7415532
   Yan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1626, DOI 10.1109/ICASSP.2014.6853873
NR 16
TC 0
Z9 0
BN 978-4-9011-2216-0
PY 2017
BP 330
EP 333
UT WOS:000426950300082
ER

PT B
AU Prajapati, SA
   Nagaraj, R
   Mitra, S
AF Prajapati, Shreyansh A.
   Nagaraj, R.
   Mitra, Suman
GP IEEE
TI Classification of Dental Diseases Using CNN and Transfer Learning
SO 2017 5TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS
   INTELLIGENCE (ISCBI)
CT 5th International Symposium on Computational and Business Intelligence
   (ISCBI)
CY AUG 11-14, 2017
CL Dubai, U ARAB EMIRATES
DE Convolutional Neural Network(CNN); Transfer Learning (TL); Machine
   Learning (ML); Computer Vision
ID NEURAL-NETWORKS; SEGMENTATION
AB Automated medical assistance system is in high demand with the advances in research in the machine learning area. In many such applications, availability of labeled medical dataset is a primary challenge and dataset of dental diseases is not an exception. An attempt towards accurate classification of dental diseases is addressed in this paper. Labeled dataset consisting of 251 Radio Visiography (RVG) x-ray images of 3 different classes is used for classification. Convolutional neural network (CNN) has become a most effective tool in machine learning which enables solving the problems like image recognition, segmentation, classification, etc., with high order of accuracy. It is found from literature that CNN performs well in natural image classification problems where large dataset is available. In this paper we experimented on the performance of CNN for diagnosis of small labeled dental dataset. In addition, transfer learning is used to improve the accuracy. Experimental results are presented for three different architectures of CNN. Overall accuracy achieved is very encouraging.
CR Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   de Brebisson Alexandre, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P20, DOI 10.1109/CVPRW.2015.7301312
   Farman AG, 2005, ORAL SURG ORAL MED O, V99, P485, DOI 10.1016/j.tripleo.2004.04.002
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li W., 2015, J COMPUT COMMUN, V3, P146, DOI DOI 10.4236/JCC.2015.311023
   Litjens G. J. S., 2017, ARXIV170205747
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937
   Selwitz RH, 2007, LANCET, V369, P51, DOI 10.1016/S0140-6736(07)60031-2
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thong W, 2018, COMP M BIO BIO E-IV, V6, P277, DOI 10.1080/21681163.2016.1148636
NR 16
TC 1
Z9 1
BN 978-1-5386-1772-4
PY 2017
BP 70
EP 74
UT WOS:000427097000015
ER

PT B
AU Condori, RHM
   Romualdo, LM
   Bruno, OM
   Luz, PHD
AF Montes Condori, Rayner Harold
   Romualdo, Liliane Maria
   Bruno, Odemir Martinez
   de Cerqueira Luz, Pedro Henrique
BE GarciaGoncalves, LM
   BeserraGomes, R
TI Comparison between traditional texture methods and deep learning
   descriptors for detection of nitrogen deficiency in maize crops
SO 2017 WORKSHOP OF COMPUTER VISION (WVC)
CT 2017 Workshop of Computer Vision (WVC)
CY OCT 30-NOV 01, 2017
CL Natal, BRAZIL
DE Nutritional assessment; maize leaf analysis; deep learning; texture
   analysis; transfer learning; convolutional neural networks
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Every year, efficient maize production is very important to the economy of many countries. Since nutritional deficiencies in maize plants are directly reflected in their grains productivity, early detection is needed to maximize the chances of proper recovery of these plants. Traditional texture methods recently showed interesting results in the identification of nutritional deficiencies. On the other hand, deep learning techniques are increasingly outperforming hand-crafted features on many tasks. In this paper, we propose a simple transfer learning approach from pre-trained cnn models and compare their results with those from traditional texture methods in the task of nitrogen deficiency identification. We perform experiments in a real-world dataset that contains digitalized images of maize leaves at different growth stages and with different levels of nitrogen fertilization. The results show that deep learning based descriptors achieve better success rates than traditional texture methods.
RI Inst Cien Matematicas Computacao, ICMC/USP/D-8320-2017; Sao Carlos
   Institute of Physics, IFSC/USP/M-2664-2016
CR Amara Jihen, 2017, BTW WORKSH, V2017, P79
   Andrearczyk V, 2016, PATTERN RECOGN LETT, V84, P63, DOI 10.1016/j.patrec.2016.08.016
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Barker A. V., 2015, HDB PLANT NUTR
   Bifano Oliveira M. C, 2016, THESIS
   Chollet  F., 2015, KERAS
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Coelho A. M., 2006, EFICIENCIA AGRONOMIC
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   de Sousa GG, 2010, REV BRAS ENG AGR AMB, V14, P1143, DOI 10.1590/S1415-43662010001100003
   Fancelli A.L., 1986, PLANTAS ALIMENTICIAS
   Field CB, 2008, TRENDS ECOL EVOL, V23, P65, DOI 10.1016/j.tree.2007.12.001
   Foley JA, 2011, NATURE, V478, P337, DOI 10.1038/nature10452
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Goodfellow A., 2016, DEEP LEARNING
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Henry W.B., 2016, CURR CLIM CHANG REP, V2, P49, DOI [10.1007/s40641-016-0035-9, DOI 10.1007/S40641-016-0035-9]
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Qi XB, 2016, NEUROCOMPUTING, V171, P1230, DOI 10.1016/j.neucom.2015.07.071
   Romualdo LM, 2014, COMPUT ELECTRON AGR, V104, P63, DOI 10.1016/j.compag.2014.03.009
   Saha B, 2016, KNOWL INF SYST, V46, P315, DOI 10.1007/s10115-015-0821-z
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, INT C LEARN REPR ICL
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
NR 31
TC 1
Z9 1
BN 978-1-5386-1451-8
PY 2017
BP 7
EP 12
DI 10.1109/WVC.2017.00009
UT WOS:000426909100002
ER

PT B
AU Reinke, C
   Doya, K
AF Reinke, Chris
   Doya, Kenji
GP IEEE
TI Adaptation of Optimization Algorithms to Problem Domains by Transfer
   Learning
SO 2017 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATICS AND
   BIOMEDICAL SCIENCES (ICIIBMS)
CT 2nd International Conference on Intelligent Informatics and Biomedical
   Sciences (ICIIBMS)
CY NOV 24-26, 2017
CL Graduate Univ, Okinawa Inst Sci & Technol, Okinawa, JAPAN
HO Graduate Univ, Okinawa Inst Sci & Technol
DE optimization; transfer learning; CMA-ES; Powell's Conjugate Gradient
AB Optimization is one of the most important problems in science and engineering. Common optimization algorithms are designed to work for a large set of problems, but not necessarily to be efficient for specific domains. We propose a new transfer learning approach to adapt optimization algorithms to specific problem domains. Our approach analyzes solved problems of a domain to identify areas in the search space where good solutions are expected for this domain. Knowledge of these areas is used to improve the optimization algorithm performance of unseen problems of the same domain. Because of its general design, our method can be applied to a wide range of problems and algorithms.
CR Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   Gallagher M, 2006, IEEE T EVOLUT COMPUT, V10, P590, DOI 10.1109/TEVC.2005.863628
   Hansen N, 2006, STUD FUZZ SOFT COMP, V192, P75
   POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155
NR 4
TC 0
Z9 0
BN 978-1-5090-6664-3
PY 2017
BP 214
EP 215
UT WOS:000426897300055
ER

PT S
AU Mathew, A
   Mathew, J
   Govind, M
   Mooppan, A
AF Mathew, Alwyn
   Mathew, Jimson
   Govind, Mahesh
   Mooppan, Asif
BE Gahegan, M
   Mulerikkal, JP
TI An Improved Transfer learning Approach for Intrusion Detection
SO 7TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING & COMMUNICATIONS
   (ICACC-2017)
SE Procedia Computer Science
CT 7th International Conference on Advances in Computing and Communications
   (ICACC)
CY AUG 22-24, 2017
CL Kochin, INDIA
DE Transfer learning; Image classification; Deep learning; Video
   surveillance; Intrusion detection
ID RECOGNITION
AB Its crucial for financial systems to have sound security measures in place. For security reasons customers are not allowed to wear a helmet while using ATM(Automated Teller Machine). An automated helmet detection using ATM surveillance camera feed can help improve security significantly. Recently deep convolutional neural network (DCNN) have shown state of the art accuracy in object detection and localization. In this work, a pretrained Google's inception model have been used and have achieved an accuracy of 95.3% by training the model on a proprietary ATM surveillance dataset. Transferred information from inception model has been feed to multiple fully connected layers with drop outs to achieve better accuracy. (C) 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the 7th International Conference on Advances in Computing & Communications.
CR Brown MW, 1996, SEMIN NEUROSCI, V8, P23, DOI 10.1006/smns.1996.0004
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Goodfellow I. J., 2013, PIECEWISE LINEAR MUL, V1050, P22
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jung K., 2012, P INT C CONS EL ICCE, P258
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/18304
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Le Q. V., 2011, ADV NEURAL INFORM PR, V24, P1017
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leordeanu M., 2007, P IEEE C COMP VIS PA, P1
   Lin M., 2013, ARXIV13124400
   Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shapiro L., 2001, TXB COMPUTER VISION
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Srivastava R K, 2015, ARXIV150500387
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yudkowsky E., 2008, GLOBAL CATASTROPHIC, V1, P184
NR 21
TC 0
Z9 0
SN 1877-0509
PY 2017
VL 115
BP 251
EP 257
DI 10.1016/j.procs.2017.09.132
UT WOS:000426436900031
ER

PT S
AU Kang, BN
   Kim, Y
   Kim, D
AF Kang, Bong-Nam
   Kim, Yonghyun
   Kim, Daijin
GP IEEE
TI Deep Convolutional Neural Network using Triplets of Faces, Deep
   Ensemble, and Score-level Fusion for Face Recognition
SO 2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Workshops (CVPRW)
CY JUL 21-26, 2017
CL Honolulu, HI
ID EIGENFACES; FEATURES
AB This paper proposes a new face verification method that uses multiple deep convolutional neural networks (DCNNs) and a deep ensemble, that extracts two types of low dimensional but discriminative and high-level abstracted features from each DCNN, then combines them as a descriptor for face verification. Our DCNNs are built from stacked multi-scale convolutional layer blocks to present multi-scale abstraction. To train our DCNNs, we use different resolutions of triplets that consist of reference images, positive images, and negative images, and triplet-based loss function that maximize the ratio of distances between negative pairs and positive pairs and minimize the absolute distances between positive face images. A deep ensemble is generated from features extracted by each DCNN, and used as a descriptor to train the joint Bayesian learning and its transfer learning method. On the LFW, although we use only 198, 018 images and only four different types of networks, the proposed method with the joint Bayesian learning and its transfer learning method achieved 98.33% accuracy. In addition to further increase the accuracy, we combine the proposed method and high dimensional LBP based joint Bayesian method, and achieved 99.08% accuracy on the LFW. Therefore, the proposed method helps to improve the accuracy of face verification when training data is insufficient to train DCNNs.
OI Kang, Bong-Nam/0000-0002-6818-7532
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398
   Chen D., 2013, CVPR 2013
   Chopra S, 2005, PROC CVPR IEEE, P539
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Huang C., 2012, CORR
   Ioffe S, 2015, INT C MACH LEARN, V37, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Jia Y., 2014, ARXIV14085093
   Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Schroff F., 2015, ARXIV E PRINTS
   Shin J, 2014, IEEE SIGNAL PROC LET, V21, P1486, DOI 10.1109/LSP.2014.2338911
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun X. W. Yi, 2015, CORR
   Sun Y., 2014, ARXIV E PRINTS
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Wang XG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P679, DOI 10.1109/ICCV.2003.1238413
   WOLF L, 2010, AS C COMP VIS ACCV, V5995, P88
   Yi D., 2014, CORR
NR 29
TC 0
Z9 0
SN 2160-7508
BN 978-1-5386-0733-6
PY 2017
BP 611
EP 618
DI 10.1109/CVPRW.2017.89
UT WOS:000426448300083
ER

PT S
AU Chugh, T
   Singh, M
   Nagpal, S
   Singh, R
   Vatsa, M
AF Chugh, Tarang
   Singh, Maneet
   Nagpal, Shruti
   Singh, Richa
   Vatsa, Mayank
GP IEEE
TI Transfer Learning based Evolutionary Algorithm for Composite Face Sketch
   Recognition
SO 2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Workshops (CVPRW)
CY JUL 21-26, 2017
CL Honolulu, HI
AB Matching facial sketches to digital face images has widespread application in law enforcement scenarios. Recent advancements in technology have led to the availability of sketch generation tools, minimizing the requirement of a sketch artist. While these sketches have helped in manual authentication, matching composite sketches with digital mugshot photos automatically show high modality gap. This research aims to address the task of matching a composite face sketch image to digital images by proposing a transfer learning based evolutionary algorithm. A new feature descriptor, Histogram of Image Moments, has also been presented for encoding features across modalities. Moreover, IIITD Composite Face Sketch Database of 150 subjects is presented to fill the gap due to limited availability of databases in this problem domain. Experimental evaluation and analysis on the proposed dataset show the effectiveness of the transfer learning approach for performing cross-modality recognition.
CR Bhatt H. S., 2010, P INT C BIOM THEOR A, P1, DOI DOI 10.3109/1354750X.2010.522731
   Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252
   Biswas S., 2008, P 2 IEEE INT C BIOM, P1
   Chugh T., 2013, IEEE INT C BIOM THEO, P1
   Dalal N, 2005, PROC CVPR IEEE, P886
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Gibson L., 2008, FORENSIC ART ESSENTI
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/TIT.1962.1057692
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Klum SJ, 2014, IEEE T INF FOREN SEC, V9, P2248, DOI 10.1109/TIFS.2014.2360825
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Mittal P, 2017, INFORM FUSION, V33, P86, DOI 10.1016/j.inffus.2016.04.003
   Mittal P, 2015, INT CONF BIOMETR, P251, DOI 10.1109/ICB.2015.7139092
   Mittal P, 2013, IEEE IMAGE PROC, P2797, DOI 10.1109/ICIP.2013.6738576
   Mittal  Paritosh, 2014, IEEE INT JOINT C BIO, P1
   Ouyang SX, 2016, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2016.601
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Shan C., 2008, BRIT MACH VIS C
   Tang X, 2002, IEEE IMAGE PROC, P257
   Taylor K., 2000, FORENSIC ART ESSENTI
   Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132
   United Nations Office on Drugs and Crime, CTS 2013 CRIM STAT R
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244
   Yadav D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112234
   Zhan C, 2010, I C CONT AUTOMAT ROB, P1848, DOI 10.1109/ICARCV.2010.5707381
   Zhang Y, 2010, IEEE T SYST MAN CY A, V40, P475, DOI 10.1109/TSMCA.2010.2041654
NR 31
TC 1
Z9 2
SN 2160-7508
BN 978-1-5386-0733-6
PY 2017
BP 619
EP 627
DI 10.1109/CVPRW.2017.90
UT WOS:000426448300084
ER

PT S
AU Kim, J
   Park, C
AF Kim, Jiman
   Park, Chanjong
GP IEEE
TI End-to-End Ego Lane Estimation based on Sequential Transfer Learning for
   Self-Driving Cars
SO 2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   WORKSHOPS (CVPRW)
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Workshops (CVPRW)
CY JUL 21-26, 2017
CL Honolulu, HI
AB Autonomous cars establish driving strategies using the positions of ego lanes. The previous methods detect lane points and select ego lanes with heuristic and complex post-processing with strong geometric assumptions. We propose a sequential end-to-end transfer learning method to estimate left and right ego lanes directly and separately without any postprocessing. We redefined a point-detection problem as a region-segmentation problem; as a result, the proposed method is insensitive to occlusions and variations of environmental conditions, because it considers the entire content of an input image during training. Also, we constructed an extensive dataset that is suitable for a deep neural network training by collecting a variety of road conditions, annotating ego lanes, and augmenting them systematically. The proposed method demonstrated improved accuracy and stability on input variations compared with a recent method based on deep learning. Our approach does not involve postprocessing, and is therefore flexible to change of target domain.
CR Abu-El-Haija Sami, 2016, ARXIV160908675
   Aly M., 2008, IVS
   Assidiq A., 2008, ICCCE
   Badrinarayanan V., SEGNET DEEP CONVOLUT
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Borkar A., 2009, CIVVS
   Borkar A., 2011, ICASSP
   Borkar A., 2009, ICIP
   Bottazzi V. S., ROBOT INTELLIGENCE T, V274, P677
   Brostow Gabriel J., 2008, PATTERN RECOGNITION, Vxx
   Chen C., 2015, ICCV
   Cheng H. Y., 2008, ICASSP
   Cordts M., 2016, CVPR
   Daigavane P., 2010, ICETET
   Donahue J., 2014, ICML
   Eigen D., 2015, ICCV
   Geiger  A., 2012, CVPR
   Gurghian A., 2016, CVPRW
   Heilbron F. C., 2015, CVPR
   Huval B., 2015, ARXIV150401716
   Ioffe  S., 2015, ICML
   Jung  H., 2013, IV
   Kim J., 2014, ICONIP
   Kim Z, 2008, IEEE T INTELL TRANSP, V9, P16, DOI 10.1109/TITS.2007.908582
   Krasin I., 2016, OPENIMAGES PUBLIC DA
   Krizhevsky  A., 2012, NIPS
   Kumar Ammu M., 2015, International Journal of Computer Science & Information Technology, V7, P65, DOI 10.5121/ijcsit.2015.7406
   Leng Y. C., 2010, ICARCV
   Li J., 2016, IEEE T NEURAL NETWOR
   Lin C. W., 2009, IITA
   Lin Q., 2010, ICCRD
   Lin T. Y., 2016, ECCVW
   Liu G., 2010, IV
   Liu G., 2011, ICRA
   Liu GL, 2013, IEEE T INTELL TRANSP, V14, P13, DOI 10.1109/TITS.2012.2205146
   Long  J., 2015, CVPR
   Noh H., 2015, ICCV
   Oliveira G. L., 2016, IROS
   Real E., 2017, ARXIV170200824
   Richter S. R., 2016, ECCV
   Ros  G., 2016, CVPR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shelhamer  E., 2016, IEEE T PATTERN ANAL
   Simonyan K., 2015, ICLR
   Szegedy C., 2015, CVPR
   Tan M., 2013, SIBGRAPI
   Trung-Thien Tran, 2011, Information Technology Journal, V10, P2300, DOI 10.3923/itj.2011.2300.2307
   Tsai S. C., 2013, ICCVE
   Wang J., 2014, ITSC
   Yenikaya S, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522970
   Yim YU, 2003, IEEE T INTELL TRANSP, V4, P219, DOI 10.1109/TITS.2003.821339
   Zhao H., 2013, J AUTOMATION CONTROL, V1
   Zhou S., 2010, IV
NR 53
TC 4
Z9 4
SN 2160-7508
BN 978-1-5386-0733-6
PY 2017
BP 1194
EP 1202
DI 10.1109/CVPRW.2017.158
UT WOS:000426448300151
ER

PT S
AU Wanderley, MDDS
   Bueno, LDE
   Zanchettin, C
   Oliveira, ALI
AF Wanderley, Miguel D. de S.
   de A. e Bueno, Leonardo
   Zanchettin, Cleber
   Oliveira, Adriano L. I.
BE Lintas, A
   Rovetta, S
   Verschure, PFMJ
   Villa, AEP
TI The Impact of Dataset Complexity on Transfer Learning over Convolutional
   Neural Networks
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING, PT II
SE Lecture Notes in Computer Science
CT 26th International Conference on Artificial Neural Networks (ICANN)
CY SEP 11-14, 2017
CL Alghero, ITALY
DE Convolution neural networks; Transfer learning; Dataset complexity
AB This paper makes use of diverse domains' datasets to analyze the impact of image complexity and diversity on the task of transfer learning in deep neural networks. As the availability of labels and quality instances for several domains are still scarce, it is imperative to use the knowledge acquired from similar problems to improve classifier performance by transferring the learned parameters. We performed a statistical analysis through several experiments in which the convolutional neural networks (LeNet-5, AlexNet, VGG-11 and VGG-16) were trained and transferred to different target tasks layer by layer. We show that when working with complex low-quality images and small datasets, fine-tuning the transferred features learned from a low complexity source dataset gives the best results.
OI Zanchettin, Cleber/0000-0001-6421-9747
CR Donahue J., 2014, INT C MACH LEARN
   He K., 2016, IEEE C COMP VIS PATT
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun  Y., MNIST DATABASE HANDW
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Oquab M., 2014, 2014 IEEE C COMP VIS
   Palumbo L, 2014, J VISION, V14, DOI 10.1167/14.14.3
   Sharif Razavian  Ali, 2014, P IEEE C COMP VIS PA
   Simonyan K., 2015, INT C LEARN REPR ICL
   Soekhoe D., 2016, 15 INT S INT DAT AN
   Szegedy C., 2015, IEEE C COMP VIS PATT
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeiler M. D., 2014, EUR C COMP VIS, P818, DOI DOI 10.1007/978-3-319-10590-1_53
NR 16
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-68612-7; 978-3-319-68611-0
PY 2017
VL 10614
BP 582
EP 589
DI 10.1007/978-3-319-68612-7_66
UT WOS:000426415100066
ER

PT S
AU Karki, M
   DiBiano, R
   Basu, S
   Mukhopadhyay, S
AF Karki, Manohar
   DiBiano, Robert
   Basu, Saikat
   Mukhopadhyay, Supratik
BE Lintas, A
   Rovetta, S
   Verschure, PFMJ
   Villa, AEP
TI Core Sampling Framework for Pixel Classification
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING, PT II
SE Lecture Notes in Computer Science
CT 26th International Conference on Artificial Neural Networks (ICANN)
CY SEP 11-14, 2017
CL Alghero, ITALY
ID SEGMENTATION
AB The intermediate map responses of a Convolutional Neural Network (CNN) contain contextual knowledge about its input. In this paper, we present a framework that uses these activation maps from several layers of a CNN as features to a Deep Belief Network (DBN) using transfer learning to provide an understanding of an input image. We create a representation of these features and the training data and use them to extract more information from an image at the pixel level, hence gaining understanding of the whole image. We experimentally demonstrate the usefulness of our framework using a pretrained model and use a DBN to perform segmentation on the BAERI dataset of Synthetic Aperture Radar (SAR) imagery and the CAMVID dataset with a relatively smaller training dataset.
CR Badrinarayanan Vijay, 2015, ARXIV150507293
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen SZ, 2014, 2014 INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA), P541, DOI 10.1109/DSAA.2014.7058124
   Ganguly S., COMMUNICATION
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31
   LECUN Y, 1995, NEURAL NETW STAT MEC, V261, P276
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   LORIUS C, 1985, NATURE, V316, P591, DOI 10.1038/316591a0
   Lotter NO, 2003, MINER ENG, V16, P857, DOI 10.1016/S0892-6875(03)00207-3
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Theano Development Team, ABS160502688 ARXIV
   Torrey L., 2009, HDB RES MACHINE LEAR, V1, P242, DOI DOI 10.1016/J.JBI.2011.04.009
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler M. D., 2014, EUR C COMP VIS, P818, DOI DOI 10.1007/978-3-319-10590-1_53
   Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51
NR 23
TC 1
Z9 1
SN 0302-9743
EI 1611-3349
BN 978-3-319-68612-7; 978-3-319-68611-0
PY 2017
VL 10614
BP 617
EP 625
DI 10.1007/978-3-319-68612-7_70
UT WOS:000426415100070
ER

PT B
AU Cisek, D
   Mahajan, M
   Dale, J
   Pepper, S
   Lin, YW
   Yoo, S
AF Cisek, Daniel
   Mahajan, M.
   Dale, Jedidiah
   Pepper, Susan
   Lin, Yuewei
   Yoo, Shinjae
GP IEEE
TI A Transfer Learning approach to parking lot classification in aerial
   imagery
SO 2017 NEW YORK SCIENTIFIC DATA SUMMIT (NYSDS)
CT New York Scientific Data Summit (NYSDS)
CY AUG 06-09, 2017
CL New York, NY
DE Deep Learning; Neural Network; Geospatial; Automation; Satellite Imagery
ID CONVOLUTIONAL NEURAL-NETWORKS
AB The importance of satellite imagery analysis has increased dramatically over the last several years, keeping pace with the rapid improvements seen in both remote sensing platforms and sensors. As this field expands, so too does the interest in using machine learning methods to automate parts of the imagery analyst's workflow. In this paper we address one aspect of this challenge: the development of a method for the automatic extraction of parking lots from aerial imagery. To the best of our knowledge, there has been no prior work conducted on the development of an end-to-end pipeline for this particular task. Due to the limited size of our dataset and to accommodate the potentially limited size of future datasets, we propose a deep learning approach using transfer learning. This process hinges upon the use of state of the art Convolutional Neural Networks (CNNs), trained on general image classification datasets. These networks were then fine-tuned on our custom dataset, to establish a comprehensive benchmark for this task. Our method exhibits promising results for automatic parking lot extraction, and is generalizable enough to work with different input types, including high resolution aerial orthoimagery, satellite imagery, full motion video (FMV), and UAV imagery.
CR Akcay S., 2016, 2016 IEEE INT C IM P, DOI [10.1109/icip.2016.7532519, DOI 10.1109/ICIP.2016.7532519]
   Chen Y., 2017, EFFICIENT PROCESSING
   Cisek D., 2016, P IEEE 2016 NEW YORK, DOI [10.1109/nysds.2016.7747821, DOI 10.1109/NYSDS.2016.7747821]
   Ge W., IEEE C COMP VIS PATT
   Han S., 2015, P 28 INT C NEUR INF
   Hilal Al-Kharusi I. A.-B., 2014, WORLD J ENG TECHNOLO, V2, P55, DOI DOI 10.4236/WJET.2014.22006
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Niemeyer I., 2001, P 23 S SAF NUCL MAT
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky Olga, 2015, IJCV
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Valipour S., 2016, 2016 IEEE 3 WORLD FO, DOI [10.1109/wf-iot.2016.7845408, DOI 10.1109/WF-IOT.2016.7845408]
   Vedaldi A., 2015, P ACM INT C MULT
   Yosinski Jason, 2014, ADV NEURAL INFORM PR
NR 16
TC 0
Z9 0
BN 978-1-5386-3161-4
PY 2017
UT WOS:000426197700015
ER

PT B
AU Rujikietgumjorn, S
   Watcharapinchai, N
AF Rujikietgumjorn, Sitapa
   Watcharapinchai, Nattachai
GP IEEE
TI Vehicle Detection with Sub-Class Training using R-CNN for the UA-DETRAC
   Benchmark
SO 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL
   BASED SURVEILLANCE (AVSS)
CT 14th IEEE International Conference on Advanced Video and Signal Based
   Surveillance (AVSS)
CY AUG 29-SEP 01, 2017
CL Lecce, ITALY
AB Different types of vehicles, such as buses and cars, can be quite different in shapes and details. This makes it more difficult to try to learn a single feature vector that can detect all types of vehicles using a single object class. We proposed an approach to perform vehicle detection with Sub-Classes categories learning using R-CNN in order to improve the performance of vehicle detection. Instead of using a single object class, which is a vehicle in this experiment, to train on the R-CNN, we used multiple sub-classes of vehicles so that the network can better learn the features of each individual type. In the experiment, we also evaluated the result of using a transfer learning approach to use a pre-trained weights on a new dataset.
CR Abadi M, 2015, TENSORFLOW LARGE SCA
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Dollr P., 2001, IEEE T PATTERN ANAL, V36, P1532
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Huang J., 2016, CORR
   Lin T., 2014, CORR
   Ren S., 2015, NEURAL INFORM PROCES
   Watcharapinchai N, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043009
   Wen L., 2007, CORR
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yosinski J., 2014, CORR
NR 12
TC 0
Z9 0
BN 978-1-5386-2939-0
PY 2017
UT WOS:000426203700062
ER

PT B
AU Saqib, M
   Sharma, N
   Khan, SD
   Blumenstein, M
AF Saqib, Muhammad
   Sharma, Nabin
   Khan, Sultan Daud
   Blumenstein, Michael
GP IEEE
TI A Study on Detecting Drones Using Deep Convolutional Neural Networks
SO 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL
   BASED SURVEILLANCE (AVSS)
CT 14th IEEE International Conference on Advanced Video and Signal Based
   Surveillance (AVSS)
CY AUG 29-SEP 01, 2017
CL Lecce, ITALY
AB The object detection is a challenging problem in computer vision with various potential real-world applications. The objective of this study is to evaluate the deep learning based object detection techniques for detecting drones. In this paper, we have conducted experiments with different Convolutional Neural Network (CNN) based network architectures namely Zeiler and Fergus (ZF), Visual Geometry Group (VGGI6) etc. Due to sparse data available for training, networks are trained with pre-trained models using transfer learning. The snapshot of trained models is saved at regular interval during training. The best models having high mean Average Precision (mAP) for each network architecture are used for evaluation on the test dataset. The experimental results show that VGGI6 with Faster R-CNN perform better than other architectures on the training dataset. Visual analysis of the test dataset is also presented.
CR Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Everingham M., 2007, PASCAL VISUAL OBJECT
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb P., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587597
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Redmon J, 2016, ARXIV161208242
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 21
TC 5
Z9 5
BN 978-1-5386-2939-0
PY 2017
DI 10.1109/AVSS.2017.8078541
UT WOS:000426203700083
ER

PT B
AU Ghahremani, P
   Manohar, V
   Hadian, H
   Povey, D
   Khudanpur, S
AF Ghahremani, Pegah
   Manohar, Vimal
   Hadian, Hossein
   Povey, Daniel
   Khudanpur, Sanjeev
GP IEEE
TI INVESTIGATION OF TRANSFER LEARNING FOR ASR USING LF-MMI TRAINED NEURAL
   NETWORKS
SO 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 16-20, 2017
CL Okinawa, JAPAN
DE Transfer learning; weight transfer; LF-MMI; multi-task learning;
   Automatic Speech Recognition
ID ADAPTATION
AB It is common in applications of ASR to have a large amount of data out-of-domain to the test data and a smaller amount of in-domain data similar to the test data. In this paper, we investigate different ways to utilize this out-of-domain data to improve ASR models based on Lattice-free MMI (LF-MMI). In particular, we experiment with multi-task training using a network with shared hidden layers; and we try various ways of adapting previously trained models to a new domain. Both types of methods are effective in reducing the WER versus in-domain models, with the jointly trained models generally giving more improvement.
CR Bengio Y., 2012, J MACHINE LEARNING R, P17
   Bengio Y., 2011, JMLR P AISTATS, P164
   Caruana R, 1998, LEARNING TO LEARN, P95
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Gemello R, 2007, SPEECH COMMUN, V49, P827, DOI 10.1016/j.specom.2006.11.005
   Grezl F, 2016, PROCEDIA COMPUT SCI, V81, P15, DOI 10.1016/j.procs.2016.04.024
   Heigold G, 2013, INT CONF ACOUST SPEE, P8619, DOI 10.1109/ICASSP.2013.6639348
   Hinton  G., 2015, ARXIV150302531
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081
   Huang Z, 2016, NEUROCOMPUTING, V218, P448, DOI 10.1016/j.neucom.2016.09.018
   Huang Zhen, 2015, 16 ANN C INT SPEECH
   Karafiat M., P ASRU DEC, P152
   Lee H., 2009, ADV NEURAL INFORM PR, P1096, DOI DOI 10.1145/1553374.1553453
   Li J., 2014, 15 ANN C INT SPEECH
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Manohar V., 2017, AUT SPEECH REC UND A
   McCowan  I., 2005, P 5 INT C METH TECHN, V88
   Neto  J., 1995, SPEAKER ADAPTATION H
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Povey  D., 2016, PURELY SEQUENCE TRAI
   Sahraeian R, 2016, PROCEDIA COMPUT SCI, V81, P152, DOI 10.1016/j.procs.2016.04.043
   Swietojanski P, 2016, IEEE-ACM T AUDIO SPE, V24, P1450, DOI 10.1109/TASLP.2016.2560534
   Swietojanski P, 2012, IEEE W SP LANG TECH, P246, DOI 10.1109/SLT.2012.6424230
   Thomas S, 2013, INT CONF ACOUST SPEE, P6704, DOI 10.1109/ICASSP.2013.6638959
   Vesely K, 2012, IEEE W SP LANG TECH, P336, DOI 10.1109/SLT.2012.6424246
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wang D, 2015, ASIAPAC SIGN INFO PR, P1225, DOI 10.1109/APSIPA.2015.7415532
   Yao KS, 2012, IEEE W SP LANG TECH, P366, DOI 10.1109/SLT.2012.6424251
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Yu D., 2013, ARXIV13013605
NR 33
TC 0
Z9 0
BN 978-1-5090-4788-8
PY 2017
BP 279
EP 286
UT WOS:000426066100039
ER

PT B
AU Tjandra, A
   Sakti, S
   Nakamura, S
AF Tjandra, Andros
   Sakti, Sakriani
   Nakamura, Satoshi
GP IEEE
TI ATTENTION-BASED WAV2TEXT WITH FEATURE TRANSFER LEARNING
SO 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 16-20, 2017
CL Okinawa, JAPAN
DE speech recognition; end-to-end neural network; raw speech waveform
AB Conventional automatic speech recognition (ASR) typically performs multi-level pattern recognition tasks that map the acoustic speech waveform into a hierarchy of speech units. But, it is widely known that information loss in the earlier stage can propagate through the later stages. After the resurgence of deep learning, interest has emerged in the possibility of developing a purely end-to-end ASR system from the raw waveform to the transcription without any predefined alignments and hand-engineered models. However, the successful attempts in end-to-end architecture still used spectral-based features, while the successful attempts in using raw waveform were still based on the hybrid deep neural network -Hidden Markov model (DNN-HMM) framework. In this paper, we construct the first end-to-end attention-based encoder-decoder model to process directly from raw speech waveform to the text transcription. We called the model as Attention-based Wav2Text. To assist the training process of the end-to-end model, we propose to utilize a feature transfer learning. Experimental results also reveal that the proposed Attention-based Wav2Text model directly with raw waveform could achieve a better result in comparison with the attentional encoder-decoder model trained on standard front-end filterbank features.
CR Amodei D., 2016, INT C MACH LEARN, P173
   Bahdanau D, 2014, ARXIV14090473
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   CHAN W, 2016, AC SPEECH SIGN PROC, P4960
   Chorowski Jan, 2014, ARXIV14121602
   Collobert  R., 2016, ARXIV160903193
   DAS A, 2015, INTERSPEECH, P3531
   Gales M., 2008, FDN TRENDS SIGNAL PR, V1, P195, DOI [10.1561/2000000004, DOI 10.1561/2000000004]
   Ghahremani Pegah, 2016, INTERSPEECH, V2016
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   GREZL F, 2007, AC SPEECH SIGN PROC, P757
   Hannun A.Y., 2014, ARXIV14082873
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Kim Suyoun, 2017, AC SPEECH SIGN PROC
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/18304
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lin M., 2013, ARXIV13124400
   Luong Minh-Thang, 2015, ARXIV150804025
   Maas A. L., 2013, ICML WORKSH DEEP LEA
   PALAZ D, 2015, AC SPEECH SIGN PROC, P4295
   Palaz Dimitri, 2013, ARXIV13122137
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT
   Sainath Tara N, 2015, INTERSPEECH, V2015
   Springenberg J. T., 2014, ARXIV14126806
   Vesely K., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P42, DOI 10.1109/ASRU.2011.6163903
   Yan Z. J., 2013, P INTERSPEECH
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 31
TC 1
Z9 1
BN 978-1-5090-4788-8
PY 2017
BP 309
EP 315
UT WOS:000426066100043
ER

PT B
AU Manohar, V
   Povey, D
   Khudanpur, S
AF Manohar, Vimal
   Povey, Daniel
   Khudanpur, Sanjeev
GP IEEE
TI JHU KALDI SYSTEM FOR ARABIC MGB-3 ASR CHALLENGE USING DIARIZATION,
   AUDIO-TRANSCRIPT ALIGNMENT AND TRANSFER LEARNING
SO 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 16-20, 2017
CL Okinawa, JAPAN
DE Multi-genre broadcast; Automatic speech recognition; Lightly-supervised
   training; LF-MMI; Segmentation
AB This paper describes the JHU team's Kaldi system submission to the Arabic MGB-3: The Arabic speech recognition in the Wild Challenge for ASRU-2017. We use a weights transfer approach to adapt a neural network trained on the out-of-domain MGB-2 multi-dialect Arabic TV broadcast corpus to the MGB-3 Egyptian YouTube video corpus. The neural network has a TDNN-LSTM architecture and is trained using lattice-free maximum mutual information (LF-MMI) objective followed by sMBR discriminative training. For supervision, we fuse transcripts from 4 independent transcribers into confusion network training graphs. We also describe our own approach for speaker diarization and audio-transcript alignment. We use this to prepare lightly supervised transcriptions for training the seed system used for adaptation to MGB3. Our primary submission to the challenge gives a multi-reference WER of 32.78% on the MGB-3 test set.
CR Ali A., 2016, ARABICASRCHALLENGE20
   Ali A, 2016, IEEE W SP LANG TECH, P279, DOI 10.1109/SLT.2016.7846277
   Ali A, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P576, DOI 10.1109/ASRU.2015.7404847
   Ali Ahmed, 2017, AUT SPEECH REC UNPUB
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Chen S. F., 1996, P ACL 1996 SANT CRUZ, V34, P310, DOI DOI 10.3115/981863.981904
   Cheng Gaofeng, 2017, P INTERSPEECH
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Garcia-Romero D., 2011, INTERSPEECH, V2011, P249
   Ghahrehmani Pegah, 2017, AUT SPEECH REC UNPUB
   Graff D, 2002, SPEECH COMMUN, V37, P15, DOI 10.1016/S0167-6393(01)00057-7
   Ioffe S, 2006, LECT NOTES COMPUT SC, V3954, P531
   Karafiat M., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P152, DOI 10.1109/ASRU.2011.6163922
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Lamel L, 2002, COMPUT SPEECH LANG, V16, P115, DOI 10.1006/csla.2001.0186
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152
   Meignier Sylvain, 2010, CMU SPUD WORKSH, V2010
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3214
   Povey  D., 2011, P AUT SPEECH REC UND
   Povey D, 2016, INTERSPEECH, P2751, DOI 10.21437/Interspeech.2016-595
   Sak H., 2014, 15 ANN C INT SPEECH
   Sell G, 2014, IEEE W SP LANG TECH, P413, DOI 10.1109/SLT.2014.7078610
   Siegler M. A., 1997, P DARPA SPEECH REC W, V1997
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Vesely K., 2013, P INTERSPEECH, P2345
   Xu HH, 2011, COMPUT SPEECH LANG, V25, P802, DOI 10.1016/j.csl.2011.03.001
NR 27
TC 0
Z9 0
BN 978-1-5090-4788-8
PY 2017
BP 346
EP 352
UT WOS:000426066100048
ER

PT B
AU Leidal, K
   Harwath, D
   Glass, J
AF Leidal, Kenneth
   Harwath, David
   Glass, James
GP IEEE
TI LEARNING MODALITY-INVARIANT REPRESENTATIONS FOR SPEECH AND IMAGES
SO 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 16-20, 2017
CL Okinawa, JAPAN
DE Modality invariance; unsupervised speech processing; multimodal language
   processing; variational methods; regularization
AB In this paper, we explore the unsupervised learning of a semantic embedding space for co-occurring sensory inputs. Specifically, we focus on the task of learning a semantic vector space for both spoken and handwritten digits using the TIDIGITs and MNIST datasets. Current techniques encode image and audio/textual inputs directly to semantic embeddings. In contrast, our technique maps an input to the mean and log variance vectors of a diagonal Gaussian from which sample semantic embeddings are drawn. In addition to encouraging semantic similarity between co-occurring inputs, our loss function includes a regularization term borrowed from variational autoencoders (VAEs) which drives the posterior distributions over embeddings to be unit Gaussian. We can use this regularization term to filter out modality information while preserving semantic information. We speculate this technique may be more broadly applicable to other areas of cross-modality/domain information retrieval and transfer learning.
CR Aytar Yusuf, 2016, ADV NEURAL INFORM PR, P892
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Harwath  D., 2016, ADV NEURAL INFORM PR, P1858
   Hsu Wei- Ning, 2017, ARXIV170404222 ARXIV
   Kashyap Karan, 2017, THESIS
   Kingma D.P., 2013, ARXIV13126114
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leonard R Gary, 1993, TEXAS INSTRUMENTS IN
   Man K, 2012, J NEUROSCI, V32, P16629, DOI 10.1523/JNEUROSCI.2342-12.2012
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT
   Saito Kuniaki, 2016, ARXIV161207976 ARXIV
   Tzeng Eric, 2017, ARXIV170205464 ARXIV
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Kaiye, 2016, ARXIV160706215 ARXIV
NR 16
TC 1
Z9 1
BN 978-1-5090-4788-8
PY 2017
BP 424
EP 429
UT WOS:000426066100059
ER

PT B
AU Rastogi, A
   Hakkani-Tur, D
   Heck, L
AF Rastogi, Abhinav
   Hakkani-Tur, Dilek
   Heck, Larry
GP IEEE
TI SCALABLE MULTI-DOMAIN DIALOGUE STATE TRACKING
SO 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 16-20, 2017
CL Okinawa, JAPAN
DE dialogue state tracking; belief tracking; dialogue systems; transfer
   learning
AB Dialogue state tracking (DST) is a key component of task-oriented dialogue systems. DST estimates the user's goal at each user turn given the interaction until then. State of the art approaches for state tracking rely on deep learning methods, and represent dialogue state as a distribution over all possible slot values for each slot present in the ontology. Such a representation is not scalable when the set of possible values are unbounded (e.g., date, time or location) or dynamic (e.g., movies or usernames). Furthermore, training of such models requires labeled data, where each user turn is annotated with the dialogue state, which makes building models for new domains challenging. In this paper, we present a scalable multi-domain deep learning based approach for DST. We introduce a novel framework for state tracking which is independent of the slot value set, and represent the dialogue state as a distribution over a set of values of interest (candidate set) derived from the dialogue history or knowledge. Restricting these candidate sets to be bounded in size addresses the problem of slot-scalability. Furthermore, by leveraging the slot-independent architecture and transfer learning, we show that our proposed approach facilitates quick adaptation to new domains.
CR Bapna A., 2017, ZERO SHOT FRAM UNPUB
   Dernoncourt F., 2017, DIALOGUES SOCIAL ROB, P475
   Hakkani-Tur D., 2016, P INT
   Henderson  M., 2014, 15 ANN M SPEC INT GR, V263
   Henderson  M., 2014, P 15 ANN M SPEC INT, P292
   Henderson M, 2014, IEEE W SP LANG TECH, P324, DOI 10.1109/SLT.2014.7078595
   Henderson Matthew, 2013, P SIGDIAL 2013 C, P467
   Hori T, 2016, IEEE W SP LANG TECH, P552, DOI 10.1109/SLT.2016.7846317
   Jaech A., 2016, P INT
   Kim  S., 2016, P 7 INT WORKSH SPOK
   Kim Seokhwan, 2016, P 2016 IEEE WORKSH S
   Kingma D. P, 2014, P 3 INT C LEARN REPR
   Liu Bing, 2017, P INT
   Mrksic  N., 2016, ARXIV160603777
   Mrksic N., 2015, ARXIV150607190
   Schatzmann Jost, 2007, P HUM LANG TECHN 200, P149
   Shah  P., 2016, NIPS 2016 DEEP LEARN
   Shi HJ, 2016, IEEE W SP LANG TECH, P559, DOI 10.1109/SLT.2016.7846318
   Wen T.-H., 2016, ARXIV160404562
   Williams J. D., 2014, P 15 ANN M SPEC INT, P282
   Williams Jason, 2013, P SIGDIAL 2013 C, P404
   Williams Jason, 2013, P SIGDIAL CIT, V62
   Williams Jason D, 2005, AUTOMATIC SPEECH REC, P177
NR 23
TC 0
Z9 0
BN 978-1-5090-4788-8
PY 2017
BP 561
EP 568
UT WOS:000426066100078
ER

PT S
AU Zhou, XY
   Huang, QX
   Sun, X
   Xue, XY
   Wei, YC
AF Zhou, Xingyi
   Huang, Qixing
   Sun, Xiao
   Xue, Xiangyang
   Wei, Yichen
GP IEEE
TI Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised
   Approach
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)
SE IEEE International Conference on Computer Vision
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB In this paper, we study the task of 3D human pose estimation in the wild. This task is challenging due to lack of training data, as existing datasets are either in the wild images with 2D pose or in the lab images with 3D pose.
   We propose a weakly-supervised transfer learning method that uses mixed 2D and 3D labels in a unified deep neutral network that presents two-stage cascaded structure. Our network augments a state-of-the-art 2D pose estimation sub-network with a 3D depth regression sub-network. Unlike previous two stage approaches that train the two sub-networks sequentially and separately, our training is end-to-end and fully exploits the correlation between the 2D pose and depth estimation sub-tasks. The deep features are better learnt through shared representations. In doing so, the 3D pose labels in controlled lab environments are transferred to in the wild images. In addition, we introduce a 3D geometric constraint to regularize the 3D pose prediction, which is effective in the absence of ground truth depth labels. Our method achieves competitive results on both 2D and 3D benchmarks.
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Andriluka Mykhaylo, 2014, IEEE C COMP VIS PATT
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Chen C.-H., 2016, ARXIV161206524
   Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58
   Chu X., 2017, ARXIV170207432
   Collobert R., 2011, BIGLEARN
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hoffman  J., 2016, ARXIV161202649
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   LI SJ, 2015, P AS C COMP VIS, V9004, P332, DOI DOI 10.1007/978-3-319-16808-1_23
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mehta D., 2016, ARXIV161109813
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   NEWELL A, 2016, EUR C COMP VIS, V9912, P483, DOI DOI 10.1007/978-3-319-46484-8_29
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Pavlakos G., 2016, ARXIV161107828
   Popa A. I., 2017, ARXIV170108985
   RAMAKRISHNA V, 2012, EUR C COMP VIS, V7575, P573
   Rogez G., 2016, ADV NEURAL INFORM PR, P3108
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Tekin B., 2016, ARXIV160505180
   Tome D., 2017, ARXIV170100295
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   WU JJ, 2016, EUR C COMP VIS, V9910, P365, DOI DOI 10.1007/978-3-319-46466-4_22
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Zhou X., 2017, ARXIV170102354
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
   Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074
   Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17
NR 35
TC 8
Z9 8
SN 1550-5499
BN 978-1-5386-1032-9
PY 2017
BP 398
EP 407
DI 10.1109/ICCV.2017.51
UT WOS:000425498400042
ER

PT S
AU Camgoz, NC
   Hadfield, S
   Koller, O
   Bowden, R
AF Camgoz, Necati Cihan
   Hadfield, Simon
   Koller, Oscar
   Bowden, Richard
GP IEEE
TI SubUNets: End-to-end Hand Shape and Continuous Sign Language Recognition
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)
SE IEEE International Conference on Computer Vision
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB We propose a novel deep learning approach to solve simultaneous alignment and recognition problems (referred to as "Sequence-to-sequence" learning). We decompose the problem into a series of specialised expert systems referred to as SubUNets. The spatio-temporal relationships between these SubUNets are then modelled to solve the task, while remaining trainable end-to-end.
   The approach mimics human learning and educational techniques, and has a number of significant advantages. SubUNets allow us to inject domain-specific expert knowledge into the system regarding suitable intermediate representations. They also allow us to implicitly perform transfer learning between different interrelated tasks, which also allows us to exploit a wider range of more varied data sources. In our experiments we demonstrate that each of these properties serves to significantly improve the performance of the overarching recognition system, by better constraining the learning problem.
   The proposed techniques are demonstrated in the challenging domain of sign language recognition. We demonstrate state-of-the-art performance on hand-shape recognition (outperforming previous techniques by more than 30%). Furthermore, we are able to obtain comparable sign recognition rates to previous research, without the need for an alignment step to segment out the signs for recognition.
CR Abadi M., 2016, ARXIV160304467
   Amodei D., 2016, INT C MACH LEARN ICM
   Assael Y. M., 2016, ARXIV161101599
   Bandanau D., 2015, INT C LEARN REPR ICL
   Camgoz N. C., 2016, INT WORKSH HUM BEH U
   Camgoz N. C., 2016, INT C LANG RES EV LR
   Chatfield K., 2014, BRIT MACH VIS C BMVC
   Cho K., 2014, SYNTAX SEMANTICS STR
   Chung J. S., 2017, IEEE C COMP VIS PATT
   Cooper H., 2009, IEEE C COMP VIS PATT
   Cooper H., 2011, VISUAL ANAL HUMANS
   Deng J., 2009, IEEE C COMP VIS PATT
   Donahue Jeff, 2015, IEEE C COMP VIS PATT
   Forster J., 2014, INT C LANG RES EV LR
   Goodfellow IJ, 2016, DEEP LEARNING
   Graves A., 2006, INT C MACH LEARN ICM
   Graves A, 2009, IEEE T PATTERN ANAL
   Graves A, 2013, IEEE INT C AC SPEECH
   He K., 2016, IEEE C COMP VIS PATT
   Hochreiter S., 1997, NEURAL COMPUTATION
   Huang D. - A., 2016, EUR C COMP VIS ECCV
   Iandola F., 2016, ARXIV160207360
   Jia Yangqing, 2014, ACM INT C MULT
   Kalchbrenner N., 2013, EMPIRICAL METHODS NA
   Kingma D. P., 2014, INT C LEARN REPR ICL
   Koller O., 2016, BRIT MACH VIS C BMVC
   Koller O., 2015, COMPUTER VISION IMAG
   Koller O., 2016, IEEE C COMP VIS PATT
   Kristoffersen J. H., 2008, ORDBOG DANSK TEGNSPR
   Krizhevsky A., 2012, ADV NEURAL INFORM PR
   McKee D., 2015, ONLINE DICT NZ SIGN
   Neubig Graham, 2017, ARXIV170301619
   Pascanu R., 2013, INT C MACH LEARN ICM
   Pigou L., 2015, INT J COMPUTER VISIO
   Poppe R., 2010, IMAGE VISION COMPUTI
   Ronneberger O., 2015, INT C MED IM COMP CO
   Simonyan K., 2015, INT C LEARN REPR ICL
   Sutskever I., 2014, ADV NEURAL INFORM PR
   Szegedy C., 2017, ASS ADV ART INT AAAI
   Szegedy C., 2015, IEEE C COMP VIS PATT
   Tran D., 2015, IEEE INT C COMP VIS
   Wang H., 2016, ACM T ACCESSIBLE COM
   Xu K., 2015, INT C MACH LEARN
NR 43
TC 1
Z9 1
SN 1550-5499
BN 978-1-5386-1032-9
PY 2017
BP 3075
EP 3084
DI 10.1109/ICCV.2017.332
UT WOS:000425498403015
ER

PT S
AU Kim, KI
   Tompkin, J
   Richardt, C
AF Kim, Kwang In
   Tompkin, James
   Richardt, Christian
GP IEEE
TI Predictor Combination at Test Time
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)
SE IEEE International Conference on Computer Vision
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB We present an algorithm for test-time combination of a set of reference predictors with unknown parametric forms. Existing multi-task and transfer learning algorithms focus on training-time transfer and combination, where the parametric forms of predictors are known and shared. However, when the parametric form of a predictor is unknown, e.g., for a human predictor or a predictor in a precompiled library, existing algorithms are not applicable. Instead, we empirically evaluate predictors on sampled data points to measure distances between different predictors. This embeds the set of reference predictors into a Riemannian manifold, upon which we perform manifold denoising to obtain the refined predictor. This allows our approach to make no assumptions about the underlying predictor forms. Our test-time combination algorithm equals or outperforms existing multi-task and transfer learning algorithms on challenging real-world datasets, without introducing specific model assumptions.
CR Agarwal A, 2010, ADV NEURAL INFORM PR, V23, P46
   Amari Shun-ichi, 2007, METHODS INFORM GEOME
   Argyriou Andreas, 2008, MACHINE LEARNING, V73
   Aytar Yusuf, 2011, ICCV
   Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356
   Bakker B., 2003, JMLR, V4
   Bonilla E. V., 2008, NIPS, P153
   Chapelle O., 2010, SEMISUPERVISED LEARN
   Chen W.-Y., 2016, ECCV
   Daume H., 2012, P 29 INT C MACH LEAR, P1383
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Hein M., 2007, NIPS, V19, P561
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   JESORSKY O, 2001, AUDIO VIDEO BASED PE, V2091, P90
   Jost J., 2011, RIEMANNIAN GEOMETRY
   Kovashka A, 2013, IEEE I CONF COMP VIS, P3432, DOI 10.1109/ICCV.2013.426
   Levinkov E, 2013, IEEE I CONF COMP VIS, P1321, DOI 10.1109/ICCV.2013.167
   Lozano A., 2012, ICML
   Luo Y, 2013, IEEE T IMAGE PROCESS, V22, P523, DOI 10.1109/TIP.2012.2218825
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pentina A, 2015, PROC CVPR IEEE, P5492, DOI 10.1109/CVPR.2015.7299188
   Pishchulin L., 2017, PATTERN RECOGNITION
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Robinette K., 1999, 3 D DIGITAL IMAGING
   Royer A, 2015, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2015.7298746
   Ruvolo P., 2013, JMLR W CP P ICML, V28
   Seeger M., 2002, JMLR, V3
   Snelson Ed, 2006, NIPS
   Titsias M. K., 2011, ADV NEURAL INFORM PR, P2339
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549
   Vijayakumar S., 2000, P 17 INT C MACH LEAR, P1079
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang F, 2009, IEEE DATA MINING, P562, DOI 10.1109/ICDM.2009.66
NR 36
TC 0
Z9 0
SN 1550-5499
BN 978-1-5386-1032-9
PY 2017
BP 3573
EP 3581
DI 10.1109/ICCV.2017.384
UT WOS:000425498403067
ER

PT S
AU Murdock, C
   De la Torre, F
AF Murdock, Calvin
   De la Torre, Fernando
GP IEEE
TI Approximate Grassmannian Intersections: Subspace-Valued Subspace
   Learning
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)
SE IEEE International Conference on Computer Vision
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
ID PRINCIPAL COMPONENT ANALYSIS; FEASIBILITY PROBLEMS; LINEAR-SUBSPACES;
   FACE RECOGNITION; ALGORITHMS; REDUCTION; MANIFOLDS; FRAMEWORK; SPACE
AB Subspace learning is one of the most foundational tasks in computer vision with applications ranging from dimensionality reduction to data denoising. As geometric objects, subspaces have also been successfully used for efficiently representing certain types of invariant data. However, methods for subspace learning from subspace-valued data have been notably absent due to incompatibilities with standard problem formulations. To fill this void, we introduce Approximate Grassmannian Intersections (AGI), a novel geometric interpretation of subspace learning posed as finding the approximate intersection of constraint sets on a Grassmann manifold. Our approach can naturally be applied to input subspaces of varying dimension while reducing to standard subspace learning in the case of vector-valued data. Despite the nonconvexity of our problem, its globally-optimal solution can be found using a singular value decomposition. Furthermore, we also propose an efficient, general optimization approach that can incorporate additional constraints to encourage properties such as robustness. Alongside standard subspace applications, AGI also enables the novel task of transfer learning via subspace completion. We evaluate our approach on a variety of applications, demonstrating improved invariance and generalization over vector-valued alternatives.
CR Artacho FJA, 2016, J GLOBAL OPTIM, V65, P309, DOI 10.1007/s10898-015-0380-6
   Baker CG, 2012, LINEAR ALGEBRA APPL, V436, P2866, DOI 10.1016/j.laa.2011.07.018
   Balzano  L., 2010, ALL C COMM CONTR COM
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Bauschke HH, 2004, J APPROX THEORY, V127, P178, DOI 10.1016/j.jat.2004.02.006
   Bauschke HH, 1996, SIAM REV, V38, P367, DOI 10.1137/S0036144593251710
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Combettes P. L., 1996, ADV IMAG ELECT PHYS, P155
   COMBETTES PL, 1994, IEEE T SIGNAL PROCES, V42, P2955, DOI 10.1109/78.330356
   Cunningham J. P., 2015, J MACHINE LEARNING R
   De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184
   Duchi J., 2008, INT C MACH LEARN ICM
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   Hamm J., 2008, INT C MACH LEARN ICM
   Harandi M., 2013, C COMP VIS PATT REC
   Harandi M, 2015, INT J COMPUT VISION, V114, P113, DOI 10.1007/s11263-015-0833-x
   He J., 2012, C COMP VIS PATT REC
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hong Y, 2016, IEEE T PATTERN ANAL, V38, P2284, DOI 10.1109/TPAMI.2016.2516533
   Huang W., 2016, C COMP VIS PATT REC
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lewis AS, 2008, MATH OPER RES, V33, P216, DOI 10.1287/moor.1070.0291
   Liu M., 2014, INT C MULT INT
   Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   RAO CR, 1948, J ROY STAT SOC B, V10, P159
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Vidal R., 2003, C COMP VIS PATT REC
   VU V. Q., 2013, ADV NEURAL INFORM PR
   Zhang D., 2016, INT C ART INT STAT A
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 40
TC 0
Z9 0
SN 1550-5499
BN 978-1-5386-1032-9
PY 2017
BP 4318
EP 4326
DI 10.1109/ICCV.2017.462
UT WOS:000425498404041
ER

PT S
AU Xiong, F
   Shi, XJ
   Yeung, DY
AF Xiong, Feng
   Shi, Xingjian
   Yeung, Dit-Yan
GP IEEE
TI Spatiotemporal Modeling for Crowd Counting in Videos
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)
SE IEEE International Conference on Computer Vision
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
ID HUMANS
AB Region of Interest (ROI) crowd counting can be formulated as a regression problem of learning a mapping from an image or a video frame to a crowd density map. Recently, convolutional neural network (CNN) models have achieved promising results for crowd counting. However, even when dealing with video data, CNN-based methods still consider each video frame independently, ignoring the strong temporal correlation between neighboring frames. To exploit the otherwise very useful temporal information in video sequences, we propose a variant of a recent deep learning model called convolutional LSTM (ConvLSTM) for crowd counting. Unlike the previous CNN-based methods, our method fully captures both spatial and temporal dependencies. Furthermore, we extend the ConvLSTM model to a bidirectional ConvLSTM model which can access long-range information in both directions. Extensive experiments using four publicly available datasets demonstrate the reliability of our approach and the effectiveness of incorporating temporal information to boost the accuracy of crowd counting. In addition, we also conduct some transfer learning experiments to show that once our model is trained on one dataset, its learning experience can be transferred easily to a new dataset which consists of only very few video frames for model adaptation.
CR Ahuja  N., 2007, ICCV, P1
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Arteta C, 2014, LECT NOTES COMPUT SC, V8691, P504, DOI 10.1007/978-3-319-10578-9_33
   Chan A. B., 2008, P IEEE C COMP VIS PA, P1, DOI [10.1109/CVPR.2008.4587569, DOI 10.1109/CVPR.2008.4587569]
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Finn C., 2016, ADV NEURAL INFORM PR, V29, P64
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Huang Y., 2015, P ADV NEUR INF PROC, P2015
   Idrees H, 2015, IEEE T PATTERN ANAL, V37, P1986, DOI 10.1109/TPAMI.2015.2396051
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Kingma D., 2015, ICLR
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lempitsky V. S., 2010, ADV NEURAL INFORM PR, P1324, DOI DOI 10.1111/1467-9280.03439
   Li B, 2015, IEEE I CONF COMP VIS, P4175, DOI 10.1109/ICCV.2015.475
   Li  M., 2008, PATT REC 2008 ICPR 2, P1, DOI [DOI 10.1109/ICPR.2008.4761705, 10.1109/icpr.2008.4761705]
   Loy CC, 2013, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2013.270
   Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48
   ONORORUBIO D, 2016, EUR C COMP VIS, V9911, P615, DOI DOI 10.1007/978-3-319-46478-7_38
   Rabaud V., 2006, IEEE COMP SOC C COMP, P705, DOI DOI 10.1109/CVPR.2006.92
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551
   Shi X., 2015, ADV NEURAL INFORM PR, P802
   Sindagi V. A., 2017, ICCV
   Sourtzinos P, 2016, LECT NOTES COMPUT SC, V9914, P655, DOI 10.1007/978-3-319-48881-3_46
   Sutskever  I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.1007/S10107-014-0839-0
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Yang J., 2017, ICLR
   Yu K., 2005, P 22 INT C MACH LEAR, P1012
   Zhang C, 2016, IEEE T MULTIMEDIA, V18, P1048, DOI 10.1109/TMM.2016.2542585
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang S, 2017, CVPR
   Zhang S., 2017, ICCV
   Zhang  Y., 2016, ARXIV161003022
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
NR 37
TC 1
Z9 1
SN 1550-5499
BN 978-1-5386-1032-9
PY 2017
BP 5161
EP 5169
DI 10.1109/ICCV.2017.551
UT WOS:000425498405026
ER

PT S
AU Noroozi, M
   Pirsiavash, H
   Favaro, P
AF Noroozi, Mehdi
   Pirsiavash, Hamed
   Favaro, Paolo
GP IEEE
TI Representation Learning by Learning to Count
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)
SE IEEE International Conference on Computer Vision
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB We introduce a novel method for representation learning that uses an artificial supervision signal based on counting visual primitives. This supervision signal is obtained from an equivariance relation, which does not require any manual annotation. We relate transformations of images to transformations of the representations. More specifically, we look for the representation that satisfies such relation rather than the transformations that match a given representation. In this paper, we use two image transformations in the context of counting: scaling and tiling. The first transformation exploits the fact that the number of visual primitives should be invariant to scale. The second transformation allows us to equate the total number of visual primitives in each tile to that in the whole image. These two transformations are combined in one constraint and used to train a neural network with a contrastive loss. The proposed task produces representations that perform on par or exceed the state of the art in transfer learning benchmarks.
CR Agrawal P., 2015, ICCV
   Arteta C., 2016, ECCV
   Bengio Y., 2013, ICML
   Chan A., 2008, CVPR
   Chan A. B., 2009, ICCV
   Chattopadhyay P., 2016, ARXIV160403505V2
   Chopra Sumit, 2005, CVPR
   Dai Jifeng, 2015, ICLR
   Doersch Carl, 2015, ICCV
   Donahue J., 2017, ICLR
   Girshick Ross, 2015, ICCV
   Goodfellow I., 2014, NIPS
   Goodfellow IJ, 2016, DEEP LEARNING
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Idrees H., 2015, PAMI
   Itseez, 2014, OPENCV REF MAN
   Jayaraman Dinesh, 2015, ICCV
   Jia Y., 2014, ACM MM
   Jing Shao, 2015, CVPR
   Krahenbuhl P., 2016, ICLR
   Krizhevsky  A., 2012, NIPS
   Larsson G., 2017, CVPR
   Larsson G., 2016, ECCV
   Lempitsky V., 2010, NIPS
   Lenc K., 2015, CVPR
   Lin T.-Y., 2014, ECCV
   Long  J., 2015, CVPR
   Misra Ishan, 2016, ECCV
   Mundhenk T. N., 2016, ECCV
   Noroozi M., 2016, ECCV
   Noroozi M., 2016, ARXIV160309246
   Owens A., 2016, ECCV
   Pathak D., 2016, ARXIV161206370
   Pathak D., 2016, CVPR
   Pinto L., 2016, ECCV
   Radford  Alec, 2016, ICLR
   Reed Scott E, 2015, NIPS, P7
   Ren M., 2017, ARXIV160509410V4
   Russakovsky Olga, 2015, IJCV
   Vincent P., 2006, ICML
   Wang X., 2015, ICCV
   Zhang C., 2015, CVPR
   Zhang R., 2016, ARXIV161109842
   Zhang R., 2016, ECCV
   Zhou B., 2014, NIPS
NR 45
TC 0
Z9 0
SN 1550-5499
BN 978-1-5386-1032-9
PY 2017
BP 5899
EP 5907
DI 10.1109/ICCV.2017.628
UT WOS:000425498405103
ER

PT B
AU Lim, J
   Son, H
   Lee, D
   Lee, D
AF Lim, Junsung
   Son, Heesuk
   Lee, Daekeun
   Lee, Dongman
BE Liu, XQ
   Bellur, U
TI An MARL-based Distributed Learning Scheme for Capturing User Preferences
   in a Smart Environment
SO 2017 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC)
CT IEEE International Conference on Services Computing (SCC)
CY JUN 25-30, 2017
CL Honolulu, HI
DE personalization; smart device; user preference; distributed learning;
   context aware
AB Providing a personalized service to a user in a smart environment has been one of the key goals in the area of pervasive computing. The proliferation of individually developed smart devices in the name of Internet of Things opens up a possibility of providing personalized services to a user in an autonomous and distributed manner. As a user's task often involves services supported by multiple devices, capturing a device-specific service preference is not enough to maximize a user's comfort. In this paper, we propose a distributed learning scheme for capturing multiple device service preferences in a smart environment. We exploit multi-agent reinforcement learning (MARL) method where each smart device acts as a reinforcement learning agent to incrementally and cooperatively capture a user specific preference of a task. Experiments confirm that smart devices with the proposed scheme are able to capture multiple device service preferences from a small number of interactions with a user and an environment. Also, the proposed transfer learning method improves learning performance for a new task.
CR Cook DJ, 2006, LECT NOTES COMPUT SC, V4008, P165
   Even-Dar E, 2003, J MACH LEARN RES, V5, P1
   Gallacher S, 2013, ACM T AUTON ADAP SYS, V8, DOI 10.1145/2451248.2451253
   Guivarch Valerian, 2012, Ambient Intelligence. Third International Joint Conference (AML 2012). Proceedings, P129, DOI 10.1007/978-3-642-34898-3_9
   Gulwani S, 2015, COMMUN ACM, V58, P90, DOI 10.1145/2736282
   Khalili A., 2009, BEH MON INT WORKSH G
   Naganuma TF, 2005, LECT NOTES COMPUT SC, V3729, P959
   Read Jesse, 2012, Advances in Intelligent Data Analysis XI. Proceedings 11th International Symposium, IDA 2012, P313, DOI 10.1007/978-3-642-34156-4_29
   Son H, 2015, P INT COMP SOFTW APP, P23, DOI 10.1109/COMPSAC.2015.101
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   Tan M., 1993, P 10 INT C MACH LEAR, P330
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Tegelund B., 2016, 2016 IEEE INT C PERV, P1
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Zhi-Hao Lin, 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P759
NR 15
TC 1
Z9 1
BN 978-1-5386-2005-2
PY 2017
BP 132
EP 139
DI 10.1109/SCC.2017.24
UT WOS:000425931600017
ER

PT S
AU Huang, PW
   Lin, CH
   Chung, ML
   Lin, TM
   Wu, BF
AF Huang, Po-Wei
   Lin, Chun-Hao
   Chung, Meng-Liang
   Lin, Tzu-Min
   Wu, Bing-Fei
GP IEEE
TI Image Based Contactless Blood Pressure Assessment using Pulse Transit
   Time
SO 2017 INTERNATIONAL AUTOMATIC CONTROL CONFERENCE (CACS)
SE CACS International Automatic Control Conference
CT International Automatic Control Conference (CACS)
CY NOV 12-15, 2017
CL Pingtung, TAIWAN
AB Recent years have seen increased attention being given to Blood Pressure (BP) monitoring. Among all kinds of measurements, the monitors based on Pulse Transit Time (PTT) have gain plenty of attention due to its continuous and cuffless features. Additionally, several studies proposed a fancy way to estimate photoplethysmography (PPG) signal simply via a regular webcam. Nevertheless, literatures on issues of integrating these two advanced techniques have emerged on a slowly and scattered way. Furthermore, accuracy of BP prediction model based on PTT is often limited due to the lack of data. To address the above-mentioned problems, we proposed an image based BP measurement algorithm using k-nearest neighbor and transfer learning results from MIMICII database to real task. The study also introduces newly defined PTT features which are especially suitable for image based PPG and domain adaptation. Compared with the state-of-the-art algorithm, root mean square error of SBP evaluation has been reduced from 15.08 to 14.02.
CR Buxi D, 2017, IEEE T BIO-MED ENG, V64, P917, DOI 10.1109/TBME.2016.2582472
   Carek AM, 2017, IEEE T BIOMED CIRCUI
   Cattivelli FS, 2009, SIXTH INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P114, DOI 10.1109/P3644.34
   Cheng J., 2016, IEEE J BIOMED HLTH I
   Costa M, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.068102
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   Ding XR, 2016, IEEE J BIOMED HEALTH, V20, P1455, DOI 10.1109/JBHI.2016.2620995
   Ding XR, 2016, IEEE T BIO-MED ENG, V63, P964, DOI 10.1109/TBME.2015.2480679
   Dolan E, 2005, HYPERTENSION, V46, P156, DOI 10.1161/01.HYP.0000170138.56903.7a
   Feng LT, 2015, IEEE T CIRC SYST VID, V25, P879, DOI 10.1109/TCSVT.2014.2364415
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Jeong IC, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0439-z
   Kim SH, 2014, ANESTHESIOLOGY, V120, P1080, DOI 10.1097/ALN.0000000000000226
   Miao F., 2017, IEEE J BIOMED HLTH I
   Nitzan M, 2002, PHYSIOL MEAS, V23, P85, DOI 10.1088/0967-3334/23/1/308
   OBRIST PA, 1979, PSYCHOPHYSIOLOGY, V16, P292, DOI 10.1111/j.1469-8986.1979.tb02993.x
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Penaz J., 1973, 10 INT C MED BIOL EN
   Seeberg T., 2016, IEEE T BIOMED ENG
   Sugita N, 2015, IEEE ENG MED BIO, P4218, DOI 10.1109/EMBC.2015.7319325
   T. H. Society, 6 24 MILL HIGH RISK
   Tsai WC, 2005, AM J HYPERTENS, V18, P1118, DOI 10.1016/j.amjhyper.2005.02.739
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Wang RP, 2014, INT CONF SIGN PROCES, P115, DOI 10.1109/ICOSP.2014.7014980
   Wang W., 2016, IEEE T BIOMED ENG
   World Health Organization, GLOB HLTH OBS GHO DA
   Zhang QC, 2018, IEEE T SYST MAN CY-S, V48, P1657, DOI 10.1109/TSMC.2017.2701797
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
NR 28
TC 0
Z9 0
SN 2473-7240
BN 978-1-5386-3900-9
PY 2017
UT WOS:000425915900046
ER

PT S
AU Bappee, FK
AF Bappee, Fateha Khanam
BE Mouhoub, M
   Langlais, P
TI Identification and Classification of Alcohol-Related Violence in Nova
   Scotia Using Machine Learning Paradigms
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, CANADIAN AI 2017
SE Lecture Notes in Artificial Intelligence
CT 30th Canadian Conference on Artificial Intelligence (AI)
CY MAY 16-19, 2017
CL Edmonton, CANADA
AB A significant improvement in big data analytics has motivated the radical change in the scientific study of crime and criminals. In terms of criminal activities, it has been observed that alcohol has a great influence in most of the cases. The main goals of our research are to analyze different types of violence happening in Nova Scotia and to apply machine learning techniques to model the relationships between alcohol consumption and violence. In many machine learning algorithms, it is assumed that, the training and testing data must be in the same distribution and feature space. Because of limited amount of Nova Scotia criminal activity data, the need of transfer learning arises which helps to gain knowledge from different domains. The results of our studies show a very satisfactory classification performance on Nova Scotia data.
CR [Anonymous], 2012, CAN ALC DRUG US MON
   [Anonymous], 2014, ANN REPORT
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1984, CLASSIFICATION REGRE
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Exum ML, 2006, J CRIM JUST, V34, P131, DOI 10.1016/jjcrimjus.2006.01.008
   Gao J, 2008, KDD, P283, DOI DOI 10.1145/1401890.1401928
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schrans T, 2008, CULTURE ALCOHOL USE
NR 9
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-57351-9; 978-3-319-57350-2
PY 2017
VL 10233
BP 421
EP 425
DI 10.1007/978-3-319-57351-9_49
UT WOS:000426181700049
ER

PT S
AU Aneja, D
   Colburn, A
   Faigin, G
   Shapiro, L
   Mones, B
AF Aneja, Deepali
   Colburn, Alex
   Faigin, Gary
   Shapiro, Linda
   Mones, Barbara
BE Lai, SH
   Lepetit, V
   Nishino, K
   Sato, Y
TI Modeling Stylized Character Expressions via Deep Learning
SO COMPUTER VISION - ACCV 2016, PT II
SE Lecture Notes in Computer Science
CT 13th Asian Conference on Computer Vision (ACCV)
CY NOV 20-24, 2016
CL Taipei, TAIWAN
ID FACIAL-EXPRESSION; FACE RECOGNITION; AGENTS; GABOR
AB We propose DeepExpr, a novel expression transfer approach from humans to multiple stylized characters. We first train two Convolutional Neural Networks to recognize the expression of humans and stylized characters independently. Then we utilize a transfer learning technique to learn the mapping from humans to characters to create a shared embedding feature space. This embedding also allows human expression-based image retrieval and character expression-based image retrieval. We use our perceptual model to retrieve character expressions corresponding to humans. We evaluate our method on a set of retrieval tasks on our collected stylized character dataset of expressions. We also show that the ranking order predicted by the proposed features is highly correlated with the ranking order provided by a facial expression expert and Mechanical Turk experiments.
OI Colburn, Alex/0000-0003-4125-4309
CR Adolphs Ralph, 2002, Behav Cogn Neurosci Rev, V1, P21, DOI 10.1177/1534582302001001003
   Amini R, 2013, INT CONF AFFECT, P270, DOI 10.1109/ACII.2013.51
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Character Animator, 2016, CHAR AN AD EFF CC 20
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Deng Z., 2008, P 2008 ACM SIGGRAPH
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Dumas M, 2001, P INT C MULT INT
   Ekman P., 1978, FACIAL ACTION CODING
   Jeni LA, 2014, LECT NOTES COMPUT SC, V8692, P135, DOI 10.1007/978-3-319-10593-2_10
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.1093/biomet/30.1-2.81
   Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lasseter J., 1987, ACM SIGGRAPH COMPUTE, V21, P35, DOI DOI 10.1145/37402.37407
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin YX, 2012, IEEE COMPUT GRAPH, V32, P76, DOI 10.1109/MCG.2012.41
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu M., 2013, 10 IEEE INT C WORKSH, P1, DOI DOI 10.1128/GEN0MEA.00300-13
   Lucey P., 2010, IEEE COMP SOC C COMP, V2010, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Lundqvist D., 1998, TECHNICAL REPORT
   Mahoor Mohammad H, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P336, DOI 10.1109/FG.2011.5771420
   MASE K, 1991, IEICE TRANS COMMUN, V74, P3474
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mollahosseini A., 2016, 2016 IEEE WINT C APP
   Muller H, 2002, LECT NOTES COMPUT SC, V2383, P38
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pantic M., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   Pereira F. C., 2002, MPEG 4 BOOK
   Porter T, 2000, COMMUN ACM, V43, P25, DOI 10.1145/323830.323839
   Roesch EB, 2011, J NONVERBAL BEHAV, V35, P1, DOI 10.1007/s10919-010-0095-9
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shu Chang, 2011, Tsinghua Science and Technology, V16, P216, DOI 10.1016/S1007-0214(11)70032-3
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Ying ZL, 2010, LECT NOTES ARTIF INT, V6216, P457, DOI 10.1007/978-3-642-14932-0_57
   Yu X., 2016, WINT C COMP VIS
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 48
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-54184-6; 978-3-319-54183-9
PY 2017
VL 10112
BP 136
EP 153
DI 10.1007/978-3-319-54184-6_9
UT WOS:000426207700009
ER

PT S
AU Kwasniewska, A
   Ruminski, J
   Rad, P
AF Kwasniewska, Alicja
   Ruminski, Jacek
   Rad, Paul
GP IEEE
TI Deep Features Class Activation Map for Thermal Face Detection and
   Tracking
SO 2017 10TH INTERNATIONAL CONFERENCE ON HUMAN SYSTEM INTERACTIONS (HSI)
SE Conference on Human System Interaction
CT 10th International Conference on Human System Interactions (HSI)
CY JUL 17-19, 2017
CL Ulsan, SOUTH KOREA
DE deep learning; convolutional neural network; transfer learning;
   inception model; class activation map; face detection; face
   localization; thermography
AB Recently, capabilities of many computer vision tasks have significantly improved due to advances in Convolutional Neural Networks. In our research, we demonstrate that it can be also used for face detection from low resolution thermal images, acquired with a portable camera. The physical size of the camera used in our research allows for embedding it in a wearable device or indoor remote monitoring solution for elderly and disabled people. The benefits of the proposed architecture were experimentally verified on the thermal video sequences, acquired in various scenarios to address possible limitations of remote diagnostics: movements of the person performing a diagnose and movements of the examined person. The achieved short processing time ( 42.05 +/- 0.21ms) along with high model accuracy ( false positives -0.43%; true positives for the patient focused on a certain task -89.2%) clearly indicates that the current state of the art in the area of image classification and face tracking in thermography was significantly outperformed.
RI ; Ruminski, Jacek/B-4244-2011
OI Kwasniewska, Alicja/0000-0001-6471-0595; Ruminski,
   Jacek/0000-0003-2266-0088
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Donahue J., P 31 INT C INT C MAC, V32
   Emad O, 2015, IEEE ENG MED BIO, P683, DOI 10.1109/EMBC.2015.7318454
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Kwasniewska A., 2016, P 13 QUANT INFR THER
   Kwasniewska A, 2016, C HUM SYST INTERACT, P504, DOI 10.1109/HSI.2016.7529681
   Kwasniewska A, 2015, C HUM SYST INTERACT, P388, DOI 10.1109/HSI.2015.7170699
   Lei B, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P597, DOI 10.1109/ICME.2006.262479
   Lin  M., 2014, P INT C LEARN REPR I
   Liu X., 2015, 8 INT C BIOM ENG INF
   Marzec M., 2010, J MED INFORM TECHNOL, V16
   McCall R., TECHNICAL REPORT
   Moody's Investors Service, POP AG WILL DAMP EC
   Raina R., P 24 INT C MACH LEAR, P759
   Raina R., 2007, ICML
   Ruminski J., 2016, P 13 QUANT INFR THER
   Ruminski J., 2017, APPL INFRARED BIOMED
   Ruminski J, 2016, C HUM SYST INTERACT, P525, DOI 10.1109/HSI.2016.7529684
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thrun S., 2015, ADV NEURAL INFORM PR, V8, P640
   Wimmer G., 2016, 2016 6 INT C IM PROC, P1
   Zhou B., 2016, COMPUTER VISION PATT
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 28
TC 1
Z9 1
SN 2158-2246
BN 978-1-5090-4688-1
PY 2017
BP 41
EP 47
UT WOS:000425850600007
ER

PT B
AU Patil, K
   Kulkarni, M
   Sriraman, A
   Karande, S
AF Patil, Kalpesh
   Kulkarni, Mandar
   Sriraman, Anand
   Karande, Shirish
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI Deep Learning Based Car Damage Classification
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
AB Image based vehicle insurance processing is an important area with large scope for automation. In this paper we consider the problem of car damage classification, where some of the categories can be fine-granular. We explore deep learning based techniques for this purpose. Initially, we try directly training a CNN. However, due to small set of labeled data, it does not work well. Then, we explore the effect of domain-specific pre-training followed by fine-tuning. Finally, we experiment with transfer learning and ensemble learning. Experimental results show that transfer learning works better than domain specific fine-tuning. We achieve accuracy of 89.5% with combination of transfer and ensemble learning.
CR Erhan D, 2010, J MACH LEARN RES, V11, P625
   He K, 2015, ARXIV151203385
   Jayawardena S., 2013, THESIS
   Kouchi K., 2005, P 26 AS C REM SENS H
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lecun B. Y., 1998, P IEEE, V86
   MASCI J, 2011, INT C ART NEUR NETW, V6791, P52
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Rathje E., 2004, 13 WORLD C EARTHQ EN, P1
   Samadzadegan F, 2008, INT ARCH PHOTOGRAMME, V37, P415
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Soumalya Sarkar M. G. M. R. G, 2016, ANN C PROGN HLTH MAN
   Szegedy C., 2015, ARXIV151200567
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 16
TC 1
Z9 1
BN 978-1-5386-1417-4
PY 2017
BP 50
EP 54
DI 10.1109/ICMLA.2017.0-179
UT WOS:000425853000008
ER

PT B
AU Sun, M
   Schwarz, A
   Wu, M
   Strom, N
   Matsoukas, S
   Vitaladevuni, S
AF Sun, Ming
   Schwarz, Andreas
   Wu, Minhua
   Strom, Nikko
   Matsoukas, Spyros
   Vitaladevuni, Shiv
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI An empirical study of cross-lingual transfer learning techniques for
   small-footprint keyword spotting
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
DE transfer learning; keyword spotting; cross lingual; small-footprint
ID CANONICAL CORRELATION-ANALYSIS; CLASSIFICATION; RECOGNITION; MODELS
AB This paper presents our work on building a small footprint keyword spotting system for a resource-limited language, which requires low CPU, memory and latency. Our keyword spotting system consists of deep neural network (DNN) and hidden Markov model (HMM), which is a hybrid DNN-HMM decoder. We investigate different transfer learning techniques to leverage knowledge and data from a resource-abundant source language to improve the keyword DNN training for a target language which has limited in-domain data. The approaches employed in this paper include training a DNN using source language data to initialize the target language DNN training, mixing data from source and target languages together in a multi-task DNN training setup, using logits computed from a DNN trained on the source language data to regularize the keyword DNN training in the target language, as well as combinations of these techniques. Given different amounts of target language training data, our experimental results show that these transfer learning techniques successfully improve keyword spotting performance for the target language, measured by the area under the curve (AUC) of DNN-HMM decoding detection error tradeoff (DET) curves using a large in-house far-field test set.
CR Ba L.J, 2014, ADV NEURAL INFORM PR, V2, P2654
   Baljekar P, 2014, IEEE W SP LANG TECH, P536, DOI 10.1109/SLT.2014.7078631
   Chen GG, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P416, DOI 10.1109/ASRU.2013.6707766
   FERNANDEZ S, 2007, INT C ART NEUR NETW, V4669, P220
   Guoguo Chen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4087, DOI 10.1109/ICASSP.2014.6854370
   He Q, 2016, INTERSPEECH, P1888, DOI 10.21437/Interspeech.2016-1562
   Heigold G, 2013, INT CONF ACOUST SPEE, P8619, DOI 10.1109/ICASSP.2013.6639348
   Hinton  G., 2015, ARXIV150302531
   HUANG JT, 2013, AC SPEECH SIGN PROC, P7304
   Knill KM, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P138, DOI 10.1109/ASRU.2013.6707719
   Kumatani K., 2017, AUT SPEECH REC UND A
   Miller  D.R., 2007, 8 ANN C INT SPEECH C
   Nakkiran P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1473
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panchapagesan S, 2016, INTERSPEECH, P760, DOI 10.21437/Interspeech.2016-1485
   Parlak S, 2008, INT CONF ACOUST SPEE, P5244, DOI 10.1109/ICASSP.2008.4518842
   Plahl C., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P371, DOI 10.1109/ASRU.2011.6163960
   ROSE RC, 1990, INT CONF ACOUST SPEE, P129, DOI 10.1109/ICASSP.1990.115555
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1478
   Sercu T, 2017, INT CONF ACOUST SPEE, P5295, DOI 10.1109/ICASSP.2017.7953167
   Sercu T, 2016, INT CONF ACOUST SPEE, P4955, DOI 10.1109/ICASSP.2016.7472620
   Shen CC, 2014, J MULTIVARIATE ANAL, V130, P310, DOI 10.1016/j.jmva.2014.05.011
   Stolcke A., AC SPEECH SIGN PROC
   Strom N., 2015, INTERSPEECH, V7, P10
   Sun M., 2017, P INTERSPEECH
   Sun  M., 2016, SPOK LANG TECHN WORK
   Sun Meiling, 2013, THESIS
   Sun M, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P369, DOI 10.1109/ICMLA.2015.121
   Sun M, 2013, PATTERN RECOGN LETT, V34, P1263, DOI 10.1016/j.patrec.2013.03.025
   Sun M, 2013, PATTERN RECOGN LETT, V34, P194, DOI 10.1016/j.patrec.2012.09.018
   Sundar H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1660
   Thomas S, 2012, INT CONF ACOUST SPEE, P4269, DOI 10.1109/ICASSP.2012.6288862
   Thomas S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P877
   Tsakalidis Stavros, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7829, DOI 10.1109/ICASSP.2014.6855124
   Tucker  G., 2016, P INTERSPEECH
   Vu N., 2012, INTERSPEECH
   WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088
   WILPON JG, 1991, INT CONF ACOUST SPEE, P309, DOI 10.1109/ICASSP.1991.150338
   Wollmer M, 2013, SPEECH COMMUN, V55, P252, DOI 10.1016/j.specom.2012.08.006
   Xu HH, 2016, INTERSPEECH, P1315, DOI 10.21437/Interspeech.2016-1099
NR 40
TC 2
Z9 2
BN 978-1-5386-1417-4
PY 2017
BP 255
EP 260
DI 10.1109/ICMLA.2017.0-150
UT WOS:000425853000037
ER

PT B
AU Weiss, KR
   Khoshgoftaar, TM
AF Weiss, Karl R.
   Khoshgoftaar, Taghi M.
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI Comparing Transfer Learning and Traditional Learning Under Domain Class
   Imbalance
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
DE Transfer learning; Domain class imbalance; Traditional machine learning
ID ADAPTATION; REGULARIZATION
AB Transfer learning is a subclass of machine learning, which uses training data (source) drawn from a different domain than that of the testing data (target). A transfer learning environment is characterized by the unavailability of labeled data from the target domain, due to data being rare or too expensive to obtain. However, there exists abundant labeled data from a different, but similar domain. These two domains are likely to have different distribution characteristics. Transfer learning algorithms attempt to align the distribution characteristics of the source and target domains to create high-performance classifiers. This paper provides comparative performance analysis between state-of-the-art transfer learning algorithms and traditional machine learning algorithms under the domain class imbalance condition. The domain class imbalance condition is characterized by the source and target domains having different class probabilities, which can create marginal distribution differences between the source and target data. Statistical analysis is provided to show the significance of the results.
CR Abdi H., 2010, ENCY RES DESIGN, P1, DOI [DOI 10.4135/9781412961288.N178, 10.4135/9781412961288]
   Aha D. W., 1997, LAZY LEARNING
   Al-Stouhi S, 2016, KNOWL INF SYST, V48, P201, DOI 10.1007/s10115-015-0870-3
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137, DOI DOI 10.1007/S10994-009-5152-4
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   CORTES C, 2008, ALT, V5254, P38
   Freund R. J., 1981, SAS LINEAR MODELS GU, V1
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   HOSMER DW, 2000, WILEY SERIES PROBABI
   Hulse JV, 2007, P 24 INT C MACH LEAR, P935, DOI DOI 10.1145/1273496.1273614
   Lichman M, 2013, UCI MACHINE LEARNING
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1805, DOI 10.1109/TKDE.2013.97
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Roweis S., SAM ROWEIS DATA
   Scholkopf B, 1999, ADV KERNEL METHODS S
   Seah CW, 2013, IEEE T CYBERNETICS, V43, P1153, DOI 10.1109/TSMCB.2012.2225102
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Seung H. S., 2000, ADV NEURAL INFORM PR, V13, P556
   Shimodaira H., 2000, J STAT PLAN INFER, V90
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Weiss KR, 2017, 2017 IEEE 18TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI 2017), P338, DOI 10.1109/IRI.2017.43
   Weiss KR, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P207, DOI [10.1109/ICMLA.2016.0042, 10.1109/ICMLA.2016.117]
   Weiss KR, 2016, PROCEEDINGS OF 2016 IEEE 17TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI), P152, DOI 10.1109/IRI.2016.27
   Witten IH, 2011, MOR KAUF D, P3, DOI 10.1016/B978-0-12-374856-0.00001-8
   ZHONG EH, 2010, P 2010 EUR C MACH, V6323, P547
NR 31
TC 0
Z9 0
BN 978-1-5386-1417-4
PY 2017
BP 337
EP 343
DI 10.1109/ICMLA.2017.0-138
UT WOS:000425853000049
ER

PT B
AU Lee, D
AF Lee, Doyup
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI Anomaly Detection in Multivariate Non-stationary Time Series for
   Automatic DBMS Diagnosis
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
DE anomaly detection; non-stationary time series; automatic diagnosis;
   reconstruction error; statistical process control; transfer learning
ID NOVELTY DETECTION
AB Anomaly detection in database management systems (DBMSs) is difficult because of increasing number of statistics (stat) and event metrics in big data system. In this paper, I propose an automatic DBMS diagnosis system that detects anomaly periods with abnormal DB stat metrics and finds causal events in the periods. Reconstruction error from deep autoencoder and statistical process control approach are applied to detect time period with anomalies. Related events are found using time series similarity measures between events and abnormal stat metrics. After training deep autoencoder with DBMS metric data, efficacy of anomaly detection is investigated from other DBMSs containing anomalies. Experiment results show effectiveness of proposed model, especially, batch temporal normalization layer. Proposed model is used for publishing automatic DBMS diagnosis reports in order to determine DBMS configuration and SQL tuning.
CR Andrews J.T.A., 2016, INT J MACHINE LEARNI, V6, P21
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Berndt D. J., 1994, KDD WORKSH
   Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Ioffe S, 2015, INT C MACH LEARN
   Keogh E. J., 2005, KNOWL INF SYST, V7
   Kingma D., 2014, ARXIV14126980
   Malhotra Pankaj, 2015, P PRESS U LOUV
   Montgomery D. C., 2009, STAT QUALITY CONTROL, V7
   Oakland J.S., 2007, STAT PROCESS CONTROL
   Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026
   Shyu M.-L., 2003, NOVEL ANOMALY DETECT
   Slch Maximilian, 2016, ARXIV160207109
   Stonebraker M, 2013, SIGMOD REC, V42, P44
   Szegedy  Christian, 2017, INCEPTION V4 INCEPTI
   Van Aken Dana, 2017, P 2017 ACM INT C MAN
   Vincent P., 2008, P 25 INT C MACH LEAR
   Wei W. W. S, 2006, TIME SERIES ANAL UNI
   Yonghui, 2016, ARXIV160908144
NR 21
TC 0
Z9 0
BN 978-1-5386-1417-4
PY 2017
BP 412
EP 419
DI 10.1109/ICMLA.2017.0-126
UT WOS:000425853000061
ER

PT B
AU Carvalho, T
   de Rezende, ERS
   Alves, MTP
   Balieiro, FKC
   Sovat, RB
AF Carvalho, Tiago
   de Rezende, Edmar R. S.
   Alves, Matheus T. P.
   Balieiro, Fernanda K. C.
   Sovat, Ricardo B.
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI Exposing Computer Generated Images by Eye's Region Classification via
   Transfer Learning of VGG19 CNN
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
AB The advance of computer graphics techniques comes revolutionizing games and movie's industries. Creating very realistic characters totally from computer graphics models is, nowadays, a reality. However, this advance comes with a big price: the realism of images is so big that it is difficult to realize when we are facing a computer generated image or a real photo. In this paper we propose a new approach for highly realistic computer generated images detection by exploring inconsistencies into the region of the eyes. Such inconsistencies are captured exploring the expression power of features extracted via transfer learning approach with VGG19 Deep Neural Network model. Unlike the state-of-the-art approaches, which looks to evaluate the entire image, proposed method focuses in specific regions (eyes) where computer graphics modeling still needs improvements. Experiments conducted over two different datasets containing extremely realistic images achieved an accuracy of 0.80 and an AUC of 0.88.
CR Bishop CM, 2006, PATTERN RECOGNITION
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Faria FA, 2014, PATTERN RECOGN LETT, V39, P52, DOI 10.1016/j.patrec.2013.07.014
   Farid H., 2004, TR2004518
   Ferreira A, 2017, IEEE T INF FOREN SEC, V12, P1860, DOI 10.1109/TIFS.2017.2692722
   Holmes O., 2016, ACM T APPL PERCEPT, V13, P12
   Johnson M., 2007, IHW
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Nishino K, 2004, ACM T GRAPHIC, V23, P704, DOI 10.1145/1015706.1015783
   Saboia P., 2011, ICIP
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Tan D. Q., 2016, Pattern Recognition and Image Analysis, V26, P720, DOI 10.1134/S1054661816040167
   Tokuda E, 2013, J VIS COMMUN IMAGE R, V24, P1276, DOI 10.1016/j.jvcir.2013.08.009
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 16
TC 1
Z9 1
BN 978-1-5386-1417-4
PY 2017
BP 866
EP 870
DI 10.1109/ICMLA.2017.00-47
UT WOS:000425853000140
ER

PT B
AU Elhadji-Ille-Gado, N
   Grall-Maes, E
   Kharouf, M
AF Elhadji-Ille-Gado, Nassara
   Grall-Maes, Edith
   Kharouf, Malika
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI Transfer Learning for Large Scale Data using Subspace Alignment
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
ID ADAPTATION
AB A major assumption in many machine learning algorithms is that the training and testing data must come from the same feature space or have the same distributions. However, in real applications, this strong hypothesis does not hold. In this paper, we introduce a new framework for transfer where the source and target domains are represented by subspaces described by eigenvector matrices. To unify subspace distribution between domains, we propose to use a fast efficient approximative SVD for fast features generation. In order to make a transfer learning between domains, we firstly use a subspace learning approach to develop a domain adaption algorithm where only target knowledge is transferable. Secondly, we use subspace alignment trick to propose a novel transfer domain adaptation method. To evaluate the proposal, we use large scale data sets. Numerical results, based on accuracy and computational time are provided with comparison with state-of-the-art methods.
CR Do VL, 2017, IEEE AERO EL SYS MAG, V32, P28, DOI 10.1109/MAES.2017.160047
   Elhadji Ille Gado N, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P961, DOI [10.1109/ICMLA.2016.125, 10.1109/ICMLA.2016.0173]
   Fernando B, 2015, PATTERN RECOGN LETT, V65, P60, DOI 10.1016/j.patrec.2015.07.009
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Gado NEI, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P359, DOI 10.5220/0006148603590365
   Gheisari M, 2015, NEUROCOMPUTING, V165, P300, DOI 10.1016/j.neucom.2015.03.020
   Guyon I, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P793, DOI 10.1109/IJCNN.2011.6033302
   Hastie T, 2001, ELEMENTS STAT LEARNI, V1.8, P371
   Hou CA, 2016, IEEE T IMAGE PROCESS, V25, P5552, DOI 10.1109/TIP.2016.2609820
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Menon AK, 2011, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1921632.1921639
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shi XX, 2013, IEEE T KNOWL DATA EN, V25, P906, DOI 10.1109/TKDE.2011.252
   Soucy P, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P647, DOI 10.1109/ICDM.2001.989592
   Tao JW, 2017, PATTERN RECOGN, V61, P47, DOI 10.1016/j.patcog.2016.07.006
NR 16
TC 0
Z9 0
BN 978-1-5386-1417-4
PY 2017
BP 1006
EP 1010
DI 10.1109/ICMLA.2017.00-20
UT WOS:000425853000167
ER

PT B
AU Rezende, E
   Ruppert, G
   Carvalho, T
   Ramos, F
   de Geus, P
AF Rezende, Edmar
   Ruppert, Guilherme
   Carvalho, Tiago
   Ramos, Fabio
   de Geus, Paulo
BE Chen, X
   Luo, B
   Luo, F
   Palade, V
   Wani, MA
TI Malicious Software Classification using Transfer Learning of ResNet-50
   Deep Neural Network
SO 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 16th IEEE International Conference on Machine Learning and Applications
   (ICMLA)
CY DEC 18-21, 2017
CL Cancun, MEXICO
AB Malicious software (malware) has been extensively used for illegal activity and new malware variants are discovered at an alarmingly high rate. The ability to group malware variants into families with similar characteristics makes possible to create mitigation strategies that work for a whole class of programs. In this paper, we present a malware family classification approach using a deep neural network based on the ResNet-50 architecture. Malware samples are represented as byteplot grayscale images and a deep neural network is trained freezing the convolutional layers of ResNet-50 pre-trained on the ImageNet dataset and adapting the last layer to malware family classification. The experimental results on a dataset comprising 9,339 samples from 25 different families showed that our approach can effectively be used to classify malware families with an accuracy of 98.62%.
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   CONTI G, 2008, VISUALIZATION COMPUT, V5210, P1
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Kancherla K, 2013, IEEE SYM COMPUT INTE, P40, DOI 10.1109/CICYBS.2013.6597204
   Kolosnjaji Bojan, 2016, AI 2016: Advances in Artificial Intelligence. 29th Australasian Joint Conference. Proceedings: LNAI 9992, P137, DOI 10.1007/978-3-319-50127-7_11
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Nataraj  L., 2011, P 8 INT S VIS CYB SE, P4
   Russakovsky O., 2014, ARXIV14090575
   Russakovsky Olga, 2015, INT J COMPUT VISION, V115, P3, DOI [DOI 10.1007/S11263-015-0816-Y, 10.1007/s11263-015-0816-y]
   Saxe J, 2015, 2015 10th International Conference on Malicious and Unwanted Software (MALWARE), P11, DOI 10.1109/MALWARE.2015.7413680
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 12
TC 0
Z9 0
BN 978-1-5386-1417-4
PY 2017
BP 1011
EP 1014
DI 10.1109/ICMLA.2017.00-19
UT WOS:000425853000168
ER

PT S
AU Le, N
   Odobez, JM
AF Le, Nam
   Odobez, Jean-Marc
GP IEEE
TI Improving speaker turn embedding by crossmodal transfer learning from
   face embedding
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB Learning speaker turn embeddings has shown considerable improvement in situations where conventional speaker modeling approaches fail. However, this improvement is relatively limited when compared to the gain observed in face embedding learning, which has proven very successful for face verification and clustering tasks. Assuming that face and voices from the same identities share some latent properties (like age, gender, ethnicity), we propose two transfer learning approaches to leverage the knowledge from the face domain learned from thousands of identities for tasks in the speaker domain. These approaches, namely target embedding transfer and clustering structure transfer, utilize the structure of the source face embedding space at different granularities to regularize the target speaker turn embedding space as optimizing terms. Our methods are evaluated on two public broadcast corpora and yield promising advances over competitive baselines in verification and audio clustering tasks, especially when dealing with short speaker utterances. The analysis gives insight into characteristics of the embedding spaces and shows their potential applications.
CR Barras C., 2006, IEEE T AUDIO SPEECH
   Bendris M., 2014, ICASSP
   Bost X., 2014, SPOK LANG TECHN WORK
   Bredin H., 2016, MULTIMEDIA
   Bredin H., 2017, ICASSP
   Chen  S., 1998, P DARPA BROADC NEWS
   Clement P., 2011, ICASSP
   Dai D., 2015, CVPR
   Dai D., 2016, ARXIV160200955
   Dubout C., 2013, BMVC
   Gay P., 2014, ICASSP
   Giraudel A., 2012, LREC
   Gravier G., 2012, LREC
   Guillaumin M., 2009, ICCV
   He K., 2016, CVPR
   Hinton  G., 2015, ARXIV150302531
   Hu D., 2016, ACM MULTIMEDIA
   Hu Y., 2015, ACM MULTIMEDIA
   Jousse Vincent, 2009, ICASSP
   Le N., 2016, ICPR
   Li A., 2011, PATTERN RECOGNITION
   Liong V. E., 2016, IEEE T MULTIMEDIA
   Long M., 2010, ICDM
   Ma C., 2007, ICASSP
   Moon S., 2015, MULT MACH LEARN WORK
   Parkhi O.M., 2015, BMVC
   Poignant J., 2014, IEEE ACM T AUDIO SPE
   Ren J., 2016, AAAI
   Sargent G., 2016, MEDIAEVAL
   Sarkar A. K., 2012, INTERSPEECH
   Schroff F., 2015, CVPR
   Tapaswi M., 2014, IND C COMP VIS GRAPH
   Tieleman  T., 2012, COURSERA NEURAL NETW, V4
   Yi D., 2014, ARXIV14117923
   Zhuang F., 2011, STAT ANAL DATA MININ
NR 35
TC 0
Z9 0
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 428
EP 437
DI 10.1109/ICCVW.2017.58
UT WOS:000425239600051
ER

PT S
AU Melekhov, I
   Ylioinas, J
   Kannala, J
   Rahtu, E
AF Melekhov, Iaroslav
   Ylioinas, Juha
   Kannala, Juho
   Rahtu, Esa
GP IEEE
TI Image-based Localization using Hourglass Networks
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
ID FEATURES
AB In this paper, we propose an encoder-decoder convolutional neural network (CNN) architecture for estimating camera pose (orientation and location) from a single RGB-image. The architecture has a hourglass shape consisting of a chain of convolution and up-convolution layers followed by a regression part. The up-convolution layers are introduced to preserve the fine-grained information of the input image. Following the common practice, we train our model in end-to-end manner utilizing transfer learning from large scale classification data. The experiments demonstrate the performance of the approach on data exhibiting different lighting conditions, reflections, and motion blur. The results indicate a clear improvement over the previous state-of-the-art even when compared to methods that utilize sequence of test frames instead of a single frame.
OI Rahtu, Esa/0000-0001-8767-0864
CR Babenko A., 2014, P ECCV
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Canziani A., 2016, IEEE INT S CIRC SYST
   Clark R., 2017, P CVPR
   Collobert  R., 2011, P BIGLEARN NIPS WORK
   Glocker B., 2013, P ISMAR
   Glorot  X., 2010, P AISTATS
   Gordo A., 2016, P ECCV
   He  K., 2016, P CVPR
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hong S., 2015, P NIPS
   Ioffe Sergey, 2015, P ICML
   Izadi S., 2011, P 24 ANN ACM S US IN
   Kendall A., 2016, P ICRA
   Kendall A., 2015, P ICCV
   Kingma D. P., P ICLR
   Krizhevsky A., 2012, ADV NIPS
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mao X., 2016, ADV NIPS
   Newell Alejandro, 2016, P ECCV
   Noh H., 2015, P ICCV
   Pinheiro P. O., 2016, P ECCV
   Rublee E., 2011, P ICCV
   Sattler T., 2016, IEEE TPAMI
   Shotton J., 2013, P CVPR
   Szegedy C., 2015, P CVPR
   Tome D., 2017, CORR
   Ummenhofer B., 2017, P CVPR
   Valentin J., 2015, P CVPR
   Walch F., 2017, P ICCV
   Xi X., 2017, CORR
NR 31
TC 1
Z9 1
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 870
EP 877
DI 10.1109/ICCVW.2017.107
UT WOS:000425239600099
ER

PT S
AU Zia, S
   Yuksel, B
   Yuret, D
   Yemez, Y
AF Zia, Saman
   Yuksel, Buket
   Yuret, Deniz
   Yemez, Yucel
GP IEEE
TI RGB-D Object Recognition Using Deep Convolutional Neural Networks
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB We address the problem of object recognition from RGB-D images using deep convolutional neural networks (CNNs). We advocate the use of 3D CNNs to fully exploit the 3D spatial information in depth images as well as the use of pretrained 2D CNNs to learn features from RGB-D images. There exists currently no large scale dataset available comprising depth information as compared to those for RGB data. Hence transfer learning from 2D source data is key to be able to train deep 3D CNNs. To this end, we propose a hybrid 2D/3D convolutional neural network that can be initialized with pretrained 2D CNNs and can then be trained over a relatively small RGB-D dataset. We conduct experiments on the Washington dataset involving RGB-D images of small household objects. Our experiments show that the features learnt from this hybrid structure, when fused with the features learnt from depth-only and RGB-only architectures, outperform the state of the art on RGB-D category recognition.
CR Bezanson J, 2017, SIAM REV, V59, P65, DOI 10.1137/141000671
   Blum M, 2012, IEEE INT CONF ROBOT, P1298, DOI 10.1109/ICRA.2012.6225188
   Bo L., 2011, NIPS, V1, P6
   Bo Liefeng, 2013, EXPT ROBOTICS, P387, DOI DOI 10.1007/978-3-319-00065-7
   Cheng YH, 2015, COMPUT VIS IMAGE UND, V139, P149, DOI 10.1016/j.cviu.2015.05.007
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Jhuo I.-H., 2014, P ACCV, P276
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   LAI K, 2011, ROB AUT ICRA 2011 IE, P1817
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li X, 2017, PATTERN RECOGN, V61, P433, DOI 10.1016/j.patcog.2016.08.016
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Payan A., 2015, ARXIV150202506
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Socher R., 2012, NIPS, V3, P8
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Torrey L., 2009, HDB RES MACHINE LEAR, V1, P242, DOI DOI 10.1016/J.JBI.2011.04.009
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Yosinski Jason, 2014, ADV NEURAL INFORM PR
   Yuret D, 2016, MACH LEARN SYST WORK
NR 29
TC 2
Z9 2
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 887
EP 894
DI 10.1109/ICCVW.2017.109
UT WOS:000425239600101
ER

PT S
AU Wang, SS
   Zhang, L
   Zuo, WM
AF Wang, Shanshan
   Zhang, Lei
   Zuo, Wangmeng
GP IEEE
TI Class-specific Reconstruction Transfer Learning via Sparse Low-rank
   Constraint
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
ID DOMAIN ADAPTATION; REPRESENTATION
AB Subspace learning and reconstruction have been widely explored in recent transfer learning work and generally a specially designed projection and reconstruction transfer matrix are wanted. However, existing subspace reconstruction based algorithms neglect the class prior such that the learned transfer function is biased, especially when data scarcity of some class is encountered. Different from those previous methods, in this paper, we propose a novel reconstruction-based transfer learning method called Class-specific Reconstruction Transfer Learning (CRTL), which optimizes a well-designed transfer loss function without class bias. Using a class-specific reconstruction matrix to align the source domain with the target domain which provides help for classification with class prior modeling. Furthermore, to keep the intrinsic relationship between data and labels after feature augmentation, a projected Hilbert-Schmidt Independence Criterion (pHSIC), that measures the dependency between two sets, is first proposed by mapping the data from original space to RKHS in transfer learning. In addition, combining low-rank and sparse constraints on the class-specific reconstruction coefficient matrix, the global and local data structures can be effectively preserved. Extensive experiments demonstrate that the proposed method outperforms conventional representation based domain adaptation methods.
CR [Anonymous], 2011, COMPUTER
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Ding Z., 2015, IJCAI
   Donahue J., 2013, COMPUTER SCI, V50, P815
   Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870
   Elhamifar Ehsan, 2012, PATTERN ANAL MACHINE, V35, P2765
   FENG JS, 2014, CVPR, P3818
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ghosn J, 2003, IEEE T NEURAL NETWOR, V14, P748, DOI 10.1109/TNN.2003.810608
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Gretton A., 2008, NIPS, P513
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Hsu TMH, 2015, IEEE I CONF COMP VIS, P4121, DOI 10.1109/ICCV.2015.469
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Kan S. M., 2014, IJCV
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Li Y, 2014, IEEE T INF FOREN SEC, V9, P2051, DOI 10.1109/TIFS.2014.2361936
   Liu G, 2010, P INT C MACH LEARN, P663
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Mesnil G., 2012, WORKSH UNS TRANSF LE, V7, P1
   Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405
   Saenko Kate, 2010, ADAPTING VISUAL CATE
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Sun B., 2016, ARXIV160701719
   Sun B., 2016, AAAI, V6, P8
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Xue Y, 2007, J MACH LEARN RES, V8, P35
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang R. J., 2007, ACM MM
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Zhang H., 2015, IEEE INT C WORKSH AU, V1, P1
   Zhang L, 2016, IEEE T IMAGE PROCESS, V25, P1177, DOI 10.1109/TIP.2016.2516952
   Zhang L, 2015, IEEE T INSTRUM MEAS, V64, P1790, DOI 10.1109/TIM.2014.2367775
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 37
TC 0
Z9 0
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 949
EP 957
DI 10.1109/ICCVW.2017.116
UT WOS:000425239600108
ER

PT S
AU Zhao, CR
   Wang, XK
   Chen, YP
   Gao, C
   Zuo, WM
   Miao, DQ
AF Zhao, Cairong
   Wang, Xuekuan
   Chen, Yipeng
   Gao, Can
   Zuo, Wangmeng
   Miao, Duoqian
GP IEEE
TI Consistent Iterative Multi-view Transfer Learning for Person
   Re-identification
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
ID RECOGNITION
AB Inconsistent data distributions among multiple views is one of the most crucial aspects of person re-identification. To solve the problem, this paper presents a novel strategy called consistent iterative multi-view transfer learning model. The proposed model captures seven groups of multi-view visual words (MvVW) through an unsupervised cluster method (K-means) from human body. For each group of MvVW, a multi-view discriminative common subspace can be obtained by the fusion of transfer learning and discriminative analysis. In these common subspaces, the original samples can be reconstructed based on MvVW under the low-rank and sparse constraints. Then, we solve it via the inexact augmented Lagrange multiplier method. The proposed strategy is performed on three different challenging person re-identification databases (i.e., VIPeR, CUHK01 and PRID450S), which shows that our model outperforms several state-of-the-art models with improving of 6.36%, 7.7% and 4.0% respectively.
CR Avraham T, 2012, LECT NOTES COMPUT SC, V7583, P381, DOI 10.1007/978-3-642-33863-2_38
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Gray D., 2007, P IEEE INT WORKSH PE, V3
   Guo YF, 2003, PATTERN RECOGN LETT, V24, P147, DOI 10.1016/S0167-8655(02)00207-6
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Li S., 2015, LEARNING ROBUST DISC
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu Guangcan, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P171, DOI 10.1109/TPAMI.2012.88
   Ma L., 2016, ARXIV160502464
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Poongothai E., 2016, INDIAN J SCI TECHNOL, V9, DOI DOI 10.17485/ijst/2016/v9i29/93823
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Varior R. R., 2016, LEARNING INVARIANT C
   Wang J., 2016, IEEE T CIRCUITS SYST
   Wang X., 2015, CROSS SCENARIO TRANS
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Yang Y., 2016, 30 AAAI C ART INT
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zhang L., 2016, ARXIV 1603 02139
   ZHAO R, 2013, P IEEE INT C COMP VI, P2528, DOI DOI 10.1109/ICCV.2013.314
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
NR 31
TC 0
Z9 0
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 1087
EP 1094
DI 10.1109/ICCVW.2017.132
UT WOS:000425239601015
ER

PT S
AU Abebe, G
   Cavallaro, A
AF Abebe, Girmaw
   Cavallaro, Andrea
GP IEEE
TI Inertial-Vision: cross-domain knowledge transfer for wearable sensors
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
ID ACTIVITY RECOGNITION
AB Multi-modal ego-centric data from inertial measurement units (IMU) and first-person videos (FPV) can be effectively fused to recognise proprioceptive activities. Existing IMU-based approaches mostly employ cascades of handcrafted triaxial motion features or deep frameworks trained on limited data. FPV approaches generally encode scene dynamics with motion and pooled appearance features. In this paper, we propose a multi-modal ego-centric proprioceptive activity recognition that uses a convolutional neural network (CNN) followed by a long short-term memory (LSTM) network, transfer learning and a merit-based fusion of IMU and/or FPV streams. The CNN encodes short-term temporal dynamics of the ego-motion and the LSTM exploits the long-term temporal dependency among activities. The merit of a stream is evaluated with a sparsity measure of its initial classification output. We validate the proposed framework on multiple visual and inertial datasets.
CR Abebe G., 2017, P INT C COMP VIS WOR
   Abebe G, 2017, NEUROCOMPUTING, V267, P362, DOI 10.1016/j.neucom.2017.06.015
   Abebe G, 2016, COMPUT VIS IMAGE UND, V149, P229, DOI 10.1016/j.cviu.2015.10.015
   Alsheikh M. A., 2016, WORKSH 30 AAAI C ART
   Anguita D., 2013, EUR S ART NEUR NETW, P1971
   Catal C, 2015, APPL SOFT COMPUT, V37, P1018, DOI 10.1016/j.asoc.2015.01.025
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Hammerla N. Y., 2016, ARXIV160408880
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kwapisz J. R., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [10.1145/1964897.1964918, DOI 10.1145/1964897.1964918]
   Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001
   Lockhart J.W., 2011, P 5 INT WORKSH KNOWL, P25
   Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209
   MA SG, 2016, PROC CVPR IEEE, P1942, DOI DOI 10.1109/CVPR.2016.214
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ordonez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Poleg Y, 2016, P IEEE WINT C APPL C, P1
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P56, DOI 10.1109/JBHI.2016.2633287
   Ravi D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085
   Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691
   Singh S, 2016, PROC CVPR IEEE, P2620, DOI 10.1109/CVPR.2016.287
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Zhan K, 2015, PERVASIVE MOB COMPUT, V16, P251, DOI 10.1016/j.pmcj.2014.11.004
NR 32
TC 1
Z9 1
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 1392
EP 1400
DI 10.1109/ICCVW.2017.165
UT WOS:000425239601049
ER

PT S
AU Xia, Y
   Huang, D
   Wang, YH
AF Xia, Yu
   Huang, Di
   Wang, Yunhong
GP IEEE
TI Detecting Smiles of Young Children via Deep Transfer Learning
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB Smile detection is an interesting topic in computer vision and has received increasing attention in recent years. However, the challenge caused by age variations has not been sufficiently focused on before. In this paper, we first highlight the impact of the discrepancy between infants and adults in a quantitative way on a newly collected database. We then formulate this issue as an unsupervised domain adaptation problem and present the solution of deep transfer learning, which applies the state of the art transfer learning methods, namely Deep Adaptation Networks (DAN) and Joint Adaptation Network (JAN), to two baseline deep models, i.e. AlexNet and ResNet. Thanks to DAN and JAN, the knowledge learned by deep models from adults can be transferred to infants, where very limited labeled data are available for training. Cross-dataset experiments are conducted and the results evidently demonstrate the effectiveness of the proposed approach to smile detection across such an age gap.
CR Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398
   Chen JX, 2012, IEEE IMAGE PROC, P2621, DOI 10.1109/ICIP.2012.6467436
   Cui Z., 2014, P AS C COMP VIS, P166
   Desai S, 2009, AM J ORTHOD DENTOFAC, V136, DOI 10.1016/j.ajodo.2009.04.013
   Ding Z., 2015, INT JOINT C ART INT
   Escalera S., 2016, IEEE C COMP VIS PATT, P1
   FARFADE SS, 2015, ACM INT C MULT RETR, P643, DOI DOI 10.1145/2671188.2749408
   Florea C., 2014, EUR C COMP VIS WORKS, P778
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Gao Y, 2016, NEUROCOMPUTING, V174, P1077, DOI 10.1016/j.neucom.2015.10.022
   Glauner P.O., 2015, ARXIV150806535
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Jain V., 2013, WSEAS INT C SIGN PRO
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long M., 2016, ARXIV160506636
   Long M., 2016, ADV NEURAL INFORM PR, P136
   Long M., 2015, INT C MACH LEARN, P97
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ramaiah N. P., 2015, IEEE INT C SIGN PROC, P1
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Sejdinovic D, 2013, ANN STAT, V41, P2263, DOI 10.1214/13-AOS1140
   Shan CF, 2012, IEEE T IMAGE PROCESS, V21, P431, DOI 10.1109/TIP.2011.2161587
   Shao M, 2012, IEEE DATA MINING, P1104, DOI 10.1109/ICDM.2012.102
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Smolka B, 2015, PROCEDIA COMPUT SCI, V51, P1555, DOI 10.1016/j.procs.2015.05.350
   Su Y, 2010, INT CONF ACOUST SPEE, P1270, DOI 10.1109/ICASSP.2010.5495414
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wu Shuzhe, 2016, NEUROCOMPUTING
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhang K., 2016, P IEEE C COMP VIS PA, P34
   Zhang KH, 2015, Proceedings 3rd IAPR Asian Conference on Pattern Recognition ACPR 2015, P534, DOI 10.1109/ACPR.2015.7486560
NR 35
TC 3
Z9 3
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 1673
EP 1681
DI 10.1109/ICCVW.2017.196
UT WOS:000425239601080
ER

PT S
AU Choe, J
   Park, S
   Kim, K
   Park, JH
   Kim, D
   Shim, H
AF Choe, Junsuk
   Park, Song
   Kim, Kyungmin
   Park, Joo Hyun
   Kim, Dongseob
   Shim, Hyunjung
GP IEEE
TI Face Generation for Low-shot Learning using Generative Adversarial
   Networks
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB Recently, low-shot learning has been proposed for handling the lack of training data in machine learning. Despite of the importance of this issue, relatively less efforts have been made to study this problem. In this paper, we aim to increase the size of training dataset in various ways to improve the accuracy and robustness of face recognition. In detail, we adapt a generator from the Generative Adversarial Network (GAN) to increase the size of training dataset, which includes a base set, a widely available dataset, and a novel set, a given limited dataset, while adopting transfer learning as a backend. Based on extensive experimental study, we conduct the analysis on various data augmentation methods, observing how each affects the identification accuracy. Finally, we conclude that the proposed algorithm for generating faces is effective in improving the identification accuracy and coverage at the precision of 99% using both the base and novel set.
CR Arjovsky M., 2017, ARXIV170107875
   Berthelot  David, 2017, ARXIV170310717
   Bertinetto  L., 2016, ADV NEURAL INFORM PR, P523
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486
   Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Guo Yandong, 2017, ARXIV170705574
   Guo Y, 2016, INT J AEROSPACE ENG, DOI 10.1155/2016/2942686
   Hariharan B., 2016, ARXIV160602819
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kingma D.P., 2013, ARXIV13126114
   Koch  G., 2015, ICML DEEP LEARN WORK, V2
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Larsen A.B.L., 2015, ARXIV151209300
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Movshovitz-Attias Y, 2015, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2015.7298778
   Park Dennis, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P58, DOI 10.1109/CVPRW.2015.7301337
   Radford A., 2015, ARXIV151106434
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K., 2014, ARXIV14091556
   Thrun S, 1996, ADV NEUR IN, V8, P640
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630
   Wang Y., 2016, EUR C COMP VIS ECCV
   Zhu XX, 2016, INT J COMPUT VISION, V119, P76, DOI 10.1007/s11263-015-0812-2
NR 25
TC 1
Z9 1
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 1940
EP 1948
DI 10.1109/ICCVW.2017.229
UT WOS:000425239601113
ER

PT S
AU Aygun, M
   Aytar, Y
   Ekenel, HK
AF Aygun, Mehmet
   Aytar, Yusuf
   Ekenel, Hazim Kemal
GP IEEE
TI Exploiting Convolution Filter Patterns for Transfer Learning
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB In this paper, we introduce a new regularization technique for transfer learning. The aim of the proposed approach is to capture statistical relationships among convolution filters learned from a well-trained network and transfer this knowledge to another network. Since convolution filters of the prevalent deep Convolutional Neural Network (CNN) models share a number of similar patterns, in order to speed up the learning procedure, we capture such correlations by Gaussian Mixture Models (GMMs) and transfer them using a regularization term. We have conducted extensive experiments on the CIFAR10, Places2, and CM-Places datasets to assess generalizability, task transferability, and cross-model transferability of the proposed approach, respectively. The experimental results show that the feature representations have efficiently been learned and transferred through the proposed statistical regularization scheme. Moreover, our method is an architecture independent approach, which is applicable for a variety of CNN architectures.
CR Aytar Y, 2015, COMPUT VIS IMAGE UND, V138, P114, DOI 10.1016/j.cviu.2015.04.004
   Aytar Yusuf, 2016, ADV NEURAL INFORM PR, P892
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Castrejon L, 2016, PROC CVPR IEEE, P2940, DOI 10.1109/CVPR.2016.321
   Chatfield K., 2014, BRIT MACH VIS C
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Denil M., 2013, ADV NEURAL INFORM PR, V26, P2148
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gao T, 2012, LECT NOTES COMPUT SC, V7576, P354, DOI 10.1007/978-3-642-33715-4_26
   GHIFARY M, 2016, EUR C COMP VIS, V9908, P597, DOI DOI 10.1007/978-3-319-46493-0_36
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Hinton  G., 2015, ARXIV150302531
   Jia Y., 2014, ARXIV14085093
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lempitsky Victor, 2014, ARXIV14097495
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Pinheiro Pedro O., 2015, ADV NEURAL INFORM PR, V2, P1990
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Romero A., 2014, ARXIV14126550
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans Tim, 2016, ADV NEURAL INFORM PR, P901
   Sener O., 2016, ARXIV160203534
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tzeng E., 2017, ARXIV170205464
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Vedaldi A., 2010, C P ACM INT C MULTIM, P1469, DOI DOI 10.1145/1873951.1874249
   Zhou B., 2016, ARXIV161002055
NR 32
TC 0
Z9 0
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 2674
EP 2680
DI 10.1109/ICCVW.2017.309
UT WOS:000425239602087
ER

PT S
AU Alonso, I
   Cambra, A
   Munoz, A
   Treibitz, T
   Murillo, AC
AF Alonso, Inigo
   Cambra, Ana
   Munoz, Adolfo
   Treibitz, Tali
   Murillo, Ana C.
GP IEEE
TI Coral-Segmentation: Training Dense Labeling Models with Sparse Ground
   Truth
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW
   2017)
SE IEEE International Conference on Computer Vision Workshops
CT 16th IEEE International Conference on Computer Vision (ICCV)
CY OCT 22-29, 2017
CL Venice, ITALY
AB Biological datasets, such as our case of study, coral segmentation, often present scarce and sparse annotated image labels. Transfer learning techniques allow us to adapt existing deep learning models to new domains, even with small amounts of training data. Therefore, one of the main challenges to train dense segmentation models is to obtain the required dense labeled training data. This work presents a novel pipeline to address this pitfall and demonstrates the advantages of applying it to coral imagery segmentation. We fine tune state-of-the-art encoder-decoder CNN models for semantic segmentation thanks to a new proposed augmented labeling strategy. Our experiments run on a recent coral dataset [4], proving that this augmented ground truth allows us to effectively learn coral segmentation, as well as provide a relevant score of the segmentation quality based on it. Our approach provides a segmentation of comparable or better quality than the baseline presented with the dataset and a more flexible end-to-end pipeline.
OI Munoz Orbananos, Adolfo/0000-0002-8160-7159
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Badrinarayanan V., 2015, ARXIV151100561
   Beijbom O., 2016, SCI REPORTS, V6
   Beijbom O, 2012, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2012.6247798
   Blanchet J.-N., PEERJ PREPRINTS, V4
   Cesar HSJ, 2000, COLLECTED ESSAYS EC, P14
   Chen PY, 2015, GLOBAL ENVIRON CHANG, V30, P12, DOI 10.1016/j.gloenvcha.2014.10.011
   Gupta A., 2016, IEEE C COMP VIS PATT
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Kolesnikov A., 2016, EUR C COMP VIS ECCV
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172
   Mostajabi M., 2015, IEEE C COMP VIS PATT
   Ros G., 2016, IEEE C COMP VIS PATT
   Sun B., 2016, ABS160701719 CORR
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Venkitasubramanian AN, 2016, PATTERN RECOGN LETT, V81, P63, DOI 10.1016/j.patrec.2016.01.025
   Vernaza P., 2017, IEEE C COMP VIS PATT
   Yong SP, 2012, PATTERN RECOGN, V45, P3439, DOI 10.1016/j.patcog.2012.02.036
   Zhou B., 2016, ABS160805442 CORR
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
NR 22
TC 3
Z9 3
SN 2473-9936
BN 978-1-5386-1034-3
PY 2017
BP 2874
EP 2882
DI 10.1109/ICCVW.2017.339
UT WOS:000425239602111
ER

PT S
AU Pop, DO
   Rogozan, A
   Nashashibi, F
   Bensrhair, A
AF Pop, Danut Ovidiu
   Rogozan, Alexandrina
   Nashashibi, Fawzi
   Bensrhair, Abdelaziz
GP IEEE
TI Incremental Cross-Modality Deep Learning for Pedestrian Recognition
SO 2017 28TH IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV 2017)
SE IEEE Intelligent Vehicles Symposium
CT 28th IEEE Intelligent Vehicles Symposium (IV)
CY JUN 11-14, 2017
CL Redondo Beach, CA
AB In spite of the large number of existing methods, pedestrian detection remains an open challenge. In recent years, deep learning classification methods combined with multi-modality images within different fusion schemes have achieved the best performance. It was proven that the late-fusion scheme outperforms both direct and intermediate integration of modalities for pedestrian recognition. Hence, in this paper, we focus on improving the late-fusion scheme for pedestrian classification on the Daimler stereo vision data set. Each image modality, Intensity, Depth and Flow, is classified by an independent Convolutional Neural Network (CNN), the outputs of which are then fused by a Multi-layer Perceptron (MLP) before the recognition decision. We propose different methods based on Cross-Modality deep learning of CNNs: (1) a correlated model where a unique CNN is trained with Intensity, Depth and Flow images for each frame, (2) an incremental model where a CNN is trained with the first modality images frames, then a second CNN, initialized by transfer learning on the first one is trained on the second modality images frames, and finally a third CNN initialized on the second one, is trained on the last modality images frames. The experiments show that the incremental cross-modality deep learning of CNNs improves classification performances not only for each independent modality classifier, but also for the multi-modality classifier based on late-fusion. Different learning algorithms are also investigated.
CR Angelova A, 2015, IEEE INT CONF ROBOT, P704, DOI 10.1109/ICRA.2015.7139256
   Benenson R., 2015, 10 YEARS PEDESTRIAN, P613
   Bunel R, 2016, IEEE INT CONF ROBOT, P2326, DOI 10.1109/ICRA.2016.7487382
   Cheng XS, 2015, P ANN HICSS, P354, DOI 10.1109/HICSS.2015.50
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Dollar P, 2009, P BRIT MACH VIS C, V91, P1, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]
   Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Eisenbach M, 2016, IEEE IJCNN, P267, DOI 10.1109/IJCNN.2016.7727208
   Enzweiler M, 2011, IEEE T IMAGE PROCESS, V20, P2967, DOI 10.1109/TIP.2011.2142006
   Enzweiler M, 2010, PROC CVPR IEEE, P990, DOI 10.1109/CVPR.2010.5540111
   Fukui H, 2015, IEEE INT VEH SYM, P223, DOI 10.1109/IVS.2015.7225690
   Hosang Jan, 2015, IEEE C COMP VIS PATT
   Karaoguz C, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1242, DOI 10.1109/ITSC.2016.7795716
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Pop Danut Ovidiu, 2017, P EUR S ART NEUR NET
   Sermanet Pierre, 2013, IEEE C COMP VIS PATT
   Vazquez D, 2014, IEEE T PATTERN ANAL, V36, P797, DOI 10.1109/TPAMI.2013.163
   Vedaldi A., 2009, P INT C COMP VIS
   Wagner J., 2016, P 24 EUR S ART NEUR, P509
NR 20
TC 0
Z9 0
SN 1931-0587
BN 978-1-5090-4804-5
PY 2017
BP 523
EP 528
UT WOS:000425212700082
ER

PT S
AU Lin, YL
   Li, L
   Dai, XY
   Zheng, NN
   Wang, FY
AF Lin, Yi-Lun
   Li, Li
   Dai, Xing-Yuan
   Zheng, Nan-Ning
   Wang, Fei-Yue
GP IEEE
TI Master General Parking Skill via Deep Learning
SO 2017 28TH IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV 2017)
SE IEEE Intelligent Vehicles Symposium
CT 28th IEEE Intelligent Vehicles Symposium (IV)
CY JUN 11-14, 2017
CL Redondo Beach, CA
ID PATH GENERATION
AB Parking is one basic function of autonomous vehicles. However, parking still remains difficult to be implemented, since it requires to generate a relatively long-term series of actions to reach a certain objective under complicated constraints. One recently proposed method used deep neural networks(DNN) to learn the relationship between the actual parking trajectories and the corresponding steering actions, so as to find the best parking trajectory via direct recalling. However, this method can only handle a special vehicle whose dynamic parameters are well known. In this paper, we use transfer learning technique to further extend this direct trajectory planning method and master general parking skills. We aim to mimic how human drivers make parking by using a specially designed deep neural network. The first few layers of this DNN contain the general parking trajectory planning knowledge for all kinds of vehicles; while the last few layers of this DNN can be quickly tuned to adapt various kinds of vehicles. Numerical tests show that, combining transfer learning and direct trajectory planning solution, our new approach enables automated vehicles to convey the knowledge of trajectory planning from one vehicle to another with a few try-and-tests.
CR DOYLE JC, 1989, IEEE T AUTOMAT CONTR, V34, P831, DOI 10.1109/9.29425
   Du XX, 2015, IEEE T INTELL TRANSP, V16, P1225, DOI 10.1109/TITS.2014.2354423
   Gomez-Bravo F, 2008, ROBOT AUTON SYST, V56, P360, DOI 10.1016/j.robot.2007.08.004
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/18304
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li L, 2006, IEEE T INTELL TRANSP, V7, P1, DOI 10.1109/TITS.2005.858624
   Li L, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P1770
   [李力 Li Li], 2017, [自动化学报, Acta Automatica Sinica], V43, P1
   Li Li, 2007, ADV MOTION CONTROL S
   Mitchell T. M., 1997, MACH LEARN, V45, P870
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rill G., 2011, ROAD VEHICLE DYNAMIC
   Vorobieva H, 2015, IEEE T INTELL TRANSP, V16, P396, DOI 10.1109/TITS.2014.2335054
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 16
TC 1
Z9 1
SN 1931-0587
BN 978-1-5090-4804-5
PY 2017
BP 941
EP 946
UT WOS:000425212700147
ER

PT S
AU de Rezende, ERS
   Ruppert, GCS
   Carvalho, T
AF de Rezende, Edmar R. S.
   Ruppert, Guilherme C. S.
   Carvalho, Tiago
GP IEEE
TI Detecting Computer Generated Images with Deep Convolutional Neural
   Networks
SO 2017 30TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES
   (SIBGRAPI)
SE SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing
CT 30th Conference on Graphics, Patterns and Images (SIBGRAPI)
CY OCT 17-20, 2017
CL Niteroi, BRAZIL
ID DISCRIMINATION; FACES
AB Computer graphics techniques for image generation are living an era where, day after day, the quality of produced content is impressing even the more skeptical viewer. Although it is a great advance for industries like games and movies, it can become a real problem when the application of such techniques is applied for the production of fake images. In this paper we propose a new approach for computer generated images detection using a deep convolutional neural network model based on ResNet-50 and transfer learning concepts. Unlike the state-of-the-art approaches, the proposed method is able to classify images between computer generated or photo generated directly from the raw image data with no need for any pre-processing or hand-crafted feature extraction whatsoever. Experiments on a public dataset comprising 9700 images show an accuracy higher than 94%, which is comparable to the literature reported results, without the drawback of laborious and manual step of specialized features extraction and selection.
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bishop CM, 2006, PATTERN RECOGNITION
   Candes E., 2000, CURVELETS SURPRISING
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Do MN, 2002, IEEE IMAGE PROC, P357
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Dang-Nguyen DT, 2012, IEEE INT WORKS INFOR, P252, DOI 10.1109/WIFS.2012.6412658
   Dang-Nguyen DT, 2012, EUR SIGNAL PR CONF, P1234
   Farid H., 2004, TR2004518
   Farid H, 2012, DIGIT INVEST, V8, P226, DOI 10.1016/j.diin.2011.06.003
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Gonzalez RC, 2007, DIGITAL IMAGE PROCES
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Holmes O., 2016, ACM T APPL PERCEPT, V13, P12
   Ioffe S., 2015, ARXIV150203167
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Kutyniok G, 2011, J APPROX THEORY, V163, P1564, DOI 10.1016/j.jat.2011.06.005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LIEBOVITCH LS, 1989, PHYS LETT A, V141, P386, DOI 10.1016/0375-9601(89)90854-2
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Ng TT, 2009, IEEE SIGNAL PROC MAG, V26, P49, DOI 10.1109/MSP.2008.931077
   Ojala T., 2001, INT C ADV PATT REC, P399, DOI DOI 10.1007/3-540-44732-6_
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schwartz W., 2011, 18 IEEE INT C IM PRO, P1053
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176.ARXIV:1312.6229
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan D. Q., 2016, Pattern Recognition and Image Analysis, V26, P720, DOI 10.1134/S1054661816040167
   Tokuda E, 2013, J VIS COMMUN IMAGE R, V24, P1276, DOI 10.1016/j.jvcir.2013.08.009
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wenxiang Li, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P2316, DOI 10.1109/FSKD.2010.5569821
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 38
TC 3
Z9 3
SN 1530-1834
BN 978-1-5386-2219-3
PY 2017
BP 71
EP 78
DI 10.1109/SIBGRAPI.2017.16
UT WOS:000425243500010
ER

PT S
AU Ge, WF
   Yu, YZ
AF Ge, Weifeng
   Yu, Yizhou
GP IEEE
TI Borrowing Treasures from the Wealthy: Deep Transfer Learning through
   Selective Joint Fine-Tuning
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB Deep neural networks require a large amount of labeled training data during supervised learning. However, collecting and labeling so much data might be infeasible in many cases. In this paper, we introduce a deep transfer learning scheme, called selective joint fine-tuning, for improving the performance of deep learning tasks with insufficient training data. In this scheme, a target learning task with insufficient training data is carried out simultaneously with another source learning task with abundant training data. However, the source learning task does not use all existing training data. Our core idea is to identify and use a subset of training images from the original source learning task whose low-level characteristics are similar to those from the target learning task, and jointly fine-tune shared convolutional layers for both tasks. Specifically, we compute descriptors from linear or nonlinear filter bank responses on training images from both tasks, and use such descriptors to search for a desired subset of training samples for the source learning task.
   Experiments demonstrate that our deep transfer learning scheme achieves state-of-the-art performance on multiple visual classification tasks with insufficient training data for deep learning. Such tasks include Caltech 256, MIT Indoor 67, and fine-grained classification problems (Oxford Flowers 102 and Stanford Dogs 120). In comparison to fine-tuning without a source domain, the proposed method can improve the classification accuracy by 2% - 10% using a single model. Codes and models are available at https://github.com/ZYYSzj/Selective-Joint-Fine-tuning.
CR Argyriou A., 2007, NEURAL INFORM PROCES, V19, P41
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Caruana R, 1998, LEARNING TO LEARN, P95
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Donggeun Yoo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P71, DOI 10.1109/CVPRW.2015.7301274
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Gavves E, 2015, INT J COMPUT VISION, V111, P191, DOI 10.1007/s11263-014-0741-5
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Griffin G., 2007, CALTECH 256 OBJECT C
   He K, 2015, COMPUT VIS PATTERN R, V5, P1
   He K., 2016, PREPRINT ARXIV 1603
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Hong S., 2016, IEEE C COMP VIS PATT
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Karen S., 2015, ARXIV PREPRINT ARXIV
   Khosla  A., 2011, P CVPR WORKSH FIN GR, V2
   Kim YJ, 2015, DIABETOL METAB SYNDR, V7, DOI 10.1186/s13098-015-0002-y
   Krause J., 2015, EUR C COMP VIS
   Krizhevsky A., 2012, ADV NEURAL INFORM PR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long M., 2015, ABS150202791 CORR
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Paulin M, 2014, PROC CVPR IEEE, P3646, DOI 10.1109/CVPR.2014.466
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Razavian A. Sharif, 2014, P IEEE C COMP VIS PA, P806
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rippel O., 2016, STAT, V1050, P2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880
   Xue Y, 2007, J MACH LEARN RES, V8, P35
   Yan Z., 2015, INT C COMP VIS ICCV
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 50
TC 3
Z9 3
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 10
EP 19
DI 10.1109/CVPR.2017.9
UT WOS:000418371400002
ER

PT S
AU Zhang, R
   Isola, P
   Efros, AA
AF Zhang, Richard
   Isola, Phillip
   Efros, Alexei A.
GP IEEE
TI Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel
   Prediction
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB We propose split-brain autoencoders, a straightforward modification of the traditional autoencoder architecture, for unsupervised representation learning. The method adds a split to the network, resulting in two disjoint sub-networks. Each sub-network is trained to perform a difficult task predicting one subset of the data channels from another. Together, the sub-networks extract features from the entire input signal. By forcing the network to solve crosschannel prediction tasks, we induce a representation within the network which transfers well to other, unseen tasks. This method achieves state-of-the-art performance on several large-scale transfer learning benchmarks.
CR Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13
   Ando R. K., J MACHINE LEARNING R, V6, P1817
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   de Sa V. R., 1994, ADV NEURAL INFORM PR, P112
   De Sa V. R., 2003, NIPS
   Dinh Laurent, 2016, ARXIV160508803
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Donahue J., 2017, ICLR
   Dumoulin V., 2017, ICLR
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Everingham M., PASCAL VISUAL OBJECT
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R., P IEEE INT C COMP VI, P1440
   Goodfellow I., 2014, ADV NEURAL INFORM PR, P2672, DOI [DOI 10.1001/JAMAINTERNMED.2016.8245, DOI 10.1017/CBO9781139058452]
   Gupta S., 2016, IEEE C COMP VIS PATT
   GUPTA S, 2014, ECCV, V8695, P345
   He K., 2016, CVPR
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Iizuka S., 2016, ACM T GRAPH P SIGGRA, V35
   Isola P., 2016, INT C LEARN REPR WOR
   Jayaraman D., P IEEE INT C COMP VI, P1413
   Kingma D. P., 2014, INT C LEARN REPR
   Krahenbuhl P., 2016, INT C LEARN REPR
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Larsson G., 2017, CVPR
   Larsson G., 2016, EUR C COMP VIS
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Noroozi M., 2016, EUR C COMP VIS
   Oord A. v. d., 2016, NIPS
   Owens A., 2016, ECCV
   Pathak D., CVPR
   Pathak D., 2016, CVPR
   Ramanarayanan G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239527
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov R., 2009, AISTATS, P3
   SILBERMAN N, 2012, EUR C COMP VIS, V7576, P746
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Smolensky Paul, 1986, TECHNICAL REPORT
   Sohn K., 2014, ADV NEURAL INFORM PR, P2141
   van den Oord A., 2016, ICML
   Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652
   Xu C., 2013, ARXIV13045634
   Zhang R., 2016, EUR C COMP VIS
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
NR 47
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 645
EP 654
DI 10.1109/CVPR.2017.76
UT WOS:000418371400069
ER

PT S
AU Ye, QX
   Zhang, TL
   Ke, W
   Qiu, Q
   Chen, J
   Sapiro, G
   Zhang, BC
AF Ye, Qixiang
   Zhang, Tianliang
   Ke, Wei
   Qiu, Qiang
   Chen, Jie
   Sapiro, Guillermo
   Zhang, Baochang
GP IEEE
TI Self-learning Scene-specific Pedestrian Detectors using a Progressive
   Latent Model
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
ID ADAPTATION
AB In this paper, a self-learning approach is proposed towards solving scene-specific pedestrian detection problem without any human' annotation involved. The self-learning approach is deployed as progressive steps of object discovery, object enforcement, and label propagation. In the learning procedure, object locations in each frame are treated as latent variables that are solved with a progressive latent model (PLM). Compared with conventional latent models, the proposed PLM incorporates a spatial regularization term to reduce ambiguities in object proposals and to enforce object localization, and also a graph-based label propagation to discover harder instances in adjacent frames. With the difference of convex (DC) objective functions, PLM can be efficiently optimized with a concave-convex programming and thus guaranteeing the stability of self-learning. Extensive experiments demonstrate that even without annotation the proposed self-learning approach outperforms weakly supervised learning approaches, while achieving comparable performance with transfer learning and fully supervised approaches.
CR Andriluka M., 2008, IEEE CVPR
   Benfold B., 2011, IEEE CVPR
   Bilen H., 2015, IEEE CVPR
   Cai Z., 2015, IEEE ICCV
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cho M., 2015, IEEE CVPR
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Divvala S. K., 2015, IEEE CVPR
   Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Donahue J., 2013, IEEE CVPR
   Donald K., 1997, ART COMPUTER PROGRAM, V3
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ferryman J., 2009, 12 IEEE INT WORKSH P
   Fu Y., 2014, ECCV
   Gaidon A., 2014, CORR
   Girshick R., 2015, IEEE ICCV
   Girshick R., 2014, IEEE CVPR
   Hattori H., 2015, IEEE CVPR
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Ke W., 2015, IEEE ICASSP
   Kuznetsova A., 2015, IEEE CVPR
   Kwak S., 2015, IEEE ICCV
   Mao Y., 2015, IEEE WACV
   Misra I., 2015, IEEE CVPR
   Papazoglou A., 2013, IEEE ICCV
   Ren S., 2016, IEEE T PATTERN ANAL
   Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908
   Shu G., 2013, IEEE CVPR
   Song  H., 2014, ICML
   Stalder S., 2009, IEEE WORKSH PETS
   Tian Y., 2015, IEEE ICCV
   Vazquez D, 2014, IEEE T PATTERN ANAL, V36, P797, DOI 10.1109/TPAMI.2013.163
   Wang C., 2014, ECCV
   Wang M., 2015, MATH PROBL ENG, V2015, P1, DOI DOI 10.1007/S12035-015-9092-7
   Wang X., 2012, IEEE CVPR
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Wu B., 2007, IEEE CVPR
   Xiao F., 2016, IEEE CVPR
   Xu JL, 2014, IEEE T PATTERN ANAL, V36, P2367, DOI 10.1109/TPAMI.2014.2327973
   Yang Y., 2008, IEEE CVPR
   Ye QX, 2013, IEEE T IMAGE PROCESS, V22, P778, DOI 10.1109/TIP.2012.2222901
   Yu C.-N.J., 2009, P 26 ANN INT C MACH, P1169, DOI DOI 10.1145/1553374.1553523
   Zeng X., 2014, ECCV
   Zhang S., 2016, IEEE CVPR
   Zhu X., 2009, INTRO SEMISUPERVISED
   Zitnick C. L., 2014, ECCV
NR 47
TC 1
Z9 1
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 2057
EP 2066
DI 10.1109/CVPR.2017.222
UT WOS:000418371402014
ER

PT S
AU Dixit, M
   Kwitt, R
   Niethammer, M
   Vasconcelos, N
AF Dixit, Mandar
   Kwitt, Roland
   Niethammer, Marc
   Vasconcelos, Nuno
GP IEEE
TI AGA : Attribute-Guided Augmentation
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB We consider the problem of data augmentation, i.e., generating artificial samples to extend a given corpus of training data. Specifically, we propose attributed-guided augmentation (AGA) which learns a mapping that allows synthesis of data such that an attribute of a synthesized sample is at a desired value or strength. This is particularly interesting in situations where little data with no attribute annotation is available for learning, but we have access to an external corpus of heavily annotated samples. While prior works primarily augment in the space of images, we propose to perform augmentation in feature space instead. We implement our approach as a deep encoder-decoder architecture that learns the synthesis function in an end-to-end manner. We demonstrate the utility of our approach on the problems of (1) one-shot object recognition in a transfer-learning setting where we have no prior knowledge of the new classes, as well as (2) object-based one-shot scene recognition. As external data, we leverage 3D depth and pose information from the SUN RGB-D dataset. Our experiments show that attribute-guided augmentation of high-level CNN features considerably improves one-shot recognition performance on both problems.
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Borji A., 2016, CVPR
   Charalambous C., 2016, BMVC
   Chatfield K., 2014, BMVC
   Cimpoi M., 2015, CVPR
   Clevert  D.A., 2016, ICLR
   Dixit M, 2015, CVPR
   Donahue J., 2014, ICML
   Drucker H., 1997, NIPS
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fink M., 2004, NIPS
   Gibbons JD, 2011, NONPARAMETRIC STAT I
   Girshick Ross, 2015, ICCV
   Gong Y., 2014, ECCV
   Hauberg S., 2016, AISTATS
   Ioffe  S., 2015, ICML
   Jaderberg M., 2015, NIPS
   Kingma D., 2015, ICLR
   Krizhevsky  A., 2012, NIPS
   Kwitt R., 2016, CVPR
   Liu  F., 2015, CVPR
   Miller E. G., 2000, CVPR
   Nair V., 2010, ICML
   Peng X., 2015, ICCV
   Quattoni A., 2009, CVPR
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Ren  Shaoqing, 2015, NIPS
   Rogez G., 2016, CORR
   Sermanet P, 2014, ICLR
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Song S., 2015, CVPR
   Srivastava N., 2014, J MACHINE LEARNING R, V15
   Su H., 2015, ICCV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Torralba A., 2011, CVPR
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zeiler M. D., 2014, ECCV
   Zhou B., 2014, NIPS
NR 38
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 3328
EP 3336
DI 10.1109/CVPR.2017.355
UT WOS:000418371403044
ER

PT S
AU Gorji, S
   Clark, JJ
AF Gorji, Siavash
   Clark, James J.
GP IEEE
TI Attentional Push: A Deep Convolutional Network for Augmenting Image
   Salience with Shared Attention Modeling in Social Scenes
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
ID VISUAL-ATTENTION; GAZE; EYES
AB We present a novel visual attention tracking technique based on Shared Attention modeling. By considering the viewer as a participant in the activity occurring in the scene, our model learns the loci of attention of the scene actors and use it to augment image salience. We go beyond image salience and instead of only computing the power of image regions to pull attention, we also consider the strength with which the scene actors push attention to the region in question, thus the term Attentional Push. We present a convolutional neural network (CNN) which augments standard saliency models with Attentional Push. Our model contains two pathways: an Attentional Push pathway which learns the gaze location of the scene actors and a saliency pathway. These are followed by a shallow augmented saliency CNN which combines them and generates the augmented saliency. For training, we use transfer learning to initialize and train the Attentional Push CNN by minimizing the classification error of following the actors' gaze location on a 2-D grid using a large-scale gaze-following dataset. The Attentional Push CNN is then fine-tuned along with the augmented saliency CNN to minimize the Euclidean distance between the augmented saliency and ground truth fixations using an eye-tracking dataset, annotated with the head and the gaze location of the scene actors. We evaluate our model on three challenging eye fixation datasets, SALICON, iSUN and CAT2000, and illustrate significant improvements in predicting viewers' fixations in social scenes.
CR Birmingham E, 2009, VISION RES, V49, P2992, DOI 10.1016/j.visres.2009.09.014
   Borji A., 2015, CVPR 2015 WORKSH FUT
   Borji A, 2014, J VISION, V14, DOI 10.1167/14.13.3
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Bylinskii Z., 2016, COMP VIS ECCV 2016 1
   Bylinskii Z., 2016, ARXIV160403605
   Bylinskii Z., MIT SALIENCY BENCHMA
   CASTELHANO MS, 2007, ATTENTION COGNITIVE, V4840, P251
   Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514
   Cornia M., 2016, 23 INT C PATT REC IC
   Glorot X., 2010, P INT C ART INT STAT
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia Y., 2014, ARXIV14085093
   Jiang M., 2015, IEEE C COMP VIS PATT
   Judd Tilke, 2012, BENCHMARK COMPUTATIO
   Kaplan F, 2006, INTERACT STUD, V7, P135, DOI 10.1075/is.7.2.04kap
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Kruthiventi S. S. S., 2015, ARXIV151002927
   Kuhn G, 2009, ATTEN PERCEPT PSYCHO, V71, P314, DOI 10.3758/APP.71.2.314
   Kummerer M, 2014, ARXIV14111045
   Liu N., 2015, IEEE C COMP VIS PATT
   Pan J., 2016, IEEE C COMP VIS PATT
   Parks D, 2015, VISION RES, V116, P113, DOI 10.1016/j.visres.2014.10.027
   Ramanathan S., 2011, P 19 ACM INT C MULT, P33
   Recasens Adria, 2015, ADV NEURAL INFORM PR
   Ricciardelli P, 2002, NEUROREPORT, V13, P2259, DOI 10.1097/01.wnr.0000044227.79663.2e
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Smith K, 2008, IEEE T PATTERN ANAL, V30, P1212, DOI 10.1109/TPAMI.2007.70773
   Smith TJ, 2012, PROJECTIONS, V6, P1, DOI 10.3167/proj.2012.060102
   Szegedy C., 2014, 14094842 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Xu P., 2015, ARXIV150406755
   Zhang J., 2015, IEEE T PATTERN ANAL
   Zhu Xiangxin, 2012, COMP VIS PATT REC CV
NR 38
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 3472
EP 3481
DI 10.1109/CVPR.2017.370
UT WOS:000418371403059
ER

PT S
AU Zhou, ZW
   Shin, J
   Zhang, L
   Gurudu, S
   Gotway, M
   Liang, JM
AF Zhou, Zongwei
   Shin, Jae
   Zhang, Lei
   Gurudu, Suryakanth
   Gotway, Michael
   Liang, Jianming
GP IEEE
TI Fine-tuning Convolutional Neural Networks for Biomedical Image Analysis:
   Actively and Incrementally
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB Intense interest in applying convolutional neural networks (CNNs) in biomedical image analysis is wide spread, but its success is impeded by the lack of large annotated datasets in biomedical imaging. Annotating biomedical images is not only tedious and time consuming, but also demanding of costly, specialty-oriented knowledge and skills, which are not easily accessible. To dramatically reduce annotation cost, this paper presents a novel method called AIFT (active, incremental fine-tuning) to naturally integrate active learning and transfer learning into a single framework. AIFT starts directly with a pre-trained CNN to seek "worthy" samples from the unannotated for annotation, and the (fine-tuned) CNN is further fine-tuned continuously by incorporating newly annotated samples in each iteration to enhance the CNN's performance incrementally. We have evaluated our method in three different biomedical imaging applications, demonstrating that the cost of annotation can be cut by at least half. This performance is attributed to the several advantages derived from the advanced active and incremental capability of our AIFT method.
CR Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Carneiro G, 2015, LECT NOTES COMPUT SC, V9351, P652, DOI 10.1007/978-3-319-24574-4_78
   Chakraborty S, 2015, IEEE T PATTERN ANAL, V37, P1945, DOI 10.1109/TPAMI.2015.2389848
   CHEN H, 2015, INT C MED IM COMP, V9349, P507, DOI DOI 10.1007/978-3-319-24553-9_62
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gao M, 2015, 1 WORKSH DEEP LEARN
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guyon I., 2011, JMLR WORKSHOP C P
   Holub Alex, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563068
   Jia Y., 2014, ARXIV14085093
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Kukar M, 2003, ARTIF INTELL MED, V29, P81, DOI [10.1016/S0933-3657(03)00043-5, 10.1016/S0933-3657(03)0043-5]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li  J., 2016, IEEE INT C IM PROC I, P1062
   Liang JM, 2007, LECT NOTES COMPUT SC, V4584, P630
   Lu L., 2016, DEEP LEARNING CONVOL
   Margeta J, 2015, COMPUT METHOD BIOMEC, P1, DOI DOI 10.1080/21681163.2015
   Schlegl T, 2014, LECT NOTES COMPUT SC, V8848, P82, DOI 10.1007/978-3-319-13972-2_8
   Settles Burr, U WISCONSIN MADISON, V52, P11
   Shin HC, 2015, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2015.7298712
   Stark F., 2015, WORKSH NEW CHALL NEU, P94
   Tajbakhsh N., INT C MED IM COMP CO, P62
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Wang D, 2014, IEEE IJCNN, P112, DOI 10.1109/IJCNN.2014.6889457
   Wang HK, 2017, EJNMMI RES, V7, DOI 10.1186/s13550-017-0260-9
   Zhou B., 2016, ARXIV161002055
   Zhou K., 2016, DEEP LEARNING MED IM
NR 28
TC 8
Z9 8
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 4761
EP 4772
DI 10.1109/CVPR.2017.506
UT WOS:000418371404090
PM 30337799
ER

PT S
AU Tamaazousti, Y
   Le Borgne, H
   Hudelot, C
AF Tamaazousti, Youssef
   Le Borgne, Herve
   Hudelot, Celine
GP IEEE
TI MuCaLe-Net: Multi Categorical-Level Networks to Generate More
   Discriminating Features
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB In a transfer-learning scheme, the intermediate layers of a pre-trained CNN are employed as universal image representation to tackle many visual classification problems. The current trend to generate such representation is to learn a CNN on a large set of images labeled among the most specific categories. Such processes ignore potential relations between categories, as well as the categorical-levels used by humans to classify. In this paper, we propose Multi Categorical-Level Networks (MuCaLe-Net) that include human-categorization knowledge into the CNN learning process. A MuCaLe-Net separates generic categories from each other while it independently distinguishes specific ones. It thereby generates different features in the intermediate layers that are complementary when combined together. Advantageously, our method does not require additive data nor annotation to train the network. The extensive experiments over four publicly available benchmarks of image classification exhibit state-of-the-art performances.
CR Ahmed K., 2016, ECCV
   Azizpour H., 2015, PAMI
   Chatfield K., 2014, BMVC
   Chua T., 2009, CIVR
   Deng J., 2009, CVPR
   Deng Jia, 2012, CVPR
   Durand T., 2016, CVPR
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Everingham M., 2010, IJCV
   Fei-Fei L., 2006, PAMI
   Girshick  R., 2014, CVPR
   Griffin G., 2007, CALTECH 256 OBJECT C
   He K., 2016, CVPR
   Herranz L., 2016, CVPR
   Hinton  G., 2015, ARXIV150302531
   Jolicoeur P., 1984, COGNITIVE PSYCHOL
   Joulin A., 2016, ECCV
   Krizhevsky  A., 2012, NIPS
   Li Y., 2016, ICLR
   Mathews A., 2015, WACV
   Mettes P., 2016, ICMR
   Murthy V. N., 2016, CVPR
   Oquab M., 2014, CVPR
   Oquab M, 2015, CVPR
   Ordonez V, 2013, ICCV
   Ordonez V., 2015, IJCV
   Ouyang W., 2016, CVPR
   Peng H., 2005, PAMI
   Rosch E., 1978, COGNITION CATEGORIZA
   Russakovsky Olga, 2015, IJCV
   Sermanet P, 2014, ICLR
   Simonyan K., 2015, ICLR
   Szegedy C., 2015, CVPR
   Tamaazousti Y., 2016, ICMR
   Tanaka J. W., 1991, COGNITIVE PSYCHOL
   Wu YB, 2016, INT J PHOTOENERGY, DOI 10.1155/2016/7368795
   Yang H., 2016, CVPR
   Yosinski J., 2015, ICML
   Yosinski J., 2014, NIPS
   Zeiler M. D., 2014, ECCV
   Zhou B., 2014, NIPS
NR 41
TC 0
Z9 0
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 5282
EP 5291
DI 10.1109/CVPR.2017.561
UT WOS:000418371405040
ER

PT S
AU Venkateswara, H
   Eusebio, J
   Chakraborty, S
   Panchanathan, S
AF Venkateswara, Hemanth
   Eusebio, Jose
   Chakraborty, Shayok
   Panchanathan, Sethuraman
GP IEEE
TI Deep Hashing Network for Unsupervised Domain Adaptation
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
ID LEARNING BINARY-CODES; ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH
AB In recent years, deep neural networks have emerged as a dominant machine learning tool for a wide variety of application domains. However, training a deep neural network requires a large amount of labeled data, which is an expensive process in terms of time, labor and human expertise. Domain adaptation or transfer learning algorithms address this challenge by leveraging labeled data in a different, but related source domain, to develop a model for the target domain. Further, the explosive growth of digital data has posed a fundamental challenge concerning its storage and retrieval. Due to its storage and retrieval efficiency, recent years have witnessed a wide application of hashing in a variety of computer vision applications. In this paper, we first introduce a new dataset, Office-Home, to evaluate domain adaptation algorithms. The dataset contains images of a variety of everyday objects from multiple domains. We then propose a novel deep learning framework that can exploit labeled source data and unlabeled target data to learn informative hash codes, to accurately classify unseen target data. To the best of our knowledge, this is the first research effort to exploit the feature learning capabilities of deep neural networks to learn representative hash codes to address the domain adaptation problem. Our extensive empirical studies on multiple transfer tasks corroborate the usefulness of the framework in learning efficient hash codes which outperform existing competitive baselines for unsupervised domain adaptation.
CR Aytar Y., 2011, IEEE ICCV
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Cao Y., 2016, ACM SIGKDD
   Cao Z., 2016, AAAI
   Carreira-Perpinan MA, 2015, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2015.7298654
   Chatfield K., 2014, BMVC
   Chattopadhyay R, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382582
   Chu WS, 2013, PROC CVPR IEEE, P3515, DOI 10.1109/CVPR.2013.451
   Donahue J., 2014, P 31 INT C MACH LEAR, V32, P647
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ganin Y, 2016, J MACH LEARN RES, V17
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Gong B., 2013, P 30 INT C MACH LEAR, P222
   Gong B., 2012, IEEE CVPR
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gretton A., 2012, ADV NEURAL INFORM PR, P1205
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Hochreiter S, 2001, GRADIENT FLOW RECURR
   Hoffman J., 2013, ICLR
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jiang  Qing-Yuan, 2016, ARXIV160202255
   Li W. - J., 2016, IJCAI 2016
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Long M., 2016, NIPS
   LONG M, 2013, P IEEE INT C COMP VI, P2200
   Long M., 2015, INT C MACH LEARN, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Lucey P., 2010, IEEE COMP SOC C COMP, V2010, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, V2011, P5
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pantic M., 2005, ICME
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Saenko K., 2010, ECCV
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Sun B., 2015, ICCV TASK CV
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Vedaldi A., 2015, P ACM INT C MULT
   Wang JH, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/783147
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhu H., 2016, 30 AAAI C ART INT
NR 50
TC 6
Z9 6
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 5385
EP 5394
DI 10.1109/CVPR.2017.572
UT WOS:000418371405051
ER

PT S
AU Pathak, D
   Girshick, R
   Dollar, P
   Darrell, T
   Hariharan, B
AF Pathak, Deepak
   Girshick, Ross
   Dollar, Piotr
   Darrell, Trevor
   Hariharan, Bharath
GP IEEE
TI Learning Features by Watching Objects Move
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB This paper presents a novel yet intuitive approach to unsupervised feature learning. Inspired by the human visual system, we explore whether low-level motion-based grouping cues can be used to learn an effective visual representation. Specifically, we use unsupervised motion-based segmentation on videos to obtain segments, which we use as 'pseudo ground truth' to train a convolutional network to segment objects from a single frame. Given the extensive evidence that motion plays a key role in the development of the human visual system, we hope that this straightforward approach to unsupervised learning will be more effective than cleverly designed 'pretext' tasks studied in the literature. Indeed, our extensive experiments show that this is the case. When used for transfer learning on object detection, our representation significantly outperforms previous unsupervised approaches across multiple settings, especially when training data for the target task is scarce.
CR Achanta R., 2012, TPAMI
   Agrawal P., 2015, ICCV
   Arbelaez P., 2015, CVPR
   Arteta C., 2016, ECCV
   Bengio Y., 2013, TPAMI, V35
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Dalal N., 2005, CVPR
   de Sa V. R., 1994, NIPS
   Doersch Carl, 2015, ICCV
   Dollar L. Z. Piotr, 2013, ICCV
   Donahue J., 2014, ICML
   Donahue J., 2017, ICLR
   Dumoulin V., 2017, ICLR
   Faktor A., 2014, BMVC
   Galasso F., 2013, ICCV
   Garg R., 2016, ECCV
   Girshick Ross, 2015, ICCV
   Goodfellow I., 2014, NIPS
   Goroshin Ross, 2015, NIPS
   Hariharan B., 2011, ICCV
   Hinton G. E., 2006, SCIENCE
   Jayaraman Dinesh, 2015, ICCV
   Kohli P., 2009, IJCV
   Krahenbuhl P., 2016, ICLR
   Krizhevsky  A., 2012, NIPS
   Larsson G., 2016, ECCV
   Li Y., 2016, CVPR
   Lin T.-Y., 2014, ECCV
   Long  J., 2015, CVPR
   Misra Ishan, 2016, ECCV
   Noroozi M., 2016, ECCV
   Ochs P., 2014, TPAMI, V36
   Ostrovsky Y., 2009, PSYCHOL SCI
   Owens A., 2016, ECCV
   Palmer S., 1999, VISION SCI PHOTONS P
   Pathak D., 2016, CVPR
   Perazzi F., 2016, CVPR
   Pinheiro P. O., 2015, NIPS
   Pinheiro P. O., 2016, ECCV
   Potapov D., 2014, ECCV
   Russakovsky Olga, 2015, IJCV
   SPELKE ES, 1990, COGNITIVE SCI, V14, P29, DOI 10.1016/0364-0213(90)90025-R
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Vincent P., 2008, ICML
   Walker J., 2016, ECCV
   Wang X., 2015, ICCV
   Wertheimer M., 1938, LAWS ORG PERCEPTUAL
   Yao B., 2011, ICCV
   Yosinski J., 2014, NIPS
   Zhang N., 2014, ECCV
   Zhang R., 2017, CVPR
   Zhang R., 2016, ECCV
NR 52
TC 2
Z9 2
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 6024
EP 6033
DI 10.1109/CVPR.2017.638
UT WOS:000418371406013
ER

PT S
AU Yim, J
   Joo, D
   Bae, J
   Kim, J
AF Yim, Junho
   Joo, Donggyu
   Bae, Jihoon
   Kim, Junmo
GP IEEE
TI A Gift from Knowledge Distillation: Fast Optimization, Network
   Minimization and Transfer Learning
SO 30TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR
   2017)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUL 21-26, 2017
CL Honolulu, HI
AB We introduce a novel technique for knowledge transfer, where knowledge from a pretrained deep neural network (DNN) is distilled and transferred to another DNN. As the DNN maps from the input space to the output space through many layers sequentially, we define the distilled knowledge to be transferred in terms of flow between layers, which is calculated by computing the inner product between features from two layers. When we compare the student DNN and the original network with the same size as the student DNN but trained without a teacher network, the proposed method of transferring the distilled knowledge as the flow between two layers exhibits three important phenomena: (1) the student DNN that learns the distilled knowledge is optimized much faster than the original model; (2) the student DNN outperforms the original DNN; and (3) the student DNN can learn the distilled knowledge from a teacher DNN that is trained at a different task, and the student DNN outperforms the original DNN that is trained from scratch.
OI Bae, Ji-Hoon/0000-0002-0035-5261
CR Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Branson S, 2014, ARXIV14062952
   Chen T., 2015, ARXIV151105641
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Gatys L. A., 2015, ARXIV150806576
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   He K, 2016, ARXIV160305027
   He K, 2015, ARXIV151203385
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton  G., 2015, ARXIV150302531
   Ioffe S., 2015, ARXIV150203167
   Kingma D., 2014, 14126980 ARXIV, DOI DOI 10.1145/18304
   Krahenbuhl P., 2015, ARXIV151106856
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mishkin D., 2015, ARXIV151106422
   Noh Hyeonwoo, 2015, ARXIV151105756
   Romero A., 2015, P ICLR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saxe A. M., 2013, ARXIV13126120
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Veit A, 2016, ARXIV160506431
   Wah C., 2011, TECHNICAL REPORT
   Zagoruyko S., 2016, ARXIV160507146
   Zeiler M. D., 2012, ARXIV12125701
   Zhou Bolei, 2015, ARXIV151202167
NR 28
TC 4
Z9 4
SN 1063-6919
BN 978-1-5386-0457-1
PY 2017
BP 7130
EP 7138
DI 10.1109/CVPR.2017.754
UT WOS:000418371407025
ER

PT S
AU Fonseca, P
   Castaneda, B
   Valenzuela, R
   Wainer, J
AF Fonseca, Pablo
   Castaneda, Benjamin
   Valenzuela, Ricardo
   Wainer, Jacques
BE BeltranCastanon, C
   Nystrom, I
   Famili, F
TI Breast Density Classification with Convolutional Neural Networks
SO PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND
   APPLICATIONS, CIARP 2016
SE Lecture Notes in Computer Science
CT 21st Iberoamerican Congress on Pattern Recognition (CIARP)
CY NOV 08-11, 2016
CL Lima, PERU
AB Breast Density Classification is a problem in Medical Imaging domain that aims to assign an American College of Radiology's BIRADS category (I-IV) to a mammogram as an indication of tissue density. This is performed by radiologists in an qualitative way, and thus subject to variations from one physician to the other. In machine learning terms it is a 4-ordered-classes classification task with highly unbalance training data, as classes are not equally distributed among populations, even with variations among ethnicities. Deep Learning techniques in general became the state-of-the-art for many imaging classification tasks, however, dependent on the availability of large datasets. This is not often the case for Medical Imaging, and thus we explore Transfer Learning and Dataset Augmentationn. Results show a very high squared weighted kappa score of 0.81 (0.95 C.I. [0.77, 0.85]) which is high in comparison to the 8 medical doctors that participated in the dataset labeling 0.82 (0.95 CI [0.77, 0.87]).
OI Fonseca, Pablo/0000-0002-0208-2842; Castaneda,
   Benjamin/0000-0002-1913-0636
CR Angulo A., 2015, EXPT ASSESSMENT AUTO
   Boyd N. F., 2011, BREAST CANCER RES, V13, P1, DOI DOI 10.1186/BCR2942
   Boyle P, 2008, WORLD CANC REPORT 20
   Casado F.L., 2015, CHARACTERIZATION BRE
   Cox D, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   D'Orsi C. J., 1998, BREAST IM REP DAT SY
   Fonseca P., 2015, AUTOMATIC BREAST DEN
   Jia Y., 2014, ARXIV14085093
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514
   Oliver A, 2006, LECT NOTES COMPUT SC, V4191, P872
   Otsuka M., 2015, LOCAL MAMMOGRAPHIC D
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Redondo A, 2012, BRIT J RADIOL, V85, P1465, DOI 10.1259/bjr/21256379
   Ursin G., 2009, Norsk Epidemiologi, V19, P59
   WOLFE JN, 1976, CANCER, V37, P2486, DOI 10.1002/1097-0142(197605)37:5<2486::AID-CNCR2820370542>3.0.CO;2-8
NR 17
TC 0
Z9 0
SN 0302-9743
EI 1611-3349
BN 978-3-319-52277-7; 978-3-319-52276-0
PY 2017
VL 10125
BP 101
EP 108
DI 10.1007/978-3-319-52277-7_13
UT WOS:000418399200013
ER

PT B
AU Wei, BZ
   Han, ZY
   He, XY
   Yin, YL
AF Wei, Benzheng
   Han, Zhongyi
   He, Xueying
   Yin, Yilong
GP IEEE
TI Deep Learning Model Based Breast Cancer Histopathological Image
   Classification
SO 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA
   ANALYSIS (ICCCBDA 2017)
CT 2nd IEEE International Conference on Cloud Computing and Big Data
   Analysis (ICCCBDA)
CY APR 28-30, 2017
CL Chengdu, PEOPLES R CHINA
DE deep learning; breast cancer; histopathological image; CNN;
   classification; massive image data
AB The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis.
OI Wei, Benzheng/0000-0001-9640-4947
CR Bayramoglu N, 2016, INT C PATT REC ICPR, P2441
   Boyd S, 1994, LINEAR MATRIX INEQUA, V15
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen H., 2016, 30 AAAI C ART INT
   Dalal N, 2005, PROC CVPR IEEE, P886
   Hamilton NA, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-110
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Spanhol F.A., 2016, INT JOINT C NEUR NET
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Stewart B., 2014, WORLD CANC REPORT 20
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wang D., 2016, ARXIV160605718
   Wang P, 2016, SIGNAL PROCESS, V122, P1, DOI 10.1016/j.sigpro.2015.11.011
   Weinberger KQ, 2005, ADV NEURAL INFORM PR, P1473
   Wu G., 2015, SCALABLE HIGH PERFON
   Zhang YG, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-17
   Zheng YJ, 2015, COMPUT MED IMAG GRAP, V46, P73, DOI 10.1016/j.compmedimag.2015.05.004
NR 21
TC 4
Z9 4
BN 978-1-5090-4499-3
PY 2017
BP 348
EP 353
UT WOS:000414283700064
ER

PT S
AU Gungor, C
   Baltaci, F
   Erdem, A
   Erdem, E
AF Gungor, Cem
   Baltaci, Fatih
   Erdem, Aykut
   Erdem, Erkut
GP IEEE
TI Turkish Cuisine: A Benchmark Dataset with Turkish Meals for Food
   Recognition
SO 2017 25TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE
   (SIU)
SE Signal Processing and Communications Applications Conference
CT 25th Signal Processing and Communications Applications Conference (SIU)
CY MAY 15-18, 2017
CL Antalya, TURKEY
DE deep learning; image recognition; collecting dataset
AB Food recognition in still images is a problem that has been recently introduced in computer vision. The benchmark data sets used in training and evaluation of food recognition methods contain sample images of popular foods from the globe. However, when they are examined thoroughly, it can be observed that very few of them are Turkish dishes. In this study, we first carry out a data collection process for Turkish dishes and construct a new dataset named "TurkishFoods-15" containing 500 images in each food class. In addition, we introduce a novel food recognition approach that depends on fine-tuning Google Inception v3 deep neural network model based on transfer learning For this purpose, our Turkish cuisine dataset was combined with the widely used Food-101 dataset from the literature and the performance analysis of the developed deep learning-based approach is carried out on this combined dataset containing 113 food classes. Our results show that the recognition of Turkish dishes can be achieved with certain success even though it does not have certain difficulties.
RI Erdem, Aykut/A-2290-2012
CR Abadi M, 2015, TENSORFLOW LARGE SCA
   Beijbom D. M. S. S. Oscar, 2015, WACV
   Bossard Lukas, 2014, EUR C COMP VIS
   Deng J., 2009, CVPR 09
   Kawano Y., 2014, P ECCV WORKSH TRANSF
   Malmaud J., 2015, NAACL
   Myers Austin, 2015, ICCV
   Singla A, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P3, DOI 10.1145/2986035.2986039
   Szegedy C., 2015, ARXIV151200567
   Yang S, 2010, CVPR
NR 10
TC 0
Z9 0
SN 2165-0608
BN 978-1-5090-6494-6
PY 2017
UT WOS:000413813100357
ER

PT S
AU Hedjazi, MA
   Kourbane, I
   Genc, Y
AF Hedjazi, Mohamed Abbas
   Kourbane, Ikram
   Genc, Yakup
GP IEEE
TI On Identifying Leaves: A Comparison of CNN with Classical ML Methods
SO 2017 25TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE
   (SIU)
SE Signal Processing and Communications Applications Conference
CT 25th Signal Processing and Communications Applications Conference (SIU)
CY MAY 15-18, 2017
CL Antalya, TURKEY
DE Machine Learning; Computer Vision; Convolution Neural Network; Transfer
   Learning
AB Convolution neural networks (CNNs) eliminate the need for feature extraction which is one of the most important and time-consuming part of traditional machine learning (ML) methods. However, the challenge of training a deep CNN model with a limited amount of training data still remains. Transfer learning and parameter fine-tuning have emerged as solutions to this problem. Following the recent trends, we address the task of visual identification of leaves in images by modifying a trained model on a similar problem. In particular, we show that a pretrained CNN model on a large dataset (ImageNet) can be used to train a model from a small training set (ImageCLEF2013 Plant Identification). The resulting model outperforms the classical machine learning methods using local binary patterns (LBPs), a well utilized feature in the field.
CR Bakic V., 2013, CLEF ONL WORK NOT LA, V2013
   Caputo B, 2013, LECT NOTES COMPUT SC, V8138, P250, DOI 10.1007/978-3-642-40802-1_26
   Chen J., 2013, BMVC
   Deng L, 2013, IEEE T AUDIO SPEECH, V21, P1060, DOI 10.1109/TASL.2013.2244083
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQueen  J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Yanikoglu B. A., 2013, CLEF WORKING NOTES
NR 14
TC 0
Z9 0
SN 2165-0608
BN 978-1-5090-6494-6
PY 2017
UT WOS:000413813100121
ER

PT S
AU Kaya, A
   Keceli, AS
   Can, AB
AF Kaya, Aydin
   Keceli, Ali Seydi
   Can, Ahinet Burak
GP IEEE
TI Investigation of Transfer Learning on Pulmonary Nodule Characteristics
SO 2017 25TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE
   (SIU)
SE Signal Processing and Communications Applications Conference
CT 25th Signal Processing and Communications Applications Conference (SIU)
CY MAY 15-18, 2017
CL Antalya, TURKEY
DE nodule characteristics; pulmonary nodules; malignancy prediction;
   tansfer learning
ID CT IMAGES; CLASSIFICATION; MALIGNANCY; DIAGNOSIS; DENSITY; BENIGN; SHAPE
AB Studies on the classification of small pulmonary nodules generally focus on the prediction of malignancy of the nodule. In the recent years, publicly available databases provided different types of data to researchers, such as nodule characteristics, apart from the lung image and malignancy degree. In this paper, a study on the classification of pulmonary nodule characteristics using conventional features and deep features obtained from transfer learning method has been proposed. The results were assessed by sensitivity, specificity, and classification accuracy. The results of the study can be used to form multi-level classifiers in predicting malignancy by combining different types of features.
RI Keceli, Ali Seydi/M-3158-2018; Can, Ahmet/M-8712-2018; KAYA,
   AYDIN/I-8550-2013
OI Keceli, Ali Seydi/0000-0001-6531-8464; Can, Ahmet/0000-0002-0101-6878; 
CR Aoyama M, 2003, MED PHYS, V30, P387, DOI 10.1118/1.1543575
   Armato SG, 2004, RADIOLOGY, V232, P739, DOI 10.1148/radiol.2323032035
   BAR Y, 2015, INT SOC OPTICS PHOTO, V9414
   Deng J., 2009, IEEE COMPUTER VISION
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Giuca AM, 2012, IEEE IMAGE PROC, P2397, DOI 10.1109/ICIP.2012.6467380
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Kawata Y., 2001, P 2001 INT C IM PROC
   Kaya A, 2015, J BIOMED INFORM, V56, P69, DOI 10.1016/j.jbi.2015.05.011
   Kim R., 2010, P INT C MULT INF RET, P185
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Li Q, 2003, MED PHYS, V30, P2584, DOI 10.1118/1.1605351
   Litjens G., 2016, DEEP LEARNING TOOL I
   Lo SCB, 2003, P SOC PHOTO-OPT INS, V5032, P183, DOI 10.1117/12.481878
   Manikandan T, 2011, COMM COM INF SC, V250, P642
   McNitt-Gray MF, 1999, MED PHYS, V26, P880, DOI 10.1118/1.598603
   Samuel CC, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P159, DOI 10.1109/ICCIMA.2007.236
   TRAN D, 2015, P IEEE INT C COMP VI, P4489, DOI DOI 10.1109/ICCV.2015.510
   Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520
   Way TW, 2006, MED PHYS, V33, P2323, DOI 10.1118/1.2207129
   Xu DM, 2008, EUR J RADIOL, V68, P347, DOI 10.1016/j.ejrad.2007.08.027
   Zhou B., 2014, ADV NEURAL INFORM PR, V27, P487, DOI DOI 10.1162/153244303322533223
   Zinovev D., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P155, DOI 10.1109/ICMLA.2011.44
   Zinovev D., 2009, PREDICTING RADIOLOGI
NR 24
TC 0
Z9 0
SN 2165-0608
BN 978-1-5090-6494-6
PY 2017
UT WOS:000413813100221
ER

PT S
AU Thendral, SE
   Valliyammai, C
AF Thendral, S. Ephina
   Valliyammai, C.
GP IEEE
TI Clustering Based Transfer Learning In Cross Domain Recommender System
SO 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING (ICOAC)
SE International Conference on Advanced Computing
CT 8th International Conference on Advanced Computing (ICoAC)
CY JAN 19-21, 2017
CL Chennai, INDIA
DE cross-domain; recommender system; transfer learning; cluster
AB The technique of collaborative filtering in recommender system suffers from data sparsity and cold start. In this paper, a cluster based approach is proposed for alleviating the problem of sparsity by transferring the knowledge from a more densely rated concomitant domain. The paper focuses on providing recommendation in a sparsely rated domain by transferring the knowledge from the highly rated domain with the same users rating the items in both the domains. This cross domain system transfers the affinity among users from the highly rated domain to the sparsely rated domain to make more accurate recommendation at the target domain. An algorithm is proposed to link the users' affinity between the domains. The proposed cross domain algorithm is tested with various clustering methods. The experiments are performed considering restaurant - tourist attraction as cross domains and results show that hierarchical agglomerative clustering performs better when transferring user affinity between associated domains.
CR Cantador Ivan, RECOMMENDER SYSTEMS, P919
   Cremonesi Paolo, 2014, IEEE INT C DAT MIN W, P496
   Dai WY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P210
   LI B, 2009, IJCAI, P2052
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan Weike, 2011, P 22 INT JOINT C ART, P2318
   Sahebi S., 2014, WORKSH NEW TRENDS CO, P57
   Shapira B, 2013, USER MODEL USER-ADAP, V23, P211, DOI 10.1007/s11257-012-9128-x
   Xu ZZ, 2016, COMPUT SCI INF SYST, V13, P359, DOI [10.2298/CSIS150730007Z, 10.2298/CSIS1507300072]
NR 10
TC 0
Z9 0
SN 2377-6927
BN 978-1-5090-5888-4
PY 2017
BP 51
EP 54
UT WOS:000414284300010
ER

PT S
AU Crosswhite, N
   Byrne, J
   Stauffer, C
   Parkhi, O
   Cao, Q
   Zisserman, A
AF Crosswhite, Nate
   Byrne, Jeffrey
   Stauffer, Chris
   Parkhi, Omkar
   Cao, Qiong
   Zisserman, Andrew
GP IEEE
TI Template Adaptation for Face Verification and Identification
SO 2017 12TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE
   RECOGNITION (FG 2017)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
AB Face recognition performance evaluation has traditionally focused on one-to-one verification, popularized by the Labeled Faces in the Wild dataset [1] for imagery and the YouTubeFaces dataset [2] for videos. In contrast, the newly released IJB-A face recognition dataset [3] unifies evaluation of one-to-many face identification with one-to-one face verification over templates, or sets of imagery and videos for a subject. In this paper, we study the problem of template adaptation, a form of transfer learning to the set of media in a template. Extensive performance evaluations on IJB-A show a surprising result, that perhaps the simplest method of template adaptation, combining deep convolutional network features with template specific linear SVMs, outperforms the state-of-the-art by a wide margin. We study the effects of template size, negative set construction and classifier fusion on performance, then compare template adaptation to convolutional networks with metric learning, 2D and 3D alignment. Our unexpected conclusion is that these other methods, when combined with template adaptation, all achieve nearly the same top performance on IJB-A for templatebased face verification and identification.
CR AbdAlmageed W., 2016, WACV
   Chatfield K., 2015, INT J MULTIMEDIA INF
   Chen D., 2012, ECCV
   Chen J., 2015, ICCV WORKSH CHAL LOO
   Chen J. -C., 2016, WACV
   Crosswhite N., 2016, ARXIV160303958V3
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Grother P., 2014, 8009 NIST
   Hu G., 2015, ICCV WORKSH CHAL LOO
   Huang G. B., 2007, 0749 U MASS
   Kazemi V., 2014, CVPR
   Klare B. F., 2015, CVPR
   Learned-Miller E., 2015, ADV FACE DETECTION F
   Lu C., 2015, AAAI
   Malisiewicz T., 2011, ICCV
   Parkhi O. M., 2014, CVPR
   Parkhi O.M., 2015, BMVC
   Phillips J., 2015, BTAS
   RoyChowdry A., 2016, WACV
   Sankaranarayanan S, 2016, ARXIV160203418
   Schroff F., 2015, CVPR
   Simonyan K., 2015, ICLR
   Sun Y, 2015, CVPR
   Sun Yi, 2014, ARXIV150200873
   Szegedy C., 2015, CVPR
   Taigman Y., 2014, CVPR
   Taigman Y., 2015, CVPR
   Wan L., 2013, ICML
   Wang D., 2015, ARXIV150707242
   Wolf L., 2011, CVPR
   Wolf L, 2011, PAMI, V33
   Wolf L, 2009, ICCV
   Yi D., 2014, ARXIV14117923
   Zinkevich M., 2011, NIPS
NR 34
TC 14
Z9 14
SN 2326-5396
BN 978-1-5090-4023-0
PY 2017
BP 1
EP 8
DI 10.1109/FG.2017.11
UT WOS:000414287400001
ER

PT S
AU Madapana, N
   Wachs, JP
AF Madapana, Naveen
   Wachs, Juan P.
GP IEEE
TI A Semantical & Analytical Approach for Zero Shot Gesture Learning
SO 2017 12TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE
   RECOGNITION (FG 2017)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
AB Zero shot learning (ZSL) is about being able to recognize gesture classes that were never seen before. This type of recognition involves the understanding that the presented gesture is a new form of expression from those observed so far, and yet carries embedded information universal to all the other gestures (also referred as context). As part of the same problem, it is required to determine what action/command this new gesture conveys, in order to react to the command autonomously. Research in this area may shed light to areas where ZSL occurs, such as spontaneous gestures. People perform gestures that may be new to the observer. This occurs when the gesturer is learning, solving a problem or acquiring a new language. The ability of having a machine recognizing spontaneous gesturing, in the same manner as humans do, would enable more fluent human-machine interaction. In this paper, we describe a new paradigm for ZSL based on adaptive learning, where it is possible to determine the amount of transfer learning carried out by the algorithm and how much knowledge is acquired from a new gesture observation. Another contribution is a procedure to determine what are the best semantic descriptors for a given command and how to use those as part of the ZSL approach proposed.
CR Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Antol S, 2014, LECT NOTES COMPUT SC, V8692, P401, DOI 10.1007/978-3-319-10593-2_27
   Belgacem S., 2015, ADAPT BIOMETRIC SYST
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cabrera J., 2016, 25 IEEE INT S ROB HU
   Cheng H-T., 2013, P 2013 ACM INT JOINT, P355
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Ferrari Vittorio, 2008, ADV NEURAL INFORM PR, P433
   Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38
   Hart P. E., 1973, ARTIF INTELL, V4, P139
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Palatucci M., 2009, ADV NEURAL INF PROCE, V22, P1
   Palatucci  Mark, 2009, ADV NEURAL INFORM PR, P1410
   Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451 
   Romera-Paredes B., 2015, P 32 INT C MACH LEAR, P2152
   Socher R., 2013, ADV NEURAL INFORM PR, P935
   Wachs JP, 2008, J AM MED INFORM ASSN, V15, P321, DOI 10.1197/jamia.M241
   Xu Y., 2005, HUMAN BEHAV LEARNING
NR 23
TC 3
Z9 3
SN 2326-5396
BN 978-1-5090-4023-0
PY 2017
BP 796
EP 801
DI 10.1109/FG.2017.100
UT WOS:000414287400108
ER

PT S
AU Zhou, YQ
   Pi, JM
   Shi, BE
AF Zhou, Yuqian
   Pi, Jimin
   Shi, Bertram E.
GP IEEE
TI Pose-independent Facial Action Unit Intensity Regression Based on
   Multi-task Deep Transfer Learning
SO 2017 12TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE
   RECOGNITION (FG 2017)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
ID EXPRESSIONS; DATABASE
AB Facial expression recognition plays an increasingly important role in human behavior analysis and human computer interaction. Facial action units (AUs) coded by the Facial Action Coding System (FACS) provide rich cues for the interpretation of facial expressions. Much past work on AU analysis used only frontal view images, but natural images contain a much wider variety of poses. The FG 2017 Facial Expression Recognition and Analysis challenge (FERA 2017) requires participants to estimate the AU occurrence and intensity under nine different pose angles. This paper proposes a multi-task deep network addressing the AU intensity estimation sub-challenge of FERA 2017. The network performs the tasks of pose estimation and pose-dependent AU intensity estimation simultaneously. It merges the pose-dependent AU intensity estimates into a single estimate using the estimated pose. The two tasks share transferred bottom layers of a deep convolutional neural network (CNN) pre-trained on ImageNet. Our model outperforms the baseline results, and achieves a balanced performance among nine pose angles for most AUs.
CR Abadi M., 2016, ARXIV160304467
   Abdalmageed  W., 2016, 2016 IEEE WINT C APP, P1
   Cohn J. F., 2009, AFF COMP INT INT WOR, P1, DOI DOI 10.1109/ACII.2009.5349358
   Ekman P., 1977, FACIAL ACTION CODING
   Glauner P.O., 2015, ARXIV150806535
   Gudi A., 2015, AUT FAC GEST REC FG, V6, P1, DOI DOI 10.1109/FG.2015.7284873
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Hammal Z., 2012, 14 ACM INT C MULT IN
   Jaiswal  S., 2016, 2016 IEEE WINT C APP, P1
   Jeni LA, 2013, 10 IEEE INT C WORKSH, P1
   Kaltwang S., 2015, REGRESSION BASED EST
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Lucey P, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, V2010, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Mavadati SM, 2014, INT C PATT RECOG, P4648, DOI 10.1109/ICPR.2014.795
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   McKeown G, 2015, EMOT REV, V7, P30, DOI 10.1177/1754073914544475
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Murphy K. P., 2002, THESIS U CALIFORNIA
   Sandbach G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P738, DOI 10.1109/ICCVW.2013.101
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Simonyan K., 2014, ARXIV14091556
   TOSER Z, 2016, COMP VISION ECCV, V9915, P359
   Valstar M., 2017, ARXIV170204174
   Valstar M.F., 2015, 2015 11 IEEE INT C W, V6, P1
   Valstar M. F., 2010, P INT C LANG RES EV, P65
   Yosinski J, 2014, 27 INT C NEUR INF PR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Y, 2015, EXPERT SYST APPL, V42, P1446, DOI 10.1016/j.eswa.2014.08.042
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhou Y., 2017, P IEEE INT JOINT C N
NR 33
TC 3
Z9 3
SN 2326-5396
BN 978-1-5090-4023-0
PY 2017
BP 872
EP 877
DI 10.1109/FG.2017.112
UT WOS:000414287400120
ER

PT S
AU Dong, B
   An, ZF
   Lin, J
   Deng, WH
AF Dong, Bin
   An, Zhanfu
   Lin, Jian
   Deng, Weihong
GP IEEE
TI Attention-Based Template Adaptation for Face Verification
SO 2017 12TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE
   RECOGNITION (FG 2017)
SE IEEE International Conference on Automatic Face and Gesture Recognition
   and Workshops
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
AB In this paper, we propose an Attention-Based Template Adaptation (termed as ABTA) algorithm for face recognition in the unconstrained environment. This ABTA algorithm can be divided into two modules, which consist of an attention-based neural network (feature extractor module) to integrate the template features of various lengths to a single fixed length feature representation according to the attention mechanism, and a template adaptation module (transfer module) which is used to transfer the knowledge of a hold-out dataset to the test templates to improve the performance via transfer learning. The feature extractor module is invariant to the order of the images and videos and can save both memory and computation resources due to its compactness. As for the transfer module, we apply the one-shot similarity to get the scores between the test template pairs, which demonstrates its power in recent research. Our method produces results comparable to the state-of-the-art in the challenging face dataset, IJB-A.
CR Abdalmageed  W., 2016, 2016 IEEE WINT C APP, P1
   Chen J. P., 2016, 2016 Compound Semiconductor Week (CSW) [includes 28th International Conference on Indium Phosphide & Related Materials (IPRM) and 43rd International Symposium on Compound Semiconductors (ISCS)], P1, DOI [10.1109/ICCE-TW.2016.7520909, 10.1109/ICIPRM.2016.7528763]
   Chowdhury Animesh R., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534285
   Crosswhite N., 2016, CORR
   Damer N, 2015, LECT NOTES COMPUT SC, V8912, P85, DOI 10.1007/978-3-319-13737-7_8
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Graves Alex, 2014, CORR
   Hassner T., 2016, CORR
   Huang G. B., 2007, 0749 U MASS
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkhi O. M., 2015, BRIT MACH VIS C
   Ranjan R., 2016, ARXIV161100851
   Sankaranarayanan S., 2016, CORR
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Song H. O., 2015, DEEP METRIC LEARNING, P4004
   Sukhbaatar S., 2015, END END MEMORY NETWO, P2440
   Sun Y., 2013, IEEE C COMP VIS PATT
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, DEEP LEARNING FACE R, P1988
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wolf L, 2009, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2009.5459323
   Yang J., 2016, CORR
NR 28
TC 1
Z9 1
SN 2326-5396
BN 978-1-5090-4023-0
PY 2017
BP 941
EP 946
DI 10.1109/FG.2017.116
UT WOS:000414287400130
ER

PT B
AU Xia, XL
   Xu, C
   Nan, B
AF Xia, Xiaoling
   Xu, Cui
   Nan, Bing
GP IEEE
TI Inception-v3 for Flower Classification
SO 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC
   2017)
CT 2nd International Conference on Image, Vision and Computing (ICIVC)
CY JUN 02-04, 2017
CL Chengdu, PEOPLES R CHINA
DE flower classification; TensorFlow; inception-v3; transfer learning
ID RECOGNITION
AB The study of flower classification system is a very important subject in the field of Botany. A classifier of flowers with high accuracy will also bring a lot of fun to people's lives. However, because of the complex background of flowers, the similarity between the different species of flowers, and the differences among the same species of flowers, there are still some challenges in the recognition of flower images. The traditional flower classification is mainly based on the three features: color, shape and texture, this classification requires people to select features for classification, and the accuracy is not very high. In this paper, based on Inception-v3 model of TensorFlow platform, we use the transfer learning technology to retrain the flower category datasets, which can greatly improve the accuracy of flower classification.
CR Abadi M., 2016, CORR
   ANGELOVA A, 2013, COMP VIS PATT REC IE, P811, DOI DOI 10.1109/CVPR.2013.110
   Ioffe S., 2015, ICML, P448
   Krizhevsky A., 2014, NIPS, P1106
   Nilsback M., 2009, THESIS
   Nilsback ME, 2010, IMAGE VISION COMPUT, V28, P1049, DOI 10.1016/j.imavis.2009.10.001
   Nilsback Maria-Elena, 2006, CVPR, V2006, P1447, DOI DOI 10.1109/CVPR.2006.42
   Nilsback Maria-Elena, 2007, BMVC, V2007, P1
   Nilsback Maria-Elena, 2008, ICVGIP, V2008, P722
   Saitoh T, 2004, INT C PATT RECOG, P27, DOI 10.1109/ICPR.2004.1333997
   Saxena A., 2016, ACM CROSSROADS, V22, P56
   Szegedy C, 2015, ARXIV151200567
   Szegedy C., 2014, 14094842 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
   Xie Xiaodong, 2014, RES FINE GRAINED CLA
   Zou J, 2004, INT C PATT RECOG, P311, DOI 10.1109/ICPR.2004.1334185
NR 15
TC 4
Z9 4
BN 978-1-5090-6238-6
PY 2017
BP 783
EP 787
UT WOS:000414298700154
ER

PT B
AU Sato, M
   Orihara, R
   Sei, Y
   Tahara, Y
   Ohsuga, A
AF Sato, Minato
   Orihara, Ryohei
   Sei, Yuichi
   Tahara, Yasuyuki
   Ohsuga, Akihiko
BE VanDenHerik, J
   Rocha, AP
   Filipe, J
TI Japanese Text Classification by Character-level Deep ConvNets and
   Transfer Learning
SO ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE, VOL 2
CT 9th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 24-26, 2017
CL Porto, PORTUGAL
DE Deep Learning; Temporal ConvNets; Transfer Learning; Text
   Classification; Sentiment Analysis
AB Temporal (one-dimensional) Convolutional Neural Network ( Temporal CNN, ConvNet) is an emergent technology for text understanding. The input for the ConvNets could be either a sequence of words or a sequence of characters. In the latter case there are no needs for natural language processing that depends on a language such as morphological analysis. Past studies showed that the character-level ConvNets worked well for news category classification and sentiment analysis / classification tasks in English and romanized Chinese text corpus. In this article we apply the character-level ConvNets to Japanese text understanding. We also attempt to reuse meaningful representations that are learned in the ConvNets from a large-scale dataset in the form of transfer learning, inspired by its success in the field of image recognition. As for the application to the news category classification and the sentiment analysis and classification tasks in Japanese text corpus, the ConvNets outperformed N-gram-based classifiers. In addition, our ConvNets transfer learning frameworks worked well for a task which is similar to one used for pre-training.
CR AGRAWAL P, 2014, P 13 EUR C COMP, V8695, P329
   Bengio Y., 2013, P 2013 IEEE INT C AC
   Chollet  F., 2015, KERAS
   Del Corso G. M., 2005, P 14 INT C WORLD WID, P97
   Deng J., 2009, P 2009 IEEE C COMP V
   Gatti  M., 2014, COLING, P69
   Girshick R, 2014, P 2014 IEEE C COMP V
   Glorot X, 2010, P 13 INT C ART INT S
   Glorot X, 2011, P 28 INT C MACH LEAR
   Gulli A., 2005, INT C WORLD WID WEB, P880
   Kim  Y., 2014, P 2014 C EMP METH NA, P1746, DOI DOI 10.3115/V1/D14-1181
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Kudo T., 2004, P 2004 C EMP METH NA, P230
   Maas A. L., 2011, P 49 ANN M ASS COMP, P142
   McAuley J. J., 2015, P 21 ACM SIGKDD INT, P785, DOI [10.1145/2783258.2783381, DOI 10.1145/2783258.2783381]
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Mikolov T., 2013, P NAACL 2013, P746
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Santos C. N. dos, 2015, P ANN M ASS COMP LIN, V1, P626
   Severyn A., 2015, P 9 INT WORKSH SEM E, P464
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Sharif Razavian  A., 2014, IEEE C COMP VIS PATT
   Socher R., 2013, P C EMP METH NAT LAN, P1631
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Theano Development Team, 2016, ABS160502688 THEAN D
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649
   Zhang Xucong, 2015, CORR
NR 28
TC 1
Z9 1
BN 978-989-758-220-2
PY 2017
BP 175
EP 184
DI 10.5220/0006193401750184
UT WOS:000413244200016
ER

PT B
AU Chen, XY
   Lengelle, R
AF Chen, Xiaoyi
   Lengelle, Regis
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Domain Adaptation Transfer Learning by SVM Subject to a
   Maximum-Mean-Discrepancy-like Constraint
SO ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN
   RECOGNITION APPLICATIONS AND METHODS
CT 6th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY FEB 24-26, 2017
CL Porto, PORTUGAL
DE Transfer Learning; Kernel; SVM; Maximum Mean Discrepancy
ID KERNEL
AB This paper is a contribution to solving the domain adaptation problem where no labeled target data is available. A new SVM approach is proposed by imposing a zero-valued Maximum Mean Discrepancy-like constraint. This heuristic allows us to expect a good similarity between source and target data, after projection onto an efficient subspace of a Reproducing Kernel Hilbert Space. Accordingly, the classifier will perform well on source and target data. We show that this constraint does not modify the quadratic nature of the optimization problem encountered in classic SVM, so standard quadratic optimization tools can be used. Experimental results demonstrate the competitiveness and efficiency of our method.
CR Blitzer J., 2007, ANN M ASS COMP LING, V7, P440, DOI DOI 10.1109/IRPS.2011.5784441
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Dudley R. M, 1984, ECOLE ETE PROBABILIT, P1
   DUDLEY R. M., 2002, REAL ANAL PROBABILIT, V74
   Fortet R, 1953, ANN SCI ECOLE NORM S, P266
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Huang CH, 2012, LECT NOTES COMPUT SC, V7583, P342, DOI 10.1007/978-3-642-33863-2_34
   Huang J., 2006, ADV NEURAL INFORM PR, V19, P601
   Jiang J., 2008, LIT SURVEY DOMAIN AD
   Li L., 2011, P 20 INT C WORLD WID, P287
   Liang FD, 2014, MACH VISION APPL, V25, P1697, DOI 10.1007/s00138-013-0549-2
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Paulsen V. I, 2009, LECT NOTES
   Quanz  Brian, 2009, CIKM, P1327, DOI DOI 10.1145/1645953.1646121
   REN JT, 2010, ADV DATA MINING APPL, V6441, P63
   SCHOLKOPF B, 2001, COMPUTATIONAL LEARNI, V2111, P416
   Serfling R J., 2009, APPROXIMATION THEORE, V162
   SMOLA A, 2007, ALGORITHMIC LEARNING, V4754, P13
   Smola A, 2006, 13 INT C ICONIP 2006
   Steinwart I, 2002, J MACH LEARN RES, V2, P67
   Tan Q., 2012, ADV DATA MINING APPL, V7713, P223, DOI [10.1007/978-3-642-35527-119, DOI 10.1007/978-3-642-35527-119]
   Tohme M, 2008, MACHINE LEARN SIGN P, P339, DOI 10.1109/MLSP.2008.4685503
   UGUROGLU S, 2011, MACHINE LEARNING KNO, V6913, P430
   Yang SZ, 2012, NEURAL COMPUT APPL, V21, P1801, DOI 10.1007/s00521-012-1084-1
   Zhang P, 2009, IEEE DATA MINING, P627, DOI 10.1109/ICDM.2009.76
   Zhang ZH, 2012, PATTERN RECOGN, V45, P465, DOI 10.1016/j.patcog.2011.05.011
NR 28
TC 1
Z9 1
BN 978-989-758-222-6
PY 2017
BP 89
EP 95
DI 10.5220/0006119900890095
UT WOS:000413240500009
ER

PT B
AU Eduardo, A
   Aidos, H
   Fred, A
AF Eduardo, Afonso
   Aidos, Helena
   Fred, Ana
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI ECG-based Biometrics using a Deep Autoencoder for Feature Learning An
   Empirical Study on Transferability
SO ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN
   RECOGNITION APPLICATIONS AND METHODS
CT 6th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY FEB 24-26, 2017
CL Porto, PORTUGAL
DE Biometrics; User Identification; Electrocardiogram (ECG); Deep Learning;
   Feature Learning; Transfer Learning; Deep Autoencoder
ID IDENTIFICATION
AB Biometric identification is the task of recognizing an individual using biological or behavioral traits and, recently, electrocardiogram has emerged as a prominent trait. In addition, deep learning is a fast-paced research field where several models, training schemes and applications are being actively investigated. In this paper, an ECG-based biometric system using a deep autoencoder to learn a lower dimensional representation of heartbeat templates is proposed. A superior identification performance is achieved, validating the expressiveness of such representation. A transfer learning setting is also explored and results show practically no loss of performance, suggesting that these deep learning methods can be deployed in systems with offline training.
OI Aidos, Helena/0000-0001-6827-4217
CR Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Carreiras C, 2016, LECT NOTES ELECTR EN, V370, P111, DOI 10.1007/978-3-319-26453-0_7
   Cohen Nadav, 2016, JMLR WORKSHOP C P, V49, P1
   Del Testa D, 2015, IEEE SIGNAL PROC LET, V22, P2304, DOI 10.1109/LSP.2015.2476667
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Eldan R., 2016, JMLR WORKSHOP C P, V49, P1
   Fratini A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0072-y
   Glorot X., 2010, JLMR P TRACK, P249, DOI DOI 10.1.1/207.2059
   Goodfellow I., 2016, DEEP LEARNING UNPUB
   Goodfellow Ian, 2014, ADV NEURAL INFORM PR, V27
   Jain A. K., 2016, PATTERN RECOGN, V79, P1
   Jones E, 2001, SCIPY OPEN SOURCE SC
   Kingma D. P., 2014, 2 INT C LEARN REPR I
   Kingma Diederik P., 2015, 3 INT C LEARN REPR I
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lourenco A, 2013, LECT NOTES COMPUT SC, V7950, P43, DOI 10.1007/978-3-642-39094-4_6
   Marques Francisco, 2015, BIOSIGNALS 2015. 8th International Conference on Bio-Inspired Systems and Signal Processing. Proceedings, P350
   Martinez HP, 2013, IEEE COMPUT INTELL M, V8, P20, DOI 10.1109/MCI.2013.2247823
   McSharry PE, 2003, IEEE T BIO-MED ENG, V50, P289, DOI 10.1109/TBME.2003.808805
   Odinaka I, 2012, IEEE T INF FOREN SEC, V7, P1812, DOI 10.1109/TIFS.2012.2215324
   Page A., 2015, IEEE BIOM CIRC SYST
   Rattani A., 2015, ADV COMPUTER VISION
   Roli F., 2008, ADV BIOMETRICS SENSO, P447, DOI DOI 10.1007/978-1-84628-921-7
   Sameni R, 2007, IEEE T BIO-MED ENG, V54, P2172, DOI 10.1109/TBME.2007.897817
   Shen T. W., 2002, Conference Proceedings. Second Joint EMBS-BMES Conference 2002. 24th Annual International Conference of the Engineering in Medicine and Biology Society. Annual Fall Meeting of the Biomedical Engineering Society (Cat. No.02CH37392), P62, DOI 10.1109/IEMBS.2002.1134388
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377
   Theano Development Team:, 2016, ABS160502688 ARXIV T
   Vincent P., 2008, P 25 INT C MACH LEAR
   Wan Y., 2008, P WORLD C ENG COMP S
   Xiong P, 2015, J MED IMAG HEALTH IN, V5, P1804, DOI 10.1166/jmihi.2015.1649
   Yosinski J., 2014, ADV NEURAL INF PROCE, V27, P1
NR 34
TC 1
Z9 1
BN 978-989-758-222-6
PY 2017
BP 463
EP 470
DI 10.5220/0006195404630470
UT WOS:000413240500055
ER

PT S
AU Heravi, EJ
   Aghdam, HH
   Puig, D
AF Heravi, Elnaz J.
   Aghdam, Hamed H.
   Puig, Domenec
BE Verikas, A
   Radeva, P
   Nikolaev, DP
   Zhang, W
   Zhou, J
TI Classification of foods by transferring knowledge from ImageNet dataset
SO NINTH INTERNATIONAL CONFERENCE ON MACHINE VISION (ICMV 2016)
SE Proceedings of SPIE
CT 9th International Conference on Machine Vision (ICMV)
CY NOV 18-20, 2016
CL Nice, FRANCE
DE Food classification; Convolutional neural network; Deep learning;
   Transfer learning
AB Automatic classification of foods is a way to control food intake and tackle with obesity. However, it is a challenging problem since foods are highly deformable and complex objects. Results on ImageNet dataset have revealed that Convolutional Neural Network has a great expressive power to model natural objects. Nonetheless, it is not trivial to train a ConyNet from scratch for classification of foods. This is due to the fact that ConyNets require large datasets and to our knowledge there is not a large public dataset of food for this purpose. Alternative solution is to transfer knowledge from trained ConyNets to the domain of foods. In this work, we study how transferable are state-of-art ConyNets to the task of food classification. We also propose a method for transferring knowledge from a bigger ConyNet to a smaller ConyNet by keeping its accuracy similar to the bigger ConyNet. Our experiments on UECFood256 datasets show that Googlenet, VGG and residual networks produce comparable results if we start transferring knowledge from appropriate layer. In addition, we show that our method is able to effectively transfer knowledge to the smaller ConyNet using unlabelled samples.
CR Christodoulidis S., 2015, FOOD RECOGNITION DIE, P458
   Fanyu Kong, 2011, 2011 8th International Conference on Body Sensor Networks (BSN), P127, DOI 10.1109/BSN.2011.19
   He K, 2015, ARXIV150601497
   Heravi E. J., 2015, 8 INT C MACH VIS ICM
   Hoashi H, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P296, DOI 10.1109/ISM.2010.51
   Kawano Y., 2015, AUTOMATIC EXPANSION, P3
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Matsuda Y, 2012, INT C PATT RECOG, P2017
   Simonyan K., 2015, INT C LEARN REPR ICL, P1
   Szegedy C., 2015, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Yanai K., 2015, IEEE INT C MULT EXP, P1
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
NR 13
TC 0
Z9 0
SN 0277-786X
EI 1996-756X
BN 978-1-5106-1132-0
PY 2017
VL 10341
AR UNSP 1034128
DI 10.1117/12.2268737
UT WOS:000410664800079
ER

PT S
AU Ng, CB
   Tay, YH
   Goi, BM
AF Ng, Choon-Boon
   Tay, Yong-Haur
   Goi, Bok-Min
BE Jiang, X
   Arai, M
   Chen, G
TI Training Strategy for Convolutional Neural Networks in Pedestrian Gender
   Classification
SO SECOND INTERNATIONAL WORKSHOP ON PATTERN RECOGNITION
SE Proceedings of SPIE
CT 2nd International Workshop on Pattern Recognition
CY MAY 01-03, 2017
CL Singapore, SINGAPORE
DE convolutional neural network; deep learning; pedestrian; gender
   classification; k-means; transfer learning
AB In this work, we studied a strategy for training a convolutional neural network in pedestrian gender classification with limited amount of labeled training data. Unsupervised learning by k-means clustering on pedestrian images was used to learn the filters to initialize the first layer of the network. As a form of pre-training, supervised learning for the related task of pedestrian classification was performed. Finally, the network was fine-tuned for gender classification. We found that this strategy improved the network's generalization ability in gender classification, achieving better test results when compared to random weights initialization and slightly more beneficial than merely initializing the first layer filters by unsupervised learning. This shows that unsupervised learning followed by pre-training with pedestrian images is an effective strategy to learn useful features for pedestrian gender classification.
RI Tay, Yong Haur/S-4394-2017
OI Tay, Yong Haur/0000-0002-9101-7080; Goi, Bok Min/0000-0002-9854-7121
CR Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chapelle O, 2006, SEMISUPERVISED LEARN
   Coates Adam, 2011, INT C ART INT STAT, P215
   Collins M., 2009, IEEE INT C COMP VIS, P1235
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dikman M, 2008, P 16 ACM INT C MULT, P725, DOI DOI 10.1145/1459359.1459470
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo GD, 2010, LECT NOTES COMPUT SC, V5996, P236
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106
   Ng CB, 2013, 2013 FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, MODELLING AND SIMULATION (AIMS 2013), P29, DOI 10.1109/AIMS.2013.13
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   Overett Gary, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P373, DOI 10.1109/IVS.2008.4621297
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zhu JQ, 2015, LECT NOTES COMPUT SC, V9010, P545, DOI 10.1007/978-3-319-16634-6_40
NR 16
TC 0
Z9 0
SN 0277-786X
BN 978-1-5106-1350-8; 978-1-5106-1351-5
PY 2017
VL 10443
AR UNSP 104431A
DI 10.1117/12.2280487
UT WOS:000406968700045
ER

PT S
AU Dong, Q
   Gong, SG
   Zhu, XT
AF Dong, Qi
   Gong, Shaogang
   Zhu, Xiatian
GP IEEE
TI Multi-Task Curriculum Transfer Deep Learning of Clothing Attributes
SO 2017 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV
   2017)
SE IEEE Winter Conference on Applications of Computer Vision
CT 17th IEEE Winter Conference on Applications of Computer Vision (WACV)
CY MAR 24-31, 2017
CL Santa Rosa, CA
ID ADAPTATION
AB Recognising detailed clothing characteristics (fine-grained attributes) in unconstrained images of people in-the-wild is a challenging task for computer vision, especially when there is only limited training data from the wild whilst most data available for model learning are captured in well-controlled environments using fashion models (well lit, no background clutter, frontal view, high-resolution). In this work, we develop a deep learning framework capable of model transfer learning from well-controlled shop clothing images collected from web retailers to in-the-wild images from the street. Specifically, we formulate a novel MultiTask Curriculum Transfer (MTCT) deep learning method to explore multiple sources of different types of web annotations with multi-labelled fine-grained attributes. Our multi-task loss function is designed to extract more discriminative representations in training by jointly learning all attributes, and our curriculum strategy exploits the staged easy-to-hard transfer learning motivated by cognitive studies. We demonstrate the advantages of the MTCT model over the state-of-the-art methods on the X-Domain benchmark, a large scale clothing attribute dataset. Moreover, we show that the MTCT model has a notable advantage over contemporary models when the training data size is small.
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Bengio Y., 2009, P 26 ANN INT C MACH, P41, DOI DOI 10.1145/1553374.1553380
   Bengio Y., 2012, J MACHINE LEARNING R, P17
   Bengio Y., 2011, JMLR P AISTATS, P164
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bossard Lukas, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P321, DOI 10.1007/978-3-642-37447-0_25
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Deng Y., 2014, P 22 ACM INT C MULT, P789, DOI DOI 10.1145/2647868.2654966
   Ding ZM, 2016, INT CONF ACOUST SPEE, P2414, DOI 10.1109/ICASSP.2016.7472110
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Feris R., 2014, P INT C MULT RETR, P153
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Fu  Jianlong, 2012, P AS C COMP VIS, P420
   Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249
   Hoffman J., 2013, ARXIV E PRINTS
   Hu J, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   Huang J., 2015, IEEE INT C COMP VIS
   Jia Y., 2014, P 22 ACM INT C MULT, P675, DOI DOI 10.1145/2647868.2654889
   Kiapour M. H., 2015, IEEE INT C COMP VIS
   Kiapour MH, 2014, LECT NOTES COMPUT SC, V8689, P472, DOI 10.1007/978-3-319-10590-1_31
   Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Krueger KA, 2009, COGNITION, V110, P380, DOI 10.1016/j.cognition.2008.11.014
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Layne R., 2012, BMVC, P8
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Lin M., 2013, ARXIV E PRINTS
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405
   Razavian A. Sharif, 2014, P IEEE C COMP VIS PA, P806
   Ren S, 2015, ADV NEURAL INFORM PR, P91
   Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1
   Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sermanet P., 2014, INT C LEARN REPR
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Simonyan K., 2015, INT C LEARN REPR
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tsuhan C., 2008, P IEEE C COMP VIS PA, P1
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   van der Maaten L, 2012, MACH LEARN SIGN PROC, P1
   Vaquero D. A., 2009, 2009 WORKSH APPL COM, P1, DOI DOI 10.1109/WACV.2009.5403131
   Wang  Xianwang, 2011, P 19 ACM INT C MULT, P1353
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 59
TC 5
Z9 5
SN 2472-6737
BN 978-1-5090-4822-9
PY 2017
BP 520
EP 529
DI 10.1109/WACV.2017.64
UT WOS:000404165800057
ER

PT S
AU Sakla, W
   Konjevod, G
   Mundhenk, TN
AF Sakla, Wesam
   Konjevod, Goran
   Mundhenk, T. Nathan
GP IEEE
TI Deep Multi-Modal Vehicle Detection in Aerial ISR Imagery
SO 2017 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV
   2017)
SE IEEE Winter Conference on Applications of Computer Vision
CT 17th IEEE Winter Conference on Applications of Computer Vision (WACV)
CY MAR 24-31, 2017
CL Santa Rosa, CA
AB Since the introduction of deep convolutional neural networks (CNNs), object detection in imagery has witnessed substantial breakthroughs in state-of-the-art performance. The defense community utilizes overhead image sensors that acquire large field-of-view aerial imagery in various bands of the electromagnetic spectrum, which is then exploited for various applications, including the detection and localization of man-made objects. In this work, we utilize a recent state-of-the art object detection algorithm, faster R-CNN, to train a deep CNN for vehicle detection in multimodal imagery. We utilize the vehicle detection in aerial imagery (VEDAI) dataset, which contains overhead imagery that is representative of an ISR setting. Our contribution includes modification of key parameters in the faster R-CNN algorithm for this setting where the objects of interest are spatially small, occupying less than 1.5 x 10(-3) of the total image pixels. Our experiments show that (1) an appropriately trained deep CNN leads to average precision rates above 93% on vehicle detection, and (2) transfer learning between imagery modalities is possible, yielding average precision rates above 90% in the absence of fine-tuning.
CR [Anonymous], 2012, UTAH AGRC WEBSITE, P3
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R., 2015, P INT C COMP VIS ICC, P2
   Goodfellow I., 2016, DEEP LEARNING UNPUB, P1
   He K., 2016, CVPR, p[2, 3, 5, 6]
   Jia Y., 2014, ACM MULTIMEDIA, V2, P4
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu W., 2016, EUR C COMP VIS ECCV, P2
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J., 2016, IEEE C COMP VIS PATT, p[2, 3, 4]
   Ren S., 2015, NIPS, P1, DOI DOI 10.1016/J.NIMA.2015.05.028.
   Sermanet P., 2014, INT C LEARN REPR, P2
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Uijlings J., 2013, INT J COMPUT VISION, P2
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 22
TC 8
Z9 8
SN 2472-6737
BN 978-1-5090-4822-9
PY 2017
BP 916
EP 923
DI 10.1109/WACV.2017.107
UT WOS:000404165800097
ER

PT S
AU Orenstein, EC
   Beijbom, O
AF Orenstein, Eric C.
   Beijbom, Oscar
GP IEEE
TI Transfer Learning and Deep Feature Extraction for Planktonic Image Data
   Sets
SO 2017 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV
   2017)
SE IEEE Winter Conference on Applications of Computer Vision
CT 17th IEEE Winter Conference on Applications of Computer Vision (WACV)
CY MAR 24-31, 2017
CL Santa Rosa, CA
ID INSTRUMENT
AB Studying marine plankton is critical to assessing the health of the world's oceans. To sample these important populations, oceanographers are increasingly using specially engineered in situ digital imaging systems that produce very large data sets. Most automated annotation efforts have considered data from individual systems in isolation. This is predicated on the assumption that the images from each system are so different that there would be little benefit to considering out-of-domain data. Meanwhile, in the computer vision community, much effort has been dedicated to understanding how using out-of-domain images can improve the performance of machine classifiers. In this paper, we leverage these advances to evaluate how well weights transfer between Convolutional Neural Networks (CNNs) trained on data from two radically different plankton imaging systems. We also examine the utility of CNNs as feature extractors on a third unique plankton data set. Our results indicate that these data sets are perhaps more similar in the eyes of a machine classifier than previously assumed. Further, these tests underscore the value of using the rich feature representations learned by CNNs to classify data in vastly different domains.
CR Arrigo KR, 2005, NATURE, V437, P349, DOI 10.1038/nature04158
   Benfield MC, 2007, OCEANOGRAPHY, V20, P172, DOI 10.5670/oceanog.2007.63
   Bengio Y., 2012, J MACHINE LEARNING R, P17
   Blaschko MB, 2005, IEEE WACV MOTIONS, V1, P79, DOI DOI 10.1109/ACVM0T.2005.29
   Cowen R. K., 2015, NOAA NATL CTR ENVIRO
   Cowen RK, 2008, LIMNOL OCEANOGR-METH, V6, P126, DOI 10.4319/lom.2008.6.126
   Culverhouse PF, 2014, MAR BIOL RES, V10, P73, DOI 10.1080/17451000.2013.810762
   Daume H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   Donahue J., 2014, P 31 INT C MACH LEAR, P647
   Ellen J., 2015, OCEANS 2015 MTS IEEE, P1
   Glorot X., 2011, P 28 INT C MACH LEAR, P513
   Grosjean P., 2004, J MAR SCI, V61, P518, DOI [10.1016/j.icesjms.2004.03.012, DOI 10.1016/J.ICESJMS.2004.03.012]
   Hays GC, 2005, TRENDS ECOL EVOL, V20, P337, DOI 10.1016/j.tree.2005.03.004
   Jia Y., 2014, ARXIV14085093
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Olson RJ, 2007, LIMNOL OCEANOGR-METH, V5, P195, DOI 10.4319/lom.2007.5.195
   Orenstein E. C., 2015, ARXIV151000745
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Picheral M, 2010, LIMNOL OCEANOGR-METH, V8, P462, DOI 10.4319/lom.2010.8.462
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Roberts P. L., 2014, OCEAN OPTICS 22
   Sosik H. M., 2016, IMAGING FLOWCYTOBOT
   Sosik HM, 2007, LIMNOL OCEANOGR-METH, V5, P204, DOI 10.4319/lom.2007.5.204
   Steel JH, 1978, SPATIAL PATTERN PLAN, P277
   Yosinski J., 2015, ARXIV150606579
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zeiler M D, 2014, ECCV, P818, DOI [DOI 10.1007/978331910590-1_53, 10.1007/978-3-319-10590-1_53]
NR 27
TC 0
Z9 0
SN 2472-6737
BN 978-1-5090-4822-9
PY 2017
BP 1082
EP 1088
DI 10.1109/WACV.2017.125
UT WOS:000404165800115
ER

PT S
AU Gideon, J
   Khorram, S
   Aldeneh, Z
   Dimitriadis, D
   Provost, EM
AF Gideon, John
   Khorram, Soheil
   Aldeneh, Zakaria
   Dimitriadis, Dimitrios
   Provost, Emily Mower
GP Int Speech Commun Assoc
TI Progressive Neural Networks for Transfer Learning in Emotion Recognition
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE neural networks; transfer learning; progressive neural networks;
   computational paralinguistics; emotion recognition
AB Many paralinguistic tasks are closely related and thus representations learned in one domain can be leveraged for another. In this paper, we investigate how knowledge can be transferred between three paralinguistic tasks: speaker, emotion, and gender recognition. Further, we extend this problem to cross-dataset tasks. asking how knowledge captured in one emotion dataset can be transferred to another. We focus on progressive neural networks and compare these networks to the conventional deep learning method of pre-training and fine-tuning. Progressive neural networks provide a way to transfer knowledge and avoid the forgetting effect present when pre-training neural networks on different tasks. Our experiments demonstrate that: (I) emotion recognition can benefit from using representations originally learned for different paralinguistic tasks and (2) transfer learning can effectively leverage additional datasets to improve the performance of emotion recognition systems.
CR Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3056, P3
   Busso C., 2016, IEEE T AFFECTIVE COM
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Das A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3531
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Fahlman S. E., 1990, CASCADE CORRELATION
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Kim Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P92, DOI 10.1145/2993148.2993151
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lotfian R., 2016, P INTERSPEECH
   Mou L., 2016, ARXIV160306111
   Rusu A. A., 2016, ARXIV161004286
   Rusu A. A., 2016, ARXIV160604671
   Schuller B., 2009, INTERSPEECH, V2009, P312
   Schuller B, 2013, COMPUT SPEECH LANG, V27, P1, DOI 10.1016/j.csl.2012.06.002
   Sidorov M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3476
   Ververidis Dimitrios, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P341
   Vogt T., 2006, P LANG RES EV C LREC
   Xia R., 2015, IEEE T AFFECTIVE COM
   Zhang BQ, 2016, INT CONF ACOUST SPEE, P5805, DOI 10.1109/ICASSP.2016.7472790
NR 21
TC 3
Z9 3
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 1098
EP 1102
DI 10.21437/Interspeech.2017-1637
UT WOS:000457505000230
ER

PT S
AU Luo, QY
   Gupta, R
   Narayanan, S
AF Luo, Qinyi
   Gupta, Rahul
   Narayanan, Shrikanth
GP Int Speech Commun Assoc
TI Transfer Learning between Concepts for Human Behavior Modeling: An
   Application to Sincerity and Deception Prediction
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE Transfer Learning (TL); sincerity prediction; deception prediction
AB Transfer learning (TL) involves leveraging information from sources outside the domain at hand for enhancing model performances. Popular TL methods either directly use the data or adapt the models learned on out-of-domain resources and incorporate them within in-domain models. TL methods have shown promise in several applications such as text classification, cross domain language classification and emotion recognition. In this paper, we propose TL methods to computational human behavioral trait modeling. Many behavioral traits are abstract constructs (e.g., sincerity of an individual), and are often conceptually related to other constructs (e.g., level of deception) making TL methods an attractive option for their modeling. We consider the problem of automatically predicting human sincerity and deception from behavioral data while leveraging transfer of knowledge from each other. We compare our methods against baseline models trained only on in-domain data. Our best models achieve an Unweighted Average Recall (UAR) of 72.02% in classifying deception (baseline: 69.64%). Similarly, applied methods achieve Spearman's/Pearson's correlation values of 49.37%/48.52% between true and predicted sincerity scores (baseline: 46.51%/41.58%), indicating the success and the potential of TL for such human behavior tasks.
CR Aggarwal C. C., 2012, MINING TEXT DATA
   Arnold A., 2007, 7 IEEE INT C DAT MIN, P77, DOI DOI 10.1109/ICDMW.2007.109
   Bengio Y., 2012, J MACHINE LEARNING R, P17
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   Blitzer J., 2007, ANN M ASS COMP LING, V7, P440, DOI DOI 10.1109/IRPS.2011.5784441
   Bone D, 2015, J AUTISM DEV DISORD, V45, P1121, DOI 10.1007/s10803-014-2268-6
   Caraiman S, 2009, CF'09: CONFERENCE ON COMPUTING FRONTIERS & WORKSHOPS, P81
   Chen JX, 2013, PATTERN RECOGN LETT, V34, P1964, DOI 10.1016/j.patrec.2013.02.002
   Dauphin G, 2012, JMLR P TRACK, P97
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freitas AA, 1999, KNOWL-BASED SYST, V12, P309, DOI 10.1016/S0950-7051(99)00019-2
   Gbor Gosztolya G. S., 2016, P INT SAN FRANC US S
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gupta R, 2016, COMPUT SPEECH LANG, V37, P47, DOI 10.1016/j.csl.2015.09.003
   Hums  R., 2016, P INT SAN FRANC US S
   Jiang J., 2008, LIT SURVEY DOMAIN AD
   Kaya  H., 2016, P INT SAN FRANC US S
   Luo LB, 2008, COMPUT ANIMAT VIRT W, V19, P271, DOI 10.1002/cav.238
   MCFALL L, 1987, ETHICS, V98, P5, DOI 10.1086/292912
   Narayanan S, 2013, P IEEE, V101, P1203, DOI 10.1109/JPROC.2012.2236291
   Pan S. J., 2008, AAAI, P677
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pratt L. Y., 1993, ADV NEURAL INFORM PR, P204
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Rohrbach Marcus, 2013, ADV NEURAL INFORM PR, P46
   Sangineto  E., 2014, P ACM INT C MULT, P357, DOI [10.1145/2647868.2654916, DOI 10.1145/2647868.2654916]
   Schuller  B., 2015, P INTERSPEECH
   Schuller B. W., 2013, ACOUSTICS EMOTION AU
   Schuller  Bjorn, 2016, P INT
   Stinchfield F. H., 1936, IND L J, V12, P449
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   TORIS C, 1984, J PERS SOC PSYCHOL, V47, P1063, DOI 10.1037//0022-3514.47.5.1063
   Vapnik V. N., 1998, STAT LEARNING THEORY, V1
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wu P., 2004, P 21 INT C MACH LEAR, P110
   Yue Zhang Z. R., 2016, P INT SAN FRANC US S
   Zhang ZX, 2016, INT CONF ACOUST SPEE, P5185, DOI 10.1109/ICASSP.2016.7472666
NR 38
TC 0
Z9 0
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 1462
EP 1466
DI 10.21437/Interspeech.2017-121
UT WOS:000457505000303
ER

PT S
AU Das, A
   Hasegawa-Johnson, M
   Vesely, K
AF Das, Amit
   Hasegawa-Johnson, Mark
   Vesely, Karel
GP Int Speech Commun Assoc
TI Deep Auto-encoder Based Multi-task Learning Using Probabilistic
   Transcriptions
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE cross-lingual speech recognition; probabilistic transcription; deep
   neural networks; multi-task learning
AB We examine a scenario where we have no access to native transcribers in the target language. This is typical of language communities that are under-resourced. However, turkers (online crowd workers) available in online marketplaces can serve as valuable alternative resources for providing transcripts in the target language. We assume that the turkers neither speak nor have any familiarity with the target language. Thus, they are unable to distinguish all phone pairs in the target language; their transcripts therefore specify, at best, a probability distribution called a probabilistic transcript (PT). Standard deep neural network (DNN) training using PTs do not necessarily improve error rates. Previously reported results have demonstrated some success by adopting the multi-task learning (MTL) approach. In this study, we report further improvements by introducing a deep auto-encoder based MTL. This method leverages large amounts of untranscribed data in the target language in addition to the PTs obtained from turkers. Furthermore, to encourage transfer learning in the feature space, we also examine the effect of using monophones from transcripts in well-resourced languages. We report consistent improvement in phone error rates (PER) for Swahili, Amharic, Dinka, and Mandarin.
CR Bengio Y., 2007, P ADV NEUR INF PROC, P153
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Das A, 2016, INTERSPEECH, P3858, DOI 10.21437/Interspeech.2016-655
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   Gehring J, 2013, INT CONF ACOUST SPEE, P3377, DOI 10.1109/ICASSP.2013.6638284
   Ghoshal A, 2013, INT CONF ACOUST SPEE, P7319, DOI 10.1109/ICASSP.2013.6639084
   Gopinath RA, 1998, INT CONF ACOUST SPEE, P661, DOI 10.1109/ICASSP.1998.675351
   Hasegawa-Johnson MA, 2017, IEEE-ACM T AUDIO SPE, V25, P50, DOI 10.1109/TASLP.2016.2621659
   Jyothi P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2774
   Liu CX, 2016, INT CONF ACOUST SPEE, P5840, DOI 10.1109/ICASSP.2016.7472797
   Mass A. L., 2012, INTERSPEECH, P22
   Povey  D., 2011, IEEE ASRU WORKSH
   Qian YM, 2016, INT CONF ACOUST SPEE, P5725, DOI 10.1109/ICASSP.2016.7472774
   Reed S., 2014, ARXIV14126596
   Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vu  N., 2012, INTERSPEECH, P2586
NR 16
TC 0
Z9 0
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 2073
EP 2077
DI 10.21437/Interspeech.2017-582
UT WOS:000457505000434
ER

PT S
AU Zhuang, XD
   Ghoshal, A
   Rosti, AV
   Paulik, M
   Liu, DB
AF Zhuang, Xiaodan
   Ghoshal, Arnab
   Rosti, Antti-Veikko
   Paulik, Matthias
   Liu, Daben
GP Int Speech Commun Assoc
TI Improving DNN Bluetooth Narrowband Acoustic Models by Cross-bandwidth
   and Cross-lingual Initialization
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE speech recognition; deep neural network; cross lingual; cross-bandwidth;
   transfer learning
AB The success of deep neural network (DNN) acoustic models is partly owed to large amounts of training data available for different applications. This work investigates ways to improve DNN acoustic models for Bluetooth narrowband mobile applications when relatively small amounts of in-domain training data are available. To address the challenge of limited in domain data, we use cross-bandwidth and cross-lingual transfer learning methods to leverage knowledge from other domains with more training data (different bandwidth and/or languages). Specifically, narrowband DNNs in a target language are initialized using the weights of DNNs trained on bandlimited wide band data in the same language or those trained on a different (resource-rich) language. We investigate multiple recipes involving such methods with different data resources. For all languages in our experiments, these recipes achieve up to 45% relative WER reduction, compared to training solely on the Blue tooth narrowband data in the target language. Furthermore, these recipes are very beneficial even when over two hundred hours of manually transcribed in-domain data is available, and we can achieve better accuracy than the baselines with as little as 20 hours of in-domain data.
CR Bengio Y., 2007, P ADV NEUR INF PROC, P153
   BRIDLE JS, 1991, INT CONF ACOUST SPEE, P277, DOI 10.1109/ICASSP.1991.150331
   Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   GHOSHAL A, 2013, P IEEE INT C AC SPEE, P7319
   Grezl Frantisek, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7654, DOI 10.1109/ICASSP.2014.6855089
   Grezl F, 2014, INTERSPEECH, P820
   Heigold  G., 2013, P IEEE ICASSP
   Huang  J.-T., 2013, P IEEE ICASSP
   Kimball  O., 2006, P ICASSP
   Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445
   Lamel L, 2002, COMPUT SPEECH LANG, V16, P115, DOI 10.1006/csla.2001.0186
   Li  J., 2012, P IEEE SLT WORKSH
   Lu L, 2014, IEEE-ACM T AUDIO SPE, V22, P17, DOI 10.1109/TASL.2013.2281575
   McDermott  E., 2014, P INTERSPEECH
   Paulik M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1463
   Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545
   Pratt  L., 1991, P AAAI
   Scanzio S, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2711
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Seide  F., 2011, P INTERSPEECH, P437, DOI DOI 10.1.1.368.3047
   Su H, 2013, INT CONF ACOUST SPEE, P6664, DOI 10.1109/ICASSP.2013.6638951
   Thomas S, 2013, INT CONF ACOUST SPEE, P6704, DOI 10.1109/ICASSP.2013.6638959
   Thrun S., 1996, ADV NEURAL INFORM PR, V8
   Vesely  K., 2012, P IEEE SLT WORKSH
   Vesely K, 2013, INTERSPEECH, P2344
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Yu D, 2010, COMPUT SPEECH LANG, V24, P433, DOI 10.1016/j.csl.2009.03.004
   Zavaliagkos  G., 1998, ICSLP
NR 29
TC 1
Z9 1
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 2148
EP 2152
DI 10.21437/Interspeech.2017-1129
UT WOS:000457505000449
ER

PT S
AU Abraham, B
   Seeram, T
   Umesh, S
AF Abraham, Basil
   Seeram, Tejaswi
   Umesh, S.
GP Int Speech Commun Assoc
TI Transfer Learning and Distillation Techniques to Improve the Acoustic
   Modeling of Low Resource Languages
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE speech recognition; low-resource languages; transfer learning;
   distillation
ID AUTOMATIC SPEECH RECOGNITION
AB Deep neural networks (DNN) require large amount of training data to build robust acoustic models for speech recognition tasks. Our work is intended in improving the low-resource language acoustic model to reach a performance comparable to that of a high-resource scenario with the help of data/model parameters from other high-resource languages. we explore transfer learning and distillation methods, where a complex high resource model guides or supervises the training of low resource model. The techniques include (i) multi-lingual framework of borrowing data from high-resource language while training the low-resource acoustic model. The KL divergence based constraints are added to make the model biased towards low-resource language. (ii) distilling knowledge from the complex high-resource model to improve the low-resource acoustic model, The experiments were performed on three Indian languages namely Hindi, Tamil and Kannada. All the techniques gave improved performance and the multi-lingual framework with KL divergence regularization giving the best results. In all the three languages a performance close to or better than high-resource scenario was obtained.
CR Abraham  B., 2016, P INTERSPEECH
   Abraham B, 2014, IEEE W SP LANG TECH, P36, DOI 10.1109/SLT.2014.7078546
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Hinton G. E., 2015, ABS150302531 CORR
   Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081
   Le VB, 2009, IEEE T AUDIO SPEECH, V17, P1471, DOI 10.1109/TASL.2009.2021723
   Marcos LM, 2016, IEEE W SP LANG TECH, P330, DOI 10.1109/SLT.2016.7846285
   Markov K, 2016, INTERSPEECH, P2364, DOI 10.21437/Interspeech.2016-852
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Povey  D., 2011, P ASRU DEC
   Povey D, 2011, COMPUT SPEECH LANG, V25, P404, DOI 10.1016/j.csl.2010.06.003
   Schalkwyk J., 2010, ADV SPEECH RECOGNITI, P61, DOI DOI 10.1007/978-1-4419-5951-5_4
   Schultz T., 1998, P ICSLP SYDN, P1819
   Scide  F., 2013, ICASSP 2013
   Vapnik V, 2015, J MACH LEARN RES, V16, P2023
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Wang D, 2015, ASIAPAC SIGN INFO PR, P1225, DOI 10.1109/APSIPA.2015.7415532
NR 19
TC 0
Z9 0
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 2158
EP 2162
DI 10.21437/Interspeech.2017-1009
UT WOS:000457505000451
ER

PT S
AU Smith, D
   Sneddon, A
   Ward, L
   Duenser, A
   Freyne, J
   Silvera-Tawil, D
   Morgans, A
AF Smith, Daniel
   Sneddon, Alex
   Ward, Lauren
   Duenser, Andreas
   Freyne, Jill
   Silvera-Tawil, David
   Morgans, Angela
GP Int Speech Commun Assoc
TI Improving child speech disorder assessment by incorporating
   out-of-domain adult speech
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE Automated Speech Recognition; Speech Therapy; Speech Assessment Tools
ID LANGUAGE; RECOGNITION; COMMUNITY; TOOL
AB This paper describes the continued development of a system to provide early assessment of speech development issues in children and better triaging to professional services. Whilst corpora of children's speech are increasingly available, recognition of disordered children's speech is still a data-scarce task. Transfer learning methods have been shown to be effective at leveraging out-of-domain data to improve ASR performance in similar data-scarce applications. This paper combines transfer learning, with previously developed methods for constrained decoding based on expert speech pathology knowledge and knowledge of the target text. Results of this study show that transfer learning with out-of-domain adult speech can improve phoneme recognition for disordered children's speech. Specifically. a Deep Neural Network (DNN) trained on adult speech and finetuned on a corpus of disordered children's speech reduced the phoneme error rate (PER) of a DNN trained on a children's corpus from 16.3% to 14.2%. Furthermore, this fine-tuned DNN also improved the performance of a Hierarchal Neural Network based acoustic model previously used by the system with a PER of 19.3%. We close with a discussion of our planned future developments of the system.
RI Morgan, Angela/J-5235-2017
OI Morgan, Angela/0000-0003-1147-7405
CR Abraham B, 2016, INTERSPEECH, P3037, DOI 10.21437/Interspeech.2016-963
   Anumanchipalli GK, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P530
   Christensen H., 2013, P INTERSPEECH, P3642
   Dodd B., 2002, DIAGNOSTIC EVALUATIO
   Duenser A, 2016, STUD HEALTH TECHNOL, V227, P21, DOI 10.3233/978-1-61499-666-8-21
   Dykstra JR, 2013, AUTISM, V17, P582, DOI 10.1177/1362361312446206
   Eadie P, 2015, DEV MED CHILD NEUROL, V57, P578, DOI 10.1111/dmcn.12635
   Estival D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3105
   Fainberg J, 2016, INTERSPEECH, P1598, DOI 10.21437/Interspeech.2016-1348
   Foy JG, 2012, READ WRIT, V25, P799, DOI 10.1007/s11145-011-9300-4
   Ganzeboom  M., 2016, ASR BASED INTERACTIV
   Gong JJ, 2016, INTERSPEECH, P112, DOI 10.21437/Interspeech.2016-549
   Heeman PA, 2016, INTERSPEECH, P2651, DOI 10.21437/Interspeech.2016-1388
   Jiao  Y., 2016, IEEE SIGNAL PROCESSI
   Karbasi Sedighah Akhavan, 2011, Acta Med Iran, V49, P33
   Maier A, 2009, SPEECH COMMUN, V51, P425, DOI 10.1016/j.specom.2009.01.004
   Mashima Pauline A, 2008, Telemed J E Health, V14, P1101, DOI 10.1089/tmj.2008.0080
   McLeod S, 2013, AM J SPEECH-LANG PAT, V22, P503, DOI 10.1044/1058-0360(2012/11-0123)
   Morgan  A., 2017, J PEDIAT
   Shahin M, 2015, SPEECH COMMUN, V70, P49, DOI 10.1016/j.specom.2015.04.002
   Sharp HM, 2008, PEDIATR CLIN N AM, V55, P1159, DOI 10.1016/j.pcl.2008.07.007
   U.S. Department of Education, 2014, 36 ANN C IMPL IND DI
   Ward  L., 2016, P INT 2016 17 ANN C
   Yilmaz E, 2016, INTERSPEECH, P218, DOI 10.21437/Interspeech.2016-109
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
NR 25
TC 0
Z9 0
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 2690
EP 2694
DI 10.21437/Interspeech.2017-455
UT WOS:000457505000558
ER

PT S
AU Yi, JY
   Tao, JH
   Wen, ZQ
   Li, Y
AF Yi, Jiangyan
   Tao, Jianhua
   Wen, Zhengqi
   Li, Ya
GP Int Speech Commun Assoc
TI Distilling Knowledge from an Ensemble of Models for Punctuation
   Prediction
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE transfer learning; knowledge distillation; ensemble; neural network;
   punctuation prediction
ID CAPITALIZATION
AB This paper proposes an approach to distill knowledge from an ensemble of models to a single deep neural network (DNN) student model for punctuation prediction. This approach makes the DNN student model mimic the behavior of the ensemble. The ensemble consists of three single models. Kullback-Leibler (KL) divergence is used to minimize the difference between the output distribution of the DNN student model and the behavior of the ensemble. Experimental results on English IWSLT2011 dataset show that the ensemble outperforms the previous state-of-the-art model by up to 4.0% absolute in overall F-I-score. The DNN student model also achieves up to 13.4% absolute overall F-I-score improvement over the conventionally-trained baseline models.
CR Asami T, 2017, INT CONF ACOUST SPEE, P5185, DOI 10.1109/ICASSP.2017.7953145
   Ba L.J, 2014, ADV NEURAL INFORM PR, V2, P2654
   Bastien F, 2012, DEEP LEARN UNS FEAT
   Batista F, 2012, IEEE T AUDIO SPEECH, V20, P474, DOI 10.1109/TASL.2011.2159594
   Bucila  C., 2006, ACM SIGKDD INT C KNO
   Chan  W., 2015, P INTERSPEECH
   Che  X., 2016, 10 INT C LANG RES EV
   Che  X., 2016, P INTERSPEECH
   Chebotar Y, 2016, INTERSPEECH, P3439, DOI 10.21437/Interspeech.2016-1190
   Cho  E., 2015, 16 ANN C INT SPEECH
   Christensen  H., 2001, ISCA TUT RES WORKSH
   Deng L., 1915, P INTERSPEECH
   Gravano A, 2009, INT CONF ACOUST SPEE, P4741, DOI 10.1109/ICASSP.2009.4960690
   Hinton  G., 2014, NEURAL INFORM PROCES
   Kim J. -H., 2001, P INTERSPEECH
   KLEJCH O, 2017, P ICASSP, P5700
   Kolar  J., 2012, P INT 2012 PORTL OR
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lample G, 2016, P NAACL HLT, P260
   Lee  A., 2012, INTERSPEECH, P1848
   Levy  T., 2012, EL EL ENG ISR IEEEI, P1
   Lu  W., 2010, EMNLP 2010
   Lu XX, 2014, INT CONF ACOUST SPEE
   Stolcke  A., 1998, P ICSLP
   Tilk  O, 2016, P INTERSPEECH
   Tilk  O., 2015, P INTERSPEECH
   Ueffing  N., 2013, P INTERSPEECH
   Wang  X., 2012, P INTERSPEECH
   Zhao  Y., 2015, SPEECH AUDIO PROCESS, P113
NR 29
TC 1
Z9 1
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 2779
EP 2783
DI 10.21437/Interspeech.2017-1079
UT WOS:000457505000576
ER

PT S
AU Wang, Y
   Metze, F
AF Wang, Yun
   Metze, Florian
GP Int Speech Commun Assoc
TI A Transfer Learning Based Feature Extractor for Polyphonic Sound Event
   Detection Using Connectionist Temporal Classification
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE sound event detection (SED); connectionist temporal classification
   (CTC); transfer learning; convolutional neural networks (CNN)
AB Sound event detection is the task of detecting the type, onset time, and offset time of sound events in audio streams. The mainstream solution is recurrent neural networks (RNNs). which usually predict the probability of each sound event at every time step. Connectionist temporal classification (CTC) has been applied in order to relax the need for exact annotations of onset and offset times: the CTC output layer is expected to generate a peak for each event boundary where the acoustic signal is most salient. However, with limited training data, the CTC network has been found to train slowly, and generalize poorly to new data.
   In this paper, we try to introduce knowledge learned from a much larger corpus into the CTC network. We train two variants of SoundNet, a deep convolutional network that takes the audio tracks of videos as input, and tries to approximate the visual information extracted by an image recognition network. A lower part of SoundNet or its variants is then used as a feature extractor for the CTC network to perform sound event detection. We show that the new feature extractor greatly accelerates the convergence of the CTC network, and slightly improves the generalization.
CR Adavanne  S., 2016, WORKSH DET CLASS AC
   Aytar  Y., 2016, P NIPS
   Bergstra  J., 2010, P 9 PYTH SCI COMP C
   Burger  S., 2012, CMULTI1207
   Chollet F., 2015, KERAS DEEP LEARNING
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Gemmeke J. F., 2017, P ICASSP
   Gers F. A., 2000, NEURAL COMPUTATION, V12
   Glorot X, 2010, P 13 INT C ART INT S
   Graves  A., 2006, P ICML
   Hayashi  T., 2016, WORKSH DET CLASS AC
   Ioffe Sergey, 2015, P ICML
   Jozefowicz  R., 2015, P ICML
   Krizhevsky  A., 2012, P NIPS
   Mesaros  A., 2016, P EUSIPCO
   Mun  S., 2017, P ICASSP
   Nesterov Y., 1983, SOVIET MATH DOKLADY, V27
   Parascandolo  G., 2016, P ICASSP
   Schmidhuber J, 1997, NEURAL COMPUT, V9, P1735
   Simonyan K., 2015, P ICLR
   Srivastava N., 2014, J MACHINE LEARNING R, V15
   Thomee  B., 2016, COMMUNICATIONS ACM, V59
   Wang  Y., 2016, P ICASSP
   Wang Yun, 2017, P ICASSP
NR 24
TC 2
Z9 2
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 3097
EP 3101
DI 10.21437/Interspeech.2017-1469
UT WOS:000457505000640
ER

PT S
AU Zhang, Y
   Weninger, F
   Schuller, BW
AF Zhang, Yue
   Weninger, Felix
   Schuller, Bjoern W.
GP Int Speech Commun Assoc
TI Cross-Domain Classification of Drowsiness in Speech: The Case of Alcohol
   Intoxication and Sleep Deprivation
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE Computational Paralinguistics; speaker states; drowsiness detection;
   transfer learning; feature analysis
ID RECOGNITION
AB In this work, we study the drowsy state of a speaker. induced by alcohol intoxication or sleep deprivation. In particular, we investigate the coherence between the two pivotal causes of drowsiness. as featured in the Intoxication and Sleepiness tasks of the INTERSPEECH Speaker State Challenge. In this way, we aim to exploit the interrelations between these different, yet highly correlated speaker states, which need to be reliably recognised in safety and security critical environments. To this end, we perform cross-domain classification of alcohol intoxication and sleepiness, thus leveraging the acoustic similarities of these speech phenomena for transfer learning. Further, we conducted in-depth feature analysis to quantitatively assess the task relatedness and to determine the most relevant features for both tasks. To test our methods in realistic contexts, we use the Alcohol Language Corpus and the Sleepy Language Corpus containing in total 60 hours of genuine intoxicated and sleepy speech. In the result, cross-domain classification combined with feature selection yields up to 60.3 % unweighted average recall, which is significantly above-chance (50 %) and highly notable given the mismatch in the training and validation data. Finally, we show that an effective, general drowsiness classifier can be obtained by aggregating the training data from both domains.
CR Behne D. M., 1991, J ACOUST SOC AM, V90, P2311
   Braun  A., 2003, P INT C PHON SCI BAR, V2645, P2645
   Cooney O. M., 1998, J ACOUST SOC AM, V103, P2895
   Curtin JJ, 2001, PSYCHOL SCI, V12, P527, DOI 10.1111/1467-9280.00397
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   DINGUS TA, 1987, ACCIDENT ANAL PREV, V19, P271, DOI 10.1016/0001-4575(87)90062-5
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI [DOI 10.1145/2502081.2502224, 10.1145/2502081.2502224]
   Eyben F., 2010, P INT C MULT, P1459, DOI DOI 10.1145/1873951.1874246
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   Headley  D., 1976, ALCOHOL TECHN REPT, V5, P45
   Hollien H, 2001, J ACOUST SOC AM, V110, P3198, DOI 10.1121/1.1413751
   Ingre M, 2006, J SLEEP RES, V15, P142, DOI 10.1111/j.1365-2869.2006.00517.x
   Johannes B, 2000, AVIAT SPACE ENVIR MD, V71, pA58
   JOHNSON K, 1990, PHONETICA, V47, P215, DOI 10.1159/000261863
   KLINGHOLZ F, 1988, J ACOUST SOC AM, V84, P929, DOI 10.1121/1.396661
   Krajewski J, 2009, BEHAV RES METHODS, V41, P795, DOI 10.3758/BRM.41.3.795
   Levit M., 2001, P WORKSH PROS SPEECH, P103
   Nwe TL, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1846
   PISONI DB, 1989, ALCOHOL CLIN EXP RES, V13, P577, DOI 10.1111/j.1530-0277.1989.tb00381.x
   Platt J, 1999, ADV LARGE MARGIN CLA, V10, P61
   Schiel F., 2011, P INT 2011 FLOR IT, P3281
   Schiel  F., 2011, LANG RESOUR EVAL, V46, P503
   Schiel F., 2009, P INTERSPEECH 2009 B, P983
   Schiel F, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P458
   Schuller B, 2014, COMPUT SPEECH LANG, V28, P346, DOI 10.1016/j.csl.2012.12.002
   Schuller Bjorn, 2011, P INTERSPEECH, P3201
   Sigmund  M., 2010, P INT C ART INT APPL, P193
   SOBELL LC, 1982, FOLIA PHONIATR, V34, P316, DOI 10.1159/000265672
   Stutts JC, 2003, ACCIDENT ANAL PREV, V35, P321, DOI 10.1016/S0001-4575(02)00007-6
   TROJAN F, 1968, FOLIA PHONIATR, V20, P217, DOI 10.1159/000263201
   Vogel AP, 2010, J ACOUST SOC AM, V128, P3747, DOI 10.1121/1.3506349
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Zhang Y, 2017, INT CONF ACOUST SPEE, P4990, DOI 10.1109/ICASSP.2017.7953106
NR 33
TC 1
Z9 1
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 3152
EP 3156
DI 10.21437/Interspeech.2017-1015
UT WOS:000457505000651
ER

PT S
AU Sun, M
   Snyder, D
   Gao, YX
   Nagaraja, V
   Rodehorst, M
   Panchapagesan, S
   Strom, N
   Matsoukas, S
   Vitaladevuni, S
AF Sun, Ming
   Snyder, David
   Gao, Yixin
   Nagaraja, Varun
   Rodehorst, Mike
   Panchapagesan, Sankaran
   Strom, Nikko
   Matsoukas, Spyros
   Vitaladevuni, Shiv
GP Int Speech Commun Assoc
TI Compressed time delay neural network for small-footprint keyword
   spotting
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
DE keyword spotting; time delay neural network; singular value
   decomposition; small-footprint
ID CANONICAL CORRELATION-ANALYSIS; RECOGNITION
AB In this paper we investigate a time delay neural network (TDNN) for a keyword spotting task that requires low CPU, memory and latency. The TDNN is trained with transfer learning and multi-task learning. Temporal subsampling enabled by the time delay architecture reduces computational complexity. We propose to apply singular value decomposition (SVD) to further reduce TDNN complexity. This allows us to first train a larger full-rank TDNN model which is not limited byCPU/memory constraints. The larger TDNN usually achieves better performance. Afterwards, its size can be compressed by SVD to meet the budget requirements. Hidden Markov models (HMM) are used in conjunction with the networks to perform keyword detection and performance is measured in terms of area under the curve (AUC) for detection error tradeoff (DET) curves. Our experimental results on a large in-house far-field corpus show that the full-rank TDNN achieves a 19.7% DET AUC reduction compared to a similar-size deep neural network (DNN) baseline. If we train a larger size full-rank TDNN first and then reduce it via SVD to the comparable size of the DNN, we obtain a 37.6% reduction in DET AUC compared to the DNN baseline.
CR Baljekar P, 2014, IEEE W SP LANG TECH, P536, DOI 10.1109/SLT.2014.7078631
   Bell P, 2015, INT CONF ACOUST SPEE, P4290, DOI 10.1109/ICASSP.2015.7178780
   Caruana R, 1998, LEARNING TO LEARN, P95
   Chen GZ, 2013, APPL MECH MATER, V345, P416, DOI 10.4028/www.scientific.net/AMM.345.416
   Fernandez S, 2007, LECT NOTES COMPUT SC, V4669, P220
   Giri R, 2015, INT CONF ACOUST SPEE, P5014, DOI 10.1109/ICASSP.2015.7178925
   Guoguo Chen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4087, DOI 10.1109/ICASSP.2014.6854370
   He Q, 2016, INTERSPEECH, P1888, DOI 10.21437/Interspeech.2016-1562
   Heigold G, 2013, INT CONF ACOUST SPEE, P8619, DOI 10.1109/ICASSP.2013.6639348
   Miller  D.R., 2007, 8 ANN C INT SPEECH C
   Nakkiran P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1473
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panchapagesan S, 2016, INTERSPEECH, P760, DOI 10.21437/Interspeech.2016-1485
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3214
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2440
   Povey  D., 2016, INTERSPEECH
   ROSE RC, 1990, INT CONF ACOUST SPEE, P129, DOI 10.1109/ICASSP.1990.115555
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1478
   Sainath TN, 2013, INT CONF ACOUST SPEE, P6655, DOI 10.1109/ICASSP.2013.6638949
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P6965, DOI 10.1109/ICASSP.2013.6639012
   Senior Andrew, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7644, DOI 10.1109/ICASSP.2014.6855087
   Shen CC, 2014, J MULTIVARIATE ANAL, V130, P310, DOI 10.1016/j.jmva.2014.05.011
   Snyder D, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P92, DOI 10.1109/ASRU.2015.7404779
   Strom N., 2015, INTERSPEECH, V7, P10
   Sun  M., 2016, SPOK LANG TECHN WORK
   Sun M, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P369, DOI 10.1109/ICMLA.2015.121
   Sun M, 2013, PATTERN RECOGN LETT, V34, P1263, DOI 10.1016/j.patrec.2013.03.025
   Sun M, 2013, PATTERN RECOGN LETT, V34, P194, DOI 10.1016/j.patrec.2012.09.018
   Tsakalidis Stavros, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7829, DOI 10.1109/ICASSP.2014.6855124
   Tucker  G., 2016, P INTERSPEECH
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Waibel A, 1989, NEURAL COMPUT, V1, P39, DOI 10.1162/neco.1989.1.1.39
   WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088
   WILPON JG, 1991, INT CONF ACOUST SPEE, P309, DOI 10.1109/ICASSP.1991.150338
   Wollmer M, 2013, SPEECH COMMUN, V55, P252, DOI 10.1016/j.specom.2012.08.006
NR 35
TC 4
Z9 4
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 3607
EP 3611
DI 10.21437/Interspeech.2017-480
UT WOS:000457505000750
ER

PT S
AU Guan, S
   Loew, M
AF Guan, Shuyue
   Loew, Murray
GP IEEE
TI Breast Cancer Detection Using Transfer Learning in Convolutional Neural
   Networks
SO 2017 IEEE APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP (AIPR)
SE IEEE Applied Imagery Pattern Recognition Workshop
CT IEEE Applied Imagery Pattern Recognition Workshop (AIPR)
CY OCT 10-12, 2017
CL Washington, DC
DE breast mass classification; transfer learning; deep learning;
   convolutional neural networks; mammogram; computer aided diagnosis;
   fine-tuning
ID MASS CLASSIFICATION; MAMMOGRAM IMAGES; STATISTICS
AB In the U.S., breast cancer is diagnosed in about 12% of women during their lifetime and it is the second leading reason for women's death. Since early diagnosis could improve treatment outcomes and longer survival times for breast cancer patients, it is significant to develop breast cancer detection techniques. The Convolutional Neural Network (CNN) can extract features from images automatically and then perform classification. To train the CNN from scratch, however, requires a large number of labeled images, which is infeasible for some kinds of medical image data such as mammographic tumor images. A promising solution is to apply transfer learning in CNN. In this paper, we firstly tested three training methods on the MIAS database: 1) trained a CNN from scratch, 2) applied the pre-trained VGG-16 model to extract features from input mammograms and used these features to train a Neural Network (NN)-classifier, 3) updated the weights in several final layers of the pre-trained VGG-16 model by back-propagation (fine-tuning) to detect abnormal regions. We found that method 2) is ideal for study because the classification accuracy of fine-tuning model was just 0.008 higher than that of feature extraction model but time cost of feature extraction model was only about 5% of that of the fine-tuning model. Then, we used method 2) to classify regions: benign vs. normal, malignant vs. normal and abnormal vs. normal from the DDSM database with 10-fold cross validation. The average validation accuracy converged at about 0.905 for abnormal vs. normal cases, and there was no obvious overfitting. This study shows that applying transfer learning in CNN can detect breast cancer from mammograms, and training a NN-classifier by feature extraction is a faster method in transfer learning.
CR Abadi M., 2016, ARXIV160304467CS
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Bar Y, 2015, I S BIOMED IMAGING, P294, DOI 10.1109/ISBI.2015.7163871
   Carneiro G, 2013, IEEE T PATTERN ANAL, V35, P2592, DOI 10.1109/TPAMI.2013.96
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   DeSantis CE, 2016, CA-CANCER J CLIN, V66, P31, DOI 10.3322/caac.21320
   Dhungel Neeraj, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P106, DOI 10.1007/978-3-319-46723-8_13
   Erhan D., 2009, DIFFICULTY TRAINING
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Friedewald SM, 2014, JAMA-J AM MED ASSOC, V311, P2499, DOI 10.1001/jama.2014.6095
   Ganesan Karthikeyan, 2013, IEEE Rev Biomed Eng, V6, P77, DOI 10.1109/RBME.2012.2232289
   He K., 2015, ARXIV151203385CS
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Heath M., 2000, P 5 INT WORKSH DIG M, P212
   Jamieson AR, 2012, PROC SPIE, V8315, DOI 10.1117/12.910710
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Khan S, 2017, MULTIMED TOOLS APPL, V76, P33, DOI 10.1007/s11042-015-3017-3
   Khan S, 2016, APPL SOFT COMPUT, V44, P267, DOI 10.1016/j.asoc.2016.04.012
   Kingma D. P., 2014, ARXIV14126980CS
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39
   Lo SCB, 1995, NEURAL NETWORKS, V8, P1201, DOI 10.1016/0893-6080(95)00061-5
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Narvaez F, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0672-5
   Nithya R., 2011, INT J COMPUTER APPL, V28, P21
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Raghavendra U, 2016, APPL SOFT COMPUT, V46, P151, DOI 10.1016/j.asoc.2016.04.036
   Rao VM, 2010, J AM COLL RADIOL, V7, P802, DOI 10.1016/j.jacr.2010.05.019
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren S., 2015, ARXIV150601497CS
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   Schlegl T, 2014, LECT NOTES COMPUT SC, V8848, P82, DOI 10.1007/978-3-319-13972-2_8
   Sharma A., 2015, DDSM UTILITY
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI 10.3322/caac.21332
   Simonyan K, 2014, ARXIV14091556CS
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suckling J., 1994, P INT WORKSHOP DIG M, P375
   Sze V., 2017, ARXIV170309039CS
   Szegedy C., 2015, ARXIV151200567CS
   Szegedy C, 2016, ARXIV160207261CS
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P2
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Wang SH, 2017, FUND INFORM, V151, P191, DOI 10.3233/FI-2017-1487
   Wolterink JM, 2015, LECT NOTES COMPUT SC, V9349, P589, DOI 10.1007/978-3-319-24553-9_72
   Yi D., 2017, ARXIV170506362CS
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
   Zhu W., 2016, ARXIV161205968CS
NR 52
TC 0
Z9 0
SN 1550-5219
BN 978-1-5386-1235-4
PY 2017
UT WOS:000454739700014
ER

PT S
AU Gada, S
   Mehta, V
   Kanchan, K
   Jain, C
   Raut, P
AF Gada, Siddhant
   Mehta, Viraj
   Kanchan, Karan
   Jain, Chahat
   Raut, Purva
BE Krishnan, N
   Karthikeyan, M
TI Monument Recognition using Deep Neural Networks
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND
   COMPUTING RESEARCH (ICCIC)
SE IEEE International Conference on Computational Intelligence and
   Computing Research
CT 8th IEEE International Conference on Computational Intelligence and
   Computing Research (IEEE ICCIC)
CY DEC 14-16, 2017
CL Tamilnadu Coll Engn, Coimbatore, INDIA
HO Tamilnadu Coll Engn
DE Deep Learning; Inception; Landmark recognition; neural networks
AB In this paper, we have classified the famous Indian Monuments across the Golden Quadrilateral. A well-known Deep Learning architectural model has been adopted to provide on-time and striking accuracies for classifying the images. A deep learning library has been used for all the training computations on the classifier for the dataset generated using a web crawler. The concept of Transfer learning has been used to prune the computational load. The last layer of the architecture is retrained as per the training set. Once the model is fully trained, the model is tested on a few arbitrary images to determine the test accuracy of the model.
CR Abadi M., 2016, ARXIV160304467
   Chen Tao, 2009, SURVEY MOBILE LANDMA
   Crudge A., 2014, CS229
   Donahue J., 2013, CORR
   Gatys L. A., 2015, ARXIV150806576
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Jarrett K, 2009, 2009 IEEE 12 INT C C
   Kazi Sabir A., INT J INNOVATIVE RES, V4, P17378
   Kim J, 2016, IEEE CONF COMPUT
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Nair Vinod, 2010, INT C MACH LEARN
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2015, ARXIV E PRINTS
   Takeuchi Y., 1998, CMURITR9820
NR 15
TC 0
Z9 0
SN 2471-7851
BN 978-1-5090-6621-6
PY 2017
BP 645
EP 650
UT WOS:000456303900114
ER

PT S
AU Liu, F
   Zhang, GQ
   Lu, J
AF Liu, Feng
   Zhang, Guangquan
   Lu, Jie
GP IEEE
TI Heterogeneous Unsupervised Domain Adaptation Based on Fuzzy Feature
   Fusion
SO 2017 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE)
SE IEEE International Conference on Fuzzy Systems
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
CY JUL 09-12, 2017
CL Naples, ITALY
DE domain adaptation; transfer learning; fuzzy features; heterogeneous
   feature space
AB Domain adaptation is a transfer learning approach that has been widely studied in the last decade. However, existing works still have two limitations: 1) the feature spaces of the domains are homogeneous, and 2) the target domain has at least a few labeled instances. Both limitations significantly restrict the domain adaptation approach when knowledge is transferred across domains, especially in the current era of big data. To address both issues, this paper proposes a novel fuzzy-based heterogeneous unsupervised domain adaptation approach. This approach maps the feature spaces of the source and target domains onto the same latent space constructed by fuzzy features. In the new feature space, the label spaces of two domains are maintained to reduce the probability of negative transfer occurring. The proposed approach delivers superior performance over current benchmarks, and the heterogeneous unsupervised domain adaptation (HeUDA) method provides a promising means of giving a learning system the associative ability to judge unknown things using related knowledge.
RI Zhang, Guangquan/G-2553-2017
OI Zhang, Guangquan/0000-0003-3960-0583
CR Behbood V, 2015, IEEE T FUZZY SYST, V23, P1917, DOI 10.1109/TFUZZ.2014.2387872
   Gong BQ, 2014, INT J COMPUT VISION, V109, P3, DOI 10.1007/s11263-014-0718-4
   Jiang J., 2007, P 16 ACM C INF KNOWL, P401
   Kanamori T, 2009, J MACH LEARN RES, V10, P1391
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Muller JS, 2011, J MACH LEARN RES, V12, P3065
   Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shi XX, 2013, IEEE T KNOWL DATA EN, V25, P906, DOI 10.1109/TKDE.2011.252
   Shi  Yuan, 2012, P INT C MACH LEARN, P1079
   Wang C., 2011, IJCAI, P1541
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Xiao M, 2015, IEEE T PATTERN ANAL, V37, P54, DOI 10.1109/TPAMI.2014.2343216
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
   Zuo H, 2017, IEEE T FUZZY SYST, V25, P1795, DOI 10.1109/TFUZZ.2016.2633376
   Zuo H, 2016, WD SCI P COMP ENG, V10, P175
NR 19
TC 0
Z9 0
SN 1098-7584
BN 978-1-5090-6034-4
PY 2017
UT WOS:000426449100188
ER

PT S
AU Zuo, H
   Zhang, GQ
   Lu, J
   Pedrycz, W
AF Zuo, Hua
   Zhang, Guangquan
   Lu, Jie
   Pedrycz, Witold
GP IEEE
TI Fuzzy Rule-based Transfer Learning for Label Space Adaptation
SO 2017 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE)
SE IEEE International Conference on Fuzzy Systems
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
CY JUL 09-12, 2017
CL Naples, ITALY
DE machine learning; fuzzy rules; transfer learning; classification
AB As the age of big data approaches, methods of massive scale data management are rapidly evolving. The traditional machine learning methods can no longer satisfy the exponential development of big data; there is a common assumption in these data-driving methods that the distribution of both the training data and testing data should be equivalent. A model built using today's data will not adequately address the classification tasks tomorrow if the distribution of the data item values has changed. Transfer learning is emerging as a solution to this issue, and many methods have been proposed. Few of the existing methods, however, explicitly indicate the solution to the case where the labels' distributions in two domains are different. This work proposes the fuzzy rule-based methods to deal with transfer learning problems where the discrepancy between the two domains shows in the label spaces. The presented methods are validated in both the synthetic and real-world datasets, and the experimental results verify the effectiveness of the introduced methods.
RI Zhang, Guangquan/G-2553-2017
OI Zhang, Guangquan/0000-0003-3960-0583; Lu, Jie/0000-0003-0690-4732; Liu,
   Feng/0000-0002-5005-9129
CR Behbood V, 2015, IEEE T FUZZY SYST, V23, P1917, DOI 10.1109/TFUZZ.2014.2387872
   Bollegala D, 2016, IEEE T KNOWL DATA EN, V28, P398, DOI 10.1109/TKDE.2015.2475761
   Hadjili ML, 2002, IEEE T FUZZY SYST, V10, P728, DOI 10.1109/TFUZZ.2002.805897
   Huang Y, 2016, COMM COM INF SC, V663, P721, DOI 10.1007/978-981-10-3005-5_59
   Joy TT, 2016, LECT NOTES ARTIF INT, V9651, P102, DOI 10.1007/978-3-319-31753-3_9
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shell Jethro, 2012, Ambient Intelligence. Third International Joint Conference (AML 2012). Proceedings, P145, DOI 10.1007/978-3-642-34898-3_10
   Shell J, 2015, INFORM SCIENCES, V293, P59, DOI 10.1016/j.ins.2014.09.004
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yang C., 2016, IEEE T FUZZY SYSTEMS
   Yang P, 2016, IEEE T KNOWL DATA EN, V28, P3154, DOI 10.1109/TKDE.2016.2611514
   Zuo H, 2017, IEEE T FUZZY SYST, V25, P1795, DOI 10.1109/TFUZZ.2016.2633376
   Zuo H, 2016, WD SCI P COMP ENG, V10, P175
   Zuo H, 2015, ADV INTEL SYS RES, V89, P1000
NR 15
TC 0
Z9 0
SN 1098-7584
BN 978-1-5090-6034-4
PY 2017
UT WOS:000426449100177
ER

PT B
AU Kalmady, KS
   Kamath, AS
   Gopakumar, G
   Subrahmanyam, GRKS
   Gorthi, SS
AF Kalmady, Kaushik S.
   Kamath, Adithya S.
   Gopakumar, G.
   Subrahmanyam, Gorthi. R. K. Sai
   Gorthi, Sai Siva
GP IEEE
TI Improved Transfer Learning through Shallow Network Embedding for
   Classification of Leukemia Cells
SO 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION
   (ICAPR)
CT 9th International Conference on Advances in Pattern Recognition (ICAPR)
CY DEC 27-30, 2017
CL Indian Stat Inst Bangalore, Bangalore, INDIA
HO Indian Stat Inst Bangalore
ID NEURAL-NETWORKS
AB One of the most crucial parts in the diagnosis of a wide variety of ailments is cytopathological testing. This process is often laborious, time consuming and requires skill. These constraints have led to interests in automating the process. Several deep learning based methods have been proposed in this domain to enable machines to gain human expertise. In this paper, we investigate the effectiveness of transfer learning using fine-tuned features from modified deep neural architectures and certain ensemble learning methods for classifying the leukemia cell lines HL60, MOLT, and K562. Microfluidics-based imaging flow cytometry (mIFC) is used for obtaining the images instead of image cytometry. This is because mIFC guarantees significantly higher throughput and is easy to set up with minimal expenses. We find that the use of fine-tuned features from a modified deep neural network for transfer learning provides a substantial improvement in performance compared to earlier works. We also identify that without any fine tuning, feature selection using ensemble methods on the deep features also provide comparable performance on the considered Leukemia cell classification problem. These results show that automated methods can in fact be a valuable guide in cytopathological testing especially in resource limited settings.
CR Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Fornaciali M., IEEE 14 INT S BIOM I, P297
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gopakumar G, 2017, J OPT SOC AM A, V34, P111, DOI 10.1364/JOSAA.34.000111
   Gopakumar G, 2016, J MICROSC-OXFORD, V261, P307, DOI 10.1111/jmi.12335
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Li Q., 13 INT C CONTR AUT R, P844
   Liang ZH, 2016, IEEE INT C BIOINFORM, P493, DOI 10.1109/BIBM.2016.7822567
   Milletari F., 2016, 4 INT C 3D VIS
   Nayar R, 2014, CANCER TREAT RES, V160, pVII
   Pouliakis A, 2016, BIOMED ENG COMPUT BI, V7, P1, DOI 10.4137/BECB.S31601
   Samala R. K., 2016, MED PHYS, V43
   Schonbrun E, 2012, LAB CHIP, V12, P268, DOI 10.1039/c1lc20843h
   Thiran JP, 1996, IEEE T BIO-MED ENG, V43, P1011, DOI 10.1109/10.536902
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Zhenghao Shi, 2011, Journal of Multimedia, V6, P244, DOI 10.4304/jmm.6.3.244-251
   Zhu N, 2016, MED PHYS, V43, P3331, DOI 10.1118/1.4955603
NR 20
TC 0
Z9 0
BN 978-1-5386-2241-4
PY 2017
BP 127
EP 132
UT WOS:000458728700021
ER

PT B
AU da Silva, FL
   Glatt, R
   Costa, AHR
AF da Silva, Felipe Leno
   Glatt, Ruben
   Reali Costa, Anna Helena
GP Assoc Comp Machinery
TI Simultaneously Learning and Advising in Multiagent Reinforcement
   Learning
SO AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS
   AGENTS AND MULTIAGENT SYSTEMS
CT 16th International Conference on Autonomous Agents and Multiagent
   Systems (AAMAS)
CY MAY 08-12, 2017
CL Sao Paulo, BRAZIL
DE Transfer Learning; Multiagent Reinforcement Learning; Cooperative
   learning; Autonomous Advice Taking
AB Reinforcement Learning has long been employed to solve sequential decision-making problems with minimal input data. However, the classical approach requires a large number of interactions with an environment to learn a suitable policy. This problem is further intensified when multiple autonomous agents are simultaneously learning in the same environment. The teacher-student approach aims at alleviating this problem by integrating an advising procedure in the learning process, in which an experienced agent (human or not) can advise a student to guide her exploration. Even though previous works reported that an agent can learn faster when receiving advice, their proposals require that the teacher is an expert in the learning task. Sharing successful episodes can also accelerate learning, but this procedure requires a lot of communication between agents, which is unfeasible for domains in which communication is limited. Thus, we here propose a multiagent advising framework where multiple agents can advise each other while learning in a shared environment. If in any state an agent is unsure about what to do, it can ask for advice to other agents and may receive answers from agents that have more confidence in their actuation for that state. We perform experiments in a simulated Robot Soccer environment and show that the learning process is improved by incorporating this kind of advice.
CR Akiyama H., 2012, HELIOS TEAM BASE COD
   Amir O., 2016, P INT JOINT C ART IN, P804
   Azar Mohammad Gheshlaghi, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8188, P97, DOI 10.1007/978-3-642-40988-2_7
   Busoniu L, 2008, IEEE T SYST MAN CY C, V38, P156, DOI 10.1109/TSMCC.2007.913919
   Clouse J. A., 1996, ADAPTATION LEARNING
   Clouse J. A., 1992, ICML 92, P92
   Fernandez F., 2006, P 5 INT JOINT C AUT, P720
   Garant D., 2015, TECHNICAL REPORT
   Hausknecht M., 2016, AAMAS AD LEARN AG AL
   Kitano H., 1998, RoboCup-97: Robot Soccer. World Cup I, P62
   Kitano H, 1997, AI MAG, V18, P73
   Kitano H., 1997, Proceedings of the First International Conference on Autonomous Agents, P340, DOI 10.1145/267658.267738
   Koga ML, 2015, IEEE T CYBERNETICS, V45, P77, DOI 10.1109/TCYB.2014.2319733
   Lauer M., 2000, P 17 INT C MACH LEAR, P535
   Littman M. L., 1994, P 11 INT C MACH LEAR, P157
   Littman ML, 2015, NATURE, V521, P445, DOI 10.1038/nature14540
   Maclin R, 1996, MACH LEARN, V22, P251, DOI 10.1007/BF00114730
   Miller D., 2015, P HUM FACT ERG SOC A, V59, P1676
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ng AY, 2006, SPRINGER TRAC ADV RO, V21, P363
   Nunes L., 2003, AISB Journal, V1, P241
   Panait L, 2005, AUTON AGENT MULTI-AG, V11, P387, DOI 10.1007/s10458-005-2631-2
   Puterman M. L., 2005, MARKOV DECISION PROC
   Sherstov AA, 2005, LECT NOTES ARTIF INT, V3607, P194
   Silva F. L., 2017, P 31 AAAI C ART INT, P5034
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Sutton RS, 1996, ADV NEUR IN, V8, P1038
   Tan M., 1993, P 10 INT C MACH LEAR, P330
   Taylor ME, 2014, CONNECT SCI, V26, DOI 10.1080/09540091.2014.885279
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Torrey L, 2005, LECT NOTES ARTIF INT, V3720, P412
   Torrey L., 2013, P 2013 INT C AUT AG, P1053
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Zhan Y., 2016, P 25 INT JOINT C ART, P2315
   Zimmer M., 2014, AAMAS WORKSH AUT ROB
NR 35
TC 4
Z9 4
PY 2017
BP 1100
EP 1108
UT WOS:000461168100130
ER

PT B
AU Garant, D
   da Silva, BC
   Lesser, V
   Zhang, CJ
AF Garant, Dan
   da Silva, Bruno C.
   Lesser, Victor
   Zhang, Chongjie
GP Assoc Comp Machinery
TI Context-Based Concurrent Experience Sharing in Multiagent Systems
SO AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS
   AGENTS AND MULTIAGENT SYSTEMS
CT 16th International Conference on Autonomous Agents and Multiagent
   Systems (AAMAS)
CY MAY 08-12, 2017
CL Sao Paulo, BRAZIL
DE Transfer Learning; Multi-agent Systems; Reinforcement Learning
AB One of the key challenges for multi-agent learning is scalability. We introduce a technique for speeding up multi-agent learning by exploiting concurrent and incremental experience sharing. This solution adaptively identifies opportunities to transfer experiences between agents and allows for the rapid acquisition of appropriate policies in large-scale, stochastic, multi-agent systems. We introduce an online, supervisor-directed transfer technique for constructing high-level characterizations of an agent's dynamic learning environment-called contexts-which are used to identify groups of agents operating under approximately similar dynamics within a short temporal window. Supervisory agents compute contextual information for groups of subordinate agents, thereby identifying candidates for experience sharing. We show that our approach results in significant performance gains, that it is robust to noise-corrupted or suboptimal context features, and that communication costs scale linearly with the supervisor-to-subordinate ratio.
CR Boutsioukis Georgios, 2012, Recent Advances in Reinforcement Learning. 9th European Workshop (EWRL 2011). Revised Selected Papers, P249, DOI 10.1007/978-3-642-29946-9_25
   Carroll JL, 2005, IEEE IJCNN, P803
   Garant D., 2017, ARXIV E PRINTS
   Hu Y., 2015, P INT C AUT AG MULT, P753
   Kretchmar R. M., 2002, P 6 WORLD C SYST CYB
   Lazaric A., 2008, P 25 INT C MACH LEAR, P544
   Littman M. L., 2001, Cognitive Systems Research, V2, P55, DOI 10.1016/S1389-0417(01)00015-8
   Mnih V., 2016, ABS160201783 CORR
   Price B, 2003, J ARTIF INTELL RES, V19, P569, DOI 10.1613/jair.898
   Taylor A., 2013, THEOR GROUND TRANSF
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Zhang CJ, 2010, PROCEEDINGS OF THE TWENTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-10), P927
NR 12
TC 0
Z9 0
PY 2017
BP 1544
EP 1546
UT WOS:000461168100198
ER

PT B
AU Liebman, E
   Zavesky, E
   Stone, P
AF Liebman, Elad
   Zavesky, Eric
   Stone, Peter
GP Assoc Comp Machinery
TI Autonomous Model Management via Reinforcement Learning
SO AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS
   AGENTS AND MULTIAGENT SYSTEMS
CT 16th International Conference on Autonomous Agents and Multiagent
   Systems (AAMAS)
CY MAY 08-12, 2017
CL Sao Paulo, BRAZIL
AB Concept drift - a change, either sudden or gradual, in the underlying properties of data - is one of the most prevalent challenges to maintaining high-performing learned models over time in autonomous systems. In the face of concept drift, one can hope that the old model is sufficiently representative despite concept drift. Alternatively, one can discard the old data and retrain a new model with (often limited) new data, or use transfer learning to combine the old data with the new to create an updated model. Which of these three options is chosen affects not only near-term decisions, but also future modeling actions. In this abstract, we model response to concept drift as a sequential decision making problem and formally frame it as a Markov Decision Process. Our reinforcement learning approach to the problem shows promising results balancing cost with performance in maintaining model accuracy.
CR Chiosi M., 2015, OPEN DAYLIGHT SUMMIT, V7
   Chow C. - S., 1989, OPTIMAL MULTIGRID AL
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Gomez-Uribe C.A., 2015, ACM T MANAGE INF SYS, V6
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ring M. B., 2015, THESIS
   Ruvolo P., 2013, ICML, V28, P507
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Singh S, 2010, IEEE T AUTON MENT DE, V2, P70, DOI 10.1109/TAMD.2010.2051031
   Sutton R. S., INTRO REINFORCEMENT
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Torrey L., 2009, HDB RES MACHINE LEAR, V1, P242, DOI DOI 10.1016/J.JBI.2011.04.009
   Tsymbal A., 2004, PROBLEM CONCEPT DRIF, V106
   Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900
   Zliobaite I., 2010, ARXIV10104784
NR 16
TC 0
Z9 0
PY 2017
BP 1601
EP 1603
UT WOS:000461168100218
ER

PT B
AU Zhang, JZ
   Bareinboim, E
AF Zhang, Junzhe
   Bareinboim, Elias
GP Assoc Comp Machinery
TI Transfer Learning in Multi-Armed Bandit: A Causal Approach
SO AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS
   AGENTS AND MULTIAGENT SYSTEMS
CT 16th International Conference on Autonomous Agents and Multiagent
   Systems (AAMAS)
CY MAY 08-12, 2017
CL Sao Paulo, BRAZIL
DE Causal Inference; Transfer Learning; Reinforcement Learning
AB We leverage causal inference tools to support a principled and more robust transfer of knowledge in reinforcement learning (RL) settings. In particular, we tackle the problem of transferring knowledge across bandit agents in settings where causal effects cannot be identified by Pearl's do-calculus nor standard off-policy learning techniques. Our new identification strategy combines two steps - first, deriving bounds over the arm's distribution based on structural knowledge; second, incorporating these bounds in a novel bandit algorithm, B-kl-UCB. Simulations demonstrate that our strategy is consistently more efficient than the current (non-causal) state-of-the-art methods.
CR Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Bareinboim E., 2015, ADV NEURAL INFORM PR, P1342
   Bareinboim E., 2012, P 28 C UNC ART INT, P113
   Bareinboim E, 2016, P NATL ACAD SCI USA, V113, P7345, DOI 10.1073/pnas.1510507113
   Cappe O, 2013, ANN STAT, V41, P1516, DOI 10.1214/13-AOS1119
   Heckerman D., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P262
   Huang Y., 2006, P 22 C UNC ART INT, P217
   Imbens GW, 1997, ANN STAT, V25, P305
   Konidaris G., BUILDING PORTABLE OP
   Lazaric A, 2012, ADAPT LEARN OPTIM, V12, P143
   Liu Y., 2006, VALUE FUNCTION BASED
   Mehta N, 2008, MACH LEARN, V73, P289, DOI 10.1007/s10994-008-5061-y
   Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.1093/biomet/82.4.669
   Pearl J, 2000, CAUSALITY MODELS REA
   Shpitser I, 2006, P 22 C UNC ART INT, P437
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Tian J, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P567
NR 18
TC 0
Z9 0
PY 2017
BP 1778
EP 1780
UT WOS:000461168100278
ER

PT S
AU Ntalampiras, S
   Potamitis, I
AF Ntalampiras, Stavros
   Potamitis, Ilyas
BE Boracchi, G
   Iliadis, L
   Jayne, C
   Likas, A
TI Emotion Prediction of Sound Events Based on Transfer Learning
SO ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EANN 2017
SE Communications in Computer and Information Science
CT 18th International Conference on Engineering Applications of Neural
   Networks (EANN)
CY AUG 25-27, 2017
CL Athens, GREECE
DE Audio emotion prediction; Transfer learning; Echo State Network;
   Regression
ID RECOGNITION; SIGNALS; MUSIC
AB Processing generalized sound events with the purpose of predicting the emotion they might evoke is a relatively young research field. Tools, datasets, and methodologies to address such a challenging task are still under development, far from any standardized format. This work aims to cover this gap by revealing and exploiting potential similarities existing during the perception of emotions evoked by sound events and music. o this end we propose (a) the usage of temporal modulation features and (b) a transfer learning module based on an Echo State Network assisting the prediction of valence and arousal measurements associated with generalized sound events. The effectiveness of the proposed transfer learning solution is demonstrated after a thoroughly designed experimental phase employing both sound and music data. The results demonstrate the importance of transfer learning in the specific field and encourage further research on approaches which manage the problem in a cooperative way.
OI Ntalampiras, Stavros/0000-0003-3482-9215
CR Asadi Reza, 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920410
   Bradley M., 2004, B3 U FLOR
   Clark P, 2009, IEEE T SIGNAL PROCES, V57, P4323, DOI 10.1109/TSP.2009.2025107
   Drossos K., 2012, P 7 AUD MOSTL C C IN, P109
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Fukayama S, 2016, INT CONF ACOUST SPEE, P71, DOI 10.1109/ICASSP.2016.7471639
   GANG MJ, 1975, PSYCHOPHYSIOLOGY, V12, P423, DOI 10.1111/j.1469-8986.1975.tb00016.x
   Garner T., 2011, P 6 AUD MOSTL C C IN, P31, DOI DOI 10.1145/2095667.2095672
   Hozjan V, 2006, J ACOUST SOC AM, V119, P3109, DOI 10.1121/1.2188647
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277
   Jalalvand A, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1736
   Klapuri A, 2008, IEEE T AUDIO SPEECH, V16, P255, DOI 10.1109/TASL.2007.908129
   Lee C., 2014, J ACOUST SOC AM, V135, P2422
   Lin YL, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4898
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Marcell M, 2007, BEHAV RES METHODS, V39, P561, DOI 10.3758/BF03193026
   Markov K, 2014, IEEE ACCESS, V2, P688, DOI 10.1109/ACCESS.2014.2333095
   Ntalampiras S, 2014, 15 ANN C INT SPEECH, P1782
   Ntalampiras S, 2017, J ACOUST SOC AM, V141, P1694, DOI 10.1121/1.4977749
   Ntalampiras S, 2015, J AUDIO ENG SOC, V63, P358, DOI 10.17743/jaes.2015.0025
   Ntalampiras S, 2012, J AUDIO ENG SOC, V60, P686
   Ntalampiras S, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/594103
   SCHARF B, 1961, PSYCHOL BULL, V58, P205, DOI 10.1037/h0049235
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schimmel SM, 2007, INT CONF ACOUST SPEE, P605
   Schuller B, 2013, INTERSPEECH, P148
   Schuller B, 2012, INT CONF ACOUST SPEE, P341, DOI 10.1109/ICASSP.2012.6287886
   Shigeno Sumi, 2016, J ACOUST SOC AM, V140, P3399
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Soleymani M., 2013, P 2 ACM INT WORKSH C, P1, DOI DOI 10.1109/ETFA.2013.6648157
   Verstraeten D, 2007, NEURAL NETWORKS, V20, P391, DOI 10.1016/j.neunet.2007.04.003
   Verstraeten D, 2006, IEEE IJCNN, P1050
   Vinton MS, 2001, INT CONF ACOUST SPEE, P3277, DOI 10.1109/ICASSP.2001.940358
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Yi-Hsuan Y, 2012, ACM T INTEL SYST TEC, V3
NR 35
TC 0
Z9 0
SN 1865-0929
EI 1865-0937
BN 978-3-319-65172-9; 978-3-319-65171-2
PY 2017
VL 744
BP 303
EP 313
DI 10.1007/978-3-319-65172-9_26
UT WOS:000454701500026
ER

PT S
AU Georgakopoulos, SV
   Kottari, K
   Delibasis, K
   Plagianakos, VP
   Maglogiannis, I
AF Georgakopoulos, S., V
   Kottari, K.
   Delibasis, K.
   Plagianakos, V. P.
   Maglogiannis, I
BE Boracchi, G
   Iliadis, L
   Jayne, C
   Likas, A
TI Detection of Malignant Melanomas in Dermoscopic Images Using
   Convolutional Neural Network with Transfer Learning
SO ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EANN 2017
SE Communications in Computer and Information Science
CT 18th International Conference on Engineering Applications of Neural
   Networks (EANN)
CY AUG 25-27, 2017
CL Athens, GREECE
DE Skin lesion; Melanoma detection; Computer Vision-based diagnostic
   systems; Convolutional neural networks - CNN; CNN architectures;
   Transfer learning
ID SKIN-CANCER; DIAGNOSIS; STREAKS
AB In this work, we report the use of convolutional neural networks for the detection of malignant melanomas against nevus skin lesions in a dataset of dermoscopic images of the same magnification. The technique of transfer learning is utilized to compensate for the limited size of the available image dataset. Results show that including transfer learning in training CNN architectures improves significantly the achieved classification results.
CR American Cancer Society, 2015, CANC FACTS FIG 2015
   Bottou L., 1998, ONLINE LEARNING NEUR, V17, P9
   Delibasis K, 2015, IFIP ADV INF COMM TE, V458, P45, DOI 10.1007/978-3-319-23868-5_4
   Deng J., 2009, CVPR09
   Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Maglogiannis I, 2015, COMPUT METH PROG BIO, V118, P124, DOI 10.1016/j.cmpb.2014.12.001
   Maglogiannis I, 2009, IEEE T INF TECHNOL B, V13, P721, DOI 10.1109/TITB.2009.2017529
   Maglogiannis Ilias G, 2004, BMC Med Inform Decis Mak, V4, P4, DOI 10.1186/1472-6947-4-4
   Maragoudakis M, 2010, P 10 IEEE INT C INF, P1, DOI [10.1109/ITAB.2010.5687620, DOI 10.1109/ITAB.2010.5687620]
   Menzies SW, 2006, DERMATOL THER, V19, P32, DOI 10.1111/j.1529-8019.2005.00054.x
   Reed KB, 2012, MAYO CLIN PROC, V87, P328, DOI 10.1016/j.mayocp.2012.01.010
   Rogers HW, 2010, ARCH DERMATOL, V146, P283, DOI 10.1001/archdermatol.2010.19
   Sadeghi M, 2013, IEEE T MED IMAGING, V32, P849, DOI 10.1109/TMI.2013.2239307
   Sadeghi M, 2012, LECT NOTES COMPUT SC, V7510, P298, DOI 10.1007/978-3-642-33415-3_37
   Stern RS, 2010, ARCH DERMATOL, V146, P279, DOI 10.1001/archdermatol.2010.4
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 22
TC 0
Z9 0
SN 1865-0929
EI 1865-0937
BN 978-3-319-65172-9; 978-3-319-65171-2
PY 2017
VL 744
BP 404
EP 414
DI 10.1007/978-3-319-65172-9_34
UT WOS:000454701500034
ER

PT S
AU Sorensen, S
   Treible, W
   Hsu, L
   Wang, XL
   Mahoney, AR
   Zitterbart, DP
   Kambhamettu, C
AF Sorensen, Scott
   Treible, Wayne
   Hsu, Leighanne
   Wang, Xiaolong
   Mahoney, Andrew R.
   Zitterbart, Daniel P.
   Kambhamettu, Chandra
BE Sharma, P
   Bianchi, FM
TI Deep Learning for Polar Bear Detection
SO IMAGE ANALYSIS, SCIA 2017, PT I
SE Lecture Notes in Computer Science
CT 20th Scandinavian Conference on Image Analysis (SCIA)
CY JUN 12-14, 2017
CL Tromso, NORWAY
DE Deep learning; Thermal imaging; Marine mammals
AB Marine mammals in the Arctic are threatened by a changing climate and increasing human activity in the region. International laws protect these animals, however detecting and identifying them is not always easy. We have developed a multimodal approach using an omnidirectional thermal camera system, and an optical band stereo system operating in parallel. Using a unified framework for transfer learning with convolutional neural networks in both modalities we have trained a system to detect and classify mammals as well as habitat indicators in the images from both camera systems. Our experiments show that mammal habitat can be identified reliably using these techniques, and our analysis provides a framework for real world use cases.
CR Abadi M, 2015, TENSORFLOW LARGE SCA
   Amstrup SC, 2004, BIOSCIENCE, V54, P337, DOI 10.1641/0006-3568(2004)054[0337:DDPBWF]2.0.CO;2
   Baldacci A., 2005, TECHNICAL REPORT
   BROOKS J W, 1972, IUCN (International Union for Conservation of Nature and Natural Resources) Publications New Series, V23, P138
   Graber J, 2011, THESIS
   Lu G, 2014, INT SOC OPTICS PHOTO
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Rohith MV, 2013, IEEE IMAGE PROC, P2232, DOI 10.1109/ICIP.2013.6738460
   Rohith MV, 2013, IEEE COMPUT SOC CONF, P407, DOI 10.1109/CVPRW.2013.68
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Sorensen S., 2017, P INT C MULT MOD JAN
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Zitterbart DP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071217
NR 14
TC 1
Z9 1
SN 0302-9743
EI 1611-3349
BN 978-3-319-59126-1; 978-3-319-59125-4
PY 2017
VL 10269
BP 457
EP 467
DI 10.1007/978-3-319-59126-1_38
PN I
UT WOS:000454359300038
ER

PT B
AU Liu, SL
   Pan, SJ
   Ho, QR
AF Liu, Sulin
   Pan, Sinno Jialin
   Ho, Qirong
GP ACM
TI Distributed Multi-Task Relationship Learning
SO KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY AND DATA MINING
CT 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 13-17, 2017
CL Halifax, CANADA
DE Distributed Multi-Task Learning; Transfer Learning
ID MULTIPLE TASKS; ALGORITHMS
AB Multi-task learning aims to learn multiple tasks jointly by exploiting their relatedness to improve the generalization performance for each task. Traditionally, to perform multi-task learning, one needs to centralize data from all the tasks to a single machine. However, in many real-world applications, data of different tasks may be geo-distributed over different local machines. Due to heavy communication caused by transmitting the data and the issue of data privacy and security, it is impossible to send data of different task to a master machine to perform multi-task learning. Therefore, in this paper, we propose a distributed multi-task learning framework that simultaneously learns predictive models for each task as well as task relationships between tasks alternatingly in the parameter server paradigm. In our framework, we first offer a general dual form for a family of regularized multi-task relationship learning methods. Subsequently, we propose a communication-efficient primal-dual distributed optimization algorithm to solve the dual problem by carefully designing local subproblems to make the dual problem decomposable. Moreover, we provide a theoretical convergence analysis for the proposed algorithm, which is specific for distributed multi-task relationship learning. We conduct extensive experiments on both synthetic and real-world datasets to evaluate our proposed framework in terms of effectiveness and convergence.
CR Ahmed Amr, 2014, P 7 ACM INT C WEB SE, P153
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Balcan Maria-Florina, 2012, COLT
   Baytas IM, 2016, IEEE DATA MINING, P11, DOI [10.1109/ICDM.2016.0012, 10.1109/ICDM.2016.61]
   Blitzer J., 2007, ANN M ASS COMP LING, V7, P440, DOI DOI 10.1109/IRPS.2011.5784441
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Cavallanti G, 2010, J MACH LEARN RES, V11, P2901
   Dinuzzo F, 2011, IEEE T NEURAL NETWOR, V22, P290, DOI 10.1109/TNN.2010.2095882
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Forero PA, 2010, J MACH LEARN RES, V11, P1663
   Jacob L, 2009, ADV NEURAL INFORM PR, P745
   Kato T, 2008, ADV NEURAL INFORM PR, P737
   Li M., 2014, 11 USENIX S OP SYST, P583
   Ma Chenxin, 2015, JMLR WORKSHOP C P, P1973
   Meng X., 2015, ARXIV150506807
   Newman D, 2009, J MACH LEARN RES, V10, P1801
   Obozinski G, 2010, STAT COMPUT, V20, P231, DOI 10.1007/s11222-008-9111-x
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rahimi Ali, 2007, ADV NEURAL INFORM PR, P1177
   Richtarik P, 2016, MATH PROGRAM, V156, P433, DOI 10.1007/s10107-015-0901-6
   Richtarik Peter, 2013, ARXIV13102059
   Saha Avishek, 2011, INT C ART INT STAT, P643
   Shalev-Shwartz S, 2013, J MACH LEARN RES, V14, P567
   Shamir Ohad, 2014, JMLR WORKSHOP C P, P1000
   Tappenden Rachael, 2015, ARXIV150303033
   Wang Jialei, 2016, AISTATS, P751
   Wang Jialei, 2016, ARXIV160302185
   Xing Eric P., 2015, IEEE Transactions on Big Data, V1, P49, DOI 10.1109/TBDATA.2015.2472014
   Yang T, 2013, ADV NEURAL INFORM PR, P629
   Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733
   Zhang Y, 2015, IEEE DATA MINING, P629, DOI 10.1109/ICDM.2015.130
NR 34
TC 2
Z9 2
BN 978-1-4503-4887-4
PY 2017
BP 937
EP 946
DI 10.1145/3097983.3098136
UT WOS:000455787300107
ER

PT B
AU Golovin, D
   Solnik, B
   Moitra, S
   Kochanski, G
   Karro, J
   Sculley, D
AF Golovin, Daniel
   Solnik, Benjamin
   Moitra, Subhodeep
   Kochanski, Greg
   Karro, John
   Sculley, D.
GP ACM
TI Google Vizier: A Service for Black-Box Optimization
SO KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY AND DATA MINING
CT 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 13-17, 2017
CL Halifax, CANADA
DE Black-Box Optimization; Bayesian Optimization; Gaussian Processes;
   Hyperparameters; Transfer Learning; Automated Stopping
AB Any sufficiently complex system acts as a black box when it becomes easier to experiment with than to understand. Hence, black-box optimization has become increasingly important as systems have become more complex. In this paper we describe Google Vizier, a Google-internal service for performing black-box optimization that has become the de facto parameter tuning engine at Google. Google Vizier is used to optimize many of our machine learning models and other systems, and also provides core capabilities to Google's Cloud Machine Learning HyperTune subsystem. We discuss our requirements, infrastructure design, underlying algorithms, and advanced features such as transfer learning and automated early stopping that the service provides.
CR Bardenet R., 2013, JMLR WORKSH C P, P199
   Bergstra J. S., 2011, ADV NEURAL INFORM PR, P2546
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   CHERNOFF H, 1959, ANN MATH STAT, V30, P755, DOI 10.1214/aoms/1177706205
   Collins Jasmine, 2017, PROF INT C LEARN REP
   Conn AR, 2009, INTRO DERIVATIVE FRE
   Desautels T, 2014, J MACH LEARN RES, V15, P3873
   Domhan T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3460
   Finck Steffen, 2009, REAL PARAMETER BLACK
   Gardner  J., 2014, P 31 INT C MACH LEAR, P937
   Gelbart M. A., 2014, P 30 C UNC ART INT, P250
   GINEBRA J, 1995, J ROY STAT SOC B MET, V57, P771
   GRAMACY R. B., 2011, BAYESIAN STAT, P229
   Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Heinrich J, 2013, STAR P EUR, V2013, P95, DOI [10.2312/conf/EG2013/stars/095-116, DOI 10.2312/C0NF/EG2013/STARS/095-116, DOI 10.2312/CONF/EG2013/STARS/095-116]
   Hutter Frank, 2011, Learning and Intelligent Optimization. 5th International Conference, LION 5. Selected Papers, P507, DOI 10.1007/978-3-642-25566-3_40
   Li Lisha, 2016, CORR
   Mockus J, 1978, APPL BAYESIAN METHOD, V2, P117
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rios LM, 2013, J GLOBAL OPTIM, V56, P1247, DOI 10.1007/s10898-012-9951-y
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Snoek J., 2015, P 32 INT C MACH LEAR, P2171
   Snoek J., 2012, ADV NEURAL INFORM PR, P2951
   Springenberg J. T., 2016, ADV NEURAL INFORM PR, P4134, DOI [10.1152/jn.00333.2004, DOI 10.1152/JN.00333.2004]
   Srinivas N., 2010, ICML
   Swersky K., 2014, ARXIV14063896
   Wilson A. G., 2016, P 19 INT C ART INT S, P370
   Yogatama D., 2014, JMLR P, V33, P1077
   Zaremba W., 2014, ARXIV14092329
NR 31
TC 12
Z9 12
BN 978-1-4503-4887-4
PY 2017
BP 1487
EP 1496
DI 10.1145/3097983.3098043
UT WOS:000455787300161
ER

PT B
AU Huang, WZ
   Yang, PP
   Huang, KQ
AF Huang, Wenzhen
   Yang, Peipei
   Huang, Kaiqi
GP IEEE
TI From Classification to Regression: Model Transfer for Visual Aesthetic
   Quality Assessment
SO PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR)
CT 4th IAPR Asian Conference on Pattern Recognition (ACPR)
CY NOV 26-29, 2017
CL Nanjing, PEOPLES R CHINA
DE Transfer Learning; Multi-task Learning; Visual Aesthetic Quality
   Assessment
AB Visual aesthetic quality assessment has played an important role in increasing number of computer vision applications. Particularly, estimating the quality score precisely is a main task of aesthetic quality assessment, but the training samples labeled with score are usually expensive to obtain. In this paper, we propose a transfer learning method which can improve the performance of aesthetic score prediction by using the coarse labeled samples, which are much easier to obtain. The proposed method incorporates the coarse information from source domain into the target domain by a novel multi-task framework, which can revise the model in target task. The effectiveness of our method is proven by experimental results that the error is reduced obviously with the help of source domain.
CR Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Chang MW, 2005, NEURAL COMPUT, V17, P1188, DOI 10.1162/0899766053491869
   Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155
   Dai W., 2007, P 24 INT C MACH LEAR, P193, DOI DOI 10.1145/1273496.1273521
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Gong B., 2013, P 30 INT C MACH LEAR, P222
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Hao Lv, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings:, P493, DOI 10.1007/978-3-319-27671-7_41
   Jiang Y.-G., 2017, IEEE T PATTERN ANAL
   Kao Y., 2017, IEEE T IMAGE PROCESS
   Kao YY, 2015, IEEE IMAGE PROC, P1583, DOI 10.1109/ICIP.2015.7351067
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Long M., 2015, INT C MACH LEARN, P97
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Luo Y, 2014, IEEE T IMAGE PROCESS, V23, P3789, DOI 10.1109/TIP.2014.2332398
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Murray N., 2012, BMVC, P1
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Raina R., 2007, LEARNING, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Shi H., 2015, BMVC, P158
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Wang Y, 2013, PERFORMANCE-BASED FIRE ENGINEERING OF STRUCTURES, P1
   Zhang Y, 2014, ACM T KNOWL DISCOV D, V8, DOI 10.1145/2538028
NR 30
TC 0
Z9 0
BN 978-1-5386-3354-0
PY 2017
BP 304
EP 309
DI 10.1109/ACPR.2017.127
UT WOS:000455581900052
ER

PT B
AU Tian, Y
   Zhao, CR
   Chen, K
   Chen, YP
   Wei, ZH
   Miao, DQ
AF Tian, Yuan
   Zhao, Cairong
   Chen, Kang
   Chen, Yipeng
   Wei, Zhihua
   Miao, Duoqian
GP IEEE
TI Discriminative Transfer Learning Siamese CNN for Person
   Re-Identification
SO PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR)
CT 4th IAPR Asian Conference on Pattern Recognition (ACPR)
CY NOV 26-29, 2017
CL Nanjing, PEOPLES R CHINA
DE person re-identification; convolutional neural network; knowledge
   transfer
AB Person re-identification (Re-ID) has become an increasingly popular computer vision problem. It remains challenging, especially when there are non-overlapping cameras. In this paper, we review the two representative architecture, i.e., identification and verification models. They both have their advancements and limitations. We present a novel method to address the Re-ID problem. First, combine the two models to consist a more effective fusion loss function. Second, we find that CNNs which are pre-trained on large image datasets learn more discriminative knowledge with objective semantic, which can be transferred to subsequent layers to promote accuracy significantly. Experiments on four benchmark datasets show the superiority of our method over the state-of-the-art alternatives.
CR Ahmed E., 2015, CVPR
   Bromley J., 1993, INT J PATTERN RECOGN, V7
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Cheng  D., 2016, CVPR
   Davis J. V., 2007, ICML
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   He K., 2016, P IEEE C COMP VIS PA
   Hirzer M., 2011, SCAND C IM AN
   Hu H., 2014, CVPR
   Huang C., 2016, CVPR
   Koestinger M., 2012, CVPR
   Li Wei, 2014, CVPR
   Li W, 2014, IEEE IPCCC
   Matsukawa  T., 2016, CVPR
   Paisitkriangkrai S., 2015, CVPR
   Philbin J., 2007, 2007 IEEE C COMP VIS
   Simonyan K., 2014, ARXIV14091556
   Varior R. R., 2016, EUR C COMP VIS
   Wang F., 2016, CVPR
   Wu L., 2016, PATTERN RECOGNITION
   Wu L., 2016, ARXIV160107255
   Xiao  T., 2016, ARXIV160401850
   Xiao T., 2016, CVPR
   Xiong F., 2014, ECCV
   Yi D., 2014, ICPR
   Yi D., PATT REC ICPR 2014 2
   Zhang  L., 2016, CVPR
   Zhao  R., 2013, CVPR
   Zheng L., 2016, ARXIV161002984
   Zheng L., 2015, P IEEE INT C COMP VI
NR 31
TC 0
Z9 0
BN 978-1-5386-3354-0
PY 2017
BP 583
EP 587
DI 10.1109/ACPR.2017.119
UT WOS:000455581900099
ER

PT B
AU Hu, J
   Liu, Z
   Yu, DJ
AF Hu, Jun
   Liu, Zi
   Yu, Dong-Jun
GP IEEE
TI Enhancing Protein-ATP and Protein-ADP Binding Sites Prediction Using
   Supervised Instance-Transfer Learning
SO PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR)
CT 4th IAPR Asian Conference on Pattern Recognition (ACPR)
CY NOV 26-29, 2017
CL Nanjing, PEOPLES R CHINA
DE Protein-ATP binding site prediction; Protein-ADP binding site
   prediction; Instance transfer learning; Random under sampling
ID RESIDUES; DNA; SEQUENCE
AB Protein-ATP and protein-ADP interactions are ubiquitous in a wide variety of biological processes. Accurately identifying ATP-binding and ADP-binding sites or pockets is of significant importance for both protein function analysis and drug design. Although much progress has been made, challenges remain, especially in the post-genome era where large volume of proteins without being functional annotated are quickly accumulated. In this study, we report an instance-transfer-learning-based predictor, ATP&ADPsite, to target both ATP-binding and ADP-binding residues from protein sequence and structural information. ATP&ADPsite first employs evolutionary information, predicted secondary structure, and predicted solvent accessibility to represent each residue sample. In the above feature space, a supervised instance-transfer-learning method is proposed to improve the ATP-binding/ADP-binding residues prediction by combining ATP-binding and ADP-binding proteins. Random under-sampling is lastly employed to solve the imbalanced data learning problem. Experimental results demonstrate that the proposed ATP&ADPsite achieves a better prediction performance and outperforms many existing sequence-based predictors. The ATP&ADPsite web-server is available at http ://csbio.njust. edu.cn/bioinf/ATP&ADPsite.
CR Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432
   Ahmad S, 2008, NUCLEIC ACIDS RES, V36, P5922, DOI 10.1093/nar/gkn573
   Anirudh R., 2015, INT J COMPUT VISION, P1
   Berman HM, 2002, ACTA CRYSTALLOGR D, V58, P899, DOI 10.1107/S0907444902003451
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chauhan JS, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-434
   Chen K, 2012, BIOINFORMATICS, V28, P331, DOI 10.1093/bioinformatics/btr657
   Chen K, 2011, PROTEOME SCI, V9, DOI 10.1186/1477-5956-9-S1-S4
   Gao M, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003302
   Gao M, 2013, BIOINFORMATICS, V29, P597, DOI 10.1093/bioinformatics/btt024
   Hu J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107676
   Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091
   Joo K, 2012, PROTEINS, V80, P1791, DOI 10.1002/prot.24074
   Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158
   Maxwell A, 2003, CURR TOP MED CHEM, V3, P283, DOI 10.2174/1568026033452500
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rose PW, 2011, NUCLEIC ACIDS RES, V39, pD392, DOI 10.1093/nar/gkq1021
   Schmidtke P, 2010, J MED CHEM, V53, P5858, DOI 10.1021/jm100574m
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Si JN, 2015, INT J MOL SCI, V16, P5194, DOI 10.3390/ijms16035194
   Vapnik VN, 1998, STAT LEARNING THEORY
   Wang LJ, 2006, NUCLEIC ACIDS RES, V34, pW243, DOI 10.1093/nar/gkl298
   Yang JY, 2013, NUCLEIC ACIDS RES, V41, pD1096, DOI 10.1093/nar/gks966
   Yu DJ, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-297
   Yu DJ, 2013, IEEE ACM T COMPUT BI, V10, P994, DOI 10.1109/TCBB.2013.104
   Yu DJ, 2013, NEUROCOMPUTING, V104, P180, DOI 10.1016/j.neucom.2012.10.012
   Yu DJ, 2013, J COMPUT CHEM, V34, P974, DOI 10.1002/jcc.23219
NR 27
TC 0
Z9 0
BN 978-1-5386-3354-0
PY 2017
BP 759
EP 763
DI 10.1109/ACPR.2017.9
UT WOS:000455581900129
ER

PT B
AU Bhatt, G
   Jha, P
   Raman, B
AF Bhatt, Gaurav
   Jha, Piyush
   Raman, Balasubramanian
GP IEEE
TI Common Representation Learning Using Step-based Correlation Multi-Modal
   CNN
SO PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR)
CT 4th IAPR Asian Conference on Pattern Recognition (ACPR)
CY NOV 26-29, 2017
CL Nanjing, PEOPLES R CHINA
DE common representation learning; multi-view data; transfer learning; deep
   learning
AB Deep learning techniques have been successfully used in learning a common representation for multi-view data, wherein the different modalities are projected onto a common subspace. In a broader perspective, the techniques used to investigate common representation learning falls under the categories of canonical correlation-based approaches and autoencoder based approaches. In this paper, we investigate the performance of deep autoencoder based methods on multi-view data. We propose a novel step-based correlation multi-modal CNN (CorrMCNN) which reconstructs one view of the data given the other while increasing the interaction between the representations at each hidden layer or every intermediate step. Finally, we evaluate the performance of the proposed model on two benchmark datasets - MNIST and XRMB. Through extensive experiments, we find that the proposed model achieves better performance than the current state-of-the-art techniques on joint common representation learning and transfer learning tasks.
CR Akaho S., 2006, CS0609071 ARXIV
   Andrew G., 2013, P 30 INT C MACH LEAR, V28, P1247
   Arora R., 2012, MLSLP, P34
   Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085
   Benton A., 2017, ARXIV170202519
   Chandar S., 2016, NEURAL COMPUTATION
   Eisenschtat  Aviv, 2016, ARXIV160807973
   Hardie W., 2007, MULTIVARIATE STAT EX, P263
   Hermann K. M., 2014, ARXIV14044641
   Hermann Karl Moritz, 2013, ARXIV13126173
   Hinton G. E., 2012, ARXIV12070580
   Ioffe S, 2015, INT C MACH LEARN, V37, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Klementiev A., 2012, INDUCING CROSSLINGUA
   Li J., 2015, ARXIV150601057
   Logan  B., 2000, ISMIR
   Lu Y., 2014, ADV NEURAL INFORM PR, V27, P91
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Michaeli T., 2016, P ICML 16 33 INT C I, P1967
   Mineiro P., 2014, ARXIV14113409
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Ng A, 2011, LECT NOTES STANFORD, V72, P1
   Ngiam J, 2011, IEEE INT C MACH LEAR, V28, P689
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Saha A., 2016, ARXIV160604754
   Thompson B., 2005, ENCY STAT BEHAV SCI
   Vinod H., 1976, J ECONOMETRICS, V4, P147, DOI DOI 10.1016/0304-4076(76)90010-5
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang S, 2015, INT CONF MACH LEARN, P883, DOI 10.1109/ICMLC.2015.7340670
   Wang WR, 2015, INT CONF ACOUST SPEE, P4590, DOI 10.1109/ICASSP.2015.7178840
   Westbury J., 1990, J ACOUST SOC AM, V88, pS56, DOI DOI 10.1121/1.20290
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu XC, 2014, BLIND SOURCE SEPARATION: THEORY AND APPLICATIONS, P145
NR 33
TC 0
Z9 0
BN 978-1-5386-3354-0
PY 2017
BP 864
EP 869
DI 10.1109/ACPR.2017.112
UT WOS:000455581900145
ER

PT B
AU Mehta, D
   Rhodin, H
   Casas, D
   Fua, P
   Sotnychenko, O
   Xu, WP
   Theobalt, C
AF Mehta, Dushyant
   Rhodin, Helge
   Casas, Dan
   Fua, Pascal
   Sotnychenko, Oleksandr
   Xu, Weipeng
   Theobalt, Christian
GP IEEE
TI Monocular 3D Human Pose Estimation In The Wild Using Improved CNN
   Supervision
SO PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON 3D VISION (3DV)
SE International Conference on 3D Vision
CT International Conference on 3D Vision (3DV)
CY OCT 10-12, 2017
CL Qingdao, CANADA
ID TRACKING
AB We propose a CNN-based approach for 3D human body pose estimation from single RGB images that addresses the issue of limited generalizability of models trained solely on the starkly limited publicly available 3D pose data. Using only the existing 3D pose data and 2D pose data, we show state-of-the-art performance on established benchmarks through transfer of learned features, while also generalizing to in-the-wild scenes. We further introduce a new training set for human body pose estimation from monocular images of real humans that has the ground truth captured with a multi-camera marker-less motion capture system. It complements existing corpora with greater diversity in pose, human appearance, clothing, occlusion, and viewpoints, and enables an increased scope of augmentation. We also contribute a new benchmark that covers outdoor and indoor scenes, and demonstrate that our 3D pose dataset shows better in-the-wild performance than existing annotated data, which is further improved in conjunction with transfer learning from 2D pose data. All in all, we argue that the use of transfer learning of representations in tandem with algorithmic and data contributions is crucial for general 3D body pose estimation.
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Andreasson M., 2014, INF SCI SYST CISS 20, VPP, P1
   Baak A., 2011, IEEE INT C COMP VIS, P1
   Balan A.O., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383340
   Belagiannis V., 2016, ARXIV160502914, P1
   Bogo F., 2016, EUR C COMP VIS ECCV, p[1, 2, 7]
   Brau E., 2016, INT C 3D VIS 3DV, P3
   Bulat A., 2016, EUR C COMP VIS ECCV, P1
   Carr JW, 2017, COGNITIVE SCI, V41, P892, DOI 10.1111/cogs.12371
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Chen CH, 2019, CEREB CORTEX, V29, P54, DOI [10.6693/CAR201712_30(1).0001, 10.1093/cercor/bhx303]
   Chen X., 2014, ADV NEURAL INFORM PR, P1736
   Cheng WC, 2017, INT J GEOMECH, V17, DOI 10.1061/(ASCE)GM.1943-5622.0000810
   Elhayek A., 2016, IEEE T PATTERN ANAL, p[2, 6]
   Everingham M., 2010, P BRIT MACH VIS C, V2, P5, DOI DOI 10.5244/C.24.12
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1
   Ganin Y, 2015, INT C MACH LEARN, P1180
   Gkioxari G., 2016, EUR C COMP VIS ECCV, P1
   He K., 2016, CVPR, P3
   Hu PJ, 2017, INT J COMPUT ASS RAD, V12, P399, DOI 10.1007/s11548-016-1501-5
   Insafutdinov E., 2016, EUR C COMP VIS ECCV, p[3, 6]
   Ionescu C, 2014, PROC CVPR IEEE, P1661, DOI 10.1109/CVPR.2014.215
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A., 2014, P AS C COMP VIS ACCV, P302
   Johnson S., 2011, P IEEE C COMP VIS PA, p[1, 3]
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Lehrmann AM, 2013, IEEE I CONF COMP VIS, P1281, DOI 10.1109/ICCV.2013.162
   Lepetit V., 2005, MONOCULAR MODEL BASE, P4
   Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Lifshitz I., 2016, EUR C COMP VIS ECCV, P1
   Long J., 2015, CVPR, P3
   Meka A., 2016, ACM T GRAPHIC, V35, P1
   Moreno-Noguer F., 2017, CVPR 2017 IEEE C COM, p[1, 7]
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Newell A., 2016, P EUR C COMPUT VIS, p[1, 2]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pavlakos G., 2017, P IEEE C COMP VIS PA, p[1, 2, 7, 8]
   Pishchulin L., 2016, IEEE C COMP VIS PATT, p[1, 2]
   Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052
   Pons-Moll G, 2014, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2014.300
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rhodin H., 2016, ACM T GRAPHIC, P5
   Rhodin H, 2016, LECT NOTES COMPUT SC, V9909, P509, DOI 10.1007/978-3-319-46454-1_31
   Robertini N., 2016, INT C COMP VIS 3DV
   Rogez G., 2017, CVPR 2017 IEEE C COM, p[3, 7]
   Rogez G., 2016, ADV NEURAL INFORM PR, P3108
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sapp B., 2013, IEEE C COMP VIS PATT, P1
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466
   Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988
   Sminchisescu C, 2001, PROC CVPR IEEE, P447
   Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915
   Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338
   Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885
   Tekin B., 2016, ARXIV161105708, p[2, 3]
   Tekin B., 2016, IEEE C COMP VIS PATT, p[1, 2, 7]
   Tekin B., 2016, BRIT MACH VIS C BMVC, P1
   Tome D., 2017, IEEE C COMP VIS PATT, P1
   Tompson J. J., 2014, ADV NEURAL INFORM PR, P1799
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Urtasun R, 2005, PROC CVPR IEEE, P932
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Wei S.-E., 2016, ARXIV160200134, p[1, 2]
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yasin H., 2016, C COMP VIS PATT REC, p[1, 3]
   Yosinski J., 2014, ADV NEURAL INFORM PR, V27, P3320
   Yu Y, 2016, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-016-0085-x
   Zhou F, 2014, LECT NOTES COMPUT SC, V8694, P62, DOI 10.1007/978-3-319-10599-4_5
   Zhou X., 2015, CVPR, V1, P2
   Zhou X., 2015, ARXIV150904309, P2
   Zhou X., 2016, ENVIRON SCI POLLUT R, p[1, 2, 7, 8]
NR 76
TC 6
Z9 6
BN 978-1-5386-2610-8
PY 2017
BP 506
EP 516
DI 10.1109/3DV.2017.00064
UT WOS:000454981700054
ER

PT B
AU Kumari, M
   Hsieh, G
   Okonkwo, CA
AF Kumari, Mamta
   Hsieh, George
   Okonkwo, Christopher A.
BE Arabnia, HR
   Deligiannidis, L
   Tinetti, FG
   Tran, QN
   Yang, MQ
TI Deep Learning Approach To Malware Multi-Class Classification Using Image
   Processing Techniques
SO PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND
   COMPUTATIONAL INTELLIGENCE (CSCI)
CT International Conference on Computational Science and Computational
   Intelligence (CSCI)
CY DEC 14-16, 2017
CL Las Vegas, NV
DE Deep Learning; Convolutional Neural Networks; Transfer Learning; Malware
   Classification
AB Malicious software has been growing exponentially during the past years. One of the major challenges for antimalware industry is the vast amounts of data and files which need to be evaluated for potential malicious content. To effectively analyze such large amounts of files, machine learning based malware classification approaches have been developed to classify malware into families based on the same forms of malicious behaviors. This paper presents our design and implementation of a malware classification approach using the Convolutional Neural Networks (CNNs), a prime example of deep learning algorithms. It makes use of CNNs to learn a feature hierarchy for classifying samples of malware binary files, represented as gray-scale images, to their corresponding families. It also uses transfer learning techniques to facilitate model building. Three different models of CNNs were developed and these implemented methods achieved validation accuracy around 97% using the large malware dataset provided for the Microsoft Malware Classification Challenge (BIG 2015).
CR Abadi M, 2015, ARXIV160304467
   Chollet F., 2015, NON TRADITIONAL REF
   David O. E., 2015, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/IJCNN.2015.7280815
   Deshpande A., 2016, NON TRADITIONAL REF
   Fergus R., 2015, NEURAL NETWORKS
   Gandotra E., 2014, J INF SECUR, V5, P56, DOI DOI 10.4236/JIS.2014.52006
   Gibert D., 2016, CONVOLUTIONAL NEURAL
   Guerrero Gomez-Ol R., 2016, DEEP LEARNING FRAMEW
   Gupta D., 2017, DEEP LEARNING
   Kaggle, 2015, MICR MALW CLASS CHAL
   Karn U., 2016, INTUITIVE EXPLANATIO
   Karpathy Andrej, 2015, NON TRADITIONAL REF
   Kolosnjaji B., 2017, DEEP LEARNING CLASSI
   Krizhevsky A., 2012, ADV NEURAL INFORM PR
   LeCun Y., 1998, GRADIENT BASED LEARN
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Nataraj L., 2011, P VIZSEC 11 PITTSB P
   Schultz MG, 2001, P IEEE S SECUR PRIV, P38, DOI 10.1109/SECPRI.2001.924286
   Simonyan  K., 2015, VERY DEEP CONVOLUTIO
   Srivastava N., 2014, DROPOUT SIMPLE WAY P
   University of Toronto AI Course, ART NEUR NETW TECHN
NR 21
TC 0
Z9 0
BN 978-1-5386-2652-8
PY 2017
BP 13
EP 18
DI 10.1109/CSCI.2017.3
UT WOS:000455029500003
ER

PT B
AU Han, XB
   Li, K
AF Han, Xuebo
   Li, Kan
BE Arabnia, HR
   Deligiannidis, L
   Tinetti, FG
   Tran, QN
   Yang, MQ
TI Hierarchical-Dynamic Embedding for Zero-shot Object Recognition
SO PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND
   COMPUTATIONAL INTELLIGENCE (CSCI)
CT International Conference on Computational Science and Computational
   Intelligence (CSCI)
CY DEC 14-16, 2017
CL Las Vegas, NV
DE Object recognition; Zero-shot learning; Transfer learning;
   Visual-Semantic Embedding; Entity embedding
AB Zero-shot object recognition is aiming to attach unseen category labels to images which are out of the training set. The key challenge in Zero-shot learning is building the map between visual domain and semantic domain. However, previous Visual-Semantic Embedding ignores the essential difference between the vectors of category names and the vectors of the entities. Hybrid model, moreover, computes the middle vector with a fixed size candidate set which limits the generalization on different images. So we propose a novel framework named Hierarchical-Dynamic Embedding. First, Hierarchical Network Embedding (HNE) takes advantage of the internal hierarchical taxonomy of the category names. We then provide Dynamic Hybrid Model (DHM) to map unseen images from visual vectors to entity vectors. Furthermore, we conduct the experiments on 1,000 seen categories and 1,548 unseen categories to show the state-of-the-art performance of our proposed framework.
CR Akata Z., 2014, ARXIV14098403
   Al-Halah Z, 2015, IEEE WINT CONF APPL, P837, DOI 10.1109/WACV.2015.116
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Frome A., 2013, ADV NEURAL INFORM PR, P2121
   Hwang S. J., 2014, NIPS, P271
   Jayaraman D., 2014, ADV NEURAL INFORM PR, P3464
   Krizhevsky A, 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li XR, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P879, DOI 10.1145/2766462.2767773
   Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045
   LOWE D. G, 1999, P IEEE INT C COMP VI, V1999, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mikolov T., 2013, ADV NEURAL INFORM PR, P3111
   Mikolov T., 2013, ARXIV13013781
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Norouzi  M., 2013, ARXIV13125650
   Palatucci  Mark, 2009, ADV NEURAL INFORM PR, P1410
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627
   Romera-Paredes B., 2015, P 32 INT C MACH LEAR, P2152
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Socher R., 2013, ADV NEURAL INFORM PR, P935
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Xian Y., 2017, ARXIV170304394
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Yu XD, 2010, LECT NOTES COMPUT SC, V6315, P127
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
NR 30
TC 0
Z9 0
BN 978-1-5386-2652-8
PY 2017
BP 520
EP 525
DI 10.1109/CSCI.2017.88
UT WOS:000455029500092
ER

PT B
AU Luttrell, J
   Zhou, ZX
   Zhang, CY
   Gong, P
   Zhang, YY
AF Luttrell, Joseph
   Zhou, Zhaoxian
   Zhang, Chaoyang
   Gong, Ping
   Zhang, Yuanyuan
BE Arabnia, HR
   Deligiannidis, L
   Tinetti, FG
   Tran, QN
   Yang, MQ
TI Facial Recognition via Transfer Learning: Fine-tuning Keras_vggface
SO PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND
   COMPUTATIONAL INTELLIGENCE (CSCI)
CT International Conference on Computational Science and Computational
   Intelligence (CSCI)
CY DEC 14-16, 2017
CL Las Vegas, NV
DE convolutional neural networks; facial recognition; transfer learning;
   FERET image dataset
AB The challenge of developing facial recognition systems has been the focus of many research efforts in recent years and has numerous applications in areas such as security, entertainment, and biometrics. Recently, most progress in this field has come from training very deep neural networks on massive datasets. Here, we use a pre-trained face recognition model and perform transfer learning to produce a network that is capable of making accurate predictions on a much smaller dataset. We also compare our results with results produced by a selection of classical algorithms on the same dataset.
CR Abadi M., 2016, ARXIV160304467
   Charles PWD, 2013, KERAS
   Chen X., 2014, BIOMED RES INT, V2014, P1, DOI DOI 10.3109/19401736.2014.974166
   Chen XM, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500175
   Chen XM, 2015, LECT NOTES COMPUT SC, V9475, P248, DOI 10.1007/978-3-319-27863-6_23
   Fukushima K., 1982, COMPETITION COOPERAT, P267, DOI DOI 10.1007/978-3-642-46466-9_18
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Malli R. C., 2017, KERAS VGGFACE VGGFAC
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkhi O.M., 2015, P BR MACH VIS, V1, P6
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Xianming Chen, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P201, DOI 10.1109/ChinaSIP.2013.6625328
   Zhou Z., FACE RECOGNITION ALG
NR 17
TC 0
Z9 0
BN 978-1-5386-2652-8
PY 2017
BP 576
EP 579
DI 10.1109/CSCI.2017.98
UT WOS:000455029500103
ER

PT B
AU Sadeghi, Z
   Testolin, A
   Zorzi, M
AF Sadeghi, Zahra
   Testolin, Alberto
   Zorzi, Marco
GP IEEE
TI Bilingualism advantage in handwritten character recognition: A deep
   learning investigation on Persian and Latin scripts
SO PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND
   KNOWLEDGE ENGINEERING (ICCKE)
CT 7th International Conference on Computer and Knowledge Engineering
   (ICCKE)
CY OCT 26-27, 2017
CL Ferdowsi Univ, Mashhad, IRAN
HO Ferdowsi Univ
DE bilingualism; handwritten character recognition; deep learning;
   hierarchical generative models; restricted Boltzmann machines; transfer
   learning
ID INTERLEXICAL HOMOGRAPHS; ACCESS
AB In this study, we investigated the effects of mastering multiple scripts in handwritten character recognition by means of computational simulations. In particular, we trained a set of deep neural networks on two different datasets of handwritten characters: the HODA dataset, which is a collection of images of handwritten Persian digits, and the MNIST dataset, which contains Latin handwritten digits. We simulated native language individuals (trained on a single dataset) as well as bilingual individuals (trained on both datasets), and compared their performance in a recognition task performed under different noisy conditions. Our results show the superior performance of bilingual networks in handwritten digit recognition in comparison to the monolingual networks, thereby suggesting that mastering multiple languages might facilitate knowledge transfer across similar domains.
OI Testolin, Alberto/0000-0001-7062-4861
CR BEAUVILLAIN C, 1987, J MEM LANG, V26, P658, DOI 10.1016/0749-596X(87)90108-2
   BENZEEV S, 1977, CHILD DEV, V48, P1009, DOI 10.2307/1128353
   BijeljacBabic R, 1997, MEM COGNITION, V25, P447, DOI 10.3758/BF03201121
   de Groot AMB, 2000, Q J EXP PSYCHOL-A, V53, P397, DOI 10.1080/713755891
   Dehaene S, 2005, TRENDS COGN SCI, V9, P335, DOI 10.1016/j.tics.2005.05.004
   Dehaene S, 2007, NEURON, V56, P384, DOI 10.1016/j.neuron.2007.10.004
   Dussias P. E., 2001, SENTENCE PARSING FLU
   GERARD LD, 1989, J EXP PSYCHOL LEARN, V15, P305, DOI 10.1037/0278-7393.15.2.305
   Grainger J, 2008, TRENDS COGN SCI, V12, P381, DOI 10.1016/j.tics.2008.06.006
   Havy M., 2015, INT J BEHAV DEV
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Ibrahim R, 2009, NEUROPSYCHOLOGY, V23, P240, DOI 10.1037/a0014193
   Jared D, 2001, J MEM LANG, V44, P2, DOI 10.1006/jmla.2000.2747
   Kaushanskaya M, 2009, PSYCHON B REV, V16, P705, DOI 10.3758/PBR.16.4.705
   Khosravi H, 2007, PATTERN RECOGN LETT, V28, P1133, DOI 10.1016/j.patrec.2006.12.022
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LI P, 2002, BILINGUAL SENTENCE P
   Miikkulainen R, 2009, LECT NOTES COMPUT SC, V5629, P191, DOI 10.1007/978-3-642-02397-2_22
   Olsen RK, 2015, BRAIN RES, V1612, P128, DOI 10.1016/j.brainres.2015.02.034
   Pelli DG, 2006, VISION RES, V46, P4646, DOI 10.1016/j.visres.2006.04.023
   Sadeghi Z., 2017, COGN PROCESS, V14, P1
   Sadeghi Z, 2016, PERCEPTION, V45, P1036, DOI 10.1177/0301006616651950
   Sadeghi Z, 2015, COMPUT INTEL NEUROSC, DOI 10.1155/2015/905421
   Simpson I. C., 2012, BEHAV RES METHODS, P431
   Su J., 2016, COLING, P3071
   Tahan S, 2011, READ WRIT, V24, P1061, DOI 10.1007/s11145-011-9301-3
   Testolin A., 2017, NAT HUM BEHAV
   Testolin A, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00013
   Testolin A, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00073
   Testolin A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00251
   Wiley RW, 2016, J EXP PSYCHOL HUMAN, V42, P1186, DOI 10.1037/xhp0000213
   Zorzi M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00515
NR 34
TC 0
Z9 0
BN 978-1-5386-0804-3
PY 2017
BP 27
EP 32
UT WOS:000454813100005
ER

PT B
AU Korzh, O
   Cook, G
   Andersen, T
   Serra, E
AF Korzh, Oxana
   Cook, Gregory
   Andersen, Timothy
   Serra, Edoardo
GP IEEE
TI Stacking Approach for CNN Transfer Learning Ensemble for Remote Sensing
   Imagery
SO PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS)
CT Intelligent Systems Conference (IntelliSys)
CY SEP 07-08, 2017
CL London, ENGLAND
DE Image classification; CNN; deep learning; transfer learning; remote
   sensing
ID REPRESENTATION; SCENE
AB In this paper we propose a stacking approach for Convolutional Neural Network (CNN) transfer learning ensemble for remote sensing imagery, in particular for the task of scene classification. We propose to use a combination of features produced by an ensemble of CNNs as one feature vector for classification. At the same time the original data set can be processed with different up-sampling and image enhancement methods and then used to obtain more features from pretrained networks. We investigate both fine-tuning and non fine-tuning approaches for transfer learning. We have selected Brazilian Coffee Scenes data set as a benchmark to measure the classification accuracy. Proposed method in case of a non fine-tuned model shows 89.18% classification accuracy. For a fine-tuned model the best classification rate is 96.11%. We analyzed how networks that have appeared recently (VGG-19 and SqueezeNet), can be applied to the task of transfer learning for remote sensing. Also we describe a method of decreasing processing time and memory consumption while preserving classification accuracy by using feature selection based on feature importance.
CR Carkacioglu A, 2003, PATTERN RECOGN, V36, P2615, DOI 10.1016/S0031-3203(03)00171-7
   Castelluccio M., 2015, ARXIV150800092
   DALAL N, 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Donahue J., 2013, ABS13101531 CORR
   Geurts P., MACHINE LEARNING, V63, P3
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Iandola F., 2016, ARXIV160207360
   Jia Y., 2014, ARXIV14085093
   Krizhevsky A., 2014, NIPS 2012 NEURAL INF
   Li Y., 2015, 151107543 CORR
   Nascimento M. A., 2002, INT C INF KNOWL MAN, P102
   Nogueira K., 2016, ABS160201517 CORR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Penatti O. A. B., 2015, EARTHVISION 2015 BOS
   Razavian A- S., 2014, CORR, V1403, P6382
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   SMOLA A. J., 2004, STAT COMPUT, V14, P3, DOI DOI 10.1023/B:STC0.0000035301.49549.88
   Still M., 2005, DEFINITIVE GUIDE IMA, P335
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Torrey L., 2009, HDB RES MACHINE LEAR
   Uba N. K., 2016, THESIS
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Xie M., 2016, P 30 AAAI C ART INT
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yosinski J, 2014, ADV NEUR IN, V27
   Zadrozny B., 2002, P 8 ACM SIGKDD INT C, P694, DOI DOI 10.1007/S10994-013-5343-X
   Zeiler M. D., 2013, ECCV 2014
NR 30
TC 1
Z9 1
BN 978-1-5090-6435-9
PY 2017
BP 599
EP 608
UT WOS:000456827800079
ER

PT S
AU Kieffer, B
   Babaie, M
   Kalra, S
   Tizhoosh, HR
AF Kieffer, Brady
   Babaie, Morteza
   Kalra, Shivam
   Tizhoosh, H. R.
GP IEEE
TI Convolutional Neural Networks for Histopathology Image Classification:
   Training vs. Using Pre-Trained Networks
SO PROCEEDINGS OF THE 2017 SEVENTH INTERNATIONAL CONFERENCE ON IMAGE
   PROCESSING THEORY, TOOLS AND APPLICATIONS (IPTA 2017)
SE International Conference on Image Processing Theory Tools and
   Applications
CT 7th International Conference on Image Processing Theory, Tools and
   Applications (IPTA)
CY NOV 28-DEC 01, 2017
CL Montreal, CANADA
DE Image retrieval; medical imaging; deep learning; CNNs; digital
   pathology; image classification; deep features; VGG; Inception
AB We explore the problem of classification within a medical image data-set based on a feature vector extracted from the deepest layer of pre-trained Convolution Neural Networks. We have used feature vectors from several pre-trained structures, including networks with/without transfer learning to evaluate the performance of pre-trained deep features versus CNNs which have been trained by that specific dataset as well as the impact of transfer learning with a small number of samples. All experiments are done on Kimia Path24 dataset which consists of 27,055 histopathology training patches in 24 tissue texture classes along with 1,325 test patches for evaluation. The result shows that pre-trained networks are quite competitive against training from scratch. As well, fine-tuning does not seem to add any tangible improvement for VGG16 to justify additional training while we observed considerable improvement in retrieval and classification accuracy when we fine-tuned the Inception structure.
CR Babaie M., CLASSIFICATION RETRI
   Bar Y, 2015, P SOC PHOTO-OPT INS, V9414, P94140
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chollet  F., 2015, KERAS
   DENG J, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Jones E, 2001, SCIPY OPEN SOURCE SC
   Karvelis Petros S, 2006, Conf Proc IEEE Eng Med Biol Soc, V1, P3009
   Khatami A., 2017, 2017 1 INT C LAT TRE, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Naik S., 2007, MIAAB WORKSH, P1
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petushi Sokol, 2006, BMC Med Imaging, V6, P14, DOI 10.1186/1471-2342-6-14
   R. Kotikalapudi and contributors, 2017, KER VIS
   Selvaraju R. R., 2016, GRAD CAM VISUAL EXPL
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tizhoosh H. R., 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P617, DOI 10.1007/978-3-319-50835-1_55
   Tizhoosh HR, 2015, IEEE IMAGE PROC, P818, DOI 10.1109/ICIP.2015.7350913
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Yi D., 2017, CORR
   Yu Dong, 2011, 12 ANN C INT SPEECH
   ZEILER MD, 2014, VIS UND CONV NETW, V8689, P818
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
NR 29
TC 1
Z9 1
SN 2154-512X
BN 978-1-5386-1842-4
PY 2017
UT WOS:000428743900073
ER

EF